[
    {
        "number": 1471,
        "label": "no",
        "change": [
            "class ConvBertModelTest(ModelTesterMixin, unittest.TestCase):",
            "def test_model_for_input_embeds(self):",
            "batch_size = 2",
            "seq_length = 10",
            "-        inputs_embeds = torch.rand([batch_size, seq_length, 768])",
            "+        inputs_embeds = torch.rand([batch_size, seq_length, 768], device=torch_device)",
            "config = self.model_tester.get_config()",
            "model = ConvBertModel(config=config)",
            "model.to(torch_device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1473,
        "label": "no",
        "change": [
            "class Seq2Seq(Layer):",
            "return_seq_2d=False,",
            "name='seq2seq',",
            "):",
            "+        if cell_init_args is None:",
            "+            cell_init_args = {'state_is_tuple': True}",
            "+",
            "Layer.__init__(self, name=name)",
            "if cell_fn is None:",
            "raise Exception(\"Please put in cell_fn\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1474,
        "label": "no",
        "change": [
            "transition_probabilities = torch.tensor(",
            "",
            "",
            "def take_step(",
            "-    last_predictions: torch.Tensor, state: Dict[str, torch.Tensor]",
            "+    last_predictions: torch.Tensor, state: Dict[str, torch.Tensor], step: int",
            ") -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:",
            "\"\"\"",
            "Take decoding step."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1475,
        "label": "no",
        "change": [
            "class InsertionTransformerModel(LevenshteinTransformerModel):",
            "cut_off = output_tokens.ne(self.pad).sum(1).max()",
            "output_tokens = output_tokens[:, :cut_off]",
            "output_scores = output_scores[:, :cut_off]",
            "-        return {\"output_tokens\": output_tokens, \"output_scores\": output_scores}",
            "+        return {\"output_tokens\": output_tokens, \"output_scores\": output_scores, \"attn\": None}",
            "",
            "",
            "class InsertionTransformerDecoder(LevenshteinTransformerDecoder):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1476,
        "label": "no",
        "change": [
            "class BinaryOutputFeature(BinaryFeatureMixin, OutputFeature):",
            "confidence_penalty=self.loss[\"confidence_penalty\"],",
            ")",
            "",
            "-    def create_calibration_module(self, feature) -> torch.nn.Module:",
            "+    def create_calibration_module(self, feature: BinaryOutputFeatureConfig) -> torch.nn.Module:",
            "\"\"\"Creates the appropriate calibration module based on the feature config.",
            "",
            "Today, only one type of calibration (\"temperature_scaling\") is available, but more options may be supported in",
            "the future.",
            "\"\"\"",
            "-        if feature.get(\"calibration\"):",
            "+        if feature.calibration:",
            "calibration_cls = calibration.get_calibration_cls(BINARY, \"temperature_scaling\")",
            "return calibration_cls(binary=True)",
            "return None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1477,
        "label": "yes",
        "change": [
            "class RandomMutator(Mutator):",
            "result = dict()",
            "for mutable in self.mutables:",
            "if isinstance(mutable, LayerChoice):",
            "-                gen_index = torch.randint(high=mutable.length, size=(1, ))",
            "-                result[mutable.key] = F.one_hot(gen_index, num_classes=mutable.length).view(-1).bool()",
            "+                gen_index = torch.randint(high=len(mutable), size=(1, ))",
            "+                result[mutable.key] = F.one_hot(gen_index, num_classes=len(mutable)).view(-1).bool()",
            "elif isinstance(mutable, InputChoice):",
            "if mutable.n_chosen is None:",
            "result[mutable.key] = torch.randint(high=2, size=(mutable.n_candidates,)).view(-1).bool()"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 1479,
        "label": "no",
        "change": [
            "\"source\": [",
            "\"# Get activations of a few sample layers\\n\",",
            "\"activations = model.run_graph([image], [\\n\",",
            "-    \"    (\\\"input_image\\\",        model.keras_model.get_layer(\\\"input_image\\\").output),\\n\",",
            "+    \"    (\\\"input_image\\\",        tf.identity(model.keras_model.get_layer(\\\"input_image\\\").output)),\\n\",",
            "\"    (\\\"res2c_out\\\",          model.keras_model.get_layer(\\\"res2c_out\\\").output),\\n\",",
            "\"    (\\\"res3c_out\\\",          model.keras_model.get_layer(\\\"res3c_out\\\").output),\\n\",",
            "\"    (\\\"res4w_out\\\",          model.keras_model.get_layer(\\\"res4w_out\\\").output),  # for resnet100\\n\","
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1480,
        "label": "no",
        "change": [
            "def sample_autoregressive(partial_sequences,",
            "if has_partial_sequences and remove_partial_sequences:",
            "# remove partial sequences from outputs",
            "partial_length = mtf.reduce_sum(",
            "-            mtf.to_int32(mtf.not_equal(partial_sequences, 0)),",
            "+            mtf.to_int32(mtf.not_equal(partial_sequences, padding_id)),",
            "reduced_dim=length_dim)",
            "outputs = mtf.dynamic_shift(",
            "outputs, -partial_length, length_dim, wrap=False)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1481,
        "label": "no",
        "change": [
            "def convert_bart_checkpoint(checkpoint_path, pytorch_dump_folder_path, hf_checkp",
            "model = BartForConditionalGeneration(config).eval()  # an existing summarization ckpt",
            "model.model.load_state_dict(state_dict)",
            "if hasattr(model, \"lm_head\"):",
            "-                model.lm_head = _make_linear_from_emb(model.model.shared)",
            "+                model.lm_head = make_linear_from_emb(model.model.shared)",
            "new_model_outputs = model.model(tokens)[0]",
            "",
            "# Check results"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1484,
        "label": "no",
        "change": [
            "class Energy(AbsFeatsExtract):",
            "else x.new_tensor(0.0)",
            "for start, end in zip(d_cumsum[:-1], d_cumsum[1:])",
            "]",
            "-        return torch.stack(x_avg).unsqueeze(-1)",
            "+        return torch.stack(x_avg)",
            "",
            "@staticmethod",
            "def _adjust_num_frames(x: torch.Tensor, num_frames: torch.Tensor) -> torch.Tensor:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1485,
        "label": "no",
        "change": [
            "class TFRobertaLMHead(tf.keras.layers.Layer):",
            "config.hidden_size, kernel_initializer=get_initializer(config.initializer_range), name=\"dense\"",
            ")",
            "self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=\"layer_norm\")",
            "-        self.act = tf.keras.layers.Activation(gelu)",
            "+        self.act = get_tf_activation(\"gelu\")",
            "",
            "# The output weights are the same as the input embeddings, but there is",
            "# an output-only bias for each token."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1487,
        "label": "no",
        "change": [
            "class EpsilonGreedy(Exploration):",
            "",
            "chose_random = tf.random_uniform(",
            "tf.stack([batch_size]),",
            "-            minval=0, maxval=1, dtype=epsilon.dtype) \\",
            "+            minval=0, maxval=1, dtype=tf.float32) \\",
            "< epsilon",
            "",
            "action = tf.cond("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1489,
        "label": "no",
        "change": [
            "class Layer_Convolution_3D_Test(unittest.TestCase):",
            "",
            "cls.input_layer = tl.layers.InputLayer(x, name='input_layer')",
            "",
            "-        print(\"input:\", cls.input_layer.all_layers)",
            "-",
            "cls.n1 = tl.layers.Conv3dLayer(cls.input_layer, shape=(2, 2, 2, 3, 32), strides=(1, 2, 2, 2, 1))",
            "",
            "cls.n2 = tl.layers.DeConv3dLayer("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1490,
        "label": "no",
        "change": [
            "class AngleProtoLossTests(unittest.TestCase):",
            "",
            "# check speaker loss with orthogonal d-vectors",
            "dummy_input = T.empty(3, 64)",
            "-        dummy_input = T.nn.init.orthogonal(dummy_input)",
            "+        dummy_input = T.nn.init.orthogonal_(dummy_input)",
            "dummy_input = T.cat(",
            "[",
            "dummy_input[0].repeat(5, 1, 1).transpose(0, 1),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1491,
        "label": "no",
        "change": [
            "class Categorical(Distribution):",
            "_ps, _vs, _one_hot = self._sanitize_input(ps, vs, one_hot)",
            "_vs = self._process_v(_vs)",
            "_ps, _vs = self._process_p(_ps, _vs)",
            "-        sample = Variable(torch.multinomial(_ps.data, 1, replacement=True))",
            "+        sample = Variable(torch.multinomial(_ps.data, 1, replacement=True).type_as(_ps.data))",
            "if _vs is not None:",
            "if isinstance(_vs, np.ndarray):",
            "# always returns a 2-d (unsqueezed 1-d) list"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1494,
        "label": "no",
        "change": [
            "class Encoder(torch.nn.Module):",
            "self.norm = LayerNorm(args.adim)",
            "",
            "def forward(self, x, mask):",
            "+        \"\"\"Embed positions in tensor",
            "+",
            "+        :param torch.Tensor x: input tensor",
            "+        :param torch.Tensor mask: input mask",
            "+        :return: position embedded tensor and mask",
            "+        :rtype Tuple[torch.Tensor, torch.Tensor]:",
            "+        \"\"\"",
            "if isinstance(self.input_layer, Conv2dSubsampling):",
            "x, mask = self.input_layer(x, mask)",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1495,
        "label": "no",
        "change": [
            "class BeitRelativePositionBias(nn.Module):",
            "# get pair-wise relative position index for each token inside the window",
            "coords_h = torch.arange(window_size[0])",
            "coords_w = torch.arange(window_size[1])",
            "-        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww",
            "+        coords = torch.stack(meshgrid([coords_h, coords_w], indexing=\"ij\"))  # 2, Wh, Ww",
            "coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww",
            "relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww",
            "relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1498,
        "label": "no",
        "change": [
            "def target_mask(ys_in_pad, ignore_id):",
            ":param torch.Tensor ys_pad: batch of padded target sequences (B, Lmax)",
            ":param int ignore_id: index of padding",
            ":param torch.dtype dtype: result dtype",
            "-    :rtype: torch.Tensor",
            "+    :rtype: torch.Tensor (B, Lmax, Lmax)",
            "\"\"\"",
            "ys_mask = ys_in_pad != ignore_id",
            "m = subsequent_mask(ys_mask.size(-1), device=ys_mask.device).unsqueeze(0)",
            "+",
            "+    #ys_mask.unsqueeze(-2).shape: (1, Lmax, Lmax)",
            "+    #m.shape: (B, 1, Lmax)",
            "return ys_mask.unsqueeze(-2) & m"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1499,
        "label": "no",
        "change": [
            "def make_loss_args(**kwargs):",
            "",
            "",
            "@pytest.mark.skipif(",
            "-    LooseVersion(torch.__version__) < LooseVersion(\"1.4\"),",
            "+    V(torch.__version__) < V(\"1.4\"),",
            "reason=\"Pytorch >= 1.4 is required.\",",
            ")",
            "@pytest.mark.skipif("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1503,
        "label": "no",
        "change": [
            "class Graph(kerastuner.HyperModel, serializable.Serializable):",
            "",
            "def build(self, hp):",
            "\"\"\"Build the HyperModel into a Keras Model.\"\"\"",
            "+        tf.keras.backend.clear_session()",
            "self._register_hps(hp)",
            "self.compile()",
            "real_nodes = {}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1506,
        "label": "no",
        "change": [
            "class HRNet(nn.Module):",
            "return y_list",
            "",
            "def train(self, mode=True):",
            "+        \"\"\"Convert the model into training mode whill keeping the normalization",
            "+        layer freezed\"\"\"",
            "super(HRNet, self).train(mode)",
            "if mode and self.norm_eval:",
            "for m in self.modules():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1507,
        "label": "yes",
        "change": [
            "def indices_where(",
            "def shape(",
            "x: Union[tf.Tensor, tf.Variable],",
            "as_array: bool = False,",
            "-) -> Union[tf.Tensor, tf.Variable, TensorShape]:",
            "+) -> Union[tf.Tensor, ivy.Shape, ivy.Array]:",
            "if as_array:",
            "-        return tf.shape(x)",
            "+        return ivy.array(tf.shape(x))",
            "else:",
            "-        return tuple(x.shape)",
            "+        return ivy.Shape(x.shape)",
            "",
            "",
            "def get_num_dims(x, as_tensor=False):"
        ],
        "comments": "",
        "Symptom": "return warning",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 1508,
        "label": "no",
        "change": [
            "def matrix_rank(",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "# ToDo: add support for default rtol value here, for the case where None is provided",
            "-    return torch.linalg.matrix_rank(x, rtol, out=out)",
            "+    return torch.linalg.matrix_rank(x, rtol=rtol, out=out)",
            "",
            "",
            "def matrix_transpose(x: torch.Tensor) -> torch.Tensor:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1509,
        "label": "no",
        "change": [
            "class TestInitializers(AllenNlpTestCase):",
            "block_orthogonal(tensor, [7, 2, 1])",
            "",
            "def test_uniform_unit_scaling_can_initialize(self):",
            "-        tensor = Variable(torch.zeros([10, 6]))",
            "+        tensor = torch.zeros([10, 6])",
            "uniform_unit_scaling(tensor, \"linear\")",
            "",
            "assert tensor.data.max() < math.sqrt(3/10)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1510,
        "label": "no",
        "change": [
            "class TorchHook:",
            "",
            "def hooked__repr__(self):",
            "if hasattr(self, \"child\"):",
            "-                return \"Parameter containing:\\n\" + self.child.__repr__()",
            "+                return \"&Parameter containing:\\n\" + self.child.__repr__()",
            "else:",
            "return self.native_param___repr__()",
            "",
            "-        torch.nn.Parameter.__repr__ = hooked__repr__",
            "+        # torch.nn.Parameter.__repr__ = hooked__repr__",
            "",
            "# Hook .data to handle chain assignment when needed"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1511,
        "label": "no",
        "change": [
            "class MedicalDialog(datasets.GeneratorBasedBuilder):",
            "path_to_manual_file = os.path.abspath(os.path.expanduser(dl_manager.manual_dir))",
            "if not os.path.exists(path_to_manual_file):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('medical_dialog', data_dir=...)`. Manual download instructions: {})\".format(",
            "-                    path_to_manual_file, self.manual_download_instructions",
            "-                )",
            "+                f\"{path_to_manual_file} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('medical_dialog', data_dir=...)`. Manual download instructions: {self.manual_download_instructions})\"",
            ")",
            "",
            "filepaths = ["
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1513,
        "label": "no",
        "change": [
            "class TFTapasPreTrainedModel(TFPreTrainedModel):",
            "@tf.function(",
            "input_signature=[",
            "{",
            "-                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),",
            "+                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),",
            "\"attention_mask\": tf.TensorSpec((None, None), tf.float32, name=\"attention_mask\"),",
            "-                \"token_type_ids\": tf.TensorSpec((None, None, None), tf.int32, name=\"token_type_ids\"),",
            "+                \"token_type_ids\": tf.TensorSpec((None, None, None), tf.int64, name=\"token_type_ids\"),",
            "}",
            "]",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1516,
        "label": "no",
        "change": [
            "def selu(x):",
            "\"\"\"",
            "alpha = 1.6732632423543772848170429916717",
            "scale = 1.0507009873554804934193349852946",
            "-    return scale * tf.nn.elu(x, alpha)",
            "+    return scale*tf.where(x>=0.0, x, alpha*tf.nn.elu(x))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1517,
        "label": "no",
        "change": [
            "class TFDeiTForMaskedImageModeling(TFDeiTPreTrainedModel):",
            "total_loss = tf.reduce_sum(reconstruction_loss * mask)",
            "num_masked_pixels = (tf.reduce_sum(mask) + 1e-5) * self.config.num_channels",
            "masked_im_loss = total_loss / num_masked_pixels",
            "+            masked_im_loss = tf.reshape(masked_im_loss, (1,))",
            "",
            "if not return_dict:",
            "output = (reconstructed_pixel_values,) + outputs[1:]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1520,
        "label": "no",
        "change": [
            "def imag(",
            "*,",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "-    if(input.dtype != torch.complex64):",
            "+    if input.dtype != torch.complex64:",
            "input = input.to(torch.complex64)",
            "return torch.imag(input)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1523,
        "label": "no",
        "change": [
            "class Searcher:",
            "if not re.search('out of memory', str(e)):",
            "raise e",
            "if self.verbose:",
            "-                print('out of memory')",
            "+                print('\\nCurrent model size is too big. Discontinuing training this model to search for other models.')",
            "Constant.MAX_MODEL_SIZE = graph.size() - 1",
            "return",
            "finally:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1525,
        "label": "no",
        "change": [
            "class BigBirdModelTest(ModelTesterMixin, unittest.TestCase):",
            "self.assertTrue(",
            "torch.allclose(",
            "hidden_states[0, 0, :5],",
            "-                    torch.tensor([1.4943, 0.0928, 0.8254, -0.2816, -0.9788], device=torch_device),",
            "+                    torch.tensor([1.4825, 0.0774, 0.8226, -0.2962, -0.9593], device=torch_device),",
            "atol=1e-3,",
            ")",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1527,
        "label": "no",
        "change": [
            "class AttentionReference(torch.nn.Module):",
            "B, _, C = psd_in.size()[:3]",
            "assert psd_in.size(2) == psd_in.size(3), psd_in.size()",
            "# psd_in: (B, F, C, C)",
            "-        psd = psd_in.masked_fill(torch.eye(C, dtype=torch.uint8,",
            "+        datatype = torch.bool if is_torch_1_2_plus else torch.uint8",
            "+        psd = psd_in.masked_fill(torch.eye(C, dtype=datatype,",
            "device=psd_in.device), 0)",
            "# psd: (B, F, C, C) -> (B, C, F)",
            "psd = (psd.sum(dim=-1) / (C - 1)).transpose(-1, -2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1528,
        "label": "no",
        "change": [
            "class CategoricalAccuracyTest(AllenNlpTestCase):",
            "assert accuracy.get_metric(reset=True) == (0.25 + 1 + 0.5) / 3.0",
            "",
            "# # # Test with mask",
            "-        mask = torch.tensor([1, 0, 1], device=device)",
            "+        mask = torch.BoolTensor([True, False, True], device=device)",
            "targets = torch.tensor([2, 1, 4], device=device)",
            "accuracy(predictions, targets, mask)",
            "assert accuracy.get_metric(reset=True) == (0.25 + 0.5) / 2.0"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1529,
        "label": "no",
        "change": [
            "def load_pointcloud_ply(filename: str, header_size: int = 8) -> torch.Tensor:",
            "if not os.path.isfile(filename):",
            "raise ValueError(\"Input filename is not an existing file.\")",
            "if not (isinstance(header_size, int) and header_size > 0):",
            "-        raise TypeError(\"Input header_size must be a positive integer. Got {}.\".format(header_size))",
            "+        raise TypeError(f\"Input header_size must be a positive integer. Got {header_size}.\")",
            "# open the file and populate tensor",
            "-    with open(filename, 'r') as f:",
            "+    with open(filename) as f:",
            "points = []",
            "",
            "# skip header"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1532,
        "label": "yes",
        "change": [
            "def remainder(",
            "res_floored = torch.where(res >= 0, torch.floor(res), torch.ceil(res))",
            "diff = res - res_floored",
            "diff, x2 = ivy.promote_types_of_inputs(diff, x2)",
            "-        return torch.mul(diff, x2, out=out).to(x1.dtype)",
            "+        return torch.round(torch.mul(diff, x2, out=out), out=out).to(x1.dtype)",
            "return torch.remainder(x1, x2, out=out)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 1533,
        "label": "no",
        "change": [
            "class NormalChol(Distribution):",
            "mu, L = self._sanitize_input(mu, L)",
            "ll_1 = Variable(torch.Tensor([-0.5 * mu.size(0) * np.log(2.0 * np.pi)])",
            ".type_as(mu.data))",
            "+        if L.dim() > 2:",
            "+            raise NotImplementedError(\"torch.diag() does not support tesors of dim > 2\")",
            "ll_2 = -torch.sum(torch.log(torch.diag(L)))",
            "# torch.trtrs() does not support cuda tensors.",
            "x_chols = torch.trtrs((x - mu).unsqueeze(1).data.cpu(), L.data.cpu(), False)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1535,
        "label": "yes",
        "change": [
            "def guide(observed_data):",
            "",
            "# do variational inference using KL_QP",
            "print(\"doing inference with simulated data\")",
            "-verbose = False",
            "+verbose = True",
            "n_steps = 3001",
            "kl_optim = KL_QP(model, guide, pyro.optim(optim.Adam, {\"lr\": 0.003, \"betas\": (0.93, 0.993)}))",
            "for step in range(n_steps):",
            "loss = kl_optim.step(observed_data)",
            "if step % 100 == 0:",
            "if verbose:",
            "-            print(\"[epoch %d] mean_mu: %.3f\" % (step, pyro.param(\"mean_mu\").data[0, 0]))",
            "+            print(\"[epoch %d] mean_mu: %.3f\" % (step, pyro.param(\"mean_mu\").data[0]))",
            "print(\"[epoch %d] sigma_mu: %.3f\" % (step,",
            "-                                                 torch.exp(pyro.param(\"log_sigma_mu\")).data[0, 0]))",
            "+                                                 torch.exp(pyro.param(\"log_sigma_mu\")).data[0]))",
            "else:",
            "print(\".\", end='')",
            "sys.stdout.flush()"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1536,
        "label": "no",
        "change": [
            "class SingleDevicePlugin(TrainingTypePlugin):",
            "",
            "self._model.to(self.root_device)",
            "",
            "-    def connect(self, model: torch.nn.Module) -> torch.nn.Module:",
            "-        self._model = model",
            "+    def setup(self, model: torch.nn.Module) -> torch.nn.Module:",
            "self.model_to_device()",
            "return self.model"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1537,
        "label": "no",
        "change": [
            "class AdaptiveSoftmax(nn.Module):",
            "",
            "head_sz = self.cutoff[0] + len(self.tail)",
            "log_probs[:, :head_sz] = self.lsm(head_y)",
            "-        tail_priors = log_probs[:, self.cutoff[0] - 1: head_sz - 1].clone()",
            "+        tail_priors = log_probs[:, self.cutoff[0] - self.buggy_offset: head_sz - self.buggy_offset].clone()",
            "",
            "for i in range(len(self.tail)):",
            "start = self.cutoff[i]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1538,
        "label": "yes",
        "change": [
            "class UNet2DConditionModel(ModelMixin, ConfigMixin):",
            "# TODO: this requires sync between CPU and GPU. So try to pass timesteps as tensors if you can",
            "# This would be a good case for the `match` statement (Python 3.10+)",
            "is_mps = sample.device.type == \"mps\"",
            "-            if torch.is_floating_point(timesteps):",
            "+            if isinstance(timestep, float):",
            "dtype = torch.float32 if is_mps else torch.float64",
            "else:",
            "dtype = torch.int32 if is_mps else torch.int64"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 1539,
        "label": "no",
        "change": [
            "class TestCameraConversions(TestCaseMixin, unittest.TestCase):",
            "cameras_opencv_to_pytorch3d = cameras_from_opencv_projection(",
            "R, tvec, camera_matrix, image_size",
            ")",
            "+        self.assertEqual(cameras_opencv_to_pytorch3d.device, device)",
            "",
            "# project the 3D points with converted cameras to screen space.",
            "pts_proj_pytorch3d_screen = cameras_opencv_to_pytorch3d.transform_points_screen("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1540,
        "label": "no",
        "change": [
            "class CapsNet(object):",
            "# Method 2. masking with true label, default mode",
            "else:",
            "# self.masked_v = tf.matmul(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, 10, 1)), transpose_a=True)",
            "-                self.masked_v = tf.multply(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, 10, 1)))",
            "+                self.masked_v = tf.multiply(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, 10, 1)))",
            "self.v_length = tf.sqrt(tf.reduce_sum(tf.square(self.caps2), axis=2, keep_dims=True) + epsilon)",
            "",
            "# 2. Reconstructe the MNIST images with 3 FC layers"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1541,
        "label": "no",
        "change": [
            "class VectorQuantizerEMA(base.Module):",
            "tf.reduce_sum(self.embeddings**2, 0, keepdims=True))",
            "",
            "encoding_indices = tf.argmax(-distances, 1)",
            "-    encodings = tf.one_hot(encoding_indices, self.num_embeddings)",
            "+    encodings = tf.one_hot(encoding_indices,",
            "+                           self.num_embeddings,",
            "+                           dtype=distances.dtype)",
            "",
            "# NB: if your code crashes with a reshape error on the line below about a",
            "# Tensor containing the wrong number of values, then the most likely cause"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1543,
        "label": "yes",
        "change": [
            "def test_utilities(head_size):",
            "mask[head_size:, head_size:] = 0.",
            "mask.view(-1)[::size + 1][head_size:] = 1.",
            "arrowhead_full = mask * cov",
            "-    expected = torch.flip(torch.flip(arrowhead_full, (-2, -1)).cholesky(), (-2, -1))",
            "+    expected = torch.flip(",
            "+        torch.linalg.cholesky(torch.flip(arrowhead_full, (-2, -1))), (-2, -1)",
            "+    )",
            "# test if those flip ops give expected upper triangular values",
            "assert_close(expected.triu(), expected)",
            "assert_close(expected.matmul(expected.t()), arrowhead_full)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1544,
        "label": "no",
        "change": [
            "unique_inverse.unsupported_dtypes = (\"float16\",)",
            "",
            "",
            "def unique_values(",
            "-    x: torch.Tensor, *, out: Optional[torch.Tensor] = None",
            "+    x: torch.Tensor, /, *, out: Optional[torch.Tensor] = None",
            ") -> torch.Tensor:",
            "ret = torch.unique(x)",
            "return ret"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1545,
        "label": "no",
        "change": [
            "def run_torch_model(",
            "input_tensors: List[torch.Tensor],",
            "dtype: torch.dtype = torch.float32,",
            ") -> List[torch.Tensor]:",
            "+    torch_model.eval()",
            "if torch.cuda.is_available():",
            "torch_model.cuda()",
            "if dtype != torch.half:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1546,
        "label": "no",
        "change": [
            "class ESPnetDiarizationModel(AbsESPnetModel):",
            "num_frames = np.sum(length)",
            "return (correct, num_frames, speech_scored, speech_miss, speech_falarm,",
            "speaker_scored, speaker_miss, speaker_falarm,",
            "-                speaker_error)",
            "\\ No newline at end of file",
            "+                speaker_error)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1547,
        "label": "no",
        "change": [
            "class FreeAnchorRetinaHead(RetinaHead):",
            "box_cls_prob = torch.sparse.sum(",
            "object_cls_box_prob, dim=0).to_dense()",
            "",
            "-                indices = torch.nonzero(box_cls_prob).t_()",
            "+                indices = torch.nonzero(box_cls_prob, as_tuple=False).t_()",
            "if indices.numel() == 0:",
            "image_box_prob = torch.zeros(",
            "anchors_.size(0),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1548,
        "label": "no",
        "change": [
            "class TrainingArguments:",
            "torch.distributed.init_process_group(backend=\"nccl\")",
            "device = torch.device(\"cuda\", self.local_rank)",
            "n_gpu = 1",
            "+",
            "+        if device.type == \"cuda\":",
            "+            torch.cuda.set_device(device)",
            "+",
            "return device, n_gpu",
            "",
            "@property"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1549,
        "label": "no",
        "change": [
            "class TFEmbeddings(tf.keras.layers.Layer):",
            "input_shape = shape_list(inputs_embeds)[:-1]",
            "",
            "if position_ids is None:",
            "-            position_ids = tf.range(start=0, limit=input_shape[-1])[tf.newaxis, :]",
            "+            position_ids = tf.expand_dims(tf.range(start=0, limit=input_shape[-1]), axis=0)",
            "",
            "position_embeds = tf.gather(params=self.position_embeddings, indices=position_ids)",
            "position_embeds = tf.tile(input=position_embeds, multiples=(input_shape[0], 1, 1))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1552,
        "label": "no",
        "change": [
            "class GitProjection(nn.Module):",
            "super().__init__()",
            "self.config = config",
            "self.visual_projection = nn.Sequential(",
            "-            nn.Linear(config.vision_config.hidden_size, config.hidden_size), nn.LayerNorm(config.hidden_size)",
            "+            nn.Linear(config.vision_config.hidden_size, config.hidden_size),",
            "+            nn.LayerNorm(config.hidden_size, eps=config.vision_config.layer_norm_eps),",
            ")",
            "",
            "def forward(self, embeddings: torch.Tensor) -> torch.Tensor:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1554,
        "label": "no",
        "change": [
            "class PretrainedConfig(PushToHubMixin):",
            "self.output_hidden_states = kwargs.pop(\"output_hidden_states\", False)",
            "self.output_attentions = kwargs.pop(\"output_attentions\", False)",
            "self.torchscript = kwargs.pop(\"torchscript\", False)  # Only used by PyTorch models",
            "+        self.torch_dtype = kwargs.pop(\"torch_dtype\", None)  # Only used by PyTorch models",
            "self.use_bfloat16 = kwargs.pop(\"use_bfloat16\", False)",
            "self.pruned_heads = kwargs.pop(\"pruned_heads\", {})",
            "self.tie_word_embeddings = kwargs.pop("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1555,
        "label": "no",
        "change": [
            "def test_multifile_join_dataset(tmpdir, f_type):",
            "assert output_df.shape[0] == train_df.shape[0] + test_df.shape[0] + val_df.shape[0]",
            "",
            "assert dataset.state == DatasetState.TRANSFORMED",
            "+    ludwig.datasets._get_dataset_configs.cache_clear()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1556,
        "label": "no",
        "change": [
            "class TFDistilBertForMultipleChoice(TFDistilBertPreTrainedModel, TFMultipleChoic",
            "Returns:",
            "tf.Tensor with dummy inputs",
            "\"\"\"",
            "-        return {\"input_ids\": tf.constant(MULTIPLE_CHOICE_DUMMY_INPUTS)}",
            "+        return {\"input_ids\": tf.constant(MULTIPLE_CHOICE_DUMMY_INPUTS, dtype=tf.int32)}",
            "",
            "@unpack_inputs",
            "@add_start_docstrings_to_model_forward("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1557,
        "label": "no",
        "change": [
            "class Layer_Flow_Control_Test(unittest.TestCase):",
            "network = tl.layers.ReshapeLayer(net_mux, shape=(-1, 800), name='reshape')",
            "network = tl.layers.DropoutLayer(network, keep=0.5, name='drop3')",
            "# output layer",
            "-        network = tl.layers.DenseLayer(network, n_units=10, act=tf.identity, name='output')",
            "+        network = tl.layers.DenseLayer(network, n_units=10, name='output')",
            "",
            "network.print_layers()",
            "network.print_params(False)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1558,
        "label": "no",
        "change": [
            "class NASFCOSHead(FCOSHead):",
            "\"\"\"Initialize weights of the head.\"\"\"",
            "# retinanet_bias_init",
            "bias_cls = bias_init_with_prob(0.01)",
            "-        normal_init(self.fcos_reg, std=0.01)",
            "-        normal_init(self.fcos_centerness, std=0.01)",
            "-        normal_init(self.fcos_cls, std=0.01, bias=bias_cls)",
            "+        normal_init(self.conv_reg, std=0.01)",
            "+        normal_init(self.conv_centerness, std=0.01)",
            "+        normal_init(self.conv_cls, std=0.01, bias=bias_cls)",
            "",
            "for branch in [self.cls_convs, self.reg_convs]:",
            "for module in branch.modules():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1559,
        "label": "no",
        "change": [
            "class GCNWithJK(torch.nn.Module):",
            "self.convs = torch.nn.ModuleList()",
            "for i in range(num_layers - 1):",
            "self.convs.append(GCNConv(hidden, hidden))",
            "-        self.lin1 = torch.nn.Linear(num_layers * hidden, hidden)",
            "+        self.lin1 = Linear(num_layers * hidden, hidden)",
            "self.lin2 = Linear(hidden, dataset.num_classes)",
            "self.mode = mode",
            "self.kwargs = kwargs"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1560,
        "label": "no",
        "change": [
            "class DataParallelPlugin(ParallelPlugin):",
            "",
            "else:",
            "",
            "-            def _reduce(tensor: torch.Tensor):",
            "-                dtype_tensor = tensor.dtype",
            "-                return tensor.float().mean().type(dtype_tensor)",
            "+            def _reduce(t: torch.Tensor):",
            "+                dtype_tensor = t.dtype",
            "+                return t.float().mean().type(dtype_tensor)",
            "",
            "tensor = apply_to_collection(tensor, torch.Tensor, _reduce)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1562,
        "label": "no",
        "change": [
            "class FastModel(TFModelV2):",
            "",
            "if not self._registered:",
            "self.register_variables(",
            "-                tf.get_collection(",
            "-                    tf.GraphKeys.TRAINABLE_VARIABLES, scope=\".+/model/.+\"))",
            "+                tf1.get_collection(",
            "+                    tf1.GraphKeys.TRAINABLE_VARIABLES, scope=\".+/model/.+\"))",
            "self._registered = True",
            "",
            "return output, []"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1565,
        "label": "yes",
        "change": [
            "class CharacterEmbeddings(TokenEmbeddings):",
            "longest_token_in_sentence = max(chars2_length)",
            "tokens_mask = torch.zeros((len(tokens_sorted_by_length), longest_token_in_sentence),",
            "dtype=torch.long, device=flair.device)",
            "+",
            "for i, c in enumerate(tokens_sorted_by_length):",
            "-                tokens_mask[i, :chars2_length[i]] = c",
            "+                tokens_mask[i, :chars2_length[i]] = torch.tensor(c, dtype=torch.long, device=flair.device)",
            "",
            "# chars for rnn processing",
            "chars = tokens_mask"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 1567,
        "label": "no",
        "change": [
            "class ElmoLstm(_EncoderBase):",
            "batch_size,",
            "sequence_length_difference,",
            "stacked_sequence_output[0].size(-1)).fill_(0)",
            "-            zeros = torch.autograd.Variable(zeros)",
            "+            zeros = Variable(zeros)",
            "stacked_sequence_output = torch.cat([stacked_sequence_output, zeros], 2)",
            "",
            "self._update_states(final_states, restoration_indices)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1568,
        "label": "no",
        "change": [
            "class MlpMixer(nn.Module):",
            "act_layer=act_layer, drop=drop_rate, drop_path=drop_path_rate)",
            "for _ in range(num_blocks)])",
            "self.norm = norm_layer(embed_dim)",
            "-        self.head = nn.Linear(embed_dim, self.num_classes)  # zero init",
            "+        self.head = nn.Linear(embed_dim, self.num_classes) if num_classes > 0 else nn.Identity()",
            "",
            "self.init_weights(nlhb=nlhb)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1569,
        "label": "no",
        "change": [
            "def initialize_device_settings(",
            "devices_to_use = [torch.device(device) for device in range(torch.cuda.device_count())]",
            "n_gpu = torch.cuda.device_count()",
            "else:",
            "-                devices_to_use = [torch.device(\"cuda\")]",
            "+                devices_to_use = [torch.device(\"cuda:0\")]",
            "n_gpu = 1",
            "else:",
            "devices_to_use = [torch.device(\"cpu\")]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1570,
        "label": "no",
        "change": [
            "def test_loading_from_pretrained(pretrained_model_name):",
            "torch.manual_seed(SEED)",
            "hf_output = pretrained_module(hidden_states, attention_mask=attention_mask_hf)",
            "",
            "-    assert torch.allclose(output[0], hf_output[0])",
            "+    assert torch.allclose(output.final_hidden_states, hf_output[0])",
            "",
            "",
            "def test_loading_partial_pretrained_weights():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1571,
        "label": "no",
        "change": [
            "multiprocessing = (",
            "indices_where = tf.where",
            "",
            "",
            "-def shape(",
            "-    x: tf.Tensor, as_tensor: bool = False",
            "-) -> Union[tf.Tensor, List[int]]:",
            "+def shape(x: tf.Tensor, as_tensor: bool = False) -> Union[tf.Tensor, List[int]]:",
            "if as_tensor:",
            "return tf.shape(x)",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1572,
        "label": "no",
        "change": [
            "def random_binomial(shape, p=0.0, dtype=_FLOATX, seed=None):",
            "if seed is None:",
            "seed = np.random.randint(10e6)",
            "return tf.select(tf.random_uniform(shape, dtype=dtype, seed=seed) <= p,",
            "-                     tf.ones(shape), tf.zeros(shape))",
            "+                     tf.ones(shape, dtype=dtype),",
            "+                     tf.zeros(shape, dtype=dtype))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1576,
        "label": "yes",
        "change": [
            "def init_seeds(seed=0, deterministic=False):",
            "torch.manual_seed(seed)",
            "torch.cuda.manual_seed(seed)",
            "torch.cuda.manual_seed_all(seed)  # for Multi-GPU, exception safe",
            "-    torch.backends.cudnn.benchmark = True  # for faster training",
            "+    # torch.backends.cudnn.benchmark = True  # AutoBatch problem https://github.com/ultralytics/yolov5/issues/9287",
            "if deterministic and check_version(torch.__version__, '1.12.0'):  # https://github.com/ultralytics/yolov5/pull/8213",
            "torch.use_deterministic_algorithms(True)",
            "torch.backends.cudnn.deterministic = True"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "removal",
        "Element": "api call"
    },
    {
        "number": 1578,
        "label": "no",
        "change": [
            "class TFFastSpeechLengthRegulator(tf.keras.layers.Layer):",
            "[i, batch_size, outputs, encoder_masks, encoder_hidden_states, durations_gt, max_durations],",
            "shape_invariants=[i.get_shape(),",
            "batch_size.get_shape(),",
            "-                              tf.TensorShape([None, None, None]),",
            "+                              tf.TensorShape([None, None, self.config.hidden_size]),",
            "tf.TensorShape([None, None]),",
            "encoder_hidden_states.get_shape(),",
            "durations_gt.get_shape(),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1579,
        "label": "yes",
        "change": [
            "def inv(",
            "*,",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "-    if tf.math.reduce_any(tf.linalg.det(x) == 0):",
            "+    if tf.math.reduce_any(tf.linalg.det(tf.cast(x, dtype=\"float64\")) == 0):",
            "ret = x",
            "else:",
            "ret = tf.linalg.inv(x)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 1580,
        "label": "no",
        "change": [
            "def main(args):  # pylint: disable=redefined-outer-name",
            "criterion = nn.L1Loss() if c.model in [\"Tacotron\", \"TacotronGST\"",
            "] else nn.MSELoss()",
            "criterion_st = nn.BCEWithLogitsLoss(",
            "-        pos_weight=torch.tensor(20.0)) if c.stopnet else None",
            "+        pos_weight=torch.tensor(10)) if c.stopnet else None",
            "",
            "if args.restore_path:",
            "checkpoint = torch.load(args.restore_path)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1581,
        "label": "no",
        "change": [
            "class Script(scripts.Script):",
            "",
            "p.seed = p.seed + 1",
            "",
            "-            return sampler.sample_img2img(p, p.init_latent, noise_dt, conditioning, unconditional_conditioning)",
            "+            return sampler.sample_img2img(p, p.init_latent, noise_dt, conditioning, unconditional_conditioning, image_conditioning=p.image_conditioning)",
            "",
            "p.sample = sample_extra"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1582,
        "label": "yes",
        "change": [
            "class Init(InsertPostInitMethodToModuleSubClasses):",
            "",
            "see_memory_usage(f'Before partitioning param {param.ds_id} {param.shape}',",
            "force=False)",
            "-            param.data = torch.ones(1).half().to(param.device)",
            "+            param.data = torch.ones(partitioned_param_data_shape).half().to(param.device)",
            "see_memory_usage(f'After partitioning param {param.ds_id} {param.shape}',",
            "force=False)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 1583,
        "label": "no",
        "change": [
            "def batch_normalization(incoming, beta=0.0, gamma=1.0, epsilon=1e-5,",
            "",
            "# Variable Scope fix for older TF",
            "try:",
            "-        vscope = tf.variable_scope(scope, name=name, values=[incoming],",
            "+        vscope = tf.variable_scope(scope, default_name=name, values=[incoming],",
            "reuse=reuse)",
            "except Exception:",
            "vscope = tf.variable_op_scope([incoming], scope, name, reuse=reuse)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1584,
        "label": "no",
        "change": [
            "class IntSoftmax(nn.Module):",
            "",
            "def forward(self, x, scaling_factor):",
            "if not self.quant_mode:",
            "-            return nn.Softmax(dim=-1)(x), None",
            "+            return nn.functional.softmax(x, dim=-1), None",
            "",
            "x_int = x / scaling_factor"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1585,
        "label": "no",
        "change": [
            "def setup_keras_trainer(",
            "input,",
            "get_cost,",
            "lambda: optimizer)",
            "-    if len(keras.backend.learning_phase().consumers()) > 0:",
            "+    if isinstance(keras.backend.learning_phase(), tf.Tensor) and len(keras.backend.learning_phase().consumers()) > 0:",
            "# check if learning_phase is used in this model",
            "trainer.register_callback(KerasPhaseCallback(True))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1587,
        "label": "yes",
        "change": [
            "class TorchService(BaseService):",
            "",
            "# FLOAT TENSOR FUNCTIONS",
            "def hook_float_tensor___init__(service_self):",
            "-        def new___init__(self, tensor, owner=service_self, *args, **kwargs):",
            "-            super(torch.FloatTensor, self).__init__(*args, **kwargs)",
            "-            self = owner.register_object(self, False)",
            "+        def new___init__(self, *args):",
            "+            super(torch.FloatTensor, self).__init__()",
            "+            self = service_self.register_object(self, False)",
            "",
            "torch.FloatTensor.__init__ = new___init__"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 1590,
        "label": "no",
        "change": [
            "class Transformer(TTSInterface, torch.nn.Module):",
            "self._reset_parameters(args)",
            "",
            "def _reset_parameters(self, args):",
            "-        # alpha in scaled positional encoding init",
            "-        self.encoder.embed[-1].alpha.data = torch.tensor(args.initial_encoder_alpha)",
            "-        self.decoder.embed[-1].alpha.data = torch.tensor(args.initial_decoder_alpha)",
            "+        if self.use_scaled_pos_enc:",
            "+            # alpha in scaled positional encoding init",
            "+            self.encoder.embed[-1].alpha.data = torch.tensor(args.initial_encoder_alpha)",
            "+            self.decoder.embed[-1].alpha.data = torch.tensor(args.initial_decoder_alpha)",
            "",
            "if args.transformer_init == \"pytorch\":",
            "return"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1591,
        "label": "yes",
        "change": [
            "def demo_gan(checkpoint_paths):",
            "img_list = []",
            "fixed_noise = torch.randn(64, nz, 1, 1)",
            "for path in checkpoint_paths:",
            "-        netG_path = os.path.join(path, \"checkpoint.pt\")",
            "+        checkpoint_dict = Checkpoint.from_directory(path).to_dict()",
            "loadedG = Generator()",
            "-        loadedG.load_state_dict(torch.load(netG_path)[\"netGmodel\"])",
            "+        loadedG.load_state_dict(checkpoint_dict[\"netGmodel\"])",
            "with torch.no_grad():",
            "fake = loadedG(fixed_noise).detach().cpu()",
            "img_list.append(vutils.make_grid(fake, padding=2, normalize=True))"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "state handling error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1592,
        "label": "yes",
        "change": [
            "class PNAConv(MessagePassing):",
            "return y",
            "",
            "def aggregate(self, inputs, index, dim_size=None):",
            "-        D = get_degree(inputs, index, self.node_dim, dim_size)",
            "+        D = get_degree(inputs, index, 0, dim_size)",
            "",
            "# aggregators",
            "-        inputs = torch.cat([aggregator(inputs, index, dim=self.node_dim, dim_size=dim_size)",
            "+        inputs = torch.cat([aggregator(inputs, index, dim=0, dim_size=dim_size)",
            "for aggregator in self.aggregators], dim=-1)",
            "# scalers",
            "return torch.cat([scaler(inputs, D, self.avg_d) for scaler in self.scalers], dim=-1)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 1593,
        "label": "no",
        "change": [
            "def test(epoch):",
            "model.eval()",
            "test_loss = 0",
            "for data, _ in test_loader:",
            "+        if args.cuda:",
            "+            data = data.cuda()",
            "data = Variable(data, volatile=True)",
            "recon_batch, mu, logvar = model(data)",
            "test_loss += loss_function(recon_batch, data, mu, logvar).data[0]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1595,
        "label": "no",
        "change": [
            "def to_float(c):",
            "def complex_norm(c: Union[torch.Tensor, ComplexTensor]) -> torch.Tensor:",
            "if not is_complex(c):",
            "raise TypeError(\"Input is not a complex tensor.\")",
            "-    return torch.sqrt((c.real**2 + c.imag**2).sum(dim=-1, keepdim=True) + EPS)",
            "+    return torch.sqrt((c.real ** 2 + c.imag ** 2).sum(dim=-1, keepdim=True) + EPS)",
            "",
            "",
            "def einsum(equation, *operands):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1596,
        "label": "yes",
        "change": [
            "class FP16_Optimizer(DeepSpeedOptimizer):",
            "will call ``model.load_state_dict()`` before",
            "``fp16_optimizer_instance.load_state_dict()`` is called.",
            "Example::",
            "-            model = torch.nn.Linear(D_in, D_out).cuda().half()",
            "+            model = torch.nn.Linear(D_in, D_out).to(get_accelerator().device_name()).half()",
            "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)",
            "optimizer = FP16_Optimizer(optimizer, static_loss_scale = 128.0)",
            "..."
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 1597,
        "label": "no",
        "change": [
            "class VisionNetwork(Model):",
            "activation=activation,",
            "padding=\"valid\",",
            "name=\"fc1\")",
            "-            fc2 = tf.layers.conv2d(",
            "+            fc2 = tf1.layers.conv2d(",
            "fc1,",
            "num_outputs, [1, 1],",
            "activation=None,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1599,
        "label": "no",
        "change": [
            "class GlowTTSLoss(torch.nn.Module):",
            "return_dict = {}",
            "# flow loss - neg log likelihood",
            "pz = torch.sum(scales) + 0.5 * torch.sum(torch.exp(-2 * scales) * (z - means) ** 2)",
            "-        log_mle = self.constant_factor + (pz - torch.sum(log_det)) / (torch.sum(y_lengths) * z.shape[1])",
            "+        log_mle = self.constant_factor + (pz - torch.sum(log_det)) / (torch.sum(y_lengths) * z.shape[2])",
            "# duration loss - MSE",
            "-        # loss_dur = torch.sum((o_dur_log - o_attn_dur)**2) / torch.sum(x_lengths)",
            "+        loss_dur = torch.sum((o_dur_log - o_attn_dur) ** 2) / torch.sum(x_lengths)",
            "# duration loss - huber loss",
            "-        loss_dur = torch.nn.functional.smooth_l1_loss(o_dur_log, o_attn_dur, reduction=\"sum\") / torch.sum(x_lengths)",
            "+        # loss_dur = torch.nn.functional.smooth_l1_loss(o_dur_log, o_attn_dur, reduction=\"sum\") / torch.sum(x_lengths)",
            "return_dict[\"loss\"] = log_mle + loss_dur",
            "return_dict[\"log_mle\"] = log_mle",
            "return_dict[\"loss_dur\"] = loss_dur"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1600,
        "label": "no",
        "change": [
            "reconstruction_function.size_average = False",
            "",
            "",
            "def loss_function(recon_x, x, mu, logvar):",
            "-    BCE = reconstruction_function(recon_x, x)",
            "+    BCE = reconstruction_function(recon_x, x.view(-1, 784))",
            "",
            "# see Appendix B from VAE paper:",
            "# Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1602,
        "label": "no",
        "change": [
            "class ProphetNetModelTester:",
            "decoder_attention_mask=decoder_attention_mask,",
            "labels=lm_labels,",
            ")",
            "-        self.parent.assertTrue(torch.allclose(result.loss, torch.tensor(128.2925, device=torch_device), atol=1e-3))",
            "+        self.parent.assertTrue(torch.allclose(result.loss, torch.tensor(4.5819, device=torch_device), atol=1e-3))",
            "",
            "expected_logit_slice = torch.tensor(",
            "[-0.1565, 0.0418, 0.1207, 0.0030, 0.0665, 0.0467, 0.0412], device=torch_device"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1603,
        "label": "no",
        "change": [
            "def select_device(device='', batch_size=0, newline=True):",
            "assert torch.cuda.is_available() and torch.cuda.device_count() >= len(device.replace(',', '')), \\",
            "f\"Invalid CUDA '--device {device}' requested, use '--device cpu' or pass valid CUDA device(s)\"",
            "",
            "-    if not (cpu or mps) and torch.cuda.is_available():  # prefer GPU if available",
            "+    if not cpu and not mps and torch.cuda.is_available():  # prefer GPU if available",
            "devices = device.split(',') if device else '0'  # range(torch.cuda.device_count())  # i.e. 0,1,6,7",
            "n = len(devices)  # device count",
            "if n > 1 and batch_size > 0:  # check batch_size is divisible by device_count"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1604,
        "label": "yes",
        "change": [
            "def read_state_dict(checkpoint_file, print_global_state=False, map_location=None",
            "if extension.lower() == \".safetensors\":",
            "device = map_location or shared.weight_load_location",
            "if device is None:",
            "-            device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"",
            "+            device = devices.get_cuda_device_string() if torch.cuda.is_available() else \"cpu\"",
            "pl_sd = safetensors.torch.load_file(checkpoint_file, device=device)",
            "else:",
            "pl_sd = torch.load(checkpoint_file, map_location=map_location or shared.weight_load_location)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1608,
        "label": "no",
        "change": [
            "class BertClassifierModel(LRScheduledTFModel):",
            "pretrained_bert = str(expand_path(pretrained_bert))",
            "",
            "if tf.train.checkpoint_exists(pretrained_bert) \\",
            "-                    and not tf.train.checkpoint_exists(str(self.load_path.resolve())):",
            "+                    and not (self.load_path and tf.train.checkpoint_exists(str(self.load_path.resolve()))):",
            "logger.info('[initializing model with Bert from {}]'.format(pretrained_bert))",
            "# Exclude optimizer and classification variables from saved variables",
            "var_list = self._get_saveable_variables("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1609,
        "label": "no",
        "change": [
            "def extract_tensor_patches(",
            "See :class:`~kornia.contrib.ExtractTensorPatches` for details.",
            "\"\"\"",
            "if not torch.is_tensor(input):",
            "-        raise TypeError(\"Input input type is not a torch.Tensor. Got {}\"",
            "-                        .format(type(input)))",
            "+        raise TypeError(\"Input input type is not a torch.Tensor. Got {}\".format(type(input)))",
            "if not len(input.shape) == 4:",
            "-        raise ValueError(\"Invalid input shape, we expect BxCxHxW. Got: {}\"",
            "-                         .format(input.shape))",
            "+        raise ValueError(\"Invalid input shape, we expect BxCxHxW. Got: {}\".format(input.shape))",
            "",
            "if padding:",
            "pad_vert, pad_horz = _pair(padding)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1611,
        "label": "no",
        "change": [
            "def RemoteTrainer(estimator, metadata, keras_utils, run_id, dataset_idx):",
            "if LooseVersion(tf.__version__) < LooseVersion(\"2.0.0\"):",
            "model.load_weights(ckpt_file)",
            "else:",
            "-                        model = k.models.load_model(ckpt_file)",
            "+                        # needs to be deserialized in the with scope",
            "+                        with k.utils.custom_object_scope(custom_objects):",
            "+                            model = k.models.load_model(ckpt_file)",
            "serialized_model = keras_utils.serialize_model(model)",
            "else:",
            "with open(ckpt_file, 'rb') as f:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1612,
        "label": "no",
        "change": [
            "for i in range(10):",
            "if not info(\"model.a\", model.module.a, 2.):  passed = False",
            "if not info(\"model.b\", model.module.b, 1.):  passed = False",
            "# torch.cuda.nvtx.range_pop()",
            "+torch.cuda.cudart().cudaProfilerStop()",
            "",
            "print(\"passed = \", passed)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1613,
        "label": "no",
        "change": [
            "def test_lightning_cli_link_arguments(tmpdir):",
            "parser.link_arguments(\"data.batch_size\", \"model.init_args.batch_size\")",
            "parser.link_arguments(\"data.num_classes\", \"model.init_args.num_classes\", apply_on=\"instantiate\")",
            "",
            "-    cli_args[-1] = \"--model=tests.utilities.test_cli.BoringModelRequiredClasses\"",
            "+    cli_args[-1] = \"--model=tests_pytorch.utilities.test_cli.BoringModelRequiredClasses\"",
            "",
            "with mock.patch(\"sys.argv\", [\"any.py\"] + cli_args):",
            "cli = MyLightningCLI("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1615,
        "label": "no",
        "change": [
            "def box3d_overlap(",
            "",
            "_check_coplanar(boxes1, eps)",
            "_check_coplanar(boxes2, eps)",
            "+    _check_nonzero(boxes1, eps)",
            "+    _check_nonzero(boxes2, eps)",
            "",
            "# pyre-fixme[16]: `_box3d_overlap` has no attribute `apply`.",
            "vol, iou = _box3d_overlap.apply(boxes1, boxes2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1617,
        "label": "no",
        "change": [
            "class DistributedFusedLAMB(torch.optim.Optimizer):",
            "",
            "def _do_overlapped_reduction(self, param_i, param_grads_size, param_offset, param):",
            "# handle overlapped reductions",
            "-        if param.dtype = torch.float16:",
            "+        if param.dtype == torch.float16:",
            "self._grads_fp16.append( (param.grad, self._individual_flat_grads[param_i]) )",
            "else:",
            "self._grads_fp32.append( (param.grad, self._individual_flat_grads[param_i]) )"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1620,
        "label": "no",
        "change": [
            "class MultiHeadSelfAttentionTest(AllenNlpTestCase):",
            "num_heads=3, input_dim=5, attention_dim=6, values_dim=9, attention_dropout_prob=0.0",
            ")",
            "tensor = torch.randn(2, 12, 5)",
            "-        mask = torch.ones([2, 12])",
            "-        mask[0, 6:] = 0",
            "+        mask = torch.ones([2, 12]).bool()",
            "+        mask[0, 6:] = False",
            "result = attention(tensor, mask)",
            "# Compute the same function without a mask, but with",
            "# only the unmasked elements - should be the same."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1621,
        "label": "no",
        "change": [
            "class RagTestMixin:",
            ")",
            "dataset.add_faiss_index(\"embeddings\", string_factory=\"Flat\", metric_type=faiss.METRIC_INNER_PRODUCT)",
            "tokenizer = self.bart_tokenizer if config.generator.model_type == \"bart\" else self.t5_tokenizer",
            "-        with patch(\"transformers.retrieval_rag.load_dataset\") as mock_load_dataset:",
            "+        with patch(\"transformers.models.rag.retrieval_rag.load_dataset\") as mock_load_dataset:",
            "mock_load_dataset.return_value = dataset",
            "retriever = RagRetriever(",
            "config,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1623,
        "label": "no",
        "change": [
            "class SimpleSeq2Seq(Model):",
            "# encoder_outputs : (batch_size, input_sequence_length, encoder_output_dim)",
            "# Ensuring mask is also a FloatTensor. Or else the multiplication within attention will",
            "# complain.",
            "-            encoder_outputs_mask = encoder_outputs_mask.type(torch.FloatTensor)",
            "+            encoder_outputs_mask = encoder_outputs_mask.float()",
            "# (batch_size, input_sequence_length)",
            "input_weights = self._decoder_attention(decoder_hidden_state, encoder_outputs, encoder_outputs_mask)",
            "# (batch_size, encoder_output_dim)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1624,
        "label": "no",
        "change": [
            "class Delta(Distribution):",
            "\"\"\"",
            "return Variable(self.v.data.unsqueeze(0))",
            "",
            "-    def analytic_mean(self):",
            "+    @property",
            "+    def mean(self):",
            "return self.v",
            "",
            "-    def analytic_var(self):",
            "+    @property",
            "+    def variance(self):",
            "return torch.zeros_like(self.v)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1625,
        "label": "no",
        "change": [
            "class DiceCoefficient(object):",
            "return",
            "torch.distributed.barrier()",
            "torch.distributed.all_reduce(self.cumulative_dice)",
            "+        torch.distributed.all_reduce(self.count)",
            "",
            "",
            "class MetricLogger(object):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1626,
        "label": "no",
        "change": [
            "def test_sample(n_cutpoints, pred_shape):",
            "def test_constraints():",
            "predictor = torch.randn(5)",
            "for cp in (",
            "-        tt([1, 2, 3, 4, 0]),",
            "-        tt([1, 2, 4, 3, 5]),",
            "-        tt([1, 2, 3, 4, 4]),",
            "+        torch.tensor([1, 2, 3, 4, 0]),",
            "+        torch.tensor([1, 2, 4, 3, 5]),",
            "+        torch.tensor([1, 2, 3, 4, 4]),",
            "):",
            "with pytest.raises(ValueError):",
            "OrderedLogistic(predictor, cp)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1628,
        "label": "no",
        "change": [
            "TORCH_DTYPE_STR = {",
            "TORCH_STR_DTYPE = {name: cls for cls, name in TORCH_DTYPE_STR.items()}",
            "",
            "",
            "-TORCH_MFORMAT_ID = {",
            "-    torch.channels_last: 1,",
            "-    torch.contiguous_format: 2,",
            "-    torch.preserve_format: 3,",
            "-}",
            "+TORCH_MFORMAT_ID = {torch.channels_last: 1, torch.contiguous_format: 2, torch.preserve_format: 3}",
            "",
            "TORCH_ID_MFORMAT = {i: cls for cls, i in TORCH_MFORMAT_ID.items()}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1629,
        "label": "yes",
        "change": [
            "class MultiHeadSelfAttention(nn.Module):",
            "q = q / math.sqrt(dim_per_head)  # (bs, n_heads, q_length, dim_per_head)",
            "scores = torch.matmul(q, k.transpose(2, 3))  # (bs, n_heads, q_length, k_length)",
            "mask = (mask == 0).view(mask_reshp).expand_as(scores)  # (bs, n_heads, q_length, k_length)",
            "-        scores = scores.masked_fill(mask, -float(\"inf\"))  # (bs, n_heads, q_length, k_length)",
            "+        scores = scores.masked_fill(mask, torch.tensor(-float(\"inf\")))  # (bs, n_heads, q_length, k_length)",
            "",
            "weights = nn.functional.softmax(scores, dim=-1)  # (bs, n_heads, q_length, k_length)",
            "weights = self.dropout(weights)  # (bs, n_heads, q_length, k_length)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 1633,
        "label": "no",
        "change": [
            "def _sample_tree_approx(edge_logits):",
            "mask = (c1 != c2)",
            "valid_logits = edge_logits[mask]",
            "probs = (valid_logits - valid_logits.max()).exp()",
            "-        k = mask.nonzero()[torch.multinomial(probs, 1)[0]]",
            "+        k = mask.nonzero(as_tuple=False)[torch.multinomial(probs, 1)[0]]",
            "components[grid[:, k]] = 1",
            "edge_ids[e] = k"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1635,
        "label": "no",
        "change": [
            "def Conv2D(x, out_channel, kernel_shape,",
            "if b_init is None:",
            "b_init = tf.constant_initializer()",
            "",
            "-    W = tf.get_variable('W', filter_shape, initializer=W_init) # TODO collections",
            "+    W = tf.get_variable('W', filter_shape, initializer=W_init)",
            "b = tf.get_variable('b', [out_channel], initializer=b_init)",
            "",
            "if split == 1:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1640,
        "label": "no",
        "change": [
            "def highway(incoming, n_units, activation='linear', transform_dropout=None,",
            "n_inputs = int(np.prod(input_shape[1:]))",
            "",
            "# Build variables and inference.",
            "-    with tf.variable_scope(scope, name, [incoming], reuse=reuse) as scope:",
            "+    with tf.variable_scope(scope, name, values=[incoming], reuse=reuse) as scope:",
            "name = scope.name",
            "",
            "W_init = weights_init"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1641,
        "label": "no",
        "change": [
            "class TestAugmentationBase2D:",
            "output = utils.tensor_to_gradcheck_var(output)  # to var",
            "other_transform = utils.tensor_to_gradcheck_var(other_transform)  # to var",
            "",
            "-        input_param = {'batch_prob': torch.tensor([True]), 'params': {'x': input_transform}, 'flags': {}}",
            "+        input_param = {'batch_prob': torch.tensor([True]), 'x': input_transform, 'y': {}}",
            "",
            "augmentation = AugmentationBase2D(p=1.0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1643,
        "label": "no",
        "change": [
            "class OptimizedStep(MetaOptimizer):",
            "loss_before = fn_compare(reference=reference)",
            "",
            "with tf.control_dependencies(control_inputs=(loss_before,)):",
            "-            applied, diffs = self.optimizer.step(time=time, variables=variables, fn_loss=fn_loss, **kwargs)",
            "+            diffs = self.optimizer.step(time=time, variables=variables, fn_loss=fn_loss, **kwargs)",
            "",
            "-        with tf.control_dependencies(control_inputs=(applied,)):",
            "+        with tf.control_dependencies(control_inputs=diffs):",
            "if fn_reference is None:",
            "loss_step = fn_loss()",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1644,
        "label": "no",
        "change": [
            "class DatasetCreatorModelFitTest(test_base.DatasetCreatorModelFitTestBase):",
            "",
            "def testModelTrainTFFunction(self, strategy):",
            "model = self._model_fit(strategy)",
            "-    self.assertIsInstance(model.train_tf_function, tf.__internal__.function.Function)",
            "+    self.assertIsInstance(model.train_tf_function,",
            "+                          tf.__internal__.function.Function)",
            "",
            "",
            "if __name__ == \"__main__\":",
            "-  tf.compat.v1.enable_v2_behavior()",
            "tf.__internal__.distribute.multi_process_runner.test_main()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1646,
        "label": "no",
        "change": [
            "def conv_layers(net_in):",
            "",
            "",
            "def conv_layers_simple_api(net_in):",
            "-    with tf.name_scope('preprocess') as scope:",
            "+    with tf.name_scope('preprocess'):",
            "\"\"\"",
            "Notice that we include a preprocessing layer that takes the RGB image",
            "with pixels values in the range of 0-255 and subtracts the mean image"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1648,
        "label": "no",
        "change": [
            "class MaskedLayerNorm(torch.nn.Module):",
            "num_elements = broadcast_mask.sum() * self.size",
            "mean = (tensor * broadcast_mask).sum() / num_elements",
            "masked_centered = (tensor - mean) * broadcast_mask",
            "-        std = torch.sqrt(",
            "-                (masked_centered * masked_centered).sum() / num_elements + self.eps",
            "-        )",
            "+        std = torch.sqrt((masked_centered * masked_centered).sum() / num_elements + self.eps)",
            "return self.gamma * (tensor - mean) / (std + self.eps) + self.beta"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1649,
        "label": "yes",
        "change": [
            "def get_extensions():",
            "extra_compile_args = {\"cxx\": []}",
            "define_macros = []",
            "",
            "-    if torch.cuda.is_available() and CUDA_HOME is not None:",
            "+    if (torch.cuda.is_available() and CUDA_HOME is not None) or os.getenv(\"FORCE_CUDA\", \"0\") == \"1\":",
            "extension = CUDAExtension",
            "sources += source_cuda",
            "define_macros += [(\"WITH_CUDA\", None)]"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 1651,
        "label": "no",
        "change": [
            "class _OMTMVNSample(Function):",
            "loc_grad = sum_leftmost(grad_output, -1)",
            "",
            "identity = eye_like(g, dim)",
            "-        R_inv = torch.triangular_solve(identity, L.t(), transpose=False, upper=True)[0]",
            "+        R_inv = torch.linalg.solve_triangular(L.t(), identity, upper=True)",
            "",
            "z_ja = z.unsqueeze(-1)",
            "g_R_inv = torch.matmul(g, R_inv).unsqueeze(-2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1652,
        "label": "no",
        "change": [
            "class Model(object):",
            "",
            "elif action_spec['type'] == 'float':",
            "for _ in range(util.rank(action) - 1):",
            "-                exploration_value = tf.expand_dims(input=exploration_value, axis=1)",
            "+                exploration_value = tf.expand_dims(input=exploration_value, axis=-1)",
            "action += exploration_value",
            "if 'min_value' in action_spec:",
            "action = tf.clip_by_value("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1653,
        "label": "no",
        "change": [
            "class Result(Dict):",
            "",
            "# sync across workers when using distributed training",
            "sync_fn = sync_fn or sync_ddp_if_available",
            "+",
            "if sync_dist and isinstance(value, (torch.Tensor, numbers.Number)):",
            "is_dist_initialized = torch.distributed.is_available() and torch.distributed.is_initialized()",
            "# TODO: Find a way to make the reduction only once, so we don't need to clone.",
            "-            if is_dist_initialized and isinstance(value, torch.Tensor):",
            "+            if (is_dist_initialized or tpu_distributed) and isinstance(value, torch.Tensor):",
            "value = value.clone()",
            "else:",
            "value = torch.tensor(value, device=device, dtype=torch.float)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1655,
        "label": "no",
        "change": [
            "class LinearDecay(Exploration):",
            "Linear decay based on episode number.",
            "\"\"\"",
            "",
            "-    def tf_explore(self, episode, timestep, num_actions):",
            "-        return tf.random_uniform(shape=num_actions) / (tf.cast(x=episode, dtype=util.tf_dtype('float') + 1.0))",
            "+    def tf_explore(self, episode, timestep, action_shape):",
            "+        return tf.random_uniform(shape=action_shape) / (tf.cast(x=episode, dtype=util.tf_dtype('float') + 1.0))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1656,
        "label": "no",
        "change": [
            "class TFMobileBertModel(TFMobileBertPreTrainedModel):",
            "",
            "return outputs",
            "",
            "-    # Copied from transformers.models.bert.modeling_tf_bert.TFBertModel.serving_output",
            "def serving_output(self, output: TFBaseModelOutputWithPooling) -> TFBaseModelOutputWithPooling:",
            "hs = tf.convert_to_tensor(output.hidden_states) if self.config.output_hidden_states else None",
            "attns = tf.convert_to_tensor(output.attentions) if self.config.output_attentions else None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1657,
        "label": "no",
        "change": [
            "class ModelTesterMixin:",
            "if model_class in MODEL_FOR_MULTIPLE_CHOICE_MAPPING.values():",
            "return {",
            "k: v.unsqueeze(1).expand(-1, self.model_tester.num_choices, -1).contiguous()",
            "-                if isinstance(v, torch.Tensor) and v.ndim != 0",
            "+                if isinstance(v, torch.Tensor) and v.ndim > 1",
            "else v",
            "for k, v in inputs_dict.items()",
            "}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1658,
        "label": "no",
        "change": [
            "class TestGatedCnnEncoder(AllenNlpTestCase):",
            ")",
            "",
            "token_embeddings = torch.rand(5, 10, 32)",
            "-        mask = torch.ones(5, 10)",
            "-        mask[0, 7:] = 0",
            "-        mask[1, 5:] = 0",
            "+        mask = torch.ones(5, 10).bool()",
            "+        mask[0, 7:] = False",
            "+        mask[1, 5:] = False",
            "",
            "output = cnn_encoder(token_embeddings, mask)",
            "assert len(output) == 3"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1659,
        "label": "yes",
        "change": [
            "class AlbertMLMHead(nn.Module):",
            "def __init__(self, config):",
            "super().__init__()",
            "",
            "-        self.LayerNorm = nn.LayerNorm(config.embedding_size)",
            "+        self.LayerNorm = nn.LayerNorm(config.embedding_size, eps=config.layer_norm_eps)",
            "self.bias = nn.Parameter(torch.zeros(config.vocab_size))",
            "self.dense = nn.Linear(config.hidden_size, config.embedding_size)",
            "self.decoder = nn.Linear(config.embedding_size, config.vocab_size)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 1660,
        "label": "no",
        "change": [
            "def test_pred_input(params, enc = None):",
            "bos = tf.constant(1, shape=[1, 1], dtype=tf.int64)",
            "src_seq = tf.random.uniform(shape=[1, length], minval=4, maxval=(params['n_vocab'] - 1), dtype=tf.int64)",
            "seq = tf.concat([bos, src_seq], axis=1)",
            "-    seq = tf.pad(seq, [[0, 0], [0, remaining]])",
            "+    seq = tf.pad(seq, [[0, 0], [0, remaining]], constant_values=params['padding_id'])",
            "dataset = tf.data.Dataset.from_tensors(seq)",
            "",
            "dataset = dataset.map(_dummy_labels)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1663,
        "label": "no",
        "change": [
            "class SpatialGradient(nn.Module):",
            "kernel: torch.Tensor = tmp_kernel.repeat(c, 1, 1, 1, 1)",
            "",
            "# convolve input tensor with sobel kernel",
            "-        return F.conv3d(input[:, :, None], kernel, padding=1, groups=c)",
            "+        kernel_flip: torch.Tensor = kernel.flip(-3)",
            "+        return F.conv3d(input[:, :, None], kernel_flip, padding=1, groups=c)",
            "",
            "",
            "class Sobel(nn.Module):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1664,
        "label": "no",
        "change": [
            "def ppo_surrogate_loss(",
            "action_kl = prev_action_dist.kl(curr_action_dist)",
            "mean_kl_loss = reduce_mean_valid(action_kl)",
            "else:",
            "-        mean_kl_loss = 0.0",
            "+        mean_kl_loss = tf.constant(0.0)",
            "",
            "curr_entropy = curr_action_dist.entropy()",
            "mean_entropy = reduce_mean_valid(curr_entropy)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1665,
        "label": "no",
        "change": [
            "class TestMaxout(AllenNlpTestCase):",
            "})",
            "maxout = Maxout.from_params(params)",
            "",
            "-        constant_init = lambda tensor: torch.nn.init.constant(tensor, 1.)",
            "+        constant_init = lambda tensor: torch.nn.init.constant_(tensor, 1.)",
            "initializer = InitializerApplicator([(\".*\", constant_init)])",
            "initializer(maxout)",
            "",
            "-        input_tensor = Variable(torch.FloatTensor([[-3, 1]]))",
            "+        input_tensor = torch.FloatTensor([[-3, 1]])",
            "output = maxout(input_tensor).data.numpy()",
            "assert output.shape == (1, 3)",
            "# This output was checked by hand"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1667,
        "label": "no",
        "change": [
            "class DomainClient(Client):",
            "",
            "binary_dataset = serialize(assets, to_bytes=True)",
            "",
            "-        self.datasets.create_syft(dataset=binary_dataset, metadata=metadata, platform=\"syft\")",
            "+        self.datasets.create_syft(",
            "+            dataset=binary_dataset, metadata=metadata, platform=\"syft\"",
            "+        )"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1668,
        "label": "yes",
        "change": [
            "def run(",
            "seen, windows, dt = 0, [], (Profile(), Profile(), Profile())",
            "for path, im, im0s, vid_cap, s in dataset:",
            "with dt[0]:",
            "-            im = im.to(device)",
            "+            im = torch.Tensor(im).to(device)",
            "im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32",
            "if len(im.shape) == 3:",
            "im = im[None]  # expand for batch dim"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 1669,
        "label": "no",
        "change": [
            "class Net(torch.nn.Module):",
            "self.gnn3_embed = GNN(3 * 64, 64, 64, lin=False)",
            "",
            "self.lin1 = torch.nn.Linear(3 * 64, 64)",
            "-        self.lin2 = torch.nn.Linear(64, 6)",
            "+        self.lin2 = torch.nn.Linear(64, dataset.num_classes)",
            "",
            "def forward(self, x, adj, mask=None):",
            "s = self.gnn1_pool(x, adj, mask)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1670,
        "label": "no",
        "change": [
            "class FCNMaskHead(nn.Module):",
            "scale_factor=self.upsample_ratio, mode=self.upsample_method)",
            "",
            "out_channels = 1 if self.class_agnostic else self.num_classes",
            "-        self.conv_logits = nn.Conv2d(self.conv_out_channels, out_channels, 1)",
            "+        logits_in_channel = (self.conv_out_channels",
            "+                             if self.upsample_method == 'deconv' else",
            "+                             upsample_in_channels)",
            "+        self.conv_logits = nn.Conv2d(logits_in_channel, out_channels, 1)",
            "self.relu = nn.ReLU(inplace=True)",
            "self.debug_imgs = None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1671,
        "label": "no",
        "change": [
            "if __name__ == \"__main__\":",
            "# ============================= EVALUATION =============================",
            "# env = gym.make(GAME)",
            "# GLOBAL_AC = ACNet(GLOBAL_NET_SCOPE)",
            "-    # tl.layers.initialize_global_variables(sess)",
            "+    # sess.run(tf.global_variables_initializer())",
            "# GLOBAL_AC.load_ckpt()",
            "# while True:",
            "#     s = env.reset()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1672,
        "label": "no",
        "change": [
            "class ModelTesterMixin:",
            "",
            "torch._C._jit_clear_class_registry()",
            "torch.jit._recursive.concrete_type_store = torch.jit._recursive.ConcreteTypeStore()",
            "-        torch.jit._state._clear_class_state()",
            "+        # torch 1.8 has no `_clear_class_state` in `torch.jit._state`",
            "+        if hasattr(torch.jit._state, \"_clear_class_state\"):",
            "+            torch.jit._state._clear_class_state()",
            "",
            "def _create_and_check_torchscript(self, config, inputs_dict):",
            "if not self.test_torchscript:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1674,
        "label": "no",
        "change": [
            "def map_fun(args, ctx):",
            "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"accuracy\")",
            "",
            "saver = tf.train.Saver()",
            "-      summary_op = tf.merge_all_summaries()",
            "-      init_op = tf.initialize_all_variables()",
            "+      summary_op = tf.summary.merge_all()",
            "+      init_op = tf.global_variables_initializer()",
            "",
            "# Create a \"supervisor\", which oversees the training process and stores model state into HDFS",
            "-    logdir = args.model if hdfs.path.isabs(args.model) else \"hdfs://default/user/{0}/{1}\".format(getpass.getuser(), args.model)",
            "+    logdir = args.model if args.model.startswith(\"hdfs://\") else \"hdfs://default/user/{0}/{1}\".format(getpass.getuser(), args.model)",
            "print(\"tensorflow model path: {0}\".format(logdir))",
            "-    summary_writer = tf.train.SummaryWriter(\"tensorboard_%d\" %(worker_num), graph=tf.get_default_graph())",
            "+    summary_writer = tf.summary.FileWriter(\"tensorboard_%d\" %(worker_num), graph=tf.get_default_graph())",
            "",
            "if args.mode == \"train\":",
            "sv = tf.train.Supervisor(is_chief=(task_index == 0),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1676,
        "label": "no",
        "change": [
            "def main(args):  # pylint: disable=redefined-outer-name",
            "model = setup_model(c)",
            "",
            "# restore model",
            "-    checkpoint = torch.load(args.checkpoint_path, map_location=\"cpu\")",
            "+    checkpoint = load_fsspec(args.checkpoint_path, map_location=\"cpu\")",
            "model.load_state_dict(checkpoint[\"model\"])",
            "",
            "if use_cuda:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1678,
        "label": "no",
        "change": [
            "class TFDebertaEmbeddings(tf.keras.layers.Layer):",
            "self.position_biased_input = getattr(config, \"position_biased_input\", True)",
            "self.initializer_range = config.initializer_range",
            "if self.embedding_size != config.hidden_size:",
            "-            self.embed_proj = tf.keras.layers.Dense(config.hidden_size, bias=False)",
            "+            self.embed_proj = tf.keras.layers.Dense(config.hidden_size, use_bias=False)",
            "self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=\"LayerNorm\")",
            "self.dropout = TFDebertaStableDropout(config.hidden_dropout_prob, name=\"dropout\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1679,
        "label": "no",
        "change": [
            "class MPNetPooler(nn.Module):",
            "self.dense = nn.Linear(config.hidden_size, config.hidden_size)",
            "self.activation = nn.Tanh()",
            "",
            "-    def forward(self, hidden_states):",
            "+    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:",
            "# We \"pool\" the model by simply taking the hidden state corresponding",
            "# to the first token.",
            "first_token_tensor = hidden_states[:, 0]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1680,
        "label": "yes",
        "change": [
            "class ParameterNoise(Exploration):",
            "else:",
            "for i in range(len(self.noise)):",
            "self.noise[i] = torch.normal(",
            "-                    0.0, self.stddev, size=self.noise[i].size())",
            "+                    mean=torch.zeros(self.noise[i].size()), std=self.stddev)",
            "",
            "def _tf_sample_new_noise_op(self):",
            "added_noises = []"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 1681,
        "label": "no",
        "change": [
            "def test_solve(real_vec):",
            "if isinstance(vec2, ComplexTensor):",
            "ret2 = FC.solve(vec2, mat, return_LU=False)",
            "else:",
            "-            ret2 = torch.solve(vec2, mat)[0]",
            "+            return torch.linalg.solve(mat, vec2)",
            "assert complex_module.allclose(ret, ret2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1682,
        "label": "no",
        "change": [
            "class ReweightedImitationLoss:",
            "# update averaged advantage norm",
            "update_adv_norm = tf.assign_add(",
            "ref=policy._ma_adv_norm,",
            "-            value=1e-6 *",
            "-            (tf.reduce_mean(tf.square(adv)) - policy._ma_adv_norm))",
            "+            value=1e-6 * (",
            "+                    tf.reduce_mean(tf.math.square(adv)) - policy._ma_adv_norm))",
            "",
            "# exponentially weighted advantages",
            "with tf.control_dependencies([update_adv_norm]):",
            "-            exp_advs = tf.exp(",
            "-                beta * tf.divide(adv, 1e-8 + tf.sqrt(policy._ma_adv_norm)))",
            "+            exp_advs = tf.math.exp(beta * tf.math.divide(",
            "+                adv, 1e-8 + tf.math.sqrt(policy._ma_adv_norm)))",
            "",
            "# log\\pi_\\theta(a|s)",
            "logprobs = action_dist.logp(actions)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1683,
        "label": "no",
        "change": [
            "class AdamW(Optimizer):",
            "):",
            "if not no_deprecation_warning:",
            "warnings.warn(",
            "-                \"This implementation of AdamW is deprecated and will be removed in a future version. Use the\"",
            "-                \" PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\",",
            "+                \"This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch\"",
            "+                \" implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this\"",
            "+                \" warning\",",
            "FutureWarning,",
            ")",
            "require_version(\"torch>=1.5.0\")  # add_ with alpha"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1684,
        "label": "no",
        "change": [
            "def draw_first_k_couples(k: int, rdims: int, dv: torch.device):",
            "repeats = torch.cat(",
            "[",
            "torch.arange(max_exhaustive_search, dtype=torch.long, device=dv) + 1,",
            "-            torch.tensor([residual_search], dtype=torch.long),",
            "+            torch.tensor([residual_search], dtype=torch.long, device=dv),",
            "]",
            ")",
            "idx_sequence = torch.stack([repeats.repeat_interleave(repeats), arange_sequence(repeats)], dim=-1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1685,
        "label": "yes",
        "change": [
            "class DartsLayerChoice(nn.Module):",
            "yield name, p",
            "",
            "def export(self):",
            "-        return torch.argmax(self.alpha).item()",
            "+        return list(self.op_choices.keys())[torch.argmax(self.alpha).item()]",
            "",
            "",
            "class DartsInputChoice(nn.Module):",
            "def __init__(self, input_choice):",
            "super(DartsInputChoice, self).__init__()",
            "-        self.name = input_choice.key",
            "+        self.name = input_choice.label",
            "self.alpha = nn.Parameter(torch.randn(input_choice.n_candidates) * 1e-3)",
            "self.n_chosen = input_choice.n_chosen or 1"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 1688,
        "label": "no",
        "change": [
            "class DeepSpeedDiffusersTransformerBlock(nn.Module):",
            "self.attn_1.do_out_bias = False",
            "self.attn_1_bias = self.attn_1.attn_ob",
            "else:",
            "-            self.attn_1_bias = nn.Paramaeter(torch.zeros_like(self.norm2_g),",
            "-                                             requires_grad=False)",
            "+            self.attn_1_bias = nn.Parameter(torch.zeros_like(self.norm2_g),",
            "+                                            requires_grad=False)",
            "",
            "# Pull the bias in if we can",
            "if isinstance(self.attn_2, DeepSpeedDiffusersAttention):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1689,
        "label": "no",
        "change": [
            "class Detections:",
            "def __init__(self, imgs, pred, files, times=None, names=None, shape=None):",
            "super().__init__()",
            "d = pred[0].device  # device",
            "-        gn = [torch.tensor([*(im.shape[i] for i in [1, 0, 1, 0]), 1., 1.], device=d) for im in imgs]  # normalizations",
            "+        gn = [torch.tensor([*(im.shape[i] for i in [1, 0, 1, 0]), 1, 1], device=d) for im in imgs]  # normalizations",
            "self.imgs = imgs  # list of images as numpy arrays",
            "self.pred = pred  # list of tensors pred[0] = (xyxy, conf, cls)",
            "self.names = names  # class names"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1691,
        "label": "no",
        "change": [
            "def test_scatter_gather():",
            "with deepspeed.zero.Init():",
            "l = torch.nn.Linear(6, 3)",
            "assert l.weight.ds_status == ZeroParamStatus.NOT_AVAILABLE",
            "-    assert l.weight.numel() == 1",
            "+    assert l.weight.shape == torch.Size(partitioned_param_data_shape)",
            "",
            "# Ensure there is no impact outside the context",
            "l2 = torch.nn.Linear(6, 3)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1694,
        "label": "no",
        "change": [
            "class TestCall(unittest.TestCase):",
            "x = np.random.randn(nb_samples, input_dim).astype(floatX)",
            "y1 = F(x)",
            "y2 = model.predict(x)",
            "+        # results of __call__ should match model.predict",
            "assert_allclose(y1, y2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1697,
        "label": "yes",
        "change": [
            "class Init(InsertPostInitMethodToModuleSubClasses):",
            "param.all_gather()",
            "return param._orig_item()",
            "",
            "-        def ds_summary(slf: torch.Tensor) -> dict:",
            "+        def ds_summary(slf: torch.Tensor, use_debug_name: bool = False) -> dict:",
            "return {",
            "-                \"id\": slf.ds_id,",
            "+                \"id\": debug_param2name_id(slf) if use_debug_name else slf.ds_id,",
            "\"status\": slf.ds_status.name,",
            "\"numel\": slf.numel(),",
            "\"ds_numel\": slf.ds_numel,"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "argument error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 1703,
        "label": "no",
        "change": [
            "class DeformableConv2d(Layer):",
            "offset_params = [osparam for osparam in offset_layer.all_params if osparam not in layer.all_params]",
            "offset_layers = [oslayer for oslayer in offset_layer.all_layers if oslayer not in layer.all_layers]",
            "",
            "-        self.all_params.extend(offset_params)",
            "-        self.all_layers.extend(offset_layers)",
            "-        self.all_drop.update(offset_layer.all_drop)",
            "+        self.all_params.extend(list(offset_params))",
            "+        self.all_layers.extend(list(offset_layers))",
            "+        self.all_drop.update(dict(offset_layer.all_drop))",
            "",
            "# this layer",
            "self.all_layers.extend([self.outputs])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1704,
        "label": "no",
        "change": [
            "def gelu_new(x):",
            "\"\"\" Implementation of the gelu activation function currently in Google Bert repo (identical to OpenAI GPT).",
            "Also see https://arxiv.org/abs/1606.08415",
            "\"\"\"",
            "-    return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))",
            "+    return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))",
            "",
            "",
            "if torch.__version__ < \"1.4.0\":"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1707,
        "label": "yes",
        "change": [
            "class ScoreSdeVeScheduler(SchedulerMixin, ConfigMixin):",
            "",
            "# For small batch sizes, the paper \"suggest replacing norm(z) with sqrt(d), where d is the dim. of z\"",
            "# sample noise for correction",
            "-        noise = torch.randn(sample.shape, layout=sample.layout, generator=generator).to(sample.device)",
            "+        noise = randn_tensor(sample.shape, layout=sample.layout, generator=generator).to(sample.device)",
            "",
            "# compute step size from the model_output, the noise, and the snr",
            "grad_norm = torch.norm(model_output.reshape(model_output.shape[0], -1), dim=-1).mean()"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1709,
        "label": "no",
        "change": [
            "if __name__ == '__main__':",
            "import coremltools as ct",
            "",
            "print(f'{prefix} starting export with coremltools {ct.__version__}...')",
            "-        # convert model from torchscript and apply pixel scaling as per detect.py",
            "model = ct.convert(ts, inputs=[ct.ImageType(name='image', shape=img.shape, scale=1 / 255.0, bias=[0, 0, 0])])",
            "f = opt.weights.replace('.pt', '.mlmodel')  # filename",
            "model.save(f)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1710,
        "label": "no",
        "change": [
            "def quadratic_beta_schedule(timesteps):",
            "scale = 1000 / timesteps",
            "beta_start = scale * 0.0001",
            "beta_end = scale * 0.02",
            "-    return torch.linspace(beta_start**2, beta_end**2, timesteps, dtype = torch.float64) ** 2",
            "+    return torch.linspace(beta_start**0.5, beta_end**0.5, timesteps, dtype = torch.float64) ** 2",
            "",
            "",
            "def sigmoid_beta_schedule(timesteps):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1711,
        "label": "no",
        "change": [
            "class DistilBertModelTest(ModelTesterMixin, unittest.TestCase):",
            "",
            "with tempfile.TemporaryDirectory() as tmp:",
            "torch.jit.save(traced_model, os.path.join(tmp, \"traced_model.pt\"))",
            "-                loaded = torch.jit.load(os.path.join(tmp, \"bert.pt\"), map_location=torch_device)",
            "+                loaded = torch.jit.load(os.path.join(tmp, \"traced_model.pt\"), map_location=torch_device)",
            "loaded(inputs_dict[\"input_ids\"].to(torch_device), inputs_dict[\"attention_mask\"].to(torch_device))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1712,
        "label": "no",
        "change": [
            "class Sequence(Preprocessor):",
            "def later_run():",
            "return tf.assign(ref=states_buffer[index], value=tensor[0])",
            "",
            "-        assignment = tf.cond(pred=(index >= 0), true_fn=later_run, false_fn=first_run)",
            "+        assignment = self.cond(pred=(index >= 0), true_fn=later_run, false_fn=first_run)",
            "",
            "with tf.control_dependencies(control_inputs=(assignment,)):",
            "previous_states = [states_buffer[(index - n - 1) % self.length] for n in range(self.length)]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1718,
        "label": "no",
        "change": [
            "class TestRandomMotionBlur3D:",
            "'angle_factor': torch.tensor([[30.0, 30.0, 30.0]]),",
            "'direction_factor': torch.tensor([-0.5]),",
            "'border_type': torch.tensor([0]),",
            "+            'idx': torch.tensor([0]),",
            "}",
            "assert gradcheck(",
            "RandomMotionBlur3D(kernel_size=3, angle=(10, 30), direction=(-0.5, 0.5), p=1.0),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1719,
        "label": "yes",
        "change": [
            "def extract_fbank_features(",
            "if output_path is not None and output_path.is_file() and not overwrite:",
            "return",
            "",
            "-    _waveform = waveform * (2 ** 15)  # Kaldi compliance: 16-bit signed integers",
            "-    _waveform = _waveform.squeeze().numpy()",
            "+    _waveform = _convert_to_mono(waveform, sample_rate)",
            "+    _waveform = _waveform * (2 ** 15)  # Kaldi compliance: 16-bit signed integers",
            "+    _waveform = _waveform.numpy()",
            "",
            "features = _get_kaldi_fbank(_waveform, sample_rate, n_mel_bins)",
            "if features is None:"
        ],
        "comments": "",
        "Symptom": "return warning",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 1721,
        "label": "no",
        "change": [
            "class MADDPGTFPolicy(MADDPGPostprocessing, TFPolicy):",
            "out = tf.layers.dense(out, units=hidden, activation=activation)",
            "feature = tf.layers.dense(",
            "out, units=act_space.shape[0], activation=None)",
            "-            sampler = RelaxedOneHotCategorical(",
            "+            sampler = tfp.distributions.RelaxedOneHotCategorical(",
            "temperature=1.0, logits=feature).sample()",
            "",
            "return sampler, feature, model, tf.global_variables(scope.name)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1724,
        "label": "no",
        "change": [
            "class Entropy(Metric):",
            "mask: ``torch.Tensor``, optional (default = None).",
            "A masking tensor of shape (batch_size, ...).",
            "\"\"\"",
            "-        # Get the data from the Variables.",
            "logits, mask = self.unwrap_to_tensors(logits, mask)",
            "",
            "if mask is None:",
            "mask = torch.ones(logits.size()[:-1])",
            "",
            "-        log_probs = torch.nn.functional.log_softmax(Variable(logits), dim=-1).data",
            "+        log_probs = torch.nn.functional.log_softmax(logits, dim=-1)",
            "probabilities = torch.exp(log_probs) * mask.unsqueeze(-1)",
            "weighted_negative_likelihood = - log_probs * probabilities",
            "entropy = weighted_negative_likelihood.sum(-1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1726,
        "label": "no",
        "change": [
            "def update_confusion_matrix_variables(variables_to_update,",
            "# Tile the thresholds for every prediction.",
            "thresh_tiled = K.tile(",
            "K.expand_dims(K.constant(thresholds), 1),",
            "-        K.stack([1, num_predictions]))",
            "+        K.cast(",
            "+            K.stack([1, num_predictions]),",
            "+            dtype='int32',",
            "+        )",
            "+    )",
            "",
            "# Tile the predictions for every threshold.",
            "preds_tiled = K.tile(predictions_2d, [num_thresholds, 1])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1730,
        "label": "no",
        "change": [
            "class NoisyLayer(tf.keras.layers.Layer if tf else object):",
            "trainable=True,",
            "tf_name=self.prefix + \"_sigma_w\",",
            "shape=[in_size, self.out_size],",
            "-            dtype=tf.float32",
            "-        )",
            "+            dtype=tf.float32)",
            "",
            "self.sigma_b = get_variable(",
            "value=tf.keras.initializers.Constant("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1731,
        "label": "no",
        "change": [
            "class MemUsageMonitor(threading.Thread):",
            "",
            "def read(self):",
            "if not self.disabled:",
            "-            free, total = torch.cuda.mem_get_info()",
            "+            free, total = self.cuda_mem_get_info()",
            "self.data[\"free\"] = free",
            "self.data[\"total\"] = total"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1733,
        "label": "no",
        "change": [
            "class GaussianDiffusionContinuousTimes(nn.Module):",
            "def get_times(self, batch_size, noise_level, *, device):",
            "return torch.full((batch_size,), noise_level, device = device, dtype = torch.float32)",
            "",
            "-    def sample_random_times(self, batch_size, max_thres = 0.999, *, device):",
            "-        return torch.zeros((batch_size,), device = device).float().uniform_(0, max_thres)",
            "+    def sample_random_times(self, batch_size, *, device):",
            "+        return torch.zeros((batch_size,), device = device).float().uniform_(0, 1)",
            "",
            "def get_condition(self, times):",
            "return maybe(self.log_snr)(times)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1734,
        "label": "no",
        "change": [
            "def _expand_mask(mask: tf.Tensor, tgt_len: Optional[int] = None, past_key_values",
            "\"\"\"",
            "Expands attention_mask from `[bsz, seq_len]` to `[bsz, 1, tgt_seq_len, src_seq_len]`.",
            "\"\"\"",
            "-    bsz, src_len = shape_list(mask)",
            "+    src_len = shape_list(mask)[1]",
            "tgt_len = tgt_len if tgt_len is not None else src_len",
            "-",
            "-    expanded_mask = tf.cast(tf.broadcast_to(mask[:, None, None, :], (bsz, 1, tgt_len, src_len)), tf.float32)",
            "+    expanded_mask = tf.cast(tf.tile(mask[:, None, None, :], (1, 1, tgt_len, 1)), tf.float32)",
            "",
            "return (1.0 - expanded_mask) * LARGE_NEGATIVE"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1735,
        "label": "no",
        "change": [
            "def LinearizedConv1d(in_channels, out_channels, kernel_size, dropout=0, **kwargs",
            "std = math.sqrt((4 * (1.0 - dropout)) / (m.kernel_size[0] * in_channels))",
            "m.weight.data.normal_(mean=0, std=std)",
            "m.bias.data.zero_()",
            "-    return nn.utils.weight_norm(m)",
            "+    return nn.utils.weight_norm(m, dim=2)",
            "",
            "",
            "def ConvTBC(in_channels, out_channels, kernel_size, dropout=0, **kwargs):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1736,
        "label": "no",
        "change": [
            "def load_image_to_tensor(path_file: str, device: str) -> Tensor:",
            "# for convenience use the torch dlpack parser to get a zero copy torch.Tensor",
            "# TODO: evaluate other potential API so that we can return in numpy, jax, mxnet since",
            "# the kornia_rs cv::Tensor has this ability.",
            "-    th_tensor = torch.utils.dlpack.from_dlpack(cv_tensor)  # type: ignore # HxWx3",
            "+    th_tensor = dlpack.from_dlpack(cv_tensor)  # HxWx3",
            "# move the tensor to the desired device, move the data layout to CHW and clone",
            "# to return an owned data tensor.",
            "return th_tensor.to(torch.device(device)).permute(2, 0, 1).clone()  # CxHxW"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1737,
        "label": "no",
        "change": [
            "class Trainer(BaseTrainer):",
            "if self.gradient_clipping_config.clipglobalnorm:",
            "torch.nn.utils.clip_grad_norm_(variables, self.gradient_clipping_config.clipglobalnorm)",
            "if self.gradient_clipping_config.clipnorm:",
            "-            torch.nn.utils.clip_grad_norm_(variables, self.gradient_clipping_config.clipglobalnorm)",
            "+            torch.nn.utils.clip_grad_norm_(variables, self.gradient_clipping_config.clipnorm)",
            "if self.gradient_clipping_config.clipvalue:",
            "torch.nn.utils.clip_grad_value_(variables, self.gradient_clipping_config.clipvalue)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1739,
        "label": "yes",
        "change": [
            "class DistributionStrategyCheckpointTest(test_utils.TestCase,",
            "",
            "def assertRestoreOnCreateInReplicaContext(self, golden, strategy,",
            "use_function):",
            "+    if self.primary_device == \"GPU\":",
            "+      self.skipTest(\"Currently not working as expected on multiple devices\")",
            "+      # TODO(b/134376796) renable this once bug is fixed",
            "with strategy.scope():",
            "module = golden.create_module()"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 1740,
        "label": "no",
        "change": [
            "class BooleanAccuracyTest(AllenNlpTestCase):",
            "accuracy = BooleanAccuracy()",
            "predictions = torch.rand([5, 7], device=device)",
            "labels = torch.rand([5, 7], device=device)",
            "-        incorrect_shape_mask = torch.randint(0, 2, [5, 8], device=device)",
            "+        incorrect_shape_mask = torch.randint(0, 2, [5, 8], device=device).bool()",
            "with pytest.raises(ValueError):",
            "accuracy(predictions, labels, incorrect_shape_mask)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1741,
        "label": "no",
        "change": [
            "def perform_analysis_torch(preds, indices, noise_eps=0.1, delta=1e-5, moments=8,",
            "data_ind_eps_list = (data_ind_log_mgf - math.log(delta)) / l_list",
            "",
            "return min(eps_list_nm), min(data_ind_eps_list)",
            "+",
            "+",
            "+",
            "\\ No newline at end of file"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1742,
        "label": "yes",
        "change": [
            "def run_modelmerger(primary_model_name, secondary_model_name, teritary_model_nam",
            "if theta_func1:",
            "for key in tqdm.tqdm(theta_1.keys()):",
            "if 'model' in key:",
            "-                t2 = theta_2.get(key, torch.zeros_like(theta_1[key]))",
            "-                theta_1[key] = theta_func1(theta_1[key], t2)",
            "+                if key in theta_2:",
            "+                    t2 = theta_2.get(key, torch.zeros_like(theta_1[key]))",
            "+                    theta_1[key] = theta_func1(theta_1[key], t2)",
            "+                else:",
            "+                    theta_1[key] = 0",
            "del theta_2, teritary_model",
            "",
            "for key in tqdm.tqdm(theta_0.keys()):"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 1744,
        "label": "yes",
        "change": [
            "def get_lst_from_rank0(lst: List[int]) -> None:",
            "lst_tensor = torch.tensor(",
            "lst if dist.get_rank() == 0 else [-1] * len(lst),",
            "dtype=int,",
            "-        # device=torch.cuda.current_device(),",
            "-        device=torch.device('cuda:{}'.format(os.environ[\"LOCAL_RANK\"])),",
            "+        # device=get_accelerator().current_device_name(),",
            "+        device=torch.device(get_accelerator().device_name(os.environ[\"LOCAL_RANK\"])),",
            "requires_grad=False,",
            ")",
            "dist.broadcast(lst_tensor, src=0, async_op=False)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 1745,
        "label": "no",
        "change": [
            "class SignedGCN(torch.nn.Module):",
            "with torch.no_grad():",
            "pos_p = self.discriminate(z, pos_edge_index)[:, :2].max(dim=1)[1]",
            "neg_p = self.discriminate(z, neg_edge_index)[:, :2].max(dim=1)[1]",
            "-        pred = 1 - torch.cat([pos_p, neg_p]).cpu()",
            "+        pred = (1 - torch.cat([pos_p, neg_p])).cpu()",
            "y = torch.cat(",
            "[pred.new_ones((pos_p.size(0))),",
            "pred.new_zeros(neg_p.size(0))])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1747,
        "label": "yes",
        "change": [
            "def wrong_module(modelstore, sklearn_onnx_model):",
            ")",
            "def test_onnx_save_load(metadata, save_proc, modelstore, sklearn_onnx_model):",
            "model, data = sklearn_onnx_model",
            "-    info = save_proc(metadata)",
            "-    assert info.metadata is not None",
            "-    assert_have_file_extension(info.path, \".onnx\")",
            "+    model = save_proc(metadata)",
            "+    assert model.info.metadata is not None",
            "+    assert_have_file_extension(model.path, \".onnx\")",
            "",
            "opts = ort.SessionOptions()",
            "opts.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL",
            "opts.log_verbosity_level = 1",
            "-    loaded = bentoml.onnx.load(info.tag, model_store=modelstore, session_options=opts)",
            "+    loaded = bentoml.onnx.load(model.tag, model_store=modelstore, session_options=opts)",
            "assert predict_arr(loaded, data)[0] == 0"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1748,
        "label": "no",
        "change": [
            "class SuperGATConv(MessagePassing):",
            "r\"\"\"Runs the forward pass of the module.",
            "",
            "Args:",
            "-            neg_edge_index (Tensor, optional): The negative edges to train",
            "-                against. If not given, uses negative sampling to calculate",
            "-                negative edges. (default: :obj:`None`)",
            "+            neg_edge_index (torch.Tensor, optional): The negative edges to",
            "+                train against. If not given, uses negative sampling to",
            "+                calculate negative edges. (default: :obj:`None`)",
            "\"\"\"",
            "N, H, C = x.size(0), self.heads, self.out_channels"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1749,
        "label": "no",
        "change": [
            "def pytest_configure(config: _pytest.config.Config) -> None:",
            "config.addinivalue_line(\"markers\", \"e2e: end-to-end integration tests\")",
            "config.addinivalue_line(\"markers\", \"security: security integration tests\")",
            "config.addinivalue_line(\"markers\", \"tff: PySyTFF integration tests\")",
            "+    config.addinivalue_line(\"markers\", \"redis: Dataset tests\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1751,
        "label": "no",
        "change": [
            "class Network(object):",
            "\"\"\"",
            "@layer",
            "def softmax(self, target, axis, name=None):",
            "-        max_axis = tf.reduce_max(target, axis, keep_dims=True)",
            "+        max_axis = tf.reduce_max(target, axis, keepdims=True)",
            "target_exp = tf.exp(target-max_axis)",
            "-        normalize = tf.reduce_sum(target_exp, axis, keep_dims=True)",
            "+        normalize = tf.reduce_sum(target_exp, axis, keepdims=True)",
            "softmax = tf.div(target_exp, normalize, name)",
            "return softmax"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1752,
        "label": "no",
        "change": [
            "class TorchHook:",
            "def module_move_(self, dest):",
            "return self.send(dest).end_get()",
            "",
            "-        torch.nn.Module.move =  module_move_",
            "+        torch.nn.Module.move = module_move_",
            "",
            "def module_get_(self):",
            "\"\"\"Get model parameters\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1753,
        "label": "no",
        "change": [
            "class DocumentRNNEmbeddings(DocumentEmbeddings):",
            "",
            "def _apply(self, fn):",
            "major, minor, build, *_ = (int(info)",
            "-                                for info in torch.__version__.split('.'))",
            "+                                for info in torch.__version__.replace(\"+cpu\",\"\").split('.'))",
            "",
            "# fixed RNN change format for torch 1.4.0",
            "if major >= 1 and minor >= 4:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1754,
        "label": "yes",
        "change": [
            "def _precision_to_scale_tril(P):",
            "# Ref: https://nbviewer.jupyter.org/gist/fehiepsi/5ef8e09e61604f10607380467eb82006#Precision-to-scale_tril",
            "Lf = torch.linalg.cholesky(torch.flip(P, (-2, -1)))",
            "L_inv = torch.transpose(torch.flip(Lf, (-2, -1)), -2, -1)",
            "-    L = torch.triangular_solve(",
            "-        torch.eye(P.shape[-1], dtype=P.dtype, device=P.device), L_inv, upper=False",
            "-    )[0]",
            "+    L = torch.linalg.solve_triangular(",
            "+        L_inv, torch.eye(P.shape[-1], dtype=P.dtype, device=P.device), upper=False",
            "+    )",
            "return L",
            "",
            "",
            "+@ignore_torch_deprecation_warnings()",
            "def _try_possibly_intractable(fn, *args, **kwargs):",
            "# Convert ValueError into NotImplementedError.",
            "try:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1755,
        "label": "no",
        "change": [
            "from torch_geometric.transforms import TargetIndegree",
            "from torch_geometric.data import Data",
            "",
            "",
            "-def test_cartesian():",
            "+def test_target_indegree():",
            "assert TargetIndegree().__repr__() == 'TargetIndegree(cat=True)'",
            "",
            "-    edge_index = torch.LongTensor([[0, 1, 1, 2], [1, 0, 2, 1]])",
            "+    edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]])",
            "data = Data(edge_index=edge_index)",
            "expected_output = [1, 0.5, 0.5, 1]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1758,
        "label": "no",
        "change": [
            "def diagflat(",
            ")",
            "",
            "temp = x - torch.full(x.shape, padding_value).type(x.dtype)",
            "-    diagonal_to_add = torch.diag(temp, diagonal=offset).type(x.dtype) # diag does not support float16",
            "+    diagonal_to_add = torch.diag(temp, diagonal=offset).type(",
            "+        x.dtype",
            "+    )  # diag does not support float16",
            "",
            "diagonal_to_add = diagonal_to_add[tuple(slice(0, n) for n in output_array.shape)]",
            "diagonal_to_add = diagonal_to_add.to(x.dtype)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1760,
        "label": "no",
        "change": [
            "class StochasticDurationPredictor(nn.Module):",
            "h = self.post_pre(dr)",
            "h = self.post_convs(h, x_mask)",
            "h = self.post_proj(h) * x_mask",
            "-            noise = torch.rand(dr.size(0), 2, dr.size(2)).to(device=x.device, dtype=x.dtype) * x_mask",
            "+            noise = torch.randn(dr.size(0), 2, dr.size(2)).to(device=x.device, dtype=x.dtype) * x_mask",
            "z_q = noise",
            "",
            "# posterior encoder"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1761,
        "label": "no",
        "change": [
            "class VisionNetwork(Model):",
            "",
            "@override(Model)",
            "def _build_layers_v2(self, input_dict, num_outputs, options):",
            "+        import tensorflow.contrib.slim as slim",
            "+",
            "inputs = input_dict[\"obs\"]",
            "filters = options.get(\"conv_filters\")",
            "if not filters:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1762,
        "label": "no",
        "change": [
            "class TestCheckpointUtils(unittest.TestCase):",
            "def test_load_ema_from_checkpoint(self):",
            "dummy_state = {\"a\": torch.tensor([1]), \"b\": torch.tensor([0.1])}",
            "with patch(f\"{checkpoint_utils.__name__}.PathManager.open\") as mock_open, patch(",
            "-                f\"{checkpoint_utils.__name__}.torch.load\") as mock_load:",
            "+            f\"{checkpoint_utils.__name__}.torch.load\"",
            "+        ) as mock_load:",
            "",
            "-            mock_load.return_value = {",
            "-                \"extra_state\": {",
            "-                    \"ema\": dummy_state",
            "-                }",
            "-            }",
            "+            mock_load.return_value = {\"extra_state\": {\"ema\": dummy_state}}",
            "filename = \"ema_checkpoint.pt\"",
            "state = checkpoint_utils.load_ema_from_checkpoint(filename)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1763,
        "label": "no",
        "change": [
            "def transform_boxes(trans_mat: torch.Tensor, boxes: torch.Tensor, mode: str = \"x",
            "",
            "\"\"\"",
            "",
            "-    if not torch.is_tensor(boxes):",
            "-        raise TypeError(f\"Boxes type is not a torch.Tensor. Got {type(boxes)}\")",
            "-",
            "-    if not torch.is_tensor(trans_mat):",
            "-        raise TypeError(f\"Tranformation matrix type is not a torch.Tensor. Got {type(trans_mat)}\")",
            "-",
            "if not isinstance(mode, str):",
            "raise TypeError(f\"Mode must be a string. Got {type(mode)}\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1764,
        "label": "no",
        "change": [
            "class MeanAbsoluteError(Metric):",
            "mean_absolute_error = self._absolute_error / self._total_count",
            "if reset:",
            "self.reset()",
            "-        return mean_absolute_error",
            "+        return {\"mae\": mean_absolute_error}",
            "",
            "@overrides",
            "def reset(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1765,
        "label": "no",
        "change": [
            "def test_is_small_dataset(",
            "dataset_size, config_max_in_memory_dataset_size, env_max_in_memory_dataset_size, monkeypatch",
            "):",
            "if config_max_in_memory_dataset_size != \"default\":",
            "-        monkeypatch.setattr(datasets.config, \"MAX_IN_MEMORY_DATASET_SIZE_IN_BYTES\", config_max_in_memory_dataset_size)",
            "+        monkeypatch.setattr(",
            "+            datasets.config, \"HF_MAX_IN_MEMORY_DATASET_SIZE_IN_BYTES\", config_max_in_memory_dataset_size",
            "+        )",
            "",
            "-    max_in_memory_dataset_size = datasets.config.MAX_IN_MEMORY_DATASET_SIZE_IN_BYTES",
            "+    max_in_memory_dataset_size = datasets.config.HF_MAX_IN_MEMORY_DATASET_SIZE_IN_BYTES",
            "if config_max_in_memory_dataset_size == \"default\":",
            "if env_max_in_memory_dataset_size:",
            "assert max_in_memory_dataset_size == env_max_in_memory_dataset_size"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1766,
        "label": "yes",
        "change": [
            "class RandomThinPlateSpline(GeometricAugmentationBase2D):",
            "",
            "def generate_parameters(self, shape: torch.Size) -> Dict[str, Tensor]:",
            "B, _, _, _ = shape",
            "-        src = torch.tensor([[[-1.0, -1.0], [-1.0, 1.0], [1.0, -1.0], [1.0, 1.0], [0.0, 0.0]]]).repeat(B, 1, 1)  # Bx5x2",
            "+        src = torch.tensor([[[-1.0, -1.0], [-1.0, 1.0], [1.0, -1.0], [1.0, 1.0], [0.0, 0.0]]]).expand(B, 5, 2)  # Bx5x2",
            "dst = src + self.dist.rsample(src.shape)",
            "return dict(src=src, dst=dst)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 1767,
        "label": "no",
        "change": [
            "def laf_from_center_scale_ori(xy: torch.Tensor, scale: torch.Tensor, ori: torch.",
            "names = ['xy', 'scale', 'ori']",
            "for var_name, var, req_shape in zip(names, [xy, scale, ori], [(\"B\", \"N\", 2), (\"B\", \"N\", 1, 1), (\"B\", \"N\", 1)]):",
            "if not isinstance(var, torch.Tensor):",
            "-            raise TypeError(\"{} type is not a torch.Tensor. Got {}\".format(var_name, type(var)))",
            "+            raise TypeError(f\"{var_name} type is not a torch.Tensor. Got {type(var)}\")",
            "if len(var.shape) != len(req_shape):  # type: ignore  # because it does not like len(tensor.shape)",
            "raise TypeError(\"{} shape should be must be [{}]. \" \"Got {}\".format(var_name, str(req_shape), var.size()))",
            "for i, dim in enumerate(req_shape):  # type: ignore # because it wants typing for dim"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1768,
        "label": "no",
        "change": [
            "with tf.device(device_fn):",
            "# the softmax is implemented internally in tl.cost.cross_entropy(y, y_) to",
            "# speed up computation, so we use identity here.",
            "# see tf.nn.sparse_softmax_cross_entropy_with_logits()",
            "-    network = tl.layers.DenseLayer(network, n_units=10, act=tf.identity, name='output')",
            "+    network = tl.layers.DenseLayer(network, n_units=10, act=None, name='output')",
            "",
            "# define cost function and metric.",
            "y = network.outputs"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1769,
        "label": "no",
        "change": [
            "class ImageResize(Preprocessor):",
            "self.size = (width, height)",
            "super(ImageResize, self).__init__(scope=scope, summary_labels=summary_labels)",
            "",
            "-    def tf_process(self, tensor):",
            "-        return tf.image.resize_images(images=tensor, size=self.size)",
            "-",
            "def processed_shape(self, shape):",
            "return self.size + (shape[-1],)",
            "+",
            "+    def tf_process(self, tensor):",
            "+        return tf.image.resize_images(images=tensor, size=self.size)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1770,
        "label": "no",
        "change": [
            "class HubertModel(HubertPreTrainedModel):",
            "if not getattr(self.config, \"apply_spec_augment\", True):",
            "return hidden_states",
            "",
            "+        # generate indices & apply SpecAugment along time axis",
            "+        batch_size, sequence_length, hidden_size = hidden_states.size()",
            "+",
            "if mask_time_indices is not None:",
            "# apply SpecAugment along time axis with given mask_time_indices",
            "hidden_states[mask_time_indices] = self.masked_spec_embed.to(hidden_states.dtype)",
            "elif self.config.mask_time_prob > 0 and self.training:",
            "-            # generate indices & apply SpecAugment along time axis",
            "-            batch_size, sequence_length, hidden_size = hidden_states.size()",
            "-",
            "mask_time_indices = _compute_mask_indices(",
            "(batch_size, sequence_length),",
            "mask_prob=self.config.mask_time_prob,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1772,
        "label": "no",
        "change": [
            "class Graph():",
            "zero_pad=False,",
            "scale=False,",
            "scope=\"dec_pe\")",
            "+                self.dec *= key_masks",
            "",
            "## Dropout",
            "self.dec = tf.layers.dropout(self.dec,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1774,
        "label": "no",
        "change": [
            "class MemoryModel(Model):",
            "tensors=batch",
            ")",
            "",
            "-            optimization = tf.cond(",
            "+            return tf.cond(",
            "pred=optimize,",
            "true_fn=(lambda: self.fn_optimization(**batch)),",
            "false_fn=tf.no_op",
            ")",
            "",
            "-        return optimization",
            "-",
            "def tf_import_experience(self, states, internals, actions, terminal, reward):",
            "\"\"\"",
            "Imports experiences into the TensorFlow memory structure. Can be used to import"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1777,
        "label": "no",
        "change": [
            "class UniPC:",
            "x_t = x_t_ - expand_dims(alpha_t * B_h, dims) * (corr_res + rhos_c[-1] * D1_t)",
            "else:",
            "x_t_ = (",
            "-                expand_dims(torch.exp(log_alpha_t - log_alpha_prev_0), dimss) * x",
            "+                expand_dims(torch.exp(log_alpha_t - log_alpha_prev_0), dims) * x",
            "- expand_dims(sigma_t * h_phi_1, dims) * model_prev_0",
            ")",
            "if x_t is None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1779,
        "label": "yes",
        "change": [
            "class DepthWarper(nn.Module):",
            "factor_y = (self.height - 1) / 2",
            "factor_y = factor_y.to(device)",
            "",
            "-        z = 1. / flow[:, 2]  # Nx(H*W)",
            "+        z = 1. / (flow[:, 2] + self.eps)  # Nx(H*W)",
            "x = (flow[:, 0] * z - factor_x) / factor_x",
            "y = (flow[:, 1] * z - factor_y) / factor_y"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 1781,
        "label": "yes",
        "change": [
            "def result_wrapper(result_fn):",
            "# Wrapping result in identity so that control dependency between",
            "# update_op from `update_state` and result works in case result",
            "# returns a tensor.",
            "-                return tf.identity(result)",
            "+                return tf.nest.map_structure(tf.identity, result)",
            "",
            "# Wrapping result in merge_call. merge_call is used when we want to",
            "# leave replica mode and compute a value in cross replica mode."
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "state handling error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1783,
        "label": "no",
        "change": [
            "class DenseGCNConv(torch.nn.Module):",
            "idx = torch.arange(N, dtype=torch.long, device=adj.device)",
            "adj[:, idx, idx] = 1 if not self.improved else 2",
            "",
            "-        out = torch.matmul(x, self.weight)",
            "+        out = self.lin(x)",
            "deg_inv_sqrt = adj.sum(dim=-1).clamp(min=1).pow(-0.5)",
            "",
            "adj = deg_inv_sqrt.unsqueeze(-1) * adj * deg_inv_sqrt.unsqueeze(-2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1787,
        "label": "yes",
        "change": [
            "class AdalamFilter:",
            ")",
            "k1, k2, d1, d2, o1, o2, s1, s2 = self.__to_torch(k1, k2, d1, d2, o1, o2, s1, s2)",
            "if len(d2) <= 1:",
            "-            return _no_match(d1)",
            "+            idxs, dists = _no_match(d1)",
            "+            if return_dist:",
            "+                return idxs, dists",
            "+            return idxs",
            "distmat = dist_matrix(d1, d2, is_normalized=False)",
            "dd12, nn12 = torch.topk(distmat, k=2, dim=1, largest=False)  # (n1, 2)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1792,
        "label": "no",
        "change": [
            "class SequenceTagger(flair.nn.Model):",
            "",
            "tags = []",
            "all_tags = []",
            "-        feature_cpu = feature.detach().to(\"cpu\")",
            "-        transitions_cpu = self.transitions.detach().to(\"cpu\")",
            "+        feature_cpu = feature.detach().cpu()",
            "+        if self.use_crf:",
            "+            transitions_cpu = self.transitions.detach().cpu()",
            "for feats, length in zip(feature_cpu, lengths):",
            "if self.use_crf:",
            "confidences, tag_seq, scores = self._viterbi_decode("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1794,
        "label": "no",
        "change": [
            "class LSTMwRecDropout(nn.Module):",
            "self.hidden_size = hidden_size",
            "",
            "self.dropout = dropout",
            "-        self.drop = Dropout(dropout)",
            "+        self.drop = nn.Dropout(dropout)",
            "self.rec_drop = nn.Dropout(rec_dropout)",
            "",
            "self.num_directions = 2 if bidirectional else 1"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1795,
        "label": "yes",
        "change": [
            "def assert_cov_validity(cov, eigenvalue_lbnd=0., condition_number_ubnd=1e6):",
            "# Symmetry",
            "assert (cov.t() == cov).all(), 'Covariance must be symmetric!'",
            "# Precompute eigenvalues for subsequent tests.",
            "-    ws, _ = torch.symeig(cov)  # The eigenvalues of cov",
            "+    ws = torch.linalg.eigvalsh(cov)  # The eigenvalues of cov",
            "w_min = torch.min(ws)",
            "w_max = torch.max(ws)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1796,
        "label": "no",
        "change": [
            "def regression(incoming, placeholder=None, optimizer='adam',",
            "if placeholder is None:",
            "pscope = \"TargetsData\" if not name else name",
            "with tf.name_scope(pscope):",
            "-            placeholder = tf.placeholder(shape=input_shape, dtype=dtype, name=\"Y\")",
            "+            p_shape = [None] if to_one_hot else input_shape",
            "+            placeholder = tf.placeholder(shape=p_shape, dtype=dtype, name=\"Y\")",
            "",
            "tf.add_to_collection(tf.GraphKeys.TARGETS, placeholder)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1802,
        "label": "no",
        "change": [
            "def main():",
            "global_step += 1",
            "",
            "# Save a trained model",
            "-    if  n_gpu > 1 and torch.distributed.get_rank() == 0  or n_gpu <=1 :",
            "+    if args.local_rank == -1 or torch.distributed.get_rank() == 0:",
            "logging.info(\"** ** * Saving fine-tuned model ** ** * \")",
            "model.save_pretrained(args.output_dir)",
            "tokenizer.save_pretrained(args.output_dir)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1803,
        "label": "no",
        "change": [
            "def conv2d(x,",
            "filter_size=(3, 3),",
            "stride=(1, 1),",
            "pad=\"SAME\",",
            "-           dtype=tf.float32,",
            "+           dtype=None,",
            "collections=None):",
            "+    if dtype is None:",
            "+        dtype = tf.float32",
            "+",
            "with tf.variable_scope(name):",
            "stride_shape = [1, stride[0], stride[1], 1]",
            "filter_shape = ["
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1804,
        "label": "yes",
        "change": [
            "class TestNnUtil(AllenNlpTestCase):",
            "\"b\": FakeTensor(),",
            "\"c\": (1, FakeTensor()),",
            "}",
            "-        new_device = 4",
            "+        new_device = torch.device(4)",
            "moved_obj = util.move_to_device(structured_obj, new_device)",
            "assert moved_obj[\"a\"][0].a == 1",
            "assert moved_obj[\"a\"][0].b._device == new_device"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 1808,
        "label": "no",
        "change": [
            "import flair",
            "",
            "def main():",
            "print(\"#### Versions:\")",
            "-    print(f\"#### Flair\\n{flair.__version__}\")",
            "-    print(f\"#### Pytorch\\n{torch.__version__}\")",
            "-    print(f\"#### Transformers\\n{transformers.__version__}\")",
            "+    print(f\"##### Flair\\n{flair.__version__}\")",
            "+    print(f\"##### Pytorch\\n{torch.__version__}\")",
            "+    print(f\"##### Transformers\\n{transformers.__version__}\")",
            "print(f\"#### GPU\\n{torch.cuda.is_available()}\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1810,
        "label": "no",
        "change": [
            "def Conv2DTranspose(",
            "bias_regularizer=bias_regularizer,",
            "activity_regularizer=activity_regularizer)",
            "ret = layer.apply(inputs, scope=tf.get_variable_scope())",
            "+        ret = tf.identity(ret, name='output')",
            "",
            "ret.variables = VariableHolder(W=layer.kernel)",
            "if use_bias:",
            "ret.variables.b = layer.bias",
            "-    return tf.identity(ret, name='output')",
            "+    return ret",
            "",
            "",
            "Deconv2D = Conv2DTranspose"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1813,
        "label": "no",
        "change": [
            "from torch_geometric.nn.functional import gini",
            "",
            "",
            "def test_gini():",
            "-    w = torch.tensor(",
            "-        [",
            "-            [0., 0., 0., 0.],",
            "-            [0., 0., 0., 1000.0]",
            "-        ]",
            "-    )",
            "+    w = torch.tensor([[0., 0., 0., 0.], [0., 0., 0., 1000.0]])",
            "assert torch.isclose(gini(w), torch.tensor(0.5))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1816,
        "label": "no",
        "change": [
            "class ArabicSpeechCorpus(datasets.GeneratorBasedBuilder):",
            "{",
            "\"file\": datasets.Value(\"string\"),",
            "\"text\": datasets.Value(\"string\"),",
            "-                    \"audio\": datasets.features.Audio(sampling_rate=48_000),",
            "+                    \"audio\": datasets.Audio(sampling_rate=48_000),",
            "\"phonetic\": datasets.Value(\"string\"),",
            "\"orthographic\": datasets.Value(\"string\"),",
            "}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1818,
        "label": "no",
        "change": [
            "def cosine_similarity(v1, v2):",
            "- `<https://en.wikipedia.org/wiki/Cosine_similarity>`__.",
            "",
            "\"\"\"",
            "-    return tf.reduce_sum(tf.multiply(v1, v2), 1) / (",
            "-        tf.sqrt(tf.reduce_sum(tf.multiply(v1, v1), 1)) * tf.sqrt(tf.reduce_sum(tf.multiply(v2, v2), 1))",
            "-    )",
            "+    return tf.reduce_sum(",
            "+        tf.multiply(v1, v2), 1",
            "+    ) / (tf.sqrt(tf.reduce_sum(tf.multiply(v1, v1), 1)) * tf.sqrt(tf.reduce_sum(tf.multiply(v2, v2), 1)))",
            "",
            "",
            "# Regularization Functions"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1821,
        "label": "no",
        "change": [
            "def test_zero_refresh(workers):",
            "t = torch.tensor([2.2, -1.0])",
            "x = t.fix_prec().share(bob, alice, crypto_provider=james)",
            "",
            "-    x_sh = x.child.child.child",
            "+    x_sh = x.child.child",
            "assert (x_sh.zero().get() == torch.zeros(*t.shape).long()).all()",
            "",
            "x = t.fix_prec().share(bob, alice, crypto_provider=james)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1825,
        "label": "yes",
        "change": [
            "def test_gaussian_tensordot(dot_dims,",
            "nb = dot_dims",
            "nc = y_dim - dot_dims",
            "try:",
            "-        torch.cholesky(x.precision[..., na:, na:] + y.precision[..., :nb, :nb])",
            "+        torch.linalg.cholesky(x.precision[..., na:, na:] + y.precision[..., :nb, :nb])",
            "except RuntimeError:",
            "pytest.skip(\"Cannot marginalize the common variables of two Gaussians.\")"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1827,
        "label": "no",
        "change": [
            "def load_image(file_name):",
            "",
            "",
            "def clip_and_convert_tensor(tensor):",
            "-    \"\"\"convert the input torch.Tensor to OpenCV image,clip it to be between",
            "+    \"\"\"Convert the input torch.Tensor to OpenCV image,clip it to be between.",
            "+",
            "[0, 255] and convert it to unit",
            "\"\"\"",
            "img = tgm.utils.tensor_to_image(255.0 * tensor)  # convert tensor to numpy"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1829,
        "label": "no",
        "change": [
            "class SISNRLoss(TimeDomainLoss):",
            "# s_target = <s', s>s / ||s||^2",
            "pair_wise_dot = torch.sum(s_estimate * s_target, dim=1, keepdim=True)  # [B, 1]",
            "s_target_energy = (",
            "-            torch.sum(s_target ** 2, dim=1, keepdim=True) + self.eps",
            "+            torch.sum(s_target**2, dim=1, keepdim=True) + self.eps",
            ")  # [B, 1]",
            "pair_wise_proj = pair_wise_dot * s_target / s_target_energy  # [B, T]",
            "# e_noise = s' - s_target",
            "e_noise = s_estimate - pair_wise_proj  # [B, T]",
            "",
            "# SI-SNR = 10 * log_10(||s_target||^2 / ||e_noise||^2)",
            "-        pair_wise_si_snr = torch.sum(pair_wise_proj ** 2, dim=1) / (",
            "-            torch.sum(e_noise ** 2, dim=1) + self.eps",
            "+        pair_wise_si_snr = torch.sum(pair_wise_proj**2, dim=1) / (",
            "+            torch.sum(e_noise**2, dim=1) + self.eps",
            ")",
            "pair_wise_si_snr = 10 * torch.log10(pair_wise_si_snr + self.eps)  # [B]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1830,
        "label": "no",
        "change": [
            "def test_arma_conv():",
            "",
            "t = '(Tensor, SparseTensor, OptTensor) -> Tensor'",
            "jit = torch.jit.script(conv.jittable(t))",
            "-    assert torch.allclose(conv(x, adj.t()), out, atol=1e-6)",
            "+    assert torch.allclose(jit(x, adj.t()), out, atol=1e-6)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1831,
        "label": "no",
        "change": [
            "def sort(",
            "*,",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "-    sorted_tensor, _ = torch.sort(x, dim=axis, descending=descending, out=out)",
            "+    sorted_tensor, _ = torch.sort(",
            "+        x, dim=axis, descending=descending, stable=stable, out=out",
            "+    )",
            "return sorted_tensor"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1832,
        "label": "no",
        "change": [
            "def run(",
            "",
            "if npr == 0:",
            "if nl:",
            "-                    stats.append((correct, *torch.zeros((3, 0), device=device)))",
            "+                    stats.append((correct, *torch.zeros((2, 0), device=device), labels[:, 0]))",
            "continue",
            "",
            "# Predictions"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1834,
        "label": "no",
        "change": [
            "def assign_anchor_to_bbox(ground_truth, anchors, device, iou_threshold=0.5):",
            "device=device)",
            "# Assign ground-truth bounding boxes according to the threshold",
            "max_ious, indices = torch.max(jaccard, dim=1)",
            "-    anc_i = torch.nonzero(max_ious >= 0.5).reshape(-1)",
            "-    box_j = indices[max_ious >= 0.5]",
            "+    anc_i = torch.nonzero(max_ious >= iou_threshold).reshape(-1)",
            "+    box_j = indices[max_ious >= iou_threshold]",
            "anchors_bbox_map[anc_i] = box_j",
            "col_discard = torch.full((num_anchors,), -1)",
            "row_discard = torch.full((num_gt_boxes,), -1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1835,
        "label": "no",
        "change": [
            "class ScoreSdeVePipeline(DiffusionPipeline):",
            "",
            "model = self.unet",
            "",
            "-        sample = torch.randn(*shape, generator=generator) * self.scheduler.init_noise_sigma",
            "+        sample = randn_tensor(shape, generator=generator) * self.scheduler.init_noise_sigma",
            "sample = sample.to(self.device)",
            "",
            "self.scheduler.set_timesteps(num_inference_steps)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1836,
        "label": "no",
        "change": [
            "def compute_loss(pred, true):",
            "",
            "if cfg.model.loss_fun == 'cross_entropy':",
            "# multiclass",
            "-        if pred.ndim > 1:",
            "+        if pred.ndim > 1 and true.ndim == 1:",
            "pred = F.log_softmax(pred, dim=-1)",
            "return F.nll_loss(pred, true), pred",
            "-        # binary",
            "+        # binary or multilabel",
            "else:",
            "true = true.float()",
            "return bce_loss(pred, true), torch.sigmoid(pred)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1837,
        "label": "no",
        "change": [
            "class TFSEquenceExampleDecoder(data_decoder.DataDecoder):",
            "",
            "# Reshape non-sparse elements just once:",
            "for k, value in all_features.items():",
            "-      if isinstance(value, parsing_ops.FixedLenFeature):",
            "-        example[k] = array_ops.reshape(example[k], value.shape)",
            "+      if isinstance(value, tf.FixedLenFeature):",
            "+        example[k] = tf.reshape(example[k], value.shape)",
            "",
            "if not items:",
            "items = self._items_to_handlers.keys()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1838,
        "label": "no",
        "change": [
            "class TFBartForConditionalGeneration(TFBartPretrainedModel, TFCausalLanguageMode",
            "if inputs[\"labels\"] is not None:",
            "inputs[\"labels\"] = tf.where(",
            "inputs[\"labels\"] == self.config.pad_token_id,",
            "-                tf.fill(shape_list(inputs[\"labels\"]), -100),",
            "+                tf.cast(tf.fill(shape_list(inputs[\"labels\"]), -100), inputs[\"labels\"].dtype),",
            "inputs[\"labels\"],",
            ")",
            "inputs[\"use_cache\"] = False"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1840,
        "label": "no",
        "change": [
            "def inference_nn4_max_pool_96(images, phase_train=True):",
            "affn1 = _affine(resh1, 896, 128)",
            "if FLAGS.keep_probability<1.0:",
            "affn1 = control_flow_ops.cond(phase_train,",
            "-                                  lambda: tf.nn.dropout(affn1, FLAGS.keep_probability), affn1)",
            "+                                  lambda: tf.nn.dropout(affn1, FLAGS.keep_probability), lambda: affn1)",
            "norm = tf.nn.l2_normalize(affn1, 1, 1e-10)",
            "",
            "return norm"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1842,
        "label": "no",
        "change": [
            "class LightningLite:",
            "",
            "@staticmethod",
            "def _get_distributed_sampler(dataloader: DataLoader, **kwargs: Any) -> DistributedSampler:",
            "+        kwargs.setdefault(\"shuffle\", isinstance(dataloader.sampler, RandomSampler))",
            "kwargs.setdefault(\"seed\", int(os.getenv(\"PL_GLOBAL_SEED\", 0)))",
            "return DistributedSamplerWrapper(dataloader.sampler, **kwargs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1843,
        "label": "no",
        "change": [
            "class FineMatching(nn.Module):",
            "",
            "# compute coordinates from heatmap",
            "coords_normalized = dsnt.spatial_expectation2d(heatmap[None], True)[0]  # [M, 2]",
            "-        grid_normalized = create_meshgrid(W, W, True, heatmap.device).reshape(1, -1, 2)  # [1, WW, 2]",
            "+        grid_normalized = create_meshgrid(",
            "+            W, W, normalized_coordinates=True, device=heatmap.device, dtype=heatmap.dtype",
            "+        ).reshape(1, -1, 2)  # [1, WW, 2]",
            "",
            "# compute std over <x, y>",
            "var = torch.sum(grid_normalized**2 * heatmap.view(-1, WW, 1), dim=1) - coords_normalized**2  # [M, 2]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1844,
        "label": "no",
        "change": [
            "class Histogram(pyro.distributions.Distribution):",
            "vs.append(v)",
            "log_weights.append(log_weight)",
            "",
            "-        log_weights = torch.cat(log_weights)",
            "-        if not isinstance(log_weights, torch.autograd.Variable):",
            "+        log_weights = torch.stack(log_weights).squeeze()  # Work around bug in torch.cat().",
            "+        if not isinstance(log_weights, Variable):",
            "log_weights = Variable(log_weights)",
            "log_z = pyro.util.log_sum_exp(log_weights)",
            "ps = torch.exp(log_weights - log_z.expand_as(log_weights))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1846,
        "label": "no",
        "change": [
            "class TFWav2Vec2ForCTC(TFWav2Vec2PreTrainedModel):",
            "",
            ">>> # wrap processor as target processor to encode labels",
            ">>> with processor.as_target_processor():",
            "-            >>>     labels = processor(transcription, return_tensors=\"tf\").input_values",
            "+            >>>     labels = processor(transcription, return_tensors=\"tf\").input_ids",
            "",
            ">>> loss = model(input_values, labels=labels).loss",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1848,
        "label": "no",
        "change": [
            "def point_mesh_face_distance(",
            "# weight each example by the inverse of number of points in the example",
            "point_to_cloud_idx = pcls.packed_to_cloud_idx()  # (sum(P_i),)",
            "num_points_per_cloud = pcls.num_points_per_cloud()  # (N,)",
            "+    # pyre-ignore[16]: `torch.Tensor` has no attribute `gather`",
            "weights_p = num_points_per_cloud.gather(0, point_to_cloud_idx)",
            "weights_p = 1.0 / weights_p.float()",
            "point_to_face = point_to_face * weights_p"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1851,
        "label": "no",
        "change": [
            "class PolicyNetwork(Model):",
            "mean + std * z",
            ")  # TanhNormal distribution as actions; reparameterization trick",
            "",
            "-        action = self.action_range * mean if deterministic else action",
            "+        action = self.action_range * tf.math.tanh(mean) if deterministic else action",
            "return action.numpy()[0]",
            "",
            "def sample_action(self, ):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1852,
        "label": "no",
        "change": [
            "def _flatten_probas(probas, labels, ignore=None):",
            "probas = probas.view(B, 1, H, W)",
            "",
            "C = probas.size(1)",
            "-    probas = torch.movedim(probas, 0, -1)  # [B, C, Di, Dj, Dk...] -> [B, C, Di...Dk, C]",
            "+    probas = torch.movedim(probas, 1, -1)  # [B, C, Di, Dj, ...] -> [B, Di, Dj, ..., C]",
            "probas = probas.contiguous().view(-1, C)  # [P, C]",
            "",
            "labels = labels.view(-1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1854,
        "label": "no",
        "change": [
            "class MADDPGTFPolicy(MADDPGPostprocessing, TFPolicy):",
            "out = obs",
            "",
            "for hidden in hiddens:",
            "-                out = tf.layers.dense(",
            "-                    out, units=hidden, activation=activation",
            "-                )",
            "+                out = tf.layers.dense(out, units=hidden, activation=activation)",
            "feature = tf.layers.dense(",
            "out, units=act_space.shape[0], activation=None)",
            "sampler = tfp.distributions.RelaxedOneHotCategorical("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1855,
        "label": "no",
        "change": [
            "class CrossAttention(nn.Module):",
            "# attention, what we cannot get enough of",
            "attn = sim.softmax(dim=-1)",
            "",
            "-        out = einsum('b i j, b j d -> b i d', attn, v)",
            "+        out = torch.einsum('b i j, b j d -> b i d', attn, v)",
            "out = rearrange(out, '(b h) n d -> b n (h d)', h=h)",
            "return self.to_out(out)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1857,
        "label": "no",
        "change": [
            "handle_average_backwards_compatibility = get_average_backwards_compatibility_fun",
            "",
            "check_num_rank_power_of_2 = num_rank_is_power_2",
            "",
            "+",
            "# This function will create a default device map which includes all visible devices.",
            "# Please run this function in a subprocess",
            "def _check_has_gpu():",
            "-  import tensorflow as tf",
            "-  return tf.test.is_gpu_available()",
            "+    import tensorflow as tf",
            "+    return tf.test.is_gpu_available()",
            "+",
            "",
            "def _normalize_name(name):",
            "\"\"\"Normalizes operation name to TensorFlow rules.\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1859,
        "label": "yes",
        "change": [
            "class MultiHeadSelfAttention(Seq2SeqEncoder):",
            "keys_per_head = keys_per_head.view(batch_size * num_heads, timesteps, int(self._attention_dim/num_heads))",
            "",
            "# shape (num_heads * batch_size, timesteps, timesteps)",
            "-        scaled_similarities = torch.bmm(queries_per_head, keys_per_head.transpose(1, 2)) / self._scale",
            "+        scaled_similarities = torch.bmm(queries_per_head / self._scale, keys_per_head.transpose(1, 2))",
            "",
            "# shape (num_heads * batch_size, timesteps, timesteps)",
            "# Normalise the distributions, using the same mask for all heads.",
            "-        attention = masked_softmax(scaled_similarities, mask.repeat(1, num_heads).view(batch_size * num_heads, timesteps))",
            "+        attention = masked_softmax(scaled_similarities,",
            "+                                   mask.repeat(1, num_heads).view(batch_size * num_heads, timesteps),",
            "+                                   memory_efficient=True)",
            "attention = self._attention_dropout(attention)",
            "",
            "# Take a weighted sum of the values with respect to the attention"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1860,
        "label": "no",
        "change": [
            "y_ = tf.placeholder(tf.int64, shape=[None], name='y_')",
            "# define the network",
            "def mlp(x, is_train=True, reuse=False):",
            "with tf.variable_scope(\"MLP\", reuse=reuse):",
            "-        tl.layers.set_name_reuse(reuse)",
            "network = tl.layers.InputLayer(x, name='input')",
            "network = tl.layers.DropoutLayer(network, keep=0.8, is_fix=True, is_train=is_train, name='drop1')",
            "network = tl.layers.DenseLayer(network, n_units=800, act=tf.nn.relu, name='relu1')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1861,
        "label": "no",
        "change": [
            "class XLNetRelativeAttention(nn.Module):",
            "v_head_h = torch.einsum(\"ibh,hnd->ibnd\", cat, self.v)",
            "",
            "# positional heads",
            "-            k_head_r = torch.einsum(\"ibh,hnd->ibnd\", r, self.r)",
            "+            # type casting for fp16 support",
            "+            k_head_r = torch.einsum(\"ibh,hnd->ibnd\", r.type(self.r.dtype), self.r)",
            "",
            "# core attention ops",
            "attn_vec = self.rel_attn_core("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1862,
        "label": "no",
        "change": [
            "class TrainerLoggingMixin(ABC):",
            "",
            "# when using DP, we get one output per gpu",
            "# average outputs and return",
            "-        if type(output) is torch.Tensor:",
            "+        if isinstance(output, torch.Tensor):",
            "return output.mean()",
            "",
            "for k, v in output.items():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1865,
        "label": "no",
        "change": [
            "class Callback(abc.ABC):",
            "\"\"\"",
            "pass",
            "",
            "+    def on_before_backward(self, trainer: 'pl.Trainer', pl_module: 'pl.LightningModule', loss: torch.Tensor) -> None:",
            "+        \"\"\"Called before ``loss.backward()``.\"\"\"",
            "+        pass",
            "+",
            "def on_after_backward(self, trainer: 'pl.Trainer', pl_module: 'pl.LightningModule') -> None:",
            "\"\"\"Called after ``loss.backward()`` and before optimizers do anything.\"\"\"",
            "pass"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1866,
        "label": "no",
        "change": [
            "class Layer_Embed_Test(CustomTestCase):",
            "embed_tensor, embed_nce_loss = emb_net([inputs, labels])",
            "self.assertEqual(embed_tensor.get_shape().as_list(), [batch_size, embedding_size])",
            "",
            "-        outputs = tl.layers.Dense(n_units=10, name=\"dense\")(embed_tensor)",
            "+        outputs = tl.layers.Dense(n_units=10)(embed_tensor)",
            "model = tl.models.Model(inputs=[inputs, labels], outputs=[outputs, embed_nce_loss], name=\"word2vec_model\")",
            "out, nce = model(",
            "[np.random.randint(0, 1, size=[batch_size]), np.random.randint(0, 1, size=[batch_size, 1])],"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1867,
        "label": "no",
        "change": [
            "def get_lazyop_shape(ast:LazyOp): return GenericShape.exec_ast(ast, GenericShape",
            "",
            "# assumes you are using ShapeTracker",
            "# used in GPUBuffer, OpenCLBuffer, and LLVMBuffer",
            "-# type: ignore",
            "-class ExplicitExecAST:",
            "+class ExplicitExecAST(DeviceBuffer):",
            "def __init__(self, shape:Union[ShapeTracker, Tuple[int, ...]], hostbuf=None):",
            "self.st = shape if isinstance(shape, ShapeTracker) else ShapeTracker(tuple(shape))",
            "self.shape = self.st.shape"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1868,
        "label": "no",
        "change": [
            "class Network(Layer):",
            "layer.name + '.\\n'",
            "'Note that input tensors are '",
            "'instantiated via '",
            "-                              '`tensor = tf.layers.Input(shape)`.\\n'",
            "+                              '`tensor = keras.layers.Input(shape)`.\\n'",
            "'The tensor that caused the issue was: ' +",
            "str(x.name))",
            "for x in self.outputs:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1870,
        "label": "no",
        "change": [
            "def gini(w):",
            "for row in w:",
            "t = row.repeat(row.shape[0], 1)",
            "u = (t - t.T).abs().sum() / (",
            "-                2 * (",
            "-                    row.shape[-1] ** 2 - row.shape[-1]",
            "-                ) * row.abs().mean() + torch.finfo().eps",
            "+            2 * (",
            "+                row.shape[-1] ** 2 - row.shape[-1]",
            "+            ) * row.abs().mean() + torch.finfo().eps",
            ")",
            "s += u",
            "s /= w.shape[0]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1873,
        "label": "yes",
        "change": [
            "class TestScalarMix(AllenNlpTestCase):",
            "for k in range(3):",
            "mean = numpy.mean(tensors[k].data.numpy()[numpy_mask == 1])",
            "std = numpy.std(tensors[k].data.numpy()[numpy_mask == 1])",
            "-            normed_tensor = (tensors[k].data.numpy() - mean) / (std + 1e-12)",
            "+            normed_tensor = (tensors[k].data.numpy() - mean) / (",
            "+                std + util.tiny_value_of_dtype(torch.float)",
            "+            )",
            "expected_result += normed_tensor * normed_weights[k]",
            "expected_result *= 0.5"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 1875,
        "label": "no",
        "change": [
            "class T5DenseGatedActDense(nn.Module):",
            "",
            "# To make 8bit quantization work for google/flan-t5-xxl, self.wo is kept in float32.",
            "# See https://github.com/huggingface/transformers/issues/20287",
            "-        if hidden_states.dtype != self.wo.weight.dtype:",
            "+        # we also make sure the weights are not in `int8` in case users will force `_keep_in_fp32_modules` to be `None``",
            "+        if hidden_states.dtype != self.wo.weight.dtype and self.wo.weight.dtype != torch.int8:",
            "hidden_states = hidden_states.to(self.wo.weight.dtype)",
            "",
            "hidden_states = self.wo(hidden_states)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1877,
        "label": "no",
        "change": [
            "def mnist_test_tsne_ssvae(name=None, ssvae=None, test_loader=None):",
            "\"\"\"",
            "if name is None:",
            "name = 'SS-VAE'",
            "-    data = Variable(test_loader.dataset.test_data.float())",
            "-    mnist_labels = Variable(test_loader.dataset.test_labels)",
            "+    data = test_loader.dataset.test_data.float()",
            "+    mnist_labels = test_loader.dataset.test_labels",
            "z_mu, z_sigma = ssvae.encoder_z([data, mnist_labels])",
            "plot_tsne(z_mu, mnist_labels, name)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1878,
        "label": "no",
        "change": [
            "class _ConvND(base.AbstractModule):",
            "while self._mask.shape.ndims < w.shape.ndims:",
            "self._mask = tf.expand_dims(self._mask, -1)",
            "",
            "-    # ResourceVariables currently don't support *=.",
            "+    # tf.Variable & tf.ResourceVariable don't support *=.",
            "w = w * self._mask  # pylint: disable=g-no-augmented-assignment",
            "",
            "return w"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1880,
        "label": "yes",
        "change": [
            "class Finfo:",
            "return float(self._tf_finfo.tiny)",
            "",
            "",
            "-def finfo(datatype_in):",
            "-    return Finfo(tf.experimental.numpy.finfo(datatype_in))",
            "+def finfo(type):",
            "+    return Finfo(tf.experimental.numpy.finfo(dtype_from_str(type)))",
            "",
            "",
            "backend = 'tensorflow'"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 1881,
        "label": "no",
        "change": [
            "class ImageNetModel(ModelDesc):",
            "image_dtype = tf.uint8",
            "",
            "def __init__(self, data_format='NCHW'):",
            "-        if data_format == 'NCHW':",
            "-            assert tf.test.is_gpu_available()",
            "self.data_format = data_format",
            "",
            "def _get_inputs(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1882,
        "label": "yes",
        "change": [
            "def train(model, criterion, optimizer,",
            "",
            "# check nan loss",
            "if torch.isnan(loss).any():",
            "-          raise RuntimeError(f'Detected NaN loss at step {self.step}.')",
            "+          raise RuntimeError(f'Detected NaN loss at step {global_step}.')",
            "",
            "optimizer.zero_grad()"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 1885,
        "label": "no",
        "change": [
            "with tf.device('/cpu:0'):",
            "with tf.variable_scope(\"model\", reuse=reuse):",
            "tl.layers.set_name_reuse(reuse)",
            "network = tl.layers.InputLayer(x_crop, name='input_layer')",
            "-",
            "+",
            "network = tl.layers.Conv2dLayer(network, act=tf.identity,",
            "shape=[5, 5, 3, 64], strides=[1, 1, 1, 1], padding='SAME', # 64 features for each 5x5x3 patch",
            "W_init=W_init, b_init=None, name='cnn_layer1')                            # output: (batch_size, 24, 24, 64)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1887,
        "label": "no",
        "change": [
            "class ValidationCallback(PeriodicCallback):",
            "batch_size = dp[0].shape[0]   # assume batched input",
            "",
            "cnt += batch_size",
            "-                outputs = self.sess.run(output_vars, feed_dict=feed)",
            "+                outputs = sess.run(output_vars, feed_dict=feed)",
            "cost = outputs[-1]",
            "# each batch might not have the same size in validation",
            "cost_sum += cost * batch_size"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1889,
        "label": "no",
        "change": [
            "def main():",
            "# extract",
            "logging.info('backend = ' + args.backend)",
            "if args.backend == \"pytorch\":",
            "-        from espnet.lmpytorch.tts_pytorch import decode",
            "+        from espnet.tts.pytorch.tts_pytorch import decode",
            "decode(args)",
            "else:",
            "raise NotImplementedError(\"Only pytorch is supported.\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1892,
        "label": "no",
        "change": [
            "class TestLocalFeatureMatcher:",
            "pts_src = data_dev['pts0']",
            "pts_dst = data_dev['pts1']",
            "with torch.no_grad():",
            "+            torch.manual_seed(0)",
            "out = matcher(data_dev)",
            "homography, inliers = ransac(out['keypoints0'], out['keypoints1'])",
            "assert inliers.sum().item() > 50  # we have enough inliers"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1893,
        "label": "no",
        "change": [
            "def SubpixelConv2d(net, scale=2, n_out_channel=None, act=tf.identity, name='subp",
            "bsize = tf.shape(X)[0] # Handling Dimension(None) type for undefined batch dim",
            "Xs=tf.split(X,r,3) #b*h*w*r*r",
            "Xr=tf.concat(Xs,2) #b*h*(r*w)*r",
            "-            X=tf.reshape(Xr,(bsize,r*a,r*b,c)) # b*(r*h)*(r*w)*c",
            "+            X=tf.reshape(Xr,(bsize,r*a,r*b,n_out_channel)) # b*(r*h)*(r*w)*c",
            "else:",
            "print(_err_log)",
            "return X"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1894,
        "label": "no",
        "change": [
            "class Memory(object):",
            "Args:",
            "loss_per_instance: Loss per instance tensor.",
            "\"\"\"",
            "-        pass",
            "+        return tf.no_op()",
            "",
            "def get_variables(self):",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1895,
        "label": "yes",
        "change": [
            "class Finfo:",
            "return self._torch_finfo.tiny",
            "",
            "",
            "-def finfo(datatype_in):",
            "-    return Finfo(_torch.finfo(datatype_in))",
            "+def finfo(type):",
            "+    return Finfo(_torch.finfo(dtype_from_str(type)))",
            "",
            "",
            "backend = 'torch'"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 1896,
        "label": "no",
        "change": [
            "class MaskFormerSwinSelfAttention(nn.Module):",
            "# get pair-wise relative position index for each token inside the window",
            "coords_h = torch.arange(self.window_size[0])",
            "coords_w = torch.arange(self.window_size[1])",
            "-        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))",
            "+        coords = torch.stack(meshgrid([coords_h, coords_w], indexing=\"ij\"))",
            "coords_flatten = torch.flatten(coords, 1)",
            "relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]",
            "relative_coords = relative_coords.permute(1, 2, 0).contiguous()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1899,
        "label": "no",
        "change": [
            "class FullyConnectedNet(BaseModel):",
            "nn.Linear(input_size, int(math.ceil(input_size/2))),",
            "torch.nn.LeakyReLU(),",
            "nn.Dropout(0.2),",
            "-            nn.Linear(int(math.ceil(input_size/2)), output_size)",
            "+            nn.Linear(int(math.ceil(input_size/2)), output_size),",
            "+            torch.nn.LeakyReLU()",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1904,
        "label": "no",
        "change": [
            "def _compute_translation_matrix(translation: torch.Tensor) -> torch.Tensor:",
            "def _compute_scaling_matrix(scale: torch.Tensor,",
            "center: torch.Tensor) -> torch.Tensor:",
            "\"\"\"Computes affine matrix for scaling.\"\"\"",
            "-    angle: torch.Tensor = torch.zeros(scale.shape[:1])",
            "+    angle: torch.Tensor = torch.zeros(scale.shape[:1], device=scale.device, dtype=scale.dtype)",
            "matrix: torch.Tensor = get_rotation_matrix2d(center, angle, scale)",
            "return matrix"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1905,
        "label": "no",
        "change": [
            "def kmean_anchors(path='./data/coco128.yaml', n=9, img_size=640, thr=4.0, gen=10",
            "# Evolve",
            "npr = np.random",
            "f, sh, mp, s = fitness(k), k.shape, 0.9, 0.1  # fitness, generations, mutation prob, sigma",
            "-    for _ in tqdm(range(gen), desc='Evolving anchors with Genetic Algorithm:'):",
            "+    for _ in tqdm(range(gen), desc='Evolving anchors with Genetic Algorithm'):",
            "v = np.ones(sh)",
            "while (v == 1).all():  # mutate until a change occurs (prevent duplicates)",
            "v = ((npr.random(sh) < mp) * npr.random() * npr.randn(*sh) * s + 1).clip(0.3, 3.0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1906,
        "label": "no",
        "change": [
            "class SamplingResult(util_mixins.NiceRepr):",
            "",
            "@property",
            "def bboxes(self):",
            "+        \"\"\"torch.Tensor: concatenated positive and negative boxes\"\"\"",
            "return torch.cat([self.pos_bboxes, self.neg_bboxes])",
            "",
            "def to(self, device):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1911,
        "label": "no",
        "change": [
            "class Detections:",
            "self.names = names  # class names",
            "self.xyxy = pred  # xyxy pixels",
            "self.xywh = [xyxy2xywh(x) for x in pred]  # xywh pixels",
            "-        gn = [torch.Tensor([*[im.shape[i] for i in [1, 0, 1, 0]], 1., 1.]) for im in imgs]  # normalization gains",
            "+        d = pred[0].device  # device",
            "+        gn = [torch.tensor([*[im.shape[i] for i in [1, 0, 1, 0]], 1., 1.], device=d) for im in imgs]  # normalizations",
            "self.xyxyn = [x / g for x, g in zip(self.xyxy, gn)]  # xyxy normalized",
            "self.xywhn = [x / g for x, g in zip(self.xywh, gn)]  # xywh normalized",
            "self.n = len(self.pred)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1912,
        "label": "no",
        "change": [
            "class HourglassNet(nn.Module):",
            "Detector's __init__() will call backbone's init_weights() with",
            "pretrained as input, so we keep this function.",
            "\"\"\"",
            "-        pass",
            "+        # Training Centripetal Model needs to reset parameters for Conv2d",
            "+        for m in self.modules():",
            "+            if isinstance(m, nn.Conv2d):",
            "+                m.reset_parameters()",
            "",
            "def forward(self, x):",
            "\"\"\"Forward function.\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1915,
        "label": "yes",
        "change": [
            "class PipelineModule(nn.Module):",
            "self.tied_weight_attrs = {}",
            "",
            "# Offset the random seed by the stage ID.",
            "-        #newseed = torch.cuda.initial_seed() + self._grid.get_stage_id()",
            "+        #newseed = get_accelerator().initial_seed() + self._grid.get_stage_id()",
            "#ds_utils.set_random_seed(newseed)",
            "",
            "-        #with torch.random.fork_rng(devices=[torch.cuda.current_device()]):",
            "+        #with torch.random.fork_rng(devices=[get_accelerator().current_device_name()]):",
            "self._build()",
            "-        self.to(f'cuda:{self.local_rank}')",
            "+        self.to(get_accelerator().device_name(self.local_rank))",
            "",
            "self.tied_comms = self._index_tied_modules()",
            "self._synchronize_tied_weights()"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1916,
        "label": "no",
        "change": [
            "texinfo_documents = [",
            "# Example configuration for intersphinx: refer to the Python standard library.",
            "intersphinx_mapping = {",
            "'python': ('https://docs.python.org/3/', None),",
            "-    'numpy': ('http://docs.scipy.org/doc/numpy/', None),",
            "-    'torch': ('http://pytorch.org/docs/master/', None),",
            "+    'numpy': ('http://numpy.org/doc/stable/', None),",
            "+    'torch': ('http://pytorch.org/docs/stable/', None),",
            "}",
            "",
            "examples_dir = os.path.join(current_path, \"tutorials\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1917,
        "label": "no",
        "change": [
            "for epoch in range(1, 301):",
            "class Classifier(nn.Module):",
            "def __init__(self, hidden_dim):",
            "super(Classifier, self).__init__()",
            "-        self.lin = nn.Linear(hidden_dim, data.num_classes)",
            "+        self.lin = nn.Linear(hidden_dim, dataset.num_classes)",
            "",
            "def reset_parameters(self):",
            "self.lin.reset_parameters()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1921,
        "label": "no",
        "change": [
            "class Tensor:",
            "",
            "def __repr__(self):",
            "return (",
            "-            \"ivy.functional.frontends.torch.Tensor(\"",
            "-            + str(ivy.to_list(self.data))",
            "-            + \")\"",
            "+            \"ivy.functional.frontends.torch.Tensor(\" + str(ivy.to_list(self.data)) + \")\"",
            ")",
            "",
            "# Instance Methoods #"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1923,
        "label": "no",
        "change": [
            "class TFMelGANDiscriminator(tf.keras.layers.Layer):",
            "return outs",
            "",
            "def _apply_weightnorm(self, list_layers):",
            "-        \"\"\"Try apply weightnorm for all layer in list_layers\"\"\"",
            "+        \"\"\"Try apply weightnorm for all layer in list_layers.\"\"\"",
            "for i in range(len(list_layers)):",
            "try:",
            "layer_name = list_layers[i].name.lower()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1925,
        "label": "no",
        "change": [
            "def train(args):",
            "set_early_stop(trainer, args)",
            "",
            "if args.tensorboard_dir is not None and args.tensorboard_dir != \"\":",
            "+        from torch.utils.tensorboard import SummaryWriter",
            "+",
            "trainer.extend(",
            "TensorboardLogger(",
            "SummaryWriter(args.tensorboard_dir),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1926,
        "label": "no",
        "change": [
            "-import pytest",
            "-import torch",
            "-",
            "-",
            "-@pytest.fixture",
            "-def data_loftr():",
            "-    url = 'https://github.com/kornia/data_test/blob/main/loftr_outdoor_and_homography_data.pt?raw=true'",
            "-    return torch.hub.load_state_dict_from_url(url)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1927,
        "label": "no",
        "change": [
            "def test_torch_layer():",
            "",
            "# tracing (freezing)",
            "model3 = torch.jit.trace(model2, example_inputs=input)",
            "-        torch.testing.assert_allclose(model1(input), model3(input), atol=1e-3, rtol=1e-3)",
            "-        torch.testing.assert_allclose(model1(input + 1), model3(input + 1), atol=1e-3, rtol=1e-3)",
            "+        torch.testing.assert_close(model1(input), model3(input), atol=1e-3, rtol=1e-3)",
            "+        torch.testing.assert_close(model1(input + 1), model3(input + 1), atol=1e-3, rtol=1e-3)",
            "",
            "model4 = torch.jit.trace(model2, example_inputs=input)",
            "-        torch.testing.assert_allclose(model1(input), model4(input), atol=1e-3, rtol=1e-3)",
            "-        torch.testing.assert_allclose(model1(input + 1), model4(input + 1), atol=1e-3, rtol=1e-3)",
            "+        torch.testing.assert_close(model1(input), model4(input), atol=1e-3, rtol=1e-3)",
            "+        torch.testing.assert_close(model1(input + 1), model4(input + 1), atol=1e-3, rtol=1e-3)",
            "",
            "",
            "def test_torch_layers_scripting():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1928,
        "label": "no",
        "change": [
            "class BooleanAccuracy(Metric):",
            "# so we'll keep predictions that aren't.",
            "keep = mask.view(batch_size, -1).max(dim=1)[0].float()",
            "else:",
            "-            keep = torch.ones(batch_size).float()",
            "+            keep = torch.ones(batch_size, device=predictions.device).float()",
            "",
            "predictions = predictions.view(batch_size, -1)",
            "gold_labels = gold_labels.view(batch_size, -1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1930,
        "label": "no",
        "change": [
            "class MPITests(tf.test.TestCase):",
            "\"\"\"Test on GPU using NCCL that the Adasum correctly computes 2D tensors.\"\"\"",
            "hvd.init()",
            "# TODO support non-MPI Adasum operation",
            "-        if not hvd.mpi_enabled() or not tf.test.is_gpu_available() or not hvd.nccl_built():",
            "+        if not hvd.mpi_enabled() or not hvd.gpu_available('tensorflow') or not hvd.nccl_built():",
            "return",
            "rank = hvd.rank()",
            "rank_tensors = []"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1931,
        "label": "no",
        "change": [
            "def seed(seed_value: int = 0) -> None:",
            "",
            "def shuffle(x):",
            "batch_size = x.shape[0]",
            "-    return x[torch.randperm(batch_size)]",
            "+    return torch.index_select(x, 0, torch.randperm(batch_size))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1932,
        "label": "yes",
        "change": [
            "class HFGPTJLayerPolicy(DSPolicy):",
            "kw = self.client_module.attn.k_proj.weight",
            "vw = self.client_module.attn.v_proj.weight",
            "",
            "-        qkvw = torch.cat((qw, kw, vw), dim=0)",
            "+        qkvw = Parameter(torch.cat((qw, kw, vw), dim=0))",
            "",
            "return self.linear_layer, \\",
            "qkvw, \\"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 1934,
        "label": "no",
        "change": [
            "class ElmoTokenEmbedder(TokenEmbedder):",
            "The ELMo representations for the input sequence, shape",
            "`(batch_size, timesteps, embedding_dim)`",
            "\"\"\"",
            "-        elmo_output = self._elmo(tokens, word_inputs)",
            "+        elmo_output = self._elmo(elmo_tokens, word_inputs)",
            "elmo_representations = elmo_output[\"elmo_representations\"][0]",
            "if self._projection:",
            "projection = self._projection"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1936,
        "label": "no",
        "change": [
            "class MultiprocessingTrainer(MultiprocessingEventLoop):",
            "'betas': eval(self.args.adam_betas),",
            "'weight_decay': self.args.weight_decay,",
            "}",
            "-            return torch.optim.Adam(self.model.parameters(), **self._override_optim_state)",
            "+            return Adam(self.model.parameters(), **self._override_optim_state)",
            "elif self.args.optimizer == 'nag':",
            "self._override_optim_state = {",
            "'lr': self.args.lr[0],"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1938,
        "label": "no",
        "change": [
            "\"source\": [",
            "\"xs = torch.linspace(X[:, 0].min() - 0.5, X[:, 0].max() + 0.5, steps=100)\\n\",",
            "\"ys = torch.linspace(X[:, 1].min() - 0.5, X[:, 1].max() + 0.5, steps=100)\\n\",",
            "-    \"try:\\n\",",
            "-    \"    # torch 1.10 or greater defaults to using indexing\\n\",",
            "-    \"    xx, yy = torch.meshgrid(xs, ys, indexing=\\\"xy\\\")\\n\",",
            "-    \"except:\\n\",",
            "-    \"    xx, yy = torch.meshgrid(xs, ys)\\n\",",
            "-    \"    xx = xx.t()\\n\",",
            "-    \"    yy = yy.t()\\n\",",
            "-    \"\\n\",",
            "+    \"xx, yy = torch.meshgrid(xs, ys, indexing=\\\"xy\\\")\\n\",",
            "\"\\n\",",
            "\"with torch.no_grad():\\n\",",
            "\"    mean, var = model(torch.vstack((xx.ravel(), yy.ravel())).t())\\n\","
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1941,
        "label": "no",
        "change": [
            "def rnn(step_function, inputs, initial_states,",
            "states = return_states",
            "successive_outputs.append(output)",
            "successive_states.append(states)",
            "-                last_output = successive_outputs[-1]",
            "-                new_states = successive_states[-1]",
            "-                outputs = tf.stack(successive_outputs)",
            "+            last_output = successive_outputs[-1]",
            "+            new_states = successive_states[-1]",
            "+            outputs = tf.stack(successive_outputs)",
            "else:",
            "for inp in input_list:",
            "output, states = step_function(inp, states + constants)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1943,
        "label": "no",
        "change": [
            "class ExtractTensorPatches(nn.Module):",
            "kernel[i, i] += 1.0",
            "return kernel.view(window_range, 1, window_size[0], window_size[1])",
            "",
            "-    def forward(self, input: torch.Tensor) -> torch.Tensor:",
            "+    def forward(self, input: torch.Tensor) -> torch.Tensor:  # type: ignore",
            "if not torch.is_tensor(input):",
            "raise TypeError(\"Input input type is not a torch.Tensor. Got {}\"",
            ".format(type(input)))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1947,
        "label": "no",
        "change": [
            "class LengthBonus(ScorerInterface):",
            "torch.float32 scores for y (B)",
            "and next state for ys",
            "\"\"\"",
            "-        return torch.tensor([1.0]).expand(self.n), None",
            "+        return torch.tensor([1.0], device=y.device).expand(self.n), None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1949,
        "label": "no",
        "change": [
            "def fpn_model(features):",
            "if idx == 0:",
            "lat_sum_5432.append(lat)",
            "else:",
            "-                lat = lat + upsample2x('upsample_c{}'.format(5 - idx), lat_sum_5432[-1])",
            "+                lat = lat + upsample2x('upsample_lat{}'.format(6 - idx), lat_sum_5432[-1])",
            "lat_sum_5432.append(lat)",
            "p2345 = [Conv2D('posthoc_3x3_p{}'.format(i + 2), c, num_channel, 3)",
            "for i, c in enumerate(lat_sum_5432[::-1])]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1951,
        "label": "no",
        "change": [
            "class MS_SSIMLoss(nn.Module):",
            "return g.reshape(-1)",
            "",
            "def _fspecial_gauss_2d(",
            "-        self, size: int, sigma: float, device: Optional[torch.device] = None, dtype: Optional[torch.dtype] = None",
            "+        self, size: int, sigma: float, device: torch.device | None = None, dtype: torch.dtype | None = None",
            ") -> torch.Tensor:",
            "\"\"\"Create 2-D gauss kernel."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1956,
        "label": "no",
        "change": [
            "def create_model(to_device=True, dim_in=None, dim_out=None) -> GraphGymModule:",
            "",
            "model = GraphGymModule(dim_in, dim_out, cfg)",
            "if to_device:",
            "-        model.to(torch.device(cfg.device))",
            "+        model.to(torch.device(cfg.accelerator))",
            "return model"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1958,
        "label": "no",
        "change": [
            "class Speech2TextStreaming:",
            "has_enough_samples = False if speech.size(0) <= self.win_length else True",
            "if not has_enough_samples:",
            "if is_final:",
            "-                pad = torch.zeros(self.win_length - speech.size(0))",
            "+                pad = torch.zeros(self.win_length - speech.size(0), dtype=getattr(torch, self.dtype))",
            "speech = torch.cat([speech, pad], dim=0)",
            "else:",
            "feats = None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1960,
        "label": "no",
        "change": [
            "def cholesky(",
            "else:",
            "ret = torch.transpose(",
            "torch.linalg.cholesky(",
            "-                torch.transpose(x, dim0=len(x.shape) - 1, dim1=len(x.shape) - 2),",
            "-                out=out,",
            "+                torch.transpose(x, dim0=len(x.shape) - 1, dim1=len(x.shape) - 2)",
            "),",
            "dim0=len(x.shape) - 1,",
            "dim1=len(x.shape) - 2,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1961,
        "label": "yes",
        "change": [
            "def sample_autoregressive(partial_sequences,",
            "",
            "ids_this_step = mtf.sample_with_temperature(",
            "logits, other_features[\"vocab_dim\"], temperature)",
            "+        ids_this_step = mtf.shift(ids_this_step, offset=1, dim=length_dim, wrap=False)",
            "one_new_id = ids_this_step * mtf.one_hot(position, length_dim, dtype=tf.int32)",
            "-        one_new_id = mtf.shift(one_new_id, offset=1, dim=length_dim, wrap=False)",
            "new_ids = ids + one_new_id",
            "new_position = position + 1",
            "return [new_position, new_ids]"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "removal",
        "Element": "api call"
    },
    {
        "number": 1965,
        "label": "no",
        "change": [
            "def create_module(",
            "name = type(module).__name__",
            "if getattr(module_config, \"load_path\", None):",
            "print(f\"Loading state of module {name} from {module_config.load_path} ...\")",
            "-        module.load_state_dict(torch.load(module_config.load_path))",
            "+        module.load_state_dict(torch.load(module_config.load_path, map_location=\"cpu\"))",
            "if getattr(module_config, \"freeze\", False):",
            "print(f\"Freezing the parameters of module {name} ...\")",
            "module.freeze()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1967,
        "label": "yes",
        "change": [
            "class Graph:",
            "if pre_node[temp_id] == temp_id:",
            "break",
            "temp_id = pre_node[temp_id]",
            "-        assert temp_id == pre_node[temp_id]",
            "+        if temp_id != pre_node[temp_id]:",
            "+            raise AssertionError(\"Error: main chain end condition not met.\")",
            "ret.reverse()",
            "return ret"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 1969,
        "label": "no",
        "change": [
            "class AutoencoderKLIntegrationTests(unittest.TestCase):",
            "",
            "def get_generator(self, seed=0):",
            "if torch_device == \"mps\":",
            "-            return torch.Generator().manual_seed(seed)",
            "+            return torch.manual_seed(seed)",
            "return torch.Generator(device=torch_device).manual_seed(seed)",
            "",
            "@parameterized.expand("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1970,
        "label": "no",
        "change": [
            "class AutoTuner(kerastuner.engine.multi_execution_tuner.MultiExecutionTuner):",
            "self.oracle.update_trial(",
            "trial.trial_id, metrics=averaged_metrics, step=self._reported_step)",
            "",
            "+        tf.keras.backend.clear_session()",
            "+",
            "def search(self,",
            "callbacks=None,",
            "fit_on_val_data=False,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1972,
        "label": "no",
        "change": [
            "class BeitModelIntegrationTest(unittest.TestCase):",
            "inputs = feature_extractor(images=image, return_tensors=\"pt\").to(torch_device)",
            "",
            "# forward pass",
            "-        outputs = model(**inputs)",
            "+        with torch.no_grad():",
            "+            outputs = model(**inputs)",
            "logits = outputs.logits",
            "",
            "# verify the logits"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1974,
        "label": "no",
        "change": [
            "class SelectiveKernelConv(nn.Module):",
            "groups = min(out_channels, groups)",
            "",
            "conv_kwargs = dict(",
            "-            stride=stride, groups=groups, drop_block=drop_block, act_layer=act_layer, norm_layer=norm_layer)",
            "+            stride=stride, groups=groups, drop_block=drop_block, act_layer=act_layer, norm_layer=norm_layer,",
            "+            aa_layer=aa_layer)",
            "self.paths = nn.ModuleList([",
            "ConvBnAct(in_channels, out_channels, kernel_size=k, dilation=d, **conv_kwargs)",
            "for k, d in zip(kernel_size, dilation)])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1975,
        "label": "no",
        "change": [
            "def train_ch11(trainer_fn, states, hyperparams, data_iter,",
            "def train_concise_ch11(trainer_fn, hyperparams, data_iter, num_epochs=2):",
            "# Initialization",
            "net = tf.keras.Sequential()",
            "-    net.add(tf.keras.layers.Dense(1,",
            "+    net.add(tf.keras.layers.Dense(1,",
            "kernel_initializer=tf.random_normal_initializer(stddev=0.01)))",
            "optimizer = trainer_fn(**hyperparams)",
            "loss = tf.keras.losses.MeanSquaredError()",
            "-    # Note: L2 Loss = 1/2 * MSE Loss. TensorFlow has MSE Loss which is",
            "+    # Note: L2 Loss = 1/2 * MSE Loss. TensorFlow has MSE Loss which is",
            "# slightly different from MXNet's L2Loss by a factor of 2. Hence we halve",
            "# the loss value to get L2Loss in TensorFlow",
            "animator = d2l.Animator(xlabel='epoch', ylabel='loss',"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1977,
        "label": "no",
        "change": [
            "class ESPnetEnhancementModel(AbsESPnetModel):",
            "losses = torch.stack([pair_loss(p) for p in all_permutations], dim=1)",
            "loss, perm = torch.min(losses, dim=1)",
            "perm = torch.index_select(",
            "-                torch.tensor(all_permutations, device=device, dtype=torch.long),",
            "-                0,",
            "-                perm,",
            "+                torch.tensor(all_permutations, device=device, dtype=torch.long), 0, perm",
            ")",
            "else:",
            "loss = torch.tensor("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1978,
        "label": "no",
        "change": [
            "def regularize_cost_from_collection(name='regularize_cost'):",
            "losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)",
            "if len(losses) > 0:",
            "logger.info(\"Add REGULARIZATION_LOSSES of {} tensors on the total cost.\".format(len(losses)))",
            "-        reg_loss = tf.add_n(losses)",
            "+        reg_loss = tf.add_n(losses, name=name)",
            "return reg_loss",
            "else:",
            "return None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1979,
        "label": "no",
        "change": [
            "class TFSequenceSummary(tf.keras.layers.Layer):",
            "if training and self.first_dropout is not None:",
            "output = self.first_dropout(output)",
            "",
            "-        output = self.summary(output)",
            "+        if self.summary is not None:",
            "+            output = self.summary(output)",
            "",
            "if self.activation is not None:",
            "output = self.activation(output)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1983,
        "label": "no",
        "change": [
            "class GatedSum(torch.nn.Module):",
            "",
            "input_dim : `int`, required",
            "The dimensionality of the input. We assume the input have shape `(..., input_dim)`.",
            "-    activation : `Activation`, optional (default = torch.nn.Sigmoid())",
            "+    activation : `Activation`, optional (default = `torch.nn.Sigmoid()`)",
            "The activation function to use.",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1986,
        "label": "no",
        "change": [
            "class BeitModelTest(ModelTesterMixin, unittest.TestCase):",
            "# this can then be incorporated into _prepare_for_class in test_modeling_common.py",
            "elif model_class.__name__ == \"BeitForSemanticSegmentation\":",
            "batch_size, num_channels, height, width = inputs_dict[\"pixel_values\"].shape",
            "-                inputs_dict[\"labels\"] = torch.zeros([self.model_tester.batch_size, height, width]).long()",
            "+                inputs_dict[\"labels\"] = torch.zeros(",
            "+                    [self.model_tester.batch_size, height, width], device=torch_device",
            "+                ).long()",
            "model = model_class(config)",
            "model.to(torch_device)",
            "model.train()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1987,
        "label": "no",
        "change": [
            "class Config(object):",
            "return defaults",
            "",
            "def __str__(self):",
            "-        s = \"wandb_version: 1\\n\\n\"",
            "-        s += yaml.dump(self.as_dict(), default_flow_style=False)",
            "+        s = \"wandb_version: 1\"",
            "+        as_dict = self.as_dict()",
            "+        if as_dict:  # adding an empty dictionary here causes a parse error",
            "+            s += '\\n\\n' + yaml.dump(as_dict, default_flow_style=False)",
            "return s"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1988,
        "label": "yes",
        "change": [
            "class TransformerEncoderLayerBase(nn.Module):",
            "# the attention weight (before softmax) for some padded element in query",
            "# will become -inf, which results in NaN in model parameters",
            "if attn_mask is not None:",
            "-            attn_mask = attn_mask.masked_fill(attn_mask.to(torch.bool), -1e8)",
            "+            attn_mask = attn_mask.masked_fill(",
            "+                attn_mask.to(torch.bool),",
            "+                -1e8 if x.dtype == torch.float32 else -1e4",
            "+            )",
            "",
            "residual = x",
            "if self.normalize_before:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 1989,
        "label": "yes",
        "change": [
            "class QModel(Model):",
            "",
            "# If loss clipping is used, calculate the huber loss",
            "if config.clip_loss > 0.0:",
            "-                huber_loss = tf.where(condition=(tf.abs(delta) < config.clip_loss), x=(0.5 * self.loss_per_instance), y=(tf.abs(delta) - 0.5))",
            "+                huber_loss = tf.where(condition=(tf.abs(delta) < config.clip_loss), x=(0.5 * self.loss_per_instance),",
            "+                                      y=config.clip_loss * tf.abs(delta) - 0.5 * config.clip_loss ** 2)",
            "self.q_loss = tf.reduce_mean(input_tensor=huber_loss, axis=0)",
            "else:",
            "self.q_loss = tf.reduce_mean(input_tensor=self.loss_per_instance, axis=0)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 1991,
        "label": "no",
        "change": [
            "class TestTorchVariable(TestCase):",
            "",
            "datasets = [(data_bob, target_bob), (data_alice, target_alice)]",
            "",
            "-        for iter in range(6):",
            "+        for iter in range(2):",
            "",
            "for data, target in datasets:",
            "model.send(data.owners[0])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1992,
        "label": "no",
        "change": [
            "def prod(",
            "if dtype is None:",
            "dtype = _infer_dtype(x.dtype)",
            "axis = tuple(axis) if isinstance(axis, list) else axis",
            "-    return tf.experimental.numpy.prod(x, axis, dtype, keepdims)",
            "+    return tf.experimental.numpy.prod(x, axis=axis, dtype=dtype, keepdims=keepdims)",
            "",
            "",
            "def std("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1997,
        "label": "no",
        "change": [
            "class BlazeFace(nn.Module):",
            "for i in range(raw_box_tensor.shape[0]):",
            "boxes = detection_boxes[i, mask[i]]",
            "scores = detection_scores[i, mask[i]].unsqueeze(dim=-1)",
            "-            output_detections.append(torch.cat((boxes, scores), dim=-1))",
            "+            output_detections.append(torch.cat((boxes, scores), dim=-1).to('cpu'))",
            "",
            "return output_detections"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1998,
        "label": "no",
        "change": [
            "def test_activation_resolver():",
            "@pytest.mark.parametrize('aggr_tuple', [",
            "(torch_geometric.nn.aggr.MeanAggregation, 'mean'),",
            "(torch_geometric.nn.aggr.SumAggregation, 'sum'),",
            "+    (torch_geometric.nn.aggr.SumAggregation, 'add'),",
            "(torch_geometric.nn.aggr.MaxAggregation, 'max'),",
            "(torch_geometric.nn.aggr.MinAggregation, 'min'),",
            "(torch_geometric.nn.aggr.MulAggregation, 'mul'),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1999,
        "label": "no",
        "change": [
            "class Perplexity(Average):",
            "\"\"\"",
            "average_loss = super().get_metric(reset)",
            "if average_loss == 0:",
            "-            return 0.0",
            "+            perplexity = 0.0",
            "",
            "# Exponentiate the loss to compute perplexity",
            "-        return float(torch.exp(average_loss))",
            "+        perplexity = float(torch.exp(average_loss))",
            "+",
            "+        return perplexity"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2000,
        "label": "no",
        "change": [
            "class Trainer:",
            "\" > Model restored from step %d\" % checkpoint[\"step\"],",
            ")",
            "restore_step = checkpoint[\"step\"]",
            "+        torch.cuda.empty_cache()",
            "return model, optimizer, scaler, restore_step",
            "",
            "def _get_loader("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2003,
        "label": "yes",
        "change": [
            "class DecoderTrainer(nn.Module):",
            "index = unet_number - 1",
            "unet = self.decoder.unets[index]",
            "",
            "-        if exists(self.max_grad_norm):",
            "-            nn.utils.clip_grad_norm_(unet.parameters(), self.max_grad_norm)",
            "-",
            "optimizer = getattr(self, f'optim{index}')",
            "scaler = getattr(self, f'scaler{index}')",
            "",
            "+        if exists(self.max_grad_norm):",
            "+            scaler.unscale_(optimizer)",
            "+            nn.utils.clip_grad_norm_(unet.parameters(), self.max_grad_norm)",
            "+",
            "scaler.step(optimizer)",
            "scaler.update()",
            "optimizer.zero_grad()"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 2005,
        "label": "yes",
        "change": [
            "def get_tiny_config_from_class(configuration_class):",
            "",
            "try:",
            "model_slug = model_type.replace(\"-\", \"_\")",
            "-        module = importlib.import_module(f\".test_modeling_{model_slug}\", package=f\"tests.{model_slug}\")",
            "+        module = importlib.import_module(f\".test_modeling_{model_slug}\", package=f\"tests.models.{model_slug}\")",
            "model_tester_class = getattr(module, f\"{camel_case_model_name}ModelTester\", None)",
            "except (ImportError, AttributeError):",
            "logger.error(f\"No model tester class for {configuration_class.__name__}\")"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 2007,
        "label": "no",
        "change": [
            "class MultiHeadSelfAttention(nn.Module):",
            "mask = (mask == 0).view(mask_reshp).expand_as(scores)  # (bs, n_heads, q_length, k_length)",
            "scores = scores.masked_fill(mask, -float(\"inf\"))  # (bs, n_heads, q_length, k_length)",
            "",
            "-        weights = nn.Softmax(dim=-1)(scores)  # (bs, n_heads, q_length, k_length)",
            "+        weights = nn.functional.softmax(scores, dim=-1)  # (bs, n_heads, q_length, k_length)",
            "weights = self.dropout(weights)  # (bs, n_heads, q_length, k_length)",
            "",
            "# Mask heads if we want to"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2008,
        "label": "no",
        "change": [
            "class Reporter:",
            "if LooseVersion(torch.__version__) >= LooseVersion(\"1.4.0\"):",
            "if torch.cuda.is_initialized():",
            "stats[\"gpu_max_cached_mem_GB\"] = (",
            "-                    torch.cuda.max_memory_reserved() / 2 ** 30",
            "+                    torch.cuda.max_memory_reserved() / 2**30",
            ")",
            "else:",
            "if torch.cuda.is_available() and torch.cuda.max_memory_cached() > 0:",
            "-                stats[\"gpu_cached_mem_GB\"] = torch.cuda.max_memory_cached() / 2 ** 30",
            "+                stats[\"gpu_cached_mem_GB\"] = torch.cuda.max_memory_cached() / 2**30",
            "",
            "self.stats.setdefault(self.epoch, {})[sub_reporter.key] = stats",
            "sub_reporter.finished()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2009,
        "label": "no",
        "change": [
            "from ray.rllib.utils import try_import_torch",
            "_, nn = try_import_torch()",
            "",
            "",
            "-class VisionNetwork(TorchModelV2):",
            "+class VisionNetwork(TorchModelV2, nn.Module):",
            "\"\"\"Generic vision network.\"\"\"",
            "",
            "def __init__(self, obs_space, action_space, num_outputs, model_config,",
            "name):",
            "TorchModelV2.__init__(self, obs_space, action_space, num_outputs,",
            "model_config, name)",
            "+        nn.Module.__init__(self)",
            "",
            "activation = get_activation_fn(",
            "model_config.get(\"conv_activation\"), framework=\"torch\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2010,
        "label": "no",
        "change": [
            "def FullyConnected(x, out_dim,",
            "prod = tf.nn.xw_plus_b(x, W, b) if use_bias else tf.matmul(x, W)",
            "if nl is None:",
            "logger.warn(",
            "-            \"[DEPRECATED] Default ReLU nonlinearity for Conv2D and FullyConnected will be deprecated. Please use argscope instead.\")",
            "+            \"[DEPRECATED] Default ReLU nonlinearity for Conv2D and FullyConnected will be deprecated.\"",
            "+            \" Please use argscope instead.\")",
            "nl = tf.nn.relu",
            "return nl(prod, name='output')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2012,
        "label": "no",
        "change": [
            "class ModelTesterMixin:",
            "model_slow_init = base_class_copy.from_pretrained(tmpdirname, _fast_init=False)",
            "",
            "for key in model_fast_init.state_dict().keys():",
            "-                    max_diff = (model_slow_init.state_dict()[key] - model_fast_init.state_dict()[key]).sum().item()",
            "+                    max_diff = torch.max(",
            "+                        torch.abs(model_slow_init.state_dict()[key] - model_fast_init.state_dict()[key])",
            "+                    ).item()",
            "self.assertLessEqual(max_diff, 1e-3, msg=f\"{key} not identical\")",
            "",
            "def test_initialization(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2013,
        "label": "no",
        "change": [
            "class WikiTablesSemanticParser(Model):",
            "entity_type_embeddings = self._type_params(entity_types.float())",
            "projected_neighbor_embeddings = self._neighbor_params(embedded_neighbors.float())",
            "# (batch_size, num_entities, embedding_dim)",
            "-        entity_embeddings = torch.nn.functional.tanh(entity_type_embeddings + projected_neighbor_embeddings)",
            "+        entity_embeddings = torch.tanh(entity_type_embeddings + projected_neighbor_embeddings)",
            "",
            "",
            "# Compute entity and question word similarity.  We tried using cosine distance here, but"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2014,
        "label": "no",
        "change": [
            "_count = 0",
            "",
            "def run_timeline(sess, ops, debug_name, feed_dict={}, timeline_dir=None):",
            "if timeline_dir:",
            "+        from tensorflow.python.client import timeline",
            "+",
            "run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)",
            "run_metadata = tf.RunMetadata()",
            "start = time.time()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2015,
        "label": "no",
        "change": [
            "def clip_faces(",
            "# (F) dim tensor containing the number of clipped vertices in each triangle",
            "faces_num_clipped_verts = faces_clipped_verts.sum(1)",
            "else:",
            "-        faces_num_clipped_verts = torch.zeros([F, 3], device=device)",
            "+        faces_num_clipped_verts = torch.zeros([F], device=device)",
            "",
            "# If no triangles need to be clipped or culled, avoid unnecessary computation",
            "# and return early"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2019,
        "label": "no",
        "change": [
            "from . import backend_version",
            "",
            "",
            "@with_unsupported_dtypes({\"1.11.0 and below\": (\"float16\",)}, backend_version)",
            "-def relu(",
            "-    x: torch.Tensor,",
            "-    /,",
            "-    *,",
            "-    out: Optional[torch.Tensor] = None",
            "-) -> torch.Tensor:",
            "+def relu(x: torch.Tensor, /, *, out: Optional[torch.Tensor] = None) -> torch.Tensor:",
            "return torch.relu(x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2023,
        "label": "no",
        "change": [
            "class Transformer2DModel(ModelMixin, ConfigMixin):",
            "if self.is_input_continuous:",
            "# TODO: should use out_channels for continous projections",
            "if use_linear_projection:",
            "-                self.proj_out = nn.Linear(in_channels, inner_dim)",
            "+                self.proj_out = nn.Linear(inner_dim, in_channels)",
            "else:",
            "self.proj_out = nn.Conv2d(inner_dim, in_channels, kernel_size=1, stride=1, padding=0)",
            "elif self.is_input_vectorized:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2024,
        "label": "yes",
        "change": [
            "class BiLSTM_CRF(nn.Module):",
            "def _get_lstm_features(self, sentence):",
            "self.hidden = self.init_hidden()",
            "embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)",
            "-        lstm_out, self.hidden = self.lstm(embeds)",
            "+        lstm_out, self.hidden = self.lstm(embeds, self.hidden)",
            "lstm_out = lstm_out.view(len(sentence), self.hidden_dim)",
            "lstm_feats = self.hidden2tag(lstm_out)",
            "return lstm_feats"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 2028,
        "label": "no",
        "change": [
            "class UNetLDMModelTests(ModelTesterMixin, unittest.TestCase):",
            "expected_output_slice = torch.tensor([-13.3258, -20.1100, -15.9873, -17.6617, -23.0596, -17.9419, -13.3675, -16.1889, -12.3800])",
            "# fmt: on",
            "",
            "-        self.assertTrue(torch.allclose(output_slice, expected_output_slice, atol=1e-3))",
            "+        self.assertTrue(torch.allclose(output_slice, expected_output_slice, rtol=1e-3))",
            "",
            "",
            "#    TODO(Patrick) - Re-add this test after having cleaned up LDM"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2029,
        "label": "no",
        "change": [
            "class TrainerDataLoadingMixin(object):",
            "self.get_val_dataloaders()",
            "",
            "# support IterableDataset for train data",
            "-        self.is_iterable_train_dataloader = isinstance(self.get_train_dataloader().dataset, IterableDataset)",
            "+        self.is_iterable_train_dataloader = (",
            "+            EXIST_ITER_DATASET and isinstance(self.get_train_dataloader().dataset, IterableDataset))",
            "if self.is_iterable_train_dataloader and not isinstance(self.val_check_interval, int):",
            "m = '''",
            "When using an iterableDataset for train_dataloader,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2033,
        "label": "yes",
        "change": [
            "def configure_logger(verbose: bool) -> None:",
            "verbose (bool):",
            "`True` to use verbose logger, `False` otherwise.",
            "\"\"\"",
            "-    tf_logger = tf_logging.get_logger()",
            "+    tf_logger = tf.get_logger()",
            "tf_logger.handlers = [handler]",
            "if verbose:",
            "-        environ['TF_CPP_MIN_LOG_LEVEL'] = '1'",
            "tf_logging.set_verbosity(tf_logging.INFO)",
            "logger.setLevel(logging.DEBUG)",
            "else:",
            "warnings.filterwarnings('ignore')",
            "-        environ['TF_CPP_MIN_LOG_LEVEL'] = '3'",
            "tf_logging.set_verbosity(tf_logging.ERROR)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 2035,
        "label": "no",
        "change": [
            "class BertModel(object):",
            "if token_type_ids is None:",
            "token_type_ids = tf.zeros(shape=[batch_size, seq_length], dtype=tf.int32)",
            "",
            "-    with tf.variable_scope(\"bert\", scope):",
            "+    with tf.variable_scope(scope, \"bert\"):",
            "with tf.variable_scope(\"embeddings\"):",
            "# Perform embedding lookup on the word ids.",
            "(self.embedding_output, self.embedding_table) = embedding_lookup("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2036,
        "label": "yes",
        "change": [
            "def test(epoch):",
            "output = model(batch_data)",
            "test_loss += criterion(output, batch_targets)",
            "pred = output.data.max(1)[1]",
            "-        correct += pred.long().eq(batch_targets.data.long()).sum()",
            "+        correct += pred.long().eq(batch_targets.data.long()).cpu().sum()",
            "",
            "test_loss = test_loss.data[0]",
            "test_loss /= (test_data.size(0) / TEST_BATCH_SIZE) # criterion averages over batch size"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 2039,
        "label": "no",
        "change": [
            "def test_get_config_and_load(tmpdir):",
            "",
            "",
            "def test_get_config_kaggle(tmpdir):",
            "-    twitter_bots_config = ludwig.datasets.get_dataset_config(\"twitter_bots\")",
            "+    twitter_bots_config = ludwig.datasets._get_dataset_config(\"twitter_bots\")",
            "assert isinstance(twitter_bots_config, DatasetConfig)",
            "",
            "twitter_bots_dataset = ludwig.datasets.get_dataset(\"twitter_bots\", cache_dir=tmpdir)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2041,
        "label": "no",
        "change": [
            "class TFModelTesterMixin:",
            "",
            "for model_class in self.all_model_classes:",
            "model = model_class(config)",
            "-            assert isinstance(model.get_input_embeddings(), tf.keras.layers.Layer)",
            "+            assert isinstance(model.get_input_embeddings(), (tf.keras.layers.Layer, TFAdaptiveEmbedding))",
            "x = model.get_output_embeddings()",
            "assert x is None or isinstance(x, tf.keras.layers.Layer)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2042,
        "label": "no",
        "change": [
            "for n_iter in range(100):",
            "if n_iter % 10 == 0:",
            "x = vutils.make_grid(x, normalize=True, scale_each=True)",
            "writer.add_image('Image', x, n_iter)  # Tensor",
            "-        writer.add_image_with_boxes('imagebox', x, torch.Tensor([[10, 10, 40, 40]]), n_iter)",
            "+        writer.add_image_with_boxes('imagebox', x, torch.Tensor([[10, 10, 40, 40], [40, 40, 60, 60]]), n_iter)",
            "x = torch.zeros(sample_rate * 2)",
            "for i in range(x.size(0)):",
            "# sound amplitude should in [-1, 1]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2043,
        "label": "no",
        "change": [
            "class AbsTask(ABC):",
            "f\":{distributed_option.dist_rank}/{distributed_option.dist_world_size}]\"",
            "f\" %(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s\",",
            ")",
            "+        # Invoking torch.distributed.init_process_group",
            "+        distributed_option.init_torch_distributed()",
            "",
            "# 1. Set random-seed",
            "set_all_random_seed(args.seed)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2044,
        "label": "no",
        "change": [
            "def random_crop_generator(",
            "size = torch.tensor(size).repeat(batch_size, 1)",
            "assert size.shape == torch.Size([batch_size, 2]), \\",
            "f\"If `size` is a tensor, it must be shaped as (B, 2). Got {size.shape}.\"",
            "+    size = size.long()",
            "",
            "x_diff = input_size[1] - size[:, 1] + 1",
            "y_diff = input_size[0] - size[:, 0] + 1"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2048,
        "label": "no",
        "change": [
            "def build_or_reuse_placeholder(tensor_spec):",
            "assert \"Placeholder\" in tensor.op.type, \"Tensor {} exists but is not a placeholder!\".format(name)",
            "assert tensor_spec.is_compatible_with(tensor), \\",
            "\"Tensor {} exists but is not compatible with the signature!\".format(tensor)",
            "-        if tensor.shape == tensor_spec.shape:",
            "+        if tensor.shape.as_list() == tensor_spec.shape.as_list():",
            "# It might be desirable to use a placeholder of a different shape in some tower",
            "# (e.g., a less specific shape)",
            "+",
            "+            # Comparing `tensor.shape` directly doesn't work, because",
            "+            # tensorflow thinks `tf.Dimension(None)` and `tf.Dimension(None)` are not equal.",
            "return tensor",
            "except KeyError:",
            "pass"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2049,
        "label": "yes",
        "change": [
            "class InstanceNormalization(Layer):",
            "",
            "reciprocal_stddev = tf.math.rsqrt(x=tf.maximum(x=variance, y=epsilon))",
            "",
            "-        x = (x - mean) * reciprocal_stddev",
            "+        x = (x - tf.stop_gradient(input=mean)) * tf.stop_gradient(input=reciprocal_stddev)",
            "",
            "return x"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 2051,
        "label": "no",
        "change": [
            "class Replay(Queue):",
            "sequence_indices = tf.boolean_mask(",
            "tensor=sequence_indices, mask=tf.logical_not(x=terminal)",
            ")",
            "-        return self.retrieve_indices(indices=sequence_indices)",
            "",
            "# Retrieve sequence indices",
            "sequences = self.retrieve_indices(indices=sequence_indices)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2054,
        "label": "no",
        "change": [
            "class RepaintPipelineIntegrationTests(unittest.TestCase):",
            "scheduler = RePaintScheduler.from_pretrained(model_id)",
            "",
            "repaint = RePaintPipeline(unet=unet, scheduler=scheduler).to(torch_device)",
            "+        repaint.set_progress_bar_config(disable=None)",
            "+        repaint.enable_attention_slicing()",
            "",
            "generator = torch.Generator(device=torch_device).manual_seed(0)",
            "output = repaint("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2058,
        "label": "no",
        "change": [
            "def train_step(x_batch, y_batch):",
            "",
            "# begin training",
            "for idx, data in enumerate(gen):",
            "-    x_batch = tf.convert_to_tensor(data[0])",
            "-    y_batch = tf.convert_to_tensor(data[1])",
            "-",
            "start_time = time.time()",
            "",
            "+    x_batch = tf.convert_to_tensor(data[0])",
            "+    y_batch = tf.convert_to_tensor(data[1])",
            "train_step(x_batch, y_batch)",
            "",
            "end_time = time.time()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2060,
        "label": "no",
        "change": [
            "class ComputeLoss:",
            "lcls *= self.hyp['cls']",
            "bs = tobj.shape[0]  # batch size",
            "",
            "-        loss = lbox + lobj + lcls",
            "-        return loss * bs, torch.cat((lbox, lobj, lcls, loss)).detach()",
            "+        return (lbox + lobj + lcls) * bs, torch.cat((lbox, lobj, lcls)).detach()",
            "",
            "def build_targets(self, p, targets):",
            "# Build targets for compute_loss(), input targets(image,class,x,y,w,h)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2064,
        "label": "no",
        "change": [
            "def conv1d(x, scope, nf, *, w_init_stdev=0.02, params=None, scale=False):",
            "b = mtf.get_variable(x.mesh, 'b', [nf], initializer=tf.constant_initializer(0, dtype=tf.bfloat16), dtype=dt)",
            "# NWC",
            "b = mtf.reshape(b, [singletona, singletonb, nf])",
            "+        b = mtf.broadcast(b, c.shape)",
            "",
            "c += b",
            "return c"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2065,
        "label": "no",
        "change": [
            "class TestSpatialSoftArgmax2d:",
            "std = torch.tensor([1.0, 1.0], device=device, dtype=dtype)",
            "",
            "hm = kornia.geometry.dsnt.spatial_softmax2d(input)",
            "-        assert_allclose(hm.sum(-1).sum(-1), torch.tensor(1.0, device=device, dtype=dtype), atol=1e-4, rtol=1e-4)",
            "+        assert_allclose(",
            "+            hm.sum(-1).sum(-1), torch.tensor([[1.0, 1.0]], device=device, dtype=dtype), atol=1e-4, rtol=1e-4)",
            "",
            "pred = kornia.geometry.dsnt.spatial_expectation2d(hm)",
            "assert_allclose("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2067,
        "label": "no",
        "change": [
            "def create_position_ids_from_input_ids(input_ids, padding_idx):",
            "\"\"\"",
            "# The series of casts and type-conversions here are carefully balanced to both work with ONNX export and XLA.",
            "mask = input_ids.ne(padding_idx).int()",
            "-    incremental_indicies = torch.cumsum(mask, dim=1).type_as(mask) * mask",
            "-    return incremental_indicies.long() + padding_idx",
            "+    incremental_indices = torch.cumsum(mask, dim=1).type_as(mask) * mask",
            "+    return incremental_indices.long() + padding_idx",
            "",
            "",
            "def prune_linear_layer(layer, index, dim=0):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2072,
        "label": "no",
        "change": [
            "class LocalGradientAggregationHelperEager:",
            "# is equal to 0.",
            "self.counter = tf.Variable(initial_value=0)",
            "",
            "-    @tf.function",
            "def compute_gradients(self, grads, vars):",
            "# On steps where allreduce happens, resulting_grads returns the allreduced",
            "# gradients, on other steps it returns the locally aggregated"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2073,
        "label": "no",
        "change": [
            "class EpsilonAnneal(Exploration):",
            "return self.initial_epsilon + completed_ratio * (self.final_epsilon - self.initial_epsilon)",
            "",
            "pred = tf.logical_or(x=(timestep < self.start_timestep), y=(timestep > self.start_timestep + self.timesteps))",
            "-        return tf.cond(pred=pred, true_fn=true_fn, false_fn=false_fn)",
            "+        return tf.constant(dims=shape, value=tf.cond(pred=pred, true_fn=true_fn, false_fn=false_fn))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2074,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "l = Conv2D('conv3', l, ch_out * 4, 1)",
            "",
            "squeeze = GlobalAvgPooling('gap', l)",
            "-            squeeze = FullyConnected('fc1', squeeze, ch_out // 4, nl=tf.identity)",
            "+            squeeze = FullyConnected('fc1', squeeze, ch_out // 4, nl=tf.nn.relu)",
            "squeeze = FullyConnected('fc2', squeeze, ch_out * 4, nl=tf.nn.sigmoid)",
            "l = l * tf.reshape(squeeze, [-1, ch_out * 4, 1, 1])",
            "return l + resnet_shortcut(shortcut, ch_out * 4, stride)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2076,
        "label": "no",
        "change": [
            "class StochasticDurationPredictor(nn.Module):",
            "",
            "flows = list(reversed(self.flows))",
            "flows = flows[:-2] + [flows[-1]]  # remove a useless vflow",
            "-        z = torch.rand(x.size(0), 2, x.size(2)).to(device=x.device, dtype=x.dtype) * noise_scale",
            "+        z = torch.randn(x.size(0), 2, x.size(2)).to(device=x.device, dtype=x.dtype) * noise_scale",
            "for flow in flows:",
            "z = torch.flip(z, [1])",
            "z = flow(z, x_mask, g=x, reverse=reverse)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2079,
        "label": "no",
        "change": [
            "def train(logdir='logdir/train1', queue=True):",
            "with tf.Graph().as_default():",
            "eval1.eval(logdir=logdir, queue=False)",
            "",
            "+            writer.add_summary(summ, global_step=gs)",
            "+",
            "writer.close()",
            "coord.request_stop()",
            "coord.join(threads)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2080,
        "label": "no",
        "change": [
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "BART_PRETRAINED_MODEL_ARCHIVE_MAP = {",
            "-    \"bart-large\": \"https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-large/pytorch_model.bin\",",
            "-    \"bart-large-mnli\": \"https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-large-mnli/pytorch_model.bin\",",
            "-    \"bart-large-cnn\": \"https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-large-cnn/pytorch_model.bin\",",
            "-    \"bart-large-xsum\": \"https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-large-xsum/pytorch_model.bin\",",
            "-    \"mbart-large-en-ro\": \"https://s3.amazonaws.com/models.huggingface.co/bert/facebook/mbart-large-en-ro/pytorch_model.bin\",",
            "+    \"bart-large\": \"https://cdn.huggingface.co/facebook/bart-large/pytorch_model.bin\",",
            "+    \"bart-large-mnli\": \"https://cdn.huggingface.co/facebook/bart-large-mnli/pytorch_model.bin\",",
            "+    \"bart-large-cnn\": \"https://cdn.huggingface.co/facebook/bart-large-cnn/pytorch_model.bin\",",
            "+    \"bart-large-xsum\": \"https://cdn.huggingface.co/facebook/bart-large-xsum/pytorch_model.bin\",",
            "+    \"mbart-large-en-ro\": \"https://cdn.huggingface.co/facebook/mbart-large-en-ro/pytorch_model.bin\",",
            "}",
            "",
            "BART_START_DOCSTRING = r\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2082,
        "label": "no",
        "change": [
            "train_loader = torch.utils.data.DataLoader(",
            "train_dataset, batch_size=args.batch_size, sampler=train_sampler, **kwargs)",
            "",
            "test_dataset = \\",
            "-    datasets.MNIST('data-%d' % hvd.rank(), train=False, transform=transforms.Compose([",
            "+    datasets.MNIST(data_dir, train=False, transform=transforms.Compose([",
            "transforms.ToTensor(),",
            "transforms.Normalize((0.1307,), (0.3081,))",
            "]))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2083,
        "label": "no",
        "change": [
            "class CellStem0(nn.Module):",
            "self.comb_iter_0_left = TwoSeparables(42, 42, 5, 2, 2, bias=False)",
            "self.comb_iter_0_right = TwoSeparables(96, 42, 7, 2, 3, bias=False)",
            "",
            "-        self.comb_iter_1_left = nn.AvgPool2d(3, stride=2, padding=1)",
            "+        self.comb_iter_1_left = nn.MaxPool2d(3, stride=2, padding=1)",
            "self.comb_iter_1_right = TwoSeparables(96, 42, 7, 2, 3, bias=False)",
            "",
            "-        self.comb_iter_2_left = nn.MaxPool2d(3, stride=2, padding=1)",
            "+        self.comb_iter_2_left = nn.AvgPool2d(3, stride=2, padding=1)",
            "self.comb_iter_2_right = TwoSeparables(96, 42, 5, 2, 2, bias=False)",
            "",
            "self.comb_iter_3_right = nn.AvgPool2d(3, stride=1, padding=1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2084,
        "label": "no",
        "change": [
            "class TFGPT2PreTrainedModel(TFPreTrainedModel):",
            "@tf.function(",
            "input_signature=[",
            "{",
            "-                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),",
            "-                \"attention_mask\": tf.TensorSpec((None, None), tf.int64, name=\"attention_mask\"),",
            "+                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),",
            "+                \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),",
            "}",
            "]",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2087,
        "label": "no",
        "change": [
            "class TransducerDecoder(AbsDecoder):",
            "dec_states = self.create_batch_states(dec_states, [d[1] for d in done])",
            "",
            "if use_lm:",
            "-            lm_labels = torch.LongTensor([h.yseq[-1] for h in hyps], device=self.device)",
            "+            lm_labels = torch.LongTensor(",
            "+                [h.yseq[-1] for h in hyps], device=self.device",
            "+            ).view(final_batch, 1)",
            "",
            "return dec_out, dec_states, lm_labels"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2093,
        "label": "no",
        "change": [
            "logger = logging.getLogger(__name__)",
            "def warmup_cosine(x, warmup=0.002):",
            "if x < warmup:",
            "return x/warmup",
            "-    return 0.5 * (1.0 + torch.cos(math.pi * x))",
            "+",
            "+    x_ = (x - warmup) / (1 - warmup)  # progress after warmup",
            "+    return 0.5 * (1. + math.cos(math.pi * x_))",
            "",
            "def warmup_constant(x, warmup=0.002):",
            "\"\"\" Linearly increases learning rate over `warmup`*`t_total` (as provided to BertAdam) training steps."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2098,
        "label": "no",
        "change": [
            "def _train_batches(model: NNModel, iterator: DataLearningIterator, train_config:",
            "tb_train_writer.add_summary(metric_sum, epochs)",
            "",
            "if losses:",
            "-                        loss_sum = tf.Summary(value=[tf.Summary.Value(tag='every_n_batches/' + 'loss',",
            "+                        loss_sum = tf.Summary(value=[tf.Summary.Value(tag='every_n_epochs/' + 'loss',",
            "simple_value=report['loss']), ])",
            "tb_train_writer.add_summary(loss_sum, i)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2100,
        "label": "no",
        "change": [
            "class TestZCA:",
            "else:",
            "expected = torch.sqrt(2 * torch.abs(data)) * torch.sign(data)",
            "",
            "-        expected.to(device)",
            "+        expected = expected.to(device)",
            "",
            "actual = kornia.zca_whiten(data, unbiased=unbiased)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2104,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "image, fg_sampled_boxes,",
            "tf.zeros_like(fg_inds_wrt_sample, dtype=tf.int32), 300)",
            "fg_sampled_patches = tf.transpose(fg_sampled_patches, [0, 2, 3, 1])",
            "-                fg_sampled_patches = tf.reverse(fg_sampled_patches, axis=-1)  # BGR->RGB",
            "+                fg_sampled_patches = tf.reverse(fg_sampled_patches, axis=[-1])  # BGR->RGB",
            "tf.summary.image('viz', fg_sampled_patches, max_outputs=30)",
            "",
            "matched_gt_boxes = tf.gather(gt_boxes, fg_inds_wrt_gt)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2106,
        "label": "no",
        "change": [
            "def non_max_suppression(prediction, conf_thres=0.1, iou_thres=0.6, fast=False, c",
            "",
            "# Filter by class",
            "if classes:",
            "-            x = x[(j.view(-1, 1) == torch.tensor(classes, device=j.device)).any(1)]",
            "+            x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]",
            "",
            "# Apply finite constraint",
            "# if not torch.isfinite(x).all():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2110,
        "label": "no",
        "change": [
            "class ThresholdsTest(tf.test.TestCase, parameterized.TestCase):",
            "self.assertAllClose(v1, v2)",
            "",
            "",
            "-if __name__ == \"__main__\":",
            "-    tf.test.main()",
            "+if __name__ == '__main__':",
            "+  tf.test.main()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2111,
        "label": "no",
        "change": [
            "class TestEvaluate(AllenNlpTestCase):",
            "archive_path = str(self.FIXTURES_ROOT / \"decomposable_attention\" / \"serialization\" / \"model.tar.gz\")",
            "# snli2 has a extra token (\"seahorse\") in it.",
            "evaluate_data_path = str(self.FIXTURES_ROOT / 'data' / 'snli2.jsonl')",
            "-        embeddings_filename = str(self.FIXTURES_ROOT / 'data' / 'seahorse_embeddings.gz') #has only seahorse vector",
            "+        embeddings_filename = str(self.FIXTURES_ROOT / 'data' / 'seahorse_embeddings.gz')  # has only seahorse vector",
            "embedding_sources_mapping = json.dumps({\"_text_field_embedder.token_embedder_tokens\": embeddings_filename})",
            "kebab_args = [\"evaluate\", archive_path, evaluate_data_path, \"--cuda-device\", \"-1\"]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2112,
        "label": "no",
        "change": [
            "def test_statsmodels_save_load(metadata, holt_model):  # noqa # pylint: disable",
            "",
            "",
            "@pytest.mark.parametrize(\"exc\", [BentoMLException])",
            "-def test_get_model_info_exc(exc, holt_model):",
            "+def test_load_model_exc(exc, holt_model):",
            "tag = wrong_module(holt_model)",
            "with pytest.raises(exc):",
            "-        bentoml._internal.frameworks.statsmodels._get_model_info(tag)",
            "+        bentoml._internal.frameworks.statsmodels.load(tag)",
            "",
            "",
            "def test_statsmodels_runner_setup_run_batch(save_proc, holt_model):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2113,
        "label": "no",
        "change": [
            "def PositionalEmbedding(num_embeddings, embedding_dim, padding_idx, left_pad, le",
            "if learned:",
            "m = LearnedPositionalEmbedding(num_embeddings, embedding_dim, padding_idx, left_pad)",
            "nn.init.normal(m.weight, mean=0, std=embedding_dim**-0.5)",
            "+        nn.init.constant(m.weight[padding_idx], 0)",
            "else:",
            "m = SinusoidalPositionalEmbedding(embedding_dim, padding_idx, left_pad, init_size=num_embeddings)",
            "return m"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2114,
        "label": "no",
        "change": [
            "def argmin(",
            "return ret",
            "",
            "",
            "-def nonzero(",
            "-    x: Union[tf.Tensor, tf.Variable],",
            "-) -> Union[tf.Tensor, tf.Variable]:",
            "-    return tf.experimental.numpy.nonzero(x)",
            "+def nonzero(x: Union[tf.Tensor, tf.Variable]) -> Tuple[Union[tf.Tensor, tf.Variable]]:",
            "+    return tuple(tf.experimental.numpy.nonzero(x))",
            "",
            "",
            "def where("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2115,
        "label": "no",
        "change": [
            "def l2_loss(tensor, weight=1.0, scope=None):",
            "Returns:",
            "the L2 loss op.",
            "\"\"\"",
            "-    with tf.op_scope([tensor], scope, 'l2_loss'):",
            "+    with tf.name_scope(scope):",
            "weight = tf.convert_to_tensor(weight,",
            "dtype=tensor.dtype.base_dtype,",
            "name='loss_weight')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2117,
        "label": "no",
        "change": [
            "if __name__ == \"__main__\":",
            "cv2.destroyAllWindows()",
            "elif url.startswith('http'):",
            "img_stream = io.BytesIO(fetch(url))",
            "-    img = cv2.imdecode(np.fromstring(img_stream.read(), np.uint8), 1)",
            "+    img = cv2.imdecode(np.frombuffer(img_stream.read(), np.uint8), 1)",
            "else:",
            "img = cv2.imread(url)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2118,
        "label": "no",
        "change": [
            "def unproject_points(",
            "tensor of (x, y, z) world coordinates with shape :math:`(*, 3)`.",
            "",
            "Example:",
            "+        >>> _ = torch.manual_seed(0)",
            ">>> x = torch.rand(1, 2)",
            ">>> depth = torch.ones(1, 1)",
            ">>> K = torch.eye(3)[None]",
            ">>> unproject_points(x, depth, K)",
            "-        tensor([[0.2711, 0.6923, 1.0000]])",
            "+        tensor([[0.4963, 0.7682, 1.0000]])",
            "\"\"\"",
            "if not isinstance(point_2d, torch.Tensor):",
            "raise TypeError(f\"Input point_2d type is not a torch.Tensor. Got {type(point_2d)}\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2119,
        "label": "no",
        "change": [
            "class BagOfWordCountsTokenEmbedder(TokenEmbedder):",
            "# also mask out positions corresponding to oov",
            "mask *= (inputs != self._oov_idx).long()",
            "for document, doc_mask in zip(inputs, mask):",
            "-            document = torch.masked_select(document, doc_mask.byte())",
            "+            document = torch.masked_select(document, doc_mask.to(dtype=torch.bool))",
            "vec = torch.bincount(document, minlength=self.vocab_size).float()",
            "vec = vec.view(1, -1)",
            "bag_of_words_vectors.append(vec)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2123,
        "label": "no",
        "change": [
            "class BartModelIntegrationTest(unittest.TestCase):",
            "output = model.forward(**inputs_dict)[0]",
            "expected_shape = torch.Size((1, 11, 1024))",
            "self.assertEqual(output.shape, expected_shape)",
            "-        expected_slice = torch.Tensor(",
            "+        expected_slice = torch.tensor(",
            "[[0.7144, 0.8143, -1.2813], [0.7144, 0.8143, -1.2813], [-0.0467, 2.5911, -2.1845]], device=torch_device",
            ")",
            "self.assertTrue(torch.allclose(output[:, :3, :3], expected_slice, atol=TOLERANCE))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2125,
        "label": "yes",
        "change": [
            "class ClusterLoader(torch.utils.data.DataLoader):",
            "node_idx = torch.cat([torch.arange(s, e) for s, e in zip(start, end)])",
            "",
            "data = copy.copy(self.cluster_data.data)",
            "-        del data.num_nodes",
            "+        if hasattr(data, '__num_nodes__'):",
            "+            del data.__num_nodes__",
            "adj, data.adj = self.cluster_data.data.adj, None",
            "adj = cat([adj.narrow(0, s, e - s) for s, e in zip(start, end)], dim=0)",
            "adj = adj.index_select(1, node_idx)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "removal",
        "Element": "api condition check"
    },
    {
        "number": 2130,
        "label": "no",
        "change": [
            "class TestRandomMotionBlur:",
            "",
            "",
            "class TestRandomMotionBlur3D:",
            "+    # TODO: improve and implement more meaningful smoke tests e.g check for a consistent",
            "+    # return values such a torch.Tensor variable.",
            "+    @pytest.mark.xfail(reason=\"might fail under windows OS due to printing preicision.\")",
            "def test_smoke(self, device, dtype):",
            "f = RandomMotionBlur3D(kernel_size=(3, 5), angle=(10, 30), direction=0.5)",
            "repr = \"RandomMotionBlur3D(kernel_size=(3, 5), angle=tensor([[10., 30.],\"\\"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2132,
        "label": "no",
        "change": [
            "def get_dataset_golden_types_path(dataset_name: str) -> str:",
            "return str(Path(__file__).resolve().parent / \"golden\" / f\"{dataset_name}.types.json\")",
            "",
            "",
            "-def get_dataset_object(dataset_name: str) -> BaseDataset:",
            "+def get_dataset_object(dataset_name: str) -> DatasetLoader:",
            "\"\"\"Returns a Ludwig dataset instance for the given dataset.\"\"\"",
            "-    return dataset_registry[dataset_name]()",
            "+    return ludwig.datasets.get_dataset(dataset_name)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2133,
        "label": "yes",
        "change": [
            "class Decoder(torch.nn.Module):",
            "else:",
            "local_scores = functional.log_softmax(self.output(z_list[-1]), dim=1).data",
            "if lpz is not None:",
            "-                    local_att_best_scores, local_att_best_ids = torch.topk(local_scores, int(beam*1.5), dim=1)",
            "+                    local_att_best_scores, local_att_best_ids = torch.topk(local_scores, int(beam * CTC_SCORING_RATIO), dim=1)",
            "ctc_scores, ctc_states = ctc_prefix_score(hyp['yseq'], local_att_best_ids[0], hyp['ctc_prev'])",
            "-                    joint_scores = (1. - ctc_weight) * (local_att_best_scores[0].numpy() + hyp['score']) + ctc_weight * ctc_scores",
            "-                    joint_best_ids = np.argsort(joint_scores)[:-beam-1:-1]",
            "+                    joint_scores = (1. - ctc_weight) * \\",
            "+                        (local_att_best_scores[0].numpy() + hyp['score']) + ctc_weight * ctc_scores",
            "+                    joint_best_ids = np.argsort(joint_scores)[:-beam - 1:-1]",
            "local_best_ids = local_att_best_ids.numpy()[:, joint_best_ids]",
            "local_best_scores = local_att_best_scores.numpy()[:, joint_best_ids]",
            "else:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 2134,
        "label": "yes",
        "change": [
            "class Random(Exploration):",
            "if explore:",
            "# Unsqueeze will be unnecessary, once we support batch/time-aware",
            "# Spaces.",
            "-            action = torch.IntTensor(self.action_space.sample()).unsqueeze(0)",
            "+            action = torch.LongTensor(self.action_space.sample()).unsqueeze(0)",
            "else:",
            "-            action = torch.IntTensor(action_dist.deterministic_sample())",
            "+            action = torch.LongTensor(action_dist.deterministic_sample())",
            "logp = torch.zeros((action.size()[0], ), dtype=torch.float32)",
            "return action, logp"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 2136,
        "label": "no",
        "change": [
            "class TorchFastModel(TorchModelV2, nn.Module):",
            "",
            "@override(ModelV2)",
            "def forward(self, input_dict, state, seq_lens):",
            "-        self._output = self.bias + \\",
            "-            torch.zeros(size=(input_dict[\"obs\"].shape[0], self.num_outputs))",
            "+        self._output = self.bias + torch.zeros(",
            "+            size=(input_dict[\"obs\"].shape[0], self.num_outputs)).to(",
            "+                self.bias.device)",
            "return self._output, []",
            "",
            "@override(ModelV2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2139,
        "label": "no",
        "change": [
            "def load_from_saved_model(saved_model_path, custom_objects=None):",
            "",
            "# Save the tf.keras model in the SavedModel format.",
            "path = '/tmp/simple_keras_model'",
            "-    tf.keras.experimental.export_saved_model(model, path)",
            "+    tf.compat.v1.keras.experimental.export_saved_model(model, path)",
            "",
            "# Load the saved keras model back.",
            "-    new_model = tf.keras.experimental.load_from_saved_model(path)",
            "+    new_model = tf.compat.v1.keras.experimental.load_from_saved_model(path)",
            "new_model.summary()",
            "```"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2141,
        "label": "no",
        "change": [
            "from torch_geometric.nn.functional.random_walk import random_walk",
            "def test_random_walk():",
            "edge_index = torch.LongTensor([[0, 0, 1, 1, 2], [0, 1, 1, 2, 2]])",
            "edge_attr = torch.Tensor([0.5, 0.5, 0.5, 0.5, 1])",
            "-    target = torch.LongTensor([1, 0, 1])",
            "+    one_hot = torch.Tensor([[0, 1], [1, 0], [0, 1]])",
            "weight = torch.Tensor(2, 4).fill_(1)  # 2 classes, 4 steps.",
            "",
            "-    random_walk(edge_index, edge_attr, target, weight)",
            "-    random_walk(edge_index, Var(edge_attr), Var(target), Var(weight))",
            "+    random_walk(edge_index, edge_attr, one_hot, weight)",
            "+    random_walk(edge_index, Var(edge_attr), Var(one_hot), Var(weight))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2142,
        "label": "yes",
        "change": [
            "class Trainer:",
            "for name, param in self._model.named_parameters():",
            "param_updates[name].sub_(param.detach().cpu())",
            "update_norm = torch.norm(param_updates[name].view(-1, ))",
            "-                    param_norm = torch.norm(param.view(-1, ))",
            "+                    param_norm = torch.norm(param.view(-1, )).cpu()",
            "self._tensorboard.add_train_scalar(\"gradient_update/\" + name,",
            "update_norm / (param_norm + 1e-7),",
            "batch_num_total)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 2143,
        "label": "no",
        "change": [
            "class SOSNet(nn.Module):",
            "# load pretrained model",
            "if pretrained:",
            "storage_fcn: Callable = lambda storage, loc: storage",
            "-            pretrained_dict = torch.hub.load_state_dict_from_url(",
            "-                urls['lib'], map_location=storage_fcn",
            "-            )",
            "+            pretrained_dict = torch.hub.load_state_dict_from_url(urls['lib'], map_location=storage_fcn)",
            "self.load_state_dict(pretrained_dict, strict=True)",
            "self.eval()",
            "return"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2144,
        "label": "no",
        "change": [
            "def train_func(config):",
            "checkpoint_epoch = checkpoint_dict[\"epoch\"]",
            "starting_epoch = checkpoint_epoch + 1",
            "",
            "-    model = train.torch.prepare_model(model)",
            "-",
            "# Load in training and validation data.",
            "transform_train = transforms.Compose(",
            "["
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2145,
        "label": "no",
        "change": [
            "def copy_array(x: Tensor) -> Tensor:",
            "",
            "",
            "def array_equal(x0: Tensor, x1: Tensor) -> bool:",
            "-    return tf.experimental.numpy.array_equal(x0, x1)",
            "+    return bool((tf.experimental.numpy.array_equal(x0, x1)))",
            "",
            "",
            "def to_numpy(x: Tensor) -> _np.ndarray:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2147,
        "label": "no",
        "change": [
            "def train(hyp, opt, device, tb_writer=None):",
            "if tb_writer and ni == 0:",
            "with warnings.catch_warnings():",
            "warnings.simplefilter('ignore')  # suppress jit trace warning",
            "-                            tb_writer.add_graph(torch.jit.trace(de_parallel(model), imgs, strict=False), [])  # graph",
            "+                            tb_writer.add_graph(torch.jit.trace(de_parallel(model), imgs[0:1], strict=False), [])",
            "elif plots and ni == 10 and wandb_logger.wandb:",
            "wandb_logger.log({'Mosaics': [wandb_logger.wandb.Image(str(x), caption=x.name) for x in",
            "save_dir.glob('train*.jpg') if x.exists()]})"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2150,
        "label": "no",
        "change": [
            "def sync_ddp_if_available(",
            "Return:",
            "reduced value",
            "\"\"\"",
            "-    if torch.distributed.is_available() and torch.distributed.is_initialized():",
            "+    if torch.distributed.is_available() and torch.distributed.is_initialized() or tpu_distributed():",
            "return sync_ddp(result, group=group, reduce_op=reduce_op)",
            "return result"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2151,
        "label": "no",
        "change": [
            "def LeakyReLU(x, alpha, name='output'):",
            "x (tf.Tensor): input",
            "alpha (float): the slope.",
            "\"\"\"",
            "+    log_deprecated(\"LeakyReLU\", \"Use tf.nn.leaky_relu in TF 1.4 instead!\", \"2018-03-30\")",
            "return tf.maximum(x, alpha * x, name=name)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2159,
        "label": "no",
        "change": [
            "class ImageFeatureMixin(BaseFeatureMixin):",
            "if isinstance(img_entry, bytes):",
            "img = read_image_from_bytes_obj(img_entry, num_channels)",
            "elif isinstance(img_entry, np.ndarray):",
            "-            img = torch.from_numpy(img_entry).permute(2, 0, 1)",
            "+            img = torch.from_numpy(np.array(img_entry, copy=True)).permute(2, 0, 1)",
            "else:",
            "img = img_entry"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2160,
        "label": "no",
        "change": [
            "config.save_json(config_path)",
            "command_train = (",
            "f\"CUDA_VISIBLE_DEVICES='{get_device_id()}' python TTS/bin/train_tts.py --config_path {config_path} \"",
            "f\"--coqpit.output_path {output_path} \"",
            "-    \"--coqpit.datasets.0.name ljspeech \"",
            "+    \"--coqpit.datasets.0.formatter ljspeech \"",
            "\"--coqpit.datasets.0.meta_file_train metadata.csv \"",
            "\"--coqpit.datasets.0.meta_file_val metadata.csv \"",
            "\"--coqpit.datasets.0.path tests/data/ljspeech \""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2162,
        "label": "no",
        "change": [
            "def beam_search_step(logits, beam_state, config):",
            "",
            "# Append new ids to current predictions",
            "next_predictions = tf.gather(beam_state.predictions, next_beam_ids)",
            "-  next_predictions = tf.concat(1, [",
            "+  next_predictions = tf.concat_v2([",
            "next_predictions[:, 0:time_ - 1],",
            "tf.to_int32(tf.expand_dims(next_word_ids, 1)), next_predictions[:, time_:]",
            "-  ])",
            "+  ], 1)",
            "",
            "next_beam_state = BeamState(",
            "time=time_,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2163,
        "label": "yes",
        "change": [
            "def main():",
            "",
            "model = BertForSequenceClassification(bert_config, len(label_list))",
            "if args.init_checkpoint is not None:",
            "-        model.load_state_dict(torch.load(args.init_checkpoint, map_location='cpu'))",
            "+        model.bert.load_state_dict(torch.load(args.init_checkpoint, map_location='cpu'))",
            "model.to(device)",
            "",
            "if args.local_rank != -1:"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "state handling error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 2164,
        "label": "no",
        "change": [
            "class ResNeXtBlock(nn.Block):",
            "use_1x1conv=False, strides=1, **kwargs):",
            "super().__init__(**kwargs)",
            "bot_channels = int(round(num_channels * bot_mul))",
            "-        self.conv1 = nn.Conv2D(bot_channels, kernel_size=1, padding=0, strides=1)",
            "+        self.conv1 = nn.Conv2D(bot_channels, kernel_size=1, padding=0,",
            "+                               strides=1)",
            "self.conv2 = nn.Conv2D(bot_channels, kernel_size=3, padding=1,",
            "strides=strides, groups=bot_channels//groups)",
            "-        self.conv3 = nn.Conv2D(num_channels, kernel_size=1, padding=0, strides=1)",
            "+        self.conv3 = nn.Conv2D(num_channels, kernel_size=1, padding=0,",
            "+                               strides=1)",
            "self.bn1 = nn.BatchNorm()",
            "self.bn2 = nn.BatchNorm()",
            "self.bn3 = nn.BatchNorm()",
            "if use_1x1conv:",
            "-            self.conv4 = nn.Conv2D(num_channels, kernel_size=1, strides=strides)",
            "+            self.conv4 = nn.Conv2D(num_channels, kernel_size=1,",
            "+                                   strides=strides)",
            "self.bn4 = nn.BatchNorm()",
            "else:",
            "self.conv4 = None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2165,
        "label": "no",
        "change": [
            "class HubertModelIntegrationTest(unittest.TestCase):",
            "expected_logits = torch.tensor([7.6692, 17.7795, 11.1562, 11.8232], dtype=torch.float16, device=torch_device)",
            "",
            "self.assertListEqual(predicted_ids.tolist(), expected_labels)",
            "-        self.assertTrue(torch.allclose(predicted_logits, expected_logits, atol=2e-2))",
            "+        self.assertTrue(torch.allclose(predicted_logits, expected_logits, atol=3e-2))",
            "",
            "def test_inference_intent_classification(self):",
            "model = HubertForSequenceClassification.from_pretrained("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2166,
        "label": "yes",
        "change": [
            "class AdditiveSharingTensor(AbstractTensor):",
            "mask_pos = x > self.max_value",
            "mask_neg = x < self.min_value",
            "if mask_pos.any():",
            "-                mask_pos = mask_pos.long()",
            "+                mask_pos = mask_pos.type(self.torch_dtype)",
            "return self.modulo(x - (mask_pos * self.field))",
            "elif mask_neg.any():",
            "-                mask_neg = mask_neg.long()",
            "+                mask_neg = mask_neg.type(self.torch_dtype)",
            "return self.modulo(x + (mask_neg * self.field))",
            "else:",
            "return x.type(self.torch_dtype)"
        ],
        "comments": "",
        "Symptom": "return warning",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 2168,
        "label": "no",
        "change": [
            "class DistributedModel(object):",
            "",
            "self.gradients = tf.gradients(self.loss, self.local_network.get_variables())",
            "",
            "-            grad_var_list = list(zip(self.gradients, self.local_network.get_variables()))",
            "+            grad_var_list = list(zip(self.gradients, self.global_network.get_variables()))",
            "",
            "global_step_inc = self.global_step.assign_add(self.batch_size)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2170,
        "label": "no",
        "change": [
            "class MentionRecall(Metric):",
            "if self._num_gold_mentions == 0:",
            "recall = 0.0",
            "else:",
            "-            recall = self._num_recalled_mentions/float(self._num_gold_mentions)",
            "+            recall = self._num_recalled_mentions / float(self._num_gold_mentions)",
            "if reset:",
            "self.reset()",
            "return recall"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2171,
        "label": "yes",
        "change": [
            "class FeaturesTest(TestCase):",
            "casted_obj = cast_to_python_objects(obj)",
            "self.assertDictEqual(casted_obj, expected_obj)",
            "",
            "-    @patch(\"nlp.features._cast_to_python_objects\", side_effect=_cast_to_python_objects)",
            "+    @patch(\"datasets.features._cast_to_python_objects\", side_effect=_cast_to_python_objects)",
            "def test_dont_iterate_over_each_element_in_a_list(self, mocked_cast):",
            "obj = {\"col_1\": [[1, 2], [3, 4], [5, 6]]}",
            "cast_to_python_objects(obj)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 2172,
        "label": "no",
        "change": [
            "torch_scatter = None",
            "def dev(x: torch.Tensor, as_native: bool = False) -> Union[ivy.Device, torch.device]:",
            "dv = x.device",
            "if as_native:",
            "-        return dv",
            "+        return torch.device(dv)",
            "return as_ivy_dev(dv)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2173,
        "label": "no",
        "change": [
            "class CycleGANModel(BaseModel):",
            "# initialize optimizers",
            "self.optimizer_G = torch.optim.Adam(itertools.chain(self.netG_A.parameters(), self.netG_B.parameters()),",
            "lr=opt.lr, betas=(opt.beta1, 0.999))",
            "-            self.optimizer_D = torch.optim.Adam(itertools.chain(self.netD_A.parameters(), self.netD_B.parameters()), lr=opt.lr, betas=(opt.beta1, 0.999))",
            "+            self.optimizer_D = torch.optim.Adam(itertools.chain(self.netD_A.parameters(), self.netD_B.parameters()),",
            "+                                                lr=opt.lr, betas=(opt.beta1, 0.999))",
            "self.optimizers = []",
            "self.schedulers = []",
            "self.optimizers.append(self.optimizer_G)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2175,
        "label": "no",
        "change": [
            "def retrieve_seq_length_op3(data, pad_val=0):  # HangSheng: return tensor for se",
            "",
            "",
            "def target_mask_op(data, pad_val=0):  # HangSheng: return tensor for mask,if input is tf.string",
            "-    \"\"\" Return tensor for mask, if input is ``tf.string``. \"\"\"",
            "+    \"\"\"Return tensor for mask, if input is ``tf.string``.\"\"\"",
            "data_shape_size = data.get_shape().ndims",
            "if data_shape_size == 3:",
            "return tf.cast(tf.reduce_any(tf.not_equal(data, pad_val), axis=2), dtype=tf.int32)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2178,
        "label": "no",
        "change": [
            "class TFPreTrainedModel(tf.keras.Model):",
            "Returns:",
            "tf.Tensor with dummy inputs",
            "\"\"\"",
            "-        return tf.constant(DUMMY_INPUTS)",
            "+        return {'input_ids': tf.constant(DUMMY_INPUTS)}",
            "",
            "def __init__(self, config, *inputs, **kwargs):",
            "super(TFPreTrainedModel, self).__init__(*inputs, **kwargs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2179,
        "label": "yes",
        "change": [
            "def test_lite_module_forward_conversion(precision, input_type, expected_type):",
            "assert precision != 16 or torch.is_autocast_enabled()",
            "return forward_input",
            "",
            "-    module = Mock(wraps=torch.nn.Linear(1, 1), side_effect=check_autocast)",
            "+    module = Mock(wraps=torch.nn.Identity(), side_effect=check_autocast)",
            "lite_module = _LiteModule(module, lite._precision_plugin).to(device)",
            "-    out = lite_module(torch.rand(1, dtype=input_type, device=device))",
            "+    out = lite_module(torch.tensor([1, 2, 3], dtype=input_type, device=device))",
            "assert module.call_args[0][0].dtype == expected_type",
            "-    assert out.dtype == torch.get_default_dtype()",
            "+    assert out.dtype == input_type or out.dtype == torch.get_default_dtype()",
            "",
            "",
            "def test_lite_dataloader_iterator():"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 2180,
        "label": "no",
        "change": [
            "class TestModules(unittest.TestCase):",
            "that it trains in a supervised setting.\"\"\"",
            "",
            "# Checks that torch and tf embedding matrices are the same",
            "-        with tf.Session().as_default() as sess:",
            "+        with tf1.Session().as_default() as sess:",
            "assert np.allclose(",
            "relative_position_embedding(20, 15).eval(session=sess),",
            "relative_position_embedding_torch(20, 15).numpy())"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2184,
        "label": "no",
        "change": [
            "class _SequencePostprocessing(torch.nn.Module):",
            "sequence_predictions.append(unit_prediction)",
            "predictions.append(sequence_predictions)",
            "",
            "-        pred_probabilities = preds[self.probabilities_key]",
            "probabilities, _ = torch.max(pred_probabilities, dim=-1)",
            "probability = torch.sum(torch.log(probabilities), dim=-1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2186,
        "label": "no",
        "change": [
            "with tf.Graph().as_default():",
            "num_filters=FLAGS.num_filters)",
            "",
            "# Define Training procedure",
            "-        global_step = tf.Variable(0, name=\"global_step\")",
            "+        global_step = tf.Variable(0, name=\"global_step\", trainable=False)",
            "optimizer = tf.train.AdamOptimizer(1e-4)",
            "grads_and_vars = optimizer.compute_gradients(cnn.loss)",
            "train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2187,
        "label": "no",
        "change": [
            "class IntegerLookupSavingTest(keras_parameterized.TestCase,",
            "",
            "",
            "if __name__ == \"__main__\":",
            "-  # IntegerLookup is only exported as a TF2 API.",
            "-  tf.compat.v1.enable_v2_behavior()",
            "tf.test.main()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2189,
        "label": "no",
        "change": [
            "class Auc(Metric):",
            "if mask is None:",
            "batch_size = gold_labels.shape[0]",
            "mask = torch.ones(batch_size)",
            "-        mask = mask.byte()",
            "+        mask = mask.to(dtype=torch.bool)",
            "",
            "self._all_predictions = torch.cat([self._all_predictions,",
            "torch.masked_select(predictions, mask).float()], dim=0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2190,
        "label": "no",
        "change": [
            "class MCMC(TracePosterior):",
            "if t == self.warmup_steps:",
            "self.kernel.end_warmup()",
            "continue",
            "-            yield (trace, torch.tensor([1.0]))",
            "+            yield (trace, 1.0)",
            "self.kernel.cleanup()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2192,
        "label": "no",
        "change": [
            "if torch.distributed.is_available():",
            "",
            "",
            "# Taken from https://github.com/pytorch/pytorch/blob/3466c1b6901f06a563b8cbfa3c942fa50bda835b/torch/distributed/distributed_c10d.py#L267 # noqa: E501",
            "-def _rank_not_in_group(group: ProcessGroup):",
            "+def _rank_not_in_group(group: \"ProcessGroup\"):",
            "\"\"\"Helper that checks if the current process's rank is not in a given group.\"\"\"",
            "if group is None:",
            "return False"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2193,
        "label": "no",
        "change": [
            "def meshgrid_ij(",
            "\"\"\"",
            "Like torch.meshgrid was before PyTorch 1.10.0, i.e. with indexing set to ij",
            "\"\"\"",
            "-    if \"indexing\" in torch.meshgrid.__kwdefaults__:",
            "+    if (",
            "+        torch.meshgrid.__kwdefaults__ is not None",
            "+        and \"indexing\" in torch.meshgrid.__kwdefaults__",
            "+    ):",
            "# PyTorch >= 1.10.0",
            "return torch.meshgrid(*A, indexing=\"ij\")",
            "return torch.meshgrid(*A)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2194,
        "label": "no",
        "change": [
            "def detect(net, img, device):",
            "# Creates a batch of 1",
            "img = img.reshape((1,) + img.shape)",
            "",
            "-    if 'cuda' in device:",
            "-        torch.backends.cudnn.benchmark = True",
            "-",
            "img = torch.from_numpy(img).float().to(device)",
            "",
            "return batch_detect(net, img, device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2195,
        "label": "no",
        "change": [
            "class DeviceDtypeModuleMixin(Module):",
            "raise RuntimeError(\"Cannot set the dtype explicitly. Please use module.to(new_dtype).\")",
            "",
            "@property",
            "-    def device(self) -> Union[str, torch.device]:",
            "+    def device(self) -> torch.device:",
            "device = self._device",
            "",
            "# make this more explicit to always include the index"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2199,
        "label": "no",
        "change": [
            "class TFFunnelRelMultiheadAttention(tf.keras.layers.Layer):",
            "",
            "self.post_proj = tf.keras.layers.Dense(d_model, kernel_initializer=initializer, name=\"post_proj\")",
            "self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=\"layer_norm\")",
            "-        self.scale = 1.0 / (d_head ** 0.5)",
            "+        self.scale = 1.0 / (d_head**0.5)",
            "",
            "def build(self, input_shape):",
            "n_head, d_head, d_model = self.n_head, self.d_head, self.d_model"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2201,
        "label": "yes",
        "change": [
            "def test_to_backend_with_tf_and_pytorch():",
            "break",
            "",
            "",
            "-def test_to_backend_with_tf_and_pytorch():",
            "+def test_to_backend_with_tf_and_pytorch_multiworker():",
            "try:",
            "import torch",
            "-        import tensorflow",
            "+        import tensorflow as tf",
            "except ImportError:",
            "print(\"Pytorch hasn't been imported and tested\")",
            "return",
            "",
            "+    tf.compat.v1.enable_eager_execution()",
            "ds = dataset.load(\"mnist/mnist\")",
            "",
            "tfds = ds.to_tensorflow().batch(8)"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "null reference error",
        "Action": "addition",
        "Element": "api call"
    },
    {
        "number": 2204,
        "label": "no",
        "change": [
            "def fft(",
            "*,",
            "norm: Optional[str] = \"backward\",",
            "n: Union[int, Tuple[int]] = None,",
            "-    out: Optional[Union[tf.Tensor, tf.Variable]] = None",
            "+    out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "if not isinstance(dim, int):",
            "raise ivy.exceptions.IvyError(f\"Expecting <class 'int'> instead of {type(dim)}\")",
            "if n is None:",
            "n = x.shape[dim]",
            "-    if n < -len(x.shape) :",
            "+    if n < -len(x.shape):",
            "raise ivy.exceptions.IvyError(",
            "f\"Invalid dim {dim}, expecting ranging\"",
            "\" from {-len(x.shape)} to {len(x.shape)-1}  \"",
            ")",
            "if not isinstance(n, int):",
            "raise ivy.exceptions.IvyError(f\"Expecting <class 'int'> instead of {type(n)}\")",
            "-    if n <= 1 :",
            "+    if n <= 1:",
            "raise ivy.exceptions.IvyError(f\"Invalid data points {n}, expecting more than 1\")",
            "if norm != \"backward\" and norm != \"ortho\" and norm != \"forward\":",
            "raise ivy.exceptions.IvyError(f\"Unrecognized normalization mode {norm}\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2205,
        "label": "no",
        "change": [
            "class TransformDataset(torch.utils.data.Dataset):",
            "",
            "",
            "class ChainerDataLoader(object):",
            "+    \"\"\"Pytorch dataloader in chainer style.",
            "+",
            "+    Args:",
            "+        all args for torch.utils.data.dataloader.Dataloader",
            "+",
            "+    \"\"\"",
            "+",
            "def __init__(self, **kwargs):",
            "self.loader = torch.utils.data.dataloader.DataLoader(**kwargs)",
            "self.len = len(kwargs['dataset'])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2206,
        "label": "no",
        "change": [
            "class TestGradientScalingAMP(unittest.TestCase):",
            "self.scaler.update()",
            "self.assertEqual(",
            "model.weight,",
            "-            torch.tensor(",
            "-                [[3.1]], device=\"cuda:0\", requires_grad=True",
            "-            ),",
            "+            torch.tensor([[3.1]], device=\"cuda:0\", requires_grad=True),",
            ")",
            "self.assertEqual(",
            "model.bias,",
            "-            torch.tensor(",
            "-                [5.1], device=\"cuda:0\", requires_grad=True",
            "-            ),",
            "+            torch.tensor([5.1], device=\"cuda:0\", requires_grad=True),",
            ")",
            "self.assertEqual(self.scaler.get_scale(), 2.0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2208,
        "label": "no",
        "change": [
            "class Decoder(nn.Module):",
            "if t > inputs.shape[1] / 4 and (stop_token > 0.6",
            "or attention[:, -1].item() > 0.6):",
            "break",
            "-            elif t > self.max_decoder_steps:",
            "+            if t > self.max_decoder_steps:",
            "print(\"   | > Decoder stopped with 'max_decoder_steps\")",
            "break",
            "return self._parse_outputs(outputs, attentions, stop_tokens)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2209,
        "label": "no",
        "change": [
            "class DisentangledSelfAttention(nn.Module):",
            "dim=-1,",
            "index=p2c_pos.squeeze(0).expand([query_layer.size(0), key_layer.size(-2), key_layer.size(-2)]),",
            ").transpose(-1, -2)",
            "-            score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)",
            "+            score += p2c_att / scale.to(dtype=p2c_att.dtype)",
            "",
            "return score"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2211,
        "label": "no",
        "change": [
            "def log_gamma(xx):",
            "",
            "",
            "def log_beta(t):",
            "+    \"\"\"",
            "+    Computes log Beta function.",
            "+",
            "+    :param t:",
            "+    :type t: torch.autograd.Variable of dimension 1 or 2",
            "+    :rtype: torch.autograd.Variable of float (if t.dim() == 1) or torch.Tensor (if t.dim() == 2)",
            "+    \"\"\"",
            "+    assert t.dim() in (1, 2)",
            "if t.dim() == 1:",
            "numer = torch.sum(log_gamma(t))",
            "denom = log_gamma(torch.sum(t))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2212,
        "label": "no",
        "change": [
            "class DepLabelIndexer(TokenIndexer[int]):",
            "return {index_name: [vocabulary.get_token_index(dep_label, self.namespace) for dep_label in dep_labels]}",
            "",
            "@overrides",
            "-    def get_padding_lengths(self, token: int) -> Dict[str, int]:  # pylint: disable=unused-argument",
            "+    def get_padding_lengths(self, token: int) -> Dict[str, int]:",
            "return {}",
            "",
            "@overrides",
            "def as_padded_tensor(self,",
            "tokens: Dict[str, List[int]],",
            "desired_num_tokens: Dict[str, int],",
            "-                         padding_lengths: Dict[str, int]) -> Dict[str, torch.Tensor]:  # pylint: disable=unused-argument",
            "+                         padding_lengths: Dict[str, int]) -> Dict[str, torch.Tensor]:",
            "return {key: torch.LongTensor(pad_sequence_to_length(val, desired_num_tokens[key]))",
            "for key, val in tokens.items()}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2214,
        "label": "no",
        "change": [
            "def make_pad_mask(lengths, xs=None, length_dim=-1, maxlen=None):",
            "if not isinstance(lengths, list):",
            "lengths = lengths.tolist()",
            "else:",
            "-        assert isinstance(lengths, torch.tensor), type(lengths)",
            "+        assert isinstance(lengths, torch.Tensor), type(lengths)",
            "lengths = lengths.long()",
            "",
            "bs = int(len(lengths))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2215,
        "label": "no",
        "change": [
            "class FAN(nn.Module):",
            "",
            "def forward(self, x):",
            "x = F.relu(self.bn1(self.conv1(x)), True)",
            "-        x = F.max_pool2d(self.conv2(x), 2)",
            "+        x = F.avg_pool2d(self.conv2(x), 2, stride=2)",
            "x = self.conv3(x)",
            "x = self.conv4(x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2216,
        "label": "no",
        "change": [
            "class DefaultClassifier(Classifier[DT], typing.Generic[DT, DT2]):",
            "else:",
            "self._multi_label_threshold = {\"default\": x}",
            "",
            "-    # def get_scores_and_labels(self, batch: List[DT]) -> Tuple[torch.Tensor, List[List[str]]]:",
            "-    #     batch = [dp for dp in batch if self._filter_data_point(dp)]",
            "-    #     predict_data_points = self._get_prediction_data_points(batch)",
            "-    #     labels = [self._get_label_of_datapoint(pdp) for pdp in predict_data_points]",
            "-    #     embedded_tensor = self._prepare_tensors(batch)",
            "-    #     logits = self._transform_embeddings(*embedded_tensor)",
            "-    #     return logits, labels",
            "-",
            "def _prepare_label_tensor(self, prediction_data_points: List[DT2]) -> torch.Tensor:",
            "labels = [self._get_label_of_datapoint(dp) for dp in prediction_data_points]",
            "if self.multi_label:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2218,
        "label": "no",
        "change": [
            "\"    new_src_mesh = src_mesh.offset_verts(deform_verts)\\n\",",
            "\"    \\n\",",
            "\"    # Add per vertex colors to texture the mesh\\n\",",
            "-    \"    new_src_mesh.textures = TexturesVertex(verts_rgb=sphere_verts_rgb) \\n\",",
            "+    \"    new_src_mesh.textures = TexturesVertex(verts_features=sphere_verts_rgb) \\n\",",
            "\"    \\n\",",
            "\"    # Losses to smooth /regularize the mesh shape\\n\",",
            "\"    loss = {k: torch.tensor(0.0, device=device) for k in losses}\\n\","
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2224,
        "label": "no",
        "change": [
            "class TestTubeLogger(LightningLoggerBase):",
            "",
            "@property",
            "def experiment(self):",
            "+        r\"\"\"",
            "+",
            "+          Actual test-tube object. To use test-tube features do the following.",
            "+",
            "+          Example::",
            "+",
            "+              self.logger.experiment.some_test_tube_function()",
            "+",
            "+          \"\"\"",
            "+",
            "if self._experiment is not None:",
            "return self._experiment"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2225,
        "label": "no",
        "change": [
            "def main():",
            "np.random.seed(args.seed)",
            "",
            "if args.backend == \"pytorch\":",
            "-        from espnet.tts.pytorch.tts_pytorch import train",
            "+        from espnet.tts.pytorch.tts import train",
            "train(args)",
            "else:",
            "raise NotImplementedError(\"Only pytorch is supported.\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2227,
        "label": "no",
        "change": [
            "class DefaultClassifier(Classifier[DT], typing.Generic[DT]):",
            "progress_bar.set_description(\"Batch inference\")",
            "dataloader = progress_bar",
            "",
            "-            overall_loss = 0",
            "+            overall_loss = torch.zeros(1, device=flair.device)",
            "label_count = 0",
            "for batch in dataloader:",
            "# stop if all sentences are empty"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2228,
        "label": "no",
        "change": [
            "class DoublePrecisionPlugin(PrecisionPlugin):",
            "incoming floating point data to double (``torch.float64``) precision. Does not alter `optimizers` or",
            "`lr_schedulers`.",
            "\"\"\"",
            "-        model = cast(pl.LightningModule, model.to(dtype=torch.float64))",
            "+        model = cast(pl.LightningModule, model.double())",
            "model = LightningDoublePrecisionModule(model)",
            "",
            "return super().connect(model, optimizers, lr_schedulers)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2229,
        "label": "no",
        "change": [
            "class SolverWrapper(object):",
            "",
            "last_snapshot_iter = -1",
            "timer = Timer()",
            "-        tf.Graph.finalize(tf.get_default_graph())",
            "+        #tf.Graph.finalize(tf.get_default_graph())",
            "# for iter in range(max_iters):",
            "for iter in range(restore_iter, max_iters):",
            "timer.tic()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2230,
        "label": "no",
        "change": [
            "logger = logging.getLogger(__name__)",
            "",
            "def get_cell_fun(cell_type):",
            "if cell_type == 'rnn':",
            "-        cell_fn = tf2.keras.layers.SimpleRNNCell   # todo tf2 remove obsolete #tf.nn.rnn_cell.BasicRNNCell",
            "+        cell_fn = tf.nn.rnn_cell.BasicRNNCell  # todo tf2: do we eventually need tf2.keras.layers.SimpleRNNCell",
            "elif cell_type == 'lstm':",
            "# allows for optional peephole connections and cell clipping",
            "cell_fn = tf.nn.rnn_cell.LSTMCell"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2231,
        "label": "no",
        "change": [
            "class TestLegacyMatrixAttention(AllenNlpTestCase):",
            "",
            "def test_forward_works_on_simple_input(self):",
            "attention = LegacyMatrixAttention(DotProductSimilarity())",
            "-        sentence_1_tensor = Variable(torch.FloatTensor([[[1, 1, 1], [-1, 0, 1]]]))",
            "-        sentence_2_tensor = Variable(torch.FloatTensor([[[1, 1, 1], [-1, 0, 1], [-1, -1, -1]]]))",
            "+        sentence_1_tensor = torch.FloatTensor([[[1, 1, 1], [-1, 0, 1]]])",
            "+        sentence_2_tensor = torch.FloatTensor([[[1, 1, 1], [-1, 0, 1], [-1, -1, -1]]])",
            "result = attention(sentence_1_tensor, sentence_2_tensor).data.numpy()",
            "assert result.shape == (1, 2, 3)",
            "assert_allclose(result, [[[3, 0, -3], [0, 2, 0]]])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2233,
        "label": "yes",
        "change": [
            "class TileLayer(Layer):",
            "",
            "@deprecated_alias(layer='prev_layer', end_support_version=1.9)  # TODO remove this line for the 1.9 release",
            "def __init__(self, prev_layer, multiples=None, name='tile'):",
            "+",
            "super(TileLayer, self).__init__(prev_layer=prev_layer, name=name)",
            "",
            "logging.info(\"TileLayer  %s: multiples:%s\" % (name, multiples))",
            "",
            "-        self.inputs = prev_layer.outputs",
            "-",
            "with tf.variable_scope(name):",
            "self.outputs = tf.tile(self.inputs, multiples=multiples)",
            "",
            "-        self.all_layers.append(self.outputs)",
            "+        self._add_layers(self.outputs)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "removal",
        "Element": "api call"
    },
    {
        "number": 2234,
        "label": "yes",
        "change": [
            "class Trainer(",
            "if 'scheduler' not in scheduler:",
            "raise ValueError(f'Lr scheduler should have key `scheduler`',",
            "' with item being a lr scheduler')",
            "-                scheduler['reduce_on_plateau'] = \\",
            "-                    isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau)",
            "+                scheduler['reduce_on_plateau'] = isinstance(",
            "+                    scheduler['scheduler'], optim.lr_scheduler.ReduceLROnPlateau)",
            "",
            "lr_schedulers.append({**default_config, **scheduler})"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 2237,
        "label": "no",
        "change": [
            "class QueueInputTrainer(Trainer):",
            "kept_summaries[k] = copy.copy(tf.get_collection(k))",
            "logger.info(\"Graph built for tower {}.\".format(i))",
            "for k in coll_keys:",
            "-                del tf.get_collection(k)[:]",
            "-                tf.get_collection(k).extend(kept_summaries[k])",
            "+                del tf.get_collection_ref(k)[:]",
            "+                tf.get_collection_ref(k).extend(kept_summaries[k])",
            "grads = QueueInputTrainer._average_grads(grad_list)",
            "cost_var = cost_var_t0",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2239,
        "label": "no",
        "change": [
            "def run_api_experiment(input_features, output_features, data_csv):",
            "model_weights = get_weights(model.model)",
            "loaded_weights = get_weights(loaded_model.model)",
            "for model_weight, loaded_weight in zip(model_weights, loaded_weights):",
            "-            assert np.allclose(model_weight, loaded_weight)",
            "+            assert torch.allclose(model_weight, loaded_weight)",
            "finally:",
            "# Remove results/intermediate data saved to disk",
            "shutil.rmtree(output_dir, ignore_errors=True)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2240,
        "label": "no",
        "change": [
            "def test_tensorflow_dropout(",
            "),",
            "name=st.sampled_from([\"sigmoid_cross_entropy_with_logits\"]),",
            "num_positional_args=helpers.num_positional_args(",
            "-        fn_name=\"ivy.functional.frontends.tensorflow.sigmoid_cross_entropy_with_logits\",",
            "+        fn_name=\"ivy.functional.frontends.tensorflow.nn.sigmoid_cross_entropy_with_logits\",  # noqa",
            "),",
            ")",
            "def test_tensorflow_sigmoid_cross_entropy_with_logits("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2241,
        "label": "no",
        "change": [
            "def test_trainer_with_gpus_options_combination_at_available_gpus_env(auto_select",
            "[\"nb\", \"expected_gpu_idxs\", \"expected_error\"],",
            "[",
            "(0, [], MisconfigurationException),",
            "-        (-1, [i for i in range(torch.cuda.device_count())], None),",
            "+        (-1, list(range(torch.cuda.device_count())), None),",
            "(1, [0], None),",
            "],",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2242,
        "label": "no",
        "change": [
            "def anchor_target_single(flat_anchors,",
            "num_valid_anchors = anchors.shape[0]",
            "bbox_targets = torch.zeros_like(anchors)",
            "bbox_weights = torch.zeros_like(anchors)",
            "-    labels = anchors.new_zeros((num_valid_anchors, ))",
            "-    label_weights = anchors.new_zeros((num_valid_anchors, ))",
            "+    labels = gt_labels.new_zeros(num_valid_anchors)",
            "+    label_weights = gt_labels.new_zeros(num_valid_anchors, dtype=torch.float)",
            "",
            "pos_inds = sampling_result.pos_inds",
            "neg_inds = sampling_result.neg_inds"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2243,
        "label": "no",
        "change": [
            "class Layer(tf.Module, version_utils.LayerVersionSelector):",
            "kwargs_spec[key] = tf.nest.pack_sequence_as(kwarg, flat_specs)",
            "",
            "self._saved_model_inputs_spec = inputs_spec",
            "-    self._saved_model_arg_spec = ([inputs_spec] + args_spec, kwargs_spec)",
            "+    self._saved_model_arg_spec = ([inputs_spec] + list(args_spec), kwargs_spec)",
            "",
            "def _get_save_spec(self, dynamic_batch=True, inputs_only=True):",
            "if self._saved_model_inputs_spec is None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2244,
        "label": "no",
        "change": [
            "def transform(point, center, scale, resolution, invert=False):",
            "",
            "if invert:",
            "t = torch.inverse(t)",
            "-    new_point = (t @ _pt)[0:2]",
            "+",
            "+    new_point = (torch.matmul(t,_pt))[0:2]",
            "",
            "return new_point.int()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2246,
        "label": "no",
        "change": [
            "def einsum(",
            "*operands: Union[tf.Tensor, tf.Variable],",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "-    return tf.einsum(equation, *operands)",
            "\\ No newline at end of file",
            "+    return tf.einsum(equation, *operands)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2250,
        "label": "no",
        "change": [
            "def avg_pool1d(",
            "x = x.permute(0, 2, 1)",
            "x_shape = x.shape[2]",
            "pad_w = ivy.handle_padding(x_shape, strides[0], kernel[0], padding)",
            "-    x = torch.nn.functional.pad(",
            "-        x, [pad_w // 2, pad_w - pad_w // 2], mode=\"replicate\"",
            "-    )",
            "+    x = torch.nn.functional.pad(x, [pad_w // 2, pad_w - pad_w // 2], mode=\"replicate\")",
            "",
            "res = torch.nn.functional.avg_pool1d(x, kernel, strides, 0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2251,
        "label": "no",
        "change": [
            "def test_pow():",
            "def test_tensor_ops():",
            "pi = 3.141592654",
            "X = Uniform(0, 1).expand([5, 5]).rv",
            "-    a = tt([[1, 2, 3, 4, 5]])",
            "+    a = torch.tensor([[1, 2, 3, 4, 5]])",
            "b = a.T",
            "X = abs(pi*(-X + a - 3*b))",
            "x = X.dist.sample()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2256,
        "label": "no",
        "change": [
            "def _convert_string_dtype(dtype):",
            "",
            "",
            "def _to_tensor(x, dtype):",
            "-    x = tf.python.framework.ops.convert_to_tensor(x)",
            "+    x = tf.convert_to_tensor(x)",
            "if x.dtype != dtype:",
            "x = tf.cast(x, dtype)",
            "return x"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2257,
        "label": "no",
        "change": [
            "class FairseqDataset(torch.utils.data.Dataset, EpochListening):",
            "indices, ignored = data_utils._filter_by_size_dynamic(indices, self.size, max_sizes)",
            "return indices, ignored",
            "",
            "+    @property",
            "+    def supports_fetch_outside_dataloader(self):",
            "+        \"\"\"Whether this dataset supports fetching outside the workers of the dataloader.\"\"\"",
            "+        return True",
            "+",
            "",
            "class FairseqIterableDataset(torch.utils.data.IterableDataset, EpochListening):",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2258,
        "label": "no",
        "change": [
            "__all__ = ['ConcatWith']",
            "@layer_register(use_scope=False, log_shape=False)",
            "def ConcatWith(x, dim, tensor):",
            "\"\"\"",
            "-    A wrapper around `tf.concat` to support `LinearWrap`",
            "+    A wrapper around `tf.concat_v2` to support `LinearWrap`",
            ":param x: the input tensor",
            ":param dim: the dimension along which to concatenate",
            ":param tensor: a tensor or list of tensor to concatenate with x.",
            "x will be at the beginning",
            "-    :return: tf.concat(dim, [x] + [tensor])",
            "+    :return: tf.concat_v2([x] + [tensor], dim)",
            "\"\"\"",
            "if type(tensor) != list:",
            "tensor = [tensor]",
            "-    return tf.concat(dim, [x] + tensor)",
            "+    return tf.concat_v2([x] + tensor, dim)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2259,
        "label": "no",
        "change": [
            "class KarrasVeScheduler(SchedulerMixin, ConfigMixin):",
            ")",
            "for i in self.timesteps",
            "]",
            "-        self.schedule = torch.tensor(schedule, dtype=torch.float32)",
            "+        self.schedule = torch.tensor(schedule, dtype=torch.float32, device=device)",
            "",
            "def add_noise_to_input(",
            "self, sample: torch.FloatTensor, sigma: float, generator: Optional[torch.Generator] = None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2261,
        "label": "no",
        "change": [
            "def vector_norm(",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "if ord == -float(\"inf\"):",
            "tn_normalized_vector = tf.reduce_min(tf.abs(x), axis, keepdims)",
            "-    elif ord == -1:",
            "+    elif ord < 1:",
            "tn_normalized_vector = tf.reduce_sum(tf.abs(x) ** ord, axis, keepdims) ** (",
            "1.0 / ord",
            ")",
            "",
            "elif ord == 0:",
            "-        tn_normalized_vector = tf.reduce_sum(",
            "-            tf.cast(x != 0, \"float32\"), axis, keepdims",
            "-        ).numpy()",
            "+        tn_normalized_vector = tf.reduce_sum(tf.cast(x != 0, x.dtype), axis, keepdims)",
            "",
            "else:",
            "tn_normalized_vector = tf.linalg.norm(x, ord, axis, keepdims)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2263,
        "label": "no",
        "change": [
            "class AlbertModel(AlbertPreTrainedModel):",
            "",
            "extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)",
            "extended_attention_mask = extended_attention_mask.to(dtype=self.dtype)  # fp16 compatibility",
            "-        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0",
            "+        extended_attention_mask = (1.0 - extended_attention_mask) * torch.finfo(self.dtype).min",
            "head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)",
            "",
            "embedding_output = self.embeddings("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2264,
        "label": "yes",
        "change": [
            "class GenerationMixin:",
            "",
            "# First if `inputs_embeds` are given, but no `attention_mask` assume that full attention_mask is used",
            "if inputs_embeds is not None:",
            "-            return torch.ones((inputs_embeds.shape[0], inputs_embeds.shape[1]), dtype=torch.long)",
            "+            return torch.ones((inputs_embeds.shape[0], inputs_embeds.shape[1]), dtype=torch.long, device=self.device)",
            "",
            "# Otherwise, use `input_ids`",
            "is_pad_token_in_inputs_ids = (pad_token_id is not None) and (pad_token_id in input_ids)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 2268,
        "label": "no",
        "change": [
            "class FastSelfAttnFunc(torch.autograd.Function) :",
            "return outputs.detach()",
            "",
            "@staticmethod",
            "-    def backward(ctx, output_grads) :",
            "+    def backward(ctx, output_grads):",
            "heads_t,                                                        \\",
            "matmul2_results,                                                \\",
            "dropout_results,                                                \\"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2270,
        "label": "no",
        "change": [
            "def flatten(index, name=\"segmented_flatten\"):",
            "for _ in range(index.batch_dims, index.indices.shape.rank):",
            "offset = tf.expand_dims(offset, -1)",
            "",
            "-    indices = offset + index.indices",
            "+    indices = tf.cast(offset, index.indices.dtype) + index.indices",
            "return IndexMap(indices=tf.reshape(indices, [-1]), num_segments=index.num_segments * batch_size, batch_dims=0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2271,
        "label": "no",
        "change": [
            "class ZeroOneAdam(torch.optim.Optimizer):",
            "(self.size * self.divider)))",
            "state['server_chunk_size'] = state[",
            "'corrected_tensor_size'] // self.size",
            "-                    torch.cuda.empty_cache()",
            "+                    get_accelerator().empty_cache()",
            "state['worker_error'] = torch.zeros(state['corrected_tensor_size'],",
            "device=p.device)",
            "state['server_error'] = torch.zeros(state['server_chunk_size'],",
            "device=p.device)",
            "# Accumulation of momentum, i.e., the u variable in the 0/1 Adam paper",
            "state['momentum_accumulator'] = torch.zeros_like(p.data)",
            "-                    torch.cuda.empty_cache()",
            "+                    get_accelerator().empty_cache()",
            "# self.freeze_key = True",
            "if not self.initialize and dist.get_rank() == 0:",
            "print(\"Cupy Buffers Initialized Successfully.\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2272,
        "label": "no",
        "change": [
            "def get_dataset(name, sparse=True, cleaned=False):",
            "for i, data in enumerate(dataset):",
            "if data.num_nodes <= num_nodes:",
            "indices.append(i)",
            "-        dataset = dataset[torch.tensor(indices)]",
            "+        dataset = dataset.copy(torch.tensor(indices))",
            "",
            "if dataset.transform is None:",
            "dataset.transform = T.ToDense(num_nodes)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2273,
        "label": "no",
        "change": [
            "class CholeskyTransform(Transform):",
            "return isinstance(other, CholeskyTransform)",
            "",
            "def _call(self, x):",
            "-        return torch.cholesky(x)",
            "+        return torch.linalg.cholesky(x)",
            "",
            "def _inverse(self, y):",
            "return torch.matmul(y, torch.transpose(y, -2, -1))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2277,
        "label": "yes",
        "change": [
            "class MishActivation(nn.Module):",
            "",
            "def __init__(self):",
            "super().__init__()",
            "-        if version.parse(torch.__version__) < version.parse(\"1.9\"):",
            "+        if version.parse(version.parse(torch.__version__).base_version) < version.parse(\"1.9\"):",
            "self.act = self._mish_python",
            "else:",
            "self.act = nn.functional.mish"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 2278,
        "label": "yes",
        "change": [
            "def Aggregate(dim, dim_out):",
            "return nn.Sequential(",
            "nn.Conv2d(dim, dim_out, 3, padding = 1),",
            "ChanNorm(dim_out),",
            "-        nn.MaxPool2d(2)",
            "+        nn.MaxPool2d(3, stride = 2, padding = 1)",
            ")",
            "",
            "class Transformer(nn.Module):"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 2280,
        "label": "no",
        "change": [
            "class VonMisesKernel(nn.Module):",
            "frange = frange.reshape(-1, 1, 1)",
            "weights = torch.zeros([2 * n + 1])",
            "weights[: n + 1] = torch.sqrt(b_coeffs)",
            "-        weights[n + 1 :] = torch.sqrt(b_coeffs[1:])",
            "+        weights[n + 1:] = torch.sqrt(b_coeffs[1:])",
            "weights = weights.reshape(-1, 1, 1)",
            "self.register_buffer('emb0', emb0)",
            "self.register_buffer('frange', frange)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2281,
        "label": "no",
        "change": [
            "def evaluate(dataset):",
            "saver = tf.train.Saver(variables_to_restore)",
            "",
            "# Build the summary operation based on the TF collection of Summaries.",
            "-    summary_op = tf.merge_all_summaries()",
            "+    summary_op = tf.summary.merge_all()",
            "",
            "graph_def = tf.get_default_graph().as_graph_def()",
            "-    summary_writer = tf.train.SummaryWriter(FLAGS.eval_dir,",
            "+    summary_writer = tf.summary.FileWriter(FLAGS.eval_dir,",
            "graph_def=graph_def)",
            "",
            "while True:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2282,
        "label": "no",
        "change": [
            "def test_annotators_and_output_format(corenlp_client):",
            "\"\"\" Test setting the annotators and output_format \"\"\"",
            "ann = corenlp_client.annotate(FRENCH_DOC, properties=FRENCH_EXTRA_PROPS,",
            "annotators=\"tokenize,ssplit,mwt,pos\", output_format=\"json\")",
            "-    assert FRENCH_JSON_GOLD == ann",
            "+    assert ann == FRENCH_JSON_GOLD"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2283,
        "label": "no",
        "change": [
            "class ScalarMix(torch.nn.Module):",
            "return self.gamma * sum(pieces)",
            "",
            "else:",
            "-            mask_float = mask.float()",
            "-            broadcast_mask = mask_float.unsqueeze(-1)",
            "+            broadcast_mask = mask.unsqueeze(-1)",
            "input_dim = tensors[0].size(-1)",
            "-            num_elements_not_masked = torch.sum(mask_float) * input_dim",
            "+            num_elements_not_masked = torch.sum(mask) * input_dim",
            "",
            "pieces = []",
            "for weight, tensor in zip(normed_weights, tensors):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2285,
        "label": "no",
        "change": [
            "def get_last_checkpoint(path):",
            "key_file_names = [fn for fn in file_names if key in fn]",
            "if last_model is None and len(key_file_names) > 0:",
            "last_model = max(key_file_names, key=os.path.getctime)",
            "-            last_model_num = os.path.getctime(last_model)",
            "+            last_model_num = torch.load(last_model)['step']",
            "",
            "if last_model is not None:",
            "last_models[key] = last_model"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2286,
        "label": "yes",
        "change": [
            "def predict():",
            "if __name__ == \"__main__\":",
            "parser = argparse.ArgumentParser(description=\"Flask API exposing YOLOv5 model\")",
            "parser.add_argument(\"--port\", default=5000, type=int, help=\"port number\")",
            "-    args = parser.parse_args()",
            "+    opt = parser.parse_args()",
            "+",
            "+    # Fix known issue urllib.error.HTTPError 403: rate limit exceeded https://github.com/ultralytics/yolov5/pull/7210",
            "+    torch.hub._validate_not_a_forked_repo = lambda a, b, c: True",
            "",
            "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\", force_reload=True)  # force_reload to recache",
            "-    app.run(host=\"0.0.0.0\", port=args.port)  # debug=True causes Restarting with stat",
            "+    app.run(host=\"0.0.0.0\", port=opt.port)  # debug=True causes Restarting with stat"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "null reference error",
        "Action": "addition",
        "Element": "api condition check"
    },
    {
        "number": 2288,
        "label": "no",
        "change": [
            "def multinomial(",
            "samples_stack.append(indices)",
            "samples_flat = tf.stack(samples_stack)",
            "return tf.convert_to_tensor(",
            "-                tf.reshape(samples_flat, orig_probs_shape[:-1] + [num_samples]))",
            "+                tf.reshape(samples_flat, orig_probs_shape[:-1] + [num_samples])",
            "+            )",
            "else:",
            "if len(probs.numpy().shape) == 1:",
            "probs = tf.expand_dims(probs, axis=0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2289,
        "label": "yes",
        "change": [
            "def synthesis(model,",
            "style_mel = compute_style_mel(style_wav, ap, use_cuda)",
            "# preprocess the given text",
            "inputs = text_to_seqvec(text, CONFIG, use_cuda)",
            "-    speaker_id = speaker_id_var = torch.from_numpy(speaker_id).unsqueeze(0)",
            "+    speaker_id = np.asarray(speaker_id)",
            "+    speaker_id = torch.from_numpy(speaker_id).unsqueeze(0)",
            "if use_cuda:",
            "speaker_id.cuda()",
            "# synthesize voice",
            "decoder_output, postnet_output, alignments, stop_tokens = run_model(",
            "-        model, inputs, CONFIG, truncated, style_mel)",
            "+        model, inputs, speaker_id, CONFIG, truncated, style_mel)",
            "# convert outputs to numpy",
            "postnet_output, decoder_output, alignment = parse_outputs(",
            "postnet_output, decoder_output, alignments)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 2290,
        "label": "no",
        "change": [
            "for idx, data in enumerate(gen):",
            "avg_mem_usage += cur_usage",
            "count += 1",
            "tl.logging.info(",
            "-            \"[*] {} iteration: memory usage {:.2f}MB, consume time {:.4f}s\".format(",
            "-                idx, cur_usage / (1024 * 1024), consume_time",
            "+            \"[*] {} iteration: memory usage {:.2f}MB, consume time {:.4f}s, loss {:.4f}\".format(",
            "+                idx, cur_usage / (1024 * 1024), consume_time, loss",
            ")",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2292,
        "label": "yes",
        "change": [
            "class TorchHook:",
            "# 5. Put instead the hooked one",
            "setattr(torch_module, func, new_func)",
            "",
            "+        # Hard fix for PyTorch versions < 1.0.2",
            "+        syft.torch.apply_fix16922(self.torch)",
            "+",
            "torch_modules = syft.torch.torch_modules",
            "-        # torch_modules = {\"torch.nn.functional\": torch.nn.functional}",
            "",
            "for module_name, torch_module in torch_modules.items():",
            "for func in dir(torch_module):"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "null reference error",
        "Action": "addition",
        "Element": "api call"
    },
    {
        "number": 2297,
        "label": "no",
        "change": [
            "def test_num_nodes_size(FeatureStore, GraphStore):",
            "assert num_nodes(feature_store, graph_store, 'x') == 100",
            "",
            "# Infer num nodes and size from edges:",
            "-    xy = get_edge_index(100, 50, 20)",
            "+    xy = get_random_edge_index(100, 50, 20)",
            "graph_store.put_edge_index(xy, edge_type=('x', 'to', 'y'), layout='coo',",
            "size=(100, 50))",
            "assert num_nodes(feature_store, graph_store, 'y') == 50"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2299,
        "label": "no",
        "change": [
            "class ArrayField(Field[numpy.ndarray]):",
            "slicing_shape = slicing_shape + [0 for _ in range(len(max_shape) - len(self.array.shape))]",
            "slices = [slice(0, x) for x in slicing_shape]",
            "return_array[slices] = self.array",
            "-        tensor = Variable(torch.from_numpy(return_array), volatile=not for_training)",
            "+        tensor = torch.from_numpy(return_array)",
            "return tensor if cuda_device == -1 else tensor.cuda(cuda_device)",
            "",
            "@overrides"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2300,
        "label": "no",
        "change": [
            "def linspace_helper(start, stop, num, axis=None, *, dtype=None, device):",
            "else:",
            "res = [linspace_method(start, stp, num, device=device) for stp in stop]",
            "else:",
            "-        return linspace_method(start, stop, num, dtype=torch.float64, device=device)",
            "+        return linspace_method(start, stop, num, dtype=dtype, device=device)",
            "res = torch.cat(res, -1).reshape(sos_shape + [num])",
            "if axis is not None:",
            "res = torch.transpose(res, axis, -1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2302,
        "label": "no",
        "change": [
            "class Categorical(Distribution):",
            "# vs is an array, so the support must be of type array",
            "r_np = _vs.shape[0]",
            "c_np = _vs.shape[1]",
            "-                ix = np.expand_dims(np.arange(r_np), axis=1)",
            "-                b = torch.ones(r_np, 1)",
            "+                np.expand_dims(np.arange(r_np), axis=1)",
            "+                torch.ones(r_np, 1)",
            "return (_vs[np.arange(r_np), torch.Tensor(list(x)).numpy().astype(int)]",
            ".reshape(r_np, 1).tolist()",
            "for x in itertools.product(torch.arange(0, c_np), repeat=r_np))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2303,
        "label": "no",
        "change": [
            "class ATSSHead(AnchorHead):",
            "",
            "# map up to original set of anchors",
            "if unmap_outputs:",
            "+            inside_flags = inside_flags.type(torch.bool)",
            "num_total_anchors = flat_anchors.size(0)",
            "anchors = unmap(anchors, num_total_anchors, inside_flags)",
            "labels = unmap(labels, num_total_anchors, inside_flags)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2305,
        "label": "yes",
        "change": [
            "class AttentionTest(tf.test.TestCase, parameterized.TestCase):",
            "attention_layer.concat_score_weight = 1",
            "attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))",
            "attention_layer.scale = 2.",
            "-    actual = attention_layer._calculate_scores(query=q, key=k)",
            "+    actual = keras.backend.get_value(",
            "+            attention_layer._calculate_scores(query=q, key=k))",
            "",
            "# Expected tensor of shape [1, 1, 1].",
            "# expected000 = tanh(2*(1.1+1.6)) = 0.9999592018254402"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 2308,
        "label": "no",
        "change": [
            "class Trainer:",
            "iterator: Iterable[Dict[str, torch.Tensor]],",
            "reporter: SubReporter,",
            "options: TrainerOptions,",
            "+        distributed_option: DistributedOption,",
            ") -> None:",
            "assert check_argument_types()",
            "ngpu = options.ngpu",
            "no_forward_run = options.no_forward_run",
            "-        distributed = isinstance(model, torch.nn.parallel.DistributedDataParallel)",
            "+        distributed = distributed_option.distributed",
            "",
            "model.eval()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2309,
        "label": "no",
        "change": [
            "class TensorFlowEstimator(BaseEstimator):",
            "if not os.path.exists(saver_filename):",
            "raise ValueError(\"Restore folder doesn't contain saver defintion.\")",
            "with open(saver_filename) as fsaver:",
            "-                saver_def = tf.python.training.saver_pb2.SaverDef()",
            "+                saver_def = tf.python.training.saver.saver_pb2.SaverDef()",
            "text_format.Merge(fsaver.read(), saver_def)",
            "self._saver = tf.train.Saver(saver_def=saver_def)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2310,
        "label": "no",
        "change": [
            "def class_balanced_cross_entropy(pred, label, name='cross_entropy_loss'):",
            "eps = 1e-12",
            "loss_pos = -beta * tf.reduce_mean(y * tf.log(z + eps))",
            "loss_neg = (1. - beta) * tf.reduce_mean((1. - y) * tf.log(1. - z + eps))",
            "-    cost = tf.sub(loss_pos, loss_neg, name=name)",
            "+    cost = tf.subtract(loss_pos, loss_neg, name=name)",
            "return cost"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2311,
        "label": "no",
        "change": [
            "def compute_posterior_stats(X, Y, msq, lam, eta1, xisq, c, sigma, jitter=1.0e-4)",
            "std = ((var * vec.unsqueeze(-1)).sum(-2) * vec.unsqueeze(-1)).sum(-2).clamp(min=0.0).sqrt()",
            "",
            "active_quad_dims = (((mu - 4.0 * std) > 0.0) | ((mu + 4.0 * std) < 0.0)) & (mu.abs() > 1.0e-4).bool()",
            "-    active_quad_dims = active_quad_dims.nonzero()",
            "+    active_quad_dims = active_quad_dims.nonzero(as_tuple=False)",
            "",
            "active_quadratic_dims = np.stack([left_dims[active_quad_dims].data.numpy().flatten(),",
            "right_dims[active_quad_dims].data.numpy().flatten()], axis=1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2312,
        "label": "yes",
        "change": [
            "class TFPolicy(Policy):",
            "",
            "# TODO(rliaw): Can consider exposing these parameters",
            "self.sess = tf.Session(graph=self.g, config=tf.ConfigProto(",
            "-            intra_op_parallelism_threads=1, inter_op_parallelism_threads=2))",
            "+            intra_op_parallelism_threads=1, inter_op_parallelism_threads=2,",
            "+            gpu_options=tf.GPUOptions(allow_growth=True)))",
            "self.variables = ray.experimental.TensorFlowVariables(self.loss,",
            "self.sess)",
            "self.sess.run(tf.global_variables_initializer())"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 2315,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "l = FullyConnected('fc1', l, out_dim=512,",
            "b_init=tf.constant_initializer(0.1))",
            "# fc will have activation summary by default. disable for the output layer",
            "-        logits = FullyConnected('linear', l, out_dim=10, summary_activation=False,",
            "-                                nl=tf.identity)",
            "+        logits = FullyConnected('linear', l, out_dim=10, nl=tf.identity)",
            "prob = tf.nn.softmax(logits, name='output')",
            "",
            "y = one_hot(label, 10)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2316,
        "label": "no",
        "change": [
            "class QModel(DistributionModel):",
            "optimization = super(QModel, self).tf_optimization(states, internals, actions, terminal, reward)",
            "",
            "target_optimization = self.target_optimizer.minimize(",
            "-            time=self.time,",
            "+            time=self.timestep,",
            "variables=self.target_network.get_variables(),",
            "source_variables=self.network.get_variables()",
            ")",
            "",
            "-        return tf.group(optimization, target_optimization)",
            "\\ No newline at end of file",
            "+        return tf.group(optimization, target_optimization)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2317,
        "label": "no",
        "change": [
            "def get_adalam_default_config():",
            "'refit': True,  # Whether to perform refitting at the end of the RANSACs. Generally improves accuracy at the cost of runtime.   # noqa: E501",
            "'force_seed_mnn': True,  # Whether to consider only MNN for the purpose of selecting seeds. Generally improves accuracy at the cost of runtime.    # noqa: E501",
            "# You can provide a MNN mask in input to skip MNN computation and still get the improvement.",
            "-        'device': get_cuda_device_if_available(),  # Device to be used for running AdaLAM. Use GPU if available.   # noqa: E501",
            "+        'device': torch.device('cpu'),  # Device to be used for running AdaLAM. Use GPU if available.",
            "}",
            "return DEFAULT_CONFIG"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2319,
        "label": "no",
        "change": [
            "if is_torch_available():",
            "",
            "# TensorFlow",
            "if is_tf_available():",
            "-    logger.info(\"TensorFlow version {} available.\".format(tf.__version__))",
            "-",
            "from .modeling_tf_utils import TFPreTrainedModel, TFSharedEmbeddings, TFSequenceSummary",
            "from .modeling_tf_auto import (TFAutoModel, TFAutoModelForSequenceClassification, TFAutoModelForQuestionAnswering,",
            "TFAutoModelWithLMHead)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2321,
        "label": "no",
        "change": [
            "def gen_gaussian_target(heatmap, center, radius, k=1):",
            "masked_heatmap = heatmap[y - top:y + bottom, x - left:x + right]",
            "masked_gaussian = gaussian_kernel[radius - top:radius + bottom,",
            "radius - left:radius + right]",
            "-    out_heatmap = torch.zeros_like(heatmap)",
            "+    out_heatmap = heatmap",
            "torch.max(",
            "masked_heatmap,",
            "masked_gaussian * k,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2327,
        "label": "no",
        "change": [
            "X_train, y_train, X_val, y_val, X_test, y_test = \\",
            "tl.files.load_mnist_dataset(shape=(-1,784))",
            "# define placeholder",
            "x = tf.placeholder(tf.float32, shape=[None, 784], name='x')",
            "-y_ = tf.placeholder(",
            "-    tf.int64, shape=[",
            "-        None,",
            "-    ], name='y_')",
            "+y_ = tf.placeholder(tf.int64, shape=[None], name='y_')",
            "",
            "# define the network",
            "network = tl.layers.InputLayer(x, name='input')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2328,
        "label": "no",
        "change": [
            "class Upsample2D(nn.Module):",
            "else:",
            "hidden_states = F.interpolate(hidden_states, size=output_size, mode=\"nearest\")",
            "",
            "+        # If the input is bfloat16, we cast back to bfloat16",
            "+        if dtype == torch.bfloat16:",
            "+            hidden_states = hidden_states.to(dtype)",
            "+",
            "# TODO(Suraj, Patrick) - clean up after weight dicts are correctly renamed",
            "if self.use_conv:",
            "if self.name == \"conv\":"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2329,
        "label": "no",
        "change": [
            "if __name__ == \"__main__\":",
            "",
            "if args.cuda:",
            "torch.set_default_tensor_type(torch.cuda.FloatTensor)",
            "-        torch.multiprocessing.set_start_method(\"spawn\", force=True)",
            "",
            "main(args)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2330,
        "label": "no",
        "change": [
            "def EfficientNet(",
            "# normalize the input, we need to divide another sqrt(var) to match the",
            "# original implementation.",
            "# See https://github.com/tensorflow/tensorflow/issues/49930 for more details",
            "-    x = x / tf.math.sqrt(IMAGENET_STDDEV_RGB)",
            "+    x = layers.Rescaling(1. / tf.math.sqrt(IMAGENET_STDDEV_RGB))(x)",
            "",
            "x = layers.ZeroPadding2D(",
            "padding=imagenet_utils.correct_pad(x, 3),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2336,
        "label": "no",
        "change": [
            "def main_word2vec_basic():",
            "# transpose_b=True, normalized_embeddings is transposed before multiplication.",
            "",
            "# Step 5: Start training.",
            "-    print()",
            "-",
            "-    tl.layers.initialize_global_variables(sess)",
            "+    sess.run(tf.global_variables_initializer())",
            "if resume:",
            "print(\"Load existing model\" + \"!\" * 10)",
            "# Load from ckpt or npz file"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2338,
        "label": "no",
        "change": [
            "class SpearmanCorrelationTest(AllenNlpTestCase):",
            "predictions_labels_ = [(predictions1, labels1), (predictions2, labels2)]",
            "",
            "# Random binary mask",
            "-        mask = torch.randint(0, 2, size=(batch_size, num_labels), device=device)",
            "+        mask = torch.randint(0, 2, size=(batch_size, num_labels), device=device).bool()",
            "",
            "for predictions, labels in predictions_labels_:",
            "spearman_correlation.reset()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2340,
        "label": "no",
        "change": [
            "class WarmupLR(object):",
            "last_batch_iteration (int): The index of the last batch. Default: -1.",
            "Example:",
            ">>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)",
            "-            >>> scheduler = torch.optim.WarmupLR(optimizer)",
            "+            >>> scheduler = WarmupLR(optimizer)",
            ">>> data_loader = torch.utils.data.DataLoader(...)",
            ">>> for epoch in range(10):",
            ">>>     for batch in data_loader:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2341,
        "label": "yes",
        "change": [
            "def subtract(x1: torch.Tensor,",
            "promoted_type = torch.promote_types(x1.dtype, x2.dtype)",
            "x1 = x1.to(promoted_type)",
            "x2 = x2.to(promoted_type)",
            "-    return torch.subtract(x1, x2, out=out)",
            "+        return torch.subtract(x1, x2, out=out)",
            "+    return torch.subtract(x1, x2)",
            "",
            "",
            "def remainder(x1: torch.Tensor,"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 2343,
        "label": "no",
        "change": [
            "with tf.Graph().as_default():",
            "with tf.name_scope('CustomMonitor'):",
            "test_var = tf.reduce_sum(tf.cast(net, tf.float32), name=\"test_var\")",
            "test_const = tf.constant(32.0, name=\"custom_constant\")",
            "-",
            "-    # Define a train op",
            "+        # Define a train op",
            "trainop = tflearn.TrainOp(loss=loss, optimizer=optimizer,",
            "-                              validation_monitors=[test_var, test_const],",
            "-                              metric=accuracy, batch_size=128)",
            "+                            validation_monitors=[test_var, test_const],",
            "+                            metric=accuracy, batch_size=128)",
            "",
            "# Tensorboard logs stored in /tmp/tflearn_logs/. Using verbose level 2.",
            "trainer = tflearn.Trainer(train_ops=trainop,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2344,
        "label": "no",
        "change": [
            "class TFModel(Trainable, Inferable, metaclass=TfModelMeta):",
            "print('model saved')",
            "",
            "def get_checkpoint_state(self):",
            "-        return tf.train.get_checkpoint_state(Path(self.model_path).parent)",
            "+        return tf.train.get_checkpoint_state(self.model_path.parent)",
            "",
            "@check_path_exists('dir')",
            "@overrides"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2345,
        "label": "yes",
        "change": [
            "class GPTNeoForSequenceClassification(GPTNeoPreTrainedModel):",
            "f\"unexpected if using padding tokens in conjunction with `inputs_embeds.`\"",
            ")",
            "",
            "-        pooled_logits = logits[torch.arange(batch_size), sequence_lengths]",
            "+        pooled_logits = logits[torch.arange(batch_size, device=self.device), sequence_lengths]",
            "",
            "loss = None",
            "if labels is not None:"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 2348,
        "label": "no",
        "change": [
            "class TestHomographyWarper:",
            "",
            "# check functional api",
            "patch_dst_to_src_functional = kornia.homography_warp(",
            "-                patch_dst, torch.inverse(dst_homo_src_i), (height, width), align_corners=True)",
            "+                patch_dst, _torch_inverse_cast(dst_homo_src_i), (height, width), align_corners=True)",
            "",
            "assert_allclose(",
            "patch_dst_to_src, patch_dst_to_src_functional, atol=1e-4, rtol=1e-4)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2350,
        "label": "no",
        "change": [
            "class PipelineModule(nn.Module):",
            "mp_rank = self._grid.get_slice_parallel_rank()",
            "mp_world_size = self._grid.get_slice_parallel_world_size()",
            "",
            "-            sd_loader = SDLoaderFactory.get_sd_loader(model_ckpt_list, version=2.0)",
            "+            sd_loader = SDLoaderFactory.get_sd_loader(",
            "+                model_ckpt_list,",
            "+                version=2.0,",
            "+                checkpoint_engine=checkpoint_engine)",
            "load_path, checkpoint, _ = sd_loader.load(mp_world_size, mp_rank, module_key=None, is_pipe_parallel=True)",
            "",
            "layer.load_state_dict(checkpoint)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2354,
        "label": "no",
        "change": [
            "class ShapeAugmentedGamma(Gamma):",
            "self._unboost_x_cache = None, None",
            "",
            "def sample(self, sample_shape=torch.Size()):",
            "-        if sample_shape:",
            "-            raise ValueError(\"Arbitrary `sample_shape` not supported by ShapeAugmentedGamma class.\")",
            "-        x = self._rejection_gamma.sample()",
            "+        x = self._rejection_gamma.sample(sample_shape)",
            "boosted_x = x.clone()",
            "for i in range(self._boost):",
            "boosted_x *= (1 - x.new(x.shape).uniform_()) ** (1 / (i + self.alpha))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2358,
        "label": "no",
        "change": [
            "def main():",
            "np.random.seed(args.seed)",
            "",
            "if args.backend == \"pytorch\":",
            "-        fromespnet.lmpytorch.tts_pytorch import train",
            "+        from espnet.lmpytorch.tts_pytorch import train",
            "train(args)",
            "else:",
            "raise NotImplementedError(\"Only pytorch is supported.\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2359,
        "label": "no",
        "change": [
            "def serialize_model_as_bytecode(model):",
            "archive.addfile(tarinfo=info, fileobj=f)",
            "tf.io.gfile.rmtree(temp_dir)",
            "b.seek(0)",
            "-  return (asarray(memoryview(b.read())), )",
            "+  return (numpy.asarray(memoryview(b.read())), )"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2360,
        "label": "no",
        "change": [
            "class Entropy(Metric):",
            "_count = 1",
            "",
            "if is_distributed():",
            "-            count = torch.tensor(_count).to(device)",
            "+            count = torch.tensor(_count, device=device)",
            "dist.all_reduce(_entropy, op=dist.ReduceOp.SUM)",
            "dist.all_reduce(count, op=dist.ReduceOp.SUM)",
            "_count = count.item()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2361,
        "label": "no",
        "change": [
            "class PyrDown(nn.Module):",
            "input, self.kernel, self.border_type)",
            "",
            "# reject even rows and columns.",
            "-        out: torch.Tensor = x_blur[..., ::2, ::2]",
            "+        out: torch.Tensor = F.avg_pool2d(x_blur, 2,2)",
            "return out"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2363,
        "label": "no",
        "change": [
            "def choose_optimizer(policy, config):",
            "return torch.optim.Adam(",
            "params=policy.model.parameters(), lr=policy.cur_lr)",
            "else:",
            "-        return torch.optim.RMSProp(",
            "+        return torch.optim.RMSprop(",
            "params=policy.model.parameters(),",
            "lr=policy.cur_lr,",
            "weight_decay=config[\"decay\"],"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2368,
        "label": "no",
        "change": [
            "class ATSSAssigner(BaseAssigner):",
            "max_overlaps != -INF] = argmax_overlaps[max_overlaps != -INF] + 1",
            "",
            "if gt_labels is not None:",
            "-            assigned_labels = assigned_gt_inds.new_zeros((num_bboxes, ))",
            "+            assigned_labels = assigned_gt_inds.new_full((num_bboxes, ), -1)",
            "pos_inds = torch.nonzero(assigned_gt_inds > 0).squeeze()",
            "if pos_inds.numel() > 0:",
            "assigned_labels[pos_inds] = gt_labels["
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2372,
        "label": "no",
        "change": [
            "class Seq2seq(Model):",
            "for i in range(n_layer):",
            "if (i == 0):",
            "self.dec_layers.append(",
            "-                    tl.layers.",
            "-                    RNN(cell=cell_dec(units=n_units), in_channels=self.embedding_size, return_last_state=True)",
            "+                    tl.layers.RNN(",
            "+                        cell=cell_dec(units=n_units), in_channels=self.embedding_size, return_last_state=True",
            "+                    )",
            ")",
            "else:",
            "self.dec_layers.append("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2373,
        "label": "no",
        "change": [
            "class SelfMultiheadAttn(nn.Module):",
            "nn.init.xavier_uniform_(self.k_weight)",
            "nn.init.xavier_uniform_(self.v_weight)",
            "else:",
            "-            nn.init.xavier_uniform_(self.in_proj_weight)",
            "+            # in_proj_weight has shape [3 * hidden, hidden] but it should be",
            "+            # initialized like a [hidden, hidden] matrix.",
            "+            # sqrt(6 / (hidden + hidden)) / sqrt(6 / (3 * hidden + hidden)) = sqrt(2)",
            "+            # therefore xavier_uniform gain should be set to sqrt(2).",
            "+            nn.init.xavier_uniform_(self.in_proj_weight, gain=math.sqrt(2))",
            "nn.init.xavier_uniform_(self.out_proj_weight)",
            "if self.bias:",
            "if self.separate_qkv_params:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2374,
        "label": "no",
        "change": [
            "def main():",
            "",
            "for predict_dataset, task in zip(predict_datasets, tasks):",
            "# Removing the `label` columns because it contains -1 and Trainer won't like that.",
            "-            predict_dataset.remove_columns_(\"label\")",
            "+            predict_dataset = predict_dataset.remove_columns(\"label\")",
            "predictions = trainer.predict(predict_dataset, metric_key_prefix=\"predict\").predictions",
            "predictions = np.squeeze(predictions) if is_regression else np.argmax(predictions, axis=1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2375,
        "label": "no",
        "change": [
            "def main():",
            "# Save a trained model",
            "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self",
            "output_model_file = os.path.join(args.output_dir, \"pytorch_model.bin\")",
            "-    torch.save(model_to_save.state_dict(), output_model_file)",
            "+    if args.do_train:",
            "+        torch.save(model_to_save.state_dict(), output_model_file)",
            "",
            "# Load a trained model that you have fine-tuned",
            "model_state_dict = torch.load(output_model_file)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2376,
        "label": "yes",
        "change": [
            "def attempt_load(weights, map_location=None, inplace=True):",
            "# Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a",
            "model = Ensemble()",
            "for w in weights if isinstance(weights, list) else [weights]:",
            "-        attempt_download(w)",
            "-        ckpt = torch.load(w, map_location=map_location)  # load",
            "+        ckpt = torch.load(attempt_download(w), map_location=map_location)  # load",
            "model.append(ckpt['ema' if ckpt.get('ema') else 'model'].float().fuse().eval())  # FP32 model",
            "",
            "# Compatibility updates"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 2377,
        "label": "no",
        "change": [
            "def decompose_essential_matrix(E_mat: torch.Tensor) -> Tuple[torch.Tensor, torch",
            "raise AssertionError(E_mat.shape)",
            "",
            "# decompose matrix by its singular values",
            "-    U, S, V = torch.svd(E_mat)",
            "+    U, _, V = torch.svd(E_mat)",
            "Vt = V.transpose(-2, -1)",
            "",
            "mask = torch.ones_like(E_mat)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2379,
        "label": "no",
        "change": [
            "class TorchHook:",
            "# 5. Put instead the hooked one",
            "setattr(torch_module, func, new_func)",
            "",
            "-        # Hard fix for PyTorch versions < 1.0.2",
            "-        syft.torch.apply_fix16922(self.torch)",
            "-",
            "torch_modules = syft.torch.torch_modules",
            "",
            "for module_name, torch_module in torch_modules.items():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2380,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "l = tf.nn.dropout(l, keep_prob)",
            "l = FullyConnected('fc7', l, 4096)",
            "l = tf.nn.dropout(l, keep_prob)",
            "-        logits = FullyConnected('fc8', l, out_dim=1000, summary_activation=False, nl=tf.identity)",
            "+        logits = FullyConnected('fc8', l, out_dim=1000, nl=tf.identity)",
            "prob = tf.nn.softmax(logits, name='output')",
            "",
            "y = one_hot(label, 1000)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2381,
        "label": "no",
        "change": [
            "def stats(policy, train_batch):",
            "",
            "def grad_stats(policy, train_batch, grads):",
            "return {",
            "-        \"grad_gnorm\": tf.global_norm(grads),",
            "+        \"grad_gnorm\": tf.linalg.global_norm(grads),",
            "}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2384,
        "label": "no",
        "change": [
            "def preprocess_for_eval(image, output_height, output_width):",
            "resized_image = tf.image.resize_image_with_crop_or_pad(image,",
            "output_width,",
            "output_height)",
            "-  tf.image_summary('resized_image', tf.expand_dims(resized_image, 0))",
            "+  tf.summary.image('resized_image', tf.expand_dims(resized_image, 0))",
            "",
            "# Subtract off the mean and divide by the variance of the pixels.",
            "return tf.image.per_image_whitening(resized_image)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2385,
        "label": "no",
        "change": [
            "def execute_with_gradients(func, xs, retain_grads=False):",
            "else:",
            "y = func_ret",
            "rest = tuple()",
            "-    x_grads_flat = _mx.autograd.grad(y, retain_graph=retain_grads, variables=[v for k, v in xs.to_iterator()])",
            "+    x_grads_flat = _mx.autograd.grad(y, [v for k, v in xs.to_iterator()], retain_graph=retain_grads,",
            "+                                     create_graph=retain_grads)",
            "return (y, xs.from_flat_list(x_grads_flat), *rest)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2386,
        "label": "yes",
        "change": [
            "class Wavegrad(nn.Module):",
            "self.noise_level = self.noise_level.to(y_0)",
            "if len(y_0.shape) == 3:",
            "y_0 = y_0.squeeze(1)",
            "-        s = torch.randint(1, self.num_steps + 1, [y_0.shape[0]])",
            "-        l_a, l_b = self.noise_level[s-1], self.noise_level[s]",
            "+        s = torch.randint(0, self.num_steps - 1, [y_0.shape[0]])",
            "+        l_a, l_b = self.noise_level[s], self.noise_level[s+1]",
            "noise_scale = l_a + torch.rand(y_0.shape[0]).to(y_0) * (l_b - l_a)",
            "noise_scale = noise_scale.unsqueeze(1)",
            "noise = torch.randn_like(y_0)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 2387,
        "label": "no",
        "change": [
            "class CategoricalToNumerical(block_module.Block):",
            "encoding.append(keras_layers.INT)",
            "else:",
            "encoding.append(keras_layers.NONE)",
            "-        return keras_layers.CategoricalEncoding(encoding)(input_node)",
            "+        return keras_layers.MultiColumnCategoricalEncoding(encoding)(input_node)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2388,
        "label": "no",
        "change": [
            "class Trainer(TrainerIO):",
            "# clip gradients",
            "if self.gradient_clip > 0:",
            "model = self.__get_model()",
            "-                torch.nn.utils.clip_grad_norm(model.parameters(), self.gradient_clip)",
            "+                torch.nn.utils.clip_grad_norm_(model.parameters(), self.gradient_clip)",
            "",
            "# update gradients across all optimizers",
            "for optimizer in self.optimizers:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2390,
        "label": "no",
        "change": [
            "def conv(inpOp, nIn, nOut, kH, kW, dH, dW, padType, prefix, phase_train=True, us",
            "global parameters",
            "name = prefix + '_' + str(conv_counter)",
            "conv_counter += 1",
            "-  with tf.variable_scope(name) as scope:",
            "+  with tf.variable_scope(name):",
            "l2_regularizer = lambda t: l2_loss(t, weight=4e-5)",
            "kernel = tf.get_variable(\"weights\", [kH, kW, nIn, nOut],",
            "initializer=tf.truncated_normal_initializer(stddev=1e-1),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2391,
        "label": "no",
        "change": [
            "class AbsTask(ABC):",
            ")",
            "model.to(device)",
            "if model_file is not None:",
            "+            if device == \"cuda\":",
            "+                # NOTE(kamo): \"cuda\" for torch.load always indicates cuda:0",
            "+                #   in PyTorch<=1.4",
            "+                device = f\"cuda:{torch.cuda.current_device()}\"",
            "model.load_state_dict(torch.load(model_file, map_location=device))",
            "",
            "return model, args"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2392,
        "label": "no",
        "change": [
            "def main():",
            "'tensorflow-variable-single-summary': tensorflow_variable_single,",
            "'tensorflow-variable-multi-summary': tensorflow_variable_multi,",
            "",
            "-            'graph-summary': graph,",
            "+            #'graph-summary': graph,",
            "})",
            "",
            "#history.add({"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2395,
        "label": "no",
        "change": [
            "class SpatialSoftArgmax2d(nn.Module):",
            "",
            "# compute softmax with max substraction trick",
            "exp_x = torch.exp(x - torch.max(x, dim=-1, keepdim=True)[0])",
            "-        exp_x_sum = 1.0 / (exp_x.sum(dim=-1, keepdim=True) + self.eps)",
            "+        exp_x_sum = torch.tensor(",
            "+            1.0) / (exp_x.sum(dim=-1, keepdim=True) + self.eps)",
            "",
            "# create coordinates grid",
            "pos_y, pos_x = create_meshgrid(input, self.normalized_coordinates)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2396,
        "label": "no",
        "change": [
            "class LayoutLMv2Output(nn.Module):",
            "self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)",
            "self.dropout = nn.Dropout(config.hidden_dropout_prob)",
            "",
            "-    def forward(self, hidden_states, input_tensor):",
            "+    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:",
            "hidden_states = self.dense(hidden_states)",
            "hidden_states = self.dropout(hidden_states)",
            "hidden_states = self.LayerNorm(hidden_states + input_tensor)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2397,
        "label": "no",
        "change": [
            "def model_batch_norm(x, y_, reuse, is_train):",
            "net = FlattenLayer(net, name='flatten')  # output: (batch_size, 2304)",
            "net = DenseLayer(net, 384, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='d1relu')",
            "net = DenseLayer(net, 192, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='d2relu')",
            "-        net = DenseLayer(net, 10, act=tf.identity, W_init=W_init2, name='output')",
            "+        net = DenseLayer(net, 10, act=None, W_init=W_init2, name='output')",
            "y = net.outputs",
            "",
            "ce = tl.cost.cross_entropy(y, y_, name='cost')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2399,
        "label": "no",
        "change": [
            "class Manga(InpaintModel):",
            "",
            "mask = torch.from_numpy(mask[np.newaxis, :, :, :]).to(self.device)",
            "mask = mask.permute(0, 3, 1, 2)",
            "-        mask = torch.where(mask > 0.5, torch.tensor(1.0), torch.tensor(0.0))",
            "+        mask = torch.where(mask > 0.5, 1.0, 0.0)",
            "noise = torch.randn_like(mask)",
            "",
            "gray_img = gray_img / 255 * 2 - 1.0"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2402,
        "label": "no",
        "change": [
            "class TFAlbertForPreTraining(TFAlbertPreTrainedModel, TFAlbertPreTrainingLoss):",
            ">>> import tensorflow as tf",
            ">>> from transformers import AlbertTokenizer, TFAlbertForPreTraining",
            "",
            "-        >>> tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')",
            "-        >>> model = TFAlbertForPreTraining.from_pretrained('albert-base-v2')",
            "+        >>> tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")",
            "+        >>> model = TFAlbertForPreTraining.from_pretrained(\"albert-base-v2\")",
            "",
            "-        >>> input_ids = tf.constant(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True))[None, :]  # Batch size 1",
            "+        >>> input_ids = tf.constant(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True))[",
            "+        ...     None, :",
            "+        >>> ]  # Batch size 1",
            ">>> outputs = model(input_ids)",
            "",
            ">>> prediction_logits = outputs.prediction_logits"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2409,
        "label": "no",
        "change": [
            "class TFTokenClassificationLoss:",
            "# make sure only labels that are not equal to -100",
            "# are taken into account as loss",
            "if tf.math.reduce_any(labels == -1):",
            "-            warnings.warn(\"Using `-1` to mask the loss for the token is deprecated. Please use `-100` instead.\")",
            "+            tf.print(\"Using `-1` to mask the loss for the token is deprecated. Please use `-100` instead.\")",
            "active_loss = tf.reshape(labels, (-1,)) != -1",
            "else:",
            "active_loss = tf.reshape(labels, (-1,)) != -100"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2410,
        "label": "yes",
        "change": [
            "from copy import deepcopy",
            "",
            "import numpy as np",
            "import torch",
            "-from torch.cuda import amp",
            "",
            "from utils.general import LOGGER, colorstr",
            "from utils.torch_utils import profile",
            "",
            "",
            "-def check_train_batch_size(model, imgsz=640):",
            "+def check_train_batch_size(model, imgsz=640, amp=True):",
            "# Check YOLOv5 training batch size",
            "-    with amp.autocast():",
            "+    with torch.cuda.amp.autocast(amp):",
            "return autobatch(deepcopy(model).train(), imgsz)  # compute optimal batch size"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 2411,
        "label": "no",
        "change": [
            "def test_tacotron2_trainable(n_speakers, n_chars, max_input_length, max_mel_leng",
            "post_mel_preds, \\",
            "stop_preds, \\",
            "alignment_history = model(input_ids,",
            "-                                          tf.constant([max_mel_length, max_mel_length]),",
            "+                                          tf.constant([max_input_length, max_input_length]),",
            "speaker_ids,",
            "mel_outputs,",
            "-                                          mel_lengths)",
            "+                                          mel_lengths,",
            "+                                          training=True)",
            "loss_before = tf.keras.losses.MeanSquaredError()(mel_outputs, mel_preds)",
            "loss_after = tf.keras.losses.MeanSquaredError()(mel_outputs, post_mel_preds)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2412,
        "label": "yes",
        "change": [
            "def apply_grad_clipping(policy, optimizer, loss):",
            "",
            "",
            "def atanh(x):",
            "-    return 0.5 * torch.log((1 + x) / (1 - x))",
            "+    return 0.5 * torch.log(",
            "+        (1 + x).clamp(min=SMALL_NUMBER) / (1 - x).clamp(min=SMALL_NUMBER))",
            "",
            "",
            "def convert_to_non_torch_type(stats):"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 2413,
        "label": "no",
        "change": [
            "def randint(",
            "device: Optional[Union[ivy.Device, str]] = None,",
            ") -> Tensor:",
            "device = default_device(device)",
            "-    low = tf.cast(low, 'int64')",
            "-    high = tf.cast(high, 'int64')",
            "+    low = tf.cast(low, \"int64\")",
            "+    high = tf.cast(high, \"int64\")",
            "with tf.device(\"/\" + device.upper()):",
            "return tf.random.uniform(shape=shape, minval=low, maxval=high, dtype=tf.int64)",
            "",
            "-",
            "+",
            "def seed(seed_value: int = 0) -> None:",
            "tf.random.set_seed(seed_value)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2414,
        "label": "no",
        "change": [
            "def update_bn_ema(xn, batch_mean, batch_var,",
            "else:",
            "tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, update_op1)",
            "tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, update_op2)",
            "-        return xn",
            "+        return tf.identity(xn, name='output')",
            "",
            "",
            "def reshape_for_bn(param, ndims, chan, data_format):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2415,
        "label": "yes",
        "change": [
            "class Trainer(object):",
            "# convert logging_outputs to CPU to avoid unnecessary",
            "# device-to-host transfers in reduce_metrics",
            "logging_outputs = utils.apply_to_sample(",
            "-                lambda t: t.to(device='cpu', non_blocking=True),",
            "+                lambda t: t.to(device='cpu', non_blocking=True, dtype=torch.double),",
            "logging_outputs",
            ")"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 2416,
        "label": "no",
        "change": [
            "\"class SingleDenseLayerBlock(ak.Block):\\n\",",
            "\"    def build(self, hp, inputs=None):\\n\",",
            "\"        # Get the input_node from inputs.\\n\",",
            "-    \"        input_node = tf.python.util.nest.flatten(inputs)[0]\\n\",",
            "+    \"        input_node = tf.nest.flatten(inputs)[0]\\n\",",
            "\"        layer = tf.keras.layers.Dense(\\n\",",
            "\"            hp.Int(\\\"num_units\\\", min_value=32, max_value=512, step=32)\\n\",",
            "\"        )\\n\","
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2417,
        "label": "no",
        "change": [
            "class ConvBertSelfAttention(nn.Module):",
            "attention_scores = attention_scores + attention_mask",
            "",
            "# Normalize the attention scores to probabilities.",
            "-        attention_probs = torch.nn.functional.softmax(attention_scores, dim=-1)",
            "+        attention_probs = nn.functional.softmax(attention_scores, dim=-1)",
            "",
            "# This is actually dropping out entire tokens to attend to, which might",
            "# seem a bit unusual, but is taken from the original Transformer paper."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2418,
        "label": "no",
        "change": [
            "def batch_flatten(x):",
            "return tf.reshape(x, [-1, total_dim])",
            "",
            "def logSoftmax(x):",
            "-    with tf.variable_scope('logSoftmax'):",
            "+    with tf.op_scope([x], 'logSoftmax'):",
            "z = x - tf.reduce_max(x, 1, keep_dims=True)",
            "logprob = z - tf.log(tf.reduce_sum(tf.exp(z), 1, keep_dims=True))",
            "return logprob"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2419,
        "label": "no",
        "change": [
            "def load_tf_weights_in_gpt2(model, gpt2_checkpoint_path):",
            "import re",
            "",
            "import tensorflow as tf",
            "+        tf.enable_eager_execution()",
            "except ImportError:",
            "logger.error(",
            "\"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2420,
        "label": "no",
        "change": [
            "from ...utils.argtools import memoized_ignoreargs",
            "try:",
            "from tensorflow.models.rnn.ptb import reader as tfreader",
            "except ImportError:",
            "-    logger.warn_dependency('PennTreeBank', 'tensorflow')",
            "+    logger.warn_dependency('PennTreeBank', 'tensorflow.models.rnn.ptb.reader')",
            "__all__ = []",
            "else:",
            "__all__ = ['get_PennTreeBank']"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2422,
        "label": "no",
        "change": [
            "class NaturalGradient(Optimizer):",
            "# [delta*lambda] / lambda",
            "estimated_diffs = [diff / lagrange_multiplier for diff in diffs]",
            "# deriv(loss)^T * sum(delta)",
            "-            estimated_improvement = tf.add_n(inputs=[tf.reduce_sum(input_tensor=(grad * diff)) for grad, diff in zip(loss_gradient, estimated_diffs)])",
            "+            estimated_improvement = tf.add_n(inputs=[tf.reduce_sum(input_tensor=(grad * diff))",
            "+                                                     for grad, diff in zip(loss_gradient, estimated_diffs)])",
            "",
            "applied = self.apply_step(variables=variables, diffs=estimated_diffs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2423,
        "label": "no",
        "change": [
            "def emulate_int8_channel(w, scale=None, zero_point=None, bits=8):",
            "",
            "def emulate_int8_tensor(w, scale=None, zero_point=None, bits=8):",
            "if scale is None:",
            "-        obs = torch.ao.quantization.observer.MinMaxObserver()",
            "+        obs = quantization.observer.MinMaxObserver()",
            "obs.to(device=w.device)",
            "_ = obs(w)",
            "scale, zero_point = obs.calculate_qparams()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2424,
        "label": "no",
        "change": [
            "def test_heterogeneous_dataloader(num_workers):",
            "data = HeteroData()",
            "data['p'].x = torch.randn(100, 128)",
            "data['a'].x = torch.randn(200, 128)",
            "-    data['p', 'a'].edge_index = get_edge_index(100, 200, 500)",
            "+    data['p', 'a'].edge_index = get_random_edge_index(100, 200, 500)",
            "data['p'].edge_attr = torch.randn(500, 32)",
            "-    data['a', 'p'].edge_index = get_edge_index(200, 100, 400)",
            "+    data['a', 'p'].edge_index = get_random_edge_index(200, 100, 400)",
            "data['a', 'p'].edge_attr = torch.randn(400, 32)",
            "",
            "loader = DataLoader([data, data, data, data], batch_size=2, shuffle=False,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2428,
        "label": "yes",
        "change": [
            "def RegNet(",
            "in_channels = out_channels",
            "",
            "if include_top:",
            "-        x = Head(num_classes=classes)(x)",
            "imagenet_utils.validate_activation(classifier_activation, weights)",
            "+        x = Head(",
            "+            num_classes=classes,",
            "+            classifier_activation=classifier_activation,",
            "+            name=model_name,",
            "+        )(x)",
            "",
            "else:",
            "if pooling == \"avg\":"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 2430,
        "label": "no",
        "change": [
            "def is_torch_tf32_available():",
            "return False",
            "if int(torch.version.cuda.split(\".\")[0]) < 11:",
            "return False",
            "-    if version.parse(torch.__version__) < version.parse(\"1.7\"):",
            "+    if version.parse(version.parse(torch.__version__).base_version) < version.parse(\"1.7\"):",
            "return False",
            "",
            "return True"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2431,
        "label": "no",
        "change": [
            "class SegmentationModel(torch.nn.Module):",
            "if self.training:",
            "self.eval()",
            "",
            "-        with torch.no_grad():",
            "-            x = self.forward(x)",
            "+        x = self.forward(x)",
            "",
            "return x"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2433,
        "label": "no",
        "change": [
            "def binary_accuracy(y_true, y_pred, threshold=0.5):",
            "prediction values are 1 or 0.",
            "",
            "Returns:",
            "-    Binary accuracy values. shape = `[batch_size, d0, .. dN-1]`",
            "+    Binary accuracy values. shape = `[batch_size, d0, .. dN]`",
            "\"\"\"",
            "y_pred = tf.convert_to_tensor(y_pred)",
            "threshold = tf.cast(threshold, y_pred.dtype)",
            "y_pred = tf.cast(y_pred > threshold, y_pred.dtype)",
            "-  return backend.mean(tf.equal(y_true, y_pred), axis=-1)",
            "+  return tf.cast(tf.equal(y_true, y_pred), tf.int8)",
            "",
            "",
            "@keras_export('keras.metrics.categorical_accuracy')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2435,
        "label": "no",
        "change": [
            "def iinfo(type: Union[DType, str, tf.Tensor, tf.Variable]) -> np.iinfo:",
            "",
            "def result_type(",
            "*arrays_and_dtypes: Union[tf.Tensor, tf.Variable, tf.DType],",
            "-) -> tf.DType:",
            "+) -> ivy.Dtype:",
            "if len(arrays_and_dtypes) <= 1:",
            "return tf.experimental.numpy.result_type(arrays_and_dtypes)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2436,
        "label": "no",
        "change": [
            "class GaussianDiffusionContinuousTimes(nn.Module):",
            "self.num_timesteps = timesteps",
            "",
            "def get_times(self, batch_size, noise_level, *, device):",
            "-        return torch.full((batch_size,), noise_level, device = device, dtype = torch.long)",
            "+        return torch.full((batch_size,), noise_level, device = device, dtype = torch.float32)",
            "",
            "def sample_random_times(self, batch_size, max_thres = 0.999, *, device):",
            "return torch.zeros((batch_size,), device = device).float().uniform_(0, max_thres)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2437,
        "label": "no",
        "change": [
            "def var(",
            "tf.experimental.numpy.var(x, axis=axis, out=out, keepdims=keepdims),",
            "size / (size - correction),",
            "),",
            "-            dtype,",
            "+            x.dtype,",
            "copy=False,",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2438,
        "label": "no",
        "change": [
            "def get_variable(value,",
            "tf_name, initializer=value, dtype=dtype, trainable=trainable)",
            "elif framework == \"torch\" and torch_tensor is True:",
            "torch, _ = try_import_torch()",
            "-        var_ = torch.from_numpy(value).to(device)",
            "+        var_ = torch.from_numpy(value)",
            "+        if device:",
            "+            var_ = var_.to(device)",
            "var_.requires_grad = trainable",
            "return var_",
            "# torch or None: Return python primitive."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2440,
        "label": "no",
        "change": [
            "class PolarAdj(object):",
            "theta += (theta < 0).type_as(theta)",
            "polar = torch.stack([rho, theta], dim=1)",
            "",
            "-        # Modify data and return.",
            "-        data.adj = SparseTensor(index, polar, torch.Size([n, n, 2]))",
            "-        return data",
            "+        return SparseTensor(index, polar, torch.Size([n, n, 2]))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2443,
        "label": "no",
        "change": [
            "def fill_tensors(x, mask, y, padding_idx: int):",
            "x = expand_2d_or_3d_tensor(x, y.size(1), padding_idx)",
            "x[mask] = y",
            "elif x.size(1) > y.size(1):",
            "-        x[mask] = torch.tensor(padding_idx)",
            "+        x[mask] = torch.tensor(padding_idx).type_as(x)",
            "if x.dim() == 2:",
            "x[mask, :y.size(1)] = y",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2447,
        "label": "no",
        "change": [
            "class XLNetModel(XLNetPreTrainedModel):",
            "# Prepare outputs, we transpose back here to shape [bsz, len, hidden_dim] (cf. beginning of forward() method)",
            "output = output.permute(1, 0, 2).contiguous()",
            "",
            "-        # TODO Teven: fix this test to only use use_cache.",
            "if not use_cache:",
            "new_mems = None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2448,
        "label": "no",
        "change": [
            "from keras.datasets import mnist",
            "from autokeras import ImageClassifier",
            "-import tensorflow",
            "",
            "if __name__ == '__main__':",
            "-    print(tensorflow.__version__)",
            "(x_train, y_train), (x_test, y_test) = mnist.load_data()",
            "x_train = x_train.reshape(x_train.shape+(1,))",
            "x_test = x_test.reshape(x_test.shape+(1,))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2451,
        "label": "no",
        "change": [
            "class MyKerasRNN(RecurrentTFModelV2):",
            "shape=(None, obs_space.shape[0]), name=\"inputs\")",
            "state_in_h = tf.keras.layers.Input(shape=(cell_size, ), name=\"h\")",
            "state_in_c = tf.keras.layers.Input(shape=(cell_size, ), name=\"c\")",
            "-        seq_in = tf.keras.layers.Input(shape=(), name=\"seq_in\")",
            "+        seq_in = tf.keras.layers.Input(shape=(), name=\"seq_in\", dtype=tf.int32)",
            "",
            "# Preprocess observation with a hidden layer and send to LSTM cell",
            "dense1 = tf.keras.layers.Dense("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2453,
        "label": "no",
        "change": [
            "class TestElmoLstmCell(AllenNlpTestCase):",
            "input_tensor[1, 4:, :] = 0.0",
            "input_tensor[2, 2:, :] = 0.0",
            "input_tensor[3, 1:, :] = 0.0",
            "-        mask = torch.ones([4, 5])",
            "-        mask[1, 4:] = 0.0",
            "-        mask[2, 2:] = 0.0",
            "-        mask[3, 1:] = 0.0",
            "+        mask = torch.ones([4, 5]).bool()",
            "+        mask[1, 4:] = False",
            "+        mask[2, 2:] = False",
            "+        mask[3, 1:] = False",
            "",
            "lstm = ElmoLstm(",
            "num_layers=2,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2455,
        "label": "no",
        "change": [
            "class ENASLayer(nn.Module):",
            "nn.init.kaiming_normal_(self.final_conv_w)",
            "",
            "def forward(self, pprev, prev):",
            "-        pprev_, prev_ = self.preproc0(pprev), self.preproc1(prev)",
            "+        pprev_, prev_ = self.preproc0(pprev), self.preproc1(prev)",
            "",
            "prev_nodes_out = [pprev_, prev_]",
            "nodes_used_mask = torch.zeros(self.num_nodes + 2, dtype=torch.bool, device=prev.device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2456,
        "label": "no",
        "change": [
            "def vector_norm(",
            "elif ord == 0:",
            "tn_normalized_vector = tf.reduce_sum(tf.cast(x != 0, x.dtype), axis, keepdims)",
            "else:",
            "-        tn_normalized_vector = tf.reduce_sum(tf.abs(x) ** ord, axis, keepdims) ** (1.0 / ord)",
            "+        tn_normalized_vector = tf.reduce_sum(tf.abs(x) ** ord, axis, keepdims) ** (",
            "+            1.0 / ord",
            "+        )",
            "return tn_normalized_vector"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2458,
        "label": "no",
        "change": [
            "class SegmentationHead(nn.Sequential):",
            "",
            "",
            "class ClassificationHead(nn.Sequential):",
            "-",
            "def __init__(self, in_channels, classes, pooling=\"avg\", dropout=0.2, activation=None):",
            "if pooling not in (\"max\", \"avg\"):",
            "raise ValueError(\"Pooling should be one of ('max', 'avg'), got {}.\".format(pooling))",
            "-        pool = nn.AdaptiveAvgPool2d(1) if pooling == 'avg' else nn.AdaptiveMaxPool2d(1)",
            "+        pool = nn.AdaptiveAvgPool2d(1) if pooling == \"avg\" else nn.AdaptiveMaxPool2d(1)",
            "flatten = nn.Flatten()",
            "dropout = nn.Dropout(p=dropout, inplace=True) if dropout else nn.Identity()",
            "linear = nn.Linear(in_channels, classes, bias=True)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2461,
        "label": "yes",
        "change": [
            "class ModelPruning(Callback):",
            "def _wrap_pruning_fn(pruning_fn: Callable, **kwargs: Any) -> Callable:",
            "return partial(pruning_fn, **kwargs)",
            "",
            "-    def make_pruning_permanent(self, pl_module: LightningModule) -> None:",
            "+    def make_pruning_permanent(self, module: nn.Module) -> None:",
            "\"\"\"",
            "Removes pruning buffers from any pruned modules",
            "",
            "Adapted from https://github.com/pytorch/pytorch/blob/1.7.1/torch/nn/utils/prune.py#L1176-L1180",
            "\"\"\"",
            "-        for _, module in pl_module.named_modules():",
            "+        for _, module in module.named_modules():",
            "for k in list(module._forward_pre_hooks):",
            "hook = module._forward_pre_hooks[k]",
            "if isinstance(hook, pytorch_prune.BasePruningMethod):"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 2465,
        "label": "no",
        "change": [
            "torch_fxn_for_op : Dict[Op, Callable] = {**base_fxn_for_op, **{",
            "MovementOps.PAD: lambda x, padding: torch.nn.functional.pad(x, [item for sublist in padding[::-1] for item in sublist]),",
            "MovementOps.STRIDED: lambda x, arg: x.contiguous().as_strided([y[0] for y in arg], [y[1] for y in arg]),",
            "ProcessingOps.CONV: lambda x,w,C: C.px == C.px_ and C.py == C.py_ and torch.conv2d(x, w, stride=(C.sy, C.sx), groups=C.groups, dilation=(C.dy, C.dx), padding=(C.py, C.px)),",
            "-  FusedOps.MULACC: einsum_mulacc(torch.einsum, lambda x: x.stride())",
            "+  FusedOps.MULACC: einsum_mulacc(torch.einsum, lambda x: x.stride(), lambda x,s: x.expand(s))",
            "}}",
            "",
            "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else (\"mps\" if getenv(\"MPS\", 0) else \"cpu\"))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2466,
        "label": "yes",
        "change": [
            "class Standardize(Preprocessor):",
            "else:",
            "axes = tuple(range(1, util.rank(tensor)))",
            "",
            "-        mean, variance = tf.nn.moments(x=tensor, axes=axes)",
            "-        return (tensor - mean) / tf.maximum(x=variance, y=util.epsilon)",
            "+        mean, variance = tf.nn.moments(x=tensor, axes=axes, keep_dims=True)",
            "+        return (tensor - mean) / tf.maximum(x=tf.sqrt(variance), y=util.epsilon)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 2468,
        "label": "no",
        "change": [
            "class Auc(Metric):",
            "",
            "if mask is None:",
            "batch_size = gold_labels.shape[0]",
            "-            mask = torch.ones(batch_size, device=gold_labels.device)",
            "-        mask = mask.to(dtype=torch.bool)",
            "+            mask = torch.ones(batch_size, device=gold_labels.device).bool()",
            "",
            "self._all_predictions = self._all_predictions.to(predictions.device)",
            "self._all_gold_labels = self._all_gold_labels.to(gold_labels.device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2471,
        "label": "no",
        "change": [
            "class ListDataset(Dataset):",
            "if np.random.random() < 0.5:",
            "img, labels = horisontal_flip(img, labels)",
            "",
            "-        boxes = torch.zeros((len(labels), 6))",
            "-        boxes[:, 1:] = labels",
            "+        # Add dummy label if there are none",
            "+        num_labels = 1 if labels is None else len(labels)",
            "+        boxes = torch.zeros((num_labels, 6))",
            "+        if labels is not None:",
            "+            boxes[:, 1:] = labels",
            "",
            "return img_path, img, boxes"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2474,
        "label": "no",
        "change": [
            "class KnowledgeBaseEntityNormalizer(Component):",
            "Example:",
            ".. code:: python",
            "",
            "-            >>> from models.seq2seq_go_bot.kb import KnowledgeBase",
            "+            >>> from deeppavlov.models.seq2seq_go_bot.kb import KnowledgeBase",
            ">>> kb = KnowledgeBase(save_path=\"kb.json\", load_path=\"kb.json\", tokenizer=lambda strings: [s.split() for s in strings])",
            ">>> kb.fit(['person1'], [['name', 'hair', 'eyes']], [[{'name': 'Sasha', 'hair': 'long   dark', 'eyes': 'light blue '}]])",
            ">>> kb(['person1'])",
            "[[('sasha_name', ['Sasha']), ('sasha_hair', ['long', 'dark']), ('sasha_eyes', ['light','blue'])]]",
            "",
            "-            >>> from models.seq2seq_go_bot.kb import KnowledgeBaseEntityNormalizer",
            "+            >>> from deeppavlov.models.seq2seq_go_bot.kb import KnowledgeBaseEntityNormalizer",
            ">>> normalizer = KnowledgeBaseEntityNormalizer(denormalize=False, remove=False)",
            ">>> normalizer([[\"some\", \"guy\", \"with\", \"long\", \"dark\", \"hair\", \"said\", \"hi\"]], kb(['person1']))",
            "[['some', 'guy', 'with', 'sasha_hair', 'hair', 'said', 'hi']]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2475,
        "label": "no",
        "change": [
            "def softmax_rgb_blend(",
            "# Sum: weights * textures + background color",
            "weighted_colors = (weights[..., None] * colors).sum(dim=-2)",
            "weighted_background = (delta / denom) * background",
            "-    pix_colors[..., :3] = weighted_colors + weighted_background",
            "-    pix_colors[..., 3] = 1.0 - alpha",
            "+    pixel_colors[..., :3] = weighted_colors + weighted_background",
            "+    pixel_colors[..., 3] = 1.0 - alpha",
            "",
            "-    return torch.flip(pix_colors, [1])",
            "+    return pixel_colors"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2477,
        "label": "no",
        "change": [
            "class AccumGradOptimizer(ProxyOptimizer):",
            "grads_and_vars = FilterNoneGrad().process(grads_and_vars)",
            "vs = []",
            "for g, v in grads_and_vars:",
            "-            assert isinstance(g, tf.Tensor) and isinstance(v, tf.Variable), \\",
            "-                \"AccumGradOptimizer only works for dense update! \" \\",
            "-                \"Types of v and g are {} and {}\".format(type(v), type(g))",
            "+            assert isinstance(g, (tf.Tensor, tf.IndexedSlices)) and isinstance(v, tf.Variable), \\",
            "+                \"AccumGradOptimizer does not work for the gradient of {}! \" \\",
            "+                \"Types of v and g are {} and {}\".format(v.op.name, type(v), type(g))",
            "vs.append(v)",
            "",
            "with tf.control_dependencies(None):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2480,
        "label": "no",
        "change": [
            "class RNNTokenizer(nn.Module):",
            "",
            "pred1 = self.dense_clf2(inp2)",
            "",
            "-        pred = torch.cat([pred0[:,:,:1], pred0[:,:,2].unsqueeze(2) + pred1, pred0[:,:,3].unsqueeze(2)], 2)",
            "+        pred = torch.cat([pred0[:,:,:2], pred0[:,:,2].unsqueeze(2) + pred1, pred0[:,:,3].unsqueeze(2)], 2)",
            "",
            "return pred, []"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2482,
        "label": "no",
        "change": [
            "def forward_backward_func_template(",
            "assert isinstance(model, list)",
            "assert len(model) == (1 if virtual_pipeline_model_parallel_size is None else virtual_pipeline_model_parallel_size)",
            "_param_groups = _get_params_for_weight_decay_optimization(model)",
            "-    torch.optim.Adam(_param_groups)",
            "+    torch.optim.Adam(_param_groups, lr=1e-4)",
            "",
            "tensor_shape = [batch_size // parallel_state.get_data_parallel_world_size(), hidden_size]",
            "batch = (torch.randn(tensor_shape).cuda(),)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2483,
        "label": "no",
        "change": [
            "class Laplacian(nn.Module):",
            "torch.Size([2, 4, 5, 5])",
            "\"\"\"",
            "",
            "-    def __init__(self,",
            "-                 kernel_size: int, border_type: str = 'reflect',",
            "-                 normalized: bool = True) -> None:",
            "+    def __init__(self, kernel_size: int, border_type: str = 'reflect', normalized: bool = True) -> None:",
            "super(Laplacian, self).__init__()",
            "self.kernel_size: int = kernel_size",
            "self.border_type: str = border_type"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2485,
        "label": "no",
        "change": [
            "from nni.retiarii.trainer import PyTorchImageClassificationTrainer, PyTorchMulti",
            "from nni.retiarii.utils import import_",
            "",
            "def _load_mnist(n_models: int = 1):",
            "-    with open('converted_mnist_pytorch.json') as f:",
            "+    path = Path(__file__).parent / 'converted_mnist_pytorch.json'",
            "+    with open(path) as f:",
            "mnist_model = Model._load(json.load(f))",
            "if n_models == 1:",
            "return mnist_model"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2486,
        "label": "no",
        "change": [
            "class MultiHeadAttention(nn.Module):",
            "k, v = cache[self.layer_id]",
            "cache[self.layer_id] = (k, v)",
            "",
            "-        q = q / math.sqrt(dim_per_head)  # (bs, n_heads, qlen, dim_per_head)",
            "-        scores = torch.matmul(q, k.transpose(2, 3))  # (bs, n_heads, qlen, klen)",
            "+        scores = torch.matmul(q, k.transpose(2, 3)) / math.sqrt(dim_per_head)  # (bs, n_heads, qlen, klen)",
            "mask = (mask == 0).view(mask_reshape).expand_as(scores)  # (bs, n_heads, qlen, klen)",
            "scores.masked_fill_(mask, torch.finfo(scores.dtype).min)  # (bs, n_heads, qlen, klen)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2487,
        "label": "no",
        "change": [
            "class SeparableConv2dLayer(Layer):# Untested",
            "strides=strides, padding=padding, data_format=data_format,",
            "dilation_rate=dilation_rate, depth_multiplier=depth_multiplier, activation=act,",
            "use_bias=use_bias, depthwise_initializer=depthwise_initializer, pointwise_initializer=pointwise_initializer,",
            "-                 bias_initializer=tf.zeros_initializer(), depthwise_regularizer=None,",
            "+                 bias_initializer=bias_initializer, depthwise_regularizer=depthwise_regularizer,",
            "pointwise_regularizer=pointwise_regularizer, bias_regularizer=bias_regularizer, activity_regularizer=activity_regularizer,)",
            "#trainable=True, name=None, reuse=None)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2488,
        "label": "no",
        "change": [
            "def test_gen_aggregation(Aggregation, learn):",
            "ptr = torch.tensor([0, 2, 5, 6])",
            "",
            "aggr = Aggregation(learn=learn)",
            "-    assert str(aggr) == f'{Aggregation.__name__}()'",
            "+    assert str(aggr) == f'{Aggregation.__name__}(learn={learn})'",
            "",
            "out = aggr(x, index)",
            "assert out.size() == (3, x.size(1))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2489,
        "label": "no",
        "change": [
            "class TestBgrToGrayscale(BaseTester):",
            "], device=device, dtype=dtype)",
            "",
            "# Output data generated with OpenCV 4.1.1: cv2.cvtColor(img_np, cv2.COLOR_BGR2GRAY)",
            "-        expected = torch.tensor([",
            "+        expected = torch.tensor([[",
            "[0.4485849, 0.8233618, 0.6262833, 0.6218331, 0.6341921],",
            "[0.3200093, 0.4340172, 0.7107211, 0.5454938, 0.2801398],",
            "[0.6149265, 0.7018101, 0.3503231, 0.4891168, 0.5292346],",
            "[0.5096100, 0.4336508, 0.6704276, 0.4525143, 0.2134447],",
            "[0.7878902, 0.6494595, 0.5211386, 0.6623823, 0.6660464],",
            "-        ], device=device, dtype=dtype)",
            "+        ]], device=device, dtype=dtype)",
            "",
            "img_gray = kornia.bgr_to_grayscale(data)",
            "assert_allclose(img_gray, expected)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2490,
        "label": "no",
        "change": [
            "class InvConvNear(nn.Module):",
            "self.no_jacobian = no_jacobian",
            "self.weight_inv = None",
            "",
            "-        if LooseVersion(torch.__version__) < LooseVersion(\"1.9\"):",
            "+        if Version(torch.__version__) < Version(\"1.9\"):",
            "w_init = torch.qr(torch.FloatTensor(self.num_splits, self.num_splits).normal_())[0]",
            "else:",
            "w_init = torch.linalg.qr(torch.FloatTensor(self.num_splits, self.num_splits).normal_(), \"complete\")[0]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2491,
        "label": "no",
        "change": [
            "def convert_points_from_homogeneous(",
            "# set the results of division by zeror/near-zero to 1.0",
            "# follow the convention of opencv:",
            "# https://github.com/opencv/opencv/pull/14411/files",
            "+    mask_valid_points = torch.abs(z_vec) > eps",
            "scale: torch.Tensor = torch.where(",
            "-        torch.abs(z_vec) > eps,",
            "-        torch.tensor(1.) / z_vec,",
            "+        mask_valid_points,",
            "+        torch.tensor(1.) / z_vec.masked_fill(~mask_valid_points, eps),",
            "torch.ones_like(z_vec))",
            "",
            "return scale * points[..., :-1]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2492,
        "label": "no",
        "change": [
            "class TPUSpawnPlugin(DDPSpawnPlugin):",
            "self.tpu_local_core_rank = 0",
            "self.start_method = None",
            "",
            "-    def connect(self, model: torch.nn.Module) -> torch.nn.Module:",
            "+    def setup(self, model: torch.nn.Module) -> torch.nn.Module:",
            "self.create_mp_queue()",
            "-        self._model = model",
            "-        return self._model",
            "+        return self.model",
            "",
            "def create_mp_queue(self):",
            "self.start_method = 'fork'"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2499,
        "label": "no",
        "change": [
            "class GPTJForSequenceClassification(GPTJPreTrainedModel):",
            "\"unexpected if using padding tokens in conjunction with `inputs_embeds.`\"",
            ")",
            "",
            "-        pooled_logits = logits[torch.arange(batch_size, device=self.device), sequence_lengths]",
            "+        pooled_logits = logits[torch.arange(batch_size, device=logits.device), sequence_lengths]",
            "",
            "loss = None",
            "if labels is not None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2500,
        "label": "no",
        "change": [
            "class TFAlbertForSequenceClassification(TFAlbertPreTrainedModel):",
            "self.num_labels = config.num_labels",
            "",
            "self.albert = TFAlbertMainLayer(config, name=\"albert\")",
            "-        self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_prob)",
            "+        self.dropout = tf.keras.layers.Dropout(config.classifier_dropout_prob)",
            "self.classifier = tf.keras.layers.Dense(",
            "config.num_labels, kernel_initializer=get_initializer(config.initializer_range), name=\"classifier\"",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2502,
        "label": "no",
        "change": [
            "class AGP_Pruner(Pruner):",
            "if epoch > 0:",
            "self.now_epoch = epoch",
            "for wrapper in self.get_modules_wrapper():",
            "-                wrapper.if_calculated.copy_(torch.tensor(0)) # pylint: disable=not-callable",
            "+                wrapper.if_calculated = False",
            "",
            "class SlimPruner(Pruner):",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2508,
        "label": "no",
        "change": [
            "class Trainer:",
            "total_train_batch_size = (",
            "self.args.train_batch_size",
            "* self.args.gradient_accumulation_steps",
            "-                * (torch.distributed.get_world_size() if self.args.local_rank != -1 else 1),",
            "+                * (torch.distributed.get_world_size() if self.args.local_rank != -1 else 1)",
            ")",
            "logger.info(\"***** Running training *****\")",
            "logger.info(\"  Num examples = %d\", num_examples)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2511,
        "label": "yes",
        "change": [
            "def get_perspective_transform(src, dst):",
            "], dim=1)",
            "",
            "# solve the system Ax = b",
            "-    X, LU = torch.solve(b, A)",
            "+    X, LU = _torch_solve_cast(b, A)",
            "",
            "# create variable to return",
            "batch_size = src.shape[0]"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 2514,
        "label": "no",
        "change": [
            "class CheckGradient(MapGradient):",
            "super(CheckGradient, self).__init__(self._mapper)",
            "",
            "def _mapper(self, grad, var):",
            "-        # this is very slow...",
            "+        # this is very slow.... see #3649",
            "#op = tf.Assert(tf.reduce_all(tf.is_finite(var)), [var], summarize=100)",
            "-        grad = tf.check_numerics(grad, 'CheckGradient')",
            "+        grad = tf.check_numerics(grad, 'CheckGradient-' + var.op.name)",
            "return grad",
            "",
            "class ScaleGradient(MapGradient):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2519,
        "label": "no",
        "change": [
            "def cudnn_compatible_lstm(units, n_hidden, n_layers=1, trainable_initial_states=",
            "",
            "# Extract last states if they are provided",
            "if seq_lengths is not None:",
            "-                indices = tf.stack([tf.range(tf.shape(h)[0]), seq_lengths], axis=1)",
            "+                indices = tf.stack([tf.range(tf.shape(h)[0]), seq_lengths-1], axis=1)",
            "h_last = tf.gather_nd(h, indices)",
            "",
            "return h, (h_last, c_last)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2520,
        "label": "no",
        "change": [
            "class GeniePathLazy(torch.nn.Module):",
            "h = torch.zeros(1, x.shape[0], lstm_hidden).to(self.device)",
            "c = torch.zeros(1, x.shape[0], lstm_hidden).to(self.device)",
            "h_tmps = []",
            "-        for i, l in enumerate(self.breaths):",
            "-            h_tmps.append(self.breaths[i](x, edge_index))",
            "+        for i, l in enumerate(self.breadths):",
            "+            h_tmps.append(self.breadths[i](x, edge_index))",
            "x = x[None, :]",
            "for i, l in enumerate(self.depths):",
            "in_cat = torch.cat((h_tmps[i][None, :], x), -1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2521,
        "label": "no",
        "change": [
            "class LSHSelfAttention(nn.Module, EfficientAttentionMixin):",
            "\"\"\"",
            "length normalization",
            "\"\"\"",
            "-        variance = torch.mean(x ** 2, -1, keepdim=True)",
            "+        variance = torch.mean(x**2, -1, keepdim=True)",
            "norm_x = x * torch.rsqrt(variance + epsilon)",
            "return norm_x"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2523,
        "label": "yes",
        "change": [
            "class Estimator(CircularBuffer):",
            "x=tf.zeros_like(tensor=discounts, dtype=util.tf_dtype(dtype='float')),",
            "y=discounts",
            ")",
            "-            reward = reward + discounts * horizon_estimate",
            "+            reward = reward + discounts * tf.stop_gradient(input=horizon_estimate)",
            "# TODO: stop gradients?",
            "",
            "return reward"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 2525,
        "label": "no",
        "change": [
            "class TensorflowPredictor(Predictor):",
            "if feature_columns:",
            "data = data[feature_columns]",
            "data = data.values",
            "-        else:",
            "-            data = data[:, feature_columns]",
            "",
            "tensor = tf.convert_to_tensor(data, dtype=dtype)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2526,
        "label": "no",
        "change": [
            "def unique_values(",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "ret = tf.unique(tf.reshape(x, [-1]))[0]",
            "-    return ret",
            "+    return tf.sort(ret)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2527,
        "label": "no",
        "change": [
            "class ZeroPad2d(Layer):",
            "if not isinstance(padding, (int, tuple)):",
            "raise AssertionError(\"Padding should be of type `int` or `tuple`\")",
            "",
            "-        self.outputs = tf.keras.layers.ZeroPadding2D(padding=padding, name=name)(self.inputs)",
            "+        self.outputs = tf.keras.layers.ZeroPadding2D(padding=padding, name=name)(self.inputs)  # TODO: Stop using Keras",
            "+",
            "self._add_layers(self.outputs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2530,
        "label": "no",
        "change": [
            "class Result(Dict):",
            "else:",
            "tbptt_reduce_fx = meta[k]['tbptt_reduce_fx']",
            "",
            "+            if isinstance(value, list):",
            "+                value = torch.tensor(value)",
            "+",
            "if isinstance(value, dict):",
            "# TODO: recursive reduce:",
            "_recursive_fx_apply(value, tbptt_reduce_fx)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2532,
        "label": "no",
        "change": [
            "def motion_blur(",
            ">>> torch.allclose(out_1[0], out_1[1])",
            "True",
            ">>> # perform element-wise motion blur accross the batch",
            "-        >>> out_1 = motion_blur(input, 5, torch.tensor([90., 180,]), torch.tensor([1, -1]))",
            "+        >>> out_1 = motion_blur(input, 5, torch.tensor([90., 180,]), torch.tensor([1., -1.]))",
            ">>> torch.allclose(out_1[0], out_1[1])",
            "False",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2533,
        "label": "no",
        "change": [
            "class TFEncoderLayer(tf.keras.layers.Layer):",
            "super().__init__(**kwargs)",
            "",
            "self.multi_head_attention = TFMultiHeadAttention(d_model_size, num_heads, name=\"multi_head_attention\")",
            "-        self.ffn = point_wise_feed_forward_network(d_model_size, dff, name=\"ffn\")",
            "+        self.ffn = TFPointWiseFeedForwardLayer(d_model_size, dff, name=\"ffn\")",
            "",
            "self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=layer_norm_epsilon, name=\"layernorm1\")",
            "self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=layer_norm_epsilon, name=\"layernorm2\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2536,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "if nrpool != 0:  # pool + passthrough if nrpool == 0",
            "x4 = Conv2D('poolproj', x4, nrpool, 1)",
            "outs.append(x4)",
            "-                return tf.concat(3, outs, name='concat')",
            "+                return tf.concat_v2(outs, 3, name='concat')",
            "",
            "with argscope(Conv2D, nl=BNReLU, use_bias=False):",
            "l = Conv2D('conv0', image, 64, 7, stride=2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2540,
        "label": "no",
        "change": [
            "class _RPN(nn.Module):",
            "rpn_label_tmp = torch.index_select(rpn_label[i], 0, rpn_keep)",
            "rpn_label_v = Variable(rpn_label_tmp.long())",
            "",
            "-                fg_cnt = torch.sum(rpn_label_v.data.ne(0))",
            "+                fg_cnt += torch.sum(rpn_label_v.data.ne(0))",
            "",
            "self.rpn_loss_cls += F.cross_entropy(rpn_cls_score_single, rpn_label_v)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2541,
        "label": "no",
        "change": [
            "class TestStackedBidirectionalLstm:",
            ")",
            "encoder = Seq2VecEncoder.from_params(params)",
            "input_tensor = torch.rand(4, 5, 3)",
            "-        mask = torch.ones(4, 5)",
            "+        mask = torch.ones(4, 5).bool()",
            "output = encoder(input_tensor, mask)",
            "assert output.detach().numpy().shape == (4, 18)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2542,
        "label": "yes",
        "change": [
            "th = TorchHijackForUnet()",
            "",
            "# Below are monkey patches to enable upcasting a float16 UNet for float32 sampling",
            "def apply_model(orig_func, self, x_noisy, t, cond, **kwargs):",
            "-    for y in cond.keys():",
            "-        cond[y] = [x.to(devices.dtype_unet) if isinstance(x, torch.Tensor) else x for x in cond[y]]",
            "+",
            "+    if isinstance(cond, dict):",
            "+        for y in cond.keys():",
            "+            cond[y] = [x.to(devices.dtype_unet) if isinstance(x, torch.Tensor) else x for x in cond[y]]",
            "+",
            "with devices.autocast():",
            "return orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs).float()"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 2543,
        "label": "no",
        "change": [
            "def define_D(input_nc, ndf, which_model_netD,",
            "n_layers_D=3, use_sigmoid=False, gpu_ids=[]):",
            "netD = None",
            "use_gpu = len(gpu_ids) > 0",
            "-    assert(torch.cuda.is_available() == use_gpu)",
            "+    if use_gpu:",
            "+        assert(torch.cuda.is_available())",
            "+",
            "if which_model_netD == 'basic':",
            "netD = define_D(input_nc, ndf, 'n_layers', use_sigmoid=use_sigmoid, gpu_ids=gpu_ids)",
            "elif which_model_netD == 'n_layers':"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2552,
        "label": "no",
        "change": [
            "def linspace(start, stop, num, axis=None, dev_str=None):",
            "res = [linspace_method(start, stp, num, device=str_to_dev(dev_str)) for stp in stop]",
            "else:",
            "return linspace_method(start, stop, num, device=str_to_dev(dev_str))",
            "-    res = _torch.cat(res, -1).reshape(start_shape + [num])",
            "+    res = _torch.cat(res, -1).reshape(sos_shape + [num])",
            "if axis is not None:",
            "res = _torch.transpose(res, axis, -1)",
            "return res.to(str_to_dev(dev_str))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2555,
        "label": "no",
        "change": [
            "def test_add_bias_parity():",
            "k = torch.rand((seq_len, bsz, embedding))",
            "v = torch.rand((seq_len, bsz, embedding))",
            "",
            "-    k_orig, v_orig, kp_mask_orig, a_mask_orig = old_bias_code(k, v, key_padding_mask, attn_mask, bsz)",
            "-    k_new, v_new, kp_mask_new, a_mask_new = mha._add_bias(k, v, key_padding_mask, attn_mask, bsz)",
            "+    k_orig, v_orig, kp_mask_orig, a_mask_orig = old_bias_code(",
            "+        k, v, key_padding_mask, attn_mask, bsz",
            "+    )",
            "+    k_new, v_new, kp_mask_new, a_mask_new = mha._add_bias(",
            "+        k, v, key_padding_mask, attn_mask, bsz",
            "+    )",
            "",
            "assert torch.equal(k_orig, k_new)",
            "assert torch.equal(v_orig, v_new)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2558,
        "label": "no",
        "change": [
            "class LightningModule(ABC, DeviceDtypeModuleMixin, GradInformation, ModelIO, Mod",
            "#: True if using amp",
            "self.use_amp = False",
            "",
            "-        #: Current dtype",
            "-        self._dtype = torch.float",
            "-",
            "-        #: device reference",
            "-        self._device = torch.device('cpu')",
            "-",
            "# optionally can be set by user",
            "self._example_input_array = None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2561,
        "label": "no",
        "change": [
            "def get_data(train_or_test):",
            "imgaug.CenterPaste((40, 40)),",
            "imgaug.RandomCrop((32, 32)),",
            "imgaug.Flip(horiz=True),",
            "-            #imgaug.Brightness(20),",
            "-            #imgaug.Contrast((0.6,1.4)),",
            "imgaug.MapImage(lambda x: x - pp_mean),",
            "]",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2562,
        "label": "yes",
        "change": [
            "class RENet(torch.nn.Module):",
            "_, perm = logits.sort(dim=1, descending=True)",
            "mask = (y.view(-1, 1) == perm)",
            "",
            "-        mrr = (1 / (mask.nonzero()[:, -1] + 1).to(torch.float)).mean().item()",
            "+        nnz = mask.nonzero(as_tuple=False)",
            "+        mrr = (1 / (nnz[:, -1] + 1).to(torch.float)).mean().item()",
            "hits1 = mask[:, :1].sum().item() / y.size(0)",
            "hits3 = mask[:, :3].sum().item() / y.size(0)",
            "hits10 = mask[:, :10].sum().item() / y.size(0)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 2563,
        "label": "yes",
        "change": [
            "class GaussianChainTests(TestCase):",
            "(self.N, reparameterized, n_repa_nodes, self.N))",
            "if self.N < 0:",
            "def array_to_string(y):",
            "-                    return str(map(lambda x: \"%.3f\" % x.data.numpy()[0], y))",
            "+                    return str(map(lambda x: \"%.3f\" % x.data.cpu().numpy()[0], y))",
            "",
            "print(\"lambdas: \" + array_to_string(self.lambdas))",
            "print(\"target_mus: \" + array_to_string(self.target_mus[1:]))"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 2564,
        "label": "no",
        "change": [
            "class DenseBlock(nn.ModuleDict):",
            "",
            "",
            "class DenseTransition(nn.Sequential):",
            "-    def __init__(self, num_input_features, num_output_features, norm_layer=nn.BatchNorm2d, aa_layer=None):",
            "+    def __init__(self, num_input_features, num_output_features, norm_layer=BatchNormAct2d, aa_layer=None):",
            "super(DenseTransition, self).__init__()",
            "self.add_module('norm', norm_layer(num_input_features))",
            "self.add_module('conv', nn.Conv2d("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2565,
        "label": "yes",
        "change": [
            "class PANConv(MessagePassing):",
            "",
            "tmp = SparseTensor.eye(adj_t.size(0), adj_t.size(1), has_value=True,",
            "dtype=dtype, device=adj_t.device())",
            "-        tmp = tmp.mul_nnz(self.weight[0])",
            "+        tmp = tmp.mul_nnz(self.weight[0], layout='coo')",
            "",
            "outs = [tmp]",
            "for i in range(1, self.filter_size + 1):",
            "tmp = tmp @ adj_t",
            "-            tmp = tmp.mul_nnz(self.weight[i])",
            "+            tmp = tmp.mul_nnz(self.weight[i], layout='coo')",
            "outs += [tmp]",
            "",
            "row = torch.cat([out.storage.row() for out in outs], dim=0)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 2566,
        "label": "no",
        "change": [
            "},",
            "\"outputs\": [],",
            "\"source\": [",
            "-    \"# Evaluate combination of Reader and Retriever through Finder\\n\",",
            "\"# Evaluate combination of Reader and Retriever through Finder\\n\",",
            "\"finder_eval_results = finder.eval(top_k_retriever=1, top_k_reader=10, label_index=label_index, doc_index=doc_index)\\n\",",
            "\"finder.print_eval_results(finder_eval_results)\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2567,
        "label": "no",
        "change": [
            "import torch",
            "",
            "",
            "def one_hot(src, num_classes=None, dtype=None):",
            "+    src = src.to(torch.long)",
            "src = src.unsqueeze(-1) if src.dim() == 1 else src",
            "assert src.dim() == 2"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2568,
        "label": "no",
        "change": [
            "class NativeModel(tf.Module):",
            "self.dense = lambda inputs: tf.matmul(inputs, self.weights)",
            "",
            "@tf.function(",
            "-        input_signature=[tf.TensorSpec(shape=None, dtype=tf.float64, name=\"inputs\")]",
            "+        input_signature=[tf.TensorSpec(shape=[1, 5], dtype=tf.float64, name=\"inputs\")]",
            ")",
            "def __call__(self, inputs):",
            "return self.dense(inputs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2570,
        "label": "no",
        "change": [
            "def load_model(keras, wrap_optimizer, filepath, custom_optimizers, custom_object",
            "horovod_objects = {",
            "subclass.__name__.lower(): wrap_optimizer(subclass)",
            "for subclass in keras.optimizers.Optimizer.__subclasses__()",
            "-        if subclass.__module__ == 'keras.optimizers'",
            "+        if subclass.__module__ == keras.optimizers.Optimizer.__module__",
            "}",
            "",
            "if custom_optimizers is not None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2571,
        "label": "no",
        "change": [
            "import flair",
            "",
            "",
            "def main():",
            "-    print(\"## Versions:\")",
            "-    print(f\"### Flair\\n{flair.__version__}\")",
            "-    print(f\"### Pytorch\\n{torch.__version__}\")",
            "-    print(f\"### Transformers\\n{transformers.__version__}\")",
            "-    print(f\"## GPU\\n{torch.cuda.is_available()}\")",
            "+    print(\"#### Versions:\")",
            "+    print(f\"#### Flair\\n{flair.__version__}\")",
            "+    print(f\"#### Pytorch\\n{torch.__version__}\")",
            "+    print(f\"#### Transformers\\n{transformers.__version__}\")",
            "+    print(f\"#### GPU\\n{torch.cuda.is_available()}\")",
            "",
            "",
            "if __name__ == \"__main__\":"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2572,
        "label": "no",
        "change": [
            "class NaturalGradient(Optimizer):",
            "return estimated_delta",
            "",
            "# Natural gradient step only works if constant > 0",
            "-        skip_step = constant > tf.constant(value=0.0, dtype=util.tf_dtype(dtype='float'))",
            "+        epsilon = tf.constant(value=util.epsilon, dtype=util.tf_dtype(dtype='float'))",
            "+        skip_step = constant < (epsilon * learning_rate)",
            "return self.cond(pred=skip_step, true_fn=no_step, false_fn=apply_step)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2573,
        "label": "no",
        "change": [
            "class BlenderDatasetMapProvider(SingleSceneDatasetMapProviderBase):",
            ")",
            "H, W, focal = hwf",
            "H, W = int(H), int(W)",
            "-        images = torch.from_numpy(images)",
            "+        images = torch.from_numpy(images).permute(0, 3, 1, 2)[:, :3]",
            "",
            "# pyre-ignore[16]",
            "self.poses = _interpret_blender_cameras(poses, H, W, focal)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2575,
        "label": "no",
        "change": [
            "class BinaryConv2d(Layer):",
            "name=self.name",
            ")",
            "if self.b_init:",
            "-            outputs = tf.nn.bias_add(outputs, self.b, name='bias_add')",
            "+            outputs = tf.nn.bias_add(outputs, self.b, data_format=self.data_format, name='bias_add')",
            "if self.act:",
            "outputs = self.act(outputs)",
            "return outputs"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2577,
        "label": "no",
        "change": [
            "class HorovodTrainer(SingleCostTrainer):",
            "# broadcast_op should be the last setup_graph: it needs to be created",
            "# \"right before\" the graph is finalized,",
            "# because it needs to capture all the variables (which may be created by callbacks).",
            "-        self._num_global_variables = len(tf.global_variables())",
            "+        self._num_global_variables = len(tfv1 .global_variables())",
            "self._broadcast_op = self.hvd.broadcast_global_variables(0)",
            "",
            "# it's important that our NewSessionCreator does not finalize the graph"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2578,
        "label": "no",
        "change": [
            "writer.add_embedding(all_features, metadata=all_labels, label_img=all_images.uns",
            "",
            "# VIDEO",
            "vid_images = dataset.train_data[:16 * 48]",
            "-vid = vid_images.view(16, 1, 48, 28, 28)  # BxCxTxHxW",
            "+vid = vid_images.view(16, 48, 1, 28, 28)  # BxTxCxHxW",
            "",
            "writer.add_video('video', vid_tensor=vid)",
            "writer.add_video('video_1_fps', vid_tensor=vid, fps=1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2579,
        "label": "no",
        "change": [
            "class TFXLNetMainLayer(tf.keras.layers.Layer):",
            "",
            "\"\"\"",
            "attn_mask = tf.ones([qlen, qlen])",
            "-        mask_u = tf.matrix_band_part(attn_mask, 0, -1)",
            "-        mask_dia = tf.matrix_band_part(attn_mask, 0, 0)",
            "+        mask_u = tf.linalg.band_part(attn_mask, 0, -1)",
            "+        mask_dia = tf.linalg.band_part(attn_mask, 0, 0)",
            "attn_mask_pad = tf.zeros([qlen, mlen])",
            "ret = tf.concat([attn_mask_pad, mask_u - mask_dia], 1)",
            "if self.same_length:",
            "-            mask_l = tf.matrix_band_part(attn_mask, -1, 0)",
            "+            mask_l = tf.linalg.band_part(attn_mask, -1, 0)",
            "ret = tf.concat([ret[:, :qlen] + mask_l - mask_dia, ret[:, qlen:]], 1)",
            "return ret"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2581,
        "label": "yes",
        "change": [
            "class PyramidVisionTransformerV2(nn.Module):",
            "cur += depths[i]",
            "",
            "# classification head",
            "-        self.head = nn.Linear(embed_dims[3], num_classes) if num_classes > 0 else nn.Identity()",
            "+        self.num_features = embed_dims[-1]",
            "+        self.head = nn.Linear(embed_dims[-1], num_classes) if num_classes > 0 else nn.Identity()",
            "",
            "self.apply(self._init_weights)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 2583,
        "label": "no",
        "change": [
            "class StringLookupVocabularyTest(keras_parameterized.TestCase,",
            "fn()",
            "",
            "if __name__ == \"__main__\":",
            "+  # StringLookup is only exported as a TF2 API.",
            "+  tf.compat.v1.enable_v2_behavior()",
            "tf.test.main()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2584,
        "label": "no",
        "change": [
            "def train_and_export(export_path,",
            "metric.result().numpy()))",
            "",
            "# We have to call either predict or fit to make it possible to export with",
            "-  # tf.keras.models.save_model.",
            "+  # tf.saved_model.save.",
            "model.predict(next(iter(dataset))[\"image\"])",
            "# Export the model as SavedModel 2.0.",
            "tf.saved_model.save(model, export_path)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2585,
        "label": "no",
        "change": [
            "class Quantizer(Compressor):",
            "Base quantizer for pytorch quantizer",
            "\"\"\"",
            "",
            "-    def __call__(self, model):",
            "-        self.compress(model)",
            "-        return model",
            "-",
            "def quantize_weight(self, weight, config, op, op_type, op_name):",
            "\"\"\"user should know where dequantize goes and implement it in quantize method",
            "we now do not provide dequantize method"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2587,
        "label": "no",
        "change": [
            "class PegasusForCausalLM(PegasusPreTrainedModel):",
            "```python",
            ">>> from transformers import PegasusTokenizer, PegasusForCausalLM",
            "",
            "-        >>> tokenizer = PegasusTokenizer.from_pretrained(\"facebook/bart-large\")",
            "-        >>> model = PegasusForCausalLM.from_pretrained(\"facebook/bart-large\", add_cross_attention=False)",
            "+        >>> tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-large\")",
            "+        >>> model = PegasusForCausalLM.from_pretrained(\"google/pegasus-large\", add_cross_attention=False)",
            ">>> assert model.config.is_decoder, f\"{model.__class__} has to be configured as a decoder.\"",
            ">>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")",
            ">>> outputs = model(**inputs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2589,
        "label": "no",
        "change": [
            "SEWD_INPUTS_DOCSTRING = r\"\"\"",
            "\"The bare SEW-D Model transformer outputting raw hidden-states without any specific head on top.\",",
            "SEWD_START_DOCSTRING,",
            ")",
            "-# Copied from transformers.models.sew.modeling_sew.SEWModel with SEW->SEWD",
            "+# Copied from transformers.models.sew.modeling_sew.SEWModel with SEW->SEWD, layer_norm_eps->feature_layer_norm_eps",
            "class SEWDModel(SEWDPreTrainedModel):",
            "def __init__(self, config: SEWDConfig):",
            "super().__init__(config)",
            "self.config = config",
            "self.feature_extractor = SEWDFeatureExtractor(config)",
            "-        self.layer_norm = nn.LayerNorm(config.conv_dim[-1], eps=config.layer_norm_eps)",
            "+        self.layer_norm = nn.LayerNorm(config.conv_dim[-1], eps=config.feature_layer_norm_eps)",
            "",
            "self.project_features = config.conv_dim[-1] != config.hidden_size",
            "if self.project_features:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2590,
        "label": "no",
        "change": [
            "class ExtendedMultiRNNCellTest(tf.test.TestCase):",
            "",
            "with tf.variable_scope(\"root\", initializer=tf.constant_initializer(0.5)):",
            "test_cell = rnn_cell.ExtendedMultiRNNCell(",
            "-          [tf.contrib.rnn.GRUCell(2)] * 2,",
            "+          [tf.contrib.rnn.GRUCell(2) for _ in range(2)],",
            "residual_connections=True, **kwargs)",
            "res_test = test_cell(inputs, state, scope=\"test\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2592,
        "label": "yes",
        "change": [
            "class SequenceGenerator(nn.Module):",
            "cum_unfin.append(prev)",
            "cum_fin_tensor = torch.tensor(cum_unfin, dtype=torch.int).to(bbsz_idx)",
            "",
            "-        unfin_idx = bbsz_idx // beam_size",
            "+        unfin_idx = torch.div(bbsz_idx, beam_size, rounding_mode='trunc')",
            "sent = unfin_idx + torch.index_select(cum_fin_tensor, 0, unfin_idx)",
            "",
            "# Create a set of \"{sent}{unfin_idx}\", where"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 2593,
        "label": "no",
        "change": [
            "eye.unsupported_dtypes = (\"uint16\",)",
            "def from_dlpack(",
            "x: Union[tf.Tensor, tf.Variable], *, out: Union[tf.Tensor, tf.Variable] = None",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "-    return tf.experimental.dlpack.from_dlpack(x)",
            "+    dlcapsule = tf.experimental.dlpack.to_dlpack(x)",
            "+    return tf.experimental.dlpack.from_dlpack(dlcapsule)",
            "",
            "",
            "def full("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2596,
        "label": "no",
        "change": [
            "from .modeling_utils import Conv1D, PreTrainedModel, SequenceSummary, prune_conv",
            "logger = logging.getLogger(__name__)",
            "",
            "GPT2_PRETRAINED_MODEL_ARCHIVE_MAP = {",
            "-    \"gpt2\": \"https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin\",",
            "-    \"gpt2-medium\": \"https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-pytorch_model.bin\",",
            "-    \"gpt2-large\": \"https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-large-pytorch_model.bin\",",
            "-    \"gpt2-xl\": \"https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-xl-pytorch_model.bin\",",
            "-    \"distilgpt2\": \"https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-pytorch_model.bin\",",
            "+    \"gpt2\": \"https://cdn.huggingface.co/gpt2-pytorch_model.bin\",",
            "+    \"gpt2-medium\": \"https://cdn.huggingface.co/gpt2-medium-pytorch_model.bin\",",
            "+    \"gpt2-large\": \"https://cdn.huggingface.co/gpt2-large-pytorch_model.bin\",",
            "+    \"gpt2-xl\": \"https://cdn.huggingface.co/gpt2-xl-pytorch_model.bin\",",
            "+    \"distilgpt2\": \"https://cdn.huggingface.co/distilgpt2-pytorch_model.bin\",",
            "}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2598,
        "label": "no",
        "change": [
            "class TestRandomRotation:",
            "torch.manual_seed(0)  # for random reproductibility",
            "",
            "@torch.jit.script",
            "-        def op_script(data: torch.Tensor) -> torch.Tensor:",
            "-",
            "+        def op_script(data: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:",
            "return kornia.random_rotation(data, degrees=45.0)",
            "",
            "input = torch.tensor([[1., 0., 0., 2.],"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2602,
        "label": "no",
        "change": [
            "def perform_analysis_torch(preds, indices, noise_eps=0.1, delta=1e-5, moments=8,",
            "data_ind_eps_list = (data_ind_log_mgf - math.log(delta)) / l_list",
            "",
            "return min(eps_list_nm), min(data_ind_eps_list)",
            "-",
            "-",
            "-",
            "\\ No newline at end of file"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2603,
        "label": "no",
        "change": [
            "class NaturalGradient(Optimizer):",
            "",
            "applied = self.apply_step(variables=variables, diffs=estimated_diffs)",
            "",
            "-            with tf.control_dependencies(control_inputs=applied):",
            "+            with tf.control_dependencies(control_inputs=(applied,)):",
            "return [tf.identity(input=estimated_diff) for estimated_diff in estimated_diffs]",
            "",
            "def false_fn():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2605,
        "label": "no",
        "change": [
            "class Rejector(Distribution):",
            "self._propose_batch_log_pdf_cache = x, self.propose.log_prob(x)",
            "return self._propose_batch_log_pdf_cache[1]",
            "",
            "-    def sample(self, sample_shape=torch.Size()):",
            "+    def rsample(self, sample_shape=torch.Size()):",
            "# Implements parallel batched accept-reject sampling.",
            "x = self.propose(sample_shape) if sample_shape else self.propose()",
            "log_prob_accept = self.log_prob_accept(x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2606,
        "label": "yes",
        "change": [
            "def test_conditional_whiten(Xnew, X, kernel, f_loc, f_scale_tril, loc, cov):",
            "loc0, cov0 = conditional(Xnew, X, kernel, f_loc, f_scale_tril, full_cov=True,",
            "whiten=False)",
            "Kff = kernel(X) + torch.eye(3) * 1e-6",
            "-    Lff = Kff.cholesky()",
            "+    Lff = torch.linalg.cholesky(Kff)",
            "whiten_f_loc = Lff.inverse().matmul(f_loc)",
            "whiten_f_scale_tril = Lff.inverse().matmul(f_scale_tril)",
            "loc1, cov1 = conditional(Xnew, X, kernel, whiten_f_loc, whiten_f_scale_tril,"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 2612,
        "label": "no",
        "change": [
            "class MsTerms(datasets.GeneratorBasedBuilder):",
            "",
            "if not os.path.exists(path_to_manual_file):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('ms_terms', data_dir=...)` that includes a file name {}. Manual download instructions: {})\".format(",
            "-                    path_to_manual_file, _FILENAME, self.manual_download_instructions",
            "-                )",
            "+                f\"{path_to_manual_file} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('ms_terms', data_dir=...)` that includes a file name {_FILENAME}. Manual download instructions: {self.manual_download_instructions})\"",
            ")",
            "return [datasets.SplitGenerator(name=datasets.Split.TRAIN, gen_kwargs={\"path\": path_to_manual_file})]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2614,
        "label": "no",
        "change": [
            "eigh.support_native_out = True",
            "",
            "@with_unsupported_dtypes({\"1.11.0 and below\": (\"float16\", \"bfloat16\")}, backend_version)",
            "def eigvalsh(",
            "-    x: torch.Tensor, /, *, UPLO: Optional[str] = \"L\", out: Optional[torch.Tensor] = None",
            "+    x: torch.Tensor,",
            "+    /,",
            "+    *,",
            "+    UPLO: Optional[str] = \"L\",",
            "+    out: Optional[torch.Tensor] = None",
            ") -> torch.Tensor:",
            "return torch.linalg.eigvalsh(x, UPLO=UPLO, out=out)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2619,
        "label": "no",
        "change": [
            "class HardNet8(nn.Module):",
            "# use torch.hub to load pretrained model",
            "if pretrained:",
            "storage_fcn: Callable = lambda storage, loc: storage",
            "-            pretrained_dict = torch.hub.load_state_dict_from_url(",
            "-                urls['hardnet8v2'], map_location=storage_fcn",
            "-            )",
            "+            pretrained_dict = torch.hub.load_state_dict_from_url(urls['hardnet8v2'], map_location=storage_fcn)",
            "self.load_state_dict(pretrained_dict, strict=True)",
            "self.eval()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2620,
        "label": "no",
        "change": [
            "class TestFilter2D:",
            "assert_allclose(actual, expected)",
            "",
            "def test_even_sized_filter(self, device):",
            "-        kernel = torch.ones(1, 4, 4).to(device)",
            "+        kernel = torch.ones(1, 2, 2).to(device)",
            "input = torch.tensor([[[",
            "[0., 0., 0., 0., 0.],",
            "[0., 0., 0., 0., 0.],"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2626,
        "label": "no",
        "change": [
            "def rotation_matrix_to_quaternion(",
            "qz = 0.25 * sq",
            "if order == QuaternionCoeffOrder.XYZW:",
            "return torch.cat((qx, qy, qz, qw), dim=-1)",
            "-        else:",
            "-            return torch.cat((qw, qx, qy, qz), dim=-1)",
            "+        return torch.cat((qw, qx, qy, qz), dim=-1)",
            "",
            "where_2 = torch.where(m11 > m22, cond_2(), cond_3())",
            "where_1 = torch.where((m00 > m11) & (m00 > m22), cond_1(), where_2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2627,
        "label": "yes",
        "change": [
            "def accuracy(pr, gt, threshold=0.5, ignore_channels=None):",
            "pr = _threshold(pr, threshold=threshold)",
            "pr, gt = _take_channels(pr, gt, ignore_channels=ignore_channels)",
            "",
            "-    tp = torch.sum(gt == pr)",
            "+    tp = torch.sum(gt == pr, dtype=pr.dtype)",
            "score = tp / gt.view(-1).shape[0]",
            "return score"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 2628,
        "label": "no",
        "change": [
            "def unsharp_mask(",
            ">>> output.shape",
            "torch.Size([2, 4, 5, 5])",
            "\"\"\"",
            "-    data_blur: torch.Tensor = gaussian_blur2d(input, kernel_size, sigma)",
            "+    data_blur: torch.Tensor = gaussian_blur2d(input, kernel_size, sigma, border_type)",
            "data_sharpened: torch.Tensor = input + (input - data_blur)",
            "return data_sharpened"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2629,
        "label": "no",
        "change": [
            "def pl_worker_init_function(worker_id: int, rank: Optional[int] = None) -> None:",
            "np.random.seed(ss.generate_state(4))",
            "# Spawn distinct SeedSequences for the PyTorch PRNG and the stdlib random module",
            "torch_ss, stdlib_ss = ss.spawn(2)",
            "-    # PyTorch 1.7 and above takes a 64-bit seed",
            "-    dtype = np.uint64 if _TORCH_GREATER_EQUAL_1_7 else np.uint32",
            "-    torch.manual_seed(torch_ss.generate_state(1, dtype=dtype)[0])",
            "+    torch.manual_seed(torch_ss.generate_state(1, dtype=np.uint64)[0])",
            "# use 128 bits expressed as an integer",
            "stdlib_seed = (stdlib_ss.generate_state(2, dtype=np.uint64).astype(object) * [1 << 64, 1]).sum()",
            "random.seed(stdlib_seed)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2631,
        "label": "no",
        "change": [
            "def test_to_homogeneous_and_vice_versa():",
            "del out._edge_type_names",
            "del out._node_type_names",
            "out = out.to_heterogeneous(node_type, edge_type)",
            "-    assert len(out) == 4",
            "+    assert len(out) == 5",
            "assert torch.allclose(data['paper'].x, out['0'].x)",
            "assert torch.allclose(data['author'].x, out['1'].x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2633,
        "label": "no",
        "change": [
            "class Tacotron(nn.Module):",
            "self.encoder = Encoder(embedding_dim)",
            "self.decoder = Decoder(256, mel_dim, r)",
            "self.postnet = PostCBHG(mel_dim)",
            "-        self.last_linear = nn.Linear(256, linear_dim)",
            "+        self.last_linear = nn.Linear(self.postnet.cbhg.gru_features * 2, linear_dim)",
            "",
            "def forward(self, characters, mel_specs=None, mask=None):",
            "B = characters.size(0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2635,
        "label": "no",
        "change": [
            "def resample(img, flow):",
            "img_flat = tf.reshape(tf.transpose(img, [0, 2, 3, 1]), [-1, c])",
            "",
            "dx, dy = tf.unstack(flow, axis=1)",
            "-    xf, yf = tf.meshgrid(tf.to_float(tf.range(w)), tf.to_float(tf.range(h)))",
            "+    xf, yf = tf.meshgrid(tf.cast(tf.range(w), tf.float32), tf.cast(tf.range(h), tf.float32))",
            "xf = xf + dx",
            "yf = yf + dy"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2636,
        "label": "yes",
        "change": [
            "def shape(",
            "as_array: bool = False,",
            ") -> Union[tf.Tensor, ivy.Shape, ivy.Array]:",
            "if as_array:",
            "-        return ivy.array(tf.shape(x))",
            "+        return ivy.array(tf.shape(x), dtype=ivy.default_int_dtype())",
            "else:",
            "return ivy.Shape(x.shape)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 2637,
        "label": "no",
        "change": [
            "class DiagonalGaussianDistribution(object):",
            "if self.deterministic:",
            "self.var = self.std = torch.zeros_like(self.mean).to(device=self.parameters.device)",
            "",
            "-    def sample(self):",
            "-        x = self.mean + self.std * torch.randn(self.mean.shape).to(device=self.parameters.device)",
            "+    def sample(self, generator=None):",
            "+        x = self.mean + self.std * torch.randn(self.mean.shape, generator=generator, device=self.parameters.device)",
            "return x",
            "",
            "def kl(self, other=None):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2638,
        "label": "no",
        "change": [
            "class Conv2dSubsampling(torch.nn.Module):",
            "if self.output is not None:",
            "sequence = self.output(sequence)",
            "",
            "-        if mask is not None:",
            "-            return sequence, self.create_new_mask(mask)",
            "-",
            "-        return sequence, None",
            "+        return sequence, self.create_new_mask(mask)",
            "",
            "def create_new_conformer_mask(self, mask: torch.Tensor) -> torch.Tensor:",
            "\"\"\"Create new conformer mask for output sequences."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2641,
        "label": "no",
        "change": [
            "def main():",
            "# extract",
            "logging.info('backend = ' + args.backend)",
            "if args.backend == \"pytorch\":",
            "-        fromespnet.lmpytorch.tts_pytorch import decode",
            "+        from espnet.lmpytorch.tts_pytorch import decode",
            "decode(args)",
            "else:",
            "raise NotImplementedError(\"Only pytorch is supported.\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2644,
        "label": "no",
        "change": [
            "class Wav2Vec2ModelIntegrationTest(unittest.TestCase):",
            "",
            "@require_pyctcdecode",
            "@require_torchaudio",
            "+    @unittest.skipIf(",
            "+        is_torch_less_than_1_9,",
            "+        reason=\"`torchaudio.functional.resample` needs torchaudio >= 0.9 which requires torch >= 0.9\",",
            "+    )",
            "def test_wav2vec2_with_lm_pool(self):",
            "ds = load_dataset(\"common_voice\", \"es\", split=\"test\", streaming=True)",
            "sample = next(iter(ds))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2645,
        "label": "no",
        "change": [
            "class WaveNet(object):",
            "shifted = tf.slice(encoded, [0, 0, 1, 0], [-1, -1, tf.shape(encoded)[2] - 1, -1])",
            "shifted = tf.pad(shifted, [[0, 0], [0, 0], [0, 1], [0, 0]])",
            "",
            "-            loss = tf.nn.softmax_cross_entropy_with_logits(raw_output, tf.reshape(shifted, [-1, self.channels]))",
            "+            prediction = tf.reshape(raw_output, [-1, self.channels])",
            "+            loss = tf.nn.softmax_cross_entropy_with_logits(prediction, tf.reshape(shifted, [-1, self.channels]))",
            "reduced_loss =  tf.reduce_mean(loss)",
            "",
            "tf.scalar_summary('loss', reduced_loss)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2646,
        "label": "no",
        "change": [
            "def elbo_test_case(backend, jit, expected_elbo, data, steps=None):",
            "if backend == \"pyro\":",
            "# TODO: this is a difference between the two implementations",
            "elbo = elbo.loss",
            "-        assert elbo(constrained_model, guide_constrained_model, data) == approx(expected_elbo, rel=0.1)",
            "+        with torch.no_grad():",
            "+            actual = elbo(constrained_model, guide_constrained_model, data)",
            "+        assert actual == approx(expected_elbo, rel=0.1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2647,
        "label": "no",
        "change": [
            "class PatchEmbed(nn.Module):",
            "",
            "def forward(self, x):",
            "B, C, H, W = x.shape",
            "-        torch._assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")",
            "-        torch._assert(W == self.img_size[1], f\"Input image width ({W}) doesn't match model ({self.img_size[1]}).\")",
            "+        _assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")",
            "+        _assert(W == self.img_size[1], f\"Input image width ({W}) doesn't match model ({self.img_size[1]}).\")",
            "x = self.proj(x)",
            "if self.flatten:",
            "x = x.flatten(2).transpose(1, 2)  # BCHW -> BNC"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2648,
        "label": "no",
        "change": [
            "class Layer_Pooling_Test(CustomTestCase):",
            "cls.network = tl.layers.DenseLayer(cls.network, 800, tf.nn.relu, name='relu2')",
            "cls.network = tl.layers.DropoutLayer(cls.network, keep=0.5, name='drop3')",
            "",
            "-        cls.network = tl.layers.DenseLayer(cls.network, n_units=10, act=tf.identity, name='output')",
            "+        cls.network = tl.layers.DenseLayer(cls.network, n_units=10, name='output')",
            "",
            "# define cost function and metric.",
            "cls.y = cls.network.outputs"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2649,
        "label": "no",
        "change": [
            "class TorchHook(object):",
            "is_old = re.match('old*', attr) is not None",
            "",
            "# Where the overloading happens",
            "-            if ((is_desc or (is_func and not is_service_func))",
            "-                and not is_base and not is_old):",
            "+            if ((is_desc or (is_func and not is_service_func)) and not is_base and not is_old):",
            "passer = self.pass_method_args(lit)",
            "new_attr = self.overload_method(passer)",
            "-                setattr(torch.autograd.variable.Variable,",
            "-                    'old_{}'.format(attr), lit)",
            "+                setattr(torch.autograd.variable.Variable,",
            "+                        'old_{}'.format(attr), lit)",
            "setattr(torch.autograd.variable.Variable, attr, new_attr)",
            "",
            "self.hook_var_send_()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2650,
        "label": "no",
        "change": [
            "class TestRasterizeMeshes(TestCaseMixin, unittest.TestCase):",
            "bin_size,",
            "max_faces_per_bin,",
            ")",
            "-        # Flip x and y axis of output before comparing to expected",
            "+",
            "bin_faces_same = (bin_faces.squeeze() == bin_faces_expected).all()",
            "self.assertTrue(bin_faces_same.item() == 1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2651,
        "label": "no",
        "change": [
            "def broadcast_to(",
            "shape: Union[ivy.NativeShape, Sequence[int]],",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "if tf.rank(x) > len(shape):",
            "-        return tf.broadcast_to(tf.reshape(x,-1), shape)",
            "+        return tf.broadcast_to(tf.reshape(x, -1), shape)",
            "return tf.broadcast_to(x, shape)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2652,
        "label": "no",
        "change": [
            "class LDMTextToImagePipelineNightlyTests(unittest.TestCase):",
            "torch.cuda.empty_cache()",
            "",
            "def get_inputs(self, device, dtype=torch.float32, seed=0):",
            "-        generator = torch.Generator(device=device).manual_seed(seed)",
            "+        generator = torch.manual_seed(seed)",
            "latents = np.random.RandomState(seed).standard_normal((1, 4, 32, 32))",
            "latents = torch.from_numpy(latents).to(device=device, dtype=dtype)",
            "inputs = {"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2653,
        "label": "no",
        "change": [
            "def create_deepspeed_args():",
            "# We assume up to one full node executing unit tests",
            "assert torch.distributed.get_world_size() <= torch.cuda.device_count()",
            "args.local_rank = torch.distributed.get_rank()",
            "-    else:",
            "-        args.local_rank = 0",
            "return args"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2654,
        "label": "yes",
        "change": [
            "class Entropy(Metric):",
            "def __call__(",
            "self,  # type: ignore",
            "logits: torch.Tensor,",
            "-        mask: Optional[torch.Tensor] = None,",
            "+        mask: Optional[torch.BoolTensor] = None,",
            "):",
            "\"\"\"",
            "# Parameters",
            "",
            "logits : `torch.Tensor`, required.",
            "A tensor of unnormalized log probabilities of shape (batch_size, ..., num_classes).",
            "-        mask : `torch.Tensor`, optional (default = None).",
            "+        mask : `torch.BoolTensor`, optional (default = None).",
            "A masking tensor of shape (batch_size, ...).",
            "\"\"\"",
            "logits, mask = self.detach_tensors(logits, mask)",
            "",
            "if mask is None:",
            "-            mask = torch.ones(logits.size()[:-1], device=logits.device)",
            "+            mask = torch.ones(logits.size()[:-1], device=logits.device).bool()",
            "",
            "log_probs = torch.nn.functional.log_softmax(logits, dim=-1)",
            "probabilities = torch.exp(log_probs) * mask.unsqueeze(-1)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 2660,
        "label": "no",
        "change": [
            "class DeepSpeedTransformerInference(nn.Module):",
            "merge_count,",
            "mlp_extra_grouping)",
            "",
            "-        device = torch.cuda.current_device()  #if config.bigscience_bloom else 'cpu'",
            "+        device = get_accelerator().current_device_name(",
            "+        )  # if config.bigscience_bloom else 'cpu'",
            "self.norm_w = nn.Parameter(torch.empty(self.config.hidden_size,",
            "dtype=data_type,",
            "device=device),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2662,
        "label": "yes",
        "change": [
            "def get_transducer_task_io(",
            "encoder_out_lens = list(map(int, encoder_out_lens))",
            "",
            "t_len = torch.IntTensor(encoder_out_lens).to(device)",
            "-    u_len = torch.IntTensor([y.size(0) for y in ys]).to(device)",
            "+    u_len = torch.IntTensor([y.size(0) for y in labels_unpad]).to(device)",
            "",
            "-    return target, t_len, u_len",
            "+    return decoder_in, target, t_len, u_len"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 2663,
        "label": "yes",
        "change": [
            "def lower_modules_to_accelerator(",
            "backend = \"NNPI\"",
            "backend_qualifier = \"\"",
            "",
            "-        if throughput_optimize:",
            "+        if throughput_optimize and gelu_clip:",
            "+            backend_qualifier = \":throughput_optimized_gelu_clip\"",
            "+        elif throughput_optimize:",
            "backend_qualifier = \":throughput_optimized\"",
            "",
            "modules_to_lower = accelerator.get_modules(model, backend + backend_qualifier)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 2664,
        "label": "no",
        "change": [
            "def _load_weights(model: nn.Module, checkpoint_path: str, prefix: str = 'resnet/",
            "model.stem.conv.weight.copy_(stem_conv_w)",
            "model.norm.weight.copy_(t2p(weights[f'{prefix}group_norm/gamma']))",
            "model.norm.bias.copy_(t2p(weights[f'{prefix}group_norm/beta']))",
            "-    if model.head.fc.weight.shape[0] == weights[f'{prefix}head/conv2d/kernel'].shape[-1]:",
            "+    if isinstance(model.head.fc, nn.Conv2d) and \\",
            "+            model.head.fc.weight.shape[0] == weights[f'{prefix}head/conv2d/kernel'].shape[-1]:",
            "model.head.fc.weight.copy_(t2p(weights[f'{prefix}head/conv2d/kernel']))",
            "model.head.fc.bias.copy_(t2p(weights[f'{prefix}head/conv2d/bias']))",
            "for i, (sname, stage) in enumerate(model.stages.named_children()):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2666,
        "label": "no",
        "change": [
            "class TRPOModel(PGModel):",
            "prob_ratio = tf.exp(current_log_prob - prev_log_prob)",
            "surrogate_loss = -tf.reduce_mean(prob_ratio * self.advantage)",
            "variables = tf.trainable_variables()",
            "-            for v in variables:",
            "-                print(v.name)",
            "+",
            "batch_float = tf.cast(self.batch_size, tf.float32)",
            "",
            "mean_kl_divergence = self.dist.kl_divergence(self.prev_dist, self.policy.get_policy_variables())\\"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2670,
        "label": "no",
        "change": [
            "def k_hop_subgraph(node_idx, num_hops, edge_index, relabel_nodes=False,",
            "",
            "if relabel_nodes:",
            "node_idx = row.new_full((num_nodes, ), -1)",
            "-        node_idx[subset] = torch.arange(subset.size(0))",
            "+        node_idx[subset] = torch.arange(subset.size(0), device=row.device)",
            "edge_index = node_idx[edge_index]",
            "",
            "return subset, edge_index, edge_mask"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2673,
        "label": "no",
        "change": [
            "class TestTexturesVertex(TestCaseMixin, unittest.TestCase):",
            ")",
            "",
            "# define TexturesVertex",
            "-        verts_texture = torch.rand(verts.shape)",
            "+        verts_texture = torch.rand(verts.shape, device=device)",
            "textures = TexturesVertex(verts_features=verts_texture)",
            "",
            "# compute packed faces"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2674,
        "label": "no",
        "change": [
            "class TorchSTFT():",
            "center=True,",
            "pad_mode=\"reflect\",  # compatible with audio.py",
            "normalized=False,",
            "-                       onesided=True)",
            "+                       onesided=True,",
            "+                       return_complex=False)",
            "M = o[:, :, :, 0]",
            "P = o[:, :, :, 1]",
            "return torch.sqrt(torch.clamp(M ** 2 + P ** 2, min=1e-8))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2678,
        "label": "no",
        "change": [
            "class CategoricalToNumerical(preprocessor.Preprocessor):",
            "\"column_names\": config[\"column_names\"],",
            "}",
            "obj = cls(**init_config)",
            "-        obj.layer = preprocessors.deserialize(config[\"layer\"])",
            "+        obj.layer = keras_layers.MultiCategoryEncoding(config[\"encoding\"])",
            "for encoding_layer, vocab in zip(",
            "obj.layer.encoding_layers, config[\"encoding_vocab\"]",
            "):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2679,
        "label": "no",
        "change": [
            "class IoUBalancedNegSampler(RandomSampler):",
            "return sampled_inds",
            "",
            "def _sample_neg(self, assign_result, num_expected, **kwargs):",
            "-        neg_inds = torch.nonzero(assign_result.gt_inds == 0)",
            "+        neg_inds = torch.nonzero(assign_result.gt_inds == 0, as_tuple=False)",
            "if neg_inds.numel() != 0:",
            "neg_inds = neg_inds.squeeze(1)",
            "if len(neg_inds) <= num_expected:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2680,
        "label": "no",
        "change": [
            "from ..autodp.phi_tensor import PhiTensor",
            "",
            "def leaky_relu(input: PhiTensor, negative_slope: float = 0.01) -> PhiTensor:",
            "",
            "-    data = nn.functional.leaky_relu(Tensor(input.child.decode()), negative_slope)",
            "+    data = nn.functional.leaky_relu(Tensor(input.child), negative_slope)",
            "data_as_numpy = data.detach().numpy()",
            "",
            "return PhiTensor("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2684,
        "label": "no",
        "change": [
            "class Model(mnist_example.Model):",
            "",
            "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, label)",
            "cost = tf.reduce_mean(cost, name='cross_entropy_loss')",
            "-        wd_cost = tf.mul(1e-5, regularize_cost('fc.*/W', tf.nn.l2_loss),",
            "-                         name='regularize_loss')",
            "+        wd_cost = tf.multiply(1e-5, regularize_cost('fc.*/W', tf.nn.l2_loss),",
            "+                              name='regularize_loss')",
            "",
            "self.cost = tf.add_n([wd_cost, cost], name='cost')",
            "add_moving_summary(cost, wd_cost, self.cost)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2685,
        "label": "yes",
        "change": [
            "class GPTJForSequenceClassification(GPTJPreTrainedModel):",
            "f\"unexpected if using padding tokens in conjunction with `inputs_embeds.`\"",
            ")",
            "",
            "-        pooled_logits = logits[range(batch_size), sequence_lengths]",
            "+        pooled_logits = logits[torch.arange(batch_size, device=self.device), sequence_lengths]",
            "",
            "loss = None",
            "if labels is not None:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 2687,
        "label": "no",
        "change": [
            "class SchNet(torch.nn.Module):",
            "batch: OptTensor = None) -> Tensor:",
            "r\"\"\"",
            "Args:",
            "-            z (LongTensor): Atomic number of each atom with shape",
            "+            z (torch.Tensor): Atomic number of each atom with shape",
            ":obj:`[num_atoms]`.",
            "-            pos (Tensor): Coordinates of each atom with shape",
            "+            pos (torch.Tensor): Coordinates of each atom with shape",
            ":obj:`[num_atoms, 3]`.",
            "-            batch (LongTensor, optional): Batch indices assigning each atom to",
            "-                a separate molecule with shape :obj:`[num_atoms]`.",
            "+            batch (torch.Tensor, optional): Batch indices assigning each atom",
            "+                to a separate molecule with shape :obj:`[num_atoms]`.",
            "(default: :obj:`None`)",
            "\"\"\"",
            "batch = torch.zeros_like(z) if batch is None else batch"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2692,
        "label": "no",
        "change": [
            "class RandomElasticTransform(AugmentationBase2D):",
            "padding_mode=padding_mode,",
            ")",
            "",
            "-    def generate_parameters(self, shape: torch.Size) -> Dict[str, Tensor]:",
            "+    def generate_parameters(self, shape: Tuple[int, ...]) -> Dict[str, Tensor]:",
            "B, _, H, W = shape",
            "if self.same_on_batch:",
            "noise = torch.rand(1, 2, H, W, device=self.device, dtype=self.dtype).expand(B, 2, H, W)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2693,
        "label": "no",
        "change": [
            "class DropconnectDenseLayer(Layer):",
            "self.n_units = n_units",
            "logging.info(\"DropconnectDenseLayer %s: %d %s\" % (self.name, self.n_units, act.__name__))",
            "",
            "-        with tf.variable_scope(name) as vs:",
            "+        with tf.variable_scope(name):",
            "W = tf.get_variable(name='W', shape=(n_in, n_units), initializer=W_init, dtype=D_TYPE, **W_init_args)",
            "b = tf.get_variable(name='b', shape=(n_units), initializer=b_init, dtype=D_TYPE, **b_init_args)",
            "-            self.outputs = act(tf.matmul(self.inputs, W) + b)  #, name=name)    # 1.2",
            "+            self.outputs = act(tf.matmul(self.inputs, W) + b)",
            "",
            "set_keep[name] = tf.placeholder(tf.float32)",
            "W_dropcon = tf.nn.dropout(W, set_keep[name])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2696,
        "label": "no",
        "change": [
            "class PReluLayer(Layer):",
            "with tf.variable_scope(name) as vs:",
            "alphas = tf.get_variable(name='alphas', shape=w_shape, initializer=a_init, **a_init_args )",
            "try:  ## TF 1.0",
            "-                self.outputs = tf.nn.relu(self.inputs) + tf.mulitply(alphas, (self.inputs - tf.abs(self.inputs))) * 0.5",
            "+                self.outputs = tf.nn.relu(self.inputs) + tf.multiply(alphas, (self.inputs - tf.abs(self.inputs))) * 0.5",
            "except: ## TF 0.12",
            "self.outputs = tf.nn.relu(self.inputs) + tf.mul(alphas, (self.inputs - tf.abs(self.inputs))) * 0.5",
            "",
            "+",
            "self.all_layers = list(layer.all_layers)",
            "self.all_params = list(layer.all_params)",
            "self.all_drop = dict(layer.all_drop)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2697,
        "label": "yes",
        "change": [
            "def clip_by_global_norm(grads, clip_norm):",
            "",
            "def get_optimizer(loss, params, summary, variable_dtype, inp_var_grads=None):",
            "\"\"\"Creates and returns an optimizer training op.\"\"\"",
            "+    mesh = loss.mesh  # get mesh info from loss",
            "+    graph = mesh.graph  # get graph info from mesh",
            "+    global_step = tf.train.get_or_create_global_step() # get global step",
            "",
            "learning_rate = tf.constant(value=params[\"lr\"], shape=[], dtype=variable_dtype.slice_dtype) # grab lr param",
            "clip_value = mtf.constant(mesh, params[\"gradient_clipping\"], dtype=variable_dtype.slice_dtype)",
            "",
            "-",
            "-    global_step = tf.train.get_or_create_global_step() # get global step",
            "-    mesh = loss.mesh  # get mesh info from loss",
            "-    graph = mesh.graph  # get graph info from mesh",
            "-",
            "if inp_var_grads is None:",
            "var_grads = mtf.gradients([loss], [v.outputs[0] for v in graph.trainable_variables])",
            "else:"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 2698,
        "label": "no",
        "change": [
            "def model_fn(features, labels, mode, params):",
            "# TODO: this is mtf code - figure out what this does",
            "fully_replicated_logits = mtf.anonymize(logits)",
            "",
            "+    # Getting total number of trainable vars",
            "print('\\n')",
            "total_parameters = 0",
            "for variable in graph.trainable_variables:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2700,
        "label": "no",
        "change": [
            "class NonFusedAdam(optimizer_v2.OptimizerV2):",
            "vhat = self.get_slot(var, \"vhat\")",
            "vhat.assign(tf.maximum(vhat, v))",
            "v = vhat",
            "-        var.assign_sub((m * alpha) / (tf.sqrt(v) - coefficients[\"epsilon\"]))",
            "+        var.assign_sub((m * alpha) / (tf.sqrt(v) + coefficients[\"epsilon\"]))",
            "",
            "@tf.function(jit_compile=True)",
            "def _resource_apply_sparse(self, grad, var, indices, apply_state=None):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2701,
        "label": "no",
        "change": [
            "class SpanField(Field[torch.Tensor]):",
            "@overrides",
            "def as_tensor(self,",
            "padding_lengths: Dict[str, int],",
            "-                  cuda_device: int = -1,",
            "-                  for_training: bool = True) -> torch.Tensor:",
            "+                  cuda_device: int = -1) -> torch.Tensor:",
            "# pylint: disable=unused-argument",
            "-        tensor = Variable(torch.LongTensor([self.span_start, self.span_end]), volatile=not for_training)",
            "+        tensor = torch.LongTensor([self.span_start, self.span_end])",
            "return tensor if cuda_device == -1 else tensor.cuda(cuda_device)",
            "",
            "@overrides"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2703,
        "label": "no",
        "change": [
            "class CompartmentalModel(ABC):",
            "to a tensor whose first dimension corresponds to sample batching.",
            ":rtype: dict",
            "\"\"\"",
            "+        _require_double_precision()",
            "if not self.samples:",
            "raise RuntimeError(\"Missing samples, try running .fit() first\")",
            "+",
            "samples = self.samples",
            "num_samples = len(next(iter(samples.values())))",
            "particle_plate = pyro.plate(\"particles\", num_samples,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2704,
        "label": "no",
        "change": [
            "class FullyConnectedNetwork(Model):",
            "name=label)",
            "i += 1",
            "",
            "-            output = tf.layers.dense(",
            "+            output = tf1.layers.dense(",
            "last_layer,",
            "num_outputs,",
            "kernel_initializer=normc_initializer(0.01),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2707,
        "label": "no",
        "change": [
            "def train_example(num_replicas=1, use_gpu=False, test_mode=False):",
            "\"test_mode\": test_mode,",
            "\"classification_model_path\": os.path.join(",
            "os.path.dirname(ray.__file__),",
            "-            \"util/sgd/pytorch/examples/mnist_cnn.pt\")",
            "+            \"util/sgd/torch/examples/mnist_cnn.pt\")",
            "}",
            "-    trainer = PyTorchTrainer(",
            "+    trainer = TorchTrainer(",
            "model_creator,",
            "data_creator,",
            "optimizer_creator,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2708,
        "label": "no",
        "change": [
            "class TestFrameWorkAgnosticComponents(unittest.TestCase):",
            "# Test recognizing default package path.",
            "scope = None",
            "if sess:",
            "-                scope = tf.variable_scope(\"exploration_object\")",
            "+                scope = tf1.variable_scope(\"exploration_object\")",
            "scope.__enter__()",
            "component = from_config(",
            "Exploration, {"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2711,
        "label": "no",
        "change": [
            "def load_openai_model(",
            "",
            "# model from OpenAI state dict is in manually cast fp16 mode, must be converted for AMP/fp32/bf16 use",
            "model = model.to(device)",
            "-        if dtype == torch.float32 or dtype.startswith('amp'):",
            "+        if dtype == torch.float32 or (",
            "+            isinstance(dtype, str) and dtype.startswith('amp')",
            "+        ):",
            "model.float()",
            "elif dtype == torch.bfloat16:",
            "convert_weights_to_lp(model, dtype=torch.bfloat16)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2713,
        "label": "no",
        "change": [
            "with tf.device('/cpu:0'):",
            "net = tl.layers.FlattenLayer(net, name='flatten')",
            "net = tl.layers.TernaryDenseLayer(net, 384, act=tf.nn.relu, name='d1relu')",
            "net = tl.layers.TernaryDenseLayer(net, 192, act=tf.nn.relu, name='d2relu')",
            "-            net = tl.layers.DenseLayer(net, 10, act=tf.identity, name='output')",
            "+            net = tl.layers.DenseLayer(net, 10, act=None, name='output')",
            "y = net.outputs",
            "",
            "ce = tl.cost.cross_entropy(y, y_, name='cost')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2715,
        "label": "no",
        "change": [
            "class TestBidirectonalEndpointSpanExtractor:",
            "# size: (batch_size=1, sequence_length=2, emb_dim=2)",
            "sequence_tensor = torch.FloatTensor([[[0.0, 0.0], [0.0, 0.0]]])",
            "# size: (batch_size=1, sequence_length=2)",
            "-        sequence_mask = torch.LongTensor([[0, 0]])",
            "+        sequence_mask = torch.BoolTensor([[False, False]])",
            "# size: (batch_size=1, spans_count=1, 2)",
            "span_indices = torch.LongTensor([[[-1, -1]]])",
            "# size: (batch_size=1, spans_count=1)",
            "-        span_indices_mask = torch.LongTensor([[0]])",
            "+        span_indices_mask = torch.BoolTensor([[False]])",
            "extractor = BidirectionalEndpointSpanExtractor(",
            "input_dim=2, forward_combination=\"x,y\", backward_combination=\"x,y\"",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2716,
        "label": "no",
        "change": [
            "def _triu_inverse(x):",
            "return x.reciprocal()",
            "else:",
            "identity = torch.eye(x.size(-1), dtype=x.dtype, device=x.device)",
            "-        return torch.triangular_solve(identity, x, upper=True)[0]",
            "+        return torch.linalg.solve_triangular(x, identity, upper=True)",
            "",
            "",
            "class BlockMassMatrix:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2718,
        "label": "no",
        "change": [
            "class E2E(ASRInterface, torch.nn.Module):",
            "",
            "if self.use_aux_ctc:",
            "if \"custom\" in self.etype:",
            "-                hs_mask = torch.IntTensor(",
            "-                    [h.size(1) for h in hs_mask],",
            "-                ).to(hs_mask.device)",
            "+                hs_mask = torch.IntTensor([h.size(1) for h in hs_mask]).to(",
            "+                    hs_mask.device",
            "+                )",
            "",
            "loss_ctc = self.aux_ctc_weight * self.aux_ctc(hs_pad, hs_mask, ys_pad)",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2719,
        "label": "no",
        "change": [
            "def quaternion_to_axis_angle(quaternions):",
            "# for x small, sin(x/2) is about x/2 - (x/2)^3/6",
            "# so sin(x/2)/x is about 1/2 - (x*x)/48",
            "sin_half_angles_over_angles[small_angles] = (",
            "-        0.5 - torch.square(angles[small_angles]) / 48",
            "+        0.5 - (angles[small_angles] * angles[small_angles]) / 48",
            ")",
            "return quaternions[..., 1:] / sin_half_angles_over_angles"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2720,
        "label": "no",
        "change": [
            "def PReLU(x, init=0.001, name='output'):",
            "init = tf.constant_initializer(init)",
            "alpha = tf.get_variable('alpha', [], initializer=init)",
            "x = ((1 + alpha) * x + (1 - alpha) * tf.abs(x))",
            "-    return tf.mul(x, 0.5, name=name)",
            "+    return tf.multiply(x, 0.5, name=name)",
            "",
            "",
            "@layer_register(use_scope=False, log_shape=False)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2721,
        "label": "no",
        "change": [
            "class SD(InpaintModel):",
            "))",
            "",
            "use_gpu = device == torch.device('cuda') and torch.cuda.is_available()",
            "-        torch_dtype = torch.float16 if use_gpu else torch.float32",
            "+        torch_dtype = torch.float16 if use_gpu and fp16 else torch.float32",
            "self.model = StableDiffusionInpaintPipeline.from_pretrained(",
            "self.model_id_or_path,",
            "revision=\"fp16\" if use_gpu and fp16 else \"main\","
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2723,
        "label": "no",
        "change": [
            "class Newsroom(datasets.GeneratorBasedBuilder):",
            "data_dir = os.path.abspath(os.path.expanduser(dl_manager.manual_dir))",
            "if not os.path.exists(data_dir):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('newsroom', data_dir=...)` that includes files unzipped from the reclor zip. Manual download instructions: {}\".format(",
            "-                    data_dir, self.manual_download_instructions",
            "-                )",
            "+                f\"{data_dir} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('newsroom', data_dir=...)` that includes files unzipped from the reclor zip. Manual download instructions: {self.manual_download_instructions}\"",
            ")",
            "return [",
            "datasets.SplitGenerator("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2724,
        "label": "no",
        "change": [
            "def set_realesrgan():",
            "tile=args.bg_tile,",
            "tile_pad=40,",
            "pre_pad=0,",
            "-        half=torch.cuda.is_available(), # need to set False in CPU/MPS mode",
            "+        half=use_half",
            ")",
            "",
            "if not gpu_is_available():  # CPU"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2726,
        "label": "no",
        "change": [
            "class ValueGuidedRLPipeline(DiffusionPipeline):",
            "shape = (batch_size, planning_horizon, self.state_dim + self.action_dim)",
            "",
            "# generate initial noise and apply our conditions (to make the trajectories start at current state)",
            "-        x1 = torch.randn(shape, device=self.unet.device)",
            "+        x1 = randn_tensor(shape, device=self.unet.device)",
            "x = self.reset_x0(x1, conditions, self.action_dim)",
            "x = self.to_torch(x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2727,
        "label": "yes",
        "change": [
            "class DomainClient(Client):",
            "",
            "return response",
            "",
            "-    def apply_to_network(self, target: str, reason: str):",
            "+    def apply_to_network(self,",
            "+            target: str,",
            "+            reason: str,",
            "+            route_index: int = 0):",
            "self.association.create(",
            "target=target,",
            "-            sender=self.conn.base_url.replace(\"/api/v1\", \"\"),",
            "+            sender=self.routes[route_index].connection.base_url.replace(\"/api/v1\", \"\"),",
            "reason=reason,",
            "node_name=self.name,",
            ")"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 2728,
        "label": "no",
        "change": [
            "class Checkpointer(Registrable):",
            "if self._serialization_dir:",
            "logger.info(\"loading best weights\")",
            "best_model_state_path = os.path.join(self._serialization_dir, \"best.th\")",
            "-            return torch.load(best_model_state_path)",
            "+            return torch.load(best_model_state_path, map_location=nn_util.device_mapping(-1))",
            "else:",
            "logger.info(",
            "\"cannot load best weights without `serialization_dir`, \""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2729,
        "label": "no",
        "change": [
            "def test_exp2(",
            "",
            "# copysign",
            "@handle_test(",
            "-    fn_tree='functional.experimental.copysign',",
            "+    fn_tree=\"functional.experimental.copysign\",",
            "dtype_x1_x2=helpers.dtype_and_values(",
            "available_dtypes=helpers.get_dtypes(\"float\"),",
            "num_arrays=2,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2730,
        "label": "no",
        "change": [
            "class PretrainedTransformerEmbedder(TokenEmbedder):",
            "return self.output_dim",
            "",
            "def forward(",
            "-        self, token_ids: torch.LongTensor, attention_mask: torch.LongTensor",
            "+        self, token_ids: torch.LongTensor, mask: torch.LongTensor",
            ") -> torch.Tensor:  # type: ignore",
            "",
            "-        return self.transformer_model(input_ids=token_ids, attention_mask=attention_mask)[0]",
            "+        return self.transformer_model(input_ids=token_ids, attention_mask=mask)[0]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2733,
        "label": "no",
        "change": [
            "def class_balanced_sigmoid_cross_entropy(logits, label, name='cross_entropy_loss",
            ":param label: size: the ground truth in {0,1}, of the same shape as logits.",
            ":returns: a scalar. class-balanced cross entropy loss",
            "\"\"\"",
            "-    z = batch_flatten(logits)",
            "-    y = tf.cast(batch_flatten(label), tf.float32)",
            "+    y = tf.cast(label, tf.float32)",
            "",
            "count_neg = tf.reduce_sum(1. - y)",
            "count_pos = tf.reduce_sum(y)",
            "beta = count_neg / (count_neg + count_pos)",
            "",
            "pos_weight = beta / (1 - beta)",
            "-    cost = tf.nn.weighted_cross_entropy_with_logits(z, y, pos_weight)",
            "+    cost = tf.nn.weighted_cross_entropy_with_logits(logits, y, pos_weight)",
            "cost = tf.reduce_mean(cost * (1 - beta), name=name)",
            "",
            "#logstable = tf.log(1 + tf.exp(-tf.abs(z)))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2734,
        "label": "no",
        "change": [
            "class SubsamplingStep(MetaOptimizer):",
            "num_samples = tf.maximum(x=tf.cast(x=num_samples, dtype=util.tf_dtype('int')), y=one)",
            "indices = tf.random.uniform(shape=(num_samples,), maxval=batch_size, dtype=tf.int32)",
            "",
            "-        function = (lambda x: x if util.rank(x=x) == 0 else tf.gather(params=x, indices=indices))",
            "+        function = (lambda x: tf.gather(params=x, indices=indices))",
            "subsampled_arguments = util.fmap(function=function, xs=arguments)",
            "",
            "return self.optimizer.step(variables=variables, arguments=subsampled_arguments, **kwargs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2735,
        "label": "no",
        "change": [
            "class GANOperator(TrainingOperator):",
            "",
            "# Compute a discriminator update for real images",
            "discriminator.zero_grad()",
            "+        # self.device is set automatically",
            "real_cpu = batch[0].to(self.device)",
            "batch_size = real_cpu.size(0)",
            "label = torch.full((batch_size, ), real_label, device=self.device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2738,
        "label": "no",
        "change": [
            "class RealESRGANer():",
            "self.half = half",
            "",
            "# initialize model",
            "-        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
            "+        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') if device is None else device",
            "# if the model_path starts with https, it will first download models to the folder: realesrgan/weights",
            "if model_path.startswith('https://'):",
            "model_path = load_file_from_url("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2741,
        "label": "no",
        "change": [
            "class PooledFlairEmbeddings(TokenEmbeddings):",
            "",
            "# set aggregation operation",
            "if self.pooling == \"mean\":",
            "-                                aggregated_embedding = torch.mean(self.word_embeddings[token.text], local_embedding)",
            "+                                aggregated_embedding = torch.add(self.word_embeddings[token.text], local_embedding)",
            "elif self.pooling == \"fade\":",
            "aggregated_embedding = torch.add(self.word_embeddings[token.text], local_embedding)",
            "aggregated_embedding /= 2"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2743,
        "label": "no",
        "change": [
            "class ResNet(nn.Module):",
            "",
            "x = self.avgpool(x)",
            "x = x.view(x.size(0), -1)",
            "-    x = self.fc(x)",
            "+    x = self.last_linear(x)",
            "",
            "return x"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2745,
        "label": "no",
        "change": [
            "class FP16_Optimizer(object):",
            "# print([param.grad.data for param in self.all_fp32_from_fp32_params])",
            "# quit()",
            "self.overflow = self.loss_scaler.update_scale()",
            "+        # torch.cuda.nvtx.range_pop()",
            "",
            "",
            "def inspect_master_grad_data(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2746,
        "label": "no",
        "change": [
            "_LICENSE = \"CC-BY-4.0\"",
            "class MBPP(datasets.GeneratorBasedBuilder):",
            "\"\"\"MBPP: Mostly Basic Python Problems Dataset\"\"\"",
            "",
            "-    VERSION = datasets.Version(\"1.0.0\")",
            "+    VERSION = datasets.Version(\"1.0.1\")",
            "",
            "BUILDER_CONFIGS = [",
            "datasets.BuilderConfig(",
            "name=f\"{split}\",",
            "-            version=datasets.Version(\"1.0.0\"),",
            "+            version=datasets.Version(\"1.0.1\"),",
            "description=_DESCRIPTION,",
            ")",
            "for split in _SPLITS"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2747,
        "label": "no",
        "change": [
            "class _ProposalLayer(nn.Module):",
            "# blob = np.hstack((batch_inds, proposals.astype(np.float32, copy=False)))",
            "# top[0].reshape(*(blob.shape))",
            "# top[0].data[...] = blob",
            "-        batch_inds = torch.FloatTensor(proposals.size(0), 1).zero_()",
            "-        output = torch.cat((batch_inds, proposals), 1)",
            "+",
            "+        self.batch_inds.resize_(proposals.size(0), 1).zero_()",
            "+        output = torch.cat((self.batch_inds, proposals), 1)",
            "",
            "# [Optional] output scores blob",
            "# if len(top) > 1:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2750,
        "label": "no",
        "change": [
            "class Evolutionary(Optimizer):",
            "applied = self.apply_step(variables=variables, diffs=perturbation_diffs)",
            "",
            "with tf.control_dependencies(control_inputs=(applied,)):",
            "-            return [tf.identity(input=diff) for diff in diffs]",
            "+            return [diff + 0.0 for diff in diffs]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2753,
        "label": "no",
        "change": [
            "class TFTacotron2(tf.keras.Model):",
            "alignment_size=max_length_encoder",
            ")",
            "",
            "-        for i in tf.range(max_decoder_steps):",
            "+        for i in range(max_decoder_steps):",
            "decoder_inputs = TFTacotronDecoderInput(",
            "time_first_mels_outputs[i],",
            "encoder_hidden_states,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2754,
        "label": "no",
        "change": [
            "class RagRetriever:",
            "",
            ">>> dataset = (",
            "...     ...",
            "-    >>> )  # dataset must be a datasets.Datasets object with columns \"title\", \"text\" and \"embeddings\", and it must have a faiss index",
            "+    ... )  # dataset must be a datasets.Datasets object with columns \"title\", \"text\" and \"embeddings\", and it must have a faiss index",
            ">>> retriever = RagRetriever.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\", indexed_dataset=dataset)",
            "",
            ">>> # To load your own indexed dataset built with the datasets library that was saved on disk. More info in examples/rag/use_own_knowledge_dataset.py"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2761,
        "label": "no",
        "change": [
            "class DecodeText(InferenceTask):",
            "if \"attention_scores\" in self._predictions:",
            "fetches[\"attention_scores\"] = self._predictions[\"attention_scores\"]",
            "",
            "-    return SessionRunArgs(fetches)",
            "+    return tf.train.SessionRunArgs(fetches)",
            "",
            "def after_run(self, _run_context, run_values):",
            "fetches_batch = run_values.results"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2765,
        "label": "no",
        "change": [
            "class Parser(nn.Module):",
            "dist_kld = dist_kld[:, 1:].masked_select(goldmask)",
            "loss -= dist_kld.sum()",
            "",
            "-            loss /= word.size(0)",
            "+            loss /= wordchars.size(0) # number of words",
            "else:",
            "loss = 0",
            "preds.append(F.log_softmax(unlabeled_scores, 2).detach().cpu().numpy())"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2766,
        "label": "no",
        "change": [
            "class Highway(torch.nn.Module):",
            "layer.bias[input_dim:].data.fill_(1)",
            "",
            "@overrides",
            "-    def forward(self, inputs: torch.Tensor) -> torch.Tensor:  # pylint: disable=arguments-differ",
            "+    def forward(self, inputs: torch.Tensor) -> torch.Tensor:",
            "current_input = inputs",
            "for layer in self._layers:",
            "projected_input = layer(current_input)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2769,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "for idx, b in enumerate([b1, b2, b3, b4, b5, final_map]):",
            "output = tf.nn.sigmoid(b, name='output{}'.format(idx+1))",
            "xentropy = class_balanced_sigmoid_cross_entropy(",
            "-                tf.squeeze(b, [3]), edgemap,",
            "+                b, edgemap,",
            "name='xentropy{}'.format(idx+1))",
            "costs.append(xentropy)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2771,
        "label": "no",
        "change": [
            "def focal_loss(",
            "device=input.device, dtype=input.dtype)",
            "",
            "# compute the actual focal loss",
            "-    weight = torch.pow(1. - input_soft, gamma)",
            "+    weight = torch.pow(-input_soft + 1., gamma)",
            "",
            "focal = -alpha * weight * torch.log(input_soft)",
            "loss_tmp = torch.sum(target_one_hot * focal, dim=1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2772,
        "label": "no",
        "change": [
            "class SqueezeBertModelIntegrationTest(unittest.TestCase):",
            "def test_inference_classification_head(self):",
            "model = SqueezeBertForSequenceClassification.from_pretrained(\"squeezebert/squeezebert-mnli\")",
            "",
            "-        input_ids = torch.tensor([[0, 29414, 232, 328, 740, 1140, 12695, 69, 13, 1588, 2]])",
            "+        input_ids = torch.tensor([[1, 29414, 232, 328, 740, 1140, 12695, 69, 13, 1588, 2]])",
            "output = model(input_ids)[0]",
            "expected_shape = torch.Size((1, 3))",
            "self.assertEqual(output.shape, expected_shape)",
            "-        expected_tensor = torch.tensor([[0.5075, 0.0682, -0.5881]])",
            "+        expected_tensor = torch.tensor([[0.6401, -0.0349, -0.6041]])",
            "self.assertTrue(torch.allclose(output, expected_tensor, atol=1e-4))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2774,
        "label": "no",
        "change": [
            "class SyntheticDataset(Dataset):",
            "img = torch.from_numpy(img).squeeze(0).float()",
            "img = ((img / 255) - 0.5) / 0.5",
            "self.img = img",
            "-        self.label = torch.ones([1], dtype=torch.long)",
            "+        self.label = 1",
            "",
            "def __getitem__(self, index):",
            "return self.img, self.label"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2775,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)",
            "cost = tf.reduce_mean(cost, name='cross_entropy_loss')",
            "",
            "-        wrong = tf.to_float(tf.logical_not(tf.nn.in_top_k(logits, label, 1)), name='incorrect_vector')",
            "+        wrong = tf.cast(tf.logical_not(tf.nn.in_top_k(logits, label, 1)), tf.float32, name='incorrect_vector')",
            "summary.add_moving_summary(tf.reduce_mean(wrong, name='train_error'))",
            "",
            "wd_cost = tf.multiply(1e-5, regularize_cost('fc.*/W', tf.nn.l2_loss),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2779,
        "label": "no",
        "change": [
            "def random_affine_generator(",
            "sx=sx,",
            "sy=sy,",
            "resample=torch.tensor(Resample.get(resample).value),",
            "+                padding_mode=torch.tensor(SamplePadding.get(padding_mode).value),",
            "align_corners=torch.tensor(align_corners))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2780,
        "label": "no",
        "change": [
            "class BertForNextSentencePrediction(PreTrainedBertModel):",
            "# Already been converted into WordPiece token ids",
            "input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])",
            "input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])",
            "-    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 2, 0]])",
            "+    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])",
            "",
            "config = BertConfig(vocab_size=32000, hidden_size=512,",
            "num_hidden_layers=8, num_attention_heads=6, intermediate_size=1024)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2781,
        "label": "no",
        "change": [
            "class WavLMAttention(nn.Module):",
            "relative_positions_if_large = torch.log(relative_positions.float() / max_exact)",
            "relative_positions_if_large = relative_positions_if_large / math.log(self.max_distance / max_exact)",
            "relative_positions_if_large = relative_positions_if_large * (num_buckets - max_exact)",
            "-        relative_postion_if_large = (max_exact + relative_positions_if_large).to(torch.long)",
            "-        relative_postion_if_large = torch.min(",
            "-            relative_postion_if_large, torch.full_like(relative_postion_if_large, num_buckets - 1)",
            "+        relative_position_if_large = (max_exact + relative_positions_if_large).to(torch.long)",
            "+        relative_position_if_large = torch.min(",
            "+            relative_position_if_large, torch.full_like(relative_position_if_large, num_buckets - 1)",
            ")",
            "",
            "-        relative_buckets += torch.where(is_small, relative_positions, relative_postion_if_large)",
            "+        relative_buckets += torch.where(is_small, relative_positions, relative_position_if_large)",
            "return relative_buckets"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2782,
        "label": "no",
        "change": [
            "def train_fn(compute_config: TfDataServiceConfig, reuse_dataset: bool = False, r",
            "",
            "# Horovod: adjust learning rate based on number of GPUs.",
            "scaled_lr = 0.001 * hvd.size()",
            "-    opt = tf.optimizers.Adam(scaled_lr)",
            "+    opt = optimizers.Adam(scaled_lr)",
            "",
            "# Horovod: add Horovod DistributedOptimizer.",
            "opt = hvd.DistributedOptimizer("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2783,
        "label": "yes",
        "change": [
            "class CNNLayerVisualization():",
            "self.conv_output = x[0, self.selected_filter]",
            "# Loss function is the mean of the output of the selected layer/filter",
            "# We try to minimize the mean of the output of that specific filter",
            "-            loss = torch.mean(self.conv_output)",
            "-            print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()[0]))",
            "+            loss = -torch.mean(self.conv_output)",
            "+            print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))",
            "# Backward",
            "loss.backward()",
            "# Update image"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 2784,
        "label": "yes",
        "change": [
            "class BitEncoder(nn.Module):",
            "dilation = 1",
            "",
            "layer_dropouts = [",
            "-            x.tolist() for x in torch.linspace(0, config.drop_path_rate, sum(config.depths)).split(config.depths)",
            "+            x.tolist()",
            "+            for x in torch.Tensor(np.linspace(0, config.drop_path_rate, sum(config.depths))).split(config.depths)",
            "]",
            "",
            "for stage_idx, (current_depth, current_hidden_size, layer_dropout) in enumerate("
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 2785,
        "label": "no",
        "change": [
            "class MultiHeadAttention(nn.Module):",
            "q = q / math.sqrt(dim_per_head)  # (bs, n_heads, qlen, dim_per_head)",
            "scores = torch.matmul(q, k.transpose(2, 3))  # (bs, n_heads, qlen, klen)",
            "mask = (mask == 0).view(mask_reshape).expand_as(scores)  # (bs, n_heads, qlen, klen)",
            "-        scores.masked_fill_(mask, -float(\"inf\"))  # (bs, n_heads, qlen, klen)",
            "+        scores.masked_fill_(mask, torch.finfo(scores.dtype).min)  # (bs, n_heads, qlen, klen)",
            "",
            "weights = nn.functional.softmax(scores.float(), dim=-1).type_as(scores)  # (bs, n_heads, qlen, klen)",
            "weights = nn.functional.dropout(weights, p=self.dropout, training=self.training)  # (bs, n_heads, qlen, klen)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2786,
        "label": "yes",
        "change": [
            "def absolute_path(path):",
            "This implementation avoids calling os.path.abspath(path) if 'path' already",
            "represents an absolute Tensorflow filesystem location (e.g. <fs type>://).",
            "\"\"\"",
            "-  return path if \"://\" in str(path) else os.path.abspath(path)",
            "+  return path if b\"://\" in tf.compat.as_bytes(path) else os.path.abspath(path)",
            "",
            "",
            "def fc2_implements_resources():"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 2787,
        "label": "no",
        "change": [
            "def mean_iou(",
            "# iterate over classes",
            "for class_id in range(num_classes):",
            "tp: torch.Tensor = conf_mat[..., None, class_id, class_id]",
            "-        total = torch.sum(conf_mat[..., class_id, :], dim=-1, keepdim=True) + \\",
            "+        total: torch.Tensor = \\",
            "+            torch.sum(conf_mat[..., class_id, :], dim=-1, keepdim=True) + \\",
            "torch.sum(conf_mat[..., :, class_id], dim=-1, keepdim=True)",
            "iou_val: torch.Tensor = tp / (total.float() - tp + 1e-6)",
            "ious[..., class_id:class_id + 1] += iou_val"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2791,
        "label": "yes",
        "change": [
            "def main():",
            "if requires_preprocessing:",
            "prepare_input = PREPROCESSING_FUNCTIONS.get(args.model_type)",
            "prompt_text, model_kwargs = prepare_input(args, model, tokenizer, prompt_text)",
            "-    encoded_prompt = torch.tensor(tokenizer.encode(prompt_text, add_special_tokens=False)).unsqueeze(0)",
            "+    encoded_prompt = tokenizer.encode(prompt_text, add_special_tokens=False, return_tensors='pt')",
            "",
            "output_sequences = model.generate(",
            "-        intput_ids=encoded_prompt,",
            "-        length=args.length,",
            "+        input_ids=encoded_prompt,",
            "+        max_length=args.length,",
            "temperature=args.temperature,",
            "top_k=args.k,",
            "top_p=args.p,"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 2793,
        "label": "no",
        "change": [
            "import tensorflow as tf",
            "from typing import Union",
            "",
            "",
            "-def l2_normalize(x: Union[tf.Tensor, tf.Variable],",
            "-                 axis: int = None,",
            "-                 out=None",
            "-                 ) -> tf.Tensor:",
            "+def l2_normalize(",
            "+    x: Union[tf.Tensor, tf.Variable], axis: int = None, out=None",
            "+) -> tf.Tensor:",
            "",
            "denorm = tf.norm(x, axis=axis, keepdims=True)",
            "denorm = tf.math.maximum(denorm, 1e-12)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2794,
        "label": "no",
        "change": [
            "def rgba_to_rgb(image: torch.Tensor) -> torch.Tensor:",
            "g_new: torch.Tensor = a_one * g + a * g",
            "b_new: torch.Tensor = a_one * b + a * b",
            "",
            "-    return torch.cat([r, g, b], dim=-3)",
            "+    return torch.cat([r_new, g_new, b_new], dim=-3)",
            "",
            "",
            "def rgba_to_bgr(image: torch.Tensor) -> torch.Tensor:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2795,
        "label": "no",
        "change": [
            "def random_uniform(",
            "device: str,",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "+    shape = _check_bounds_and_get_shape(low, high, shape)",
            "low = tf.cast(low, dtype)",
            "high = tf.cast(high, dtype)",
            "with tf.device(device):",
            "-        return tf.random.uniform(shape if shape else (), low, high, dtype=dtype)",
            "+        return tf.random.uniform(shape, low, high, dtype=dtype)",
            "",
            "",
            "def random_normal("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2796,
        "label": "no",
        "change": [
            "def matrix_to_quaternion(matrix: torch.Tensor) -> torch.Tensor:",
            "dim=-2,",
            ")",
            "",
            "-    # clipping is not important here; if q_abs is small, the candidate won't be picked",
            "-    quat_candidates = quat_by_rijk / (2.0 * q_abs[..., None].clip(0.1))",
            "+    # We floor here at 0.1 but the exact level is not important; if q_abs is small,",
            "+    # the candidate won't be picked.",
            "+    # pyre-ignore [16]: `torch.Tensor` has no attribute `new_tensor`.",
            "+    quat_candidates = quat_by_rijk / (2.0 * q_abs[..., None].max(q_abs.new_tensor(0.1)))",
            "",
            "# if not for numerical problems, quat_candidates[i] should be same (up to a sign),",
            "# forall i; we pick the best-conditioned one (with the largest denominator)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2797,
        "label": "no",
        "change": [
            "class AutoencoderKLTests(ModelTesterMixin, unittest.TestCase):",
            "model.config.in_channels,",
            "model.config.sample_size,",
            "model.config.sample_size,",
            "-            generator=generator,",
            "+            generator=torch.manual_seed(0),",
            ")",
            "image = image.to(torch_device)",
            "with torch.no_grad():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2798,
        "label": "yes",
        "change": [
            "class PlanTranslatorTorchscript(AbstractPlanTranslator):",
            "translation_plan = self.plan.copy()",
            "translation_plan.forward = None",
            "",
            "-        args_shape = translation_plan.get_args_shape()",
            "-        args = PlaceHolder.create_placeholders(args_shape)",
            "+        args = translation_plan.create_dummy_args()",
            "",
            "-        # To avoid storing Plan state tensors in torchscript, they will be send as parameters",
            "+        # jit.trace clones input args and can change their type, so we have to skip types check",
            "+        # TODO see if type check can be made less strict,",
            "+        #  e.g. tensor/custom tensor/nn.Parameter could be considered same type",
            "+        translation_plan.validate_input_types = False",
            "+",
            "+        # To avoid storing Plan state tensors in torchscript, they will be sent as parameters",
            "# we trace wrapper func, which accepts state parameters as last arg",
            "# and sets them into the Plan before executing the Plan",
            "def wrap_stateful_plan(*args):"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 2799,
        "label": "no",
        "change": [
            "def sample_autoregressive(partial_sequences,",
            "partial_sequences_eos_count = 0",
            "else:",
            "initial_states = context_first_part.new_states",
            "-    partial_sequences_eos_count = mtf.reduce_sum(",
            "-        mtf.to_int32(mtf.equal(partial_sequences, stop_at_token)),",
            "-        reduced_dim=length_dim)",
            "+    if stop_at_token is not None:",
            "+        partial_sequences_eos_count = mtf.reduce_sum(",
            "+            mtf.to_int32(mtf.equal(partial_sequences, stop_at_token)),",
            "+            reduced_dim=length_dim)",
            "",
            "def cond_fn(position, ids, *unused_states):",
            "\"\"\"Should we run another loop iteration.\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2802,
        "label": "no",
        "change": [
            "def unmap(data, count, inds, fill=0):",
            "size count) \"\"\"",
            "if data.dim() == 1:",
            "ret = data.new_full((count, ), fill)",
            "-        ret[inds] = data",
            "+        ret[inds.type(torch.bool)] = data",
            "else:",
            "new_size = (count, ) + data.size()[1:]",
            "ret = data.new_full(new_size, fill)",
            "-        ret[inds, :] = data",
            "+        ret[inds.type(torch.bool), :] = data",
            "return ret"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2803,
        "label": "yes",
        "change": [
            "class TFEmbedding(tf.keras.layers.Embedding):",
            "super().__init__(*args, **kwargs)",
            "",
            "def call(self, inputs):",
            "-        inputs = tf.cast(tf.expand_dims(inputs, -1), tf.int32)",
            "-        outputs = tf.gather_nd(self.embeddings, inputs)",
            "+        inputs = tf.cast(inputs, tf.int32)",
            "+        outputs = tf.gather(self.embeddings, inputs)",
            "return outputs"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "removal",
        "Element": "api call"
    },
    {
        "number": 2804,
        "label": "no",
        "change": [
            "class AUROC(TensorMetric):",
            "Example:",
            "",
            ">>> pred = torch.tensor([0, 1, 2, 3])",
            "-        >>> target = torch.tensor([0, 1, 2, 2])",
            "+        >>> target = torch.tensor([0, 1, 1, 0])",
            ">>> metric = AUROC()",
            ">>> metric(pred, target)",
            "-        tensor(0.3333)",
            "+        tensor(0.5000)",
            "",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2805,
        "label": "no",
        "change": [
            "class CLIPModelIntegrationTest(unittest.TestCase):",
            "torch.Size((inputs.input_ids.shape[0], inputs.pixel_values.shape[0])),",
            ")",
            "",
            "-        expected_logits = torch.tensor([[24.5056, 18.8076]], device=torch_device)",
            "+        expected_logits = torch.tensor([[24.5701, 19.3049]], device=torch_device)",
            "",
            "self.assertTrue(torch.allclose(outputs.logits_per_image, expected_logits, atol=1e-3))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2806,
        "label": "no",
        "change": [
            "class TRPOModel(PolicyGradientModel):",
            "# Improve update step through simple backtracking line search",
            "# N.b. some implementations skip the line search",
            "previous_theta = self.flat_variable_helper.get()",
            "-        improved, theta = line_search(self.compute_surrogate_loss, previous_theta, update_step, negative_gradient_direction / (lagrange_multiplier + util.epsilon), self.ls_max_backtracks, self.ls_accept_ratio)",
            "+        improved, theta = line_search(self.compute_surrogate_loss, previous_theta, update_step,",
            "+                                      negative_gradient_direction / (lagrange_multiplier + util.epsilon),",
            "+                                      self.ls_max_backtracks, self.ls_accept_ratio)",
            "",
            "# Use line search results, otherwise take full step",
            "# N.B. some implementations don't use the line search"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2810,
        "label": "no",
        "change": [
            "class AssignResult(util_mixins.NiceRepr):",
            "return self",
            "",
            "def add_gt_(self, gt_labels):",
            "+        \"\"\"Add ground truth as assigned results",
            "+",
            "+        Args:",
            "+            gt_labels (torch.Tensor): Labels of gt boxes",
            "+        \"\"\"",
            "self_inds = torch.arange(",
            "1, len(gt_labels) + 1, dtype=torch.long, device=gt_labels.device)",
            "self.gt_inds = torch.cat([self_inds, self.gt_inds])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2812,
        "label": "no",
        "change": [
            "class ShaDowKHopSampler(torch.utils.data.DataLoader):",
            "batch.edge_index = torch.stack([row, col], dim=0)",
            "",
            "for k, v in self.data:",
            "-            if k in ['edge_index', 'adj_t']:",
            "+            if k in ['edge_index', 'adj_t', 'num_nodes']:",
            "continue",
            "if k == 'y' and v.size(0) == self.data.num_nodes:",
            "batch[k] = v[n_id][root_n_id]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2819,
        "label": "yes",
        "change": [
            "class Model(object):",
            "self.deterministic_mode = config.get('deterministic_mode', False)",
            "self.episode_length = tf.placeholder(tf.int32, (None,), name='episode_length')",
            "",
            "-        self.alpha = config.get('alpha', 0.001)",
            "+        self.learning_rate = config.get('learning_rate', 0.001)",
            "",
            "optimizer = config.get('optimizer')",
            "if not optimizer:",
            "-            self.optimizer = tf.train.AdamOptimizer(self.alpha)",
            "+            self.optimizer = tf.train.AdamOptimizer(self.learning_rate)",
            "else:",
            "args = config.get('optimizer_args', [])",
            "kwargs = config.get('optimizer_kwargs', {})",
            "optimizer_cls = get_function(optimizer)",
            "-            self.optimizer = optimizer_cls(self.alpha, *args, **kwargs)",
            "+            self.optimizer = optimizer_cls(self.learning_rate, *args, **kwargs)",
            "",
            "exploration = config.get('exploration')",
            "if not exploration:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 2820,
        "label": "no",
        "change": [
            "class BertEncoder(layers.Layer):",
            "super().__init__(**kwargs)",
            "embedding_width = 768",
            "dropout_rate = 0.1",
            "-        initializer = keras.initializers.TruncatedNormal(stddev=0.02)",
            "+        initializer = keras.initializers.TruncatedNormal(stddev=0.02, seed=42)",
            "",
            "self._embedding_layer = OnDeviceEmbedding(",
            "vocab_size=30522,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2822,
        "label": "no",
        "change": [
            "class Twins(nn.Module):",
            "",
            "def reset_classifier(self, num_classes, global_pool=''):",
            "self.num_classes = num_classes",
            "-        self.head = nn.Linear(self.embed_dim, num_classes) if num_classes > 0 else nn.Identity()",
            "+        self.head = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()",
            "",
            "def _init_weights(self, m):",
            "if isinstance(m, nn.Linear):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2824,
        "label": "no",
        "change": [
            "class ParityModuleMNIST(LightningModule):",
            "self.c_d1_bn = nn.BatchNorm1d(128)",
            "self.c_d1_drop = nn.Dropout(0.3)",
            "self.c_d2 = nn.Linear(in_features=128, out_features=10)",
            "+        self.example_input_array = torch.rand(2, 1, 28, 28)",
            "",
            "def forward(self, x):",
            "x = x.view(x.size(0), -1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2825,
        "label": "no",
        "change": [
            "def test_rmsle(pred, target, expected):",
            "])",
            "def test_psnr_with_skimage(pred, target):",
            "score = psnr(pred=torch.tensor(pred),",
            "-                 target=torch.tensor(target))",
            "+                 target=torch.tensor(target), data_range=3)",
            "sk_score = ski_psnr(np.array(pred), np.array(target), data_range=3)",
            "assert torch.allclose(score, torch.tensor(sk_score, dtype=torch.float), atol=1e-3)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2827,
        "label": "yes",
        "change": [
            "class Metric(Registrable):",
            "raise NotImplementedError",
            "",
            "@staticmethod",
            "-    def unwrap_to_tensors(*tensors: torch.Tensor):",
            "+    def detach_tensors(*tensors: torch.Tensor) -> Iterable[torch.Tensor]:",
            "\"\"\"",
            "If you actually passed gradient-tracking Tensors to a Metric, there will be",
            "a huge memory leak, because it will prevent garbage collection for the computation",
            "-        graph. This method ensures that you're using tensors directly and that they are on",
            "-        the CPU.",
            "+        graph. This method ensures the tensors are detached.",
            "\"\"\"",
            "-        return (x.detach().cpu() if isinstance(x, torch.Tensor) else x for x in tensors)",
            "+        # Check if it's actually a tensor in case something else was passed.",
            "+        return (x.detach() if isinstance(x, torch.Tensor) else x for x in tensors)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 2828,
        "label": "no",
        "change": [
            "D_gan = torch.nn.Sequential(",
            "",
            "D_aux = torch.nn.Sequential(",
            "torch.nn.Linear(h_dim, y_dim),",
            "-    torch.nn.Softmax()",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2832,
        "label": "no",
        "change": [
            "class UNet2DConditionModel(ModelMixin, ConfigMixin):",
            "# 6. post-process",
            "# make sure hidden states is in float32",
            "# when running in half-precision",
            "-        sample = self.conv_norm_out(sample.float()).type(sample.dtype)",
            "+        sample = self.conv_norm_out(sample)",
            "sample = self.conv_act(sample)",
            "sample = self.conv_out(sample)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2833,
        "label": "no",
        "change": [
            "class Reshaper(object):",
            "def split_tensor(self, tensor, axis=-1):",
            "# FIXME (ev) This won't work for mixed action distributions like",
            "# one agent Gaussian one agent discrete",
            "-        slice_rescale = int(tensor.shape.as_list()[axis] /",
            "-                            int(np.sum(self.get_slice_lengths())))",
            "-        return tf.split(tensor, slice_rescale*self.get_slice_lengths(),",
            "-                        axis=axis)",
            "+        slice_rescale = int(tensor.shape.as_list()[axis] / int(",
            "+            np.sum(self.get_slice_lengths())))",
            "+        return tf.split(",
            "+            tensor, slice_rescale * self.get_slice_lengths(), axis=axis)",
            "",
            "def split_number(self, number):",
            "slice_rescale = int(number / int(np.sum(self.get_slice_lengths())))",
            "-        return slice_rescale*self.get_slice_lengths()",
            "+        return slice_rescale * self.get_slice_lengths()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2836,
        "label": "no",
        "change": [
            "class TargetIndegreeAdj(object):",
            "degree /= degree.max()  # Normalize.",
            "degree = degree[col]  # Target nodes.",
            "",
            "-        # Modify data and return.",
            "-        data.adj = SparseTensor(index, degree, torch.Size([n, n]))",
            "-        return data",
            "+        return SparseTensor(index, degree, torch.Size([n, n]))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2838,
        "label": "no",
        "change": [
            "def max_pool2d(",
            "pad_h = ivy.handle_padding(x_shape[0], strides[0], kernel[0], padding)",
            "pad_w = ivy.handle_padding(x_shape[1], strides[1], kernel[1], padding)",
            "x = torch.nn.functional.pad(",
            "-        x, [pad_w // 2,",
            "-            pad_w - pad_w // 2,",
            "-            pad_h // 2,",
            "-            pad_h - pad_h // 2],",
            "-        value=float(\"-inf\")",
            "+        x,",
            "+        [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2],",
            "+        value=float(\"-inf\"),",
            ")",
            "if padding != \"VALID\" and padding != \"SAME\":",
            "raise ivy.exceptions.IvyException("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2839,
        "label": "no",
        "change": [
            "def connect(",
            "metadata, _user_key = conn.login(credentials=credentials)  # type: ignore",
            "_user_key = SigningKey(_user_key.encode(), encoder=HexEncoder)",
            "else:",
            "-        metadata = conn.auth_using_key(user_key=user_key)  # type: ignore",
            "+        # metadata = conn.auth_using_key(user_key=user_key)  # type: ignore",
            "_user_key = user_key",
            "",
            "# Check node client type based on metadata response"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2840,
        "label": "no",
        "change": [
            "class ProjectedNormal(TorchDistribution):",
            "Note this is the mean in the sense of a centroid in the submanifold",
            "that minimizes expected squared geodesic distance.",
            "\"\"\"",
            "-        return safe_project(self.concentration)",
            "+        return safe_normalize(self.concentration)",
            "",
            "@property",
            "def mode(self):",
            "-        return safe_project(self.concentration)",
            "+        return safe_normalize(self.concentration)",
            "",
            "def rsample(self, sample_shape=torch.Size()):",
            "shape = self._extended_shape(sample_shape)",
            "x = self.concentration.new_empty(shape).normal_()",
            "x = x + self.concentration",
            "-        x = safe_project(x)",
            "+        x = safe_normalize(x)",
            "return x",
            "",
            "def log_prob(self, value):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2841,
        "label": "yes",
        "change": [
            "class Synthesizer(object):",
            "sample_rate=self.ap.sample_rate,",
            ").cuda()",
            "",
            "-        check = torch.load(model_file)",
            "-        self.wavernn.load_state_dict(check['model'], map_location=\"cpu\")",
            "+        check = torch.load(model_file, map_location=\"cpu\")",
            "+        self.wavernn.load_state_dict(check['model'])",
            "if use_cuda:",
            "self.wavernn.cuda()",
            "self.wavernn.eval()"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 2843,
        "label": "no",
        "change": [
            "class BeamSearch(Registrable):",
            "",
            "for i, constraint in enumerate(self.constraints):",
            "constraint_states[i] = constraint.update_state(",
            "-                    constraint_states[i], restricted_predicted_classes",
            "+                    constraint_states[i], restricted_predicted_classes, last_backpointer=backpointer",
            ")",
            "",
            "# Warn about \"-inf\" log probabilities if not using any constraints (negligible"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2844,
        "label": "no",
        "change": [
            "class TestEqualization(BaseTester):",
            "inputs = torch.rand(bs, channels, height, width, device=device, dtype=dtype)",
            "inputs = tensor_to_gradcheck_var(inputs)",
            "",
            "-        def grad_rot(input, a, b, c):",
            "-            rot = rotate(input, torch.tensor(30.0, dtype=input.dtype, device=device))",
            "+        def grad_rot(inpt, a, b, c):",
            "+            rot = rotate(inpt, torch.tensor(30.0, dtype=inpt.dtype, device=device))",
            "return enhance.equalize_clahe(rot, a, b, c)",
            "",
            "assert gradcheck(grad_rot, (inputs, 40.0, (2, 2), True), nondet_tol=1e-4, raise_exception=True, fast_mode=True)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2845,
        "label": "yes",
        "change": [
            "def floor_divide(",
            "if (not np.all(x2)) or (np.any(x2) == -0):  # check for division by zero",
            "ret = np.floor_divide(x1, x2)",
            "else:",
            "-        ret = tf.math.floordiv(x1, x2)",
            "+        ret = tf.experimental.numpy.floor_divide(x1, x2)",
            "",
            "if (any(isinf(x1)) and any(isfinite(x2))) or (any(isfinite(x1)) and any(isinf(x2))):",
            "return ivy.full_like(ret, floor(divide(x1, x2)), dtype=ret.dtype)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 2848,
        "label": "no",
        "change": [
            "def test_plan_module_tracing():",
            "y = torch.rand([1])",
            "return x + y",
            "",
            "-    p = plan_test(torch.tensor([3]))",
            "+    plan_test(torch.tensor([3]))",
            "assert len(plan_test.role.actions) == 2"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2850,
        "label": "no",
        "change": [
            "class TvltModelIntegrationTest(unittest.TestCase):",
            "outputs = model(**inputs)",
            "",
            "# verify the logits",
            "-        expected_last_hidden_state_slice = torch.tensor([[-0.0186, -0.0691], [0.0242, -0.0398]])",
            "+        expected_last_hidden_state_slice = torch.tensor([[-0.0186, -0.0691], [0.0242, -0.0398]], device=torch_device)",
            "self.assertTrue(",
            "torch.allclose(outputs.last_hidden_state[:, :2, :2], expected_last_hidden_state_slice, atol=1e-4)",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2852,
        "label": "no",
        "change": [
            "class RandomVerticalFlip(RandomFlip):",
            "wont be concatenated",
            "",
            "Examples:",
            "-        >>> input = torch.tensor([[[",
            "-            [0., 0., 0.],",
            "-            [0., 0., 0.],",
            "-            [0., 1., 1.]]]])",
            "+        >>> input = torch.tensor([[[[0., 0., 0.],",
            "+                                    [0., 0., 0.],",
            "+                                    [0., 1., 1.]]]])",
            ">>> seq = nn.Sequential(kornia.augmentation.RandomVerticalFlip(p=1.0, return_transform=True))",
            ">>> seq(input)",
            "(tensor([[0., 1., 1.],"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2859,
        "label": "yes",
        "change": [
            "class DDIMScheduler(SchedulerMixin, ConfigMixin):",
            "prev_sample = alpha_prod_t_prev ** (0.5) * pred_original_sample + pred_sample_direction",
            "",
            "if eta > 0:",
            "+            # randn_like does not support generator https://github.com/pytorch/pytorch/issues/27072",
            "device = model_output.device if torch.is_tensor(model_output) else \"cpu\"",
            "-            noise = torch.randn(model_output.shape, generator=generator).to(device)",
            "+            noise = torch.randn(model_output.shape, dtype=model_output.dtype, generator=generator).to(device)",
            "variance = self._get_variance(timestep, prev_timestep) ** (0.5) * eta * noise",
            "",
            "prev_sample = prev_sample + variance"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 2861,
        "label": "no",
        "change": [
            "def masked_accuracy(preds, labels, mask):",
            "mask = tf.cast(mask, dtype=tf.float32)",
            "mask /= tf.reduce_mean(mask)",
            "accuracy_all *= mask",
            "-    return tf.reduce_mean(accuracy_all)",
            "\\ No newline at end of file",
            "+    return tf.reduce_mean(accuracy_all)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2864,
        "label": "no",
        "change": [
            "class SplineGCN(Module):",
            "self.reset_parameters()",
            "",
            "def reset_parameters(self):",
            "-        stdv = 1. / math.sqrt(self.in_features * self.k_max)",
            "+        stdv = 1. / math.sqrt(self.in_features * self.K)",
            "",
            "self.weight.data.uniform_(-stdv, stdv)",
            "if self.bias is not None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2865,
        "label": "no",
        "change": [
            "class TFGPT2MainLayer(tf.keras.layers.Layer):",
            "# indices on GPU, returning zeros instead. This is a dangerous silent behavior.",
            "tf.debugging.assert_less(",
            "input_ids,",
            "-                tf.cast(self.vocab_size, dtype=input_ids.dtype),",
            "+                tf.cast(self.config.vocab_size, dtype=input_ids.dtype),",
            "message=(",
            "\"input_ids must be smaller than the embedding layer's input dimension (got\"",
            "f\" {tf.math.reduce_max(input_ids)} >= {self.vocab_size})\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2870,
        "label": "no",
        "change": [
            "class CTC(torch.nn.Module):",
            "self.ctc_lo = torch.nn.Linear(eprojs, odim)",
            "",
            "# In case of Pytorch >= 1.2.0, CTC will be always builtin",
            "-        torch_ver = int(torch.__version__.replace('.', ''))",
            "+        torch_ver = int(torch.__version__.replace('.', '').replace('post2', ''))",
            "self.ctc_type = ctc_type if torch_ver < 120 else 'builtin'",
            "",
            "if self.ctc_type == 'builtin':"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2872,
        "label": "no",
        "change": [
            "class TestDotProductSimilarityFunction(AllenNlpTestCase):",
            "a_vectors = numpy.random.rand(5, 4, 3, 6, 7)",
            "b_vectors = numpy.random.rand(5, 4, 3, 6, 7)",
            "desired_result = numpy.sum(a_vectors * b_vectors, axis=-1)",
            "-        result = dot_product(torch.from_numpy(a_vectors),",
            "-                             torch.from_numpy(b_vectors)).data.numpy()",
            "+        result = dot_product(torch.from_numpy(a_vectors), torch.from_numpy(b_vectors)).data.numpy()",
            "assert result.shape == (5, 4, 3, 6)",
            "# We're cutting this down here with a random partial index, so that if this test fails the",
            "# output isn't so huge and slow.",
            "assert_almost_equal(result[2, 3, 1], desired_result[2, 3, 1])",
            "",
            "def test_can_construct_from_params(self):",
            "-        assert DotProductSimilarity.from_params(Params({})).__class__.__name__ == 'DotProductSimilarity'",
            "+        assert (",
            "+            DotProductSimilarity.from_params(Params({})).__class__.__name__",
            "+            == \"DotProductSimilarity\"",
            "+        )"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2874,
        "label": "no",
        "change": [
            "def guide(data, k):",
            "",
            "def local_guide(latent, k):",
            "# The local guide simply guesses category assignments.",
            "-    latent.ps.param_(Variable(torch.ones(k) / k, requires_grad=True))",
            "+    latent.ps.param_(torch.tensor(torch.ones(k) / k, requires_grad=True))",
            "latent.id.sample_(dist.Categorical(softmax(latent.ps)))",
            "",
            "",
            "def main(args):",
            "optim = Adam({\"lr\": 0.1})",
            "inference = SVI(model, guide, optim, loss=\"ELBO\")",
            "-    data = Variable(torch.Tensor([0, 1, 2, 20, 30, 40]))",
            "+    data = torch.tensor([0, 1, 2, 20, 30, 40])",
            "k = 2",
            "",
            "print('Step\\tLoss')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2877,
        "label": "no",
        "change": [
            "def patch_norm_fp32(module):",
            "\"\"\"",
            "if isinstance(module, (nn.modules.batchnorm._BatchNorm, nn.GroupNorm)):",
            "module.float()",
            "-        if isinstance(module, nn.GroupNorm) or torch.__version__ < '1.3':",
            "+        if isinstance(module, nn.GroupNorm) or torch.__version__ == 'parrots':",
            "module.forward = patch_forward_method(module.forward, torch.half,",
            "torch.float)",
            "for child in module.children():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2878,
        "label": "no",
        "change": [
            "class ModelTesterMixin:",
            "self.assertLessEqual(max_diff, tol, f\"{name}: Difference between torch and tf is {max_diff} (>= {tol}).\")",
            "else:",
            "raise ValueError(",
            "-                f\"`tf_outputs` should be an instance of `tf.Tensor`, a `tuple`, or an instance of `tf.Tensor`. Got {type(tf_outputs)} instead.\"",
            "+                \"`tf_outputs` should be an instance of `tf.Tensor`, a `tuple`, or an instance of `tf.Tensor`. Got\"",
            "+                f\" {type(tf_outputs)} instead.\"",
            ")",
            "",
            "def prepare_tf_inputs_from_pt_inputs(self, pt_inputs_dict):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2880,
        "label": "no",
        "change": [
            "class DeepSpeedSelfAttentionFunction(Function):",
            "return tensor_list",
            "",
            "def backup_attention(mixed_x_layer, layer_past, alibi, input_mask, norm_factor):",
            "+            alibi = alibi.to(torch.cuda.current_device())",
            "head_dim = hidden_size_per_partition // num_attention_heads_per_partition",
            "new_tensor_shape = mixed_x_layer.size()[:-1] + (",
            "num_attention_heads_per_partition,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2881,
        "label": "no",
        "change": [
            "class PipelineFastTests(unittest.TestCase):",
            "",
            "# Validate that the text encoder safetensor exists and are of the correct format",
            "text_encoder_path = os.path.join(tmpdirname, \"text_encoder\", \"model.safetensors\")",
            "-            if transformers.__version__ >= \"4.25.1\":",
            "-                assert os.path.exists(text_encoder_path), f\"Could not find {text_encoder_path}\"",
            "-                _ = safetensors.torch.load_file(text_encoder_path)",
            "+            assert os.path.exists(text_encoder_path), f\"Could not find {text_encoder_path}\"",
            "+            _ = safetensors.torch.load_file(text_encoder_path)",
            "",
            "pipeline = StableDiffusionPipeline.from_pretrained(tmpdirname)",
            "assert pipeline.unet is not None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2882,
        "label": "no",
        "change": [
            "class TorchBinaryAutoregressiveDistribution(TorchDistributionWrapper):",
            "",
            "def _a1_distribution(self):",
            "BATCH = self.inputs.shape[0]",
            "-        a1_logits, _ = self.model.action_module(self.inputs,",
            "-                                                torch.zeros((BATCH, 1)))",
            "+        zeros = torch.zeros((BATCH, 1)).to(self.inputs.device)",
            "+        a1_logits, _ = self.model.action_module(self.inputs, zeros)",
            "a1_dist = TorchCategorical(a1_logits)",
            "return a1_dist"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2883,
        "label": "yes",
        "change": [
            "class Fixture(object):",
            "",
            "def _convert_logits_to_ps(self, dist_params):",
            "if 'logits' in dist_params:",
            "-            logits = torch.Tensor(dist_params.pop('logits'))",
            "+            logits = Variable(torch.Tensor(dist_params.pop('logits')))",
            "is_multidimensional = self.get_test_distribution_name() != 'Bernoulli'",
            "ps, _ = get_probs_and_logits(logits=logits, is_multidimensional=is_multidimensional)",
            "dist_params['ps'] = list(ps.data.cpu().numpy())"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 2884,
        "label": "yes",
        "change": [
            "class GEDDataset(InMemoryDataset):",
            "xs += [assoc[x]]",
            "ys += [assoc[y]]",
            "gs += [g]",
            "-            x, y, g = torch.tensor(xs), torch.tensor(ys), torch.tensor(gs)",
            "+            x, y = torch.tensor(xs), torch.tensor(ys)",
            "+            g = torch.tensor(gs, dtype=torch.float)",
            "mat[x, y], mat[y, x] = g, g",
            "",
            "path = osp.join(self.processed_dir, '{}_ged.pt'.format(self.name))"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 2886,
        "label": "no",
        "change": [
            "class TransformReparam(Reparam):",
            "is_observed = msg[\"is_observed\"]",
            "",
            "fn, event_dim = self._unwrap(fn)",
            "-        assert isinstance(fn, dist.TransformedDistribution)",
            "+        assert isinstance(fn, torch.distributions.TransformedDistribution)",
            "",
            "# Differentiably invert transform.",
            "value_base = value"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2888,
        "label": "yes",
        "change": [
            "def extract_info_from_torch_data(",
            "input_types = ifnone(",
            "input_types,",
            "[",
            "-            \"int\" if isinstance(x.cpu(), torch.LongTensor) else \"float\"",
            "+            \"int64\"",
            "+            if isinstance(x.cpu(), torch.LongTensor)",
            "+            else \"int32\"",
            "+            if isinstance(x.cpu(), torch.IntTensor)",
            "+            else \"float32\"",
            "for x in input_row",
            "],",
            ")"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 2889,
        "label": "no",
        "change": [
            "\"def guide(data):\\n\",",
            "\"    with pyro.iarange('data'):\\n\",",
            "\"        p = softmax(pyro.param('unconstrained_p',\\n\",",
            "-    \"                               Variable(torch.zeros(len(data), K), requires_grad=True)))\\n\",",
            "+    \"                               torch.zeros(len(data), K, requires_grad=True)))\\n\",",
            "\"        pyro.sample('z', Categorical(p))\"",
            "]",
            "},"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2891,
        "label": "yes",
        "change": [
            "def block(params, scope, past, append_dim, train=False):",
            "def model(features, labels, params, mesh, past=None):",
            "\"\"\"A GPT style model implemented in mesh tensorlfow.\"\"\"",
            "results = {}",
            "+    sequence_dim = mtf.Dimension('sequence', params[\"n_ctx\"])",
            "if params[\"num_microbatches\"] > 1:",
            "x = features[\"inputs\"]",
            "labels = features[\"labels\"]",
            "batch_dim = x.shape[0]",
            "-",
            "-",
            "else:",
            "+      batch_dim = mtf.Dimension('batch', params[\"train_batch_size\"])",
            "x = mtf.import_tf_tensor(mesh, features, mtf.Shape([batch_dim, sequence_dim]))",
            "# In this case, labels are simply input shifted one token to the right",
            "# this op is done in the input_fn",
            "# define mtf dims",
            "-      batch_dim = mtf.Dimension('batch', params[\"train_batch_size\"])",
            "labels = mtf.import_tf_tensor(mesh, labels, mtf.Shape([batch_dim, sequence_dim]))",
            "",
            "-    sequence_dim = mtf.Dimension('sequence', params[\"n_ctx\"])",
            "",
            "# we need this because gathering when both the args have the same dimension in them it breaks stuff.",
            "# this dim is specifically for the weights"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "addition",
        "Element": "api parameter"
    },
    {
        "number": 2892,
        "label": "no",
        "change": [
            "class GPT2ModelTest(ModelTesterMixin, unittest.TestCase):",
            "",
            "inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True)",
            "",
            "-        torch.manual_seed(0)",
            "outputs = model.generate(",
            "input_ids=inputs[\"input_ids\"].to(torch_device),",
            "attention_mask=inputs[\"attention_mask\"].to(torch_device),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2893,
        "label": "no",
        "change": [
            "class Conv2dSubsampling(torch.nn.Module):",
            "torch.nn.ReLU()",
            ")",
            "self.out = torch.nn.Sequential(",
            "-            torch.nn.Linear(odim * (idim // 4), odim),",
            "+            torch.nn.Linear(odim * (((idim - 1) // 2 - 1) // 2), odim),",
            "PositionalEncoding(odim, dropout_rate)",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2898,
        "label": "no",
        "change": [
            "class LanguageModel(nn.Module):",
            "",
            "text = prefix + \"\".join(characters)",
            "",
            "-            log_prob = log_prob.item()",
            "-            log_prob /= len(characters)",
            "+            log_prob_float = log_prob.item()",
            "+            log_prob_float /= len(characters)",
            "",
            "if not self.is_forward_lm:",
            "text = text[::-1]",
            "",
            "-            return text, log_prob",
            "+            return text, log_prob_float",
            "",
            "def calculate_perplexity(self, text: str) -> float:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2899,
        "label": "no",
        "change": [
            "class GlowTTSTrainTest(unittest.TestCase):",
            "assert (param - param_ref).sum() == 0, param",
            "count += 1",
            "",
            "-        optimizer = optim.Adam(model.parameters(), lr=c.lr)",
            "+        optimizer = optim.Adam(model.parameters(), lr=0.001)",
            "for _ in range(5):",
            "+            optimizer.zero_grad()",
            "z, logdet, y_mean, y_log_scale, alignments, o_dur_log, o_total_dur = model.forward(",
            "input_dummy, input_lengths, mel_spec, mel_lengths, None)",
            "-            optimizer.zero_grad()",
            "loss_dict = criterion(z, y_mean, y_log_scale, logdet, mel_lengths,",
            "o_dur_log, o_total_dur, input_lengths)",
            "loss = loss_dict['loss']"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2902,
        "label": "no",
        "change": [
            "class Trainer(object):",
            "print(msg, file=sys.stderr)",
            "if torch.cuda.is_available() and hasattr(torch.cuda, \"memory_summary\"):",
            "for device_idx in range(torch.cuda.device_count()):",
            "-                            print(torch.cuda.memory_summary(device=torch.cuda.device(device_idx)),",
            "+                            print(torch.cuda.memory_summary(device=device_idx),",
            "file=sys.stderr)",
            "sys.stderr.flush()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2904,
        "label": "no",
        "change": [
            "def rpn_losses(anchor_labels, anchor_boxes, label_logits, box_logits):",
            "# But the total RPN loss will be fine.  TODO make the summary op smarter",
            "placeholder = 0.",
            "label_loss = tf.nn.sigmoid_cross_entropy_with_logits(",
            "-        labels=tf.to_float(valid_anchor_labels), logits=valid_label_logits)",
            "+        labels=tf.cast(valid_anchor_labels, tf.float32), logits=valid_label_logits)",
            "label_loss = tf.reduce_sum(label_loss) * (1. / cfg.RPN.BATCH_PER_IM)",
            "label_loss = tf.where(tf.equal(nr_valid, 0), placeholder, label_loss, name='label_loss')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2907,
        "label": "no",
        "change": [
            "class Iterative(Solver):",
            "",
            "# Initialization step",
            "args = self.initialize(x_init, *args)",
            "+        # args = util.map_tensors(fn=tf.stop_gradient, tensors=args)",
            "",
            "# Iteration loop with termination condition",
            "if self.unroll_loop:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2908,
        "label": "no",
        "change": [
            "class DynamicConvolution(nn.Module):",
            "#                 Linear",
            "self.linear1 = nn.Linear(n_feat, n_feat * 2)",
            "self.linear2 = nn.Linear(n_feat, n_feat)",
            "-        self.linear_weight = nn.Linear(n_feat, self.wshare * 1 * self.kernel_size)",
            "+        self.linear_weight = nn.Linear(n_feat, self.wshare * 1 * kernel_size)",
            "nn.init.xavier_uniform(self.linear_weight.weight)",
            "self.act = nn.GLU()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2912,
        "label": "no",
        "change": [
            "class VersatileDiffusionDualGuidedPipelineIntegrationTests(unittest.TestCase):",
            "image_slice = image[0, 253:256, 253:256, -1]",
            "",
            "assert image.shape == (1, 512, 512, 3)",
            "-        expected_slice = np.array([0.014, 0.0112, 0.0136, 0.0145, 0.0107, 0.0113, 0.0272, 0.0215, 0.0216])",
            "+        expected_slice = np.array([0.0787, 0.0849, 0.0826, 0.0812, 0.0807, 0.0795, 0.0818, 0.0798, 0.0779])",
            "+",
            "assert np.abs(image_slice.flatten() - expected_slice).max() < 1e-2"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2917,
        "label": "no",
        "change": [
            "class Hippocorpus(datasets.GeneratorBasedBuilder):",
            "",
            "if not os.path.exists(data_dir):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('hippocorpus', data_dir=...)` that includes files unzipped from the hippocorpus zip. Manual download instructions: {}\".format(",
            "-                    data_dir, self.manual_download_instructions",
            "-                )",
            "+                \"{data_dir} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('hippocorpus', data_dir=...)` that includes files unzipped from the hippocorpus zip. Manual download instructions: {self.manual_download_instructions}\"",
            ")",
            "return [",
            "datasets.SplitGenerator("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2918,
        "label": "no",
        "change": [
            "\"metadata\": {},",
            "\"outputs\": [],",
            "\"source\": [",
            "-    \"kernel = gp.kernels.RBF(input_dim=1, variance=torch.tensor(5.), lengthscale=torch.tensor(10.))\\n\",",
            "+    \"kernel = gp.kernels.RBF(input_dim=1, variance=torch.tensor(5.),\\n\",",
            "+    \"                        lengthscale=torch.tensor(10.))\\n\",",
            "\"gpr = gp.models.GPRegression(X, y, kernel, noise=torch.tensor(1.))\"",
            "]",
            "},"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2920,
        "label": "no",
        "change": [
            "class Embedding(TokenEmbedder):",
            "if weight is None:",
            "weight = torch.FloatTensor(num_embeddings, embedding_dim)",
            "self.weight = torch.nn.Parameter(weight, requires_grad=trainable)",
            "-            torch.nn.init.xavier_uniform(self.weight.data)",
            "+            torch.nn.init.xavier_uniform_(self.weight)",
            "else:",
            "if weight.size() != (num_embeddings, embedding_dim):",
            "raise ConfigurationError(\"A weight matrix was passed with contradictory embedding shapes.\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2921,
        "label": "no",
        "change": [
            "class HalfPrecisionTransformation(BaseTransformation):",
            "if _input.dtype == torch.float32",
            "else _input",
            ")",
            "-        elif isinstance(_input, tf.Tensor):",
            "+        elif isinstance(_input, tf.Tensor) and _input is not None:",
            "return (",
            "self._transform_tf(_input)",
            "if _input.dtype == tf.float32"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2923,
        "label": "no",
        "change": [
            "class MixedInt8Test(BaseMixedInt8Test):",
            "super().setUp()",
            "",
            "# Models and tokenizer",
            "-        self.model_fp16 = AutoModelForCausalLM.from_pretrained(self.model_name, torch_dtype=\"auto\", device_map=\"auto\")",
            "+        self.model_fp16 = AutoModelForCausalLM.from_pretrained(",
            "+            self.model_name, torch_dtype=torch.float16, device_map=\"auto\"",
            "+        )",
            "self.model_8bit = AutoModelForCausalLM.from_pretrained(self.model_name, load_in_8bit=True, device_map=\"auto\")",
            "",
            "def tearDown(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2925,
        "label": "no",
        "change": [
            "class _EdgewiseSplineGcn_gpu(Function):",
            "features_grad_in = features_grad_out.new(e,M_in)",
            "weight_grad_in = features_grad_out.new(K, M_in, M_out)",
            "n = features_grad_in.numel()*self.k",
            "-        with torch.cuda.device_of(input):",
            "+        with torch.cuda.device_of(features_grad_out):",
            "f = load_kernel('bspline_basis_backward_kernel', _bspline_basis_backward_kernel, Dtype=Dtype(input),",
            "num_edges=e,num_threads=n, M_in=M_in, M_out=M_out, k_max=self.k, K=K)",
            "f(block=(CUDA_NUM_THREADS, 1, 1),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2926,
        "label": "yes",
        "change": [
            "class CrossAttention(nn.Module):",
            "key_slice = key_slice.float()",
            "",
            "attn_slice = torch.baddbmm(",
            "-                torch.empty(slice_size, query.shape[1], key.shape[1], dtype=query.dtype, device=query.device),",
            "-                query[start_idx:end_idx],",
            "-                key[start_idx:end_idx].transpose(-1, -2),",
            "+                torch.empty(slice_size, query.shape[1], key.shape[1], dtype=query_slice.dtype, device=query.device),",
            "+                query_slice,",
            "+                key_slice.transpose(-1, -2),",
            "beta=0,",
            "alpha=self.scale,",
            ")"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 2928,
        "label": "no",
        "change": [
            "class StringLookupVocabularyTest(keras_parameterized.TestCase,",
            "fn()",
            "",
            "if __name__ == \"__main__\":",
            "-  # StringLookup is only exported as a TF2 API.",
            "-  tf.compat.v1.enable_v2_behavior()",
            "tf.test.main()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2934,
        "label": "no",
        "change": [
            "class TorchDistribution(torch.distributions.Distribution, TorchDistributionMixin",
            "assert d.shape(sample_shape) == sample_shape + d.batch_shape + d.event_shape",
            "",
            "Distributions provide a vectorized",
            "-    :meth`~torch.distributions.distribution.Distribution.log_prob` method that",
            "+    :meth:`~torch.distributions.distribution.Distribution.log_prob` method that",
            "evaluates the log probability density of each event in a batch",
            "independently, returning a tensor of shape",
            "``sample_shape + d.batch_shape``::"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2935,
        "label": "no",
        "change": [
            "class UNet2DConditionModelTests(ModelTesterMixin, unittest.TestCase):",
            "for name in grad_checkpointed:",
            "self.assertTrue(torch.allclose(grad_checkpointed[name], grad_not_checkpointed[name], atol=5e-5))",
            "",
            "+        # disable deterministic behavior for gradient checkpointing",
            "+        del os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]",
            "+        torch.use_deterministic_algorithms(False)",
            "+",
            "",
            "#    TODO(Patrick) - Re-add this test after having cleaned up LDM",
            "#    def test_output_pretrained_spatial_transformer(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2937,
        "label": "no",
        "change": [
            "def test_sequential_as_downstream_of_masking_layer():",
            "np.random.random((10, 3, 5)), epochs=1, batch_size=6)",
            "",
            "mask_outputs = [model.layers[1].compute_mask(model.layers[1].input)]",
            "-    mask_outputs += [model.layers[2].compute_mask(model.layers[2].input, mask_outputs[-1])]",
            "+    mask_outputs += [model.layers[2].compute_mask(model.layers[2].input,",
            "+                                                  mask_outputs[-1])]",
            "func = K.function([model.input], mask_outputs)",
            "mask_outputs_val = func([model_input])",
            "assert np.array_equal(mask_outputs_val[0], np.any(model_input, axis=-1))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2938,
        "label": "no",
        "change": [
            "def test_fastspeech2(",
            "with torch.no_grad():",
            "model.eval()",
            "",
            "-        inputs = dict(",
            "-            text=torch.randint(0, 10, (2,)),",
            "-        )",
            "+        inputs = dict(text=torch.randint(0, 10, (2,)))",
            "if use_gst:",
            "inputs.update(speech=torch.randn(5, 5))",
            "if spk_embed_dim is not None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2943,
        "label": "no",
        "change": [
            "class Meshes(object):",
            "return",
            "",
            "if self.isempty():",
            "-            self._edges_packed = -torch.ones(",
            "-                (0, 2), dtype=torch.int64, device=self.device",
            "+            self._edges_packed = torch.full(",
            "+                (0, 2), fill_value=-1, dtype=torch.int64, device=self.device",
            ")",
            "self._edges_packed_to_mesh_idx = torch.zeros(",
            "(0,), dtype=torch.int64, device=self.device"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2946,
        "label": "no",
        "change": [
            "class Wikihow(datasets.GeneratorBasedBuilder):",
            "",
            "if not os.path.exists(path_to_manual_file):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('wikihow', data_dir=...)` that includes a file name {}. Manual download instructions: {})\".format(",
            "-                    path_to_manual_file, self.config.filename, self.manual_download_instructions",
            "-                )",
            "+                f\"{path_to_manual_file} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('wikihow', data_dir=...)` that includes a file name {self.config.filename}. Manual download instructions: {self.manual_download_instructions})\"",
            ")",
            "return [",
            "datasets.SplitGenerator("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2948,
        "label": "yes",
        "change": [
            "class InMemoryDataset(Dataset):",
            "for key in keys:",
            "item = data_list[0][key]",
            "if torch.is_tensor(item):",
            "-                data[key] = torch.cat(",
            "-                    data[key], dim=data.__cat_dim__(key, data_list[0][key]))",
            "+                data[key] = torch.cat(data[key],",
            "+                                      dim=data.__cat_dim__(key, item))",
            "elif isinstance(item, int) or isinstance(item, float):",
            "data[key] = torch.tensor(data[key])"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 2949,
        "label": "no",
        "change": [
            "def frexp(",
            "x: Union[tf.Tensor, tf.Variable],",
            "/,",
            "*,",
            "-    out: Optional[Union[Tuple[tf.Tensor, tf.Tensor], Tuple[tf.Variable, tf.Variable]]] = None,",
            "+    out: Optional[",
            "+        Union[Tuple[tf.Tensor, tf.Tensor], Tuple[tf.Variable, tf.Variable]]",
            "+    ] = None,",
            ") -> Union[Tuple[tf.Tensor, tf.Tensor], Tuple[tf.Variable, tf.Variable]]:",
            "e = tf.math.floor(tf.math.log(tf.math.abs(x)) / tf.cast(tf.math.log(2.), x.dtype))",
            "e = tf.cast(e, x.dtype)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2952,
        "label": "no",
        "change": [
            "def accuracy(output, target, topk=(1,)):",
            "_, pred = output.topk(maxk, 1, True, True)",
            "pred = pred.t()",
            "correct = pred.eq(target.reshape(1, -1).expand_as(pred))",
            "-    return [",
            "-        correct[:k].reshape(-1).float().sum(0) * 100. / batch_size",
            "-        if k <= maxk else torch.tensor(100.) for k in topk",
            "-    ]",
            "+    return [correct[:min(k, maxk)].reshape(-1).float().sum(0) * 100. / batch_size for k in topk]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2956,
        "label": "yes",
        "change": [
            "class FloatVectorField(Field):",
            ")",
            "self.dim_error_check = dim_error_check  # dims in data should match config",
            "self.dummy_model_input = torch.tensor(",
            "-            [[1.0] * dim], dtype=torch.float, device=\"cpu\"",
            "+            [[1.0] * dim, [1.0] * dim], dtype=torch.float, device=\"cpu\"",
            ")",
            "",
            "def _parse_vector(self, s):"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 2958,
        "label": "no",
        "change": [
            "class Data(object):",
            "@property",
            "def num_edges(self):",
            "for key, item in self('edge_index', 'edge_attr'):",
            "-            return item.size(self.cat_dim(key))",
            "+            return item.size(self.cat_dim(key, item))",
            "return None",
            "",
            "@property"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2959,
        "label": "no",
        "change": [
            "def main():",
            "np.random.seed(args.seed)",
            "",
            "if args.backend == \"pytorch\":",
            "-        from espnet.lmpytorch.tts_pytorch import train",
            "+        from espnet.tts.pytorch.tts_pytorch import train",
            "train(args)",
            "else:",
            "raise NotImplementedError(\"Only pytorch is supported.\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2961,
        "label": "no",
        "change": [
            "class Preprocessor(object):",
            "self.summaries = list()",
            "",
            "def custom_getter(getter, name, registered=False, **kwargs):",
            "-            print(name)",
            "variable = getter(name=name, registered=True, **kwargs)",
            "if not registered:",
            "self.variables[name] = variable",
            "return variable",
            "",
            "-        self.explore = tf.make_template(",
            "+        self.process = tf.make_template(",
            "name_=(scope + '/process'),",
            "func_=self.tf_process,",
            "custom_getter_=custom_getter"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2962,
        "label": "no",
        "change": [
            "class LJSpeechDataset(Dataset):",
            "linear = torch.FloatTensor(linear)",
            "mel = torch.FloatTensor(mel)",
            "mel_lengths = torch.LongTensor(mel_lengths)",
            "-            stop_targets = torch.FloatTensor(stop_targets)",
            "+            stop_targets = torch.FloatTensor(stop_targets).squeeze()",
            "",
            "return text, text_lenghts, linear, mel, mel_lengths, stop_targets, item_idxs[0]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2967,
        "label": "no",
        "change": [
            "class AutoLaplaceApproximation(AutoContinuous):",
            "H = hessian(loss, self.loc)",
            "cov = H.inverse()",
            "loc = self.loc",
            "-        scale_tril = cov.cholesky()",
            "+        scale_tril = torch.linalg.cholesky(cov)",
            "",
            "gaussian_guide = AutoMultivariateNormal(self.model)",
            "gaussian_guide._setup_prototype(*args, **kwargs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2969,
        "label": "yes",
        "change": [
            "class WGAN_GP(object):",
            "alpha = tf.random_uniform(shape=self.inputs.get_shape(), minval=0.,maxval=1.)",
            "differences = G - self.inputs # This is different from MAGAN",
            "interpolates = self.inputs + (alpha * differences)",
            "-        D_inter,_,_=self.discriminator(interpolates, is_training=True, reuse=True)",
            "+        _,D_inter,_=self.discriminator(interpolates, is_training=True, reuse=True)",
            "gradients = tf.gradients(D_inter, [interpolates])[0]",
            "slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))",
            "gradient_penalty = tf.reduce_mean((slopes - 1.) ** 2)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 2971,
        "label": "yes",
        "change": [
            "class TransferLearningModel(pl.LightningModule):",
            "# 1. Forward pass:",
            "x, y = batch",
            "y_logits = self.forward(x)",
            "+        y_scores = torch.sigmoid(y_logits)",
            "y_true = y.view((-1, 1)).type_as(x)",
            "",
            "# 2. Compute loss",
            "self.log(\"val_loss\", self.loss(y_logits, y_true), prog_bar=True)",
            "",
            "# 3. Compute accuracy:",
            "-        self.log(\"val_acc\", self.valid_acc(y_logits, y_true.int()), prog_bar=True)",
            "+        self.log(\"val_acc\", self.valid_acc(y_scores, y_true.int()), prog_bar=True)",
            "",
            "def configure_optimizers(self):",
            "parameters = list(self.parameters())"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 2972,
        "label": "no",
        "change": [
            "class BDDMPipeline(DiffusionPipeline):",
            "num_prediction_steps = len(self.noise_scheduler)",
            "for t in tqdm.tqdm(reversed(range(num_prediction_steps)), total=num_prediction_steps):",
            "# 1. predict noise residual",
            "-            with torch.no_grad():",
            "-                t = (torch.tensor(timestep_values[t]) * torch.ones((1, 1))).to(torch_device)",
            "-                residual = self.diffwave(audio, mel_spectrogram, t)",
            "+            ts = (torch.tensor(timestep_values[t]) * torch.ones((1, 1))).to(torch_device)",
            "+            residual = self.diffwave((audio, mel_spectrogram, ts))",
            "",
            "# 2. predict previous mean of audio x_t-1",
            "pred_prev_audio = self.noise_scheduler.step(residual, audio, t)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2973,
        "label": "no",
        "change": [
            "def test_tensorflow_negative(",
            "native_array_flags=native_array,",
            "fw=fw,",
            "frontend=\"tensorflow\",",
            "-        fn_name=\"negative\",",
            "+        fn_tree=\"negative\",",
            "x=np.asarray(x, dtype=input_dtype),",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2975,
        "label": "yes",
        "change": [
            "class Decoder(nn.Module):",
            "self.attention = inputs.data.new(B, T).zero_()",
            "self.attention_cum = inputs.data.new(B, T).zero_()",
            "",
            "-    def _parse_outputs(self, outputs, stop_tokens, attentions):",
            "+    def _parse_outputs(self, outputs, attentions, stop_tokens):",
            "# Back to batch first",
            "attentions = torch.stack(attentions).transpose(0, 1)",
            "outputs = torch.stack(outputs).transpose(0, 1).contiguous()",
            "-        stop_tokens = torch.stack(stop_tokens).transpose(0, 1)",
            "-        return outputs, stop_tokens, attentions",
            "+        stop_tokens = torch.stack(stop_tokens).transpose(0, 1).squeeze(-1)",
            "+        return outputs, attentions, stop_tokens",
            "",
            "def decode(self,",
            "inputs,"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 2978,
        "label": "yes",
        "change": [
            "class GAE(torch.nn.Module):",
            "data.val_pos_edge_index = torch.stack([r, c], dim=0)",
            "r, c = row[n_v:n_v + n_t], col[n_v:n_v + n_t]",
            "data.test_pos_edge_index = torch.stack([r, c], dim=0)",
            "+",
            "r, c = row[n_v + n_t:], col[n_v + n_t:]",
            "-        data.train_pos_edge_index = torch.stack([r, c], dim=0)",
            "+        edge_index = torch.stack([r, c], dim=0)",
            "+        data.train_pos_edge_index = to_undirected(edge_index)",
            "",
            "# Negative edges.",
            "num_nodes = data.num_nodes"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "removal",
        "Element": "api call"
    },
    {
        "number": 2980,
        "label": "yes",
        "change": [
            "class LatentDiffusion(DiffusionPipeline):",
            "num_trained_timesteps = self.noise_scheduler.timesteps",
            "inference_step_times = range(0, num_trained_timesteps, num_trained_timesteps // num_inference_steps)",
            "",
            "-        image = self.noise_scheduler.sample_noise(",
            "+        image = torch.randn(",
            "(batch_size, self.unet.in_channels, self.unet.image_size, self.unet.image_size),",
            "device=torch_device,",
            "generator=generator,"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 2982,
        "label": "no",
        "change": [
            "class TestSIFTDescriptor:",
            "assert_allclose(out, expected, atol=1e-3, rtol=1e-3)",
            "",
            "def test_gradcheck(self):",
            "-        batch_size, channels, height, width = 1, 1, 41, 41",
            "+        batch_size, channels, height, width = 1, 1, 13, 13",
            "patches = torch.rand(batch_size, channels, height, width)",
            "patches = utils.tensor_to_gradcheck_var(patches)  # to var",
            "-        assert gradcheck(sift_describe, (patches, 41),",
            "+        assert gradcheck(sift_describe, (patches, 13),",
            "raise_exception=True)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2983,
        "label": "no",
        "change": [
            "def trace(",
            "if len(x) == 0:",
            "return ivy.array([])",
            "ret = torch.diagonal(x, offset=offset, dim1=axis1, dim2=axis2)",
            "-    ret = torch.sum(ret)",
            "+    ret = torch.sum(ret, dim=-1)",
            "return ret"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2984,
        "label": "no",
        "change": [
            "class TextRNN(object):",
            "with tf.name_scope(\"score\"):",
            "# 全连接层，后面接dropout以及relu激活",
            "fc = tf.layers.dense(last, self.config.hidden_dim, name='fc1')",
            "-            fc = tf.contrib.layers.dropout(fc,",
            "-                self.config.dropout_keep_prob)",
            "+            fc = tf.contrib.layers.dropout(fc, self.keep_prob)",
            "fc = tf.nn.relu(fc)",
            "",
            "# 分类器"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2986,
        "label": "no",
        "change": [
            "class XSoftmax(torch.autograd.Function):",
            "g, self, r_mask, g.op(\"Constant\", value_t=torch.tensor(torch.finfo(self.type().dtype()).min))",
            ")",
            "output = softmax(g, output, dim)",
            "-        return masked_fill(g, output, r_mask, g.op(\"Constant\", value_t=torch.tensor(0, dtype=torch.uint8)))",
            "+        return masked_fill(g, output, r_mask, g.op(\"Constant\", value_t=torch.tensor(0, dtype=torch.bool)))",
            "",
            "",
            "# Copied from transformers.models.deberta.modeling_deberta.DropoutContext"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2987,
        "label": "no",
        "change": [
            "def bitwise_invert(",
            "bitwise_invert.support_native_out = True",
            "",
            "",
            "-def isfinite(",
            "-    x: torch.Tensor, *, out: Optional[torch.Tensor] = None",
            "-) -> torch.Tensor:",
            "+def isfinite(x: torch.Tensor, *, out: Optional[torch.Tensor] = None) -> torch.Tensor:",
            "return torch.isfinite(x)",
            "",
            "",
            "-def isinf(",
            "-    x: torch.Tensor, *, out: Optional[torch.Tensor] = None",
            "-) -> torch.Tensor:",
            "+def isinf(x: torch.Tensor, *, out: Optional[torch.Tensor] = None) -> torch.Tensor:",
            "return torch.isinf(x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2990,
        "label": "no",
        "change": [
            "def test_gaussian_hmm_distribution(diag, sample_shape, batch_shape, num_steps, h",
            "actual_std = actual_cov.diagonal(dim1=-2, dim2=-1).sqrt()",
            "actual_corr = actual_cov / (actual_std.unsqueeze(-1) * actual_std.unsqueeze(-2))",
            "",
            "-            expected_cov = g.precision.cholesky().cholesky_inverse()",
            "+            expected_cov = torch.linalg.cholesky(g.precision).cholesky_inverse()",
            "expected_mean = expected_cov.matmul(g.info_vec.unsqueeze(-1)).squeeze(-1)",
            "expected_std = expected_cov.diagonal(dim1=-2, dim2=-1).sqrt()",
            "expected_corr = expected_cov / (expected_std.unsqueeze(-1) * expected_std.unsqueeze(-2))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2992,
        "label": "no",
        "change": [
            "def test_models(tmpdir: \"Path\"):",
            "export_path_2 = os.path.join(tmpdir, \"testmodel1\")",
            "bentoml.models.export_model(testmodel1tag, export_path_2, _model_store=store)",
            "bentoml.models.delete(testmodel1tag, _model_store=store)",
            "-    bentoml.models.import_model(export_path_2, _model_store=store)",
            "+    bentoml.models.import_model(export_path_2 + \".bentomodel\", _model_store=store)",
            "",
            "assert bentoml.models.get(\"testmodel\", _model_store=store).tag == testmodel2tag"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 2995,
        "label": "yes",
        "change": [
            "class EmpiricalMarginal(Empirical):",
            "in ``[0, num_chains - 1]``, and there must be equal number",
            "of samples per chain.",
            "\"\"\"",
            "-        weight_type = value.new_empty(1).float().type() if value.dtype in (torch.int32, torch.int64) \\",
            "-            else value.type()",
            "# Apply default weight of 1.0.",
            "if log_weight is None:",
            "-            log_weight = torch.tensor(0.0).type(weight_type)",
            "-        if isinstance(log_weight, numbers.Number):",
            "-            log_weight = torch.tensor(log_weight).type(weight_type)",
            "-        if self._validate_args and log_weight.dim() > 0:",
            "+            log_weight = 0.0",
            "+        if self._validate_args and not isinstance(log_weight, numbers.Number) and log_weight.dim() > 0:",
            "raise ValueError(\"``weight.dim() > 0``, but weight should be a scalar.\")",
            "",
            "# Append to the buffer list"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 2999,
        "label": "no",
        "change": [
            "def set_keras_threads(threads):",
            "# We set threads here to avoid contention, as Keras",
            "# is heavily parallelized across multiple cores.",
            "K.set_session(",
            "-        K.tf.Session(",
            "-            config=K.tf.ConfigProto(",
            "+        tf.Session(",
            "+            config=tf.ConfigProto(",
            "intra_op_parallelism_threads=threads,",
            "inter_op_parallelism_threads=threads)))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3000,
        "label": "no",
        "change": [
            "class DeterministicRandomTestToolTest(tf.test.TestCase):",
            "a_prime = tf.random.uniform(shape=(3, 1))",
            "a_prime = a_prime * 3",
            "error_string = \"An exception should have been raised before this\"",
            "-            error_raised = \"An exception should have been raised before this\"",
            "try:",
            "-                c = tf.random.uniform(shape=(3, 1))",
            "+                tf.random.uniform(shape=(3, 1))",
            "raise RuntimeError(error_string)",
            "",
            "except ValueError as err:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3001,
        "label": "no",
        "change": [
            "def _for_loop(*, dim, steps_num, current_state, drift_fn, volatility_fn,",
            "dt, sqrt_dt, time_indices, keep_mask, random_type, seed,",
            "normal_draws, input_gradients, stratonovich_order,",
            "aux_normal_draws):",
            "-  \"\"\"Smaple paths using custom for_loop.\"\"\"",
            "+  \"\"\"Sample paths using custom for_loop.\"\"\"",
            "num_time_points = time_indices.shape.as_list()[-1]",
            "if num_time_points == 1:",
            "iter_nums = steps_num"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3006,
        "label": "no",
        "change": [
            "class LstmCellWithProjection(torch.nn.Module):",
            "timestep_output = self.state_projection(pre_projection_timestep_output)",
            "if self.state_projection_clip_value:",
            "# pylint: disable=invalid-unary-operand-type",
            "-                timestep_output.data.clamp_(-self.state_projection_clip_value,",
            "-                                            self.state_projection_clip_value)",
            "+                timestep_output = torch.clamp(timestep_output,",
            "+                                              -self.state_projection_clip_value,",
            "+                                              self.state_projection_clip_value)",
            "",
            "# Only do dropout if the dropout prob is > 0.0 and we are in training mode.",
            "if dropout_mask is not None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3007,
        "label": "no",
        "change": [
            "def temp_seed(seed: int, set_pytorch=False, set_tensorflow=False):",
            "if not tf.executing_eagerly():",
            "raise ValueError(\"Setting random seed for TensorFlow is only available in eager mode\")",
            "",
            "-        tf_context = tfpy.context.context()  # eager mode context",
            "+        tf_context = tfpycontext.context()  # eager mode context",
            "tf_seed = tf_context._seed",
            "tf_rng_initialized = hasattr(tf_context, \"_rng\")",
            "if tf_rng_initialized:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3008,
        "label": "no",
        "change": [
            "class CopyNetTest(ModelTestCase):",
            "]",
            ")",
            "",
            "-        generation_scores_mask = generation_scores.new_full(generation_scores.size(), 1.0)",
            "+        generation_scores_mask = generation_scores.new_full(",
            "+            generation_scores.size(), True, dtype=torch.bool",
            "+        )",
            "ll_actual, selective_weights_actual = self.model._get_ll_contrib(",
            "generation_scores,",
            "generation_scores_mask,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3010,
        "label": "no",
        "change": [
            "def test_torch_is_tensor(",
            "helpers.test_frontend_function(",
            "input_dtypes=input_dtype,",
            "as_variable_flags=as_variable,",
            "-        with_out=with_out,",
            "+        with_out=False,",
            "num_positional_args=num_positional_args,",
            "native_array_flags=native_array,",
            "fw=fw,",
            "frontend=\"torch\",",
            "fn_tree=\"is_tensor\",",
            "-        input=np.asarray(x, dtype=input_dtype),",
            "-        out=None,",
            "+        obj=np.asarray(x, dtype=input_dtype),",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3012,
        "label": "yes",
        "change": [
            "def _convert_to_tf(x):",
            "return x",
            "",
            "if x is not None:",
            "-        x = tf.nest.map_structure(tf.convert_to_tensor, x)",
            "+        x = tf.nest.map_structure(",
            "+            lambda f: tf.convert_to_tensor(f) if f is not None else None, x)",
            "return x"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 3015,
        "label": "no",
        "change": [
            "class StructuredDataInput(Input):",
            "",
            "def transform(self, x):",
            "if isinstance(x, pd.DataFrame):",
            "-            # convert x,y,validation_data to tf.Dataset",
            "+            # convert x, y, validation_data to tf.Dataset",
            "x = tf.data.Dataset.from_tensor_slices(",
            "x.values.astype(np.unicode))",
            "if isinstance(x, np.ndarray):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3017,
        "label": "yes",
        "change": [
            "class CTCPrefixScoreTH(object):",
            "r_prev, s_prev, f_min_prev, f_max_prev = state",
            "",
            "# select input dimensions for scoring",
            "-        if self.scoring_num > 0 and prep_scores is not None:",
            "-            scoring_ids = torch.topk(prep_scores, self.scoring_num, 1)[1]",
            "+        if self.scoring_num > 0 and pre_scores is not None:",
            "+            pre_scores[:, self.blank] = self.logzero  # ignore blank from pre-selection",
            "+            scoring_ids = torch.topk(pre_scores, self.scoring_num, 1)[1]",
            "scoring_idmap = torch.full((self.n_bb, self.odim), -1, dtype=torch.long, device=self.device)",
            "snum = scoring_ids.size(1)",
            "scoring_idmap[self.bb_idx, scoring_ids] = torch.arange(snum, device=self.device)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3019,
        "label": "no",
        "change": [
            "class FBetaMeasureTest(AllenNlpTestCase):",
            "def test_fbeta_handles_batch_size_of_one(self, device: str):",
            "predictions = torch.tensor([[0.2862, 0.3479, 0.1627, 0.2033]], device=device)",
            "targets = torch.tensor([1], device=device)",
            "-        mask = torch.tensor([1], device=device)",
            "+        mask = torch.BoolTensor([True], device=device)",
            "",
            "fbeta = FBetaMeasure()",
            "fbeta(predictions, targets, mask)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3021,
        "label": "yes",
        "change": [
            "class MultiHeadedAttention(nn.Module):",
            "",
            "scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)  # (batch, head, time1, time2)",
            "if mask is not None:",
            "-            mask.unsqueeze_(1).eq_(0)  # (batch, 1, time1, time2)",
            "+            mask = mask.unsqueeze(1).eq(0)  # (batch, 1, time1, time2)",
            "scores = scores.masked_fill(mask, MIN_VALUE)",
            "self.attn = torch.softmax(scores, dim=-1).masked_fill(mask, 0.0)  # (batch, head, time1, time2)",
            "else:",
            "-            self.attn = torch.softmax(scores, dim=-1)",
            "+            self.attn = torch.softmax(scores, dim=-1)  # (batch, head, time1, time2)",
            "",
            "p_attn = self.dropout(self.attn)",
            "x = torch.matmul(p_attn, v)  # (batch, head, time1, d_k)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3022,
        "label": "no",
        "change": [
            "def parse_args():",
            "def main():",
            "args = parse_args()",
            "",
            "-    model = init_detector(",
            "-        args.config, args.checkpoint, device=torch.device('cuda', args.device))",
            "+    device = torch.device(args.device)",
            "+",
            "+    model = init_detector(args.config, args.checkpoint, device=device)",
            "",
            "camera = cv2.VideoCapture(args.camera_id)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3026,
        "label": "no",
        "change": [
            "class Trainer(Trainable):",
            "logger.info(\"Executing eagerly, with eager_tracing={}\".format(",
            "\"True\" if config.get(\"eager_tracing\") else \"False\"))",
            "",
            "-        if tf and not tf.executing_eagerly():",
            "+        if tf and not tf.executing_eagerly() and not config.get(\"use_pytorch\"):",
            "logger.info(\"Tip: set 'eager': true or the --eager flag to enable \"",
            "\"TensorFlow eager execution\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3028,
        "label": "no",
        "change": [
            "class ComputeLoss:",
            "gi, gj = gij.T  # grid indices",
            "",
            "# Append",
            "-            indices.append((b, a, gj.clamp_(0, gain[3] - 1), gi.clamp_(0, gain[2] - 1)))  # image, anchor, grid indices",
            "+            indices.append((b, a, gj.clamp_(0, shape[2] - 1), gi.clamp_(0, shape[3] - 1)))  # image, anchor, grid",
            "tbox.append(torch.cat((gxy - gij, gwh), 1))  # box",
            "anch.append(anchors[a])  # anchors",
            "tcls.append(c)  # class"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3031,
        "label": "no",
        "change": [
            "def distributed_broadcast_scalars(",
            ") -> \"torch.Tensor\":",
            "if is_torch_available():",
            "try:",
            "-            tensorized_scalar = torch.Tensor(scalars).cuda()",
            "+            tensorized_scalar = torch.tensor(scalars).cuda()",
            "output_tensors = [tensorized_scalar.clone() for _ in range(torch.distributed.get_world_size())]",
            "torch.distributed.all_gather(output_tensors, tensorized_scalar)",
            "concat = torch.cat(output_tensors, dim=0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3033,
        "label": "no",
        "change": [
            "def initialize_model(input_shape) -> nn.Model:",
            "model.add(",
            "nn.Convolution(nb_filter=32, filter_size=3, padding=2, input_shape=input_shape)",
            ")",
            "-    model.add(nn.BatchNorm(activation=nn.leaky_ReLU()))",
            "+    model.add(nn.BatchNorm(activation=\"leaky_relu\"))",
            "model.add(nn.MaxPool(pool_size=2, stride=2))",
            "",
            "# Layer 2",
            "# model.add(nn.Convolution(nb_filter=64, filter_size=3, padding=2))",
            "-    # model.add(nn.BatchNorm(activation=nn.leaky_ReLU()))",
            "+    # model.add(nn.BatchNorm(activation=\"leaky_relu\"))",
            "# model.add(nn.MaxPool(pool_size=2, stride=2))",
            "",
            "# Layer 3"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3034,
        "label": "no",
        "change": [
            "class ClusterData(torch.utils.data.Dataset):",
            "",
            "N, E = self.data.num_nodes, self.data.num_edges",
            "data = copy.copy(self.data)",
            "-        if hasattr(data, '__num_nodes__'):",
            "-            del data.__num_nodes__",
            "+        del data.num_nodes",
            "+        del data.num_edges",
            "adj, data.adj = data.adj, None",
            "",
            "adj = adj.narrow(0, start, length).narrow(1, start, length)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3035,
        "label": "no",
        "change": [
            "def rnn_seq2seq(encoder_inputs, decoder_inputs, encoder_cell, decoder_cell=None,",
            "List of tensors for outputs and states for trianing and sampling sub-graphs.",
            "\"\"\"",
            "with tf.variable_scope(scope or \"rnn_seq2seq\"):",
            "-        _, enc_states = tf.nn.rnn(encoder_cell, encoder_inputs, dtype=dtype)",
            "-        return rnn_decoder(decoder_inputs, enc_states[-1], decoder_cell or encoder_cell)",
            "-",
            "+        _, last_enc_state = tf.nn.rnn(encoder_cell, encoder_inputs, dtype=dtype)",
            "+        return rnn_decoder(decoder_inputs, last_enc_state, decoder_cell or encoder_cell)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3037,
        "label": "no",
        "change": [
            "class Trainer:",
            "gathering predictions.",
            "",
            "Return:",
            "-            Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]: A tuple with the loss, logits and",
            "-            labels (each being optional).",
            "+            Tuple[Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor]]: A tuple with the loss,",
            "+            logits and labels (each being optional).",
            "\"\"\"",
            "has_labels = all(inputs.get(k) is not None for k in self.label_names)",
            "inputs = self._prepare_inputs(inputs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3040,
        "label": "no",
        "change": [
            "class TFLongformerEmbeddings(tf.keras.layers.Layer):",
            "def create_position_ids_from_inputs_embeds(self, inputs_embeds):",
            "\"\"\"We are provided embeddings directly. We cannot infer which are padded so just generate",
            "sequential position ids.",
            "-        :param tf.Tensor inputs_embeds:",
            "-        :return tf.Tensor:",
            "+",
            "+        Args:",
            "+            inputs_embeds: tf.Tensor",
            "+",
            "+        Returns: tf.Tensor",
            "\"\"\"",
            "seq_length = shape_list(inputs_embeds)[1]",
            "position_ids = tf.range(self.padding_idx + 1, seq_length + self.padding_idx + 1, dtype=tf.int32)[tf.newaxis, :]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3043,
        "label": "no",
        "change": [
            "class PipelineIntegrationTests(unittest.TestCase):",
            "pipe = pipe.to(device)",
            "pipe.set_progress_bar_config(disable=None)",
            "",
            "-        generator = torch.Generator(device=device).manual_seed(0)",
            "+        generator = torch.manual_seed(0)",
            "output = pipe(generator=generator, num_inference_steps=100, audio_length_in_s=4.096)",
            "audio = output.audios",
            "",
            "audio_slice = audio[0, -3:, -3:]",
            "",
            "assert audio.shape == (1, 2, pipe.unet.sample_size)",
            "-        expected_slice = np.array([-0.1693, -0.1698, -0.1447, -0.3044, -0.3203, -0.2937])",
            "+        expected_slice = np.array([-0.0367, -0.0488, -0.0771, -0.0525, -0.0444, -0.0341])",
            "+",
            "assert np.abs(audio_slice.flatten() - expected_slice).max() < 1e-2"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3046,
        "label": "no",
        "change": [
            "class LocalDatasetTest(parameterized.TestCase):",
            "",
            "def get_packaged_dataset_names():",
            "packaged_datasets = [{\"testcase_name\": x, \"dataset_name\": x} for x in _PACKAGED_DATASETS_MODULES.keys()]",
            "-    if version.parse(pa.__version__) < version.parse(\"3.0.0\"):  # parquet is not supported for pyarrow<3.0.0",
            "+    if datasets.config.PYARROW_VERSION.major < 3:  # parquet is not supported for pyarrow<3.0.0",
            "packaged_datasets = [pd for pd in packaged_datasets if pd[\"dataset_name\"] != \"parquet\"]",
            "return packaged_datasets"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3048,
        "label": "yes",
        "change": [
            "class TopKPooling(torch.nn.Module):",
            "",
            "weight = F.normalize(self.weight, p=2, dim=-1)",
            "score = (x * weight).sum(dim=-1)",
            "-        perm = self.topk(score, self.k, batch)",
            "-",
            "-        x = x[perm] * self.tanh(score[perm])",
            "+        perm = self.topk(score, self.ratio, batch)",
            "+        x = x[perm] * torch.tanh(score[perm]).view(-1, 1)",
            "batch = batch[perm]",
            "edge_index, edge_attr = self.filter_adj(",
            "-            edge_index, edge_attr, perm, num_nodes=x.size(0))",
            "+            edge_index, edge_attr, perm, num_nodes=score.size(0))",
            "",
            "-        return x, edge_index, edge_attr, batch",
            "+        return x, edge_index, edge_attr, batch, perm",
            "",
            "def __repr__(self):",
            "return '{}({})'.format(self.__class__.__name__, self.ratio)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 3049,
        "label": "no",
        "change": [
            "def get_learning_rate(batch):",
            "DECAY_STEP,          # Decay step.",
            "DECAY_RATE,          # Decay rate.",
            "staircase=True)",
            "-    learing_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!!",
            "+    learning_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!!",
            "return learning_rate",
            "",
            "def get_bn_decay(batch):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3050,
        "label": "yes",
        "change": [
            "class HaloAttn(nn.Module):",
            "",
            "kv = self.kv(x)",
            "# FIXME I 'think' this unfold does what I want it to, but I should investigate",
            "-        k = F.unfold(kv, kernel_size=self.win_size, stride=self.block_size, padding=self.halo_size)",
            "-        k = k.reshape(",
            "+        kv = F.unfold(kv, kernel_size=self.win_size, stride=self.block_size, padding=self.halo_size)",
            "+        kv = kv.reshape(",
            "B * self.num_heads, self.dim_head + (self.dim_v // self.num_heads), -1, num_blocks).transpose(1, 3)",
            "-        k, v = torch.split(k, [self.dim_head, self.dim_v // self.num_heads], dim=-1)",
            "+        k, v = torch.split(kv, [self.dim_head, self.dim_v // self.num_heads], dim=-1)",
            "",
            "attn_logits = (q @ k.transpose(-1, -2)) * self.scale  # FIXME should usual attn scale be applied?",
            "attn_logits = attn_logits + self.pos_embed(q)  # B * num_heads, block_size ** 2, win_size ** 2"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3055,
        "label": "no",
        "change": [
            "class VTraceSurrogateLoss:",
            "tf.float32))",
            "",
            "self.is_ratio = tf.clip_by_value(",
            "-            tf.exp(prev_actions_logp - old_policy_actions_logp), 0.0, 2.0)",
            "+            tf.math.exp(prev_actions_logp - old_policy_actions_logp), 0.0, 2.0)",
            "logp_ratio = self.is_ratio * tf.exp(actions_logp - prev_actions_logp)",
            "",
            "advantages = self.vtrace_returns.pg_advantages"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3059,
        "label": "no",
        "change": [
            "def main(_):",
            "optimizer = tf.train.GradientDescentOptimizer(lr)",
            "train_op = optimizer.apply_gradients(zip(grads, tvars))",
            "",
            "-    # sess.run(tf.global_variables_initializer())",
            "-    tl.layers.initialize_global_variables(sess)",
            "+    sess.run(tf.global_variables_initializer())",
            "",
            "net.print_params()",
            "net.print_layers()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3063,
        "label": "no",
        "change": [
            "class TestTopHat:",
            "None, None, :, :",
            "]",
            "assert_allclose(",
            "-            top_hat(tensor, torch.ones_like(structural_element), structuring_element=structural_element), expected,",
            "-            atol=1e-3, rtol=1e-3",
            "+            top_hat(tensor, torch.ones_like(structural_element), structuring_element=structural_element),",
            "+            expected,",
            "+            atol=1e-3,",
            "+            rtol=1e-3,",
            ")",
            "",
            "def test_exception(self, device, dtype):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3065,
        "label": "no",
        "change": [
            "class DistributedRunner(object):",
            "logdir=\"/tmp/train_logs\",",
            "global_step=worker_agent.model.global_step,",
            "init_op=init_op,",
            "+                                             local_init_op=local_init_op,",
            "init_fn=init_fn,",
            "ready_op=tf.report_uninitialized_variables(variables_to_save),",
            "saver=worker_agent.model.saver)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3066,
        "label": "no",
        "change": [
            "def segment_cumsum(x, segment_ids, exclusive=False, dtype=None, name=None):",
            "`n-sum(min(order, length(segment_j)), j)` where the sum is over segments.",
            "If `exclusive` is False, then the size is `n`.",
            "\"\"\"",
            "-  with tf.compat.v1.name_scope(name, default_name='segment_diff', values=[x]):",
            "+  with tf.compat.v1.name_scope(name, default_name='segment_cumsum', values=[x]):",
            "x = tf.convert_to_tensor(x, dtype=dtype)",
            "raw_cumsum = tf.math.cumsum(x, exclusive=exclusive)",
            "if segment_ids is None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3067,
        "label": "no",
        "change": [
            "class FullAttention(Module):",
            "QK.masked_fill_(~(q_mask[:, :, None, None] * kv_mask[:, None, :, None]), float('-inf'))",
            "",
            "# Compute the attention and the weighted average",
            "-        softmax_temp = 1. / queries.size(3)**.5  # sqrt(D)",
            "+        softmax_temp = 1.0 / queries.size(3) ** 0.5  # sqrt(D)",
            "A = torch.softmax(softmax_temp * QK, dim=2)",
            "if self.use_dropout:",
            "A = self.dropout(A)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3074,
        "label": "no",
        "change": [
            "class TFT5EncoderModel(TFT5PreTrainedModel):",
            "",
            "@property",
            "def dummy_inputs(self):",
            "-        return {\"input_ids\": tf.constant(DUMMY_INPUTS)}",
            "+        return {\"input_ids\": tf.constant(DUMMY_INPUTS, dtype=tf.int32)}",
            "",
            "def get_encoder(self):",
            "return self.encoder"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3075,
        "label": "no",
        "change": [
            "class TensorflowBackendInferenceLearner(TensorflowBaseInferenceLearner):",
            "super(TensorflowBackendInferenceLearner, self).__init__(**kwargs)",
            "self.model = tf_model",
            "",
            "-    @tf.function(jit_compile=True)",
            "def run(self, *input_tensors: tf.Tensor) -> Tuple[tf.Tensor, ...]:",
            "-        res = self.model.predict(*input_tensors)",
            "+        res = self.model.predict(input_tensors)",
            "if not isinstance(res, tuple):",
            "return (res,)",
            "return res"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3077,
        "label": "no",
        "change": [
            "class FixedPoints(object):",
            "choice = np.random.choice(data.num_nodes, self.num, replace=True)",
            "",
            "for key, item in data:",
            "-            if item.size(0) == num_nodes:",
            "+            if torch.is_tensor(item) and item.size(0) == num_nodes:",
            "data[key] = item[choice]",
            "",
            "return data"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3078,
        "label": "no",
        "change": [
            "class DeepQNetwork(ValueFunction):",
            "",
            "with tf.name_scope(\"update\"):",
            "self.q_targets = tf.placeholder(tf.float32, [None], name='q_targets')",
            "-            self.actions = tf.placeholder(tf.int64, [None], name='actions')",
            "+            self.actions = tf.placeholder(tf.float32, [None, self.action_count], name='actions')",
            "",
            "# Q values for actions taken in batch",
            "-            actions_one_hot = tf.one_hot(self.actions, self.env_actions, 1.0, 0.0, name='action_one_hot')",
            "+            actions_one_hot = tf.one_hot(self.actions, self.action_count, 1.0, 0.0, name='action_one_hot')",
            "q_values_actions_taken = tf.reduce_sum(self.training_output * actions_one_hot, reduction_indices=1,",
            "name='q_acted')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3080,
        "label": "no",
        "change": [
            "def convert_pandas_to_tf_tensor(",
            "# them. If the columns contain different types (for example, `float32`s",
            "# and `int32`s), then `tf.concat` raises an error.",
            "dtype: np.dtype = np.find_common_type(df.dtypes, [])",
            "+",
            "+            # if the columns are `ray.data.extensions.tensor_extension.TensorArray`,",
            "+            # the dtype will be `object`. In this case, we need to set the dtype to",
            "+            # none, and use the automatic type casting of `tf.convert_to_tensor`.",
            "+            if is_object_dtype(dtype):",
            "+                dtype = None",
            "+",
            "except TypeError:",
            "# `find_common_type` fails if a series has `TensorDtype`. In this case,",
            "# don't cast any of the series and continue."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3081,
        "label": "no",
        "change": [
            "class ThePile(datasets.GeneratorBasedBuilder):",
            "key += 1",
            "else:",
            "for subset in files:",
            "-                if subset in {\"europarl\", \"free_law\", \"nih_exporter\", \"pubmed\", \"ubuntu_irc\"}:",
            "+                if subset in {\"enron_emails\", \"europarl\", \"free_law\", \"nih_exporter\", \"pubmed\", \"ubuntu_irc\"}:",
            "import zstandard as zstd",
            "",
            "with zstd.open(open(files[subset], \"rb\"), \"rt\", encoding=\"utf-8\") as f:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3084,
        "label": "no",
        "change": [
            "def test_mel_scale():",
            "f = 16000.0",
            "x = MelScale.convert(f)",
            "f_back = MelScale.invert(x)",
            "-    assert torch.abs(f_back - f) < 0.0001",
            "+    assert torch.abs(f_back - f) < 0.1",
            "MelScale.bank(128, 16000.0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3087,
        "label": "no",
        "change": [
            "import torch.nn as nn",
            "def glu(x: torch.Tensor, dim: int = -1):",
            "\"\"\"Generalized linear unit nonlinear activation.",
            "",
            "-    Expects 2*n_units-dimensional input.",
            "-    Half of it is used to determine the gating of the GLU activation",
            "-    and the other half is used as an input to GLU,",
            "+    Expects 2*n_units-dimensional input. Half of it is used to determine the gating of the GLU activation and the other",
            "+    half is used as an input to GLU,",
            "\"\"\"",
            "return nn.functional.glu(x, dim)",
            "",
            "",
            "def gelu(features: torch.Tensor, approximate: bool = False):",
            "if approximate:",
            "-        return 0.5 * features * (1.0 + nn.tanh(",
            "-            0.7978845608028654 * (features + 0.044715 * (features ** 3))",
            "-        ))",
            "+        return 0.5 * features * (1.0 + nn.tanh(0.7978845608028654 * (features + 0.044715 * (features ** 3))))",
            "else:",
            "return 0.5 * features * (1.0 + torch.erf(features / 1.4142135623730951))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3089,
        "label": "no",
        "change": [
            "class BlipVisionModel(BlipPreTrainedModel):",
            "",
            "self.embeddings = BlipVisionEmbeddings(config)",
            "self.encoder = BlipEncoder(config)",
            "-        self.post_layernorm = nn.LayerNorm(embed_dim)",
            "+        self.post_layernorm = nn.LayerNorm(embed_dim, eps=config.layer_norm_eps)",
            "",
            "self.post_init()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3092,
        "label": "yes",
        "change": [
            "class XLNetRelativeAttention(nn.Module):",
            "",
            "# Mask heads if we want to",
            "if head_mask is not None:",
            "-            attn_prob = attn_prob * head_mask",
            "+            attn_prob = attn_prob * torch.einsum('ijbn->bnij', head_mask)",
            "",
            "# attention output",
            "attn_vec = torch.einsum('bnij,jbnd->ibnd', attn_prob, v_head_h)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3094,
        "label": "no",
        "change": [
            "class LMSDiscreteScheduler(SchedulerMixin, ConfigMixin):",
            "sigmas = np.array(((1 - self.alphas_cumprod) / self.alphas_cumprod) ** 0.5)",
            "sigmas = np.interp(timesteps, np.arange(0, len(sigmas)), sigmas)",
            "sigmas = np.concatenate([sigmas, [0.0]]).astype(np.float32)",
            "-        self.sigmas = torch.from_numpy(sigmas)",
            "-        self.timesteps = torch.from_numpy(timesteps)",
            "+        self.sigmas = torch.from_numpy(sigmas).to(device=device)",
            "+        self.timesteps = torch.from_numpy(timesteps).to(device=device)",
            "",
            "self.derivatives = []"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3095,
        "label": "no",
        "change": [
            "class TorchModelV2(ModelV2, nn.Module):",
            "model_config,",
            "name,",
            "framework=\"torch\")",
            "-        nn.Module.__init__(self)",
            "",
            "@override(ModelV2)",
            "def variables(self, as_dict=False):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3100,
        "label": "no",
        "change": [
            "class ClassificationHead(head_module.Head):",
            "output_node = layers.Dropout(dropout_rate)(output_node)",
            "output_node = layers.Dense(self.output_shape[-1])(output_node)",
            "if self.loss == 'binary_crossentropy':",
            "-            output_node = keras_layers.Sigmoid(name=self.name)(output_node)",
            "+            output_node = layers.Activation(activations.sigmoid,",
            "+                                            name=self.name)(output_node)",
            "else:",
            "output_node = layers.Softmax(name=self.name)(output_node)",
            "return output_node"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3101,
        "label": "no",
        "change": [
            "def test_onnxruntime_half(",
            "assert all(",
            "[",
            "torch.allclose(",
            "-                        res_tensor, res_orig_tensor.half(), rtol=1e-01",
            "+                        res_tensor.float(), res_orig_tensor, rtol=1e-01",
            ")",
            "for (res_tensor, res_orig_tensor) in zip(res, res_orig)",
            "]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3102,
        "label": "no",
        "change": [
            "def draw_rectangle(",
            "fill (bool, optional): is a flag used to fill the boxes with color if True. Default: False.",
            "width (int): The line width. Default: 1. (Not implemented yet).",
            "Returns:",
            "-            torch.Tensor: This operation modifies image inplace but also returns",
            "-            the drawn tensor for convenience with same shape the of the input BxCxHxW.",
            "+            torch.Tensor: This operation modifies image inplace but also returns the drawn tensor for",
            "+            convenience with same shape the of the input BxCxHxW.",
            "",
            "Example:",
            ">>> img = torch.rand(2, 3, 10, 12)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3103,
        "label": "no",
        "change": [
            "def subtract(",
            "return torch.subtract(x1, x2, out=out)",
            "return torch.subtract(",
            "x1 if isinstance(x1, torch.Tensor) else torch.tensor(x1),",
            "-        x2 if isinstance(x2, torch.Tensor) else torch.tensor(x2)",
            "+        x2 if isinstance(x2, torch.Tensor) else torch.tensor(x2),",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3104,
        "label": "no",
        "change": [
            "def recog(args):",
            "if args.rnnlm:",
            "rnnlm = lm_train_th.ClassifierWithState(",
            "lm_train_th.RNNLM(len(train_args.char_list), 650))",
            "-        rnnlm.load_state_dict(torch.load(args.rnnlm))",
            "+        rnnlm.load_state_dict(torch.load(args.rnnlm, map_location=cpu_loader))",
            "else:",
            "rnnlm = None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3109,
        "label": "no",
        "change": [
            "class SpatialBottleneckFunction(torch.autograd.Function):",
            "w1by3 = w[:,:1,:,:].clone()",
            "ctx.stream2.wait_stream(ctx.stream1) # wait for halo transfers to finish",
            "ctx.stream2.wait_stream(torch.cuda.current_stream()) # wait for backward_grad_out1_mask to finish before launching halo correction kernel",
            "-                    with torch.cuda.stream(ctx.stream1):",
            "+                    with torch.cuda.stream(ctx.stream2):",
            "btm_grad_out1_halo = fast_bottleneck.backward_grad_out1_halo_corr(ctx.explicit_nhwc, ctx.stride_1x1, t_list, w1by3, grads, btm_halo, btm_relu_halo, btm_grad_out1.clone())",
            "btm_grad_out1.copy_(btm_grad_out1_halo)",
            "if ctx.spatial_group_rank > 0:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3112,
        "label": "no",
        "change": [
            "def test_hook_args_and_cmd_signature_malleability():",
            "assert (r1 == syft.LoggingTensor().on(torch.tensor([2.0, 4]))).all()",
            "",
            "r2 = a + 1",
            "-    assert (r2 == syft.LoggingTensor().on(torch.tensor([2.0, 4]))).all()",
            "+    assert (r2 == syft.LoggingTensor().on(torch.tensor([2.0, 3]))).all()",
            "",
            "r3 = a + b",
            "assert (r3 == syft.LoggingTensor().on(torch.tensor([2.0, 4]))).all()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3114,
        "label": "no",
        "change": [
            "def conv_module(",
            "",
            "",
            "def dense_module(",
            "-        prev_layer, n_units, is_train, use_batchnorm=True, activation_fn=None,",
            "-        dense_init=tl.initializers.random_uniform(),",
            "-        batch_norm_init=tl.initializers.truncated_normal(mean=1.,",
            "-                                                         stddev=0.02), bias_init=tf.zeros_initializer(), name=None",
            "+    prev_layer, n_units, is_train, use_batchnorm=True, activation_fn=None, dense_init=tl.initializers.random_uniform(),",
            "+    batch_norm_init=tl.initializers.truncated_normal(mean=1., stddev=0.02), bias_init=tf.zeros_initializer(), name=None",
            "):",
            "",
            "if activation_fn not in [\"ReLU\", \"ReLU6\", \"Leaky_ReLU\", \"PReLU\", \"PReLU6\", \"PTReLU6\", \"CReLU\", \"ELU\", \"SELU\","
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3116,
        "label": "no",
        "change": [
            "class NativeMixedPrecisionPlugin(MixedPrecisionPlugin):",
            "return closure_loss",
            "",
            "@contextmanager",
            "-    def train_step_context(self) -> Generator[torch.cuda.amp.autocast, None, None]:",
            "+    def train_step_context(self) -> Generator[autocast, None, None]:",
            "\"\"\"Enable autocast context\"\"\"",
            "yield torch.cuda.amp.autocast()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3118,
        "label": "no",
        "change": [
            "class TestBiMPMMatching(AllenNlpTestCase):",
            "test1_fw, test1_bw = torch.split(test1, d // 2, dim=-1)",
            "test2_fw, test2_bw = torch.split(test2, d // 2, dim=-1)",
            "",
            "-        ml_fw = BiMpmMatching.from_params(Params({\"is_forward\": True, \"num_perspectives\": l}))",
            "-        ml_bw = BiMpmMatching.from_params(Params({\"is_forward\": False, \"num_perspectives\": l}))",
            "+        ml_fw = BiMpmMatching.from_params(Params({\"is_forward\": True, \"num_perspectives\": n}))",
            "+        ml_bw = BiMpmMatching.from_params(Params({\"is_forward\": False, \"num_perspectives\": n}))",
            "",
            "vecs_p_fw, vecs_h_fw = ml_fw(test1_fw, mask1, test2_fw, mask2)",
            "vecs_p_bw, vecs_h_bw = ml_bw(test1_bw, mask1, test2_bw, mask2)",
            "vecs_p, vecs_h = torch.cat(vecs_p_fw + vecs_p_bw, dim=2), torch.cat(vecs_h_fw + vecs_h_bw, dim=2)",
            "",
            "-        assert vecs_p.size() == torch.Size([batch, len1, 10 + 10 * l])",
            "-        assert vecs_h.size() == torch.Size([batch, len2, 10 + 10 * l])",
            "+        assert vecs_p.size() == torch.Size([batch, len1, 10 + 10 * n])",
            "+        assert vecs_h.size() == torch.Size([batch, len2, 10 + 10 * n])",
            "assert ml_fw.get_output_dim() == ml_bw.get_output_dim() == vecs_p.size(2) // 2 == vecs_h.size(2) // 2"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3120,
        "label": "no",
        "change": [
            "def solve_pnp_dlt(",
            "# Checking if world_points_norm (of any element of the batch) has rank = 3. This",
            "# function cannot be used if all world points (of any element of the batch) lie",
            "# on a line or if all world points (of any element of the batch) lie on a plane.",
            "-    _, s, _ = torch.svd(world_points_norm)",
            "+    s = torch.linalg.svdvals(world_points_norm)",
            "if torch.any(s[:, -1] < svd_eps):",
            "raise AssertionError(",
            "f\"The last singular value of one/more of the elements of the batch is smaller \""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3121,
        "label": "no",
        "change": [
            "def _RoiPoolingShape(op):",
            "pool_width = op.get_attr('pool_width')",
            "",
            "#TODO: check the width/hegiht order",
            "-    return [tf.TensorShape([n_rois, n_channels, pool_width, pool_height]),",
            "-            tf.TensorShape(None)]",
            "+    return [tf.TensorShape([n_rois, n_channels, pool_width, pool_height]), tf.TensorShape(None)]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3126,
        "label": "no",
        "change": [
            "def choose_random_framework(excluded=None):",
            "while True:",
            "if len(excluded) == 5:",
            "raise Exception(",
            "-                \"Unable to select framework, all backends are either excluded or not installed.\"",
            "+                \"Unable to select framework, all backends are either excluded \"",
            "+                \"or not installed.\"",
            ")",
            "f = np.random.choice(",
            "[f_srt for f_srt in list(FW_DICT.keys()) if f_srt not in excluded]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3128,
        "label": "no",
        "change": [
            "class Pipeline(_ScikitCompat):",
            "self.device = torch.device(f\"cuda:{device}\")",
            "else:",
            "self.device = device",
            "+        self.torch_dtype = torch_dtype",
            "self.binary_output = binary_output",
            "",
            "# Special handling"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3129,
        "label": "no",
        "change": [
            "def load_depth(file_name):",
            "",
            "",
            "def load_camera_data(file_name):",
            "-    \"\"\"Loads the camera data using the syntel SDK and converts to torch.Tensor.\"\"\"",
            "+    \"\"\"Load the camera data using the syntel SDK and converts to torch.Tensor.\"\"\"",
            "if not os.path.isfile(file_name):",
            "raise AssertionError(f\"Invalid file {file_name}\")",
            "import sintel_io"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3130,
        "label": "no",
        "change": [
            "class GCNTest(TestCase):",
            "conv = GCN(1, 10)",
            "i = torch.LongTensor([[0, 0, 1, 1, 2, 2], [1, 2, 0, 2, 0, 1]])",
            "w = torch.FloatTensor([1, 1, 1, 1, 1, 1])",
            "-        adj = Variable(torch.sparse.FloatTensor(i, w, torch.Size([3, 3])))",
            "+        adj = torch.sparse.FloatTensor(i, w, torch.Size([3, 3]))",
            "features = Variable(torch.FloatTensor([[1], [2], [3]]))",
            "",
            "out = conv(adj, features)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3131,
        "label": "no",
        "change": [
            "class LabelField(Field[torch.Tensor]):",
            "@overrides",
            "def as_tensor(self,",
            "padding_lengths: Dict[str, int],",
            "-                  cuda_device: int = -1,",
            "-                  for_training: bool = True) -> torch.Tensor:",
            "+                  cuda_device: int = -1) -> torch.Tensor:",
            "# pylint: disable=unused-argument",
            "-        tensor = Variable(torch.LongTensor([self._label_id]), volatile=not for_training)",
            "+        tensor = torch.LongTensor([self._label_id])",
            "return tensor if cuda_device == -1 else tensor.cuda(cuda_device)",
            "",
            "@overrides"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3138,
        "label": "no",
        "change": [
            "class BeamformerNet(AbsEnhancement):",
            "enhanced = [torch.stack([enh.real, enh.imag], dim=-1) for enh in enhanced]",
            "else:",
            "# single-speaker output",
            "-            enhanced = torch.stack([enhanced.real, enhanced.imag], dim=-1).float()",
            "+            enhanced = [torch.stack([enhanced.real, enhanced.imag], dim=-1)]",
            "return enhanced, flens, masks",
            "",
            "def forward_rawwav(self, input: torch.Tensor, ilens: torch.Tensor):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3142,
        "label": "no",
        "change": [
            "class SimpleOptimizer(torch.optim.Optimizer):",
            "return loss",
            "",
            "",
            "-def random_dataloader(model, total_samples, hidden_dim, device):",
            "+def random_dataloader(model, total_samples, hidden_dim, device, dtype=torch.half):",
            "batch_size = model.train_micro_batch_size_per_gpu()",
            "-    train_data = torch.randn(total_samples, hidden_dim, device=device, dtype=torch.half)",
            "+    train_data = torch.randn(total_samples, hidden_dim, device=device, dtype=dtype)",
            "train_label = torch.empty(total_samples,",
            "dtype=torch.long,",
            "device=device).random_(hidden_dim)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3143,
        "label": "no",
        "change": [
            "class TextField(SequenceField[Dict[str, torch.Tensor]]):",
            "# than a LongTensor here, and it's not clear how to signal that.  Maybe we'll need to",
            "# add a class method to TokenIndexer to tell us the type?  But we can worry about that",
            "# when there's a compelling use case for it.",
            "-            tensor = Variable(torch.LongTensor(padded_array), volatile=not for_training)",
            "+            tensor = torch.LongTensor(padded_array)",
            "tensors[indexer_name] = tensor if cuda_device == -1 else tensor.cuda(cuda_device)",
            "return tensors"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3144,
        "label": "no",
        "change": [
            "class WeightNormalization(WeightNormalizationOriginal):",
            "self.built = True",
            "",
            "def call(self, inputs):",
            "-        \"\"\"Call `Layer`\"\"\"",
            "+        \"\"\"Call `Layer`.\"\"\"",
            "",
            "def _do_nothing():",
            "return tf.identity(self.g)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3146,
        "label": "no",
        "change": [
            "class Conformer(torch.nn.Module):",
            "",
            "residual = x",
            "x = self.norm_self_att(x)",
            "-        key = torch.cat([self.cache[0], x], dim=1)",
            "+        if left_context > 0:",
            "+            key = torch.cat([self.cache[0], x], dim=1)",
            "+        else:",
            "+            key = x",
            "val = key",
            "",
            "if right_context > 0:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3149,
        "label": "no",
        "change": [
            "def unravel_index(",
            "for dim in reversed(shape):",
            "output.append(temp % dim)",
            "temp = temp // dim",
            "-    ret = tf.constant(reversed(output), dtype=tf.int32)",
            "+    output.reverse()",
            "+    ret = tf.constant(output, dtype=tf.int32)",
            "return tuple(ret)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3153,
        "label": "no",
        "change": [
            "class TransformerEncoderLayerBase(nn.Module):",
            "def _get_fc_rank(self, remove_num: int) -> List[int]:",
            "f1_filter_param = []",
            "for i in range(self.fc1.out_features):",
            "-            f1_filter_param.append(torch.sum(torch.abs(self.fc1.weight[i])) + torch.sum(torch.abs(self.fc2.weight[:, i])) + torch.abs(self.fc1.bias[i]))",
            "-        return sorted(range(len(f1_filter_param)), key=lambda k: f1_filter_param[k], reverse=False)[0:remove_num]",
            "+            f1_filter_param.append(",
            "+                torch.sum(torch.abs(self.fc1.weight[i]))",
            "+                + torch.sum(torch.abs(self.fc2.weight[:, i]))",
            "+                + torch.abs(self.fc1.bias[i])",
            "+            )",
            "+        return sorted(",
            "+            range(len(f1_filter_param)), key=lambda k: f1_filter_param[k], reverse=False",
            "+        )[0:remove_num]",
            "",
            "def _prune_fc_layer(self, remove_index: List[int]):",
            "new_fc1_weight = []"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3155,
        "label": "no",
        "change": [
            "def asarray(",
            "dtype = as_native_dtype((default_dtype(dtype, object_in)))",
            "",
            "if copy is True:",
            "-        return (",
            "-            torch.as_tensor(object_in, dtype=dtype)",
            "-            .clone()",
            "-            .detach()",
            "-            .to(device)",
            "-        )",
            "+        return torch.as_tensor(object_in, dtype=dtype).clone().detach().to(device)",
            "else:",
            "return torch.as_tensor(object_in, dtype=dtype).to(device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3156,
        "label": "no",
        "change": [
            "class FP16OptimizerFairseq(Fairseq_FP16OptimizerMixin, FP16Optimizer):",
            "",
            "# reset fp32_optimizer param groups to using master weights",
            "fp32_param_group = self.fp32_optimizer.param_groups[0]",
            "-        fp32_param_group[\"params\"] = [self.fp32_params]",
            "+        fp32_param_group[\"params\"] = [self.fp32_params[torch.cuda.current_device()]]",
            "self.fp32_optimizer.param_groups = []",
            "self.fp32_optimizer.add_param_group(fp32_param_group)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3157,
        "label": "no",
        "change": [
            "def image_histogram2d(",
            "u = torch.abs(image.unsqueeze(0) - centers) / bandwidth",
            "",
            "if kernel == \"gaussian\":",
            "-        kernel_values = torch.exp(-0.5 * u ** 2)",
            "-    elif kernel in (\"triangular\", \"uniform\", \"epanechnikov\",):",
            "+        kernel_values = torch.exp(-0.5 * u**2)",
            "+    elif kernel in (\"triangular\", \"uniform\", \"epanechnikov\"):",
            "# compute the mask and cast to floating point",
            "mask = (u <= 1).to(u.dtype)",
            "if kernel == \"triangular\":",
            "-            kernel_values = (1. - u) * mask",
            "+            kernel_values = (1.0 - u) * mask",
            "elif kernel == \"uniform\":",
            "kernel_values = torch.ones_like(u) * mask",
            "else:  # kernel == \"epanechnikov\"",
            "-            kernel_values = (1. - u ** 2) * mask",
            "+            kernel_values = (1.0 - u**2) * mask",
            "else:",
            "raise ValueError(f\"Kernel must be 'triangular', 'gaussian', \" f\"'uniform' or 'epanechnikov'. Got {kernel}.\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3158,
        "label": "no",
        "change": [
            "def main():",
            "# download url: https://download.pytorch.org/models/mobilenet_v2-b0353104.pth",
            "model_weight_path = \"./mobilenet_v2.pth\"",
            "assert os.path.exists(model_weight_path), \"file {} dose not exist.\".format(model_weight_path)",
            "-    pre_weights = torch.load(model_weight_path, map_location=device)",
            "+    pre_weights = torch.load(model_weight_path, map_location='cpu')",
            "",
            "# delete classifier weights",
            "pre_dict = {k: v for k, v in pre_weights.items() if net.state_dict()[k].numel() == v.numel()}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3161,
        "label": "yes",
        "change": [
            "class LAFOrienter(nn.Module):",
            "self.patch_size,",
            "self.patch_size)",
            "angles_radians: torch.Tensor = self.angle_detector(patches).view(B, N)",
            "-        laf_out: torch.Tensor = set_laf_orientation(laf, rad2deg(angles_radians))",
            "+        prev_angle = get_laf_orientation(laf).view_as(angles_radians)",
            "+        laf_out: torch.Tensor = set_laf_orientation(laf, rad2deg(angles_radians) + prev_angle)",
            "return laf_out"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3165,
        "label": "no",
        "change": [
            "class RelationExtractor(flair.nn.DefaultClassifier[Sentence, Relation]):",
            "]",
            ")",
            "else:",
            "-            return torch.cat([span_1.tokens[0].get_embedding(embedding_names), span_2.tokens[0].get_embedding(embedding_names)])",
            "+            return torch.cat(",
            "+                [span_1.tokens[0].get_embedding(embedding_names), span_2.tokens[0].get_embedding(embedding_names)]",
            "+            )",
            "",
            "def _print_predictions(self, batch, gold_label_type):",
            "lines = []"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3166,
        "label": "no",
        "change": [
            "class ScalarMix(torch.nn.Module):",
            "",
            "normed_weights = torch.nn.functional.softmax(torch.cat([parameter for parameter",
            "in self.scalar_parameters]), dim=0)",
            "-        normed_weights = torch.split(normed_weights, split_size=1)",
            "+        normed_weights = torch.split(normed_weights, split_size_or_sections=1)",
            "",
            "if not self.do_layer_norm:",
            "pieces = []"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3167,
        "label": "no",
        "change": [
            "def guide(data):",
            "priors = {'linear.weight': w_prior, 'linear.bias': b_prior}",
            "# overloading the parameters in the module with random samples from the prior",
            "lifted_module = pyro.random_module(\"module\", regression_model, priors)",
            "-    # sample a nn",
            "-    lifted_module()",
            "+    # sample a regressor",
            "+    return lifted_module()",
            "",
            "",
            "# instantiate optim and inference objects"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3170,
        "label": "no",
        "change": [
            "def generate_two_view_random_scene(",
            "P2 = scene['P'][1:2].to(device, dtype)",
            "",
            "# fundamental matrix",
            "-    F_mat = epi.fundamental_from_projections(",
            "-        P1[..., :3, :], P2[..., :3, :])",
            "+    F_mat = epi.fundamental_from_projections(P1[..., :3, :], P2[..., :3, :])",
            "",
            "F_mat = epi.normalize_transformation(F_mat)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3173,
        "label": "no",
        "change": [
            "class RandomElasticTransform(GeometricAugmentationBase2D):",
            "def generate_parameters(self, shape: torch.Size) -> Dict[str, Tensor]:",
            "B, _, H, W = shape",
            "if self.same_on_batch:",
            "-            noise = torch.rand(1, 2, H, W, device=self.device, dtype=self.dtype).repeat(B, 1, 1, 1)",
            "+            noise = torch.rand(1, 2, H, W, device=self.device, dtype=self.dtype).expand(B, 2, H, W)",
            "else:",
            "noise = torch.rand(B, 2, H, W, device=self.device, dtype=self.dtype)",
            "return dict(noise=noise * 2 - 1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3174,
        "label": "no",
        "change": [
            "class SpatialSoftArgmax2d(nn.Module):",
            "See :func:`~kornia.geometry.subpix.spatial_soft_argmax2d` for details.",
            "\"\"\"",
            "",
            "-    def __init__(",
            "-        self, temperature: torch.Tensor = torch.tensor(1.0), normalized_coordinates: bool = True",
            "-    ) -> None:",
            "+    def __init__(self, temperature: torch.Tensor = torch.tensor(1.0), normalized_coordinates: bool = True) -> None:",
            "super().__init__()",
            "self.temperature: torch.Tensor = temperature",
            "self.normalized_coordinates: bool = normalized_coordinates"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3175,
        "label": "no",
        "change": [
            "class EfficientNetBaseEncoder(EfficientNet, EncoderMixin):",
            "def get_stages(self):",
            "return [",
            "nn.Identity(),",
            "-            nn.Sequential(self.conv_stem, self.bn1, self.act1),",
            "+            nn.Sequential(self.conv_stem, self.bn1),",
            "self.blocks[: self._stage_idxs[0]],",
            "self.blocks[self._stage_idxs[0] : self._stage_idxs[1]],",
            "self.blocks[self._stage_idxs[1] : self._stage_idxs[2]],"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3176,
        "label": "no",
        "change": [
            "def get_optimal_device():",
            "if torch.cuda.is_available():",
            "return torch.device(get_cuda_device_string())",
            "",
            "-    # if has_mps():",
            "-    #     return torch.device(\"mps\")",
            "+    if has_mps():",
            "+        return torch.device(\"mps\")",
            "",
            "return cpu"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3177,
        "label": "yes",
        "change": [
            "def regularize_cost(regex, func, name='regularize_cost'):",
            "for p in params:",
            "para_name = p.name",
            "# in replicated mode, only regularize variables inside this tower",
            "-        if ctx.has_own_variables and (not para_name.startswith(ctx.name)):",
            "+        if ctx.has_own_variables and (not para_name.startswith(ctx.vs_name)):",
            "continue",
            "if re.search(regex, para_name):",
            "costs.append(func(p))",
            "_log_regularizer(para_name)",
            "if not costs:",
            "-        return 0",
            "+        return tf.constant(0, dtype=tf.float32, name='empty_regularize_cost')",
            "return tf.add_n(costs, name=name)"
        ],
        "comments": "",
        "Symptom": "return warning",
        "Root_Cause": "argument error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 3182,
        "label": "no",
        "change": [
            "class KerasLayerTest(tf.test.TestCase):",
            "self.assertEqual(result, new_result)",
            "",
            "def testGetConfigFromConfigWithHParams(self):",
            "+    if tf.__version__ == \"2.0.0-alpha0\":",
            "+      self.skipTest(\"b/127938157 broke use of default hparams\")",
            "export_dir = os.path.join(self.get_temp_dir(), \"with-hparams\")",
            "_save_model_with_hparams(export_dir)",
            "layer = hub.KerasLayer(export_dir, arguments=dict(a=10.))  # Leave b=0."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3184,
        "label": "no",
        "change": [
            "class OpsTest(tf.test.TestCase):",
            "filter_shape = (5, 5)",
            "vals = np.random.randn(batch_size, input_shape[0], input_shape[1], 1)",
            "with self.test_session() as sess:",
            "+            tf.add_to_collection(\"IS_TRAINING\", True)",
            "tensor_in = tf.placeholder(tf.float32, [batch_size, input_shape[0],",
            "input_shape[1], 1])",
            "-            res = ops.conv2d(tensor_in, n_filters, filter_shape)",
            "+            res = ops.conv2d(",
            "+                tensor_in, n_filters, filter_shape, batch_norm=True)",
            "sess.run(tf.initialize_all_variables())",
            "conv = sess.run(res, feed_dict={tensor_in.name: vals})",
            "self.assertEqual(conv.shape, (batch_size, input_shape[0],"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3185,
        "label": "no",
        "change": [
            "class TestRandomEqualize3D:",
            "",
            "class TestRandomAffine3D:",
            "def test_batch_random_affine_3d(self, device, dtype):",
            "-        # TODO(jian): crashes with pytorch 1.10, cuda and fp64",
            "-        if torch_version_geq(1, 10) and \"cuda\" in str(device) and dtype == torch.float64:",
            "+        # TODO(jian): cuda and fp64",
            "+        if \"cuda\" in str(device) and dtype == torch.float64:",
            "pytest.skip(\"AssertionError: assert tensor(False, device='cuda:0')\")",
            "",
            "f = RandomAffine3D((0, 0, 0), p=1.0, return_transform=True)  # No rotation"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3187,
        "label": "yes",
        "change": [
            "class TFConvBertEmbeddings(tf.keras.layers.Layer):",
            "token_type_ids = tf.fill(dims=input_shape, value=0)",
            "",
            "if position_ids is None:",
            "-            position_ids = tf.expand_dims(tf.range(start=0, limit=input_shape[-1]), axis=0)",
            "+            position_ids = tf.expand_dims(",
            "+                tf.range(start=past_key_values_length, limit=input_shape[1] + past_key_values_length), axis=0",
            "+            )",
            "",
            "position_embeds = tf.gather(params=self.position_embeddings, indices=position_ids)",
            "position_embeds = tf.tile(input=position_embeds, multiples=(input_shape[0], 1, 1))"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3188,
        "label": "no",
        "change": [
            "def load_data_mnist():",
            "torch.set_num_threads(4)",
            "",
            "kwargs = {'num_workers': 0, 'pin_memory': True} if args.cuda else {}",
            "+    data_dir = args.data_dir or './data'",
            "from filelock import FileLock",
            "with FileLock(os.path.expanduser(\"~/.datalock\")):",
            "train_dataset = \\",
            "-            datasets.MNIST('./data', train=True, download=True,",
            "+            datasets.MNIST(data_dir, train=True, download=True,",
            "transform=transforms.Compose([",
            "transforms.ToTensor(),",
            "transforms.Normalize((0.1307,), (0.3081,))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3189,
        "label": "no",
        "change": [
            "class ResNeXtBlock(nn.Module):",
            "super().__init__()",
            "bot_channels = int(round(num_channels * bot_mul))",
            "self.conv1 = nn.LazyConv2d(bot_channels, kernel_size=1, stride=1)",
            "-        self.conv2 = nn.LazyConv2d(bot_channels, kernel_size=3, stride=strides,",
            "-                                   padding=1, groups=bot_channels//groups)",
            "+        self.conv2 = nn.LazyConv2d(bot_channels, kernel_size=3,",
            "+                                   stride=strides, padding=1,",
            "+                                   groups=bot_channels//groups)",
            "self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1, stride=1)",
            "self.bn1 = nn.LazyBatchNorm2d()",
            "self.bn2 = nn.LazyBatchNorm2d()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3190,
        "label": "no",
        "change": [
            "class DQNPrioritizedReplay:",
            "def store_transition(self, s, a, r, s_):",
            "if self.prioritized:    # prioritized replay",
            "transition = np.hstack((s, [a, r], s_))",
            "-            self.memory.store(1, transition)    # have 1 priority for newly arrived transition",
            "+            self.memory.store(0.9, transition)    # have 1 priority for newly arrived transition",
            "else:       # random replay",
            "if not hasattr(self, 'memory_counter'):",
            "self.memory_counter = 0"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3192,
        "label": "no",
        "change": [
            "class TFGPTJAttention(tf.keras.layers.Layer):",
            "key = self._split_heads(key, True)",
            "value = self._split_heads(value, False)",
            "",
            "-        sincos = tf.gather(self.embed_positions, position_ids, axis=0)",
            "+        sincos = tf.cast(tf.gather(self.embed_positions, position_ids, axis=0), hidden_states.dtype)",
            "sincos = tf.split(sincos, 2, axis=-1)",
            "if self.rotary_dim is not None:",
            "k_rot = key[:, :, :, : self.rotary_dim]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3193,
        "label": "no",
        "change": [
            "class TFMT5ModelIntegrationTest(unittest.TestCase):",
            "labels = tokenizer(\"Hi I am\", return_tensors=\"tf\").input_ids",
            "",
            "loss = model(input_ids, labels=labels).loss",
            "-        mtf_score = -tf.math.reduce_sum(loss).numpy()",
            "+        mtf_score = -tf.math.reduce_mean(loss).numpy()",
            "",
            "-        EXPECTED_SCORE = -84.9127",
            "+        EXPECTED_SCORE = -21.210594",
            "self.assertTrue(abs(mtf_score - EXPECTED_SCORE) < 2e-4)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3196,
        "label": "no",
        "change": [
            "def get_config():",
            ")",
            "",
            "def update_target_param():",
            "-        vars = tf.trainable_variables()",
            "+        vars = tf.global_variables()",
            "ops = []",
            "G = tf.get_default_graph()",
            "for v in vars:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3199,
        "label": "no",
        "change": [
            "class TestCropByBoxes3D:",
            "patches = kornia.geometry.transform.crop_by_boxes3d(inp, src_box, dst_box, align_corners=True)",
            "assert_close(patches, expected, rtol=1e-4, atol=1e-4)",
            "",
            "-    def test_jit(self, device, dtype):",
            "+    def test_dynamo(self, device, dtype, torch_optimizer):",
            "# Define script",
            "op = kornia.geometry.transform.crop_by_boxes3d",
            "-        op_script = torch.jit.script(op)",
            "+        op_script = torch_optimizer(op)",
            "# Define input",
            "inp = torch.randn((1, 1, 7, 7, 7), device=device, dtype=dtype)",
            "src_box = torch.tensor("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3203,
        "label": "no",
        "change": [
            "class TFLongformerMainLayer(tf.keras.layers.Layer):",
            "inputs_embeds_padding = self.embeddings(input_ids_padding)",
            "return tf.concat([inputs_embeds, inputs_embeds_padding], axis=-2)",
            "",
            "-            inputs_embeds = tf.cond(padding_len > 0, pad_embeddings, lambda: inputs_embeds)",
            "+            inputs_embeds = tf.cond(tf.math.greater(padding_len, 0), pad_embeddings, lambda: inputs_embeds)",
            "",
            "attention_mask = tf.pad(attention_mask, paddings, constant_values=False)  # no attention on the padding tokens",
            "token_type_ids = tf.pad(token_type_ids, paddings, constant_values=0)  # pad with token_type_id = 0"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3205,
        "label": "yes",
        "change": [
            "class Pipeline(pps_module.Preprocessor):",
            "transformed.append(data)",
            "if len(transformed) == 1:",
            "return transformed[0]",
            "-        return tuple(transformed)",
            "+        return tf.data.Dataset.zip(tuple(transformed))",
            "",
            "def save(self, filepath):",
            "io_utils.save_json(filepath, self.get_config())"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3209,
        "label": "no",
        "change": [
            "class Covost2(datasets.GeneratorBasedBuilder):",
            "features=datasets.Features(",
            "client_id=datasets.Value(\"string\"),",
            "file=datasets.Value(\"string\"),",
            "-                audio=datasets.features.Audio(sampling_rate=16_000),",
            "+                audio=datasets.Audio(sampling_rate=16_000),",
            "sentence=datasets.Value(\"string\"),",
            "translation=datasets.Value(\"string\"),",
            "id=datasets.Value(\"string\"),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3210,
        "label": "no",
        "change": [
            "class DecoderRNNTAtt(torch.nn.Module):",
            "",
            "hyp = {'score': 0.0, 'yseq': [self.blank]}",
            "",
            "-        eys = torch.zeros((1, self.dunits))",
            "+        eys = torch.zeros((1, self.embed_dim))",
            "att_c, att_w = self.att[0](h.unsqueeze(0), [h.size(0)],",
            "self.dropout_dec[0](z_list[0]), None)",
            "ey = torch.cat((eys, att_c), dim=1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3220,
        "label": "yes",
        "change": [
            "class Iterative(Solver):",
            "next_step = self.next_step(*args)",
            "step = (lambda: self.step(*args))",
            "do_nothing = (lambda: args)",
            "-                args = tf.cond(pred=next_step, true_fn=step, false_fn=do_nothing)",
            "+                args = self.cond(pred=next_step, true_fn=step, false_fn=do_nothing)",
            "",
            "else:",
            "# TensorFlow while loop",
            "-            args = tf.while_loop(",
            "+            args = self.while_loop(",
            "cond=self.next_step, body=self.step, loop_vars=args,",
            "maximum_iterations=self.max_iterations",
            ")"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3223,
        "label": "yes",
        "change": [
            "def train(hyp):",
            "if not opt.evolve:",
            "plot_results()  # save as results.png",
            "print('%g epochs completed in %.3f hours.\\n' % (epoch - start_epoch + 1, (time.time() - t0) / 3600))",
            "-    dist.destroy_process_group() if torch.cuda.device_count() > 1 else None",
            "+    dist.destroy_process_group() if device.type != 'cpu' and torch.cuda.device_count() > 1 else None",
            "torch.cuda.empty_cache()",
            "return results"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 3225,
        "label": "no",
        "change": [
            "class EvalModelTemplate(",
            "self.test_step_end_called = False",
            "self.test_epoch_end_called = False",
            "",
            "-        # if you specify an example input, the summary will show input/output for each layer",
            "-        # TODO: to be fixed in #1773",
            "-        # self.example_input_array = torch.rand(5, 28 * 28)",
            "+        self.example_input_array = torch.rand(5, 28 * 28)",
            "",
            "# build model",
            "self.__build_model()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3226,
        "label": "no",
        "change": [
            "def main(args):",
            "if args.lfw_dir:",
            "evaluate(sess, enqueue_op, image_paths_placeholder, labels_placeholder, phase_train_placeholder, batch_size_placeholder,",
            "embeddings, label_batch, lfw_paths, actual_issame, args.lfw_batch_size, args.lfw_nrof_folds, log_dir, step, summary_writer)",
            "+    sess.close()",
            "return model_dir",
            "",
            "def find_threshold(var, percentile):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3227,
        "label": "no",
        "change": [
            "class Model:",
            "def flatten(obs, framework):",
            "\"\"\"Flatten the given tensor.\"\"\"",
            "if framework == \"tf\":",
            "-        return tf.layers.flatten(obs)",
            "+        return tf1.layers.flatten(obs)",
            "elif framework == \"torch\":",
            "assert torch is not None",
            "return torch.flatten(obs, start_dim=1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3230,
        "label": "no",
        "change": [
            "def predict_df(inference_sess: ExecutionSession, df: pd.DataFrame):",
            "@pytest.fixture()",
            "def tensorflow_model(tmpdir):",
            "model = NativeModel()",
            "-    tf.saved_model.save(model, tmpdir)",
            "+    tf.saved_model.save(model, str(tmpdir))",
            "",
            "",
            "@pytest.fixture()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3231,
        "label": "no",
        "change": [
            "class BatchNormModel(TFModelV2):",
            "# Add a batch norm layer",
            "last_layer = tf1.layers.batch_normalization(",
            "last_layer,",
            "-                    training=input_dict.is_training,",
            "+                    training=input_dict[\"is_training\"],",
            "name=\"bn_{}\".format(i))",
            "",
            "output = tf1.layers.dense("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3236,
        "label": "no",
        "change": [
            "class T5Block(nn.Module):",
            "",
            "# Apply Feed Forward layer",
            "hidden_states = self.layer[-1](hidden_states)",
            "-        if torch.isinf(hidden_states).any():",
            "+",
            "+        # clamp inf values to enable fp16 training",
            "+        if hidden_states.dtype == torch.float16 and torch.isinf(hidden_states).any():",
            "clamp_value = torch.finfo(hidden_states.dtype).max - 1000",
            "hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)",
            "+",
            "outputs = (hidden_states,)",
            "",
            "outputs = outputs + (present_key_value_state,) + attention_outputs"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3238,
        "label": "yes",
        "change": [
            "class PinholeCamera:",
            ">>> _ = torch.manual_seed(0)",
            ">>> x = torch.rand(1, 2)",
            ">>> depth = torch.ones(1, 1)",
            "-            >>> I = torch.eye(4)[None]",
            "+            >>> K = torch.eye(4)[None]",
            ">>> E = torch.eye(4)[None]",
            ">>> h = torch.ones(1)",
            ">>> w = torch.ones(1)",
            ">>> pinhole = kornia.geometry.camera.PinholeCamera(K, E, h, w)",
            "-            >>> pinhole.unproject_points(x, depth)",
            "+            >>> pinhole.unproject(x, depth)",
            "tensor([[0.4963, 0.7682, 1.0000]])",
            "\"\"\"",
            "P = self.intrinsics @ self.extrinsics"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3239,
        "label": "yes",
        "change": [
            "class TorchHook:",
            "if type(native_func) in [types.FunctionType, types.BuiltinFunctionType]:",
            "# 3. Build the hooked function",
            "new_func = self.get_hooked_func(native_func)",
            "-                # 4. Move the native function",
            "-                setattr(torch_module, f\"native_{func}\", native_func)",
            "+                # 4. Move the native function to its original module",
            "+                # /!\\ Can be different from the torch_module!",
            "+                # Ex: in torch.py `torch.argmax = torch.functional.argmax`",
            "+                # ... So torch.argmax.__module__ is 'torch.functional' != 'torch'",
            "+                setattr(eval(native_func.__module__), f\"native_{func}\", native_func)",
            "# 5. Put instead the hooked one",
            "setattr(torch_module, func, new_func)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3240,
        "label": "no",
        "change": [
            "class EvalResult(Result):",
            "",
            "def weighted_mean(result, weights):",
            "weights = weights.to(result.device)",
            "-    numerator = torch.dot(result.float(), weights.t().float())",
            "+    numerator = torch.dot(result.float(), weights.transpose(-1, 0).float())",
            "result = numerator / weights.sum().float()",
            "return result"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3242,
        "label": "yes",
        "change": [
            "class TowerContext(object):",
            "global _CurrentTowerContext",
            "assert _CurrentTowerContext is None, \"Cannot nest TowerContext!\"",
            "_CurrentTowerContext = self",
            "-        curr_vs = tf.get_variable_scope()",
            "-        assert curr_vs.name == '', \"Cannot nest TowerContext with an existing variable scope!\"",
            "+        if self.is_training:",
            "+            curr_vs = tf.get_variable_scope()",
            "+            assert curr_vs.name == '', \"In training, cannot nest TowerContext with an existing variable scope!\"",
            "",
            "self._ctxs = self._get_scopes()",
            "self._ctxs.append(self._collection_guard)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "state handling error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 3243,
        "label": "no",
        "change": [
            "class Trainer(object):",
            "\"\"\"",
            "assert isinstance(config, TrainConfig), type(config)",
            "self.config = config",
            "-        tf.add_to_collection(MODEL_KEY, config.model)",
            "+        self.model = config.model",
            "",
            "@abstractmethod",
            "def train(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3244,
        "label": "yes",
        "change": [
            "class SelfMultiheadAttn(nn.Module):",
            "self.register_parameter('lyr_norm_beta_weights', None)",
            "self.lyr_nrm_gamma_weights = None",
            "self.lyr_nrm_beta_weights  = None",
            "-                self.lyr_nrm = torch.nn.LayerNorm(embed_dim)",
            "+                self.lyr_nrm = FusedLayerNorm(embed_dim)",
            "self.reset_parameters()",
            "",
            "if self.include_norm_add:"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3247,
        "label": "no",
        "change": [
            "def submit(net, gpu=False):",
            "if __name__ == '__main__':",
            "net = UNet(3, 1).cuda()",
            "net.load_state_dict(torch.load('MODEL.pth'))",
            "-    submit(net, True)",
            "+    submit(net)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3248,
        "label": "no",
        "change": [
            "class Trainer(object):",
            "# 0.7 workaround, restore values",
            "for t in l_stags:",
            "tf.add_to_collection(\"summary_tags\", t)",
            "+        for t in l4_stags:",
            "+            tf.add_to_collection(tf.GraphKeys.GRAPH_CONFIG, t)",
            "for t in l1_dtags:",
            "tf.add_to_collection(tf.GraphKeys.DATA_PREP, t)",
            "for t in l2_dtags:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3249,
        "label": "no",
        "change": [
            "def make_vocab_from_params(params: Params, serialization_dir: str):",
            "logger.info(\"From dataset instances, %s will be considered for vocabulary creation.\",",
            "\", \".join(datasets_for_vocab_creation))",
            "",
            "-    instances = [instance for key, dataset in all_datasets.items()",
            "+    instances = (instance for key, dataset in all_datasets.items()",
            "for instance in dataset",
            "-                 if key in datasets_for_vocab_creation]",
            "+                 if key in datasets_for_vocab_creation)",
            "",
            "vocab = Vocabulary.from_params(vocab_params, instances)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3250,
        "label": "yes",
        "change": [
            "class ScaleSpaceDetector(nn.Module):",
            "max_coords_best = _scale_index_to_scale(max_coords_best, sigmas_oct)",
            "",
            "# Create local affine frames (LAFs)",
            "-            rotmat = angle_to_rotation_matrix(torch.zeros(B, N))",
            "+            rotmat = angle_to_rotation_matrix(torch.zeros(B, N).to(max_coords_best.device).to(max_coords_best.dtype))",
            "current_lafs = torch.cat([self.mr_size * max_coords_best[:, :, 0].view(B, N, 1, 1) * rotmat,",
            "max_coords_best[:, :, 1:3].view(B, N, 2, 1)], dim=3)",
            "# Normalize LAFs"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3251,
        "label": "no",
        "change": [
            "class BertForMultipleChoice(BertPreTrainedModel):",
            "self.num_choices = num_choices",
            "self.bert = BertModel(config)",
            "self.dropout = nn.Dropout(config.hidden_dropout_prob)",
            "-        self.classifier = nn.Linear(config.hidden_size, 1)",
            "+        self.classifier = nn.Linear(config.hidden_size, num_choices)",
            "self.apply(self.init_bert_weights)",
            "",
            "def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):",
            "flat_input_ids = input_ids.view(-1, input_ids.size(-1))",
            "-        flat_token_type_ids = token_type_ids.view(-1, token_type_ids.size(-1))",
            "-        flat_attention_mask = attention_mask.view(-1, attention_mask.size(-1))",
            "+        flat_token_type_ids = token_type_ids.view(-1, token_type_ids.size(-1)) if token_type_ids is not None else None",
            "+        flat_attention_mask = attention_mask.view(-1, attention_mask.size(-1)) if attention_mask is not None else None",
            "_, pooled_output = self.bert(flat_input_ids, flat_token_type_ids, flat_attention_mask, output_all_encoded_layers=False)",
            "pooled_output = self.dropout(pooled_output)",
            "logits = self.classifier(pooled_output)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3255,
        "label": "no",
        "change": [
            "class LearningRateScheduler(Registrable):",
            "self.lr_scheduler.step_batch(batch_num_total)",
            "return",
            "",
            "+    # Requires custom from_params",
            "@classmethod",
            "-    def from_params(cls, optimizer: torch.optim.Optimizer, params: Params):",
            "+    def from_params(cls, optimizer: torch.optim.Optimizer, params: Params):  # type: ignore",
            "+        # pylint: disable=arguments-differ",
            "scheduler = params.pop_choice(\"type\", LearningRateScheduler.list_available())",
            "",
            "schedulers = LearningRateScheduler.by_name(scheduler)(optimizer, **params.as_dict())  # type: ignore"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3257,
        "label": "no",
        "change": [
            "class Trainer:",
            "elif is_torch_tpu_available():",
            "# tpu-comment: Get all predictions and labels from all worker shards of eval dataset",
            "if preds is not None:",
            "-                preds = nested_xla_mesh_reduce(\"eval_preds\", preds)",
            "+                preds = nested_xla_mesh_reduce(preds, \"eval_preds\")",
            "if label_ids is not None:",
            "-                label_ids = nested_xla_mesh_reduce(\"eval_label_ids\", label_ids, torch.cat)",
            "+                label_ids = nested_xla_mesh_reduce(label_ids, \"eval_label_ids\")",
            "if eval_losses is not None:",
            "eval_losses = xm.mesh_reduce(\"eval_losses\", torch.tensor(eval_losses), torch.cat).tolist()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3259,
        "label": "no",
        "change": [
            "def train(hyp, opt, device, callbacks):  # hyp is path/to/hyp.yaml or hyp dictio",
            "",
            "# DP mode",
            "if cuda and RANK == -1 and torch.cuda.device_count() > 1:",
            "-        LOGGER.warning('WARNING: DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\\n'",
            "+        LOGGER.warning('WARNING ⚠️ DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\\n'",
            "'See Multi-GPU Tutorial at https://github.com/ultralytics/yolov5/issues/475 to get started.')",
            "model = torch.nn.DataParallel(model)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3260,
        "label": "no",
        "change": [
            "def tf_default_data_collator(features: List[InputDataClass]) -> Dict[str, Any]:",
            "label_col_name = None",
            "if label_col_name is not None:",
            "if isinstance(first[label_col_name], tf.Tensor):",
            "-            dtype = tf.int64 if first[label_col_name].dtype.is_integer() else tf.float32",
            "+            dtype = tf.int64 if first[label_col_name].dtype.is_integer else tf.float32",
            "elif isinstance(first[label_col_name], np.ndarray) or isinstance(first[label_col_name], np.generic):",
            "dtype = tf.int64 if np.issubdtype(first[label_col_name].dtype, np.integer) else tf.float32",
            "elif isinstance(first[label_col_name], (tuple, list)):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3263,
        "label": "no",
        "change": [
            "def load_bart_od():",
            "-   \"counts\": a ``torch.FloatTensor`` of ridership counts, with shape",
            "``(num_hours, len(stations), len(stations))``.",
            "\"\"\"",
            "+    _mkdir_p(DATA)",
            "filename = os.path.join(DATA, \"bart_full.pkl.bz2\")",
            "# Work around apparent bug in torch.load(),torch.save().",
            "pkl_file = filename.rsplit(\".\", 1)[0]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3264,
        "label": "no",
        "change": [
            "def warp_perspective(src: torch.Tensor, M: torch.Tensor, dsize: Tuple[int, int],",
            "See a working example `here <https://kornia.readthedocs.io/en/latest/",
            "tutorials/warp_perspective.html>`_.",
            "\"\"\"",
            "-    if not torch.is_tensor(src):",
            "-        raise TypeError(\"Input src type is not a torch.Tensor. Got {}\"",
            "-                        .format(type(src)))",
            "-",
            "-    if not torch.is_tensor(M):",
            "-        raise TypeError(\"Input M type is not a torch.Tensor. Got {}\"",
            "-                        .format(type(M)))",
            "+    check_is_tensor(src)",
            "+    check_is_tensor(M)",
            "",
            "if not len(src.shape) == 4:",
            "raise ValueError(\"Input src must be a BxCxHxW tensor. Got {}\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3266,
        "label": "no",
        "change": [
            "def test_tensorflow_logical_xor(",
            "dtype_and_x=helpers.dtype_and_values(",
            "available_dtypes=tuple(",
            "set(ivy_np.valid_float_dtypes).intersection(",
            "-            set(ivy_tf.valid_float_dtypes)",
            "+                set(ivy_tf.valid_float_dtypes)",
            ")",
            "),",
            "num_arrays=2,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3269,
        "label": "no",
        "change": [
            "def get_affine_matrix2d(translations: torch.Tensor, center: torch.Tensor, scale:",
            "sy_tan = torch.tan(sy)  # type: ignore",
            "zeros = torch.zeros_like(sx)  # type: ignore",
            "ones = torch.ones_like(sx)  # type: ignore",
            "-        shear_mat = torch.stack([ones, -sx_tan, sx_tan * x,  # type: ignore   # noqa: E241",
            "-                                 -sy_tan, ones + sx_tan * sy_tan, sy_tan * (-sx_tan * x + y)],  # noqa: E241",
            "+        shear_mat = torch.stack([ones, -sx_tan, sx_tan * y,  # type: ignore   # noqa: E241",
            "+                                 -sy_tan, ones + sx_tan * sy_tan, sy_tan * (sx_tan * y + x)],  # noqa: E241",
            "dim=-1).view(-1, 2, 3)",
            "shear_mat = convert_affinematrix_to_homography(shear_mat)",
            "transform_h = transform_h @ shear_mat"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3271,
        "label": "yes",
        "change": [
            "class T5EncoderModel(T5PreTrainedModel):",
            "class PreTrainedModel",
            "\"\"\"",
            "for layer, heads in heads_to_prune.items():",
            "-            self.encoder.layer[layer].attention.prune_heads(heads)",
            "+            self.encoder.block[layer].layer[0].SelfAttention.prune_heads(heads)",
            "",
            "@add_start_docstrings_to_model_forward(T5_ENCODER_INPUTS_DOCSTRING)",
            "@replace_return_docstrings(output_type=BaseModelOutput, config_class=_CONFIG_FOR_DOC)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3272,
        "label": "no",
        "change": [
            "class ElucidatedImagen(nn.Module):",
            "",
            "lowres_cond_img_noisy = None",
            "if exists(lowres_cond_img):",
            "-            lowres_cond_img_noisy, _ = self.lowres_noise_schedule.q_sample(x_start = lowres_cond_img, t = lowres_aug_times, noise = torch.randn_like(lowres_cond_img))",
            "+            lowres_cond_img_noisy, *_ = self.lowres_noise_schedule.q_sample(x_start = lowres_cond_img, t = lowres_aug_times, noise = torch.randn_like(lowres_cond_img))",
            "",
            "# get the sigmas"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3273,
        "label": "no",
        "change": [
            "def local_guide(i, datum):",
            "",
            "def inspect_posterior_samples(i):",
            "c = local_guide(i, None)",
            "-    mean_param = Variable(torch.zeros(784), requires_grad=True)",
            "+    mean_param = Variable(torch.zeros(784, 1), requires_grad=True)",
            "# do MLE for class means",
            "m = pyro.param(\"mean_of_class_\" + str(c[0]), mean_param)",
            "sigma = Variable(torch.ones(m.size()))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3274,
        "label": "no",
        "change": [
            "class Auc(Metric):",
            "if self._all_gold_labels.shape[0] == 0:",
            "return 0.5",
            "false_positive_rates, true_positive_rates, _ = metrics.roc_curve(",
            "-            self._all_gold_labels.numpy(),",
            "-            self._all_predictions.numpy(),",
            "+            self._all_gold_labels.cpu().numpy(),",
            "+            self._all_predictions.cpu().numpy(),",
            "pos_label=self._positive_label,",
            ")",
            "auc = metrics.auc(false_positive_rates, true_positive_rates)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3275,
        "label": "no",
        "change": [
            "def perturb_past(",
            "print(' pplm_loss', (loss - kl_loss).data.cpu().numpy())",
            "",
            "# compute gradients",
            "-        loss.backward(retain_graph=True)",
            "+        loss.backward()",
            "",
            "# calculate gradient norms",
            "if grad_norms is not None and loss_type == PPLM_BOW:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3277,
        "label": "no",
        "change": [
            "def einsum(",
            "*operands: torch.Tensor,",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "+    dtype = _get_promoted_type_of_operands(operands)",
            "operands = (operand.to(torch.float32) for operand in operands)",
            "-    return torch.einsum(equation, *operands)",
            "+    return torch.einsum(equation, *operands).to(dtype)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3279,
        "label": "no",
        "change": [
            "class DocumentLSTMEmbeddings(DocumentEmbeddings):",
            "# EXTRACT EMBEDDINGS FROM LSTM",
            "# --------------------------------------------------------------------",
            "for sentence_no, length in enumerate(lengths):",
            "-            last_rep = outputs[length - 1, sentence_no, :].unsqueeze(0)",
            "+            last_rep = outputs[length - 1, sentence_no].unsqueeze(0)",
            "",
            "embedding = last_rep",
            "if self.use_first_representation:",
            "-                first_rep = outputs[0, sentence_no, :].unsqueeze(0)",
            "+                first_rep = outputs[0, sentence_no].unsqueeze(0)",
            "embedding = torch.cat([first_rep, last_rep], 1)",
            "",
            "sentence = sentences[sentence_no]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3282,
        "label": "no",
        "change": [
            "class AttentionRNNCell(nn.Module):",
            "memory_dim (int): memory vector (decoder autogression) feature dimension.",
            "align_model (str): 'b' for Bahdanau, 'ls' Location Sensitive alignment.",
            "\"\"\"",
            "-        super(AttentionRNN, self).__init__()",
            "+        super(AttentionRNNCell, self).__init__()",
            "self.align_model = align_model",
            "self.rnn_cell = nn.GRUCell(out_dim + memory_dim, out_dim)",
            "# pick bahdanau or location sensitive attention"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3283,
        "label": "yes",
        "change": [
            "class ResNet_Cifar(ModelDesc):",
            "ce_cost = tf.nn.softmax_cross_entropy_with_logits(labels=label, logits=logits)",
            "ce_cost = tf.reduce_mean(ce_cost, name='cross_entropy_loss')",
            "",
            "-        single_label = tf.to_int32(tf.argmax(label, axis=1))",
            "-        wrong = tf.to_float(tf.logical_not(tf.nn.in_top_k(logits, single_label, 1)), name='wrong_vector')",
            "+        single_label = tf.cast(tf.argmax(label, axis=1), tf.int32)",
            "+        wrong = tf.cast(tf.logical_not(tf.nn.in_top_k(logits, single_label, 1)), tf.float32, name='wrong_vector')",
            "# monitor training error",
            "add_moving_summary(tf.reduce_mean(wrong, name='train_error'), ce_cost)",
            "add_param_summary(('.*/W', ['histogram']))"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3284,
        "label": "no",
        "change": [
            "class GPT2ModelTest(ModelTesterMixin, unittest.TestCase):",
            "",
            "# append to next input_ids and attn_mask",
            "next_input_ids = torch.cat([input_ids, next_tokens], dim=-1)",
            "-            attn_mask = torch.cat([attn_mask, torch.ones((attn_mask.shape[0], 1)).long()], dim=1)",
            "+            attn_mask = torch.cat(",
            "+                [attn_mask, torch.ones((attn_mask.shape[0], 1), dtype=torch.long, device=torch_device)], dim=1",
            "+            )",
            "",
            "# get two different outputs",
            "output_from_no_past, _ = model(next_input_ids, attention_mask=attn_mask)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3287,
        "label": "no",
        "change": [
            "def conv2d_mask(module_masks, mask):",
            "if index is None:",
            "return None, None, None",
            "else:",
            "-            index = torch.LongTensor(index).to(weight_mask.device)",
            "+            index = index.long().to(weight_mask.device)",
            "weight_cmask = CoarseMask(num_dim=4)",
            "weight_cmask.add_index_mask(dim=dim, index=index)",
            "bias_cmask = None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3288,
        "label": "no",
        "change": [
            "class CodeGenAttention(nn.Module):",
            "max_positions = config.max_position_embeddings",
            "self.register_buffer(",
            "\"causal_mask\",",
            "-            torch.tril(torch.ones((max_positions, max_positions), dtype=torch.uint8)).view(",
            "+            torch.tril(torch.ones((max_positions, max_positions), dtype=torch.bool)).view(",
            "1, 1, max_positions, max_positions",
            "),",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3291,
        "label": "no",
        "change": [
            "class GAN(LightningModule):",
            "",
            "self.validation_z = torch.randn(8, self.latent_dim)",
            "",
            "+        self.example_input_array = torch.zeros(2, hparams.latent_dim)",
            "+",
            "def forward(self, z):",
            "return self.generator(z)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3293,
        "label": "no",
        "change": [
            "class GaussianNoise(Exploration):",
            "action = action_dist.deterministic_sample()",
            "",
            "# Logp=always zero.",
            "-        logp = torch.zeros(shape=(action.size()[0], ), dtype=torch.float32)",
            "+        logp = torch.zeros(",
            "+            (action.size()[0], ), dtype=torch.float32, device=self.device)",
            "",
            "return action, logp"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3295,
        "label": "no",
        "change": [
            "class StableDiffusionInpaintPipelineIntegrationTests(unittest.TestCase):",
            "",
            "prompt = \"Face of a yellow cat, high resolution, sitting on a park bench\"",
            "",
            "-        generator = torch.Generator(device=torch_device).manual_seed(0)",
            "+        generator = torch.manual_seed(0)",
            "_ = pipe(",
            "prompt=prompt,",
            "image=init_image,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3296,
        "label": "no",
        "change": [
            "class WindowAttention(nn.Module):",
            "B_, N, C = x.shape",
            "qkv_bias = None",
            "if self.q_bias is not None:",
            "-            qkv_bias = torch.cat((self.q_bias, torch.zeros_like(self.v_bias, requires_grad=False), self.v_bias))",
            "+            qkv_bias = torch.cat((self.q_bias, self.k_bias, self.v_bias))",
            "qkv = F.linear(input=x, weight=self.qkv.weight, bias=qkv_bias)",
            "qkv = qkv.reshape(B_, N, 3, self.num_heads, -1).permute(2, 0, 3, 1, 4)",
            "q, k, v = qkv[0], qkv[1], qkv[2]  # make torchscript happy (cannot use tensor as tuple)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3297,
        "label": "no",
        "change": [
            "D_prior = tf.nn.sigmoid(D(X, z))",
            "X_samples, _ = P(z)",
            "",
            "disc = tf.reduce_mean(-D_sample)",
            "-loglike = -tf.reduce_mean(",
            "-    tf.nn.sigmoid_cross_entropy_with_logits(logits=X_logits, labels=X)",
            "+nll = tf.reduce_sum(",
            "+    tf.nn.sigmoid_cross_entropy_with_logits(logits=X_logits, labels=X),",
            "+    axis=1",
            ")",
            "+loglike = -tf.reduce_mean(nll)",
            "",
            "elbo = disc + loglike",
            "D_loss = tf.reduce_mean(log(D_q) + log(1. - D_prior))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3301,
        "label": "no",
        "change": [
            "class ELMoTokenCharactersIndexer(TokenIndexer):",
            "def padding_token():",
            "return [0] * ELMoCharacterMapper.max_word_length",
            "",
            "-        tensor_dict[\"tokens\"] = torch.LongTensor(",
            "+        tensor_dict[\"elmo_tokens\"] = torch.LongTensor(",
            "pad_sequence_to_length(",
            "-                tokens[\"tokens\"], padding_lengths[\"tokens\"], default_value=padding_token",
            "+                tokens[\"elmo_tokens\"], padding_lengths[\"elmo_tokens\"], default_value=padding_token",
            ")",
            ")",
            "return tensor_dict"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3302,
        "label": "no",
        "change": [
            "class SquadModel(TFModel):",
            "self.opt = tf.train.AdadeltaOptimizer(learning_rate=self.lr_ph, epsilon=1e-6)",
            "grads = self.opt.compute_gradients(self.loss)",
            "gradients, variables = zip(*grads)",
            "-",
            "-            capped_grads, _ = tf.clip_by_global_norm(gradients, self.grad_clip)",
            "+            capped_grads = [tf.clip_by_norm(g, self.grad_clip) for g in gradients]",
            "self.train_op = self.opt.apply_gradients(zip(capped_grads, variables), global_step=self.global_step)",
            "",
            "def _build_feed_dict(self, c_tokens, c_chars, q_tokens, q_chars, y1=None, y2=None):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3306,
        "label": "no",
        "change": [
            "class SolverWrapper(object):",
            "while iter < max_iters + 1:",
            "# Learning rate",
            "if iter == cfg.TRAIN.STEPSIZE + 1:",
            "-        sess.run(tf.assign(lr, cfg.TRAIN.LEARNING_RATE * cfg.TRAIN.GAMMA))",
            "+        # Add snapshot here before reducing the learning rate",
            "self.snapshot(sess, iter)",
            "+        sess.run(tf.assign(lr, cfg.TRAIN.LEARNING_RATE * cfg.TRAIN.GAMMA))",
            "",
            "timer.tic()",
            "# Get training data, one batch at a time"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3307,
        "label": "no",
        "change": [
            "class ConvolutionBlock(nn.Module):",
            ")",
            "self.norm = nn.BatchNorm1d(channels)",
            "self.pointwise_cov2 = nn.Conv1d(",
            "-            channels,",
            "-            channels,",
            "-            kernel_size=1,",
            "-            stride=1,",
            "-            padding=0,",
            "-            bias=bias,",
            "+            channels, channels, kernel_size=1, stride=1, padding=0, bias=bias,",
            ")",
            "self.act = activation"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3309,
        "label": "yes",
        "change": [
            "class PermuteTransform(Transform):",
            "vector of zeros works.",
            "\"\"\"",
            "",
            "-        return torch.zeros_like(x)",
            "+        return torch.zeros(x.size()[:-1])"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3310,
        "label": "no",
        "change": [
            "class PrimitiveStorage:",
            "assert (",
            "n_party == 2",
            "), f\"The FSS protocol only works for 2 workers, {n_party} were provided.\"",
            "-            alpha, s_00, s_01, *CW = fss_class.keygen(n_values=n_instances)",
            "+            alpha, s_00, s_01, *CW = sy.frameworks.torch.mpc.fss.keygen(n_values=n_instances, op=op)",
            "# simulate sharing TODO clean this",
            "mask = np.random.randint(0, 2 ** n, alpha.shape, dtype=alpha.dtype)",
            "return [((alpha - mask) % 2 ** n, s_00, *CW), (mask, s_01, *CW)]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3313,
        "label": "yes",
        "change": [
            "def select_device(device='', batch_size=0, newline=True):",
            "for i, d in enumerate(devices):",
            "p = torch.cuda.get_device_properties(i)",
            "s += f\"{'' if i == 0 else space}CUDA:{d} ({p.name}, {p.total_memory / (1 << 20):.0f}MiB)\\n\"  # bytes to MB",
            "+    elif mps:",
            "+        s += 'MPS\\n'",
            "else:",
            "s += 'CPU\\n'",
            "",
            "if not newline:",
            "s = s.rstrip()",
            "LOGGER.info(s.encode().decode('ascii', 'ignore') if platform.system() == 'Windows' else s)  # emoji-safe",
            "-    return torch.device('cuda:0' if cuda else 'cpu')",
            "+    return torch.device('cuda:0' if cuda else 'mps' if mps else 'cpu')",
            "",
            "",
            "def time_sync():"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3315,
        "label": "yes",
        "change": [
            "def _get_cached_vs(name):",
            "@contextmanager",
            "def _enter_vs_reuse_ns(name):",
            "vs = _get_cached_vs(name)",
            "+    # XXX Not good to enter the cached vs directly, because this will clean-up custom getter",
            "+    # with tf.variable_scope(name, reuse=tf.AUTO_REUSE):    # available in 1.4 only",
            "with tf.variable_scope(vs):",
            "with tf.name_scope(vs.original_name_scope):",
            "yield vs"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3317,
        "label": "yes",
        "change": [
            "def iou(",
            "",
            "Example:",
            "",
            "-        >>> target = torch.randint(0, 1, (10, 25, 25))",
            "+        >>> target = torch.randint(0, 2, (10, 25, 25))",
            ">>> pred = torch.tensor(target)",
            ">>> pred[2:5, 7:13, 9:15] = 1 - pred[2:5, 7:13, 9:15]",
            ">>> iou(pred, target)",
            "-        tensor(0.4914)",
            "+        tensor(0.9660)",
            "",
            "\"\"\"",
            "num_classes = get_num_classes(pred=pred, target=target, num_classes=num_classes)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 3321,
        "label": "no",
        "change": [
            "def get_input_nodes(",
            ") -> Tuple[Optional[str], Sequence]:",
            "def to_index(tensor):",
            "if isinstance(tensor, Tensor) and tensor.dtype == torch.bool:",
            "-            return torch.nonzero(as_tuple=False).view(-1)",
            "-        else:",
            "-            return tensor",
            "+            return tensor.nonzero(as_tuple=False).view(-1)",
            "+        return tensor",
            "",
            "if isinstance(data, Data):",
            "if input_nodes is None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3323,
        "label": "no",
        "change": [
            "class Distiller:",
            "# https://github.com/peterliht/knowledge-distillation-pytorch/blob/master/model/net.py#L100",
            "# https://github.com/peterliht/knowledge-distillation-pytorch/issues/2",
            "if self.params.restrict_ce_to_mask:",
            "-            mask = (lm_labels > -1).unsqueeze(-1).expand_as(s_logits)  # (bs, seq_lenth, voc_size)",
            "+            mask = (lm_labels > -1).unsqueeze(-1).expand_as(s_logits)  # (bs, seq_length, voc_size)",
            "else:",
            "-            mask = attention_mask.unsqueeze(-1).expand_as(s_logits)  # (bs, seq_lenth, voc_size)",
            "+            mask = attention_mask.unsqueeze(-1).expand_as(s_logits)  # (bs, seq_length, voc_size)",
            "s_logits_slct = torch.masked_select(s_logits, mask)  # (bs * seq_length * voc_size) modulo the 1s in mask",
            "s_logits_slct = s_logits_slct.view(-1, s_logits.size(-1))  # (bs * seq_length, voc_size) modulo the 1s in mask",
            "t_logits_slct = torch.masked_select(t_logits, mask)  # (bs * seq_length * voc_size) modulo the 1s in mask"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3324,
        "label": "yes",
        "change": [
            "class E2E(STInterface, torch.nn.Module):",
            "isinstance(m, MultiHeadedAttention) and m.attn is not None",
            "):  # skip MHA for submodules",
            "ret[name] = m.attn.cpu().numpy()",
            "+        self.train()",
            "return ret"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "state handling error",
        "Action": "addition",
        "Element": "api call"
    },
    {
        "number": 3325,
        "label": "no",
        "change": [
            "def test_elbo_zip(gate, rate):",
            "dist1 = dist.Delta(torch.tensor(0.))",
            "dist0 = dist.Poisson(rate)",
            "with pyro.plate(\"data\", len(data)):",
            "-            mask = pyro.sample(\"mask\", dist.Bernoulli(gate), infer={\"enumerate\": \"parallel\"}).byte()",
            "+            mask = pyro.sample(\"mask\", dist.Bernoulli(gate), infer={\"enumerate\": \"parallel\"}).bool()",
            "pyro.sample(\"obs\", dist.MaskedMixture(mask, dist0, dist1), obs=data)",
            "",
            "def guide(data):",
            "pass",
            "",
            "-    gate = pyro.param(\"gate\", torch.tensor(gate), constraint=constraints.unit_interval)",
            "-    rate = pyro.param(\"rate\", torch.tensor(rate), constraint=constraints.positive)",
            "+    pyro.param(\"gate\", torch.tensor(gate), constraint=constraints.unit_interval)",
            "+    pyro.param(\"rate\", torch.tensor(rate), constraint=constraints.positive)",
            "",
            "data = torch.tensor([0., 1., 2.])",
            "elbo = TraceEnum_ELBO(max_plate_nesting=1, strict_enumeration_warning=False)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3327,
        "label": "no",
        "change": [
            "class Conv1dLinear(torch.nn.Module):",
            "super(Conv1dLinear, self).__init__()",
            "self.w_1 = torch.nn.Conv1d(in_chans, hidden_chans, kernel_size,",
            "stride=1, padding=(kernel_size - 1) // 2)",
            "-        self.w_2 = nn.Linear(hidden_chans, in_chans)",
            "+        self.w_2 = torch.nn.Linear(hidden_chans, in_chans)",
            "self.dropout = torch.nn.Dropout(dropout_rate)",
            "",
            "def forward(self, x):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3329,
        "label": "no",
        "change": [
            "class MsrTextCompression(datasets.GeneratorBasedBuilder):",
            "data_dir = os.path.abspath(os.path.expanduser(dl_manager.manual_dir))",
            "if not os.path.exists(data_dir):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('msr_text_compression', data_dir=...)` per the manual download instructions: {}\".format(",
            "-                    data_dir, self.manual_download_instructions",
            "-                )",
            "+                f\"{data_dir} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('msr_text_compression', data_dir=...)` per the manual download instructions: {self.manual_download_instructions}\"",
            ")",
            "return [",
            "datasets.SplitGenerator("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3330,
        "label": "no",
        "change": [
            "def linear_transform(",
            "new_order: List[int] = perm.tolist()",
            "inv_order: List[int] = perm_inv.tolist()",
            "",
            "-    feature_sizes = torch.tensor(inp_size[0:dim] + inp_size[dim + 1 : :])",
            "+    feature_sizes = torch.tensor(inp_size[0:dim] + inp_size[dim + 1::])",
            "num_features: int = int(torch.prod(feature_sizes).item())",
            "",
            "inp_permute = inp.permute(new_order)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3332,
        "label": "no",
        "change": [
            "def vecdot(",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "dtype = ivy.as_native_dtype(ivy.promote_types(x1.dtype, x2.dtype))",
            "-    x1, x2 = x1.to(dtype=torch.float32), x2.to(dtype=torch.float32)",
            "+    if dtype != \"float64\":",
            "+        x1, x2 = x1.to(dtype=torch.float32), x2.to(dtype=torch.float32)",
            "return torch.tensordot(x1, x2, dims=([axis], [axis]), out=out).to(dtype=dtype)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3334,
        "label": "no",
        "change": [
            "class NLayerDiscriminator(nn.Module):",
            "sequence += [[nn.Conv2d(nf, 1, kernel_size=kw, stride=1, padding=padw)]]",
            "",
            "if use_sigmoid:",
            "-            sequence += [nn.Sigmoid()]",
            "+            sequence += [[nn.Sigmoid()]]",
            "",
            "if getIntermFeat:",
            "for n in range(len(sequence)):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3338,
        "label": "no",
        "change": [
            "def create(",
            "yield res",
            "finally:",
            "res.info.freeze()",
            "+        res.flush()",
            "res.save(_model_store)",
            "",
            "track("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3341,
        "label": "no",
        "change": [
            "class TFPolicy(Policy):",
            "",
            "# build output signatures",
            "output_signature = self._extra_output_signature_def()",
            "-        for i, a in enumerate(tree.flatten(self._sampled_action)):",
            "+        for i, a in enumerate(tf.nest.flatten(self._sampled_action)):",
            "output_signature[\"actions_{}\".format(i)] = \\",
            "tf.saved_model.utils.build_tensor_info(a)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3342,
        "label": "no",
        "change": [
            "class TestRandomPerspective:",
            "assert len(out_perspective) == 2",
            "assert out_perspective[0].shape == x_data.shape",
            "assert out_perspective[1].shape == (1, 3, 3)",
            "-        assert_allclose(out_perspective[0], expected_output, atol=1e-4, rtol=1e-4)",
            "-        assert_allclose(out_perspective[1], expected_transform, atol=1e-4, rtol=1e-4)",
            "+        assert_close(out_perspective[0], expected_output, atol=1e-4, rtol=1e-4)",
            "+        assert_close(out_perspective[1], expected_transform, atol=1e-4, rtol=1e-4)",
            "assert aug.inverse(out_perspective).shape == x_data.shape",
            "",
            "def test_gradcheck(self, device):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3344,
        "label": "no",
        "change": [
            "class Categorical(Distribution):",
            "maxval=(1.0 - util.epsilon)",
            ")",
            "gumbel_distribution = -tf.log(x=-tf.log(x=uniform_distribution))",
            "-        sampled = tf.argmax(input=(logits + gumbel_distribution), axis=-1)",
            "+        sampled = tf.argmax(input=(logits + gumbel_distribution), axis=-1, output_type=util.tf_dtype('int'))",
            "",
            "return tf.where(condition=deterministic, x=definite, y=sampled)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3345,
        "label": "no",
        "change": [
            "class TransformerDecoder(FairseqIncrementalDecoder):",
            "if k in state_dict:",
            "state_dict['decoder.layers.{}.{}.{}'.format(i, new, m)] = state_dict[k]",
            "del state_dict[k]",
            "-        if state_dict.get('decoder.version', torch.Tensor([1]))[0] < 2:",
            "+        if utils.item(state_dict.get('decoder.version', torch.Tensor([1]))[0]) < 2:",
            "# earlier checkpoints did not normalize after the stack of layers",
            "self.layer_norm = None",
            "self.normalize = False"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3349,
        "label": "no",
        "change": [
            "class BaseDatasetTest(TestCase):",
            "self.assertIn(\"tmp\", dset_test1.cache_files[0][\"filename\"])",
            "self.assertIn(\"tmp\", dset_test2.cache_files[0][\"filename\"])",
            "finally:",
            "-                datasets.set_caching_enabled(True)",
            "+                datasets.enable_caching()",
            "",
            "@require_torch",
            "def test_map_torch(self, in_memory):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3350,
        "label": "no",
        "change": [
            "class HillClimbingSearcher(Searcher):",
            "return self.load_best_model()",
            "",
            "",
            "-class BayesianSearcher(HillClimbingSearcher):",
            "+class BayesianSearcher(Searcher):",
            "",
            "def __init__(self, n_classes, input_shape, path, verbose):",
            "super().__init__(n_classes, input_shape, path, verbose)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3354,
        "label": "no",
        "change": [
            "def to_float(c):",
            "def complex_norm(c: Union[torch.Tensor, ComplexTensor]) -> torch.Tensor:",
            "if not is_complex(c):",
            "raise TypeError(\"Input is not a complex tensor.\")",
            "-    return torch.sqrt((c.real ** 2 + c.imag ** 2).sum(dim=-1, keepdim=True) + EPS)",
            "+    return torch.sqrt((c.real**2 + c.imag**2).sum(dim=-1, keepdim=True) + EPS)",
            "",
            "",
            "def einsum(equation, *operands):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3355,
        "label": "no",
        "change": [
            "class CausalSelfAttention(nn.Module):",
            "# [ batch_size x n_heads x sequence_length x sequence_length ]",
            "attn_weights = (torch.matmul(query, key.transpose(-2, -1))) * (1.0 / math.sqrt(key.size(-1)))",
            "attn_weights = attn_weights.masked_fill(",
            "-            self.mask[:, :, :sequence_length, :sequence_length] == 0, float(\"-inf\")",
            "+            self.mask[:, :, :sequence_length, :sequence_length] == 0, torch.finfo(attn_weights.dtype).min",
            ")",
            "attn_weights = F.softmax(attn_weights, dim=-1)",
            "self._attn_map = attn_weights.clone()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3356,
        "label": "no",
        "change": [
            "class KerasModel(Trainable, Inferable):",
            "for i in range(len(metrics_names)):",
            "metrics_func = getattr(keras.metrics, metrics_names[i], None)",
            "if callable(metrics_func):",
            "-                metrics_funcs.append(keras.metrics.metrics_func)",
            "+                metrics_funcs.append(metrics_func)",
            "else:",
            "raise AttributeError(\"Metric %s is not defined\" % metrics_names[i])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3357,
        "label": "yes",
        "change": [
            "class TestHausdorffLoss:",
            "assert_close(actual, expected)",
            "",
            "@pytest.mark.parametrize(\"hd,shape\", [",
            "-        [kornia.losses.HausdorffERLoss, (10, 10)],",
            "-        [kornia.losses.HausdorffERLoss3D, (10, 10, 10)],",
            "+        [kornia.losses.HausdorffERLoss, (5, 5)],",
            "+        [kornia.losses.HausdorffERLoss3D, (5, 5, 5)],",
            "])",
            "-    @pytest.mark.skip(reason='It passed, but will take too much time to run.')",
            "def test_gradcheck(self, hd, shape, device):",
            "num_classes = 3",
            "logits = torch.rand(2, num_classes, *shape, device=device)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 3358,
        "label": "no",
        "change": [
            "class ModelMixin(torch.nn.Module):",
            ")",
            "",
            "if torch_dtype is not None and not isinstance(torch_dtype, torch.dtype):",
            "-            raise ValueError(f\"{torch_dtype} needs to be of type `torch.dtype`, e.g. `torch.float16`, but is {type(torch_dtype)}.\")",
            "+            raise ValueError(",
            "+                f\"{torch_dtype} needs to be of type `torch.dtype`, e.g. `torch.float16`, but is {type(torch_dtype)}.\"",
            "+            )",
            "elif torch_dtype is not None:",
            "model = model.to(torch_dtype)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3359,
        "label": "no",
        "change": [
            "class RandomModel(Model):",
            "actions[name] = (tf.random_uniform(shape=shape) < 0.5)",
            "",
            "elif action['type'] == 'int':",
            "-                action = tf.floor(x=(tf.random_uniform(shape=shape) * action['num_actions']))",
            "-                actions[name] = tf.cast(x=action, dtype=util.tf_dtype(action['type']))",
            "+                sampled_action = tf.floor(x=(tf.random_uniform(shape=shape) * action['num_actions']))",
            "+                actions[name] = tf.cast(x=sampled_action, dtype=util.tf_dtype(action['type']))",
            "",
            "elif action['type'] == 'float':",
            "if 'min_value' in action:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3360,
        "label": "no",
        "change": [
            "class Tensor:",
            "self.data = self.abs()",
            "return self.data",
            "",
            "-    def contiguous(self, memory_format=torch.contiguous_format):",
            "+    def contiguous(self, memory_format=None):",
            "return self.data",
            "",
            "def new_ones(self, size, *, dtype=None, device=None, requires_grad=False):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3362,
        "label": "yes",
        "change": [
            "class TargetIndegree(object):",
            "",
            "if pseudo is not None and self.cat:",
            "pseudo = pseudo.view(-1, 1) if pseudo.dim() == 1 else pseudo",
            "-            data.weight = torch.cat([pseudo, deg.type_as(pseudo)], dim=-1)",
            "+            data.edge_attr = torch.cat([pseudo, deg.type_as(pseudo)], dim=-1)",
            "else:",
            "-            data.weight = deg",
            "+            data.edge_attr = deg",
            "",
            "return data"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3363,
        "label": "no",
        "change": [
            "class TFDebertaV2ConvLayer(tf.keras.layers.Layer):",
            "else:",
            "if len(shape_list(input_mask)) != len(shape_list(layer_norm_input)):",
            "if len(shape_list(input_mask)) == 4:",
            "-                    mask = tf.squeeze(tf.squeeze(input_mask, axis=1), axis=1)",
            "-                mask = tf.cast(tf.expand_dims(input_mask, axis=2), tf.float32)",
            "+                    input_mask = tf.squeeze(tf.squeeze(input_mask, axis=1), axis=1)",
            "+                input_mask = tf.cast(tf.expand_dims(input_mask, axis=2), tf.float32)",
            "",
            "-            output_states = output * mask",
            "+            output_states = output * input_mask",
            "",
            "return output_states"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3364,
        "label": "no",
        "change": [
            "def get_test_devices() -> Dict[str, torch.device]:",
            "",
            "devices[\"tpu\"] = xm.xla_device()",
            "if hasattr(torch.backends, 'mps'):",
            "-        if torch.backends.mps.is_available():  # type: ignore",
            "+        if torch.backends.mps.is_available():",
            "devices[\"mps\"] = torch.device(\"mps\")",
            "return devices"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3365,
        "label": "no",
        "change": [
            "class GraphParser(Model):",
            "\"\"\"",
            "# Parameters",
            "",
            "-        tokens : Dict[str, torch.LongTensor], required",
            "+        tokens : TextFieldTensors, required",
            "The output of ``TextField.as_array()``.",
            "pos_tags : torch.LongTensor, optional (default = None)",
            "The output of a ``SequenceLabelField`` containing POS tags."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3368,
        "label": "no",
        "change": [
            "def confusion_matrix(",
            "confusion_list = []",
            "for iter_id in range(batch_size):",
            "pb: torch.Tensor = pre_bincount_vec[iter_id]",
            "-        bin_count: torch.Tensor = torch.bincount(pb, minlength=num_classes ** 2)",
            "+        bin_count: torch.Tensor = torch.bincount(pb, minlength=num_classes**2)",
            "confusion_list.append(bin_count)",
            "",
            "confusion_vec: torch.Tensor = torch.stack(confusion_list)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3370,
        "label": "no",
        "change": [
            "def train(args):",
            "# Make a specified GPU current",
            "chainer.cuda.get_device_from_id(gpu_id).use()",
            "model.to_gpu()  # Copy the model to the GPU",
            "-        logging.info('single gpu calculatetion.')",
            "+        logging.info('single gpu calculation.')",
            "elif ngpu > 1:",
            "gpu_id = 0",
            "args.batch_size = math.ceil(args.batch_size / ngpu)",
            "-        # Make a specified GPU current",
            "-        # chainer.cuda.get_device_from_id(gpu_id).use()",
            "devices = {'main': gpu_id}",
            "for gid in six.moves.xrange(1, ngpu):",
            "devices['sub_%d' % gid] = gid",
            "-        logging.info('multi gpu calculatetion (#gpu = %d).' % ngpu)",
            "+        logging.info('multi gpu calculation (#gpus = %d).' % ngpu)",
            "else:",
            "gpu_id = -1",
            "logging.info('cpu calculation')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3372,
        "label": "yes",
        "change": [
            "class LukeModelIntegrationTests(unittest.TestCase):",
            "expected_shape = torch.Size((1, 1, 1024))",
            "self.assertEqual(outputs.entity_last_hidden_state.shape, expected_shape)",
            "",
            "-        expected_slice = torch.tensor([[0.0466, -0.0106, -0.0179]])",
            "+        expected_slice = torch.tensor([[0.0466, -0.0106, -0.0179]]).to(torch_device)",
            "self.assertTrue(torch.allclose(outputs.entity_last_hidden_state[0, :3, :3], expected_slice, atol=1e-4))"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    }
]
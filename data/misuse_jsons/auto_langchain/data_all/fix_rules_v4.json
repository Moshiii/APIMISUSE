{"number": 5, "change": "class AlbertEmbeddings(nn.Module):\n# position_ids (1, len position emb) is contiguous in memory and exported when serialized\nself.register_buffer(\"position_ids\", torch.arange(config.max_position_embeddings).expand((1, -1)))\nself.position_embedding_type = getattr(config, \"position_embedding_type\", \"absolute\")\n-        if version.parse(torch.__version__) > version.parse(\"1.6.0\"):\n+        if is_torch_greater_than_1_6:\nself.register_buffer(\n\"token_type_ids\",\ntorch.zeros(self.position_ids.size(), dtype=torch.long),\n", "fix_pattern": "if version check for torch.__version__ is detected, replace it with a boolean variable is_torch_greater_than_1_6."}
{"number": 7, "change": "def test_quantile():\n\n\ndef test_pi():\n-    x = torch.empty(1000).log_normal_(0, 1)\n+    x = torch.randn(1000).exp()\nassert_equal(pi(x, prob=0.8), quantile(x, probs=[0.1, 0.9]))\n", "fix_pattern": "If a tensor is initialized using `torch.empty` followed by a log-normal distribution, it can be replaced with `torch.randn` followed by an exponential function."}
{"number": 8, "change": "class TPUAccelerator(Accelerator):\nReturn:\nA tensor of shape (world_size, batch, ...)\n\"\"\"\n-        return xm.all_gather(tensor, group=group, sync_grads=sync_grads)\n+        # todo: Add support for backward with all_gather\n+        if torch.distributed.is_initialized():\n+            return xm.all_gather(tensor, group=group, sync_grads=sync_grads)\n+        return tensor\n", "fix_pattern": "if a call to xm.all_gather() is detected, add a check to see if torch.distributed.is_initialized() and return xm.all_gather() if true, otherwise return the tensor as is"}
{"number": 12, "change": "def get_rotation_matrix2d(\n\n# create output tensor\nbatch_size: int = center.shape[0]\n-    one = torch.tensor(1.).to(center.device)\n+    one = torch.tensor(1., device=center.device, dtype=center.dtype)\nM: torch.Tensor = torch.zeros(\nbatch_size, 2, 3, device=center.device, dtype=center.dtype)\nM[..., 0:2, 0:2] = scaled_rotation\n", "fix_pattern": "if a tensor initialization with a device is detected, add device=<device> to the initialization"}
{"number": 15, "change": "class Trainer(TrainerBase):\nbreak\nsys.stdout.flush()\n\n-        model.load_state_dict(torch.load(best_model_path))\n+        if rank == 0:\n+            model.load_state_dict(torch.load(best_model_path))\nreturn model, best_metric\n\ndef _run_epoch(\n", "fix_pattern": "if loading the state dict of a model is performed, add a condition to load the state dict only when the rank is 0"}
{"number": 23, "change": "class TacotronTrainTest(unittest.TestCase):\noptimizer = optim.Adam(model.parameters(), lr=c.lr)\nfor i in range(5):\nmel_out, linear_out, align, stop_tokens = model.forward(\n-                input, input_lengths, mel_spec)\n+                input, input_lengths, mel_spec, speaker_ids)\noptimizer.zero_grad()\nloss = criterion(mel_out, mel_spec, mel_lengths)\nstop_loss = criterion_st(stop_tokens, stop_targets)\n", "fix_pattern": "if an additional argument (in this case, speaker_ids) is added to the API method call, include it in the code change."}
{"number": 24, "change": "def evaluate(args, model, tokenizer, prefix=\"\", test=False):\neval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n\n# multi-gpu evaluate\n-        if args.n_gpu > 1:\n+        if args.n_gpu > 1 and not isinstance(model, torch.nn.DataParallel):\nmodel = torch.nn.DataParallel(model)\n\n# Eval!\n", "fix_pattern": "if checking the number of GPUs and the model is not an instance of torch.nn.DataParallel,"}
{"number": 25, "change": "class TestMotionBlur:\n) -> torch.Tensor:\nreturn kornia.filters.motion_blur(input, ksize, angle, direction)\n\n-        img = torch.rand(2, 3, 4, 5)\n+        img = torch.rand(2, 3, 4, 5).to(device)\nksize = 5\nangle = 65.\ndirection = .1\n", "fix_pattern": "If a tensor object is created without specifying the device, add .to(device) to the end of the API call."}
{"number": 30, "change": "class _Seq2VecWrapper:\ndef from_params(self, params: Params) -> PytorchSeq2VecWrapper:\nif not params.pop('batch_first', True):\nraise ConfigurationError(\"Our encoder semantics assumes batch is always first!\")\n-        params['batch_first'] = True\n+        if self._module_class in self.PYTORCH_MODELS:\n+            params['batch_first'] = True\nmodule = self._module_class(**params.as_dict())\nreturn PytorchSeq2VecWrapper(module)\n", "fix_pattern": "if the parameter 'batch_first' is detected without conditional check, add conditional check to set 'batch_first' to True in specific cases"}
{"number": 31, "change": "class StableDiffusionProcessingTxt2Img(StableDiffusionProcessing):\nreturn samples\n\nx = create_random_tensors([opt_C, self.firstphase_height // opt_f, self.firstphase_width // opt_f], seeds=seeds, subseeds=subseeds, subseed_strength=self.subseed_strength, seed_resize_from_h=self.seed_resize_from_h, seed_resize_from_w=self.seed_resize_from_w, p=self)\n-        samples = self.sampler.sample(self, x, conditioning, unconditional_conditioning, image_conditioning=self.create_dummy_mask(x))\n+        samples = self.sampler.sample(self, x, conditioning, unconditional_conditioning, image_conditioning=self.create_dummy_mask(x, first_phase=True))\n\nsamples = samples[:, :, self.truncate_y//2:samples.shape[2]-self.truncate_y//2, self.truncate_x//2:samples.shape[3]-self.truncate_x//2]\n", "fix_pattern": "if an API method is called with additional arguments, add the missing argument to the API call"}
{"number": 40, "change": "def makenp(x, modality=None):\n\ndef pytorch_np(x, modality):\nimport torch\n-    if isinstance(x, torch.autograd.variable.Variable):\n+    if isinstance(x, torch.autograd.Variable):\nx = x.data\nx = x.cpu().numpy()\nif modality == 'IMG':\n", "fix_pattern": "if isinstance(x, torch.autograd.variable.Variable) is detected, replace torch.autograd.variable.Variable with torch.Tensor"}
{"number": 43, "change": "class TrainingTypePlugin(ABC):\nself.lr_schedulers = schedulers\n\ndef _move_optimizer_state(self, device: Optional[torch.device] = None) -> None:\n-        \"\"\"Moves the state of the optimizers to the GPU if needed.\"\"\"\n-        device = device or self.root_device\n+        \"\"\"Moves the state of the optimizers to the appropriate device if needed.\"\"\"\nfor opt in self.optimizers:\nfor p, v in opt.state.items():\n-                opt.state[p] = apply_to_collection(v, torch.Tensor, move_data_to_device, device)\n+                # `self.root_device` would raise error if called outside the spawn process\n+                # while training on 8 and more cores.\n+                opt.state[p] = apply_to_collection(v, torch.Tensor, move_data_to_device, device or self.root_device)\n\ndef optimizer_state(self, optimizer: Optimizer) -> Dict[str, Tensor]:\n\"\"\"Returns state of an optimizer.\n", "fix_pattern": "if an API call to move data to a device is detected, and a default device is used, add `or self.root_device` to the `device` argument"}
{"number": 50, "change": "class GraphConv(MessagePassing):\nself.lin.reset_parameters()\n\ndef forward(self, x, edge_index):\n+        if isinstance(x, Tensor):\n+            x = (x, x)\nreturn self.propagate(edge_index, x=(self.lin(x[0]), x[1]))\n", "fix_pattern": "if isinstance(x, Tensor): \n    x = (x, x)"}
{"number": 53, "change": "class Trainer:\n).to(self.args.device)\n\nelif is_sagemaker_dp_enabled():\n-            model = DDP(model, device_ids=[dist.get_local_rank()], broadcast_buffers=False)\n+            model = nn.parallel.DistributedDataParallel(\n+                model, device_ids=[int(os.getenv(\"SMDATAPARALLEL_LOCAL_RANK\"))]\n+            )\nelif self.args.local_rank != -1:\nkwargs = {}\nif self.args.ddp_find_unused_parameters is not None:\n", "fix_pattern": "if DDP is detected with device_ids=[dist.get_local_rank()], replace it with nn.parallel.DistributedDataParallel(model, device_ids=[int(os.getenv(\"SMDATAPARALLEL_LOCAL_RANK\"))])"}
{"number": 55, "change": "class RNN(torch.nn.Module):\nif not isinstance(ilens, torch.Tensor):\nilens = torch.tensor(ilens)\nxs_pack = pack_padded_sequence(xs_pad, ilens.cpu(), batch_first=True)\n-        self.nbrnn.flatten_parameters()\n+        if self.training:\n+            self.nbrnn.flatten_parameters()\nif prev_state is not None and self.nbrnn.bidirectional:\n# We assume that when previous state is passed,\n# it means that we're streaming the input\n", "fix_pattern": "if an API method is called \"flatten_parameters()\" and it is called outside of the \"if self.training\" condition, then move the API call inside the \"if self.training\" condition."}
{"number": 56, "change": "class TFXLNetModelTest(TFModelTesterMixin, unittest.TestCase):\n# Send to model\nloss = model(tuple_input[:-1])[0]\n\n-                self.assertEqual(loss.shape, [loss_size])\n+                self.assertEqual(loss.shape.as_list(), expected_loss_size)\n\n\n@require_tf\n", "fix_pattern": "if a shape comparison method like shape.as_list() is detected, replace it with shape"}
{"number": 58, "change": "def sigmoid_example(design):\ntorch.tensor([[-1.5, 0.5], [1.5, 0.]])\n),\n(\n-        known_covariance_linear_model(torch.tensor([1., -1.]), torch.tensor(10.), torch.tensor(1.)),\n+        known_covariance_linear_model(torch.tensor([1., -1.]), torch.tensor([10., 10.]), torch.tensor(1.)),\nnz_lm_2p_10_10_1,\ntorch.tensor([[-1., 0.5], [2.5, -2.]])\n),\n", "fix_pattern": "If the third argument in known_covariance_linear_model API call is a scalar, change it to a tensor with the same shape as the first argument."}
{"number": 59, "change": "class DetaModel(DetaPreTrainedModel):\nscale = 2 * math.pi\n\ndim_t = torch.arange(num_pos_feats, dtype=torch.float32, device=proposals.device)\n-        dim_t = temperature ** (2 * (dim_t // 2) / num_pos_feats)\n+        dim_t = temperature ** (2 * torch.div(dim_t, 2) / num_pos_feats)\n# batch_size, num_queries, 4\nproposals = proposals.sigmoid() * scale\n# batch_size, num_queries, 4, 128\n", "fix_pattern": "if using integer division for division by 2 is detected, replace it with torch.div()"}
{"number": 61, "change": "class LxmertAttention(nn.Module):\nattention_scores = attention_scores + attention_mask\n\n# Normalize the attention scores to probabilities.\n-        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n+        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n\n# This is actually dropping out entire tokens to attend to, which might\n# seem a bit unusual, but is taken from the original Transformer paper.\n", "fix_pattern": "if deprecated API nn.Softmax(dim=-1) detected, replace with nn.functional.softmax(attention_scores, dim=-1)"}
{"number": 68, "change": "class Gru(TransformationBase):\n\ndef tf_apply(self, x, sequence_length=None):\nx, state = tf.nn.dynamic_rnn(\n-            cell=self.cell, inputs=x, sequence_length=sequence_length, dtype=tf.float32,\n+            cell=self.cell, inputs=x, sequence_length=sequence_length, initial_state=None,\n+            dtype=util.tf_dtype(dtype='float'),\n# Weird TensorFlow behavior? (https://github.com/tensorflow/tensorflow/issues/15874)\nparallel_iterations=(self.input_spec['shape'][0] + 1)\n)\n", "fix_pattern": "if dtype parameter is detected, replace tf.float32 with util.tf_dtype(dtype='float') and remove initial_state=None"}
{"number": 71, "change": "class DeepSpeedSelfAttention(nn.Module):\ndata_type_fp = torch.half if config.fp16 else torch.float\nself.config.layer_id = DeepSpeedSelfAttention.num_layers\nDeepSpeedSelfAttention.num_layers = DeepSpeedSelfAttention.num_layers + 1\n-        device = torch.cuda.current_device() if config.bigscience_bloom else 'cpu'\n+        device = torch.cuda.current_device()  #if config.bigscience_bloom else 'cpu'\nqkv_size_per_partition = (self.config.hidden_size // self.config.mp_size) * 3\nself.attn_qkvw = nn.Parameter(torch.empty(self.config.hidden_size,\nqkv_size_per_partition,\n", "fix_pattern": "There is no specific pattern identified for the change in this code. It appears to be a code optimization or modification specific to the configuration option `bigscience_bloom`."}
{"number": 76, "change": "def main(args):\nbob_decision = Marginal(Search(bob))\n\n# Here Alice and Bob slightly prefer one location over the other a priori\n-    shared_preference = Variable(torch.Tensor([args.preference]))\n+    shared_preference = torch.tensor([args.preference])\n\nbob_depth = args.depth\nnum_samples = args.num_samples\n", "fix_pattern": "If a Variable tensor is detected, replace it with torch.tensor() to create a tensor."}
{"number": 81, "change": "class Planetoid(Dataset):\n# Create unweighted sparse adjacency matrix.\nweight = torch.ones(index.size(1))\nn = input.size(0)\n-        adj = torch.sparse.FloatTensor(index, weight, torch.Size([n, n]))\n+        adj = SparseTensor(index, weight, torch.Size([n, n]))\n\n# Bundle graph to data object.\n-        self.data = Data(input, adj, position=None, target=target)\n+        self.data = Data(input, adj, position=None, target=target.long())\n\ndef __getitem__(self, index):\ndata = self.data\n", "fix_pattern": "If a torch.sparse.FloatTensor is detected, replace it with SparseTensor from the torch_geometric library. Additionally, if the target tensor is of type float, change it to target.long()."}
{"number": 84, "change": "class Tacotron2(TTSInterface, torch.nn.Module):\n\ndef __init__(self, idim, odim, args):\nsuper(Tacotron2, self).__init__()\n+        torch.nn.Module.__init__(self)\n# store hyperparameters\nself.idim = idim\nself.odim = odim\n", "fix_pattern": "Add a call to the superclass constructor `torch.nn.Module.__init__(self)` to the `__init__` method of the class."}
{"number": 85, "change": "\"import sys\\n\",\n\"sys.path.append(f'{os.getcwd()}/SentEval')\\n\",\n\"\\n\",\n-        \"import tensorflow_hub as hub\\n\",\n\"import tensorflow as tf\\n\",\n+        \"\\n\",\n+        \"# Prevent TF from claiming all GPU memory so there is some left for pytorch.\\n\",\n+        \"gpus = tf.config.list_physical_devices('GPU')\\n\",\n+        \"if gpus:\\n\",\n+        \"  # Memory growth needs to be the same across GPUs.\\n\",\n+        \"  for gpu in gpus:\\n\",\n+        \"    tf.config.experimental.set_memory_growth(gpu, True)\\n\",\n+        \"\\n\",\n+        \"import tensorflow_hub as hub\\n\",\n\"import tensorflow_text\\n\",\n\"import senteval\\n\",\n\"import time\\n\",\n", "fix_pattern": "if TensorFlow import is detected, add the following code to prevent TensorFlow from claiming all GPU memory:\n\n```python\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n  # Memory growth needs to be the same across GPUs.\n  for gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)\n```"}
{"number": 86, "change": "class Encoder(torch.nn.Module):\nself.embed = Conv2dSubsampling(idim, attention_dim, dropout_rate)\nelif input_layer == \"embed\":\nself.embed = torch.nn.Sequential(\n-                torch.nn.Embedding(idim, attention_dim),\n+                torch.nn.Embedding(idim, attention_dim, padding_idx=padding_idx),\npos_enc_class(attention_dim, positional_dropout_rate)\n)\nelif isinstance(input_layer, torch.nn.Module):\n", "fix_pattern": "If a torch.nn.Embedding API call is detected without the padding_idx argument, add padding_idx=padding_idx to the API call."}
{"number": 88, "change": "def create_checkerboard(h, w, nw):\n\n\n# TODO: Isn't this function duplicated with eye_like?\n-def create_eye_batch(batch_size, eye_size):\n+def create_eye_batch(batch_size, eye_size, device=None, dtype=None):\n\"\"\"Creates a batch of identity matrices of shape Bx3x3\n\"\"\"\n-    return torch.eye(eye_size).view(\n+    return torch.eye(eye_size, device=device, dtype=dtype).view(\n1, eye_size, eye_size).expand(batch_size, -1, -1)\n", "fix_pattern": "if torch.eye( detected, add device=device, dtype=dtype) to the end of the API call."}
{"number": 91, "change": "class TransformerSeparator(AbsSeparator):\n\n# if complex spectrum,\nif isinstance(input, ComplexTensor) or (\n-            is_torch_1_8_plus and torch.is_complex(input)\n+            is_torch_1_9_plus and torch.is_complex(input)\n):\nfeature = abs(input)\nelse:\n", "fix_pattern": "If a torch version condition is detected (e.g., is_torch_1_8_plus), update the torch version number in the condition (e.g., is_torch_1_9_plus)"}
{"number": 97, "change": "def _get_ort_session_options() -> ort.SessionOptions:\nif not torch.cuda.is_available():\nsess_options.execution_mode = ort.ExecutionMode.ORT_PARALLEL\nsess_options.inter_op_num_threads = 1\n-        sess_options.intra_op_num_threads = max(torch.get_num_threads(), 1)\n+        sess_options.intra_op_num_threads = max(\n+            int(\n+                os.environ.get(\"NEBULLVM_THREADS_PER_MODEL\")\n+                or torch.get_num_threads()\n+            ),\n+            1,\n+        )\nreturn sess_options\n", "fix_pattern": "if setting intra_op_num_threads, use max() function to choose a value between the value obtained from os.environ.get(\"NEBULLVM_THREADS_PER_MODEL\") or torch.get_num_threads() and 1."}
{"number": 100, "change": "class TFFlaubertMainLayer(tf.keras.layers.Layer):\ntensor_normalized = self.layer_norm2[i](tensor)\ntensor = tensor + self.ffns[i](tensor_normalized)\n\n-            tensor = tensor * mask[..., tf.newaxis]\n+            tensor = tensor * tf.expand_dims(mask, axis=-1)\n\n# Add last hidden state\nif inputs[\"output_hidden_states\"]:\n", "fix_pattern": "if the code uses * operator to multiply a mask tensor with another tensor, and the mask tensor has an extra dimension added using tf.newaxis, replace it with tf.expand_dims(mask, axis=-1)"}
{"number": 101, "change": "def _replace_global_by_local(kwargs):\nif 'collections' in kwargs:\ncollections = kwargs['collections']\nif not collections:\n-        collections = set(tf.GraphKeys.GLOBAL_VARIABLES)\n+        collections = {tf.GraphKeys.GLOBAL_VARIABLES}\nelse:\ncollections = set(collections.copy())\ncollections.remove(tf.GraphKeys.GLOBAL_VARIABLES)\n", "fix_pattern": "If a collection is set to `set(tf.GraphKeys.GLOBAL_VARIABLES)`, replace it with `collections = {tf.GraphKeys.GLOBAL_VARIABLES}`."}
{"number": 103, "change": "class ReformerLayer(nn.Module):\n\"\"\"\n# randomize seeds\n# use cuda generator if available\n-        if len(torch.cuda.default_generators) > 0:\n+        if hasattr(torch.cuda, \"default_generators\") and len(torch.cuda.default_generators) > 0:\n# GPU\ndevice_idx = torch.cuda.current_device()\nself.feed_forward_seed = torch.cuda.default_generators[device_idx].seed()\n", "fix_pattern": "if accessing a property or attribute on an object that may not exist, use the hasattr() function to check if the object has the attribute before accessing it"}
{"number": 104, "change": "def get_projective_transform(center: torch.Tensor, angles: torch.Tensor) -> torc\n\n# create rotation matrix\nangle_axis_rad: torch.Tensor = K.deg2rad(angles)\n-    rmat: torch.Tensor = K.angle_axis_to_rotation_matrix(angle_axis_rad)  # Bx3x3\n+    rmat: torch.Tensor = K.angle_axis_to_rotation_matrix(angle_axis_rad) * scales.view(-1, 1, 1)  # Bx3x3\n\n# define matrix to move forth and back to origin\nfrom_origin_mat = torch.eye(4)[None].repeat(rmat.shape[0], 1, 1).type_as(center)  # Bx4x4\n", "fix_pattern": "if a multiplication of a tensor and a view(-1) tensor is detected, modify the API call to multiply the tensor with the view(-1, 1, 1) tensor"}
{"number": 105, "change": "class FQETorchModel:\nq_values, _ = self.q_model({\"obs\": obs}, [], None)\nif actions is not None:\nactions = torch.tensor(actions, device=self.device, dtype=int)\n-            q_values = torch.gather(q_values, -1, actions.unsqueeze(-1)).squeeze()\n+            q_values = torch.gather(q_values, -1, actions.unsqueeze(-1)).squeeze(-1)\nreturn q_values.detach()\n\ndef estimate_v(\n", "fix_pattern": "If the squeeze() method is called without specifying a dimension, add -1 as the argument to squeeze() method."}
{"number": 107, "change": "class ModelCatalog:\nmodel_name (str): Name to register the model under.\nmodel_class (type): Python class of the model.\n\"\"\"\n-        if issubclass(model_class, tf.keras.Model):\n-            deprecation_warning(old=\"register_custom_model\", error=False)\n+        if tf is not None:\n+            if issubclass(model_class, tf.keras.Model):\n+                deprecation_warning(old=\"register_custom_model\", error=False)\n_global_registry.register(RLLIB_MODEL, model_name, model_class)\n\n@staticmethod\n", "fix_pattern": "if an API call to a TensorFlow library is detected, add a condition to check if tf is not None before using it"}
{"number": 109, "change": "class DLA(nn.Module):\nif self.drop_rate > 0.:\nx = F.dropout(x, p=self.drop_rate, training=self.training)\nx = self.fc(x)\n-        if not self.global_pool.is_identity():\n-            x = x.flatten(1)  # conv classifier, flatten if pooling isn't pass-through (disabled)\n+        x = self.flatten(x)\nreturn x\n", "fix_pattern": "if a flatten operation is detected, replace it with self.flatten() method."}
{"number": 110, "change": "class OnlineLinearRegression(tf.Module if tf else object):\nx = tf.squeeze(x, axis=0)\ny = y[0]\nself.time += 1\n-        self.delta_f += y * x\n+        self.delta_f += tf.cast(y, tf.float32) * x\nself.delta_b += tf.tensordot(x, x, axes=0)\n# Can follow an update schedule if not doing sherman morison updates\nif self.time % self.update_schedule == 0:\n", "fix_pattern": "If a mathematical operation involves tensors of different types, cast the tensor to the desired type using the appropriate casting function."}
{"number": 112, "change": "class Trainer(\n\nresults = self.predict_loop.on_predict_epoch_end()\nself.predict_loop.on_predict_end()\n+\n+        # re-enable grads\n+        torch.set_grad_enabled(True)\n+\nreturn results\n\ndef run_sanity_check(self, ref_model):\n", "fix_pattern": "This code change does not involve fixing an API method problem."}
{"number": 113, "change": "def filter2d(\ninput = input.view(-1, tmp_kernel.size(0), input.size(-2), input.size(-1))\n\n# convolve the tensor with the kernel.\n-    output = F.conv2d(input, tmp_kernel, groups=tmp_kernel.size(0), padding=0, stride=1)\n+    # NOTE: type(...) to fix getting `torch.bfloat16` type.\n+    # TODO: @johnnv1, fix it through the Augmentation Base.\n+    output = F.conv2d(input, tmp_kernel, groups=tmp_kernel.size(0), padding=0, stride=1).type(input.dtype)\n\nif padding == 'same':\nout = output.view(b, c, h, w)\n", "fix_pattern": "If there is a need to fix the type of the output tensor, add .type(new_dtype) to the end of the API call."}
{"number": 114, "change": "def remainder(\nres_floored = torch.where(res >= 0, torch.floor(res), torch.ceil(res))\ndiff = res - res_floored\ndiff, x2 = ivy.promote_types_of_inputs(diff, x2)\n-        return torch.mul(diff, x2, out=out)\n+        return torch.mul(diff, x2, out=out).to(x1.dtype)\nreturn torch.remainder(x1, x2, out=out)\n", "fix_pattern": "If an API method call has an output tensor specified with the \"out\" parameter, add \".to(dtype)\" to the end of the method call."}
{"number": 115, "change": "class GoalOrientedBotNetwork(TFModel):\nname='features')\nself._action = tf.placeholder(tf.int32, [1, None],\nname='ground_truth_action')\n-        self._action_mask = tf.placeholder(tf.float32, [1, None, self.n_actions],\n+        self._action_mask = tf.placeholder(tf.float32, [None, None, self.n_actions],\nname='action_mask')\n\ndef _build_body(self):\n", "fix_pattern": "if the shape of the tensor is changed, modify the shape parameter accordingly in the API call"}
{"number": 116, "change": "class EpsilonGreedy(Exploration):\ntorch.multinomial(random_valid_action_logits, 1), axis=1)\n# Pick either random or greedy.\naction = torch.where(\n-                torch.empty((batch_size, )).uniform_() < epsilon,\n+                torch.empty(\n+                    (batch_size, )).uniform_().to(self.device) < epsilon,\nrandom_actions, exploit_action)\n\nreturn action, action_logp\n", "fix_pattern": "If a tensor is created using torch.empty() and a comparison operation is performed on it without specifying the device, add .to(device) to the end of the tensor creation."}
{"number": 118, "change": "class Delta(TorchDistribution):\n\ndef expand(self, batch_shape):\nvalidate_args = self.__dict__.get('_validate_args')\n+        batch_shape = torch.Size(batch_shape)\nv = self.v.expand(batch_shape + self.event_shape)\nlog_density = self.log_density.expand(batch_shape)\nreturn Delta(v, log_density, self.event_dim, validate_args=validate_args)\n", "fix_pattern": "If a torch.Size object is being created or modified, use the torch.Size() constructor to ensure proper initialization."}
{"number": 119, "change": "def main():\n\npruner = AGP_Pruner(model, configure_list)\nmodel = pruner.compress()\n-\n+    model = model.to(device)\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\nfor epoch in range(10):\npruner.update_epoch(epoch)\nprint('# Epoch {} #'.format(epoch))\ntrain(model, device, train_loader, optimizer)\ntest(model, device, test_loader)\n-    pruner.export_model('model.pth', 'mask.pth', 'model.onnx', [1, 1, 28, 28])\n+    pruner.export_model('model.pth', 'mask.pth', 'model.onnx', [1, 1, 28, 28], device)\n\n\nif __name__ == '__main__':\n", "fix_pattern": "If exporting a model and there is a device specified, move the device specification to the model initialization line and pass the device parameter to the export_model() method."}
{"number": 120, "change": "class TestBidirectionalLanguageModelTransformer(AllenNlpTestCase):\ninput_dim=32, hidden_dim=64, num_layers=2\n)\n\n-        mask = torch.ones(3, 6).int()\n-        mask[0, 3:] = 0\n-        mask[1, 5:] = 0\n+        mask = torch.ones(3, 6).bool()\n+        mask[0, 3:] = False\n+        mask[1, 5:] = False\n\nforward_mask, backward_mask = transformer_encoder.get_attention_masks(mask)\n", "fix_pattern": "If a mask tensor is detected with type int, replace it with type bool."}
{"number": 121, "change": "from ray.air.config import ScalingConfig\n\n\ndef mnist_dataset(batch_size: int) -> tf.data.Dataset:\n-    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n+    with FileLock(os.path.expanduser(\"~/.mnist_lock\")):\n+        (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n# The `x` arrays are in uint8 and have values in the [0, 255] range.\n# You need to convert them to float32 with values in the [0, 1] range.\nx_train = x_train / np.float32(255)\n", "fix_pattern": "if loading a dataset with tf.keras.datasets, add a FileLock context manager to ensure thread safety while accessing the dataset."}
{"number": 122, "change": "def rnn_model(X, y):\n# Given encoding of RNN, take encoding of last step (e.g hidden size of the\n# neural network of last step) and pass it as features for logistic\n# regression over output classes.\n-    return skflow.models.logistic_regression(encoding[-1], y)\n+    return skflow.models.logistic_regression(encoding, y)\n\nclassifier = skflow.TensorFlowEstimator(model_fn=rnn_model, n_classes=15,\nsteps=1000, optimizer='Adam', learning_rate=0.01, continue_training=True)\n", "fix_pattern": "if an encoding tensor is detected with an indexing (-1), remove the indexing"}
{"number": 126, "change": "def main_fun(argv, ctx):\ngrads = average_gradients(tower_grads)\n\n# Add a summary to track the learning rate.\n-      summaries.append(tf.scalar_summary('learning_rate', lr))\n+      summaries.append(tf.summary.scalar('learning_rate', lr))\n\n# Add histograms for gradients.\nfor grad, var in grads:\nif grad is not None:\nsummaries.append(\n-              tf.histogram_summary(var.op.name + '/gradients', grad))\n+              tf.summary.histogram(var.op.name + '/gradients', grad))\n\n# Apply the gradients to adjust the shared variables.\napply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n\n# Add histograms for trainable variables.\nfor var in tf.trainable_variables():\n-        summaries.append(tf.histogram_summary(var.op.name, var))\n+        summaries.append(tf.summary.histogram(var.op.name, var))\n\n# Track the moving averages of all trainable variables.\nvariable_averages = tf.train.ExponentialMovingAverage(\n", "fix_pattern": "if tf.scalar_summary is detected, replace with tf.summary.scalar\nif tf.histogram_summary is detected, replace with tf.summary.histogram"}
{"number": 127, "change": "class Trainer(TrainerBase):\n\n@timing.time(\"Trainer.test\")\ndef test(self, test_iter, model, metric_reporter: MetricReporter):\n+        if cuda.CUDA_ENABLED:\n+            model = model.cuda()\n+\nmodel.eval()\nwith torch.no_grad():\ntest_metric = self._run_epoch(\n", "fix_pattern": "if cuda.CUDA_ENABLED is detected, add the model.cuda() statement to move the model to the GPU."}
{"number": 128, "change": "class TrainingArguments:\n@torch_required\ndef _setup_devices(self) -> \"torch.device\":\nlogger.info(\"PyTorch: setting up devices\")\n-        if torch.distributed.is_initialized() and self.local_rank == -1:\n+        if torch.distributed.is_available() and torch.distributed.is_initialized() and self.local_rank == -1:\nlogger.warning(\n\"torch.distributed process group is initialized, but local_rank == -1. \"\n\"In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\"\n", "fix_pattern": "if torch.distributed.is_available() and torch.distributed.is_initialized() are detected, add torch.distributed.is_available() to the if condition."}
{"number": 131, "change": "with tf.Graph().as_default():\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"model\")\nif not os.path.exists(checkpoint_dir):\nos.makedirs(checkpoint_dir)\n-        saver = tf.train.Saver(tf.all_variables())\n+        saver = tf.train.Saver(tf.global_variables())\n\n# Write vocabulary\nvocab_processor.save(os.path.join(out_dir, \"vocab\"))\n\n# Initialize all variables\n-        sess.run(tf.initialize_all_variables())\n+        sess.run(tf.global_variables_initializer())\n\ndef train_step(x_batch, y_batch):\n\"\"\"\n", "fix_pattern": "if tf.all_variables() is detected, replace with tf.global_variables(). \nif tf.initialize_all_variables() is detected, replace with tf.global_variables_initializer()"}
{"number": 132, "change": "class CLIPTextTransformer(nn.Module):\nattentions=encoder_outputs.attentions,\n)\n\n-    def _build_causal_attention_mask(self, bsz, seq_len):\n+    def _build_causal_attention_mask(self, bsz, seq_len, dtype):\n# lazily create causal attention mask, with full attention between the vision tokens\n# pytorch uses additive attention mask; fill with -inf\n-        mask = torch.empty(bsz, seq_len, seq_len)\n-        mask.fill_(torch.tensor(float(\"-inf\")))\n+        mask = torch.empty(bsz, seq_len, seq_len, dtype=dtype)\n+        mask.fill_(torch.tensor(torch.finfo(dtype).min))\nmask.triu_(1)  # zero out the lower diagonal\nmask = mask.unsqueeze(1)  # expand mask\nreturn mask\n", "fix_pattern": "if initializing a tensor with a fill value, use torch.tensor(<fill value>) instead of torch.tensor(float(<fill value>))"}
{"number": 135, "change": "def get_mini_batch(mini_batch_indices, sequences, seq_lengths, cuda=False):\n# get mask for mini-batch\nmini_batch_mask = get_mini_batch_mask(mini_batch, sorted_seq_lengths)\n\n-    # wrap in PyTorch Variables\n-    mini_batch = Variable(torch.Tensor(mini_batch))\n-    mini_batch_reversed = Variable(torch.Tensor(mini_batch_reversed))\n-    mini_batch_mask = Variable(torch.Tensor(mini_batch_mask))\n+    # wrap in PyTorch Tensors\n+    mini_batch = torch.tensor(mini_batch)\n+    mini_batch_reversed = torch.tensor(mini_batch_reversed)\n+    mini_batch_mask = torch.tensor(mini_batch_mask)\n\n# cuda() here because need to cuda() before packing\nif cuda:\n", "fix_pattern": "If the code is wrapping tensors in PyTorch Variables, replace it with wrapping them in PyTorch Tensors."}
{"number": 137, "change": "class FlopsProfiler(object):\nstart_time_hook)\n\ndef end_time_hook(module, input, output):\n-                torch.cuda.synchronize()\n+                get_accelerator().synchronize()\nmodule.__duration__ += time.time() - module.__start_time__\n\nif not hasattr(module, \"__end_time_hook_handle__\"):\n", "fix_pattern": "if calling torch.cuda.synchronize() is detected, replace with get_accelerator().synchronize()"}
{"number": 151, "change": "def main(args):\n# CNN will transform a high dimension image into a low dimension 2D tensors for RBF kernel.\n# This kernel accepts inputs are inputs of CNN and gives outputs are covariance matrix of RBF on\n# outputs of CNN.\n-    kernel = gp.kernels.RBF(input_dim=10, lengthscale=torch.ones(10)).warp(iwarping_fn=cnn_fn)\n+    kernel = gp.kernels.Warp(gp.kernels.RBF(input_dim=10, lengthscale=torch.ones(10)),\n+                             iwarping_fn=cnn_fn)\n\n# init inducing points (taken randomly from dataset)\nXu = next(iter(train_loader))[0][:args.num_inducing]\n", "fix_pattern": "if a kernel is being created using gp.kernels.RBF, wrap it inside gp.kernels.Warp and pass iwarping_fn=cnn_fn as a parameter."}
{"number": 153, "change": "def linspace_helper(start, stop, num, axis=None, *, device):\nelse:\nres = [linspace_method(start, stp, num, device=device) for stp in stop]\nelse:\n-        return linspace_method(start, stop, num, device=device)\n+        return linspace_method(start, stop, num, dtype=torch.float64, device=device)\nres = torch.cat(res, -1).reshape(sos_shape + [num])\nif axis is not None:\nres = torch.transpose(res, axis, -1)\n", "fix_pattern": "if the dtype argument of a method call is missing, add dtype=torch.float64 to the method call."}
{"number": 156, "change": "class UnittestBase(object):\ndatetime.now().strftime('%H:%M:%S'), self.__class__.__name__[4:], name\n))\nsys.stdout.flush()\n+        tf.compat.v1.reset_default_graph()\n\ndef finished_test(self, assertion=None):\n\"\"\"\n", "fix_pattern": "if tf.compat.v1.reset_default_graph() is detected, replace it with tf.reset_default_graph()"}
{"number": 158, "change": "class GPTNeoXModel(GPTNeoXPreTrainedModel):\n# Since we are adding it to the raw scores before the softmax, this is\n# effectively the same as removing these entirely.\nattention_mask = attention_mask.to(dtype=self.dtype)  # fp16 compatibility\n-            attention_mask = (1.0 - attention_mask) * -10000.0\n+            attention_mask = (1.0 - attention_mask) * torch.finfo(self.dtype).min\n\n# Prepare head mask if needed\n# 1.0 in head_mask indicate we keep the head\n", "fix_pattern": "If a mathematical operation is performed on the attention_mask variable, and the value \"-10000.0\" is being used, replace it with \"torch.finfo(self.dtype).min\"."}
{"number": 160, "change": "def compute_tf_latency(\nwith tf.device(device):\nfor _ in range(steps):\nstarting_time = time.time()\n-            _ = model(x)\n+            _ = model(*xs)\nlatencies.append(time.time() - starting_time)\nlatency = sum(latencies) / steps\nreturn latency, latencies\n", "fix_pattern": "if a function call is detected with an input argument as a single tensor, change it to a tuple of tensors"}
{"number": 163, "change": "def non_max_suppression(prediction, conf_thres=0.1, iou_thres=0.6, classes=None,\nmerge = False  # use merge-NMS\n\nt = time.time()\n-    output = [torch.zeros(0, 6)] * prediction.shape[0]\n+    output = [torch.zeros((0, 6), device=prediction.device)] * prediction.shape[0]\nfor xi, x in enumerate(prediction):  # image index, image inference\n# Apply constraints\n# x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height\n", "fix_pattern": "if torch.zeros() is used to create an empty tensor, add the device argument to specify the device for the tensor."}
{"number": 166, "change": "class DartsTrainer(BaseOneShotTrainer):\np += e * d\n\n_, loss = self._logits_and_loss(trn_X, trn_y)\n-            dalphas.append(torch.autograd.grad(loss, [c.alpha for c in self.nas_modules]))\n+            dalphas.append(torch.autograd.grad(loss, [c.alpha for _, c in self.nas_modules]))\n\ndalpha_pos, dalpha_neg = dalphas  # dalpha { L_trn(w+) }, # dalpha { L_trn(w-) }\nhessian = [(p - n) / (2. * eps) for p, n in zip(dalpha_pos, dalpha_neg)]\n", "fix_pattern": "If torch.autograd.grad() is called with a list comprehension of c.alpha, change it to [c.alpha for _, c in self.nas_modules] to also include the index in the loop."}
{"number": 167, "change": "def subtract(\nout: Optional[Union[tf.Tensor, tf.Variable]] = None,\n) -> Union[tf.Tensor, tf.Variable]:\nx1, x2 = ivy.promote_types_of_inputs(x1, x2)\n-    return tf.subtract(x1, x2)\n+    return tf.experimental.numpy.subtract(x1, x2)\n\n\ndef tan(\n", "fix_pattern": "if a TensorFlow API is replaced with a TensorFlow experimental API, replace the API name with the experimental version (e.g., tf.subtract -> tf.experimental.numpy.subtract)"}
{"number": 169, "change": "class XDropout(torch.autograd.Function):\n# Once https://github.com/pytorch/pytorch/issues/78391 is fixed, do something like:\n# if opset_version < 12:\n#   return torch.onnx.symbolic_opset9.dropout(g, input, dropout_p, train)\n-        return torch.onnx.symbolic_opset12.dropout(g, input, dropout_p, train)\n+        return symbolic_opset12.dropout(g, input, dropout_p, train)\n\n\n# Copied from transformers.models.deberta.modeling_deberta.StableDropout\n", "fix_pattern": "if the torch.onnx prefix is detected before a symbolic function, remove it"}
{"number": 170, "change": "class Parquet(datasets.ArrowBasedBuilder):\nBUILDER_CONFIG_CLASS = ParquetConfig\n\ndef _info(self):\n-        if version.parse(pa.__version__) < version.parse(\"3.0.0\"):\n+        if datasets.config.PYARROW_VERSION.major < 3:\nraise ImportError(\n\"PyArrow >= 3.0.0 is required to used the Parquet dataset builder: pip install --upgrade pyarrow\"\n)\n", "fix_pattern": "if a comparison of library version using pa.__version__ is detected, replace it with datasets.config.PYARROW_VERSION.major < version_number."}
{"number": 171, "change": "class RPCPlugin(DDPPlugin):\nworld_size: int) -> None:\nos.environ['MASTER_PORT'] = os.getenv('RPC_MASTER_PORT', '15000')\nrpc.init_rpc(f\"worker{global_rank}\", rank=global_rank, world_size=world_size)\n+        rpc._set_rpc_timeout(self.rpc_timeout_sec)\nself.rpc_initialized = True\n\ndef rpc_save_model(self,\n", "fix_pattern": "if an RPC timeout is set using rpc._set_rpc_timeout(), it is important to verify and set the timeout value using self.rpc_timeout_sec"}
{"number": 172, "change": "class SimpleSeq2SeqTest(ModelTestCase):\nstate = self.model._init_decoder_state(state)\nbatch_size = state[\"source_mask\"].size()[0]\nstart_predictions = state[\"source_mask\"].new_full(\n-            (batch_size,), fill_value=self.model._start_index\n+            (batch_size,), fill_value=self.model._start_index, dtype=torch.long\n)\nall_top_k_predictions, _ = beam_search.search(\nstart_predictions, state, self.model.take_step\n", "fix_pattern": "if a tensor is initialized with fill_value and no dtype is specified, add dtype=torch.long to the end of the API call"}
{"number": 174, "change": "class StableDiffusionDepth2ImgPipeline(DiffusionPipeline):\n`pipeline.enable_sequential_cpu_offload()` the execution device can only be inferred from Accelerate's module\nhooks.\n\"\"\"\n-        if self.device != torch.device(\"meta\") or not hasattr(self.unet, \"_hf_hook\"):\n+        if not hasattr(self.unet, \"_hf_hook\"):\nreturn self.device\nfor module in self.unet.modules():\nif (\n", "fix_pattern": "if device check is present (self.device) and device is not \"meta\", or device check is not present, remove it"}
{"number": 177, "change": "class IvyModule(ivy.Module):\nif ivy.array_mode():\na, kw = ivy.args_to_native(*a, **kw)\n# noinspection PyUnresolvedReferences\n-        params_hk = self._native_module.init(ivy.functional.core.random.RNG, *a, **kw)\n+        params_hk = self._native_module.init(ivy.random.RNG, *a, **kw)\nparams_dict = _hk_flat_map_to_dict(params_hk)\nself._hk_params = ivy.Container(params_dict)\nparam_iterator = self._hk_params.to_iterator()\n", "fix_pattern": "if the ivy.functional.core.random.RNG module is used, replace it with ivy.random.RNG"}
{"number": 179, "change": "class DataParallel(torch.nn.DataParallel):\nBatch.from_data_list(data_list[split[i]:split[i + 1]],\nfollow_batch=self.follow_batch,\nexclude_keys=self.exclude_keys).to(\n-                                     torch.device('cuda:{}'.format(\n-                                         device_ids[i])))\n+                                     torch.device(f'cuda:{device_ids[i]}'))\nfor i in range(len(split) - 1)\n]\n", "fix_pattern": "if torch.device() call is detected with formatting using .format(), replace it with f-string formatting using {}\n\nEXAMPLE:\n\ncode removed:\n'''\nmask = torch.arange(max_len, device=device).expand(len(indices), max_len) >= lengths[:, None]\n'''\n\ncode added:\n'''\nmask = torch.arange(max_len, device=device).expand(len(indices), max_len) >= lengths[:, None].to(device)\n'''\n\n<pattern>: if a tensor is used in a comparison operator, add .to(device) to the end of the tensor call."}
{"number": 180, "change": "class ProjectedAdaptiveLogSoftmax(nn.Module):\nd_emb_i = d_embed // (div_val ** i)\n\nself.out_projs.append(\n-                    nn.Parameter(torch.Tensor(d_proj, d_emb_i))\n+                    nn.Parameter(torch.FloatTensor(d_proj, d_emb_i))\n)\n\nself.out_layers.append(nn.Linear(d_emb_i, r_idx-l_idx))\n", "fix_pattern": "if torch.Tensor is detected, replace with torch.FloatTensor"}
{"number": 181, "change": "class TensorFlowEstimator(BaseEstimator):\nraise NotFittedError()\npredict_data_feeder = setup_predict_data_feeder(X)\npreds = []\n-        dropouts = tf.get_collection(DROPOUTS)\n-        feed_dict = {prob: 0.0 for prob in dropouts}\n+        dropouts = self._graph.get_collection(DROPOUTS)\n+        feed_dict = {prob: 1.0 for prob in dropouts}\nfor data in predict_data_feeder:\nfeed_dict[self._inp] = data\npreds.append(self._session.run(\n", "fix_pattern": "if tf.get_collection(DROPOUTS) is detected, replace it with self._graph.get_collection(DROPOUTS) and change the value of prob in feed_dict from 0.0 to 1.0."}
{"number": 187, "change": "class Pix2PixModel(BaseModel):\ndef backward_D(self):\n# Fake\n# stop backprop to the generator by detaching fake_B\n-        fake_AB = self.fake_AB_pool.query(torch.cat((self.real_A, self.fake_B), 1))\n+        fake_AB = self.fake_AB_pool.query(torch.cat((self.real_A, self.fake_B), 1).data)\npred_fake = self.netD.forward(fake_AB.detach())\nself.loss_D_fake = self.criterionGAN(pred_fake, False)\n\n# Real\nreal_AB = torch.cat((self.real_A, self.real_B), 1)\npred_real = self.netD.forward(real_AB)\n-        self.loss_D_real = self.criterionGAN(self.pred_real, True)\n+        self.loss_D_real = self.criterionGAN(pred_real, True)\n\n# Combined loss\nself.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n", "fix_pattern": "If torch.cat() is called with a tensor as an argument, replace it with torch.cat().data."}
{"number": 189, "change": "class Trainer:\ntransformer_cls_to_wrap = get_module_class_from_name(\nmodel, self.args.fsdp_transformer_layer_cls_to_wrap\n)\n+                    if transformer_cls_to_wrap is None:\n+                        raise Exception(\"Could not find the transformer layer class to wrap in the model.\")\nauto_wrap_policy = functools.partial(\ntransformer_auto_wrap_policy,\n# Transformer layer class to wrap\n", "fix_pattern": "if a specific condition is not met, raise an exception with a specific message."}
{"number": 193, "change": "class tensorflow_extractor(base_extractor):\nwriter.close()\nsess.run(init)\nsaver = tf.train.Saver()\n+            tf.train.export_meta_graph(\"kit.meta\", as_text=True)\nsaver.restore(sess, path + cls.architecture_map[architecture]['filename'])\nsave_path = saver.save(sess, path + \"imagenet_{}.ckpt\".format(architecture))\nprint(\"Model saved in file: %s\" % save_path)\n", "fix_pattern": "The pattern for fixing the API method problem in the given code change is to use the appropriate replacement API and adjust the method parameters accordingly.\n\nIn the given example:\ncode removed:\n'''\nattention_scores = F.normalize(query_layer, dim=-1) @ F.normalize(key_layer, dim=-1).transpose(-2, -1)\n'''\n\ncode added:\n'''\nattention_scores = nn.functional.normalize(query_layer, dim=-1) @ nn.functional.normalize(\nkey_layer, dim=-1\n).transpose(-2, -1)\n'''\n\nThe pattern used is to replace the deprecated API method `F.normalize()` with the replacement API `nn.functional.normalize()`. The code change ensures that the deprecated API is replaced with the correct and up-to-date API method.\n\nSimilarly, for the next code change:\ncode removed:\n'''\nbbsz_offsets = (torch.arange(0, bsz) * beam_size).unsqueeze(1).type_as(tokens)\",\ncand_offsets = torch.arange(0, cand_size).type_as(tokens)\",\n'''\n\ncode added:\n'''\nbbsz_offsets = (torch.arange(0, bsz) * beam_size).unsqueeze(1).type_as(tokens).to(src_tokens.device)\",\ncand_offsets = torch.arange(0, cand_size).type_as(tokens).to(src_tokens.device)\",,\n'''\n\nThe pattern used is to add the `.to(device)` at the end of the API call to ensure that the offset tensor is correctly placed on the desired device. The code change ensures that the offset tensors are converted to the same device as `src_tokens.device`.\n\nFor the last code change:\ncode removed:\n'''\n\n'''\n\ncode added:\n'''\n            tf.train.export_meta_graph(\"kit.meta\", as_text=True)\n\n'''\n\nThe pattern used is to export the meta graph using the `tf.train.export_meta_graph()` method with the specified parameters. The code change exports the meta graph with the provided name and as a text file.\n\nNote: The pattern for this code change is not well-defined as the code removed does not provide sufficient context for determining the exact pattern."}
{"number": 194, "change": "def test_auto_diagonal_gaussians(auto_class, Elbo):\nguide = auto_class(model, rank=1)\nelse:\nguide = auto_class(model)\n-    adam = optim.Adam({\"lr\": .001, \"betas\": (0.95, 0.999)})\n+    adam = optim.ClippedAdam({\"lr\": .01, \"betas\": (0.95, 0.999),\n+                              \"lrd\": 0.1 ** (1 / n_steps)})\nsvi = SVI(model, guide, adam, loss=Elbo())\n\nfor k in range(n_steps):\n", "fix_pattern": "If an optimizer object is detected with parameters: \"betas\", \"lr\", and \"lrd\", replace the optimizer with ClippedAdam and add the \"lrd\" parameter with the value of 0.1 ** (1 / n_steps)."}
{"number": 195, "change": "def test_frontend_backward_multi_channel(train, use_wpe, use_beamformer):\nfrontend.train()\nelse:\nfrontend.eval()\n+    torch.random.manual_seed(14)\nx = torch.randn(2, 1000, 2, requires_grad=True)\nx_lengths = torch.LongTensor([1000, 980])\ny, y_lengths = frontend(x, x_lengths)\n", "fix_pattern": "Add a random seed initialization by calling torch.random.manual_seed(seed)"}
{"number": 199, "change": "class EulerSamplingTest(tf.test.TestCase, parameterized.TestCase):\ntimes=times,\nnum_samples=num_samples,\ninitial_state=x0,\n-            random_type=tff.math.random.RandomType.SOBOL,\n+            random_type=tff.math.random.RandomType.HALTON,\ntime_step=0.01,\n-            seed=12134))\n+            seed=12134,\n+            skip=100,\n+            dtype=tf.float32))\n\n-    self.assertAllClose(paths.shape, (num_samples, 5, 2), atol=0)\n+    self.assertAllClose(paths.shape, (num_samples, 3, 2), atol=0)\nmeans = np.mean(paths, axis=0)\ntimes = np.reshape(times, [-1, 1])\nexpected_means = x0 + (2.0 / 3.0) * mu * np.power(times, 1.5)\n", "fix_pattern": "if random_type=tff.math.random.RandomType.SOBOL is detected, replace it with random_type=tff.math.random.RandomType.HALTON"}
{"number": 203, "change": "class BatchNorm(TransformModule):\nif self.training:\nmean, var = y.mean(0), y.var(0)\n\n-            # NOTE: The momentum variable agrees with the definition in e.g. `torch.nn.BatchNorm1d`\n-            self.moving_mean.mul_(1 - self.momentum).add_(mean * self.momentum)\n-            self.moving_variance.mul_(1 - self.momentum).add_(var * self.momentum)\n+            with torch.no_grad():\n+                # NOTE: The momentum variable agrees with the definition in e.g. `torch.nn.BatchNorm1d`\n+                self.moving_mean.mul_(1 - self.momentum).add_(mean * self.momentum)\n+                self.moving_variance.mul_(1 - self.momentum).add_(var * self.momentum)\n\n# During test time, use smoothed averages rather than the sample ones\nelse:\n", "fix_pattern": "if an API call is made within a \"with torch.no_grad():\" block, move the API call inside the block"}
{"number": 205, "change": "class RNNLM(nn.Module):\n\ndef forward(self, state, x):\nh0 = self.embed(x)\n-        h1, c1 = self.l1(F.dropout(h0), (state['h1'], state['c1']))\n-        h2, c2 = self.l2(F.dropout(h1), (state['h2'], state['c2']))\n-        y = self.lo(F.dropout(h2))\n+        h1, c1 = self.l1(self.d0(h0), (state['h1'], state['c1']))\n+        h2, c2 = self.l2(self.d1(h1), (state['h2'], state['c2']))\n+        y = self.lo(self.d2(h2))\nstate = {'c1': c1, 'h1': h1, 'c2': c2, 'h2': h2}\nreturn state, y\n", "fix_pattern": "if a dropout layer is detected before a recurrent layer, wrap the input to the recurrent layer with the dropout layer."}
{"number": 208, "change": "def reportScore(name, scoreTotal, wordsTotal):\ndef main():\nopt = parser.parse_args()\nopt.cuda = opt.gpu > -1\n-    torch.cuda.set_device(opt.gpu)\n+    if opt.cuda:\n+        torch.cuda.set_device(opt.gpu)\n\ntranslator = onmt.Translator(opt)\n", "fix_pattern": "if a device is set using torch.cuda.set_device(), wrap the code in an if statement to check if opt.cuda is True, then call torch.cuda.set_device(opt.gpu)"}
{"number": 209, "change": "class Conv2dStaticSamePadding(nn.Conv2d):\npad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\npad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\nif pad_h > 0 or pad_w > 0:\n-            self.static_padding = nn.ZeroPad2d((pad_w - pad_w // 2, pad_w - pad_w // 2,\n-                                                pad_h - pad_h // 2, pad_h - pad_h // 2))\n+            self.static_padding = nn.ZeroPad2d((pad_w // 2, pad_w - pad_w // 2,\n+                                                pad_h // 2, pad_h - pad_h // 2))\nelse:\nself.static_padding = nn.Identity()\n", "fix_pattern": "if the padding values are calculated using \"// 2\" for half values, change it to \"// 2\" for the first value and \"- // 2\" for the second value."}
{"number": 213, "change": "class SpeedySpeech(BaseTTS):\noutputs = {\"model_outputs\": o_de.transpose(1, 2), \"durations_log\": o_dr_log.squeeze(1), \"alignments\": attn}\nreturn outputs\n\n+    @torch.no_grad()\ndef inference(self, x, aux_input={\"d_vectors\": None, \"speaker_ids\": None}):  # pylint: disable=unused-argument\n\"\"\"\nShapes:\n", "fix_pattern": "Adding the @torch.no_grad() decorator at the beginning of a function or method means that the function or method will be executed without tracking any gradient information. This is useful when performing inference or when we don't want to compute gradients during training."}
{"number": 214, "change": "class KerasBackend(AbstractBackend):\nreturn keras\n\ndef einsum(self, pattern, *x):\n-        return self.tf.einsum(pattern, *x)\n+        return self.tf.vectorized_map(\n+            functools.partial(self.tf.einsum, pattern),\n+            *x\n+        )\n\n\nclass OneFlowBackend(AbstractBackend):\n", "fix_pattern": "if tf.einsum() method is detected, replace it with tf.vectorized_map() method"}
{"number": 215, "change": "def run_modelmerger(primary_model_name, secondary_model_name, teritary_model_nam\nt2 = theta_2.get(key, torch.zeros_like(theta_1[key]))\ntheta_1[key] = theta_func1(theta_1[key], t2)\nelse:\n-                    theta_1[key] = 0\n+                    theta_1[key] = torch.zeros_like(theta_1[key])\ndel theta_2, teritary_model\n\nfor key in tqdm.tqdm(theta_0.keys()):\n", "fix_pattern": "If setting a tensor to a specific value (in this case, 0), replace the value assignment with torch.zeros_like() to create a tensor of the same shape and type as the original."}
{"number": 216, "change": "class DefaultClassifier(Classifier):\n\ndef _calculate_loss(self, scores, labels):\n\n-        if len(labels) == 0: return torch.tensor(0., requires_grad=True), 1\n+        if len(labels) == 0: return torch.tensor(0., requires_grad=True, device=flair.device), 1\n\nif self.multi_label:\nlabels = torch.tensor([[1 if l in all_labels_for_point else 0 for l in self.label_dictionary.get_items()]\n", "fix_pattern": "if a tensor is returned with requires_grad=True, add device=<device> to the tensor initialization."}
{"number": 217, "change": "class EmbeddingLayer(nn.Module):\ntorch.empty(weight_shape[0],\nweight_shape[1],\ndtype=dtype,\n-                        device=torch.cuda.current_device()))\n+                        device=get_accelerator().current_device_name()))\n\ndef forward(self, input):\nreturn F.embedding(input, self.weight)\n", "fix_pattern": "If the device argument in the API call is `torch.cuda.current_device()`, replace it with `get_accelerator().current_device_name()`"}
{"number": 218, "change": "class MultiActionDistribution(ActionDistribution):\n\ndef logp(self, x):\n\"\"\"The log-likelihood of the action distribution.\"\"\"\n-        split_list = self.reshaper.split_tensor(x)\n+        split_list = tf.split(x, len(self.input_lens), axis=1)\nfor i, distribution in enumerate(self.child_distributions):\n# Remove extra categorical dimension\nif isinstance(distribution, Categorical):\n", "fix_pattern": "if a tensor split operation is detected with self.reshaper.split_tensor(), replace it with tf.split()."}
{"number": 219, "change": "class CategoricalOneHotPolicy(StochasticPolicy):\ndef __init__(self, network, session, state, random, action_count=1, scope='policy'):\nwith tf.variable_scope(scope):\naction_layer = linear(layer_input=network.output, config={'num_outputs': action_count}, scope='outputs')\n+            action_layer = tf.reshape(action_layer, [-1, action_count])\n+\ndistribution = tf.nn.softmax(action_layer)\nsample = tf.multinomial(distribution, 1)\n", "fix_pattern": "if reshaping a tensor using tf.reshape(), add a -1 as the first argument to reshape the tensor into a 1D tensor"}
{"number": 222, "change": "def test(data,\nelse:  # called by train.py\ntraining = True\ndevice = next(model.parameters()).device  # get model device\n-        half = device.type != 'cpu'  # half precision only supported on CUDA\n+        half = device.type != 'cpu' and torch.cuda.device_count() == 1  # half precision only supported on single-GPU\nif half:\nmodel.half()  # to FP16\n", "fix_pattern": "If a check for device type is detected without checking for the number of CUDA devices, add \"and torch.cuda.device_count() == 1\" to the end of the condition."}
{"number": 223, "change": "class MobileNetV3LargeEncoder(MobileNetV3):\n)\n\nif pretrained:\n-            self.load_state_dict(load_state_dict_from_url(\n+            self.load_state_dict(torch.hub.load_state_dict_from_url(\n'https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth'))\n\ndel self.avgpool\n", "fix_pattern": "if loading state_dict using load_state_dict_from_url is detected, replace it with torch.hub.load_state_dict_from_url"}
{"number": 224, "change": "def make_non_pad_mask(lengths):\n\"\"\"\nbs = int(len(lengths))\nmaxlen = int(max(lengths))\n-    mask = torch.zeros(bs, maxlen).byte()\n+    mask = torch.zeros(bs, maxlen, dtype=torch.uint8)\nfor i, l in enumerate(lengths):\nmask[i, :l] = 1\n", "fix_pattern": "If a byte tensor is detected, replace with dtype=torch.uint8."}
{"number": 229, "change": "class TFXGLMPreTrainedModel(TFPreTrainedModel):\n@tf.function(\ninput_signature=[\n{\n-                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),\n-                \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),\n+                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),\n+                \"attention_mask\": tf.TensorSpec((None, None), tf.int64, name=\"attention_mask\"),\n}\n]\n)\n", "fix_pattern": "if the data type of a tensor specification is changed, update the corresponding data type in the code"}
{"number": 233, "change": "class TacotronTrainTest(unittest.TestCase):\noptimizer = optim.Adam(model.parameters(), lr=c.lr)\nfor i in range(5):\nmel_out, linear_out, align, stop_tokens = model.forward(\n-                input, mel_spec)\n+                input, input_lengths, mel_spec)\nassert stop_tokens.data.max() <= 1.0\nassert stop_tokens.data.min() >= 0.0\noptimizer.zero_grad()\n", "fix_pattern": "if an API call is made with fewer arguments than before, add the missing arguments to the API call"}
{"number": 234, "change": "class EulerAncestralDiscreteScheduler(SchedulerMixin, ConfigMixin):\n\nprev_sample = sample + derivative * dt\n\n-        device = model_output.device if torch.is_tensor(model_output) else torch.device(\"cpu\")\n+        device = model_output.device\nif device.type == \"mps\":\n# randn does not work reproducibly on mps\nnoise = torch.randn(model_output.shape, dtype=model_output.dtype, device=\"cpu\", generator=generator).to(\n", "fix_pattern": "If the code checks whether `model_output` is a tensor and assigns `model_output.device` to `device`, then the pattern for fixing the API method problem is to remove the `torch.is_tensor()` check and the alternative `torch.device(\"cpu\")` assignment."}
{"number": 244, "change": "def test_runway_sd_1_5_negative_prompt(sd_device, strategy, sampler):\ndef test_cv2(strategy, cv2_flag, cv2_radius):\nmodel = ModelManager(\nname=\"cv2\",\n-        device=device,\n+        device=torch.device(device),\n)\ncfg = get_config(strategy, cv2_flag=cv2_flag, cv2_radius=cv2_radius)\nassert_equal(\n", "fix_pattern": "In this case, the pattern for fixing the API method problem is to wrap the 'device' argument with torch.device(). \n\nThe pattern is: if device argument detected, wrap it with torch.device() method."}
{"number": 250, "change": "def train_cnn_and_compute_accuracy(params, steps, train_images, train_labels, va\n# Do the training and evaluation.\nwith tf.Session() as sess:\n# Initialize the network weights.\n-    sess.run(tf.initialize_all_variables())\n+    sess.run(tf.global_variables_initializer())\nfor i in range(1, steps + 1):\n# Fetch the next batch of data.\nimage_batch = get_batch(train_images, i, batch_size)\n", "fix_pattern": "if tf.initialize_all_variables() is detected, replace with tf.global_variables_initializer()"}
{"number": 251, "change": "def actor_critic_loss(policy, model, dist_class, train_batch):\nvalues = model.value_function()\ndist = dist_class(logits, model)\nlog_probs = dist.logp(train_batch[SampleBatch.ACTIONS])\n-    policy.entropy = dist.entropy().mean()\n+    policy.entropy = dist.entropy().sum()\npolicy.pi_err = -train_batch[Postprocessing.ADVANTAGES].dot(\nlog_probs.reshape(-1))\n-    policy.value_err = nn.functional.mse_loss(\n-        values.reshape(-1), train_batch[Postprocessing.VALUE_TARGETS])\n+    policy.value_err = torch.sum(\n+        torch.pow(\n+            values.reshape(-1) - train_batch[Postprocessing.VALUE_TARGETS],\n+            2.0))\noverall_err = sum([\npolicy.pi_err,\npolicy.config[\"vf_loss_coeff\"] * policy.value_err,\n", "fix_pattern": "If the API method .mean() is detected, replace it with .sum().\nIf nn.functional.mse_loss() is detected, replace it with torch.sum(torch.pow())."}
{"number": 252, "change": "class DeepSpeedDataLoader(object):\nelse:\nif data_sampler is None:\ndata_sampler = RandomSampler(dataset)\n-                device_count = torch.cuda.device_count()\n+                device_count = get_accelerator().device_count()\nbatch_size *= device_count\n\nif num_local_io_workers is None:\n", "fix_pattern": "If the function `.cuda()` or `.cuda(device)` is detected, replace it with `get_accelerator().device_count()`."}
{"number": 258, "change": "class StopwatchMeter(Meter):\nif self.start_time is not None:\ndelta = time.perf_counter() - self.start_time\nself.sum = self.sum + delta\n-            self.n = self.n + n\n+            self.n = type_as(self.n, n) + n\n\ndef reset(self):\nself.sum = 0  # cumulative time during which stopwatch was active\n", "fix_pattern": "if self.n is a tensor, replace self.n = self.n + n with self.n = torch.type_as(self.n, n) + n"}
{"number": 259, "change": "class RagTokenForGeneration(RagPreTrainedModel):\nn_docs = n_docs if n_docs is not None else self.config.n_docs\n\n# RAG-token marginalization\n-        seq_logprobs = torch.nn.functional.log_softmax(seq_logits, dim=-1).view(\n+        seq_logprobs = nn.functional.log_softmax(seq_logits, dim=-1).view(\nseq_logits.shape[0] // n_docs, n_docs, -1, seq_logits.size(-1)\n)\ndoc_logprobs = torch.log_softmax(doc_scores, dim=1)\n", "fix_pattern": "The pattern for fixing the API method problem in the code change is to replace \"torch.nn.functional\" with \"nn.functional\"."}
{"number": 265, "change": "class HorovodTrainer(DataParallelTrainer):\n),\n)\ntrain_dataset = ray.data.from_items([{\"x\": x, \"y\": x + 1} for x in range(32)])\n-        scaling_config = ScalingConfig(num_workers=3)\n-        # If using GPUs, use the below scaling config instead.\n-        # scaling_config = ScalingConfig(num_workers=3, use_gpu=True)\n+        scaling_config = ScalingConfig(num_workers=3, use_gpu=use_gpu)\ntrainer = HorovodTrainer(\ntrain_loop_per_worker=train_loop_per_worker,\nscaling_config=scaling_config,\n", "fix_pattern": "if a specific configuration option is detected, change the value of that option to a variable or parameter."}
{"number": 267, "change": "def qr(A: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:  # pragma: no cove\n\"\"\"\nLike torch.linalg.qr.\n\"\"\"\n-    if hasattr(torch.linalg, \"qr\"):\n+    if hasattr(torch, \"linalg\") and hasattr(torch.linalg, \"qr\"):\n# PyTorch version >= 1.9\nreturn torch.linalg.qr(A)\nreturn torch.qr(A)\n", "fix_pattern": "if an API call checks for the presence of a specific module or function using hasattr(), extend the check to include the module itself"}
{"number": 268, "change": "def prepare_bart_inputs_dict(\nif decoder_attention_mask is None:\ndecoder_attention_mask = decoder_input_ids.ne(config.pad_token_id)\nif head_mask is None:\n-        head_mask = torch.ones(config.encoder_layers, config.encoder_attention_heads)\n+        head_mask = torch.ones(config.encoder_layers, config.encoder_attention_heads, device=torch_device)\nif decoder_head_mask is None:\n-        decoder_head_mask = torch.ones(config.decoder_layers, config.decoder_attention_heads)\n+        decoder_head_mask = torch.ones(config.decoder_layers, config.decoder_attention_heads, device=torch_device)\nreturn {\n\"input_ids\": input_ids,\n\"decoder_input_ids\": decoder_input_ids,\n", "fix_pattern": "if a tensor is created without specifying a device, add the device=torch_device argument to the API call."}
{"number": 271, "change": "class Plan(Serializable):\n# prevent circular dependency\n# syft relative\nfrom ...core.node.vm.vm import VirtualMachine  # noqa: F401\n+        if self.local_executor is not None:\n+            # this is necessary for syfts nn.module, because the plan contains state from the module\n+            # in order to use this state, we first need to send the model, and then execute te plan\n+            return self.local_executor(**kwargs)\n\nalice = VirtualMachine(name=\"plan_executor\")\nalice_client: client.Client = alice.get_client()\n", "fix_pattern": "if a local executor is not None, return the result of executing the local executor with the given arguments."}
{"number": 272, "change": "class GradTTS(DiffusionPipeline):\nmu_y = mu_y.transpose(1, 2)\n\n# Sample latent representation from terminal distribution N(mu_y, I)\n-        z = mu_y + torch.randn_like(mu_y, device=mu_y.device) / temperature\n+        z = mu_y + torch.randn(mu_y.shape, device=mu_y.device, generator=generator) / temperature\n\nxt = z * y_mask\nh = 1.0 / num_inference_steps\n", "fix_pattern": "if torch.randn_like() is detected, replace with torch.randn()"}
{"number": 273, "change": "class NanDetector:\ngradients = {}\nfor name, param in self.named_parameters:\nif param.grad is not None:\n-                grad_norm = torch.norm(param.grad.data, p=2, dtype=torch.float32)\n+                grad_norm = torch.norm(param.grad.data.float(), p=2)\nnorm[name] = grad_norm.item()\nif torch.isnan(grad_norm).any() or torch.isinf(grad_norm).any():\ngradients[name] = param.grad.data\n", "fix_pattern": "If grad_norm = torch.norm(param.grad.data.float(), p=2) is detected, remove dtype=torch.float32 from the API call."}
{"number": 274, "change": "def create_loader(\n# of samples per-process, will slightly alter validation results\nsampler = OrderedDistributedSampler(dataset)\n\n+    if collate_fn is None:\n+        collate_fn = fast_collate if use_prefetcher else torch.utils.data.dataloader.default_collate\n+\nloader = torch.utils.data.DataLoader(\ndataset,\nbatch_size=batch_size,\nshuffle=sampler is None and is_training,\nnum_workers=num_workers,\nsampler=sampler,\n-        collate_fn=fast_collate if use_prefetcher else torch.utils.data.dataloader.default_collate,\n+        collate_fn=collate_fn,\ndrop_last=is_training,\n)\nif use_prefetcher:\n", "fix_pattern": "if collate_fn is detected in the code, add the line \"collate_fn=collate_fn,\" after assigning a value to collate_fn"}
{"number": 278, "change": "def mesh_laplacian_smoothing(meshes, method: str = \"uniform\"):\nelif method == \"cot\":\nloss = L.mm(verts_packed) * norm_w - verts_packed\nelif method == \"cotcurv\":\n-        loss = (L.mm(verts_packed) - verts_packed) * norm_w\n+        loss = (L.mm(verts_packed) - L_sum * verts_packed) * norm_w\nloss = loss.norm(dim=1)\n\nloss = loss * weights\n", "fix_pattern": "if a matrix multiplication operation is detected, add a missing operation to calculate the sum of the matrix before the multiplication"}
{"number": 280, "change": "class AsyncMultiGPUTrainer(MultiGPUTrainer,\n\nself._setup_predictor_factory(predict_tower)\nself._average_gradient = average_gradient\n+        assert tf.test.is_gpu_available()\n\ndef _setup(self):\nsuper(AsyncMultiGPUTrainer, self)._setup()\n", "fix_pattern": "This code change pattern is to add an assertion that checks if a GPU is available using the `is_gpu_available()` function from the `tf.test` module."}
{"number": 282, "change": "class GCNConv(MessagePassing):\nx = torch.matmul(x, self.weight)\n\nif not self.cached or self.cached_result is None:\n-            edge_index, norm = GCNConv.norm(edge_index,\n-                                            x.size(0), edge_weight,\n+            edge_index, norm = GCNConv.norm(edge_index, x.size(0), edge_weight,\nself.improved, x.dtype)\nself.cached_result = edge_index, norm\n", "fix_pattern": "There is no pattern to be identified for this code change as it is the same code before and after the change."}
{"number": 283, "change": "class CTC(torch.nn.Module):\nif self.ctc_type == \"builtin\":\nolens = to_device(ys_hat, torch.LongTensor([len(s) for s in ys]))\nhlens = hlens.long()\n+            ys_pad = torch.cat(ys)  # without this the code breaks for asr_mix\nself.loss = self.loss_fn(ys_hat, ys_pad, hlens, olens)\nelse:\nself.loss = None\n", "fix_pattern": "if concatenation of tensors using torch.cat() is detected, add the missing dimension to the tensors before concatenation"}
{"number": 296, "change": "class DeformableDetrModelIntegrationTests(unittest.TestCase):\nresults = feature_extractor.post_process_object_detection(\noutputs, threshold=0.3, target_sizes=[image.size[::-1]]\n)[0]\n-        expected_scores = torch.tensor([0.7999, 0.7894, 0.6331, 0.4720, 0.4382])\n+        expected_scores = torch.tensor([0.7999, 0.7894, 0.6331, 0.4720, 0.4382]).to(torch_device)\nexpected_labels = [17, 17, 75, 75, 63]\n-        expected_slice_boxes = torch.tensor([16.5028, 52.8390, 318.2544, 470.7841])\n+        expected_slice_boxes = torch.tensor([16.5028, 52.8390, 318.2544, 470.7841]).to(torch_device)\n\nself.assertEqual(len(results[\"scores\"]), 5)\nself.assertTrue(torch.allclose(results[\"scores\"], expected_scores, atol=1e-4))\n", "fix_pattern": "if tensors are created without specifying the device, add .to(device) to the end of the API call"}
{"number": 297, "change": "class Critic(object):\nn = InputLayer(self.s, name='in')\nn = DenseLayer(n, n_units=30, act=tf.nn.relu6, W_init=tf.random_uniform_initializer(0, 0.01), name='hidden')\n# n = DenseLayer(n, n_units=5, act=tf.nn.relu, W_init=tf.random_uniform_initializer(0, 0.01), name='hidden2')\n-            n = DenseLayer(n, n_units=1, act=tf.identity, name='V')\n+            n = DenseLayer(n, n_units=1, act=None, name='V')\nself.v = n.outputs\n\nwith tf.variable_scope('squared_TD_error'):\n", "fix_pattern": "If the activation parameter is set to tf.identity, replace it with act=None."}
{"number": 298, "change": "class TensorflowBackendInferenceLearner(TensorflowBaseInferenceLearner):\nmetadata = LearnerMetadata.read(path)\nnetwork_parameters = ModelParams(**metadata.network_parameters)\ninput_tfms = metadata.input_tfms\n-        model = nebullvm.operations.inference_learners.utils.load_model(\n+        model = tf.keras.models.load_model(\npath / TENSORFLOW_BACKEND_FILENAMES[\"tf_model\"]\n)\ndevice = Device(metadata.device)\n", "fix_pattern": "if a model is loaded using the nebullvm.operations.inference_learners.utils.load_model() API, replace it with tf.keras.models.load_model()."}
{"number": 300, "change": "FileType = Any\n# Represents the result dict returned by Trainer.train().\nResultDict = dict\n\n+# A tf or torch local optimizer object.\n+LocalOptimizer = Union[\"tf.keras.optimizers.Optimizer\",\n+                       \"torch.optim.Optimizer\"]\n+\n# Dict of tensors returned by compute gradients on the policy, e.g.,\n# {\"td_error\": [...], \"learner_stats\": {\"vf_loss\": ..., ...}}, for multi-agent,\n# {\"policy1\": {\"learner_stats\": ..., }, \"policy2\": ...}.\n", "fix_pattern": "if the type annotation \"Union\" is detected, add the import statement for that type annotation at the top of the file"}
{"number": 305, "change": "def ones_like(x, name=None):\n[ 1.,  1.,  1.]], dtype=float32)\n```\n\"\"\"\n-    return tf.ones_like(x, name=name)\n+    return tf.ones_like(x, dtype=dtype, name=name)\n\n\ndef random_uniform_variable(shape, low, high, dtype=None,\n", "fix_pattern": "If dtype argument is missing in the API call tf.ones_like(), add dtype=dtype to the API call."}
{"number": 307, "change": "from allennlp.common.params import Params\n\nclass TestStackedBidirectionalLstm(AllenNlpTestCase):\ndef test_stacked_bidirectional_lstm_completes_forward_pass(self):\n-        input_tensor = torch.autograd.Variable(torch.rand(4, 5, 3))\n+        input_tensor = torch.rand(4, 5, 3)\ninput_tensor[1, 4:, :] = 0.\ninput_tensor[2, 2:, :] = 0.\ninput_tensor[3, 1:, :] = 0.\n", "fix_pattern": "No pattern is identified for this code change as it is simply removing the usage of `torch.autograd.Variable()`."}
{"number": 309, "change": "class TFCTRLMainLayer(tf.keras.layers.Layer):\ntoken_type_embeds = 0\nposition_ids = tf.reshape(position_ids, [-1, shape_list(position_ids)[-1]])\n\n-        inputs_embeds = self.w(input_ids)\n+        inputs_embeds = self.w(input_ids, mode='embedding')\n# x = embedded.unsqueeze(0) if len(input_ids.shape)<2 else embedded\nseq_len = input_shape[-1]\nmask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n", "fix_pattern": "if an API method is called with additional arguments, add the additional argument to the API call."}
{"number": 315, "change": "class TFWav2Vec2MainLayer(tf.keras.layers.Layer):\nif inputs[\"attention_mask\"] is not None:\n# compute real output lengths according to convolution formula\noutput_lengths = self._get_feat_extract_output_lengths(tf.reduce_sum(inputs[\"attention_mask\"], -1))\n-            attention_mask = tf.sequence_mask(output_lengths, dtype=hidden_states.dtype)\n+\n+            attention_mask = tf.sequence_mask(\n+                output_lengths, maxlen=shape_list(hidden_states)[1], dtype=hidden_states.dtype\n+            )\n\nhidden_states = self.feature_projection(hidden_states, training=inputs[\"training\"])\n", "fix_pattern": "if tf.sequence_mask() is called without specifying maxlen, add maxlen=shape_list(hidden_states)[1] as an argument"}
{"number": 323, "change": "class BaseModel():\nsave_filename = '%s_net_%s.pth' % (which_epoch, name)\nsave_path = os.path.join(self.save_dir, save_filename)\nnet = getattr(self, 'net' + name)\n-                net.load_state_dict(torch.load(save_path))\n+                net.module.load_state_dict(torch.load(save_path))\n\n# print network information\ndef print_networks(self, verbose):\n", "fix_pattern": "if using a model that is wrapped with nn.DataParallel, add .module before the load_state_dict() method to access the inner model."}
{"number": 324, "change": "class SpeedsterRootOp(Operation):\n) -> List[BaseInferenceLearner]:\nif self.orig_latency_measure_op.get_result() is not None:\nmodel_outputs = self.orig_latency_measure_op.get_result()[0]\n-            if isinstance(model, Module):\n+            if isinstance(model, torch.nn.Module):\noptimization_op = self.torch_optimization_op\nelif isinstance(model, tf.Module) and model is not None:\noptimization_op = self.tensorflow_optimization_op\n", "fix_pattern": "if isinstance(module, Module) detected, replace it with if isinstance(module, torch.nn.Module)"}
{"number": 328, "change": "class UNet2DConditionModel(ModelMixin, ConfigMixin):\nif not torch.is_tensor(timesteps):\ntimesteps = torch.tensor([timesteps], dtype=torch.long, device=sample.device)\nelif torch.is_tensor(timesteps) and len(timesteps.shape) == 0:\n-            timesteps = timesteps[None].to(sample.device)\n+            timesteps = timesteps.to(dtype=torch.float32)\n+            timesteps = timesteps[None].to(device=sample.device)\n\n# broadcast to batch dimension in a way that's compatible with ONNX/Core ML\ntimesteps = timesteps.expand(sample.shape[0])\n", "fix_pattern": "if a tensor is converted to a different dtype, first convert to the desired dtype using \".to(dtype=desired_dtype)\", then use \".to(device=device)\" to specify the device."}
{"number": 333, "change": "class BilinearSimilarity(SimilarityFunction):\nself.reset_parameters()\n\ndef reset_parameters(self):\n-        torch.nn.init.xavier_uniform(self._weight_matrix)\n+        torch.nn.init.xavier_uniform_(self._weight_matrix)\nself._bias.data.fill_(0)\n\n@overrides\n", "fix_pattern": "if an initialization method is called without the underscore at the end, add the underscore at the end of the API call."}
{"number": 335, "change": "class AdaptiveEmbedding(nn.Module):\n\ninp_i = inp_flat.index_select(0, indices_i) - l_idx\nemb_i = self.emb_layers[i](inp_i)\n-                emb_i = F.linear(emb_i, self.emb_projs[i])\n+                emb_i = nn.functional.linear(emb_i, self.emb_projs[i])\n\nemb_flat.index_copy_(0, indices_i, emb_i)\n", "fix_pattern": "If the API F.linear() is detected, replace it with nn.functional.linear()."}
{"number": 337, "change": "class Residual(tf.keras.Model):  #@save\nif self.conv3 is not None:\nX = self.conv3(X)\nY += X\n-        return tf.keras.activations.relu(Y + X)\n+        return tf.keras.activations.relu(Y)\n", "fix_pattern": "if an addition operation is detected inside the activation function, remove the addition operation"}
{"number": 341, "change": "for m in model_list:\ndata_root=os.environ.get('IMAGENET_DIR', './imagenet')\n)\n\n+    torch.cuda.empty_cache()\n+\n", "fix_pattern": "No pattern can be identified for the given code change. The code change simply adds the line \"torch.cuda.empty_cache()\" which clears the cache in GPU memory."}
{"number": 342, "change": "class TFMLP(tf.keras.layers.Layer):\nnx = config.n_embd\nself.c_fc = TFConv1D(n_state, nx, initializer_range=config.initializer_range, name=\"c_fc\")\nself.c_proj = TFConv1D(nx, n_state, initializer_range=config.initializer_range, name=\"c_proj\")\n-        self.act = gelu\n+        self.act = get_tf_activation(\"gelu\")\nself.dropout = tf.keras.layers.Dropout(config.resid_pdrop)\n\ndef call(self, x, training=False):\n", "fix_pattern": "if a direct assignment of a function or method is detected (e.g., self.act = gelu), replace it with a function or method call as necessary (e.g., self.act = get_tf_activation(\"gelu\"))"}
{"number": 347, "change": "class TacotronAbstract(ABC, nn.Module):\ndef _backward_pass(self, mel_specs, encoder_outputs, mask):\n\"\"\" Run backwards decoder \"\"\"\ndecoder_outputs_b, alignments_b, _ = self.decoder_backward(\n-            encoder_outputs, torch.flip(mel_specs, dims=(1,)), mask,\n-            self.speaker_embeddings_projected)\n+            encoder_outputs, torch.flip(mel_specs, dims=(1,)), mask)\ndecoder_outputs_b = decoder_outputs_b.transpose(1, 2).contiguous()\nreturn decoder_outputs_b, alignments_b\n", "fix_pattern": "There is no specific pattern for the code change provided. It appears that the `self.speaker_embeddings_projected` argument was removed from the API method call. Without further context or understanding of the purpose of `self.speaker_embeddings_projected`, it is difficult to identify a specific pattern for fixing this API method problem."}
{"number": 348, "change": "def main():\nmodel = MMDataParallel(model, device_ids=[0])\noutputs = single_gpu_test(model, data_loader, args.show)\nelse:\n-        model = MMDistributedDataParallel(model.cuda())\n+        model = MMDistributedDataParallel(\n+            model.cuda(),\n+            device_ids=[torch.cuda.current_device()],\n+            broadcast_buffers=False)\noutputs = multi_gpu_test(model, data_loader, args.tmpdir,\nargs.gpu_collect)\n", "fix_pattern": "if using the MMDistributedDataParallel wrapper, add the following arguments:\n        - model.cuda()\n        - device_ids=[torch.cuda.current_device()]\n        - broadcast_buffers=False"}
{"number": 357, "change": "class Tester(unittest.TestCase):\n# generate input data\nbatch_size = 1\ncenter = torch.zeros(batch_size, 2)\n-        angle = torch.ones(batch_size, 1)\n-        scale = torch.ones(batch_size, 1)\n+        angle = torch.ones(batch_size)\n+        scale = torch.ones(batch_size)\n\ncenter = utils.tensor_to_gradcheck_var(center)  # to var\nangle = utils.tensor_to_gradcheck_var(angle)  # to var\n", "fix_pattern": "If the shape argument of torch.ones() is specified as (batch_size, 1), change it to (batch_size) to remove the redundant dimension."}
{"number": 360, "change": "class Trainer:\nreturn type(data)(self._prepare_input(v) for v in data)\nelif isinstance(data, torch.Tensor):\nkwargs = {\"device\": self.args.device}\n-            if self.deepspeed and data.dtype != torch.int64:\n-                # NLP models inputs are int64 and those get adjusted to the right dtype of the\n+            if self.deepspeed and (torch.is_floating_point(data) or torch.is_complex(data)):\n+                # NLP models inputs are int/uint and those get adjusted to the right dtype of the\n# embedding. Other models such as wav2vec2's inputs are already float and thus\n# may need special handling to match the dtypes of the model\nkwargs.update({\"dtype\": self.args.hf_deepspeed_config.dtype()})\n", "fix_pattern": "If the condition checks for the dtype of the data and the dtype is not torch.int64, replace the condition with (torch.is_floating_point(data) or torch.is_complex(data))."}
{"number": 362, "change": "class DeformableDetrImageProcessor(BaseImageProcessor):\nimg_w = torch.Tensor([i[1] for i in target_sizes])\nelse:\nimg_h, img_w = target_sizes.unbind(1)\n-        scale_fct = torch.stack([img_w, img_h, img_w, img_h], dim=1)\n+        scale_fct = torch.stack([img_w, img_h, img_w, img_h], dim=1).to(boxes.device)\nboxes = boxes * scale_fct[:, None, :]\n\nresults = []\n", "fix_pattern": "If a tensor is created and assigned to a variable, and that tensor is used later on in the code (in this case, the variable `boxes`), and the code has been modified to add `.to(device)` at the end of the variable assignment line, then the pattern is to add `.to(device)` to the end of the API call."}
{"number": 363, "change": "class SpanBasedF1Test(AllenNlpTestCase):\ngold_indices = [self.vocab.get_token_index(x, \"tags\") for x in bio_tags]\ngold_tensor = torch.tensor([gold_indices], device=device)\nprediction_tensor = torch.rand([1, 6, self.vocab.get_vocab_size(\"tags\")], device=device)\n-        mask = torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]], device=device)\n+        mask = torch.BoolTensor(\n+            [[True, True, True, True, True, True, True, True, True]], device=device\n+        )\n\n# Make prediction so that it is exactly correct.\nfor i, tag_index in enumerate(gold_indices):\n", "fix_pattern": "if a tensor is created with the device specified using torch.tensor(), replace it with the corresponding data type followed by the device specified using torch.<dtype>Tensor()"}
{"number": 364, "change": "class TowerContext(object):\nself._ctxs = []\nif len(self._name):\nif self.has_own_variables:\n-                # open new variable scopes\n-                self._ctxs.append(tf.variable_scope(self._name))\n+                if self.vs_name:\n+                    self._ctxs.append(tf.variable_scope(self.vs_name))\nelse:\n# use existing variable scope\nreuse = self.index > 0 or (not self.is_training)\n", "fix_pattern": "if tf.variable_scope() is used, replace with if self.vs_name: self._ctxs.append(tf.variable_scope(self.vs_name))"}
{"number": 367, "change": "class _BinaryPostprocessing(torch.nn.Module):\npredictions = [self.bool2str.get(pred, self.bool2str[0]) for pred in predictions]\n\nprobs = preds[self.probabilities_key]\n-        probs = torch.dstack(1 - probs, probs)\n+        probs = torch.stack([1 - probs, probs], dim=-1)\n\nreturn {\nself.predictions_key: predictions,\n", "fix_pattern": "if torch.dstack() is detected, replace with torch.stack() and specify the dimension to stack on"}
{"number": 368, "change": "if __name__ == \"__main__\":\nexp = get_exp(args.exp_file, args.name)\nexp.merge(args.opts)\n\n-    num_gpu = get_num_devices() if args.devices is None else args.devices\n-    assert num_gpu <= get_num_devices()\n+    num_gpu = torch.cuda.device_count() if args.devices is None else args.devices\n+    assert num_gpu <= torch.cuda.device_count()\n\ndist_url = \"auto\" if args.dist_url is None else args.dist_url\nlaunch(\n", "fix_pattern": "if a get_num_devices() API call is detected, replace it with torch.cuda.device_count() API call."}
{"number": 370, "change": "def test_log_prob_eta1(d):\nassert (lps_less_ladj - lps_less_ladj.min()).abs().sum() < 1e-4\n\n\n-@pytest.mark.parametrize(\"eta\", [.1, .5, 1, 2, 5])\n+@pytest.mark.parametrize(\"eta\", [.1, .5, 1., 2., 5.])\ndef test_log_prob_d2(eta):\n-    dist = LKJCorrCholesky(2, torch.DoubleTensor([eta]))\n+    dist = LKJCorrCholesky(2, torch.tensor([eta]))\ntest_dist = TransformedDistribution(Beta(eta, eta), AffineTransform(loc=-1., scale=2.0))\n\nsamples = dist.sample(torch.Size([100]))\n", "fix_pattern": "If a test parameter is a float number without a decimal point, add a decimal point to the number in the new code."}
{"number": 375, "change": "def corr2d(X, K):  #@save\n\n# Defined in file: ./chapter_convolutional-neural-networks/lenet.md\ndef evaluate_accuracy_gpu(net, data_iter, device=None): #@save\n+    net.eval()  # Set the model to evaluation mode\nif not device:\ndevice = next(iter(net.parameters())).device\nmetric = d2l.Accumulator(2)  # num_corrected_examples, num_examples\n", "fix_pattern": "if a comment is detected as the only change, add a blank line and the corresponding API call"}
{"number": 376, "change": "class VideoSequential(ImageSequential):\n# Size of T\nframe_num = input.size(self._temporal_channel)\n# Got param generation shape to (B, C, H, W). Ignoring T.\n-        batch_shape = self.__infer_channel_exclusive_batch_shape__(input)\n+        batch_shape = self.__infer_channel_exclusive_batch_shape__(input, self._temporal_channel)\ninput = self._input_shape_convert_in(input)\ninput = input.reshape(-1, *batch_shape[1:])\nif not self.same_on_frame:\n", "fix_pattern": "if a method call is modified to include an additional argument, add the additional argument to the method call"}
{"number": 377, "change": "def create_dataloader(path, imgsz, batch_size, stride, single_cls=False, hyp=Non\nprefix=prefix)\n\nbatch_size = min(batch_size, len(dataset))\n-    nw = min([os.cpu_count() // DEVICE_COUNT, batch_size if batch_size > 1 else 0, workers])  # number of workers\n+    nd = torch.cuda.device_count()  # number of CUDA devices\n+    nw = min([os.cpu_count() // max(nd, 1), batch_size if batch_size > 1 else 0, workers])  # number of workers\nsampler = None if rank == -1 else distributed.DistributedSampler(dataset, shuffle=shuffle)\nloader = DataLoader if image_weights else InfiniteDataLoader  # only DataLoader allows for attribute updates\nreturn loader(dataset,\n", "fix_pattern": "if the number of CUDA devices is detected, replace os.cpu_count() // DEVICE_COUNT with os.cpu_count() // max(nd,1)"}
{"number": 384, "change": "def array(object_in, dtype: Optional[str] = None, dev: Optional[str] = None):\ndev = default_device(dev)\ndtype = dtype_from_str(default_dtype(dtype, object_in))\nif isinstance(object_in, np.ndarray):\n-        return _torch.Tensor(object_in).to(dev_from_str(dev))\n+        return torch.Tensor(object_in).to(dev_from_str(dev))\nif dtype is not None:\n-        return _torch.tensor(object_in, dtype=dtype, device=dev_from_str(dev))\n-    elif isinstance(object_in, _torch.Tensor):\n+        return torch.tensor(object_in, dtype=dtype, device=dev_from_str(dev))\n+    elif isinstance(object_in, torch.Tensor):\nreturn object_in.to(dev_from_str(dev))\nelse:\n-        return _torch.tensor(object_in, device=dev_from_str(dev))\n+        return torch.tensor(object_in, device=dev_from_str(dev))\n\nasarray = array\n", "fix_pattern": "There seems to be a pattern of replacing \"_torch\" with \"torch\" in the code change."}
{"number": 387, "change": "class Trainer(\nself.gpus = gpus\nself.data_parallel_device_ids = parse_gpu_ids(self.gpus)\nself.root_gpu = determine_root_gpu_device(self.data_parallel_device_ids)\n+        self.root_device = torch.device(\"cpu\")\n\n# tpu state flags\nself.use_tpu = False\n", "fix_pattern": "Add the initialization of the 'root_device' variable with a torch.device() call and set it to \"cpu\"."}
{"number": 390, "change": "def _calculate_expected_result(\naggregation_op_only_probs = gumbel_dist.sample()\nelse:\n# <float32>[batch_size, num_aggregation_labels - 1]\n-        aggregation_op_only_probs = torch.nn.functional.softmax(\n+        aggregation_op_only_probs = nn.functional.softmax(\nlogits_aggregation[:, 1:] / config.aggregation_temperature, dim=-1\n)\n", "fix_pattern": "if deprecated API torch.nn.functional.softmax( detected, replace with nn.functional.softmax("}
{"number": 394, "change": "if torch_available and torch.cuda.is_available():\nif rocm_major <= 4:\ncupy = f\"cupy-rocm-{rocm_major}-{rocm_minor}\"\nelse:\n-        cupy = f\"cupy-cuda{torch.version.cuda.replace('.','')[:3]}\"\n+        cupy = f\"cupy-cuda{''.join(map(str,installed_cuda_version()))}\"\nif cupy:\nextras_require['1bit'].append(cupy)\nextras_require['1bit_mpi'].append(cupy)\n", "fix_pattern": "if the API call torch.version.cuda.replace('.','')[:3] is being replaced with installed_cuda_version()"}
{"number": 397, "change": "def spatial_soft_argmax2d(\n>>> coords = kornia.spatial_soft_argmax2d(input, False)\ntensor([[[1.0000, 1.0000]]])\n\"\"\"\n-    input_soft: torch.Tensor = dsnt.spatial_softmax_2d(input, temperature)\n-    output: torch.Tensor = dsnt.spatial_softargmax_2d(input_soft,\n-                                                      normalized_coordinates)\n+    input_soft: torch.Tensor = spatial_softmax_2d(input, temperature)\n+    output: torch.Tensor = spatial_softargmax_2d(input_soft,\n+                                                 normalized_coordinates)\nreturn output\n", "fix_pattern": "if API call dsnt is detected, replace it with spatial_"}
{"number": 401, "change": "def test_torch_instance_to(\nfrontend,\n):\ninput_dtype, x, method_num_positional_args, method_all_as_kwargs_np = args_kwargs\n+    method_flags.num_positional_args = method_num_positional_args\nhelpers.test_frontend_method(\ninit_input_dtypes=input_dtype,\ninit_all_as_kwargs_np={\n", "fix_pattern": "if a method_flags variable is detected, set its num_positional_args attribute to the value of method_num_positional_args"}
{"number": 407, "change": "class UnigramRecall(Metric):\nA tensor of predictions of shape (batch_size, k, sequence_length).\ngold_labels : `torch.Tensor`, required.\nA tensor of integer class label of shape (batch_size, sequence_length).\n-        mask : `torch.Tensor`, optional (default = None).\n+        mask : `torch.BoolTensor`, optional (default = None).\nA masking tensor the same size as `gold_labels`.\n\"\"\"\npredictions, gold_labels, mask = self.detach_tensors(predictions, gold_labels, mask)\n", "fix_pattern": "if a data type argument is detected, update the argument to the correct data type"}
{"number": 408, "change": "\"        # compute the gating function and one minus the gating function\\n\",\n\"        gate_intermediate = self.relu(self.lin_gate_z_to_hidden(z_t_1))\\n\",\n\"        gate = self.sigmoid(self.lin_gate_hidden_to_z(gate_intermediate))\\n\",\n-    \"        one_minus_gate = ng_ones(gate.size()).type_as(gate) - gate\\n\",\n+    \"        one_minus_gate = torch.ones(gate.size()).type_as(gate) - gate\\n\",\n\"        # compute the 'proposed mean'\\n\",\n\"        proposed_mean_intermediate = self.relu(self.lin_proposed_mean_z_to_hidden(z_t_1))\\n\",\n\"        proposed_mean = self.lin_proposed_mean_hidden_to_z(proposed_mean_intermediate)\\n\",\n", "fix_pattern": "if an ng_ones() API call is detected, replace it with torch.ones() API call"}
{"number": 410, "change": "def rotation_matrix_to_quaternion(\nreturn torch.cat([qx, qy, qz, qw], dim=-1)\n\ndef cond_3():\n-        sq = torch.sqrt(trace + 1.0 + m00 - m11 - m22) * 2.  # sq = 4 * qw.\n+        sq = torch.sqrt(1.0 + m00 - m11 - m22 + eps) * 2.  # sq = 4 * qw.\nqw = safe_zero_division(m10 - m01, sq)\nqx = safe_zero_division(m02 - m20, sq)\nqy = safe_zero_division(m12 - m21, sq)\n", "fix_pattern": "If an arithmetic expression involving a torch.sqrt() function is detected, replace trace with 1.0 + m00 - m11 - m22 and add + eps at the end of the expression."}
{"number": 417, "change": "class Model(ModelDesc):\nif get_current_tower_context().is_training:\nwd_w = tf.train.exponential_decay(2e-4, get_global_step_var(),\n80000, 0.7, True)\n-            wd_cost = tf.mul(wd_w, regularize_cost('.*/W', tf.nn.l2_loss), name='wd_cost')\n+            wd_cost = tf.multiply(wd_w, regularize_cost('.*/W', tf.nn.l2_loss), name='wd_cost')\ncosts.append(wd_cost)\n\nadd_param_summary(('.*/W', ['histogram']))   # monitor W\n", "fix_pattern": "if deprecated API tf.mul( detected, replace with tf.multiply("}
{"number": 418, "change": "if __name__ == '__main__':\nloss_values.clear()\naccuracies.clear()\nif step % 100 == 0:\n-            vis.draw_projections(embeds.detach().cpu().numpy(), utterances_per_speaker, step)\n+            vis.draw_projections(embeds.detach().numpy(), utterances_per_speaker, step)\n", "fix_pattern": "if converting a tensor to a numpy array using .cpu().numpy(), replace with .numpy()"}
{"number": 419, "change": "class ScoreSdeVpScheduler(SchedulerMixin, ConfigMixin):\nx_mean = x + drift * dt\n\n# add noise\n-        noise = torch.randn(x.shape, layout=x.layout, generator=generator).to(x.device)\n+        noise = randn_tensor(x.shape, layout=x.layout, generator=generator, device=x.device, dtype=x.dtype)\nx = x_mean + diffusion * math.sqrt(-dt) * noise\n\nreturn x, x_mean\n", "fix_pattern": "if a tensor is created using torch.randn() and then transferred to a specific device and dtype, replace with a call to randn_tensor() with the same arguments"}
{"number": 422, "change": "def get_keras_model():\nM.add(KL.Conv2D(32, 3, padding='same', activation='relu'))\nM.add(KL.Flatten())\nM.add(KL.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(1e-5)))\n-        M.add(KL.Dropout(0.5))\n+        M.add(KL.Dropout(rate=0.5))\nM.add(KL.Dense(10, activation=None, kernel_regularizer=keras.regularizers.l2(1e-5)))\nreturn M\n", "fix_pattern": "if an API call to KL.Dropout with only a single positional argument is detected, replace it with KL.Dropout(rate=value)"}
{"number": 424, "change": "def main(parsed_args):\n\ndef cli_main():\nparser = options.get_eval_lm_parser()\n+    add_distributed_training_args(parser)\nargs = options.parse_args_and_arch(parser)\n-    main(args)\n+    distributed_utils.call_main(args, main)\n\n\nif __name__ == '__main__':\n", "fix_pattern": "if the main function call is removed, replace it with adding the distributed training arguments and calling the main function using distributed_utils.call_main()"}
{"number": 425, "change": "def degree(index, num_nodes=None, dtype=None, device=None):\ntensor([3., 1., 1.])\n\"\"\"\nnum_nodes = maybe_num_nodes(index, num_nodes)\n-    out = torch.zeros((num_nodes), dtype=dtype, device=device)\n+    out = torch.zeros((num_nodes), dtype=dtype, device=index.device)\nreturn out.scatter_add_(0, index, out.new_ones((index.size(0))))\n", "fix_pattern": "if the device argument is used in torch.zeros(), replace device argument with index.device."}
{"number": 426, "change": "class TransducerTasks(torch.nn.Module):\nif ctc_loss:\nself.ctc_lin = torch.nn.Linear(encoder_dim, output_dim)\n\n-            if LooseVersion(torch.__version__) < LooseVersion(\"1.7.0\"):\n+            if LooseVersion(torch.__version__) > LooseVersion(\"1.0.1\"):\nself.ctc_loss = torch.nn.CTCLoss(\nblank=blank_id,\nreduction=\"sum\",\n", "fix_pattern": "if a version check is detected, update the version number to the desired version"}
{"number": 429, "change": "class RandomThinPlateSpline(AugmentationBase2D):\n\ndef generate_parameters(self, shape: torch.Size) -> Dict[str, Tensor]:\nB, _, _, _ = shape\n-        src = torch.tensor([[[-1.0, -1.0], [-1.0, 1.0], [1.0, -1.0], [1.0, 1.0], [0.0, 0.0]]]).expand(B, 5, 2)  # Bx5x2\n+        src = tensor([[[-1.0, -1.0], [-1.0, 1.0], [1.0, -1.0], [1.0, 1.0], [0.0, 0.0]]]).expand(B, 5, 2)  # Bx5x2\ndst = src + self.dist.rsample(src.shape)\nreturn dict(src=src, dst=dst)\n", "fix_pattern": "The pattern for fixing the API method problem in the given code change is to replace \"torch.tensor\" with \"tensor\"."}
{"number": 433, "change": "def HomographyRegressionApp():\n[-1, 1],  # top-right\n]]).to(dst_homo_src.device)\n# transform points\n-            pts_dst = dgm.transform_points(dgm.inverse(dst_homo_src), pts_src)\n+            pts_dst = dgm.transform_points(torch.inverse(dst_homo_src), pts_src)\n\ndef compute_factor(size):\nreturn 1.0 * size / 2\n", "fix_pattern": "if an API method is detected with dgm.inverse(), replace it with torch.inverse()"}
{"number": 436, "change": "class Highway(torch.nn.Module):\n# above, too.\nnonlinear_part, gate = projected_input.chunk(2, dim=-1)\nnonlinear_part = self._activation(nonlinear_part)\n-            gate = torch.nn.functional.sigmoid(gate)\n+            gate = torch.sigmoid(gate)\ncurrent_input = gate * linear_part + (1 - gate) * nonlinear_part\nreturn current_input\n", "fix_pattern": "If the sigmoid function is used from torch.nn.functional, replace it with torch.sigmoid."}
{"number": 437, "change": "class Model(object):\n\"It should be either Tensor or a list of Tensor.\"\n)\nfor idx in range(len(check_argu)):\n-                        if not isinstance(check_argu[idx], tf_ops._TensorLike) or not tf_ops.is_dense_tensor_like(\n+                        if not isinstance(check_argu[idx], [tf.Tensor, tf.SparseTensor, tf.Variable]) or not tf_ops.is_dense_tensor_like(\ncheck_argu[idx]):\nraise TypeError(\n\"The argument `%s` should be either Tensor or a list of Tensor \" % (check_order[co]) +\n", "fix_pattern": "if isinstance(check_argu[idx], [removed_tf_ops._TensorLike]) is detected, replace it with isinstance(check_argu[idx], [added_tf.Tensor, added_tf.SparseTensor, added_tf.Variable])"}
{"number": 446, "change": "class Csv(datasets.ArrowBasedBuilder):\nif schema is not None\nelse None\n)\n-        for file_idx, file in enumerate(files):\n+        for file_idx, file in enumerate(itertools.chain.from_iterable(files)):\ncsv_file_reader = pd.read_csv(file, iterator=True, dtype=dtype, **self.config.read_csv_kwargs)\ntry:\nfor batch_idx, df in enumerate(csv_file_reader):\n", "fix_pattern": "if an iterable object is detected in the loop, use itertools.chain.from_iterable() to flatten the list before iterating over it."}
{"number": 448, "change": "class ARMAConv(MessagePassing):\nif self.bias is not None:\nout += self.bias[0 if self.shared_weights else t]\n\n-            if t < self.num_layers - 1:\n+            if self.act is not None and t < self.num_layers - 1:\nout = self.act(out)\n\nreturn out.mean(dim=-3)\n", "fix_pattern": "if a condition is added to the code that checks if self.act is not None before the existing condition"}
{"number": 449, "change": "class DependencyParser(flair.nn.Model):\nsentence_tensor = self.word_dropout(sentence_tensor)\n\nif self.use_rnn:\n-            sentence_tensor = pack_padded_sequence(sentence_tensor, lengths, True, False)\n+            sentence_sequence = pack_padded_sequence(sentence_tensor, torch.IntTensor(lengths), True, False)\n\n-            sentence_tensor, _ = self.lstm(sentence_tensor)\n-            sentence_tensor, _ = pad_packed_sequence(sentence_tensor, True, total_length=seq_len)\n+            sentence_sequence, _ = self.lstm(sentence_sequence)\n+            sentence_tensor, _ = pad_packed_sequence(sentence_sequence, True, total_length=seq_len)\n\n# apply MLPs for arc and relations to the BiLSTM output states\narc_h = self.mlp_arc_h(sentence_tensor)\n", "fix_pattern": "if a tensor is passed as an argument to pack_padded_sequence, convert it to a torch.Tensor"}
{"number": 451, "change": "def testtanh():\n\nPtensor = PolynomialTensor()\n\n-    x = torch.linspace(-3, 3, steps=10)\n+    x = torch.tensor(np.linspace(-3, 3, 10))\nexpected = torch.tensor(\n[\n-3.3883e02,\n", "fix_pattern": "if a torch.linspace call is detected, replace it with torch.tensor(np.linspace())"}
{"number": 452, "change": "class BartTranslationTests(unittest.TestCase):\nwith torch.no_grad():\nlogits, *other_stuff = model(**self.net_input)\n\n-        expected_slice = torch.tensor([9.0078, 10.1113, 14.4787])\n+        expected_slice = torch.tensor([9.0078, 10.1113, 14.4787], device=torch_device)\nresult_slice = logits[0][0][:3]\nself.assertTrue(torch.allclose(expected_slice, result_slice, atol=TOLERANCE))\n", "fix_pattern": "if a tensor is detected without device information, add device=torch_device to the end of the API call"}
{"number": 453, "change": "def test_dc_crn_separator_invalid_type():\ndef test_dc_crn_separator_output():\nreal = torch.rand(2, 10, 17)\nimag = torch.rand(2, 10, 17)\n-    x = ComplexTensor(real, imag) if is_torch_1_9_plus else torch.complex(real, imag)\n+    x = torch.complex(real, imag) if is_torch_1_9_plus else ComplexTensor(real, imag)\nx_lens = torch.tensor([10, 8], dtype=torch.long)\n\nfor num_spk in range(1, 3):\n", "fix_pattern": "If a conditional check is present, where a new API call is used with a fallback to the old API call, the pattern is to switch the order of the API calls in the conditional statement."}
{"number": 457, "change": "def multilevel_roi_align(features, rcnn_boxes, resolution):\nall_rois = tf.concat(all_rois, axis=0)  # NCHW\n# Unshuffle to the original order, to match the original samples\nlevel_id_perm = tf.concat(level_ids, axis=0)  # A permutation of 1~N\n-    level_id_invert_perm = tf.invert_permutation(level_id_perm)\n+    level_id_invert_perm = tf.math.invert_permutation(level_id_perm)\nall_rois = tf.gather(all_rois, level_id_invert_perm, name=\"output\")\nreturn all_rois\n", "fix_pattern": "if a method from the tf module is detected, replace the tf module with tf.math"}
{"number": 458, "change": "def SoftMax(x, use_temperature=False, temperature_init=1.0):\n:param x: a 2D tensor\n\"\"\"\nif use_temperature:\n-        t = tf.get_variable('temp', [1],\n+        t = tf.get_variable('invtemp', [],\ninitializer=tf.constant_initializer(1.0 / float(temperature_init)))\nx = x * t\nreturn tf.nn.softmax(x, name='output')\n", "fix_pattern": "If a variable name is changed, update the name in the API call."}
{"number": 459, "change": "def _preprocess_deconv_output_shape(x, shape, dim_ordering):\nshape = (shape[0], shape[2], shape[3], shape[1])\n\nif shape[0] is None:\n-        shape = (tf.shape(x)[0], ) + shape[1:]\n+        shape = (tf.shape(x)[0], ) + tuple(shape[1:])\nreturn shape\n", "fix_pattern": "If a TensorFlow shape tensor is detected and the shape tuple is being accessed or modified, replace the comma-separated list of shape values with a tuple."}
{"number": 462, "change": "class RGCNConv(MessagePassing):\nreturn out if edge_norm is None else out * edge_norm.view(-1, 1)\n\ndef update(self, aggr_out, x):\n-        if x.dtype == torch.long:\n+        if x is None:\nout = aggr_out + self.root\nelse:\nout = aggr_out + torch.matmul(x, self.root)\n", "fix_pattern": "if the dtype of a tensor x is checked with torch.long, replace the condition with if x is None."}
{"number": 470, "change": "class DenseGCNConv(torch.nn.Module):\nidx = torch.arange(N, dtype=torch.long, device=adj.device)\nadj[:, idx, idx] = 1 if not self.improved else 2\n\n-        out = self.lin(x)\n+        out = torch.matmul(x, self.weight)\ndeg_inv_sqrt = adj.sum(dim=-1).clamp(min=1).pow(-0.5)\n\nadj = deg_inv_sqrt.unsqueeze(-1) * adj * deg_inv_sqrt.unsqueeze(-2)\n", "fix_pattern": "if a linear transformation using self.lin is detected, replace it with torch.matmul(x, self.weight)"}
{"number": 472, "change": "class GradientsTest(tf.test.TestCase):\n\n\nif __name__ == \"__main__\":\n-  tf.test.main()\n+  if tf.__internal__.tf2.enabled():\n+    tf.test.main()\n", "fix_pattern": "The pattern for the code change is: if tf.__internal__.tf2.enabled() is detected, add the if statement before calling tf.test.main()."}
{"number": 473, "change": "class Model(ModelDesc):\ncost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)\ncost = tf.reduce_mean(cost, name='cross_entropy_loss')\n\n-        acc = tf.to_float(tf.nn.in_top_k(logits, label, 1))\n+        acc = tf.cast(tf.nn.in_top_k(logits, label, 1), tf.float32)\n\nacc = tf.reduce_mean(acc, name='accuracy')\nsummary.add_moving_summary(acc)\n", "fix_pattern": "if tf.to_float() is detected, replace it with tf.cast() and specify the desired data type as tf.float32"}
{"number": 476, "change": "class TFCoreModelTesterMixin:\n\nself.assertIsNotNone(outputs)\n\n-        tf.keras.mixed_precision.experimental.set_policy(\"float32\")\n+        tf.keras.mixed_precision.set_global_policy(\"float32\")\n\n@slow\ndef test_train_pipeline_custom_model(self):\n", "fix_pattern": "if deprecated API tf.keras.mixed_precision.experimental.set_policy( detected, replace with tf.keras.mixed_precision.set_global_policy("}
{"number": 479, "change": "class TFMBartForConditionalGeneration(TFMBartPreTrainedModel, TFCausalLanguageMo\nif labels is not None:\nlabels = tf.where(\nlabels == self.config.pad_token_id,\n-                tf.fill(shape_list(labels), -100),\n+                tf.cast(tf.fill(shape_list(labels), -100), labels.dtype),\nlabels,\n)\nuse_cache = False\n", "fix_pattern": "if a tensor is filled with a value using tf.fill(), cast the tensor to the same data type as the labels using tf.cast()"}
{"number": 481, "change": "def main():\n# Setup CUDA, GPU & distributed training\nif args.local_rank == -1 or args.no_cuda:\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n-        args.n_gpu = torch.cuda.device_count()\n+        args.n_gpu = 0 if args.no_cuda else torch.cuda.device_count()\nelse:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\ntorch.cuda.set_device(args.local_rank)\ndevice = torch.device(\"cuda\", args.local_rank)\n", "fix_pattern": "if checking for the number of available GPUs using \"torch.cuda.device_count()\" is detected, add a condition to assign 0 if args.no_cuda is True, otherwise assign the result of \"torch.cuda.device_count()\" to args.n_gpu."}
{"number": 482, "change": "class Pandas(datasets.ArrowBasedBuilder):\nreturn pa_table\n\ndef _generate_tables(self, files):\n-        for i, file in enumerate(files):\n+        for i, file in enumerate(itertools.chain.from_iterable(files)):\nwith open(file, \"rb\") as f:\npa_table = pa.Table.from_pandas(pd.read_pickle(f))\nyield i, self._cast_table(pa_table)\n", "fix_pattern": "If an iterator is detected in the for loop, replace it with itertools.chain.from_iterable()."}
{"number": 483, "change": "class DiceLoss(nn.Module):\ncardinality = torch.sum(input_soft + target_one_hot, dims)\n\ndice_score = 2. * intersection / (cardinality + self.eps)\n-        return torch.mean(1. - dice_score)\n+        return torch.mean(torch.tensor(1.) - dice_score)\n\n\n######################\n", "fix_pattern": "if torch tensor subtraction is detected, replace it with torch.tensor(1.) - tensor_name"}
{"number": 488, "change": "class SageMakerTrainingArguments(TrainingArguments):\n# Here, we'll use torch.distributed.\n# Initializes the distributed backend which will take care of synchronizing nodes/GPUs\nif not torch.distributed.is_initialized():\n-                torch.distributed.init_process_group(backend=\"nccl\")\n+                torch.distributed.init_process_group(backend=\"nccl\", timeout=self.ddp_timeout_delta)\ndevice = torch.device(\"cuda\", self.local_rank)\nself._n_gpu = 1\n", "fix_pattern": "If the API method `torch.distributed.init_process_group()` is detected, add the `timeout` parameter with the desired value."}
{"number": 489, "change": "def main(_):\n# net = tl.layers.ReshapeLayer(net,\n#       shape=[-1, int(net.outputs._shape[-1])], name='reshape')\nnet = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop3')\n-            net = tl.layers.DenseLayer(net, vocab_size, W_init=init, b_init=init, act=tf.identity, name='output')\n+            net = tl.layers.DenseLayer(net, vocab_size, W_init=init, b_init=init, act=None, name='output')\nreturn net, lstm1, lstm2\n\n# Inference for Training\n", "fix_pattern": "If an activation function parameter (act) is set to tf.identity, replace it with act=None."}
{"number": 494, "change": "class DecoderLayer(nn.Module):\nself.sublayer = nn_util.clone(SublayerConnection(size, dropout), 3)\n\ndef forward(\n-        self, x: torch.Tensor, memory: torch.Tensor, src_mask: torch.Tensor, tgt_mask: torch.Tensor\n+        self,\n+        x: torch.Tensor,\n+        memory: torch.Tensor,\n+        src_mask: torch.BoolTensor,\n+        tgt_mask: torch.BoolTensor,\n) -> torch.Tensor:\n# Follow Figure 1 (right) for connections.\nx = self.sublayer[0](x, lambda y: self.self_attn(y, y, y, tgt_mask))\n", "fix_pattern": "If the data type of mask tensors is changed from torch.Tensor to torch.BoolTensor, update the function signature accordingly."}
{"number": 497, "change": "class EvalbBracketingScorer(Metric):\nshutil.rmtree(tempdir)\n\nif is_distributed():\n-            # Setting the device to CPU since this metric is not expected to run on GPUs.\n-            device = torch.device(\"cpu\")\n+            device = torch.device(\"cuda\" if dist.get_backend() == \"nccl\" else \"cpu\")\ncorrect_predicted_brackets = torch.tensor(_correct_predicted_brackets).to(device)\npredicted_brackets = torch.tensor(_predicted_brackets).to(device)\ngold_brackets = torch.tensor(_gold_brackets).to(device)\n", "fix_pattern": "if a device tensor is set to CPU, change it to \"cuda\" if dist.get_backend() is \"nccl\" and \"cpu\" in all other cases."}
{"number": 501, "change": "class E2E(torch.nn.Module):\n# Neither CPUTensor nor float/int value can be used\n# because NCCL communicates between GPU devices.\ndevice = next(self.parameters()).device\n-        acc = torch.tensor([acc], device=device)\n+\n+        acc = torch.tensor([acc], device=device) if acc is not None else None\ncer = torch.tensor([cer], device=device)\nwer = torch.tensor([wer], device=device)\nreturn self.loss, loss_ctc, loss_att, acc, cer, wer\n", "fix_pattern": "if a tensor variable is being initialized with device information, check if the variable is None before assigning it to the tensor."}
{"number": 502, "change": "class DeepQNetwork(ValueFunction):\n\"\"\"\n\n# Compute estimated future value\n-        float_terminals = tf.to_float(batch['terminals'])\n+        float_terminals = batch['terminals'].astype(float)\nq_targets = batch['rewards'] + (1. - float_terminals) \\\n* self.gamma * self.get_target_values(batch['next_states'])\n", "fix_pattern": "If tf.to_float() is detected, replace with the astype(float) method on the tensor object."}
{"number": 508, "change": "class DistributedFusedAdam(torch.optim.Optimizer):\ngrp = torch.distributed.new_group(ranks=ranks)\nif torch.distributed.get_rank() in ranks:\nself._rs_pg.append(grp)\n-            if self._compute_L2_grad_norm and torch.distributed.get_rank() in ranks:\n-                self._l2_grad_norm_pg = torch.distributed.new_group(ranks=ranks)\n-                torch.distributed.all_reduce(self._overflow_buf,group=self._l2_grad_norm_pg)\n+            if self._compute_L2_grad_norm:\n+                l2_grad_norm_pg = torch.distributed.new_group(ranks=ranks)\n+                if torch.distributed.get_rank() in ranks:\n+                    self._l2_grad_norm_pg = l2_grad_norm_pg\n+                    torch.distributed.all_reduce(self._overflow_buf,group=self._l2_grad_norm_pg)\nself._rs_st = [torch.cuda.Stream() for _ in range(self._num_rs_pg)]\nfor rs_pg in self._rs_pg:\ntorch.distributed.all_reduce(self._overflow_buf,group=rs_pg)\n", "fix_pattern": "if an API call to torch.distributed.get_rank() is detected, move the subsequent API calls that depend on it inside an if statement to ensure that they are only executed when the condition is met."}
{"number": 510, "change": "def cartesian_product_of_parameters(**possible_parameters):\n\n\ndef default_with_one_parameter_changed(*, default={}, **possible_parameters):\n-    assert isinstance(default, dict), f\"default should be a dict not a {type(default)}\"\n+    if not isinstance(default, dict):\n+        raise AssertionError(f\"default should be a dict not a {type(default)}\")\n\nfor parameter_name, possible_values in possible_parameters.items():\nfor v in possible_values:\n", "fix_pattern": "if assertion statement is used to check the type of a variable, replace the assert statement with an if statement and raise an AssertionError if the condition is not met"}
{"number": 516, "change": "class Speech2Text2SinusoidalPositionalEmbedding(nn.Module):\nemb = torch.cat([emb, torch.zeros(num_embeddings, 1)], dim=1)\nif padding_idx is not None:\nemb[padding_idx, :] = 0\n-        return emb\n+        return emb.to(torch.get_default_dtype())\n\n@torch.no_grad()\ndef forward(self, input_ids: torch.Tensor, past_key_values_length: int = 0):\n", "fix_pattern": "if the return type of a function is a tensor, and the code is not specifying the data type, add .to(torch.get_default_dtype()) to the end of the return statement."}
{"number": 518, "change": "class EulerAncestralDiscreteScheduler(SchedulerMixin, ConfigMixin):\n\nprev_sample = sample + derivative * dt\n\n-        device = model_output.device if torch.is_tensor(model_output) else \"cpu\"\n-        if str(device) == \"mps\":\n+        device = model_output.device if torch.is_tensor(model_output) else torch.device(\"cpu\")\n+        if device.type == \"mps\":\n# randn does not work reproducibly on mps\nnoise = torch.randn(model_output.shape, dtype=model_output.dtype, device=\"cpu\", generator=generator).to(\ndevice\n", "fix_pattern": "If device is checked using the string comparison \"mps\", replace it with torch.device(\"mps\") and check device.type instead."}
{"number": 519, "change": "class AutoRegressiveNN(nn.Module):\n\nif permutation is None:\n# By default set a random permutation of variables, which is important for performance with multiple steps\n-            self.permutation = torch.randperm(input_dim)\n+            self.permutation = torch.randperm(input_dim, device='cpu').to(torch.Tensor().device)\nelse:\n# The permutation is chosen by the user\nself.permutation = permutation.type(dtype=torch.int64)\n", "fix_pattern": "if the device specification is 'cpu' in torch.randperm(), add .to(torch.Tensor().device) to the end of the API call"}
{"number": 522, "change": "class StableDiffusionInpaintPipeline(DiffusionPipeline):\nelse:\nraise ImportError(\"Please install accelerate via `pip install accelerate`\")\n\n-        device = torch.device(\"cuda\")\n+        device = torch.device(f\"cuda:{gpu_id}\")\n\nfor cpu_offloaded_model in [self.unet, self.text_encoder, self.vae, self.safety_checker]:\nif cpu_offloaded_model is not None:\n", "fix_pattern": "if the device is set to \"cuda\", replace it with \"cuda:{gpu_id}\" where {gpu_id} is the desired GPU ID."}
{"number": 524, "change": "class TwoStageDetector(BaseDetector, RPNTestMixin, BBoxTestMixin,\nif self.with_rpn:\nrpn_outs = self.rpn_head(x)\nouts = outs + (rpn_outs, )\n-        proposals = torch.randn(1000, 4).cuda()\n+        proposals = torch.randn(1000, 4).to(device=img.device)\n# bbox head\nrois = bbox2roi([proposals])\nif self.with_bbox:\n", "fix_pattern": "If an API call is detected that moves a tensor to a specific device, replace \".cuda()\" with \".to(device)\"."}
{"number": 526, "change": "class PGModel(Model):\nactions = np.concatenate([path['actions'] for path in batch])\nbatch_advantage = np.concatenate([path[\"advantage\"] for path in batch])\nbatch_advantage = zero_mean_unit_variance(batch_advantage)\n+        batch_advantage = np.expand_dims(batch_advantage, axis=1)\nstates = np.concatenate([path['states'] for path in batch])\n\nreturn action_log_stds, action_means, actions, batch_advantage, states\n", "fix_pattern": "There is no apparent pattern for the code change. It seems that a line of code was removed and a new line of code was added, but the purpose or intent of the change cannot be determined without additional context."}
{"number": 529, "change": "class Categorical(Distribution):\nelif one_hot:\nboolean_mask = x\nelse:\n-                boolean_mask = torch.zeros(ps.size()).scatter_(-1, x.data.long(), 1)\n+                boolean_mask = torch_zeros_like(ps.data).scatter_(-1, x.data.long(), 1)\n# apply log function to masked probability tensor\nreturn torch.log(ps.masked_select(boolean_mask.byte()).contiguous().view(*batch_pdf_size))\n", "fix_pattern": "if a creation of a tensor using torch.zeros is detected, replace with torch.zeros_like."}
{"number": 530, "change": "class ViTMAEModelIntegrationTest(unittest.TestCase):\n\n# forward pass\nwith torch.no_grad():\n-            outputs = model(**inputs, noise=torch.from_numpy(noise))\n+            outputs = model(**inputs, noise=torch.from_numpy(noise).to(device=torch_device))\n\n# verify the logits\nexpected_shape = torch.Size((1, 196, 768))\n", "fix_pattern": "if a tensor is created with torch.from_numpy() and passed as an argument, add .to(device=device) to the end of the tensor."}
{"number": 532, "change": "def initialize_vocabulary(vocabulary_path):\nrev_vocab = []\nwith gfile.GFile(vocabulary_path, mode=\"rb\") as f:\nrev_vocab.extend(f.readlines())\n-    rev_vocab = [line.strip() for line in rev_vocab]\n+    rev_vocab = [tf.compat.as_bytes(line.strip()) for line in rev_vocab]\nvocab = dict([(x, y) for (y, x) in enumerate(rev_vocab)])\nreturn vocab, rev_vocab\nelse:\n", "fix_pattern": "if a list comprehension is used to modify each element of a list, and the modification involves calling a function on the element, replace the function call with a different function call"}
{"number": 534, "change": "class ConformerSeparator(AbsSeparator):\n\"\"\"\n\n# if complex spectrum,\n-        if isinstance(input, ComplexTensor):\n+        if isinstance(input, ComplexTensor) or (\n+            is_torch_1_8_plus and torch.is_complex(input)\n+        ):\nfeature = abs(input)\nelse:\nfeature = input\n", "fix_pattern": "If checking if the input is an instance of ComplexTensor is detected, add an additional condition to also check if the input is a complex tensor using the new function torch.is_complex(input), if the torch version is 1.8 or later."}
{"number": 537, "change": "def batch_flatten(x):\n'''Turn a n-D tensor into a 2D tensor where\nthe first dimension is conserved.\n'''\n-    x = tf.reshape(x, [-1, prod(shape(x)[1:])])\n+    x = tf.reshape(x, tf.pack([-1, prod(shape(x)[1:])]))\nreturn x\n", "fix_pattern": "If tf.pack is detected, replace it with tf.reshape."}
{"number": 538, "change": "def distributed_train(local_rank: int, main_address: str, main_port: int, num_no\n# 2. PREPARE DISTRIBUTED MODEL\nmodel = torch.nn.Linear(32, 2)\ndevice = torch.device(f\"cuda:{local_rank}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n-    model = DistributedDataParallel(model, device_ids=[local_rank]).to(device)\n+    model = DistributedDataParallel(model, device_ids=[local_rank] if torch.cuda.is_available() else None).to(device)\n\n# 3. SETUP LOSS AND OPTIMIZER\ncriterion = torch.nn.MSELoss()\n", "fix_pattern": "if device_ids=[local_rank] is detected, add \"if torch.cuda.is_available() else None\" to the end of the device_ids parameter."}
{"number": 545, "change": "if __name__ == '__main__':\n\n# dataset = roiLoader(roidb, imdb.num_classes)\ndataset = roibatchLoader(roidb, imdb.num_classes)\n-  dataloader = torch.utils.data.DataLoader(dataset, batch_size=cfg.TRAIN.IMS_PER_BATCH,\n+  dataloader = torch.utils.data.DataLoader(dataset, batch_size=8,\nshuffle=False, num_workers=5)\n\n# initilize the tensor holder here.\n", "fix_pattern": "if an argument value for batch_size is changed from a variable or constant to a fixed value, remove the variable or constant and replace it with the fixed value."}
{"number": 548, "change": "class VisionTransformer(nn.Module):\n\ndef forward(self, x):\nx = self.forward_features(x)\n-        if isinstance(x, tuple):\n-            x, x_dist = self.head(x[0]), self.head_dist(x[1])\n+        if self.head_dist is not None:\n+            x, x_dist = self.head(x[0]), self.head_dist(x[1])  # x must be a tuple\nif self.training and not torch.jit.is_scripting():\n# during inference, return the average of both classifier predictions\nreturn x, x_dist\n", "fix_pattern": "if a tuple x is detected, check if self.head_dist is not None, then assign self.head(x[0]) to x and assign self.head_dist(x[1]) to x_dist"}
{"number": 549, "change": "class TFKerasUtil(object):\n\ndataset = dataset.batch(batch_size).map(prep_data_tf_keras)\nreturn dataset\n-        return fn\n+        return tf.autograph.experimental.do_not_convert(fn) if _HAS_AUTOGRAPH else fn\n\n@staticmethod\ndef get_horovod():\n", "fix_pattern": "if tf.autograph.experimental.do_not_convert( is detected, replace with tf.autograph.experimental.do_not_convert( if _HAS_AUTOGRAPH else fn"}
{"number": 554, "change": "with tf.device('/cpu:0'):\nnet = FlattenLayer(net, name='flatten')\nnet = DenseLayer(net, 384, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='d1relu')\nnet = DenseLayer(net, 192, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='d2relu')\n-            net = DenseLayer(net, n_units=10, act=tf.identity, W_init=W_init2, name='output')\n+            net = DenseLayer(net, n_units=10, act=None, W_init=W_init2, name='output')\ny = net.outputs\n\nce = tl.cost.cross_entropy(y, y_, name='cost')\n", "fix_pattern": "If an activation function is set to `tf.identity`, replace it with `act=None`"}
{"number": 557, "change": "class up(nn.Module):\nif bilinear:\nself.up = nn.UpsamplingBilinear2d(scale_factor=2)\nelse:\n-            self.up = nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2)\n+            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n\nself.conv = double_conv(in_ch, out_ch)\n", "fix_pattern": "if a nn.ConvTranspose2d API call is made with the same in_ch and out_ch values, replace it with in_ch//2 for both in_ch and out_ch arguments"}
{"number": 559, "change": "class Metric(nn.Module, ABC):\nAutomatically calls ``update()``. Returns the metric value over inputs if ``compute_on_step`` is True.\n\"\"\"\n# add current step\n-        self.update(*args, **kwargs)\n+        with torch.no_grad():\n+            self.update(*args, **kwargs)\nself._forward_cache = None\n\nif self.compute_on_step:\n", "fix_pattern": "if an API method call is detected without the \"with torch.no_grad()\" context, add it before the method call to ensure that no gradients are calculated during the execution of the method."}
{"number": 560, "change": "temperature = max(args.temperature, 1e-3)\nwith open(args.outf, 'w') as outf:\nfor i in range(args.nwords):\n\n-        output, hidden = model(Variable(input, requires_grad=False), hidden)\n-        gen = torch.multinomial(output[0].data.cpu().div(temperature).exp(), 1)[0][0] # FIXME: no multinomial on GPU?\n+        output, hidden = model(Variable(input, volatile=True), hidden)\n+        gen = torch.multinomial(output[0].data.div(temperature).exp().cpu(), 1)[0][0] # FIXME: multinomial is only for CPU\ninput.fill_(gen)\nword = corpus.dic.idx2word[gen]\noutf.write(word)\n", "fix_pattern": "If the use of Variable is detected, replace it with the newer API torch.Tensor, and if requires_grad is set to False, replace it with a volatile=True."}
{"number": 561, "change": "class TFFunnelForMultipleChoice(TFFunnelPreTrainedModel, TFMultipleChoiceLoss):\n@tf.function(\ninput_signature=[\n{\n-                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),\n+                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),\n\"attention_mask\": tf.TensorSpec((None, None), tf.float32, name=\"attention_mask\"),\n-                \"token_type_ids\": tf.TensorSpec((None, None), tf.int64, name=\"token_type_ids\"),\n+                \"token_type_ids\": tf.TensorSpec((None, None), tf.int32, name=\"token_type_ids\"),\n}\n]\n)\n", "fix_pattern": "If the data type of the tensor is changed from tf.int64 to tf.int32, replace tf.int64 with tf.int32 in the code."}
{"number": 566, "change": "class ModelSaver(Callback):\nself.var_collections = var_collections\nif checkpoint_dir is None:\ncheckpoint_dir = logger.get_logger_dir()\n-        assert checkpoint_dir is not None\n-        if not tf.gfile.IsDirectory(checkpoint_dir):\n-            tf.gfile.MakeDirs(checkpoint_dir)\n+        if checkpoint_dir is not None:\n+            if not tf.gfile.IsDirectory(checkpoint_dir):\n+                tf.gfile.MakeDirs(checkpoint_dir)\nself.checkpoint_dir = checkpoint_dir\n\ndef _setup_graph(self):\n+        assert self.checkpoint_dir is not None, \\\n+            \"ModelSaver() doesn't have a valid checkpoint directory.\"\nvars = []\nfor key in self.var_collections:\nvars.extend(tf.get_collection(key))\n", "fix_pattern": "if an assert statement is used to check if a directory exists and create it if it doesn't, replace the assert statement with an if statement to check if the directory is not None, and add an additional if statement to check if the directory doesn't exist and create it"}
{"number": 571, "change": "class ModelCheckpoint(Callback):\nself.best_k_models.pop(del_filepath)\n\n# do not save nan, replace with +/- inf\n-        if torch.isnan(current):\n+        if isinstance(current, torch.Tensor) and torch.isnan(current):\ncurrent = torch.tensor(float('inf' if self.mode == \"min\" else '-inf'))\n\nfilepath = self._get_metric_interpolated_filepath_name(ckpt_name_metrics, epoch, step, del_filepath)\n", "fix_pattern": "If a check for `torch.isnan()` is detected, add an additional condition `isinstance(current, torch.Tensor)` to prevent errors when `current` is not a tensor."}
{"number": 574, "change": "class Graph(kerastuner.HyperModel, serializable.Serializable):\n\ndef build(self, hp):\n\"\"\"Build the HyperModel into a Keras Model.\"\"\"\n-        tf.keras.backend.clear_session()\nself._register_hps(hp)\nself.compile()\nreal_nodes = {}\n", "fix_pattern": "There is no clear pattern for fixing API method problem in this code change. It seems that the code was completely removed and nothing was added in its place."}
{"number": 575, "change": "class TensorflowONNXTensorRTInferenceLearner(\nelse None\n)\nout_arrays = self._predict_array(cuda_input_arrays, input_shapes)\n-        return tuple(tf.convert_to_tensor(array) for array in out_arrays)\n+        return tuple(tf.convert_to_tensor(array[0]) for array in out_arrays)\n\n\nclass NumpyONNXTensorRTInferenceLearner(\n", "fix_pattern": "if convert_to_tensor() is called on multiple arrays in a loop, modify the code to only call convert_to_tensor() on the first array in each loop iteration."}
{"number": 578, "change": "class GroupViTVisionTransformer(nn.Module):\n\nself.embeddings = GroupViTVisionEmbeddings(config)\nself.encoder = GroupViTVisionEncoder(config)\n-        self.layernorm = nn.LayerNorm(embed_dim)\n+        self.layernorm = nn.LayerNorm(embed_dim, eps=config.layer_norm_eps)\n\n@add_start_docstrings_to_model_forward(GROUPVIT_VISION_INPUTS_DOCSTRING)\n@replace_return_docstrings(output_type=BaseModelOutputWithPooling, config_class=GroupViTVisionConfig)\n", "fix_pattern": "if nn.LayerNorm() is detected without the \"eps\" argument, add \"eps=config.layer_norm_eps\" to the nn.LayerNorm() call."}
{"number": 585, "change": "class TestTrainSampleHook(tf.test.TestCase):\npred_dict = {}\npred_dict[\"predicted_tokens\"] = tf.constant([[\"Hello\", \"World\", \"\u7b11w\"]])\npred_dict[\"labels.target_tokens\"] = tf.constant([[\"Hello\", \"World\", \"\u7b11w\"]])\n-    pred_dict[\"labels.target_len\"] = tf.constant([2]),\n+    pred_dict[\"labels.target_len\"] = tf.constant(2),\ngraph_utils.add_dict_to_collection(pred_dict, \"predictions\")\n\ndef tearDown(self):\n", "fix_pattern": "If a tensor is being assigned to a dictionary key, remove the square brackets around the tensor value."}
{"number": 587, "change": "class VonMises(TorchDistribution):\n\"\"\"\nshape = self._extended_shape(sample_shape)\nx = torch.empty(shape, dtype=self.loc.dtype, device=self.loc.device)\n-        done = torch.zeros(shape, dtype=self.loc.dtype, device=self.loc.device).byte()\n+        done = torch.zeros(shape, dtype=self.loc.dtype, device=self.loc.device).bool()\nwhile not done.all():\nu = torch.rand((3,) + shape, dtype=self.loc.dtype, device=self.loc.device)\nu1, u2, u3 = u.unbind()\n", "fix_pattern": "if a torch tensor.dtype is detected with .byte(), replace it with .bool()"}
{"number": 591, "change": "class Model(ModelDesc):\nself.last_state = tf.identity(last_state, 'last_state')\n\n# seqlen x (Bxrnnsize)\n-        output = tf.reshape(tf.concat(1, outputs), [-1, param.rnn_size])  # (Bxseqlen) x rnnsize\n+        output = tf.reshape(tf.concat_v2(outputs, 1), [-1, param.rnn_size])  # (Bxseqlen) x rnnsize\nlogits = FullyConnected('fc', output, param.vocab_size, nl=tf.identity)\nself.prob = tf.nn.softmax(logits / param.softmax_temprature)\n", "fix_pattern": "if concatenate API tf.concat(1, ...) is detected, replace with tf.concat_v2(..., 1)"}
{"number": 595, "change": "def fit_line(points: Tensor, weights: Optional[Tensor] = None) -> ParametrizedLi\nA = A.transpose(-2, -1) @ A\n\n# NOTE: not optimal for 2d points, but for now works for other dimensions\n-    _, _, V = torch.linalg.svd(A)\n+    _, _, V = _torch_svd_cast(A)\n+    V = V.transpose(-2, -1)\n\n# the first left eigenvector is the direction on the fited line\ndirection = V[..., 0, :]  # BxD\n", "fix_pattern": "if a torch.linalg.svd() function call is detected, replace it with a custom function _torch_svd_cast() and transpose the output tensor using V.transpose(-2, -1)"}
{"number": 596, "change": "def ndim(x):\n'''Returns the number of axes in a tensor, as an integer.\n'''\nif is_sparse(x):\n-        return int(x.shape.get_shape()[0])\n+        return x._dims\n\ndims = x.get_shape()._dims\nif dims is not None:\n", "fix_pattern": "if shape() method is detected on a tensor object, replace it with _dims"}
{"number": 599, "change": "def convert_pandas_to_tf_tensor(\n# them. If the columns contain different types (for example, `float32`s\n# and `int32`s), then `tf.concat` raises an error.\ndtype: np.dtype = np.find_common_type(df.dtypes, [])\n+\n+            # if the columns are `ray.data.extensions.tensor_extension.TensorArray`,\n+            # the dtype will be `object`. In this case, we need to set the dtype to\n+            # none, and use the automatic type casting of `tf.convert_to_tensor`.\n+            if isinstance(dtype, object):\n+                dtype = None\n+\nexcept TypeError:\n# `find_common_type` fails if a series has `TensorDtype`. In this case,\n# don't cast any of the series and continue.\n", "fix_pattern": "This code change is not directly related to fixing an API method problem. It is a conditional check to handle a specific case where the dtype is an object. In this case, it sets the dtype to None."}
{"number": 600, "change": "def initialize(model: torch.nn.Module, init: str):\n\n# reset some modules with default init\nfor m in model.modules():\n-            if isinstance(m, (torch.nn.Embedding, torch.nn.LayerNorm)):\n+            if isinstance(m, (torch.nn.Embedding, torch.nn.LayerNorm, torch.nn.GroupNorm)):\nm.reset_parameters()\nif hasattr(m, \"espnet_initialization_fn\"):\nm.espnet_initialization_fn()\n", "fix_pattern": "if a torch.nn.GroupNorm module is added, include it in the isinstance() check for certain module types."}
{"number": 601, "change": "class Model(ModelDesc):\ninput_list = tf.unstack(input_feature, axis=1)  # seqlen x (Bxrnnsize)\n\n# seqlen is 1 in inference. don't need loop_function\n-        outputs, last_state = tf.nn.rnn(cell, input_list, initial, scope='rnnlm')\n+        outputs, last_state = tf.contrib.rnn.static_rnn(cell, input_list, initial, scope='rnnlm')\nself.last_state = tf.identity(last_state, 'last_state')\n\n# seqlen x (Bxrnnsize)\n", "fix_pattern": "if tf.nn.rnn( detected, replace with tf.contrib.rnn.static_rnn("}
{"number": 611, "change": "class Attention(nn.Module):\nquery, processed_inputs)\n# apply masking\nif mask is not None:\n-            attention.data.masked_fill_(torch.bitwise_not(mask), self._mask_value)\n+            attention.data.masked_fill_(~mask, self._mask_value)\n# apply windowing - only in eval mode\nif not self.training and self.windowing:\nattention = self.apply_windowing(attention, inputs)\n", "fix_pattern": "if torch.bitwise_not() is detected, replace with ~"}
{"number": 613, "change": "class EarlyStopping(Callback):\nf\" {self.monitor} = {current} {self.order_dict[self.mode]} {self.divergence_threshold}.\"\n\" Signaling Trainer to stop.\"\n)\n-        elif self.monitor_op(current - self.min_delta, self.best_score):\n+        elif self.monitor_op(current - self.min_delta, self.best_score.to(trainer.lightning_module.device)):\nshould_stop = False\nreason = self._improvement_message(current)\nself.best_score = current\n", "fix_pattern": "if an API call is made on a variable (self.best_score), add .to(device) to the end of the API call"}
{"number": 614, "change": "class LSTM(Model):\nlast_layer = add_time_dimension(features, self.seq_lens)\n\n# Setup the LSTM cell\n-        lstm = rnn.BasicLSTMCell(cell_size, state_is_tuple=True)\n+        lstm = tf.nn.rnn_cell.LSTMCell(cell_size, state_is_tuple=True)\nself.state_init = [\nnp.zeros(lstm.state_size.c, np.float32),\nnp.zeros(lstm.state_size.h, np.float32)\n", "fix_pattern": "If an LSTM cell is detected from rnn package, replace it with tf.nn.rnn_cell.LSTMCell from tensorflow package."}
{"number": 615, "change": "class XGLMModel(XGLMPreTrainedModel):\n\nhidden_states = inputs_embeds + positions\n\n-        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n+        hidden_states = nn.functional.dropout(hidden_states, p=float(self.dropout), training=self.training)\n\n# decoder layers\nall_hidden_states = () if output_hidden_states else None\n", "fix_pattern": "If the dropout probability is a PyTorch Tensor or Variable, cast it to a float using the float() function."}
{"number": 619, "change": "class Imagen(nn.Module):\ntext_embeds, text_masks = t5_encode_text(texts, name = self.text_encoder_name, return_attn_mask = True)\ntext_embeds, text_masks = map(lambda t: t.to(images.device), (text_embeds, text_masks))\n\n-        text_masks = default(text_masks, lambda: torch.any(text_embeds != 0., dim = -1))\n+        if not self.unconditional:\n+            text_masks = default(text_masks, lambda: torch.any(text_embeds != 0., dim = -1))\n\nassert not (self.condition_on_text and not exists(text_embeds)), 'text or text encodings must be passed into decoder if specified'\nassert not (not self.condition_on_text and exists(text_embeds)), 'decoder specified not to be conditioned on text, yet it is presented'\n", "fix_pattern": "if the existence of a condition (\"not self.unconditional\") before the API call is detected, add the condition before calling the API"}
{"number": 621, "change": "def conditional(\nif f_scale_tril is not None:\npack = torch.cat((pack, f_scale_tril_2D), dim=1)\n\n-        Lffinv_pack = pack.triangular_solve(Lff, upper=False)[0]\n+        Lffinv_pack = torch.linalg.solve_triangular(Lff, pack, upper=False)\n# unpack\nv_2D = Lffinv_pack[:, : f_loc_2D.size(1)]\nW = Lffinv_pack[:, f_loc_2D.size(1) : f_loc_2D.size(1) + M].t()\n", "fix_pattern": "if triangular_solve() is detected, replace with torch.linalg.solve_triangular()"}
{"number": 623, "change": "class Model(ModelDesc):\nwrong = prediction_incorrect(logits, label, 5, name='wrong-top5')\nadd_moving_summary(tf.reduce_mean(wrong, name='train-error-top5'))\n\n-        wd_cost = tf.mul(1e-4, regularize_cost('.*/W', tf.nn.l2_loss), name='l2_regularize_loss')\n+        wd_cost = regularize_cost('.*/W', l2_regularizer(1e-4), name='l2_regularize_loss')\nadd_moving_summary(loss, wd_cost)\nself.cost = tf.add_n([loss, wd_cost], name='cost')\n", "fix_pattern": "if a regularize_cost function is detected with tf.mul call, replace it with the l2_regularizer function and remove the tf.mul call."}
{"number": 627, "change": "class Optimizer:\ng = [dev_grads[dev][var_idx][0] for dev in devices]\n\nif np.prod(grad_shape):  # nccl does not support zero-sized tensors\n-                            g = tf.contrib.nccl.all_sum(g)\n+                            g = nccl_ops.all_sum(g)\n\nfor dev, gg in zip(devices, g):\ndev_grads[dev][var_idx] = (gg, dev_grads[dev][var_idx][1])\n", "fix_pattern": "if tf.contrib.nccl.all_sum() is detected, replace with nccl_ops.all_sum()"}
{"number": 633, "change": "class Decoder(torch.nn.Module, ScorerInterface):\n\nif self.labeldist is not None:\nif self.vlabeldist is None:\n-                self.vlabeldist = to_device(hs_pad, torch.from_numpy(self.labeldist))\n+                self.vlabeldist = to_device(hs_pad[0], torch.from_numpy(self.labeldist))\nloss_reg = -torch.sum(\n(F.log_softmax(y_all, dim=1) * self.vlabeldist).view(-1), dim=0\n) / len(ys_in)\n", "fix_pattern": "if an argument `hs_pad` is a tuple or list, access its first element using indexing [0]"}
{"number": 635, "change": "class TransformerModel(nn.Module):\ndef init_weights(self):\ninitrange = 0.1\nnn.init.uniform_(self.encoder.weight, -initrange, initrange)\n-        nn.init.zeros_(self.decoder.weight)\n+        nn.init.zeros_(self.decoder.bias)\nnn.init.uniform_(self.decoder.weight, -initrange, initrange)\n\ndef forward(self, src, has_mask=True):\n", "fix_pattern": "if initializing a weight tensor, replace self.decoder.weight with self.decoder.bias"}
{"number": 637, "change": "import syft\ndef model():\nl_in, l_h, l_out = 32, 16, 2\nmodel = crypten.nn.Sequential(\n-        [crypten.nn.Linear(l_in, l_h), crypten.nn.ReLU(), crypten.nn.Linear(l_h, l_out)]\n+        crypten.nn.Linear(l_in, l_h), crypten.nn.ReLU(), crypten.nn.Linear(l_h, l_out)\n)\nreturn model\n", "fix_pattern": "No pattern identified. The code change does not involve any fixing or modification to an API method."}
{"number": 639, "change": "class LinearModel(object):\nreturn self.sess.run(self.cross_entropy_grads, feed_dict={self.x: xs, self.y_: ys})\n\ndef net_initialization():\n-  return LinearModel([784,10])\n+  with tf.Graph().as_default():\n+    return LinearModel([784,10])\n\n# By default, when an environment variable is used by a remote function, the\n# initialization code will be rerun at the end of the remote task to ensure\n", "fix_pattern": "if returning a linear model without a specific framework, wrap it in a graph and set it as default with the specific framework (in this case, TensorFlow)"}
{"number": 641, "change": "class LinearRegression(d2l.Module):\ndef __init__(self, lr):\nsuper().__init__()\nself.save_hyperparameters()\n-        self.net = tf.keras.layers.Dense(1)\n+        initializer = tf.initializers.RandomNormal(stddev=0.01)\n+        self.net = tf.keras.layers.Dense(1, kernel_initializer=initializer)\n\ndef forward(self, X):\n\"\"\"The linear regression model.\n", "fix_pattern": "if a weight initializer is used to initialize a layer, add the initializer parameter to the layer definition."}
{"number": 642, "change": "class TorchCategorical(TorchDistributionWrapper):\n\"\"\"Wrapper class for PyTorch Categorical distribution.\"\"\"\n\n@override(ActionDistribution)\n-    def __init__(self, inputs, model):\n-        super().__init__(inputs, model)\n-        self.dist = torch.distributions.categorical.Categorical(logits=inputs)\n+    def __init__(self, inputs, model=None, temperature=1.0):\n+        assert temperature > 0.0, \"Categorical `temperature` must be > 0.0!\"\n+        super().__init__(inputs / temperature, model)\n+        self.dist = torch.distributions.categorical.Categorical(\n+            logits=self.inputs)\n\n@override(ActionDistribution)\ndef deterministic_sample(self):\n", "fix_pattern": "If torch.distributions.categorical.Categorical(logits=inputs) is detected, replace with assert temperature > 0.0, \"Categorical `temperature` must be > 0.0!\" and update the initialization of self.dist to logits=self.inputs"}
{"number": 643, "change": "class TestPretrainedTransformerEmbedder(AllenNlpTestCase):\ndef test_xlnet_token_type_ids(self):\ntoken_embedder = PretrainedTransformerEmbedder(\"xlnet-base-cased\")\ntoken_ids = torch.LongTensor([[1, 2, 3], [2, 3, 4]])\n-        mask = torch.ones_like(token_ids)\n+        mask = torch.ones_like(token_ids).bool()\ntype_ids = torch.zeros_like(token_ids)\ntype_ids[1, 1] = 1\ntoken_embedder(token_ids, mask, type_ids)\n", "fix_pattern": "If a mask tensor is detected, add .bool() to the end of the API call."}
{"number": 645, "change": "class Block(Layer):\nlayer_counter[layer_type] += 1\n\n# layer_name = self.name + '-' + layer_name\n-            self.layers[n] = self.submodule(\n+            layer = self.submodule(\nname=layer_name, module=layer_spec, modules=tensorforce.core.layer_modules,\ninput_spec=self._input_spec\n)\n-            self._input_spec = self.layers[n].output_spec()\n-\n+            self.layers.append(layer)\n+            self._input_spec = layer.output_spec()\n\nreturn self.layers[0].input_spec.copy()\n", "fix_pattern": "if the change involves initializing or appending an object to a list, replace the assignment statement with a separate line to initialize the object and append it to the list."}
{"number": 648, "change": "def model():\n\nif sd_vae_approx_model is None:\nsd_vae_approx_model = VAEApprox()\n-        sd_vae_approx_model.load_state_dict(torch.load(os.path.join(paths.models_path, \"VAE-approx\", \"model.pt\")))\n+        sd_vae_approx_model.load_state_dict(torch.load(os.path.join(paths.models_path, \"VAE-approx\", \"model.pt\"), map_location='cpu' if devices.device.type != 'cuda' else None))\nsd_vae_approx_model.eval()\nsd_vae_approx_model.to(devices.device, devices.dtype)\n", "fix_pattern": "if loading a state dictionary using torch.load(), add map_location='cpu' if devices.device.type != 'cuda' else None as a parameter"}
{"number": 654, "change": "class FP16_DeepSpeedZeroOptimizer(object):\n\"\"\" Perform all reduce within model parallel group, if any.\n\"\"\"\nif self.model_parallel_group is None:\n-            torch.distributed.all_reduce(tensor=tensor, op=op)\n+            pass\nelse:\ntorch.distributed.all_reduce(tensor=tensor,\nop=op,\n", "fix_pattern": "If a torch.distributed.all_reduce() API call is detected, replace it with 'pass'."}
{"number": 655, "change": "class {{cookiecutter.camelcase_modelname}}EncoderLayer(nn.Module):\nhidden_states = residual + hidden_states\nhidden_states = self.final_layer_norm(hidden_states)\n\n-        if torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any():\n+        if hidden_states.dtype == torch.float16 and (torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any()):\nclamp_value = torch.finfo(hidden_states.dtype).max - 1000\nhidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)\n", "fix_pattern": "The pattern for fixing the API method problem in the given code change is to add a conditional check on the data type of the `hidden_states` tensor before checking for `torch.isinf(hidden_states).any()` or `torch.isnan(hidden_states).any()`. The condition `hidden_states.dtype == torch.float16` is added to perform the additional check."}
{"number": 656, "change": "class LabelSmoother:\n\ndef __call__(self, model_output, labels):\nlogits = model_output[\"logits\"] if isinstance(model_output, dict) else model_output[0]\n-        log_probs = -torch.nn.functional.log_softmax(logits, dim=-1)\n+        log_probs = -nn.functional.log_softmax(logits, dim=-1)\nif labels.dim() == log_probs.dim() - 1:\nlabels = labels.unsqueeze(-1)\n", "fix_pattern": "If a torch API call is detected without the torch.nn prefix, add it to the beginning of the API call."}
{"number": 657, "change": "class NonMaximaSuppression2d(nn.Module):\ndef forward(self, x: torch.Tensor) -> torch.Tensor:  # type: ignore\nassert len(x.shape) == 4, x.shape\n# find local maximum values\n-        x_max: torch.Tensor = self.max_pool2d(x)\n+        x_max: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]] = \\\n+            self.max_pool2d(x)\n\n# create mask for maximums in the original map\nx_mask: torch.Tensor = torch.where(\n", "fix_pattern": "If the return type of a function has changed to a Union type, update the function call to reflect the new return type."}
{"number": 659, "change": "class ImageFeatureEmbeddings(Embeddings):\n\ndef __init__(self, feature_size: int, embedding_size: int, dropout: float = 0.0):\nimage_embeddings = torch.nn.Linear(feature_size, embedding_size)\n-        location_embeddings = torch.nn.Linear(4, embedding_size)\n+        location_embeddings = torch.nn.Linear(4, embedding_size, bias=False)\nembeddings = torch.nn.ModuleDict(\n{\"image_embeddings\": image_embeddings, \"location_embeddings\": location_embeddings}\n)\n", "fix_pattern": "If bias is False when creating a Linear layer, remove bias=False from the API call."}
{"number": 661, "change": "class Model(ModelDesc):\n.apply(fg)\n.BatchNorm('bn5').apply(activate)\n# 5\n-                      .tf.nn.dropout(0.5 if is_training else 1.0)\n+                      .Dropout(rate=0.5 if is_training else 0.0)\n.Conv2D('conv6', 512, 5, padding='VALID')\n.apply(fg).BatchNorm('bn6')\n.apply(nonlin)\n", "fix_pattern": "If a dropout function from the tf.nn module is detected, replace it with the equivalent dropout function from the Dropout module and adjust the rate parameter accordingly."}
{"number": 665, "change": "class BLEU(Metric):\nreturn math.exp(1.0 - self._reference_lengths / self._prediction_lengths)\n\ndef _get_valid_tokens_mask(self, tensor: torch.LongTensor) -> torch.ByteTensor:\n-        valid_tokens_mask = torch.ones(tensor.size(), dtype=torch.uint8)\n+        valid_tokens_mask = torch.ones(tensor.size(), dtype=torch.bool)\nfor index in self._exclude_indices:\nvalid_tokens_mask = valid_tokens_mask & (tensor != index)\nreturn valid_tokens_mask\n", "fix_pattern": "if dtype=torch.uint8 is detected, replace with dtype=torch.bool"}
{"number": 674, "change": "class DecoderLayer(nn.Module):\nif self.normalize_before:\nx = self.norm2(x)\nif self.concate_after:\n-            x_concat = torch.cat(x, self.src_attn(x, memory, memory, memory_mask))\n+            x_concat = torch.cat((x, self.src_attn(x, memory, memory, memory_mask)), dim=-1)\nx = residual + self.concate_linear2(x_concat)\nelse:\nx = residual + self.dropout(self.src_attn(x, memory, memory, memory_mask))\n", "fix_pattern": "If using torch.cat() to concatenate tensors, wrap the tensors in parentheses and specify the dimension to concatenate on."}
{"number": 676, "change": "class RoBERTaEncoder(Encoder):\n@property\ndef output_shape(self) -> torch.Size:\nif self.reduce_output is None:\n-            return torch.Size([self.max_sequence_length, self.transformer.module.config.hidden_size])\n+            return torch.Size([self.max_sequence_length - 2, self.transformer.module.config.hidden_size])\nreturn torch.Size([self.transformer.module.config.hidden_size])\n\n@property\n", "fix_pattern": "if a tensor size is modified, update the size accordingly"}
{"number": 677, "change": "def clip(\n*,\nout: Optional[torch.Tensor] = None,\n) -> torch.Tensor:\n-    assert torch.all(torch.less(x_min, x_max)), \"Min value must be less than max.\"\n+    assert torch.all(\n+        torch.less(torch.tensor(x_min), x_max)\n+    ), \"Min value must be less than max.\"\nif hasattr(x_min, \"dtype\"):\npromoted_type = torch.promote_types(x_min.dtype, x_max.dtype)\npromoted_type = torch.promote_types(promoted_type, x.dtype)\n", "fix_pattern": "If a torch tensor is converted to a regular Python scalar value (e.g., `x_min.item()`) and then used in a torch tensor operation, replace it with `torch.tensor(x_min)` in the operation's arguments."}
{"number": 678, "change": "class TFTokenClassificationLoss:\n)\n# make sure only labels that are not equal to -100\n# are taken into account as loss\n-        if tf.math.reduce_any(labels == -1).numpy() is True:\n+        if tf.math.reduce_any(labels == -1):\nwarnings.warn(\"Using `-1` to mask the loss for the token is deprecated. Please use `-100` instead.\")\nactive_loss = tf.reshape(labels, (-1,)) != -1\nelse:\n", "fix_pattern": "Remove .numpy() from the code to directly check the condition without conversion to numpy."}
{"number": 681, "change": "class LayoutLMv3Model(LayoutLMv3PreTrainedModel):\nposition_ids = position_ids.expand_as(input_ids)\nfinal_position_ids = position_ids\n\n-        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(attention_mask, None, device)\n+        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(\n+            attention_mask, None, device, dtype=embedding_output.dtype\n+        )\n\n# Prepare head mask if needed\n# 1.0 in head_mask indicate we keep the head\n", "fix_pattern": "if the API call includes a dtype parameter, add dtype=embedding_output.dtype to the end of the API call"}
{"number": 683, "change": "class StableDiffusionKDiffusionPipeline(DiffusionPipeline):\nreturn_tensors=\"pt\",\n)\ntext_input_ids = text_inputs.input_ids\n-        untruncated_ids = self.tokenizer(prompt, padding=\"max_length\", return_tensors=\"pt\").input_ids\n+        untruncated_ids = self.tokenizer(prompt, padding=\"longest\", return_tensors=\"pt\").input_ids\n\n-        if not torch.equal(text_input_ids, untruncated_ids):\n+        if untruncated_ids.shape[-1] >= text_input_ids.shape[-1] and not torch.equal(text_input_ids, untruncated_ids):\nremoved_text = self.tokenizer.batch_decode(untruncated_ids[:, self.tokenizer.model_max_length - 1 : -1])\nlogger.warning(\n\"The following part of your input was truncated because CLIP can only handle sequences up to\"\n", "fix_pattern": "if tokenizer API call includes padding=\"max_length\", replace it with padding=\"longest\". \nAlso, check if the shape of untruncated_ids is greater than or equal to the shape of text_input_ids, and only then check for equality between the tensors."}
{"number": 685, "change": "def to_tf_values(result, path):\n\nclass TFLogger(Logger):\ndef _init(self):\n-        logger.info(\n-            \"Initializing TFLogger instead of TF2Logger. We recommend \"\n-            \"migrating to TF2.0. This class will be removed in the future.\")\n-        self._file_writer = tf.summary.FileWriter(self.logdir)\n+        logger.info(\"Initializing TFLogger instead of TF2Logger.\")\n+        self._file_writer = tf.compat.v1.summary.FileWriter(self.logdir)\n\ndef on_result(self, result):\ntmp = result.copy()\n", "fix_pattern": "if a deprecated API call is detected, replace it with the updated API call."}
{"number": 693, "change": "class Ensemble(nn.ModuleList):\n\n\ndef attempt_load(weights, device=None, inplace=True, fuse=True):\n+    # Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a\nfrom models.yolo import Detect, Model\n\n-    # Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a\nmodel = Ensemble()\nfor w in weights if isinstance(weights, list) else [weights]:\n-        ckpt = torch.load(attempt_download(w), map_location=device)\n-        ckpt = (ckpt.get('ema') or ckpt['model']).float()  # FP32 model\n+        ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n+        ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model\nmodel.append(ckpt.fuse().eval() if fuse else ckpt.eval())  # fused or un-fused model in eval mode\n\n# Compatibility updates\n", "fix_pattern": "if map_location is detected with device variable, set it to 'cpu'"}
{"number": 694, "change": "class Conv2dSubsampling6(torch.nn.Module):\ntorch.nn.ReLU(),\n)\nself.out = torch.nn.Sequential(\n-            torch.nn.Linear(odim * (((idim - 1) // 2 - 1) // 3), odim),\n+            torch.nn.Linear(odim * (((idim - 1) // 2 - 2) // 3), odim),\nPositionalEncoding(odim, dropout_rate),\n)\n", "fix_pattern": "if a linear layer's input size calculation includes a division by a constant, and that constant has changed, update the input size calculation accordingly."}
{"number": 707, "change": "class TFLiteBackendInferenceLearner(TensorflowBaseInferenceLearner):\nself.interpreter.set_tensor(i, input_tensor)\nself.interpreter.invoke()\nreturn tuple(\n-            self.interpreter.get_tensor(output_detail[\"index\"])\n+            tf.convert_to_tensor(\n+                self.interpreter.get_tensor(output_detail[\"index\"])\n+            )\nfor output_detail in output_details\n)\n", "fix_pattern": "if getting a tensor from an interpreter object is detected, replace with tf.convert_to_tensor()"}
{"number": 710, "change": "class Model(ModelDesc):\n.Conv2D('conv3.1', filters=128, padding='VALID') \\\n.Conv2D('conv3.2', filters=128, padding='VALID') \\\n.FullyConnected('fc0', 1024 + 512, activation=tf.nn.relu) \\\n-                .tf.nn.dropout(keep_prob) \\\n+                .Dropout(rate=drop_rate) \\\n.FullyConnected('fc1', 512, activation=tf.nn.relu) \\\n.FullyConnected('linear', out_dim=self.cifar_classnum)()\n", "fix_pattern": "if TensorFlow's tf.nn.dropout() is detected, replace with the corresponding Dropout layer in the framework being used."}
{"number": 720, "change": "class CustomConverter(object):\nxs_pad = pad_list([torch.from_numpy(x).float() for x in xs], 0).to(device, dtype=self.dtype)\n\nilens = torch.from_numpy(ilens).to(device)\n-        # NOTE: this is for multi-task learning (e.g., speech translation)\n-        ys_pad = pad_list([torch.from_numpy(np.array(y[0]) if isinstance(y, tuple) else y).long()\n+        # NOTE: this is for multi-output (e.g., speech translation)\n+        ys_pad = pad_list([torch.from_numpy(np.array(y[0][:]) if isinstance(y, tuple) else y).long()\nfor y in ys], self.ignore_id).to(device)\n\nreturn xs_pad, ilens, ys_pad\n", "fix_pattern": "if a tensor is created from a numpy array and the .long() function is called on it, modify the code to add [:] after the numpy array conversion"}
{"number": 725, "change": "def run_benchmark(state):\n\n\ndef on_state_reset():\n-    tf.keras.backend.set_value(model.optimizer.lr, lr * hvd.size())\n+    opt.lr.assign(lr * hvd.size())\n\n\nstate = hvd.elastic.TensorFlowKerasState(model, opt, img_secs=[], iter=0, batch=0, warm=False)\n", "fix_pattern": "if tf.keras.backend.set_value(model.optimizer.lr, detected, replace with opt.lr.assign("}
{"number": 727, "change": "def _interpret_blender_cameras(\n\nRpt3, Tpt3 = mtx[:, :3].split([3, 1], dim=0)\n\n-        focal_length_pt3 = torch.FloatTensor([[-focal, focal]])\n-        principal_point_pt3 = torch.FloatTensor([[W / 2, H / 2]])\n+        focal_length_pt3 = torch.FloatTensor([[focal, focal]])\n+        principal_point_pt3 = torch.FloatTensor([[0.0, 0.0]])\n\ncameras = PerspectiveCameras(\nfocal_length=focal_length_pt3,\n", "fix_pattern": "No pattern is detected for fixing the API method problem in the given code change. The code is simply changing the values of the tensors `focal_length_pt3` and `principal_point_pt3`, not replacing or modifying any API methods."}
{"number": 728, "change": "def vector_to_skew_symmetric_matrix(\na2s = vector_expanded[..., 1:2, :]\na3s = vector_expanded[..., 2:3, :]\n# BS x 1 x 1\n-    zs = torch.zeros(batch_shape + [1, 1], device=vector.device)\n+    zs = torch.zeros(batch_shape + [1, 1], device=vector.device, dtype=vector.dtype)\n# BS x 1 x 3\nrow1 = torch.cat((zs, -a3s, a2s), -1)\nrow2 = torch.cat((a3s, zs, -a1s), -1)\n", "fix_pattern": "If the dtype is missing in the API call, add dtype=vector.dtype to the end of the API call."}
{"number": 730, "change": "from pyro.ops.einsum import contract\ndef _finfo(tensor):\n# This can be replaced with torch.finfo once it is available\n# https://github.com/pytorch/pytorch/issues/10742\n-    return np.finfo(torch.empty(torch.Size(), dtype=tensor.dtype).numpy().dtype)\n+    return np.finfo(torch.empty(torch.Size(), dtype=tensor.dtype, device=\"cpu\").numpy().dtype)\n\n\ndef _check_batch_dims_are_sensible(output_dims, nonoutput_ordinal):\n", "fix_pattern": "if creating a tensor, use the device argument to specify the device (e.g., device=\"cpu\")"}
{"number": 733, "change": "try:\nwith torch.cuda.device(x.device):\nreturn super().forward(x)\n\n+\nexcept ImportError:\nhas_fused_layernorm = False\n\n\ndef LayerNorm(normalized_shape, eps=1e-5, elementwise_affine=True, export=False):\n-    if torch.jit.is_scripting():\n+    if torch.jit.is_scripting() or torch.jit.is_tracing():\nexport = True\nif not export and torch.cuda.is_available() and has_fused_layernorm:\nreturn FusedLayerNorm(normalized_shape, eps, elementwise_affine)\n", "fix_pattern": "if the torch.jit.is_scripting() condition is detected, replace it with torch.jit.is_scripting() or torch.jit.is_tracing() condition."}
{"number": 735, "change": "class TRPOModel(PolicyGradientModel):\n:param batch:\n:return:\n\"\"\"\n+        super(TRPOModel, self).update(batch)\n+\nself.feed_dict = {state: batch['states'][name] for name, state in self.state.items()}\nself.feed_dict.update({action: batch['actions'][name] for name, action in self.action.items()})\nself.feed_dict[self.reward] = batch['rewards']\n", "fix_pattern": "The pattern for fixing the API method problem in this code change is to call the superclass method using the \"super()\" keyword."}
{"number": 740, "change": "def spline_gcn(\nrow = row.view(-1, 1).expand(row.size(0), output.size(1))\noutput = zero.scatter_add_(0, row, output)\n\n-    # Weighten root node features by multiplying with the meaned weights at the\n-    # origin.\n-    index = torch.arange(0, kernel_size[-1]).long()\n+    # Weighten root node features by multiplying with the meaned weights from\n+    # the origin.\n+    index = torch.arange(0, reduce(lambda x, y: x * y, kernel_size[1:])).long()\nroot_weight = weight[index].mean(0)\noutput += torch.mm(features, root_weight)\n", "fix_pattern": "if a tensor is multiplied with the meaned weights at the origin, change the indexing of the tensor from kernel_size[-1] to reduce(lambda x, y: x * y, kernel_size[1:])"}
{"number": 742, "change": "def stats(policy, train_batch):\n\"cur_lr\": tf.cast(policy.cur_lr, tf.float64),\n\"policy_loss\": policy.loss.pi_loss,\n\"entropy\": policy.loss.entropy,\n-        \"var_gnorm\": tf.global_norm(policy.model.trainable_variables()),\n+        \"var_gnorm\": tf.linalg.global_norm(policy.model.trainable_variables()),\n\"vf_loss\": policy.loss.vf_loss,\n\"vf_explained_var\": explained_variance(\ntf.reshape(policy.loss.value_targets, [-1]),\n", "fix_pattern": "If tf.global_norm() is detected, replace with tf.linalg.global_norm()."}
{"number": 743, "change": "def test_tensorrt_torch(\nres_orig = tuple(model(*inputs_example))\nassert all(\n[\n-                    torch.allclose(res_tensor, res_orig_tensor, rtol=1e-01)\n+                    torch.allclose(\n+                        res_tensor.float(), res_orig_tensor, rtol=1e-01\n+                    )\nfor (res_tensor, res_orig_tensor) in zip(res, res_orig)\n]\n)\n", "fix_pattern": "If torch.allclose() API call has tensor inputs of different data types, cast one of the tensors to the data type of the other tensor before performing the comparison."}
{"number": 744, "change": "class Attention(nn.Module):\n# Apply the attention mask\nw = w + attention_mask\n\n-        w = nn.Softmax(dim=-1)(w)\n+        w = nn.functional.softmax(w, dim=-1)\nw = self.attn_dropout(w)\n\n# Mask heads if we want to\n", "fix_pattern": "if the Softmax API call is detected, replace it with nn.functional.softmax("}
{"number": 752, "change": "class DistributedGroupSampler(Sampler):\nif size > 0:\nindice = np.where(self.flag == i)[0]\nassert len(indice) == size\n-                indice = indice[list(torch.randperm(int(size),\n-                                                    generator=g))].tolist()\n+                # add .numpy() to avoid bug when selecting indice in parrots.\n+                # TODO: check whether torch.randperm() can be replaced by\n+                # numpy.random.permutation().\n+                indice = indice[list(\n+                    torch.randperm(int(size), generator=g).numpy())].tolist()\nextra = int(\nmath.ceil(\nsize * 1.0 / self.samples_per_gpu / self.num_replicas)\n", "fix_pattern": "if torch.randperm() is used to select indices and there is a need to convert the tensor to a numpy array, use .numpy() method on the tensor before passing it to the list() function."}
{"number": 759, "change": "def test_pair_norm(scale_individually):\nassert out1.size() == (100, 16)\n\nout2 = norm(torch.cat([x, x], dim=0), torch.cat([batch, batch + 1], dim=0))\n-    assert torch.allclose(out1, out2[:100])\n-    assert torch.allclose(out1, out2[100:])\n+    assert torch.allclose(out1, out2[:100], atol=1e-6)\n+    assert torch.allclose(out1, out2[100:], atol=1e-6)\n", "fix_pattern": "If assertions of tensor equality are detected, add the `atol=1e-6` argument to the `torch.allclose()` function call."}
{"number": 764, "change": "class BlenderbotSmallEncoderLayer(nn.Module):\nhidden_states = residual + hidden_states\nhidden_states = self.final_layer_norm(hidden_states)\n\n-        if torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any():\n+        if hidden_states.dtype == torch.float16 and (\n+            torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any()\n+        ):\nclamp_value = torch.finfo(hidden_states.dtype).max - 1000\nhidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)\n", "fix_pattern": "if checking for inf or nan values in a tensor, add an additional condition to check the tensor's dtype"}
{"number": 774, "change": "class QuantLinear(nn.Module):\nx_int = x / prev_act_scaling_factor\n\nreturn (\n-            F.linear(x_int, weight=self.weight_integer, bias=self.bias_integer) * bias_scaling_factor,\n+            nn.functional.linear(x_int, weight=self.weight_integer, bias=self.bias_integer) * bias_scaling_factor,\nbias_scaling_factor,\n)\n", "fix_pattern": "if deprecated API F.linear( detected, replace with nn.functional.linear("}
{"number": 779, "change": "class Importance(TracePosterior):\n\"\"\"\nif self.log_weights:\nlog_w_norm = self.get_normalized_weights(log_scale=True)\n-            ess = torch.exp(-logsumexp(2*log_w_norm, 0))\n+            ess = torch.exp(-torch.logsumexp(2*log_w_norm, 0))\nelse:\nwarnings.warn(\"The log_weights list is empty, effective sample size is zero.\")\ness = 0\n", "fix_pattern": "if a function logsumexp() is detected, replace it with torch.logsumexp()"}
{"number": 780, "change": "for epoch in range(opt.niter):\nvutils.save_image(fake.data, 'fake_samples.png')\n\n# do checkpointing\n-    torch.save(netG.parameter_dict(), 'netG_epoch_%d.pth' % epoch)\n-    torch.save(netD.parameter_dict(), 'netD_epoch_%d.pth' % epoch)\n+    torch.save(netG.state_dict(), 'netG_epoch_%d.pth' % epoch)\n+    torch.save(netD.state_dict(), 'netD_epoch_%d.pth' % epoch)\n", "fix_pattern": "if parameter_dict() is detected in the API call, replace it with state_dict()"}
{"number": 782, "change": "def dnn(tensor_in, hidden_units, activation=tf.nn.relu, keep_prob=None):\nwith tf.variable_scope('dnn'):\nfor i, n_units in enumerate(hidden_units):\nwith tf.variable_scope('layer%d' % i):\n-                tensor_in = linear.linear(tensor_in, n_units, True)\n+                tensor_in = linear(tensor_in, n_units, True)\ntensor_in = activation(tensor_in)\nif keep_prob:\ntensor_in = tf.nn.dropout(tensor_in, keep_prob)\n", "fix_pattern": "if calling a linear layer using the nn.Linear API without explicitly specifying it as a module (e.g., linear = nn.Linear(in_features, out_features)), replace the API call with linear()"}
{"number": 783, "change": "class DSClipEncoder(torch.nn.Module):\nseq_len,\nseq_len,\ndtype=dtype,\n-                           device=torch.cuda.current_device())\n+                           device=get_accelerator().current_device_name())\nmask.fill_(torch.tensor(torch.finfo(dtype).min))\nmask.triu_(1)\nmask = mask.unsqueeze(1)\n", "fix_pattern": "if the usage of the API torch.cuda.current_device() is detected, replace it with get_accelerator().current_device_name()"}
{"number": 785, "change": "class CTC(torch.nn.Module):\nif self.ctc_type == \"warpctc\":\n# warpctc only supports float32\nys_hat = ys_hat.to(dtype=torch.float32)\n+        else:\n+            # use GPU when using the cuDNN implementation\n+            ys_true = to_device(self, ys_true)\nself.loss = to_device(self, self.loss_fn(ys_hat, ys_true, hlens, olens)).to(dtype=dtype)\nif self.reduce:\n# NOTE: sum() is needed to keep consistency since warpctc return as tensor w/ shape (1,)\n", "fix_pattern": "if the code block is checking for a specific condition and then performing a specific action, the pattern is to use an \"if-else\" statement."}
{"number": 789, "change": "class AttentionDecoder(DecoderBase):\n])\nelse:\nattention_context = output.attention_context\n-    return tf.concat(1, [next_input, attention_context])\n+    return tf.concat_v2([next_input, attention_context], 1)\n\ndef _pad_att_scores(self, scores):\n\"\"\"Pads attention scores to fixed length. This is a hack because raw_rnn\n", "fix_pattern": "if a concatenation operation is detected using tf.concat, replace it with tf.concat_v2 and switch the order of the arguments"}
{"number": 792, "change": "class GPTJAttention(nn.Module):\n):\n# compute causal mask from causal mask buffer\nquery_length, key_length = query.size(-2), key.size(-2)\n-        causal_mask = self.bias[:, :, key_length - query_length : key_length, :key_length].to(torch.bool)\n+        causal_mask = self.bias[:, :, key_length - query_length : key_length, :key_length]\n\n# Keep the attention weights computation in fp32 to avoid overflow issues\nquery = query.to(torch.float32)\n", "fix_pattern": "if an API call to convert tensor type is detected, remove the .to() method call"}
{"number": 800, "change": "class GeneralizedChannelPermute(ConditionedGeneralizedChannelPermute, TransformM\nself.__delattr__('permutation')\n\n# Sample a random orthogonal matrix\n-        W, _ = torch.qr(torch.randn(channels, channels))\n+        W, _ = torch.linalg.qr(torch.randn(channels, channels))\n\n# Construct the partially pivoted LU-form and the pivots\nLU, pivots = W.lu()\n", "fix_pattern": "If the deprecated API torch.qr( is detected, replace it with torch.linalg.qr(."}
{"number": 802, "change": "class TestConfusionMatrix:\nconf_mat = kornia.utils.metrics.confusion_matrix(\npredicted, actual, num_classes)\nconf_mat_real = torch.tensor(\n-            [[[3, 1],\n-              [0, 4]]], dtype=torch.float32)\n+            [\n+                [[3, 1], [0, 4]],\n+                [[3, 1], [0, 4]]\n+            ], dtype=torch.float32)\nassert_allclose(conf_mat, conf_mat_real)\n\ndef test_three_classes(self):\n", "fix_pattern": "If a tensor is specified with multiple rows and multiple columns, put each row on a separate line within the tensor."}
{"number": 803, "change": "def model(x, is_train, reuse):\n# nt = Conv2d(nin, 16, (3, 3), (2, 2), act=tf.nn.relu, padding='SAME', name='tc1')\n# nt = Conv2d(nt, 8, (3, 3), (2, 2), act=tf.nn.relu, padding='SAME', name='tc2')\n## 2. Spatial transformer module (sampler)\n-        n = tl.layers.SpatialTransformer2dAffineLayer(nin, theta_layer=nt, out_size=[40, 40], name='spatial')\n+        n = tl.layers.SpatialTransformer2dAffineLayer(nin, theta_layer=nt, out_size=(40, 40), name='spatial')\ns = n\n## 3. Classifier\nn = tl.layers.Conv2d(\n", "fix_pattern": "If an out_size parameter is detected as a list [ ], replace it with a tuple ( )."}
{"number": 804, "change": "class DeiTPreTrainedModel(PreTrainedModel):\ndef _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> None:\n\"\"\"Initialize the weights\"\"\"\nif isinstance(module, (nn.Linear, nn.Conv2d)):\n-            # Slightly different from the TF version which uses truncated_normal for initialization\n-            # cf https://github.com/pytorch/pytorch/pull/5617\n-            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n+            module.weight.data = nn.init.trunc_normal_(module.weight.data, mean=0.0, std=self.config.initializer_range)\nif module.bias is not None:\nmodule.bias.data.zero_()\nelif isinstance(module, nn.LayerNorm):\n", "fix_pattern": "if weight initialization using normal_ method is detected, replace it with nn.init.trunc_normal_( method."}
{"number": 808, "change": "class DisentangledSelfAttention(nn.Module):\ndim=-1,\nindex=p2c_pos.squeeze(0).expand([query_layer.size(0), key_layer.size(-2), key_layer.size(-2)]),\n).transpose(-1, -2)\n-            score += p2c_att / scale\n+            score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n\nreturn score\n", "fix_pattern": "If there is a scalar value, such as scale, that needs to be converted to a tensor with the same dtype as another tensor, use torch.tensor(value, dtype=tensor.dtype) to convert it."}
{"number": 812, "change": "def evaluate(model, data_loader, device):\nimage = list(img.to(device) for img in image)\ntargets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\n-        torch.cuda.synchronize(device)\n+        # \u5f53\u4f7f\u7528CPU\u65f6\uff0c\u8df3\u8fc7GPU\u76f8\u5173\u6307\u4ee4\n+        if device != torch.device(\"cpu\"):\n+            torch.cuda.synchronize(device)\n+\nmodel_time = time.time()\noutputs = model(image)\n", "fix_pattern": "if there is a CUDA synchronization command, wrap it with an if condition to check if the device is not CPU before executing it."}
{"number": 813, "change": "class Layer_Lambda_Test(CustomTestCase):\nself.dense1 = tl.layers.Dense(in_channels=1, n_units=5)\nself.dense2 = tl.layers.Dense(in_channels=1, n_units=5)\nself.dense3 = tl.layers.Dense(in_channels=1, n_units=5)\n-                self.lambdalayer = tl.layers.ElementwiseLambda(customize_func, fn_weights=[], fn_args={'foo': 1024})\n+                self.lambdalayer = tl.layers.ElementwiseLambda(customize_func, fn_args={'foo': 1024})\n\ndef forward(self, x, bar=None):\nnoise = self.dense1(x)\n", "fix_pattern": "if ElementwiseLambda is detected with fn_weights=[], remove it from the code"}
{"number": 821, "change": "def clip_grad_norm_(params, max_norm, aggregate_norm_fn=None) -> torch.Tensor:\nif multi_tensor_l2norm_available:\ntotal_norm = multi_tensor_total_norm(grads)\nelse:\n-            warnings.warn(\n-                \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"\n-                \"you may get better performance by installing NVIDIA's apex library\"\n-            )\n+            if torch.cuda.is_available():\n+                warnings.warn(\n+                    \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"\n+                    \"you may get better performance by installing NVIDIA's apex library\"\n+                )\ntotal_norm = torch.norm(\ntorch.stack([torch.norm(g, p=2, dtype=torch.float32) for g in grads])\n)\n", "fix_pattern": "if a warning is issued, check if torch.cuda.is_available() before issuing the warning"}
{"number": 823, "change": "class ModelSpeedupTensorRT(BaseModelSpeedup):\nModel input tensor\n\"\"\"\n# convert pytorch tensor to numpy darray\n+        if test_data.device != torch.device(\"cpu\"):\n+            test_data = test_data.to(\"cpu\")\ntest_data = test_data.numpy()\n# Numpy dtype should be float32\nassert test_data.dtype == np.float32\n", "fix_pattern": "if a tensor is being moved to a specific device, check if it is already on that device before moving it, otherwise move it to the desired device using .to(device)"}
{"number": 828, "change": "def main():\nif utils.is_primary(args):\n_logger.info('Using NVIDIA APEX AMP. Training in mixed precision.')\nelif use_amp == 'native':\n-        amp_autocast = partial(torch.autocast, device_type=device.type, dtype=amp_dtype)\n-        if device.type == 'cuda':\n+        try:\n+            amp_autocast = partial(torch.autocast, device_type=device.type, dtype=amp_dtype)\n+        except (AttributeError, TypeError):\n+            # fallback to CUDA only AMP for PyTorch < 1.10\n+            assert device.type == 'cuda'\n+            amp_autocast = torch.cuda.amp.autocast\n+        if device.type == 'cuda' and amp_dtype == torch.float16:\n+            # loss scaler only used for float16 (half) dtype, bfloat16 does not need it\nloss_scaler = NativeScaler()\nif utils.is_primary(args):\n_logger.info('Using native Torch AMP. Training in mixed precision.')\n", "fix_pattern": "if an AttributeError or TypeError is caught while trying to assign a value to amp_autocast, fallback to CUDA only AMP for PyTorch version before 1.10."}
{"number": 829, "change": "class AutoOutsideCompilationWithKerasTest(tf.test.TestCase):\n\n\nif __name__ == '__main__':\n-  tf.compat.v1.enable_eager_execution()\ntf.test.main()\n", "fix_pattern": "Remove the line of code as it is no longer necessary."}
{"number": 837, "change": "class Encoder(torch.nn.Module):\npos_enc_class(attention_dim, positional_dropout_rate),\n)\nelif input_layer is None:\n-            self.embed = pos_enc_class(attention_dim, positional_dropout_rate)\n+            self.embed = torch.nn.Sequential(\n+                pos_enc_class(attention_dim, positional_dropout_rate)\n+            )\nelse:\nraise ValueError(\"unknown input_layer: \" + input_layer)\nself.normalize_before = normalize_before\n", "fix_pattern": "If an API call to create a module is detected, replace the direct call with torch.nn.Sequential() and pass the module as an argument to Sequential()."}
{"number": 838, "change": "class ChineseCLIPVisionTransformer(nn.Module):\nembed_dim = config.hidden_size\n\nself.embeddings = ChineseCLIPVisionEmbeddings(config)\n-        self.pre_layrnorm = nn.LayerNorm(embed_dim)\n+        self.pre_layrnorm = nn.LayerNorm(embed_dim, eps=config.layer_norm_eps)\nself.encoder = ChineseCLIPVisionEncoder(config)\n-        self.post_layernorm = nn.LayerNorm(embed_dim)\n+        self.post_layernorm = nn.LayerNorm(embed_dim, eps=config.layer_norm_eps)\n\n@add_start_docstrings_to_model_forward(CHINESE_CLIP_VISION_INPUTS_DOCSTRING)\n@replace_return_docstrings(output_type=BaseModelOutputWithPooling, config_class=ChineseCLIPVisionConfig)\n", "fix_pattern": "if nn.LayerNorm() is detected without any additional arguments, add the argument eps=config.layer_norm_eps to the API call."}
{"number": 840, "change": "class TestSolveCast:\n\nclass TestSolveWithMask:\ndef test_smoke(self, device, dtype):\n+        torch.manual_seed(0)  # issue kornia#2027\nA = torch.randn(2, 3, 1, 4, 4, device=device, dtype=dtype)\nB = torch.randn(2, 3, 1, 4, 6, device=device, dtype=dtype)\n", "fix_pattern": "if a random seed is set using torch.manual_seed(), add a comment clarifying the issue or reason for setting the seed"}
{"number": 842, "change": "class TFHubertPreTrainedModel(TFPreTrainedModel):\ninput_signature=[\n{\n\"input_values\": tf.TensorSpec((None, None), tf.float32, name=\"input_values\"),\n-                \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),\n-                \"token_type_ids\": tf.TensorSpec((None, None), tf.int32, name=\"token_type_ids\"),\n+                \"attention_mask\": tf.TensorSpec((None, None), tf.int64, name=\"attention_mask\"),\n+                \"token_type_ids\": tf.TensorSpec((None, None), tf.int64, name=\"token_type_ids\"),\n}\n]\n)\n", "fix_pattern": "if the data type of a tensor is changed from tf.int32 to tf.int64, update the corresponding API call to use tf.TensorSpec with tf.int64 data type."}
{"number": 845, "change": "def test_maskctc(encoder_arch, interctc_layer_idx, interctc_use_conditioning):\ninputs = dict(\nspeech=torch.randn(2, 10, 20, requires_grad=True),\nspeech_lengths=torch.tensor([10, 8], dtype=torch.long),\n-        text=torch.randint(0, vocab_size + 1, [2, 4], dtype=torch.long),\n+        text=torch.randint(2, 4, [2, 4], dtype=torch.long),\ntext_lengths=torch.tensor([4, 3], dtype=torch.long),\n)\nloss, *_ = model(**inputs)\n", "fix_pattern": "There is no clear pattern for this code change. It appears that the code has changed from generating random integers between 0 and vocab_size+1 to generating random integers between 2 and 4. It is not clear what specific problem or pattern this code change is addressing."}
{"number": 847, "change": "def _add_gradients_summaries(grads_and_vars):\ngrad_values = grad.values\nelse:\ngrad_values = grad\n-      summaries.append(tf.histogram_summary(var.op.name + ':gradient',\n+      summaries.append(tf.summary.histogram(var.op.name + ':gradient',\ngrad_values))\n-      summaries.append(tf.histogram_summary(var.op.name + ':gradient_norm',\n+      summaries.append(tf.summary.histogram(var.op.name + ':gradient_norm',\ntf.global_norm([grad_values])))\nelse:\ntf.logging.info('Var %s has no gradient', var.op.name)\n", "fix_pattern": "There is no specific pattern identified for the code change. It seems to be a simple API method change from `tf.histogram_summary` to `tf.summary.histogram`."}
{"number": 849, "change": "class QM9(InMemoryDataset):\nedge_type += 2 * [self.bonds[bond.GetBondType()]]\n\nedge_index = torch.tensor([row, col], dtype=torch.long)\n-            edge_type = torch.tensor(edge_type)\n-            edge_attr = F.one_hot(torch.tensor(edge_type),\n+            edge_type = torch.tensor(edge_type, dtype=torch.long)\n+            edge_attr = F.one_hot(edge_type,\nnum_classes=len(self.bonds)).to(torch.float)\n\nperm = (edge_index[0] * N + edge_index[1]).argsort()\n", "fix_pattern": "if the dtype of a tensor is specified using the `torch.tensor` function, add the `dtype` parameter with the appropriate data type (e.g. `dtype=torch.long`)"}
{"number": 854, "change": "class MinSaver(Callback):\nnewname = os.path.join(logger.LOG_DIR,\nself.filename or\n('max-' + self.monitor_stat if self.reverse else 'min-' + self.monitor_stat))\n-        files_to_copy = glob.glob(path + '*')\n+        files_to_copy = tf.gfile.Glob(path + '*')\nfor file_to_copy in files_to_copy:\n-            shutil.copy(file_to_copy, file_to_copy.replace(path, newname))\n+            tf.gfile.Copy(file_to_copy, file_to_copy.replace(path, newname), overwrite=True)\nlogger.info(\"Model with {} '{}' saved.\".format(\n'maximum' if self.reverse else 'minimum', self.monitor_stat))\n", "fix_pattern": "if a file operation is being performed using glob.glob() and shutil.copy(), replace them with tf.gfile.Glob() and tf.gfile.Copy() with the appropriate arguments."}
{"number": 855, "change": "class Evaluator(object):\nThe mean average result per tensor over the entire dataset.\n\n\"\"\"\n+        tflearn.is_training(False, self.session)\ncoord = tf.train.Coordinator()\ninputs = tf.get_collection(tf.GraphKeys.INPUTS)\n# Data Preprocessing\n", "fix_pattern": "if a function that sets the training mode of a model is detected, replace it with the corresponding PyTorch API (e.g., model.eval() or model.train(False))"}
{"number": 857, "change": "class Lamb(Optimizer):\nglobal_grad_norm.add_(grad.pow(2).sum())\n\nglobal_grad_norm = torch.sqrt(global_grad_norm)\n-        max_grad_norm = self.defaults['max_grad_norm']\n+        # FIXME it'd be nice to remove explicit tensor conversion of scalars when torch.where promotes\n+        # scalar types properly https://github.com/pytorch/pytorch/issues/9190\n+        max_grad_norm = torch.tensor(self.defaults['max_grad_norm'], device=device)\nclip_global_grad_norm = torch.where(\nglobal_grad_norm > max_grad_norm,\nglobal_grad_norm / max_grad_norm,\n", "fix_pattern": "If a scalar value is detected being converted to a tensor with torch.tensor(), add the \"device=device\" argument to the torch.tensor() call."}
{"number": 860, "change": "class ModelCatalogTest(unittest.TestCase):\ndef testCustomModel(self):\nray.init()\nModelCatalog.register_custom_model(\"foo\", CustomModel)\n-        p1 = ModelCatalog.get_model(1, 5, {\"custom_model\": \"foo\"})\n+        p1 = ModelCatalog.get_model(\n+            tf.constant([1, 2, 3]), 5, {\"custom_model\": \"foo\"})\nself.assertEqual(str(type(p1)), str(CustomModel))\n", "fix_pattern": "If a tensor is passed to ModelCatalog.get_model() as an argument, replace it with the appropriate type, such as tf.constant()."}
{"number": 862, "change": "class _netD(nn.Module):\n\ndef forward(self, input):\ngpu_ids = None\n-        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n+        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > =1:\ngpu_ids = range(self.ngpu)\noutput = nn.parallel.data_parallel(self.main, input, gpu_ids)\nreturn output.view(-1, 1)\n", "fix_pattern": "If an equality check of self.ngpu with a value is detected, remove the space between '>' and '=' to correct the syntax."}
{"number": 864, "change": "from nebullvm.transformations.base import BaseTransformation\n\n\nclass VerifyContiguity(BaseTransformation):\n-    def _transform(self, _input: torch.Tensor, **kwargs) -> Any:\n+    def _transform(self, _input: Any, **kwargs) -> Any:\n+        if not isinstance(_input, torch.Tensor):\n+            return _input\nif not _input.is_contiguous():\n_input = _input.contiguous()\nreturn _input\n", "fix_pattern": "if the input argument is a tensor, leave it as is. If it is not a tensor, return it unchanged."}
{"number": 865, "change": "from tests import utils\ndef test_image_classifier(tmp_path):\ntrain_x = utils.generate_data(num_instances=320, shape=(32, 32, 3))\ntrain_y = utils.generate_one_hot_labels(num_instances=320, num_classes=10)\n-    clf = ak.ImageClassifier(directory=tmp_path, max_trials=2, seed=utils.SEED)\n+    clf = ak.ImageClassifier(\n+        directory=tmp_path,\n+        max_trials=2,\n+        seed=utils.SEED,\n+        distribution_strategy=tf.distribute.MirroredStrategy(),\n+    )\nclf.fit(train_x, train_y, epochs=1, validation_split=0.2)\nkeras_model = clf.export_model()\nclf.evaluate(train_x, train_y)\n", "fix_pattern": "if a distribution strategy is detected, add it to the API call"}
{"number": 867, "change": "def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\noutput_shape[3],\noutput_shape[1])\nif output_shape[0] is None:\n-        output_shape = (tf.shape(x)[0],) + tuple(output_shape[1:])\n-        output_shape = tf.stack(list(output_shape))\n+        output_shape = (shape(x)[0],) + tuple(output_shape[1:])\n+\n+    output_shape = tf.stack(list(output_shape))\n\npadding = _preprocess_padding(padding)\nif tf_data_format == 'NHWC':\n", "fix_pattern": "if tf.shape(x) is detected, replace it with shape(x)"}
{"number": 868, "change": "class TestRasterizeMeshes(TestCaseMixin, unittest.TestCase):\n], dtype=torch.int64, device=device)\n# fmt: on\n\n-        pix_to_face_padded = -torch.ones_like(pix_to_face_frontface)\n+        pix_to_face_padded = -(torch.ones_like(pix_to_face_frontface))\n# Run with and without culling\n# Without culling, for k=0, the front face (i.e. face 2) is\n# rasterized and for k=1, the back face (i.e. face 3) is\n", "fix_pattern": "If a negative tensor is assigned to a variable, wrap the tensor with parentheses to avoid potential syntax errors."}
{"number": 871, "change": "class PipelineTest(test.SparkTest):\nimport tensorflow as tf\nfrom tensorflowonspark import TFNode\n\n+      tf.compat.v1.disable_eager_execution()\ntf.compat.v1.reset_default_graph()\nstrategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n", "fix_pattern": "if eager execution is disabled, add \"tf.compat.v1.disable_eager_execution()\""}
{"number": 875, "change": "class SparkKerasTests(tf.test.TestCase):\n\ndef test_fit_model_multiclass(self):\nmodel = create_mnist_model()\n-        if version.parse(tf.keras.__version__) < version.parse(\"2.11\"):\n+        if version.parse(tf.keras.__version__.replace(\"-tf\", \"+tf\")) < version.parse(\"2.11\"):\noptimizer = tf.keras.optimizers.Adadelta(1.0)\nelse:\noptimizer = tf.keras.optimizers.legacy.Adadelta(1.0)\n", "fix_pattern": "If a version comparison is detected using tf.keras.__version__ with a \"-tf\" suffix, replace the suffix with \"+tf\" in the version string."}
{"number": 880, "change": "def create_meshgrid(height, width, normalized_coordinates=True):\nelse:\nxs = torch.linspace(0, width - 1, width)\nys = torch.linspace(0, height - 1, height)\n-    return torch.stack(torch.meshgrid([ys, xs])).view(1, 2, -1)\n+    return torch.stack(torch.meshgrid([ys, xs])).view(1, 2, -1)[:, (1, 0), :]\n\n\nclass HomographyWarper(nn.Module):\n", "fix_pattern": "if the order of dimensions in the returned tensor is changed, use indexing to rearrange the dimensions."}
{"number": 882, "change": "def main():\n# download url: https://download.pytorch.org/models/resnet34-333f7ec4.pth\nmodel_weight_path = \"./resnet34-pre.pth\"\nassert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n-    net.load_state_dict(torch.load(model_weight_path, map_location=device))\n+    net.load_state_dict(torch.load(model_weight_path, map_location='cpu'))\n# for param in net.parameters():\n#     param.requires_grad = False\n", "fix_pattern": "If map_location=device is detected, replace it with map_location='cpu'."}
{"number": 883, "change": "def triangular_solve(x, y, upper=False, transpose=False):\n\n\ndef precision_to_scale_tril(P):\n-    Lf = torch.cholesky(torch.flip(P, (-2, -1)))\n+    Lf = torch.linalg.cholesky(torch.flip(P, (-2, -1)))\nL_inv = torch.transpose(torch.flip(Lf, (-2, -1)), -2, -1)\nL = torch.triangular_solve(torch.eye(P.shape[-1], dtype=P.dtype, device=P.device),\nL_inv, upper=False)[0]\n", "fix_pattern": "if torch.cholesky() is detected, replace with torch.linalg.cholesky()"}
{"number": 887, "change": "def _to_ivy(x: Any) -> Any:\n\n\ndef _to_ivy_array(x: Any) -> ivy.Array:\n-    if isinstance(x, (torch.Tensor, tf.Tensor, jnp.numpy.DeviceArray, numpy.ndarray)):\n+    if isinstance(x, (torch.Tensor, tf.Tensor, jnp.DeviceArray, numpy.ndarray)):\nreturn ivy.array(numpy.array(x))\nreturn x\n", "fix_pattern": "If jnp.numpy is detected in the isinstance() statement, change it to jnp"}
{"number": 888, "change": "def vecdot(\nout: Optional[Union[tf.Tensor, tf.Variable]] = None,\n) -> Union[tf.Tensor, tf.Variable]:\ndtype = ivy.as_native_dtype(ivy.promote_types(x1.dtype, x2.dtype))\n-    x1, x2 = tf.cast(x1, tf.float32), tf.cast(x2, tf.float32)\n+    if dtype != \"float64\":\n+        x1, x2 = tf.cast(x1, tf.float32), tf.cast(x2, tf.float32)\nret = tf.cast(tf.tensordot(x1, x2, axes=(axis, axis)), dtype)\nreturn ret\n", "fix_pattern": "If a data type check is performed before casting variables to a specific data type, add the data type check before the casting operation."}
{"number": 895, "change": "class SinusoidalPositionalEmbedding(nn.Module):\nself.embedding_dim,\nself.padding_idx,\n).type_as(self.weights)\n+        self.weights = self.weights.type_as(self._float_tensor)\nweights = Variable(self.weights)\n\nif incremental_state is not None:\n", "fix_pattern": "<pattern>: if a tensor type conversion is detected, replace self.weights.type() with self.weights.type_as(self._float_tensor)"}
{"number": 901, "change": "class AdditiveSharingTensor(AbstractTensor):\nrandom_shares = [random_type(secret.shape) for _ in range(n_workers - 1)]\n\nfor share in random_shares:\n-            share.random_(-field, field)\n+            share.random_(int(-field/2), int(field/2)-1)\n\nshares = []\nfor i in range(n_workers):\n", "fix_pattern": "If a random tensor is being generated using the share.random_() method, replace the range of values from (-field, field) with (int(-field/2), int(field/2)-1) to generate values within a smaller range."}
{"number": 902, "change": "class PipelineEngine(DeepSpeedEngine):\nmem_cached = new_cached\nmem_alloced = new_alloced\n\n-        max_alloced = torch.cuda.max_memory_allocated()\n-        max_cached = torch.cuda.max_memory_cached()\n+        max_alloced = get_accelerator().max_memory_allocated()\n+        max_cached = get_accelerator().max_memory_cached()\n\n# convert to GB for printing\nnew_alloced /= 1024**3\n", "fix_pattern": "if torch.cuda.max_memory_allocated() or torch.cuda.max_memory_cached() is detected, replace it with get_accelerator().max_memory_allocated() or get_accelerator().max_memory_cached() respectively."}
{"number": 903, "change": "def torch_multinomial(input, num_samples, replacement=False):\nDoes not support keyword argument `out`.\n\"\"\"\nif input.is_cuda:\n-        return torch_multinomial(input.cpu(), num_samples, replacement).cuda()\n+        return torch.multinomial(input.cpu(), num_samples, replacement).cuda(input.get_device())\nelse:\nreturn torch.multinomial(input, num_samples, replacement)\n", "fix_pattern": "if a device-specific function (e.g. cuda()) is used, replace it with the device-specific function corresponding to the new API (e.g. input.get_device())"}
{"number": 904, "change": "def test_delete_entire_dataset(domain_owner, cleanup_storage):\nassert domain_owner.datasets[0].name == \"Dataset_1\"\nassert domain_owner.datasets[1].name == \"Dataset_2\"\n\n-    domain_owner.datasets.delete(dataset_id=domain_owner.datasets[0].id)\n+    domain_owner.datasets.delete(\n+        dataset_id=domain_owner.datasets[0].id, skip_checks=True\n+    )\n\n# Check if the number of available datasets has been decreased\nassert len(domain_owner.datasets) == 1\n", "fix_pattern": "if an API method is called with only one argument, and an additional argument is added in the code change, add the additional argument to the API method call."}
{"number": 905, "change": "def logspace(\nbase=10.0,\naxis=None,\n*,\n+    dtype: torch.dtype,\ndevice: torch.device,\nout: Optional[torch.Tensor] = None,\n):\n-    power_seq = linspace(\n-        start, stop, num, axis, dtype=None, device=default_device(device)\n+    power_seq = ivy.linspace(\n+        start, stop, num, axis, dtype=dtype, device=ivy.default_device(device)\n)\nreturn base**power_seq\n", "fix_pattern": "if a default_device() function is detected, replace with ivy.default_device() and pass the device argument to the function"}
{"number": 908, "change": "def pack(\ntry:\nimport torch\n\n-        meta_objs.update(torch=torch.__version__)\n+        meta_objs.update(torch=str(torch.__version__))\nexcept ImportError:\npass\ntry:\n", "fix_pattern": "if assigning torch.__version__ to a dictionary, update the assignment to convert torch.__version__ to a string by using the str() function"}
{"number": 909, "change": "def main():\n# recog\nlogging.info('backend = ' + args.backend)\nif args.backend == \"chainer\":\n-        from espnet.lmchainer.asr_chainer import recog\n+        from espnet.asr.chainer.asr_chainer import recog\nrecog(args)\nelif args.backend == \"pytorch\":\n-        from espnet.lmpytorch.asr_pytorch import recog\n+        from espnet.asr.pytorch.asr_pytorch import recog\nrecog(args)\nelse:\nraise ValueError(\"Only chainer and pytorch are supported.\")\n", "fix_pattern": "if a module import path contains lmchainer, replace it with asr.chainer\nif a module import path contains lmpytorch, replace it with asr.pytorch"}
{"number": 910, "change": "class Schedule(metaclass=ABCMeta):\nraise NotImplementedError\n\ndef value(self, t):\n-        if self.framework == \"tf\" and tf.executing_eagerly() is False:\n+        if self.framework == \"tf\":\nreturn tf.cast(\n-                tf.py_func(self._value, [t], tf.float64),\n+                tf.py_function(self._value, [t], tf.float64),\ntf.float32,\n-                name=\"schedule-value\")\n+                name=\"schedule_value\")\nreturn self._value(t)\n\ndef __call__(self, t):\n", "fix_pattern": "if the framework is \"tf\" and the method tf.executing_eagerly() is used, replace tf.py_func with tf.py_function and remove the unnecessary is False check. Also, remove the hyphen in the name parameter and replace it with an underscore."}
{"number": 912, "change": "class FeedForwardTransformer(TTSInterface, torch.nn.Module):\n\n# concat speaker embedding\nif self.spk_embed_dim is not None:\n-            spembs = torch.nn.functional.normalize(spembs).unsqueeze(1).expand(-1, hs.size(1), -1)\n-            hs = self.projection(torch.cat([hs, spembs], dim=-1))\n+            spembs_ = F.normalize(spembs).unsqueeze(1).expand(-1, hs.size(1), -1)\n+            hs = self.projection(torch.cat([hs, spembs_], dim=-1))\n\n# forward duration predictor and length regulator\nd_masks = make_pad_mask(ilens).to(xs.device)\n", "fix_pattern": "if normalization is applied using torch.nn.functional.normalize(), replace with F.normalize()."}
{"number": 919, "change": "def image_histogram2d(\nhist = hist.squeeze()\nelif image.dim() == 3:\nhist = hist.squeeze(0)\n-    return hist, torch.zeros_like(hist, dtype=hist.dtype, device=device)\n+    return hist, torch.zeros_like(hist, dtype=hist.dtype, device=hist.device)\n", "fix_pattern": "if a device argument is detected in the API call, replace with the corresponding argument from the input argument."}
{"number": 920, "change": "class FeedForwardEncoder(Seq2SeqEncoder):\nreturn self._feedforward(inputs)\nelse:\noutputs = self._feedforward(inputs)\n-            return outputs * mask.unsqueeze(dim=-1).float()\n+            return outputs * mask.unsqueeze(dim=-1)\n", "fix_pattern": "If the mask tensor is being unsqueezed without converting it to float, add .float() at the end of the API call."}
{"number": 921, "change": "def elastic_transform2d(\nsigma_t = sigma.to(device=device, dtype=dtype)\n\n# Get Gaussian kernel for 'y' and 'x' displacement\n-    kernel_x: torch.Tensor = get_gaussian_kernel2d_t(kernel_size, sigma_t[0].expand(2).unsqueeze(0))\n-    kernel_y: torch.Tensor = get_gaussian_kernel2d_t(kernel_size, sigma_t[1].expand(2).unsqueeze(0))\n+    kernel_x: torch.Tensor = get_gaussian_kernel2d(kernel_size, sigma_t[0].expand(2).unsqueeze(0))\n+    kernel_y: torch.Tensor = get_gaussian_kernel2d(kernel_size, sigma_t[1].expand(2).unsqueeze(0))\n\n# Convolve over a random displacement matrix and scale them with 'alpha'\ndisp_x: torch.Tensor = noise[:, :1]\n", "fix_pattern": "if a method get_gaussian_kernel2d_t is detected, replace it with get_gaussian_kernel2d"}
{"number": 929, "change": "def rand_like_with_shape(shape, ori_t):\nhigher_bound = torch.max(ori_t)\n\nif dtype in [torch.uint8, torch.int16, torch.short, torch.int16, torch.long, torch.bool]:\n-        return torch.randint(lower_bound, higher_bound+1, shape, dtype=dtype, device=device)\n+        return torch.randint(lower_bound.long(), higher_bound.long() + 1, shape, dtype=dtype, device=device)\nelse:\nreturn torch.rand(shape, dtype=dtype, device=device, requires_grad=require_grad)\n", "fix_pattern": "if lower_bound and higher_bound are integers, convert them to long() before adding 1 in the API call."}
{"number": 933, "change": "class SelfAttnFunc(torch.autograd.Function):\nvalues_grads   = torch.bmm(dropout_results.transpose(1,2), output_lin_grads, out=values_grads.transpose(0,1))\n\n# Mask and Scaling for Dropout (not a publically documented op)\n-        dropout_grads = torch._masked_scale(matmul2_dgrad1, dropout_mask, dropout_prob_t[0])\n+        dropout_grads = torch._masked_scale(matmul2_dgrad1, dropout_mask, 1.0/(1.0-dropout_prob_t[0]))\n\n# Softmax Grad (not a publically documented op)\nsoftmax_grads = torch._softmax_backward_data(dropout_grads, softmax_results, -1, softmax_results)\n", "fix_pattern": "if dropout_grads is scaled using torch._masked_scale(), replace the scaling factor with 1.0/(1.0-dropout_prob_t[0])"}
{"number": 934, "change": "class ValidationEpochEndVariations(ABC):\n\nval_acc_mean += val_acc\n\n-        val_loss_mean /= len(outputs)\n-        val_acc_mean /= len(outputs)\n+        if outputs:  # skip zero divisions\n+            val_loss_mean /= len(outputs)\n+            val_acc_mean /= len(outputs)\n\nmetrics_dict = {'val_loss': val_loss_mean.item(), 'val_acc': val_acc_mean.item()}\nresults = {'progress_bar': metrics_dict, 'log': metrics_dict}\n", "fix_pattern": "if a division by len(outputs) is detected, add a conditional statement to check if outputs is not empty before performing the division."}
{"number": 935, "change": "class AutoShape(nn.Module):\n#   multiple:        = [Image.open('image1.jpg'), Image.open('image2.jpg'), ...]  # list of images\n\nt = [time_sync()]\n-        p = next(self.model.parameters()) if self.pt else torch.zeros(1)  # for device and type\n+        p = next(self.model.parameters()) if self.pt else torch.zeros(1, device=self.model.device)  # for device, type\nautocast = self.amp and (p.device.type != 'cpu')  # Automatic Mixed Precision (AMP) inference\nif isinstance(imgs, torch.Tensor):  # torch\nwith amp.autocast(autocast):\n", "fix_pattern": "If a tensor is assigned to a variable without specifying the device, add the device parameter to the tensor creation function call."}
{"number": 936, "change": "class CycleDiffusionPipeline(DiffusionPipeline):\n\ndevice = torch.device(f\"cuda:{gpu_id}\")\n\n-        for cpu_offloaded_model in [self.unet, self.text_encoder, self.vae, self.safety_checker]:\n+        for cpu_offloaded_model in [self.unet, self.text_encoder, self.vae]:\nif cpu_offloaded_model is not None:\ncpu_offload(cpu_offloaded_model, device)\n\n+        if self.safety_checker is not None:\n+            # TODO(Patrick) - there is currently a bug with cpu offload of nn.Parameter in accelerate\n+            # fix by only offloading self.safety_checker for now\n+            cpu_offload(self.safety_checker.vision_model)\n+\n@property\n# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline._execution_device\ndef _execution_device(self):\n", "fix_pattern": "if there is a CPU-offloaded model in a for loop, remove the model from the list and handle it separately with an if statement."}
{"number": 937, "change": "def shift_tokens_right(input_ids: tf.Tensor, pad_token_id: int, decoder_start_to\n\nif tf.executing_eagerly():\n# \"Verify that `labels` has only positive values and -100\"\n-        assert_gte0 = tf.debugging.assert_greater_equal(shifted_input_ids, tf.constant(0))\n+        assert_gte0 = tf.debugging.assert_greater_equal(shifted_input_ids, tf.constant(0, dtype=input_ids.dtype))\n\n# Make sure the assertion op is called by wrapping the result in an identity no-op\nwith tf.control_dependencies([assert_gte0]):\n", "fix_pattern": "if assert_greater_equal() API is detected, replace tf.constant(0) with tf.constant(0, dtype=input_ids.dtype)"}
{"number": 940, "change": "def arange(start, stop=None, step=1, dtype=None, dev=None):\nif dtype in [torch.int8, torch.uint8, torch.int16]:\nreturn torch.arange(start, stop, step=step, dtype=torch.int64, device=dev).to(dtype)\nelse:\n-            return torch.range(start, stop, step=step, dtype=dtype, device=dev)\n+            return torch.arange(start, stop, step=step, dtype=dtype, device=dev)\n", "fix_pattern": "if torch.range() is detected, replace it with torch.arange()"}
{"number": 944, "change": "def _apply_affine(input: torch.Tensor,\n\nheight, width = x_data.shape[-2:]\ntransform: torch.Tensor = params['transform'].to(device, dtype)\n-\n-    out_data: torch.Tensor = warp_perspective(x_data, transform, (height, width))\n+    out_data: torch.Tensor = warp_affine(x_data, transform[:, :2, :], (height, width))\n\nif return_transform:\nreturn out_data.view_as(input), transform\n", "fix_pattern": "If the API method `warp_perspective()` is detected, replace it with `warp_affine()`."}
{"number": 946, "change": "class GPTNeoAttentionMixin:\nelse:\nraise ValueError(f\"Input tensor rank should be one of [2, 3], but is: {len(tensor.shape)}\")\n\n-        padded_tensor = F.pad(tensor, padding_side, value=pad_value)\n+        padded_tensor = nn.functional.pad(tensor, padding_side, value=pad_value)\npadded_tensor = padded_tensor.unfold(dimension=1, size=window_size + block_length, step=block_length)\n\nif is_key_value:\n", "fix_pattern": "If API method F.pad( is detected, replace with nn.functional.pad("}
{"number": 949, "change": "class TFTransfoXLPreTrainedModel(TFPreTrainedModel):\n@tf.function(\ninput_signature=[\n{\n-                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),\n+                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),\n}\n]\n)\n", "fix_pattern": "If a tensor specification is changed from tf.int32 to tf.int64, the pattern for fixing the API method problem is to update the data type to tf.int64 in the code change."}
{"number": 951, "change": "class BiattentiveClassificationNetwork(Model):\n# Create ELMo embeddings if applicable\nif self._elmo:\nif elmo_tokens is not None:\n-                elmo_representations = self._elmo(elmo_tokens)[\"elmo_representations\"]\n+                elmo_representations = self._elmo(elmo_tokens[\"tokens\"])[\"elmo_representations\"]\n# Pop from the end is more performant with list\nif self._use_integrator_output_elmo:\nintegrator_output_elmo = elmo_representations.pop()\n", "fix_pattern": "if an argument inside the API call is changed, modify the argument name accordingly."}
{"number": 957, "change": "class Function(object):\nif is_sparse(tensor):\nsparse_coo = value.tocoo()\nindices = np.concatenate((np.expand_dims(sparse_coo.row, 1), np.expand_dims(sparse_coo.col, 1)), 1)\n-                value = (indices, value.data, value.shape)\n+                value = (indices, sparse_coo.data, sparse_coo.shape)\nfeed_dict[tensor] = value\nsession = get_session()\nupdated = session.run(self.outputs + [self.updates_op], feed_dict=feed_dict)\n", "fix_pattern": "if a variable named \"value\" is detected with \".data\" at the end, replace it with the corresponding updated variable name \"sparse_coo\""}
{"number": 960, "change": "def test_transformer_trainable_and_decodable(model_dict):\nattn_dict = model.calculate_all_attentions(\nx[0:1], ilens[0:1], y_tgt[0:1], y_src[0:1]\n)\n-    plot.plot_multi_head_attention(data, attn_dict, \"\", savefn=_savefn)\n+    plot.plot_multi_head_attention(data, uttid_list, attn_dict, \"\", savefn=_savefn)\n\n# test CTC plot\nctc_probs = model.calculate_all_ctc_probs(\n", "fix_pattern": "If the plot_multi_head_attention() API call has an additional parameter (uttid_list) added, include it as an argument in the API call."}
{"number": 961, "change": "class TFLayoutLMv3PreTrainedModel(TFPreTrainedModel):\n@tf.function(\ninput_signature=[\n{\n-                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),\n-                \"bbox\": tf.TensorSpec((None, None, 4), tf.int32, name=\"bbox\"),\n+                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),\n+                \"bbox\": tf.TensorSpec((None, None, 4), tf.int64, name=\"bbox\"),\n\"pixel_values\": tf.TensorSpec((None, None, None, None), tf.float32, name=\"pixel_values\"),\n-                \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),\n+                \"attention_mask\": tf.TensorSpec((None, None), tf.int64, name=\"attention_mask\"),\n}\n]\n)\n", "fix_pattern": "There is no clear pattern for fixing the API method problem in this code change. The change involves modifying the data type of the tensors from tf.int32 to tf.int64. This change could be driven by the specific requirements of the code or the desired data type for the tensors."}
{"number": 962, "change": "class DecisionTransformerGPT2Attention(nn.Module):\n# Need to be a tensor, otherwise we get error: `RuntimeError: expected scalar type float but found double`.\n# Need to be on the same device, otherwise `RuntimeError: ..., x and y to be on the same device`\nmask_value = torch.full([], mask_value, dtype=attn_weights.dtype).to(attn_weights.device)\n-            attn_weights = torch.where(causal_mask, attn_weights, mask_value)\n+            attn_weights = torch.where(causal_mask, attn_weights.to(attn_weights.dtype), mask_value)\n\nif attention_mask is not None:\n# Apply the attention mask\n", "fix_pattern": "if an API call is made with a tensor and another object of different data type, use the to() method to convert the tensor to the same data type as the other object"}
{"number": 963, "change": "def load_tf_graph(graph_file):\n\"\"\"\n# We load the protobuf file from the disk and parse it to retrieve the\n# unserialized graph_def\n-    with tf.gfile.GFile(graph_file, \"rb\") as f:\n-        graph_def = tf.GraphDef()\n+    with tf.io.gfile.GFile(graph_file, \"rb\") as f:\n+        graph_def = tf.compat.v1.GraphDef()\ngraph_def.ParseFromString(f.read())\n\n# Then, we import the graph_def into a new Graph and returns it\n", "fix_pattern": "if tf.gfile.GFile is detected, replace with tf.io.gfile.GFile. \nSimilarly, if tf.GraphDef is detected, replace with tf.compat.v1.GraphDef."}
{"number": 967, "change": "class TestScalarMix(AllenNlpTestCase):\ntensors = [torch.randn([3, 4, 5]) for _ in range(3)]\nnumpy_mask = numpy.ones((3, 4), dtype=\"int32\")\nnumpy_mask[1, 2:] = 0\n-        mask = torch.from_numpy(numpy_mask)\n+        mask = torch.from_numpy(numpy_mask).bool()\n\nweights = [0.1, 0.2, 0.3]\nfor k in range(3):\n", "fix_pattern": "If a tensor is converted from a numpy array using torch.from_numpy(), and the original numpy array is a boolean mask, add .bool() to the end of the API call."}
{"number": 968, "change": "def get_global_step_var():\nwith tf.variable_scope(scope, reuse=False), \\\ntf.name_scope(None):\nvar = tf.get_variable(GLOBAL_STEP_OP_NAME,\n-                                  initializer=0,\n-                                  trainable=False, dtype=tf.int32)\n+                                  initializer=tf.constant(0, dtype=tf.int64),\n+                                  trainable=False, dtype=tf.int64)\nreturn var\n", "fix_pattern": "If the initializer for a variable is set to 0, change the dtype to tf.int64."}
{"number": 969, "change": "class SequenceFeatureExtractionTestMixin(FeatureExtractionSavingTestMixin):\ninput_np = feat_extract.pad(processed_features, padding=\"longest\", return_tensors=\"np\")[input_name]\ninput_tf = feat_extract.pad(processed_features, padding=\"longest\", return_tensors=\"tf\")[input_name]\n\n-        self.assertTrue(abs(input_np.sum() - input_tf.numpy().sum()) < 1e-2)\n+        self.assertTrue(abs(input_np.astype(np.float32).sum() - input_tf.numpy().sum()) < 1e-2)\n\ndef test_attention_mask(self):\nfeat_dict = self.feat_extract_dict\n", "fix_pattern": "if the input tensor is of type numpy.ndarray, add .astype(np.float32) to convert it to float32 before performing the sum operation"}
{"number": 972, "change": "class SSIM(nn.Module):\nssim_map = ((2 * mu1_mu2 + self.C1) * (2 * sigma12 + self.C2)) / \\\n((mu1_sq + mu2_sq + self.C1) * (sigma1_sq + sigma2_sq + self.C2))\n\n-        loss = torch.clamp(1. - ssim_map, min=0, max=1) / 2.\n+        loss = torch.clamp(torch.tensor(1.) - ssim_map, min=0, max=1) / 2.\n\nif self.reduction == 'mean':\nloss = torch.mean(loss)\n", "fix_pattern": "if a scalar value is used as an operand in an API call, wrap it in a torch.tensor() function call"}
{"number": 974, "change": "def rpn_losses(anchor_labels, anchor_boxes, label_logits, box_logits):\nplaceholder = 1.\nlabel_loss = tf.nn.sigmoid_cross_entropy_with_logits(\nlabels=tf.to_float(valid_anchor_labels), logits=valid_label_logits)\n-    label_loss = label_loss * (1. / config.RPN_BATCH_PER_IM)\n+    label_loss = tf.reduce_sum(label_loss) * (1. / config.RPN_BATCH_PER_IM)\nlabel_loss = tf.where(tf.equal(nr_valid, 0), placeholder, label_loss, name='label_loss')\n\npos_anchor_boxes = tf.boolean_mask(anchor_boxes, pos_mask)\n", "fix_pattern": "if a tensor is detected before a reduction operation (e.g., sum, mean), use the reduction operation from the framework's API instead of multiplying by a scalar"}
{"number": 975, "change": "def test_beamformer_net_wpe_output(ch, num_spk, use_dnn_mask_for_wpe):\ndef test_beamformer_net_bf_output(num_spk):\nch = 3\ninputs = torch.randn(2, 16, ch)\n+    inputs = inputs.float()\nilens = torch.LongTensor([16, 12])\nmodel = BeamformerNet(\nn_fft=8,\n", "fix_pattern": "No pattern identified."}
{"number": 976, "change": "from allennlp.common.testing import AllenNlpTestCase\n\nclass TestElmoLstmCell(AllenNlpTestCase):\ndef test_elmo_lstm(self):\n-        input_tensor = Variable(torch.rand(4, 5, 3))\n+        input_tensor = torch.rand(4, 5, 3)\ninput_tensor[1, 4:, :] = 0.\ninput_tensor[2, 2:, :] = 0.\ninput_tensor[3, 1:, :] = 0.\n-        mask = Variable(torch.ones([4, 5]))\n+        mask = torch.ones([4, 5])\nmask[1, 4:] = 0.\nmask[2, 2:] = 0.\nmask[3, 1:] = 0.\n", "fix_pattern": "No pattern is identified for the given code change. It is a simple replacement of the deprecated Variable() function with direct tensor creation."}
{"number": 977, "change": "class TpuStrategyTest(tf.test.TestCase):\nserving_fn = create_serving_signature(model)\n\nsaved_model_dir = tempfile.mkdtemp(dir=self.get_temp_dir())\n-      tf.saved_model.save(\n-          model, saved_model_dir, signatures={\"serving_default\": serving_fn})\n+      model.save(saved_model_dir, save_format=\"tf\",\n+                 signatures={\"serving_default\": serving_fn})\n\n# Test the saved_model.\nloaded_serving_fn = tf.keras.models.load_model(\n", "fix_pattern": "if tf.saved_model.save( detected, replace with model.save( with save_format=\"tf\" argument."}
{"number": 984, "change": "def _preprocess_conv3d_input(x, data_format):\n# Returns\nA tensor.\n\"\"\"\n-    if dtype(x) == 'float64':\n+    # tensorflow doesn't support float64 for conv layer before 1.8.0\n+    if (dtype(x) == 'float64'\n+            and StrictVersion(tf.__version__) < StrictVersion('1.8.0')):\nx = tf.cast(x, 'float32')\ntf_data_format = 'NDHWC'\nif data_format == 'channels_first':\n", "fix_pattern": "if a conditional block is checking the data type of a variable and the specific data type being checked is 'float64', add an additional condition that checks the TensorFlow version and only executes the block if the version is less than '1.8.0'"}
{"number": 987, "change": "class SingleRoIExtractor(BaseRoIExtractor):\nnum_levels = len(feats)\nroi_feats = feats[0].new_zeros(\nrois.size(0), self.out_channels, *out_size)\n+        # TODO: remove this when parrots supports\n+        if torch.__version__ == 'parrots':\n+            roi_feats.requires_grad = True\n\nif num_levels == 1:\nif len(rois) == 0:\n", "fix_pattern": "if a specific version of the torch library is detected (in this case 'parrots'), add a conditional statement and modify the code block accordingly"}
{"number": 988, "change": "def main(args):\naccelerator.clip_grad_norm_(params_to_clip, args.max_grad_norm)\noptimizer.step()\nlr_scheduler.step()\n-                optimizer.zero_grad()\n+                optimizer.zero_grad(set_to_none=args.set_grads_to_none)\n\n# Checks if the accelerator has performed an optimization step behind the scenes\nif accelerator.sync_gradients:\n", "fix_pattern": "if the parameter set_to_none is added to the zero_grad() method call"}
{"number": 989, "change": "class Tagger(nn.Module):\n# criterion\nself.crit = nn.CrossEntropyLoss(ignore_index=0) # ignore padding\n\n-        self.drop = Dropout(args['dropout'])\n+        self.drop = nn.Dropout(args['dropout'])\nself.worddrop = WordDropout(args['word_dropout'])\n\ndef forward(self, word, word_mask, wordchars, wordchars_mask, upos, xpos, ufeats, pretrained, word_orig_idx, sentlens, wordlens):\n", "fix_pattern": "If the code includes a custom dropout layer called \"Dropout\", replace it with nn.Dropout()"}
{"number": 991, "change": "def build_linear_positions(index_dims, output_range=(-1.0, 1.0)):\nreturn torch.linspace(start=output_range[0], end=output_range[1], steps=n_xels_per_dim, dtype=torch.float32)\n\ndim_ranges = [_linspace(n_xels_per_dim) for n_xels_per_dim in index_dims]\n-    array_index_grid = torch.meshgrid(*dim_ranges)\n+    array_index_grid = meshgrid(*dim_ranges, indexing=\"ij\")\n\nreturn torch.stack(array_index_grid, dim=-1)\n", "fix_pattern": "if a torch.meshgrid() API call is detected, replace it with meshgrid(*dim_ranges, indexing=\"ij\")"}
{"number": 1007, "change": "class GPT2Attention(nn.Module):\n# Apply the attention mask\nattn_weights = attn_weights + attention_mask\n\n-        attn_weights = nn.Softmax(dim=-1)(attn_weights)\n+        attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n\n# Downcast (if necessary) back to V's dtype (if in mixed-precision) -- No-Op if otherwise\nif attn_weights.dtype != torch.float32:\n", "fix_pattern": "if Softmax API call is detected, replace with nn.functional.softmax("}
{"number": 1008, "change": "class BidirectionalEndpointSpanExtractor(SpanExtractor):\nsequence_lengths = util.get_lengths_from_binary_sequence_mask(sequence_mask)\nelse:\n# shape (batch_size), filled with the sequence length size of the sequence_tensor.\n-            sequence_lengths = util.ones_like(sequence_tensor[:, 0, 0]).long() * sequence_tensor.size(1)\n+            sequence_lengths = (torch.ones_like(sequence_tensor[:, 0, 0], dtype=torch.long) *\n+                                sequence_tensor.size(1))\n\n# shape (batch_size, num_spans, 1)\nend_sentinel_mask = (exclusive_span_ends == sequence_lengths.unsqueeze(-1)).long().unsqueeze(-1)\n", "fix_pattern": "if creating a tensor using util.ones_like() with a specific dtype, replace it with torch.ones_like() and specify the dtype as an argument"}
{"number": 1013, "change": "class ARSTFPolicy:\nself.num_params = sum(\nnp.prod(variable.shape.as_list())\nfor _, variable in self.variables.variables.items())\n-        self.sess.run(tf.global_variables_initializer())\n+        self.sess.run(tf1.global_variables_initializer())\n\ndef compute_actions(self,\nobservation,\n", "fix_pattern": "if tf.global_variables_initializer() is detected, replace it with tf1.global_variables_initializer()"}
{"number": 1016, "change": "class LanguageModel(nn.Module):\n\nfor i in range(number_of_characters):\n\n-                if torch.cuda.is_available():\n-                    input = input.cuda()\n+                input = input.to(flair.device)\n\n# get predicted weights\nprediction, _, hidden = self.forward(input, hidden)\n", "fix_pattern": "if torch.cuda.is_available() is detected, replace with input.to(flair.device)"}
{"number": 1024, "change": "class MultiCategorical(TFActionDistribution):\n\n@override(ActionDistribution)\ndef multi_kl(self, other):\n-        return [cat.kl(oth_cat) for cat, oth_cat in zip(self.cats, other.cats)]\n+        return tf.stack(\n+            [cat.kl(oth_cat) for cat, oth_cat in zip(self.cats, other.cats)],\n+            axis=1)\n\n@override(ActionDistribution)\ndef kl(self, other):\n", "fix_pattern": "If using a list comprehension to calculate a metric for each element of two lists and returning a list as the result, wrap the list comprehension in a function that converts the list to a tensor using the tf.stack() function. Specify the axis along which to stack the tensors."}
{"number": 1027, "change": "class Trainer:\nif self.args.past_index >= 0:\ninputs[\"mems\"] = past\n# Our model outputs do not work with DataParallel, so forcing return tuple.\n-            if self.args.n_gpu > 1:\n+            if isinstance(model, nn.DataParallel):\ninputs[\"return_tuple\"] = True\n\nwith torch.no_grad():\n", "fix_pattern": "if a check for the number of GPUs in use (self.args.n_gpu > 1) is detected, replace it with a check for the model being an instance of nn.DataParallel"}
{"number": 1028, "change": "class PolicyWithValue:\ndef sample(logits, mask_npinf):\nnew_logits = tf.math.add(logits, mask_npinf)\nu = tf.random_uniform(tf.shape(new_logits), dtype=logits.dtype)\n-            return tf.argmax(new_logits - tf.log(-tf.log(u)), axis=-1)\n+            return tf.argmax(new_logits - tf.log(-1*tf.log(u)), axis=-1)\n\ndef neglogp(logits, x):\n# return tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.logits, labels=x)\n", "fix_pattern": "if tf.log(-tf.log(u)) is detected in the code, replace it with tf.log(-1*tf.log(u))"}
{"number": 1030, "change": "def Conv2DTranspose(\nif get_tf_version_tuple() <= (1, 12):\nkernel_initializer = tf.contrib.layers.variance_scaling_initializer(2.0),\nelse:\n-            kernel_initializer = tf.keras.initializers.VarianceScaling(2.0)\n+            kernel_initializer = tf.keras.initializers.VarianceScaling(2.0, distribution='untruncated_normal')\n\nwith rename_get_variable({'kernel': 'W', 'bias': 'b'}):\nlayer = tf.layers.Conv2DTranspose(\n", "fix_pattern": "if specifying a distribution parameter in kernel_initializer, add the distribution parameter with the appropriate value"}
{"number": 1033, "change": "def make_batches(lines, args, task, max_positions, encode_fn):\n).long()\nfor src_str in lines\n]\n-    lengths = torch.LongTensor([t.numel() for t in tokens])\n+    lengths = [t.numel() for t in tokens]\nitr = task.get_batch_iterator(\ndataset=task.build_dataset_for_inference(tokens, lengths),\nmax_tokens=args.max_tokens,\n", "fix_pattern": "if creating a tensor using \"torch.LongTensor\" is detected, replace it with a list comprehension to create a list"}
{"number": 1034, "change": "class EarlyStopping(Callback):\n\nif trainer.use_tpu:\nstop = torch.tensor(int(trainer.should_stop), device=pl_module.device, dtype=torch.int32)\n-            stop = xm.mesh_reduce(\"stop_signal\", stop, torch.cat)\n+            stop = xm.mesh_reduce(\"stop_signal\", stop, sum)\ntorch_xla.core.xla_model.rendezvous(\"pl.EarlyStoppingCallback.stop_distributed_training_check\")\ntrainer.should_stop = int(stop.item()) == trainer.world_size\n", "fix_pattern": "if an API method is used as an argument to another API method, and the second parameter of the method is changed to a different API method."}
{"number": 1035, "change": "class Entropy(Metric):\nmask : `torch.Tensor`, optional (default = None).\nA masking tensor of shape (batch_size, ...).\n\"\"\"\n-        logits, mask = self.unwrap_to_tensors(logits, mask)\n+        logits, mask = self.detach_tensors(logits, mask)\n\nif mask is None:\n-            mask = torch.ones(logits.size()[:-1])\n+            mask = torch.ones(logits.size()[:-1], device=logits.device)\n\nlog_probs = torch.nn.functional.log_softmax(logits, dim=-1)\nprobabilities = torch.exp(log_probs) * mask.unsqueeze(-1)\n", "fix_pattern": "If device information is missing, add .to(device) to the end of the tensor definition."}
{"number": 1039, "change": "class ImageEmbedder(nn.Module):\n\nself.to_patch_embedding = nn.Sequential(\nRearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_size, p2 = patch_size),\n+            nn.LayerNorm(patch_dim),\nnn.Linear(patch_dim, dim),\n+            nn.LayerNorm(dim)\n)\n\nself.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n", "fix_pattern": "if LayerNorm API is detected, replace it with nn.LayerNorm"}
{"number": 1043, "change": "class BertForSequenceClassification(BertPreTrainedModel):\n\nself.bert = BertModel(config)\nself.dropout = nn.Dropout(config.hidden_dropout_prob)\n-        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n+        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n\nself.init_weights()\n", "fix_pattern": "If the config object is used to access a property in the API call, remove the self prefix."}
{"number": 1044, "change": "def fmod(\nout: Optional[Union[tf.Tensor, tf.Variable]] = None,\n) -> Union[tf.Tensor, tf.Variable]:\nresult = tf.math.floormod(x1, x2, name=None)\n-    temp = (result, x1)\n-    return tf.map_fn(lambda x: x[0] if (x[0] * x[1] >= 0) else (-1 * x[0]), temp)\n+    temp = [result, x1]\n+    return tf.map_fn(lambda x: x[0] if (x[0] * x[1] >= 0) else (-1 * x[0]), temp, fn_output_signature=result.dtype)\n\n\ndef fmax(\n", "fix_pattern": "if using tf.map_fn, add fn_output_signature to specify the output dtype"}
{"number": 1046, "change": "class MT5DenseGatedActDense(nn.Module):\n# To make 8bit quantization work for google/flan-t5-xxl, self.wo is kept in float32.\n# See https://github.com/huggingface/transformers/issues/20287\n# we also make sure the weights are not in `int8` in case users will force `_keep_in_fp32_modules` to be `None``\n-        if hidden_states.dtype != self.wo.weight.dtype and self.wo.weight.dtype != torch.int8:\n+        if (\n+            isinstance(self.wo.weight, torch.Tensor)\n+            and hidden_states.dtype != self.wo.weight.dtype\n+            and self.wo.weight.dtype != torch.int8\n+        ):\nhidden_states = hidden_states.to(self.wo.weight.dtype)\n\nhidden_states = self.wo(hidden_states)\n", "fix_pattern": "If an if statement checks for the dtype of a tensor, add an isinstance() check for the tensor before checking the dtype."}
{"number": 1048, "change": "def vector_to_skew_symmetric_matrix(vector):\na2s = vector_expanded[..., 1:2, :]\na3s = vector_expanded[..., 2:3, :]\n# BS x 1 x 1\n-    zs = torch.zeros(batch_shape + [1, 1])\n+    zs = torch.zeros(batch_shape + [1, 1], device=vector.device)\n# BS x 1 x 3\nrow1 = torch.cat((zs, -a3s, a2s), -1)\nrow2 = torch.cat((a3s, zs, -a1s), -1)\n", "fix_pattern": "if creating a tensor with device specified, add device argument to the tensor creation function (e.g., torch.zeros(..., device=device))"}
{"number": 1050, "change": "class PointAssigner(BaseAssigner):\n\nif gt_labels is not None:\nassigned_labels = assigned_gt_inds.new_full((num_points, ), -1)\n-            pos_inds = torch.nonzero(assigned_gt_inds > 0).squeeze()\n+            pos_inds = torch.nonzero(\n+                assigned_gt_inds > 0, as_tuple=False).squeeze()\nif pos_inds.numel() > 0:\nassigned_labels[pos_inds] = gt_labels[\nassigned_gt_inds[pos_inds] - 1]\n", "fix_pattern": "If torch.nonzero() is called with the argument as_tuple=False, remove the as_tuple=False argument from the API call."}
{"number": 1052, "change": "def att_to_numpy(att_ws, att):\natt_ws = torch.stack([aw[:, -1] for aw in att_ws], dim=1).cpu().numpy()\nelif isinstance(att, (AttCov, AttCovLoc)):\n# att_ws => list of list of previous attentions\n-        att_ws = torch.stack([aw[-1] for aw in att_ws], dim=1).cpu().numpy()\n+        att_ws = torch.stack([aw[idx] for idx, aw in enumerate(att_ws)], dim=1).cpu().numpy()\nelif isinstance(att, AttLocRec):\n# att_ws => list of tuple of attention and hidden states\natt_ws = torch.stack([aw[0] for aw in att_ws], dim=1).cpu().numpy()\n", "fix_pattern": "if accessing elements in a list of tensors using an index, replace the indexing operation with enumerate() function to get both index and element"}
{"number": 1054, "change": "class HestonModel(generic_ito_process.GenericItoProcess):\ndrift = tf.stack([log_spot_drift, var_drift], -1)\nreturn drift\n\n-    super(HestonModel, self).__init__(2, _drift_fn, _vol_fn, dtype, name)\n+    super(HestonModel, self).__init__(2, _drift_fn, _vol_fn, self._dtype, name)\n\ndef sample_paths(self,\ntimes: types.RealTensor,\n", "fix_pattern": "if passing a data type variable directly (e.g., dtype) is detected, replace it with self._dtype"}
{"number": 1056, "change": "class SimilarityLearner(flair.nn.Model):\nepoch_results_str,\ndetailed_results,\n),\n-            0,\n+            torch.tensor(0),\n)\n\ndef _get_state_dict(self):\n", "fix_pattern": "if a numeric value is detected, replace it with a tensor using torch.tensor()"}
{"number": 1059, "change": "class TFOPTDecoder(tf.keras.layers.Layer):\nif output_attentions:\nall_self_attns += (layer_self_attn,)\n\n+        if self.final_layer_norm is not None:\n+            hidden_states = self.final_layer_norm(hidden_states)\n+\nif self.project_out is not None:\nhidden_states = self.project_out(hidden_states)\n", "fix_pattern": "if an IF condition is added for `self.final_layer_norm`, then apply the normalization (`self.final_layer_norm`) to `hidden_states`"}
{"number": 1060, "change": "def convert_examples_to_features(examples, seq_length, tokenizer):\nif ex_index < 5:\ntf.logging.info(\"*** Example ***\")\ntf.logging.info(\"unique_id: %s\" % (example.unique_id))\n-      tf.logging.info(\"tokens: %s\" % \" \".join([str(x) for x in tokens]))\n+      tf.logging.info(\"tokens: %s\" % \" \".join(\n+          [tokenization.printable_text(x) for x in tokens]))\ntf.logging.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\ntf.logging.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\ntf.logging.info(\n", "fix_pattern": "If the tf.logging.info statement contains a list comprehension that joins the elements with quotes, replace str(x) with tokenization.printable_text(x)"}
{"number": 1064, "change": "def load_model(filepath, custom_optimizers=None, custom_objects=None, compressio\n\"\"\"\ndef wrap_optimizer(cls):\nreturn lambda **kwargs: DistributedOptimizer(cls(**kwargs), compression=compression)\n-    return _impl.load_model(keras, wrap_optimizer, filepath, custom_optimizers, custom_objects)\n+    optimizer_modules = {keras.optimizers.Optimizer.__module__}\n+    return _impl.load_model(keras, wrap_optimizer, optimizer_modules, filepath, custom_optimizers, custom_objects)\n", "fix_pattern": "if an API method call includes `keras.optimizers.Optimizer.__module__`, include `optimizer_modules` parameter in the API call"}
{"number": 1065, "change": "class ParabolicEquationStepperTest(tf.test.TestCase, parameterized.TestCase):\nsecond_order_coeff_fn=second_order_coeff_fn,\ninner_first_order_coeff_fn=inner_first_order_coeff_fn)[0]\n\n-    true_values = tf.math.exp(final_t + grid[0])\n+    true_values = tf.expand_dims(tf.math.exp(final_t + grid[0]), axis=0)\nself.assertAllClose(\nest_values, true_values, atol=1e-2, rtol=1e-2)\n", "fix_pattern": "if an API call tf.math.exp( is detected without tf.expand_dims(, add tf.expand_dims( with the appropriate dimensions as the first argument."}
{"number": 1066, "change": "class LocalMultiGPUOptimizer(PolicyOptimizer):\nelse:\nrnn_inputs = []\nself.par_opt = LocalSyncParallelOptimizer(\n-                        tf.train.AdamOptimizer(\n-                            self.sgd_stepsize), self.devices,\n+                        self.policy.optimizer(), self.devices,\n[v for _, v in self.policy.loss_inputs()], rnn_inputs,\nself.per_device_batch_size, self.policy.copy,\nos.getcwd())\n", "fix_pattern": "if tf.train.OptimizerType( detected, replace with self.policy.optimizer()"}
{"number": 1067, "change": "class DistributedReplicatedBuilder(DataParallelBuilder):\nreturn grads\n\n# Ngpu * Nvar * 2\n-        grad_list = self.build_on_multi_tower(\n-            get_grads,\n+        grad_list = DataParallelBuilder.build_on_towers(\n+            self.towers, get_grads,\ndevices=self.raw_devices,\nuse_vs=[True] * len(self.towers))  # open vs at each tower\nDataParallelBuilder._check_grad_list(grad_list)\n", "fix_pattern": "if a method call with \"self\" as the first argument is detected, replace it with ClassName.method_call(\n    ClassName being the class name of the object calling the method)"}
{"number": 1069, "change": "class OPTForSequenceClassification(OPTPreTrainedModel):\nsequence_lengths = -1\nelse:\nif input_ids is not None:\n-                sequence_lengths = torch.ne(input_ids, self.config.pad_token_id).sum(-1) - 1\n+                sequence_lengths = (torch.ne(input_ids, self.config.pad_token_id).sum(-1) - 1).to(logits.device)\nelse:\nsequence_lengths = -1\nlogger.warning(\n", "fix_pattern": "If a tensor is detected without .to(), add .to(device) to the end of the API call."}
{"number": 1072, "change": "def test_discrete_parallel(continuous_class):\n\ndef model(data):\nweights = pyro.sample('weights', dist.Dirichlet(0.5 * torch.ones(K)))\n-        locs = pyro.sample('locs', dist.Normal(0, 10).reshape([K], extra_event_dims=1))\n+        locs = pyro.sample('locs', dist.Normal(0, 10).expand_by([K]).independent(1))\nscale = pyro.sample('scale', dist.LogNormal(0, 1))\n\nwith pyro.iarange('data', len(data)):\n", "fix_pattern": "if dist reshaping API .reshape() is detected, replace it with .expand_by() and .independent() APIs"}
{"number": 1077, "change": "class MaskTokensDataset(BaseWrapperDataset):\nif self.mask_whole_words is not None:\nmask = np.repeat(mask, word_lens)\nnew_item = np.full(len(mask), self.pad_idx)\n-                new_item[mask] = item[torch.from_numpy(mask)]\n+                new_item[mask] = item[torch.from_numpy(mask.astype(np.uint8))]\nreturn torch.from_numpy(new_item)\n\n# decide unmasking and random replacement\n", "fix_pattern": "If a mask is used to index an item tensor, and the mask is a numpy array, add \".astype(np.uint8)\" to the mask before passing it to torch.from_numpy()."}
{"number": 1079, "change": "def _sample_coalescent_times(leaf_times):\ncoal_times.append(t)\ncoal_times.reverse()\n\n-    return torch.tensor(coal_times)\n+    return proto.new_tensor(coal_times)\n", "fix_pattern": "if torch.tensor() is detected, replace with proto.new_tensor()"}
{"number": 1083, "change": "class CategoricalAccuracy(Metric):\n# ith entry in gold_labels points to index (0-num_classes) for ith row in max_predictions\n# For each row check if index pointed by gold_label is was 1 or not (among max scored classes)\ncorrect = max_predictions_mask[\n-                torch.arange(gold_labels.numel()).long(), gold_labels\n+                torch.arange(gold_labels.numel(), device=gold_labels.device).long(), gold_labels\n].float()\ntie_counts = max_predictions_mask.sum(-1)\ncorrect /= tie_counts.float()\n", "fix_pattern": "if generating a tensor with the device argument detected, replace torch.arange(gold_labels.numel()).long() with torch.arange(gold_labels.numel(), device=gold_labels.device).long()"}
{"number": 1091, "change": "class Model(ModelDesc):\n.GlobalAvgPooling('gap')\n.FullyConnected('linear', 1000, nl=tf.identity)())\n\n-        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, label)\n+        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)\nloss = tf.reduce_mean(loss, name='xentropy-loss')\n\nwrong = prediction_incorrect(logits, label, 1, name='wrong-top1')\n", "fix_pattern": "if API call with kwargs passed as positional arguments is detected, replace with kwargs= argument format"}
{"number": 1094, "change": "def batchnorm_example(optimizer_fn,\nfor z in range(batch_per_epoch)]).repeat()\n\noptimizer = optimizer_fn()\n-  batchnorm = tf.compat.v1.layers.BatchNormalization(\n+  batchnorm = normalization.BatchNormalization(\nrenorm=renorm, momentum=momentum, fused=False)\n-  layer = tf.compat.v1.layers.Dense(1, use_bias=False)\n+  layer = core.Dense(1, use_bias=False)\n\ndef model_fn(x):\n\"\"\"A model that uses batchnorm.\"\"\"\n", "fix_pattern": "if a deprecated API is detected, replace the deprecated API with the recommended API calls"}
{"number": 1104, "change": "class EpsilonDecay(Exploration):\n\npred = tf.logical_or(x=(timestep < self.start_timestep),\ny=(timestep > self.start_timestep + int(self.timesteps)))\n-        return tf.cond(pred=pred, true_fn=true_fn, false_fn=false_fn)\n+        return tf.fill(dims=shape, value=tf.cond(pred=pred, true_fn=true_fn, false_fn=false_fn))\n", "fix_pattern": "if a tf.cond() statement is used as the value in a tf.fill() call, add dims=shape and value= to the tf.fill() call."}
{"number": 1114, "change": "class Stft(torch.nn.Module, InversibleInterface):\npad = self.n_fft // 2\nilens = ilens + 2 * pad\n\n-            olens = (\n-                torch.div((ilens - self.n_fft), self.hop_length, rounding_mode=\"floor\")\n-                + 1\n-            )\n+            olens = torch.div((ilens - self.n_fft), self.hop_length) + 1\noutput.masked_fill_(make_pad_mask(olens, output, 1), 0.0)\nelse:\nolens = None\n", "fix_pattern": "if rounding_mode=\"floor\" is detected in the API call torch.div(), remove it."}
{"number": 1118, "change": "def _scale_channel(im: torch.Tensor) -> torch.Tensor:\n# and then normalization by step.\nlut = (torch.cumsum(histo, 0) + (step // 2)) // step\n# Shift lut, prepending with 0.\n-        lut = torch.cat([torch.zeros(1, device=lut.device), lut[:-1]])\n+        lut = torch.cat([torch.zeros(1, device=lut.device, dtype=lut.dtype), lut[:-1]])\n# Clip the counts to be in range.  This is done\n# in the C code for image.point.\nreturn torch.clamp(lut, 0, 255)\n", "fix_pattern": "If a tensor is created using torch.zeros() without specifying the dtype, add the dtype parameter to the API call."}
{"number": 1122, "change": "class DonutSwinLayer(nn.Module):\n# partition windows\nhidden_states_windows = window_partition(shifted_hidden_states, self.window_size)\nhidden_states_windows = hidden_states_windows.view(-1, self.window_size * self.window_size, channels)\n-        attn_mask = self.get_attn_mask(height_pad, width_pad)\n+        attn_mask = self.get_attn_mask(height_pad, width_pad, dtype=hidden_states.dtype)\nif attn_mask is not None:\nattn_mask = attn_mask.to(hidden_states_windows.device)\n", "fix_pattern": "If an API method is missing a parameter, check the original method signature to identify the missing parameter(s) and add them to the API call. In this case, the missing parameter 'dtype' is added to the 'get_attn_mask' method call."}
{"number": 1126, "change": "for it in range(1000000):\nD_reg = D(G_sample_reg)\n\nmse = torch.sum((X - G_sample_reg)**2, 1)\n-    E_loss = torch.mean(lam1 * mse + lam2 * D_reg)\n+    E_loss = torch.mean(lam1 * mse + lam2 * log(D_reg))\n\nE_loss.backward()\nE_solver.step()\n", "fix_pattern": "Do not replace any API or add any new pattern"}
{"number": 1127, "change": "class VisualBertEmbeddings(nn.Module):\ninputs_embeds = self.word_embeddings(input_ids)\n\nif token_type_ids is None:\n-            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.input_embeds.device)\n+            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.position_ids.device)\n\ntoken_type_embeddings = self.token_type_embeddings(token_type_ids)\n", "fix_pattern": "if a tensor is created with dtype=torch.long and its device is specified using self.input_embeds.device, change the device argument to self.position_ids.device."}
{"number": 1128, "change": "class BCELossMasked(nn.Module):\nReturns:\nloss: An average loss value in range [0, 1] masked by the length.\n\"\"\"\n-        # mask: (batch, max_len, 1)\ntarget.requires_grad = False\nif length is not None:\n-            mask = sequence_mask(sequence_length=length, max_len=target.size(1)).float()\n-            x = x * mask\n-            target = target * mask\n+            # mask: (batch, max_len, 1)\n+            mask = sequence_mask(sequence_length=length, max_len=target.size(1))\nnum_items = mask.sum()\n+            loss = functional.binary_cross_entropy_with_logits(x.masked_select(mask), target.masked_select(mask), pos_weight=self.pos_weight, reduction=\"sum\")\nelse:\n+            loss = functional.binary_cross_entropy_with_logits(x, target, pos_weight=self.pos_weight, reduction=\"sum\")\nnum_items = torch.numel(x)\n-        loss = functional.binary_cross_entropy_with_logits(x, target, pos_weight=self.pos_weight, reduction=\"sum\")\nloss = loss / num_items\nreturn loss\n", "fix_pattern": "If a mask tensor is used with binary_cross_entropy_with_logits, use masked_select function on the mask tensor before applying it to inputs and targets."}
{"number": 1132, "change": "class TFFastSpeech(tf.keras.Model):\n== config.decoder_self_attention_params.hidden_size,\nname=\"decoder\",\n)\n-        self.mel_dense = tf.keras.layers.Dense(units=config.num_mels, name=\"mel_before\")\n-        self.postnet = TFTacotronPostnet(config=config, name=\"postnet\")\n+        self.mel_dense = tf.keras.layers.Dense(units=config.num_mels, dtype=tf.float32, name=\"mel_before\")\n+        self.postnet = TFTacotronPostnet(config=config, dtype=tf.float32, name=\"postnet\")\n\nself.setup_inference_fn()\n", "fix_pattern": "If the data type of a layer or module is explicitly specified, replace the \"name\" argument with \"dtype\" and set the data type to the desired type."}
{"number": 1140, "change": "class Model(object):\n#     raise TensorForceError(\"Invalid model directory/file.\")\n\nself.saver.restore(sess=self.session, save_path=file)\n+        self.session.run(self.buffer_index_reset_op)\n\ndef get_components(self):\n\"\"\"\n", "fix_pattern": "No pattern identified. The code change doesn't have a direct correlation with the code that was removed."}
{"number": 1142, "change": "class TexturesAtlas(TexturesBase):\n# pyre-fixme[16]: `bool` has no attribute `__getitem__`.\nmask = (pix_to_face < 0)[..., None]\nbary_w01 = torch.where(mask, torch.zeros_like(bary_w01), bary_w01)\n-        w_xy = (bary_w01 * R).to(torch.int64)  # (N, H, W, K, 2)\n+        # If barycentric coordinates are > 1.0 (in the case of\n+        # blur_radius > 0.0), wxy might be > R. We need to clamp this\n+        # index to R-1 to index into the texture atlas.\n+        w_xy = (bary_w01 * R).to(torch.int64).clamp(max=R - 1)  # (N, H, W, K, 2)\n\nbelow_diag = (\nbary_w01.sum(dim=-1) * R - w_xy.float().sum(dim=-1)\n", "fix_pattern": "if an integer conversion of a float tensor is detected, add a .clamp(max=R-1) to the end of the API call"}
{"number": 1144, "change": "class VariationalSparseGP(GPModel):\nM = self.Xu.size(0)\nKuu = self.kernel(self.Xu).contiguous()\nKuu.view(-1)[::M + 1] += self.jitter  # add jitter to the diagonal\n-        Luu = Kuu.cholesky()\n+        Luu = torch.linalg.cholesky(Kuu)\n\nzero_loc = self.Xu.new_zeros(self.u_loc.shape)\nif self.whiten:\n", "fix_pattern": "if the function cholesky() from the torch library is called on a tensor Kuu, replace it with torch.linalg.cholesky()"}
{"number": 1148, "change": "def _matvecmul(x, y):\n\n\ndef _cholesky(x):\n-    return x.sqrt() if x.dim() == 1 else x.cholesky()\n+    return x.sqrt() if x.dim() == 1 else torch.linalg.cholesky(x)\n\n\ndef _transpose(x):\n", "fix_pattern": "If a cholesky operation is detected, replace it with torch.linalg.cholesky()"}
{"number": 1152, "change": "def rnn(step_function, inputs, initial_states,\nnew_states = []\n\n# all this circus is to recover the last vector in the sequence.\n-        begin = tf.pack([tf.shape(outputs)[0] - 1] + [0] * (ndim - 1))\n-        size = tf.pack([1] + [-1] * (ndim - 1))\n-        last_output = tf.slice(outputs, begin, size)\n+        slice_begin = tf.pack([tf.shape(outputs)[0] - 1] + [0] * (ndim - 1))\n+        slice_size = tf.pack([1] + [-1] * (ndim - 1))\n+        last_output = tf.slice(outputs, slice_begin, slice_size)\nlast_output = tf.squeeze(last_output, [0])\n\naxes = [1, 0] + list(range(2, len(outputs.get_shape())))\n", "fix_pattern": "if tf.pack() is detected, replace it with tf.stack()"}
{"number": 1190, "change": "class TorchCheckpointWrapper(CheckpointWrapper):\n#  --> https://github.com/facebookresearch/fairscale/blob/1e4a503cda8571851a68effd6e504a192838ab06/fairscale/nn/checkpoint/checkpoint_activations.py#L145-L153  # noqa: E501\n# We just patch the forward method to avoid having to proxy all the fields and other methods.\n# The use of weakref here is to prevent creating a ref cycle: m -> m.forward -> m.\n+\n+        assert len(kwargs) == 0  # This way of wrapping only works for positional arguments.\n+\nmodule.forward = functools.partial(  # type: ignore[assignment]\n_checkpointed_forward, type(module).forward, weakref.ref(module)\n)\n", "fix_pattern": "if an assert statement is added to validate the number of keyword arguments, add a comment indicating that it only works for positional arguments."}
{"number": 1193, "change": "class RNN(torch.nn.Module):\ndef __init__(self, idim, elayers, cdim, hdim, dropout, typ=\"blstm\"):\nsuper(RNN, self).__init__()\nbidir = typ[0] == \"b\"\n-        self.nblstm = torch.nn.LSTM(idim, cdim, elayers, batch_first=True,\n-                                    dropout=dropout, bidirectional=bidir) if \"lstm\" in typ \\\n+        self.nbrnn = torch.nn.LSTM(idim, cdim, elayers, batch_first=True,\n+                                   dropout=dropout, bidirectional=bidir) if \"lstm\" in typ \\\nelse torch.nn.GRU(idim, cdim, elayers, batch_first=True, dropout=dropout,\nbidirectional=bidir)\nif bidir:\n", "fix_pattern": "if an LSTM layer is detected (torch.nn.LSTM), and the variable name contains \"lstm\", replace self.nblstm with self.nbrnn"}
{"number": 1200, "change": "class TokenCharactersIndexer(TokenIndexer[List[int]]):\n# Removes the \"dummy token\".\npadded_tokens.pop()\n# Truncates all the tokens to the desired length, and return the result.\n-        return {key: [list(token[:desired_token_length]) for token in padded_tokens]}\n+        return {key: torch.LongTensor([list(token[:desired_token_length])\n+                                       for token in padded_tokens])}\n", "fix_pattern": "If a list comprehension is used to create a nested list, replace it with a torch.LongTensor() call."}
{"number": 1201, "change": "class LKJCorrCholesky(TorchDistribution):\nKm1 = self._d - 1\n\nlog_diagonals = x.diagonal(offset=0, dim1=-1, dim2=-2)[..., 1:].log()\n+        # TODO: Figure out why the `device` kwarg to torch.linspace seems to not work in certain situations,\n+        # and a seemingly redundant .to(x.device) is needed below.\nvalues = log_diagonals * torch.linspace(start=Km1 - 1, end=0, steps=Km1,\ndtype=x.dtype,\n-                                                device=x.device).expand_as(log_diagonals)\n+                                                device=x.device).expand_as(log_diagonals).to(x.device)\n\nvalues += log_diagonals.mul(eta.mul(2).add(-2.0))\nvalues = values.sum(-1) + lp\n", "fix_pattern": "if an API call with the `device` keyword argument is detected, add `.to(x.device)` after the API call."}
{"number": 1215, "change": "class EKFState(object):\nS = H.mm(P).mm(H.transpose(-1, -2)) + R  # innovation cov\n\nK_prefix = self._cov.mm(H.transpose(-1, -2))\n-        dx = K_prefix.mm(torch.gesv(dz, S)[0]).squeeze(1)  # K*dz\n+        dx = K_prefix.mm(torch.gesv(dz.unsqueeze(1), S)[0]).squeeze(1)  # K*dz\nx = self._dynamic_model.geodesic_difference(x, -dx)\n\nI = eye_like(x, self._dynamic_model.dimension)  # noqa: E741\n", "fix_pattern": "if an input tensor is detected as a vector (with shape [n]), unsqueeze it to add an extra dimension (dz.unsqueeze(1)) before using it in mathematical operations."}
{"number": 1230, "change": "class patch_submodule:\nExamples:\n\n>>> import importlib\n-        >>> from datasets.load import prepare_module\n+        >>> from datasets.load import dataset_module_factory\n>>> from datasets.streaming import patch_submodule, xjoin\n>>>\n-        >>> snli_module_path, _ = prepare_module(\"snli\")\n-        >>> snli_module = importlib.import_module(snli_module_path)\n+        >>> dataset_module = dataset_module_factory(\"snli\")\n+        >>> snli_module = importlib.import_module(dataset_module.module_path)\n>>> patcher = patch_submodule(snli_module, \"os.path.join\", xjoin)\n>>> patcher.start()\n>>> assert snli_module.os.path.join is xjoin\n", "fix_pattern": "if importing a module using the prepare_module() function is detected, replace it with dataset_module_factory() function and update the import statement."}
{"number": 1248, "change": "class DeepSpeedZeRoOffload(object):\nself._prefetch_bucket_sz = int(prefetch_bucket_size)\nself._max_reuse_distance_in_numel = int(max_reuse_distance)\nself._max_available_parameters_in_numel = int(max_live_parameters)\n-        self.__allgather_stream = Stream(\n-        ) if overlap_comm else torch.cuda.default_stream()\n+        self.__allgather_stream = get_accelerator().Stream(\n+        ) if overlap_comm else get_accelerator().default_stream()\n\nself.forward_hooks = []\nself.backward_hooks = []\n", "fix_pattern": "if the CUDA stream object is created using torch.cuda.default_stream(), replace it with get_accelerator().default_stream()"}
{"number": 1257, "change": "class Module(tf.Module):\nelif initializer == 'ones':\ninitializer = tf_util.ones(shape=spec.shape, dtype=spec.type)\nelif initializer == 'constant':\n-            initializer = tf_util.fill(dims=spec.shape, value=self.initialization_scale)\n+            initializer = tf.fill(\n+                dims=spec.shape, value=tf_util.constant(value=initialization_scale, dtype=spec.type)\n+            )\n\n# Variable\nvariable = tf.Variable(\n", "fix_pattern": "if tf_util.fill() is detected, replace with tf.fill(), and modify the arguments accordingly"}
{"number": 1266, "change": "PT_SEQUENCE_CLASSIFICATION_SAMPLE = r\"\"\"\n...     \"{checkpoint}\", num_labels=num_labels, problem_type=\"multi_label_classification\"\n... )\n\n-    >>> labels = torch.nn.functional.one_hot(torch.tensor(predicted_class_ids), num_classes=num_labels).to(torch.float)\n+    >>> labels = torch.sum(\n+    ...     torch.nn.functional.one_hot(predicted_class_ids[None, :].clone(), num_classes=num_labels), dim=1\n+    ... ).to(torch.float)\n>>> loss = model(**inputs, labels=labels).loss\n```\n\"\"\"\n", "fix_pattern": "if one_hot() API is detected, clone the input tensor and add [None, :] indexing before calling one_hot() function."}
{"number": 1294, "change": "class SCSEModule(nn.Module):\nnn.Conv2d(in_channels // reduction, in_channels, 1),\nnn.Sigmoid(),\n)\n-        self.sSE = nn.Sequential(nn.Conv2d(in_channels, in_channels, 1), nn.Sigmoid())\n+        self.sSE = nn.Sequential(nn.Conv2d(in_channels, 1, 1), nn.Sigmoid())\n\ndef forward(self, x):\nreturn x * self.cSE(x) + x * self.sSE(x)\n", "fix_pattern": "If a convolutional layer is reshaping the number of channels in a neural network, change the number of output channels from in_channels to 1."}
{"number": 1302, "change": "def main(args):  # pylint: disable=redefined-outer-name\npos_weight=torch.tensor(10)) if c.stopnet else None\n\nif args.restore_path:\n-        checkpoint = torch.load(args.restore_path)\n+        checkpoint = torch.load(args.restore_path, map_location='cpu')\ntry:\n# TODO: fix optimizer init, model.cuda() needs to be called before\n# optimizer restore\n", "fix_pattern": "If loading a checkpoint with torch.load() and the code does not specify a map_location, add map_location='cpu' to the API call."}
{"number": 1308, "change": "def count_nonzero(\ndef _dtype_count_nonzero(a, axis, dtype):\nif dtype is None:\nreturn torch.count_nonzero(a, dim=axis)\n-        return torch.tensor(torch.count_nonzero(a, dim=axis), dtype=dtype)\n+        return torch.tensor(torch.count_nonzero(a, dim=axis),\n+                            dtype=ivy.as_native_dtype(dtype))\n\nx = _dtype_count_nonzero(a, axis, dtype)\nif not keepdims:\n", "fix_pattern": "If the dtype parameter is not the standard PyTorch dtype, wrap it with an appropriate conversion function (such as ivy.as_native_dtype()) to ensure compatibility."}
{"number": 1312, "change": "class TorchTensor(AbstractTensor):\n\n\"\"\"\n\n-        assert isinstance(self.child, PointerTensor)\n+        if not isinstance(self.child, PointerTensor):\n+            raise TypeError(\"child should be a PointerTensor\")\n\nps = list(pointers)\nps.append(self)\n", "fix_pattern": "If an assert statement checking the instance type of an object is detected, replace it with an if statement and raise a TypeError if the condition is not met."}
{"number": 1313, "change": "def unravel_index(\nfor dim in reversed(shape):\noutput.append(temp % dim)\ntemp = temp // dim\n-    return tuple(reversed(output))\n+    return torch.tensor(reversed(output))\n\n\nunravel_index.support_native_out = False\n", "fix_pattern": "if returning a reversed sequence as a tuple, replace with torch.tensor(reversed(sequence))"}
{"number": 1315, "change": "class CanineSelfAttention(nn.Module):\n# Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n# masked positions, this operation will create a tensor which is 0.0 for\n# positions we want to attend and -10000.0 for masked positions.\n-                attention_mask = (1.0 - attention_mask.float()) * -10000.0\n+                attention_mask = (1.0 - attention_mask.float()) * torch.finfo(attention_scores.dtype).min\n# Apply the attention mask (precomputed for all layers in CanineModel forward() function)\nattention_scores = attention_scores + attention_mask\n", "fix_pattern": "if casting a tensor to a specific dtype, use torch.finfo(dtype).min instead of a specific scalar value."}
{"number": 1323, "change": "class TFModel(NNModel, metaclass=TfModelMeta):\nopt_scope = tf.variable_scope(optimizer_scope_name)\nwith opt_scope:\nif learnable_scopes is None:\n-                variables_to_train = tf.trainable_variables()\n+                variables_to_train = tf.global_variables()\nelse:\nvariables_to_train = []\nfor scope_name in learnable_scopes:\n-                    for var in tf.trainable_variables():\n+                    for var in tf.global_variables():\nif scope_name in var.name:\nvariables_to_train.append(var)\n", "fix_pattern": "if the method `tf.trainable_variables()` is detected, replace it with `tf.global_variables()`."}
{"number": 1338, "change": "class EncdecMultiheadAttn(nn.Module):\n\ndef reset_parameters(self):\nnn.init.xavier_uniform_(self.in_proj_weight_q)\n-        nn.init.xavier_uniform_(self.in_proj_weight_kv)\n+        # in_proj_weight_kv has shape [2 * hidden, hidden] but it should be\n+        # initialized like a [hidden, hidden] matrix.\n+        # sqrt(6 / (hidden + hidden)) / sqrt(6 / (2 * hidden + hidden)) = sqrt(1.5)\n+        # therefore xavier_uniform gain should be set to sqrt(1.5).\n+        nn.init.xavier_uniform_(self.in_proj_weight_kv, gain=math.sqrt(1.5))\nnn.init.xavier_uniform_(self.out_proj_weight)\nif self.bias:\nnn.init.constant_(self.in_proj_bias_q, 0.)\n", "fix_pattern": "if an initialization function is called with additional arguments (such as gain), include those arguments in the function call"}
{"number": 1363, "change": "def get_timestep_embedding(\nassert len(timesteps.shape) == 1, \"Timesteps should be a 1d-array\"\n\nhalf_dim = embedding_dim // 2\n-    exponent = -math.log(max_period) * torch.arange(start=0, end=half_dim, dtype=torch.float32)\n+    exponent = -math.log(max_period) * torch.arange(\n+        start=0, end=half_dim, dtype=torch.float32, device=timesteps.device\n+    )\nexponent = exponent / (half_dim - downscale_freq_shift)\n\n-    emb = torch.exp(exponent).to(device=timesteps.device)\n+    emb = torch.exp(exponent)\nemb = timesteps[:, None].float() * emb[None, :]\n\n# scale embeddings\n", "fix_pattern": "if a tensor is created with the .to() method, move the device argument to the end of the API call."}
{"number": 1373, "change": "def train_func(config):\ntrain_dataset = Subset(train_dataset, list(range(64)))\nvalidation_dataset = Subset(validation_dataset, list(range(64)))\n\n-    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"])\n-    validation_loader = DataLoader(validation_dataset, batch_size=config[\"batch_size\"])\n+    worker_batch_size = config[\"batch_size\"] // train.world_size()\n+\n+    train_loader = DataLoader(train_dataset, batch_size=worker_batch_size)\n+    validation_loader = DataLoader(validation_dataset, batch_size=worker_batch_size)\n\ntrain_loader = train.torch.prepare_data_loader(train_loader)\nvalidation_loader = train.torch.prepare_data_loader(validation_loader)\n", "fix_pattern": "if train.world_size() is used to determine the worker batch size, divide the original batch size (config[\"batch_size\"]) by train.world_size() to get the worker batch size."}
{"number": 1397, "change": "def binary_config():\ndef test_binary_input_feature(binary_config: Dict, encoder: str) -> None:\nbinary_config.update({\"encoder\": encoder})\nbinary_input_feature = BinaryInputFeature(binary_config)\n-    binary_tensor = torch.randn([SEQ_SIZE, BINARY_W_SIZE], dtype=torch.float32)\n+    binary_tensor = torch.randn([SEQ_SIZE, BINARY_W_SIZE], dtype=torch.float32).to(DEVICE)\nencoder_output = binary_input_feature(binary_tensor)\nassert encoder_output[\"encoder_output\"].shape[1:] == binary_input_feature.output_shape\n", "fix_pattern": "if a tensor is created without specifying the device, add .to(device) to the end of the API call"}
{"number": 1399, "change": "class TestEulerFromQuaternion(BaseTester):\ndef test_module(self, device, dtype):\npass\n\n-    def test_jit(self, device, dtype):\n+    def test_dynamo(self, device, dtype, torch_optimizer):\nq = Quaternion.random(batch_size=1)\nq = q.to(device, dtype)\nop = euler_from_quaternion\n-        op_jit = torch.jit.script(op)\n-        assert_close(op(q.w, q.x, q.y, q.z), op_jit(q.w, q.x, q.y, q.z))\n+        op_optimized = torch_optimizer(op)\n+        assert_close(op(q.w, q.x, q.y, q.z), op_optimized(q.w, q.x, q.y, q.z))\n\ndef test_forth_and_back(self, device, dtype):\nq = Quaternion.random(batch_size=2)\n", "fix_pattern": "If using torch.jit.script(op) is detected, replace it with torch_optimizer(op) and update the test method name from \"test_jit\" to \"test_dynamo\"."}
{"number": 1405, "change": "def run(\nseen, windows, dt = 0, [], (Profile(), Profile(), Profile())\nfor path, im, im0s, vid_cap, s in dataset:\nwith dt[0]:\n-            im = torch.Tensor(im).to(device)\n+            im = torch.Tensor(im).to(model.device)\nim = im.half() if model.fp16 else im.float()  # uint8 to fp16/32\nif len(im.shape) == 3:\nim = im[None]  # expand for batch dim\n", "fix_pattern": "if a tensor is being moved to a specific device, replace .to(device) with .to(model.device)"}
{"number": 1415, "change": "class SwapBufferManager(object):\nself.count = count\nself.dtype = dtype\nself.all_buffers = [\n-            torch.zeros(num_elems,\n-                        device='cpu',\n-                        dtype=dtype).pin_memory() for _ in range(count)\n+            get_accelerator().pin_memory(\n+                torch.zeros(num_elems,\n+                            device='cpu',\n+                            dtype=dtype)) for _ in range(count)\n]\nself.free_buffer_index = [i for i in range(count)]\nself.used_buffer_index = {}\n", "fix_pattern": "if pin_memory() is called on a tensor, use get_accelerator().pin_memory() to pin the tensor to accelerator memory."}
{"number": 1427, "change": "def test_gcn2_conv():\n\nt = '(Tensor, Tensor, SparseTensor, OptTensor) -> Tensor'\njit = torch.jit.script(conv.jittable(t))\n-    assert torch.allclose(conv(x, x_0, adj1.t()), out1, atol=1e-6)\n-    assert torch.allclose(conv(x, x_0, adj2.t()), out2, atol=1e-6)\n+    assert torch.allclose(jit(x, x_0, adj1.t()), out1, atol=1e-6)\n+    assert torch.allclose(jit(x, x_0, adj2.t()), out2, atol=1e-6)\n\nconv.cached = True\nconv(x, x_0, edge_index)\n", "fix_pattern": "if conv is detected as the API method, replace it with jit."}
{"number": 1435, "change": "def test_load_dataset_streaming(dataset_loading_script_dir, data_dir):\ndef test_loading_from_the_datasets_hub():\nwith tempfile.TemporaryDirectory() as tmp_dir:\ndataset = load_dataset(SAMPLE_DATASET_IDENTIFIER, cache_dir=tmp_dir)\n-        assert len(dataset[\"train\"]), 2\n-        assert len(dataset[\"validation\"]), 3\n+        assert len(dataset[\"train\"]) == 2\n+        assert len(dataset[\"validation\"]) == 3\ndel dataset\n", "fix_pattern": "if assert statement has a comma-separated expression with a numeric value, replace it with a comparison statement using '=='."}
{"number": 1450, "change": "class BertForQuestionAnswering(nn.Module):\n\ndef compute_loss(logits, positions):\nmax_position = positions.max().item()\n-                one_hot = torch.FloatTensor(batch_size, max(max_position, seq_length) +1, device=input_ids.device).zero_()\n+                one_hot = torch.FloatTensor(batch_size, max(max_position, seq_length) +1).zero_()\none_hot = one_hot.scatter(1, positions.cpu(), 1) # Second argument need to be LongTensor and not cuda.LongTensor\n-                one_hot = one_hot[:, :seq_length]\n+                one_hot = one_hot[:, :seq_length].to(input_ids.device)\nlog_probs = nn.functional.log_softmax(logits, dim = -1).view(batch_size, seq_length)\nloss = -torch.mean(torch.sum(one_hot*log_probs), dim = -1)\nreturn loss\n", "fix_pattern": "if a tensor is initialized with device attribute, add .to(device) to the end of the API call"}
{"number": 1463, "change": "def main():\n\n# Save the result as an audio summary.\ndatestring = str(datetime.now()).replace(' ', 'T')\n-    writer = tf.train.SummaryWriter(logdir)\n-    tf.audio_summary('generated', decode, wavenet_params['sample_rate'])\n-    summaries = tf.merge_all_summaries()\n+    writer = tf.summary.FileWriter(logdir)\n+    tf.summary.audio('generated', decode, wavenet_params['sample_rate'])\n+    summaries = tf.summary.merge_all()\nsummary_out = sess.run(summaries,\nfeed_dict={samples: np.reshape(waveform, [-1, 1])})\nwriter.add_summary(summary_out)\n", "fix_pattern": "if the API calls tf.train.SummaryWriter, tf.audio_summary, tf.merge_all_summaries() are detected,\nreplace them with tf.summary.FileWriter, tf.summary.audio, tf.summary.merge_all() respectively."}
{"number": 1465, "change": "def load_indexes():\n\n@st.cache(allow_output_mutation=True)\ndef load_train_data():\n-    eli5 = nlp.load_dataset(\"eli5\", name=\"LFQA_reddit\")\n+    eli5 = datasets.load_dataset(\"eli5\", name=\"LFQA_reddit\")\neli5_train = eli5[\"train_eli5\"]\neli5_train_q_reps = np.memmap(\n\"eli5_questions_reps.dat\", dtype=\"float32\", mode=\"r\", shape=(eli5_train.num_rows, 128)\n", "fix_pattern": "if a dataset is loaded using the method nlp.load_dataset, replace it with datasets.load_dataset"}
{"number": 1466, "change": "def depthwise_conv2d(\ndilations: Optional[Union[int, Tuple[int, int]]] = 1,\nout: Optional[torch.Tensor] = None,\n) -> torch.Tensor:\n-    x = torch.tensor(x)\n-    filters = torch.tensor(filters)\n+    x = torch.as_tensor(x)\n+    filters = torch.as_tensor(filters)\nstrides = [strides] * 2 if isinstance(strides, int) else strides\nstrides = [strides[1], strides[2]] if len(strides) == 4 else strides\ndilations = [dilations] * 2 if isinstance(dilations, int) else dilations\n-    filters = ivy.squeeze(filters, 3) if filters.ndim == 4 else filters\n+    filters = ivy.squeeze(filters, 3).to_native() if filters.ndim == 4 else filters\n\nf_w_after_dilation = filters.shape[1] + (\n(dilations[1] - 1) * (filters.shape[1] - 1)\n", "fix_pattern": "if torch.tensor() is detected, replace with torch.as_tensor(). If ivy.squeeze() is detected, add .to_native() to the end of the API call."}
{"number": 1477, "change": "class RandomMutator(Mutator):\nresult = dict()\nfor mutable in self.mutables:\nif isinstance(mutable, LayerChoice):\n-                gen_index = torch.randint(high=mutable.length, size=(1, ))\n-                result[mutable.key] = F.one_hot(gen_index, num_classes=mutable.length).view(-1).bool()\n+                gen_index = torch.randint(high=len(mutable), size=(1, ))\n+                result[mutable.key] = F.one_hot(gen_index, num_classes=len(mutable)).view(-1).bool()\nelif isinstance(mutable, InputChoice):\nif mutable.n_chosen is None:\nresult[mutable.key] = torch.randint(high=2, size=(mutable.n_candidates,)).view(-1).bool()\n", "fix_pattern": "if an object has a property length, replace mutable.length with len(mutable)"}
{"number": 1507, "change": "def indices_where(\ndef shape(\nx: Union[tf.Tensor, tf.Variable],\nas_array: bool = False,\n-) -> Union[tf.Tensor, tf.Variable, TensorShape]:\n+) -> Union[tf.Tensor, ivy.Shape, ivy.Array]:\nif as_array:\n-        return tf.shape(x)\n+        return ivy.array(tf.shape(x))\nelse:\n-        return tuple(x.shape)\n+        return ivy.Shape(x.shape)\n\n\ndef get_num_dims(x, as_tensor=False):\n", "fix_pattern": "if tf.Tensor or tf.Variable is detected in the return type annotation, replace with ivy.Shape or ivy.Array"}
{"number": 1532, "change": "def remainder(\nres_floored = torch.where(res >= 0, torch.floor(res), torch.ceil(res))\ndiff = res - res_floored\ndiff, x2 = ivy.promote_types_of_inputs(diff, x2)\n-        return torch.mul(diff, x2, out=out).to(x1.dtype)\n+        return torch.round(torch.mul(diff, x2, out=out), out=out).to(x1.dtype)\nreturn torch.remainder(x1, x2, out=out)\n", "fix_pattern": "if torch.mul() is detected, add a torch.round() before it"}
{"number": 1535, "change": "def guide(observed_data):\n\n# do variational inference using KL_QP\nprint(\"doing inference with simulated data\")\n-verbose = False\n+verbose = True\nn_steps = 3001\nkl_optim = KL_QP(model, guide, pyro.optim(optim.Adam, {\"lr\": 0.003, \"betas\": (0.93, 0.993)}))\nfor step in range(n_steps):\nloss = kl_optim.step(observed_data)\nif step % 100 == 0:\nif verbose:\n-            print(\"[epoch %d] mean_mu: %.3f\" % (step, pyro.param(\"mean_mu\").data[0, 0]))\n+            print(\"[epoch %d] mean_mu: %.3f\" % (step, pyro.param(\"mean_mu\").data[0]))\nprint(\"[epoch %d] sigma_mu: %.3f\" % (step,\n-                                                 torch.exp(pyro.param(\"log_sigma_mu\")).data[0, 0]))\n+                                                 torch.exp(pyro.param(\"log_sigma_mu\")).data[0]))\nelse:\nprint(\".\", end='')\nsys.stdout.flush()\n", "fix_pattern": "if verbose flag is detected, change the value to True."}
{"number": 1538, "change": "class UNet2DConditionModel(ModelMixin, ConfigMixin):\n# TODO: this requires sync between CPU and GPU. So try to pass timesteps as tensors if you can\n# This would be a good case for the `match` statement (Python 3.10+)\nis_mps = sample.device.type == \"mps\"\n-            if torch.is_floating_point(timesteps):\n+            if isinstance(timestep, float):\ndtype = torch.float32 if is_mps else torch.float64\nelse:\ndtype = torch.int32 if is_mps else torch.int64\n", "fix_pattern": "if torch.is_floating_point(variable_name): -> if isinstance(variable_name, float):"}
{"number": 1543, "change": "def test_utilities(head_size):\nmask[head_size:, head_size:] = 0.\nmask.view(-1)[::size + 1][head_size:] = 1.\narrowhead_full = mask * cov\n-    expected = torch.flip(torch.flip(arrowhead_full, (-2, -1)).cholesky(), (-2, -1))\n+    expected = torch.flip(\n+        torch.linalg.cholesky(torch.flip(arrowhead_full, (-2, -1))), (-2, -1)\n+    )\n# test if those flip ops give expected upper triangular values\nassert_close(expected.triu(), expected)\nassert_close(expected.matmul(expected.t()), arrowhead_full)\n", "fix_pattern": "if torch.flip().cholesky() is detected, replace it with torch.linalg.cholesky(torch.flip())"}
{"number": 1565, "change": "class CharacterEmbeddings(TokenEmbeddings):\nlongest_token_in_sentence = max(chars2_length)\ntokens_mask = torch.zeros((len(tokens_sorted_by_length), longest_token_in_sentence),\ndtype=torch.long, device=flair.device)\n+\nfor i, c in enumerate(tokens_sorted_by_length):\n-                tokens_mask[i, :chars2_length[i]] = c\n+                tokens_mask[i, :chars2_length[i]] = torch.tensor(c, dtype=torch.long, device=flair.device)\n\n# chars for rnn processing\nchars = tokens_mask\n", "fix_pattern": "if tensor is detected without a specific device, add .to(device) to the end of the API call and specify the dtype as torch.long."}
{"number": 1576, "change": "def init_seeds(seed=0, deterministic=False):\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)  # for Multi-GPU, exception safe\n-    torch.backends.cudnn.benchmark = True  # for faster training\n+    # torch.backends.cudnn.benchmark = True  # AutoBatch problem https://github.com/ultralytics/yolov5/issues/9287\nif deterministic and check_version(torch.__version__, '1.12.0'):  # https://github.com/ultralytics/yolov5/pull/8213\ntorch.use_deterministic_algorithms(True)\ntorch.backends.cudnn.deterministic = True\n", "fix_pattern": "If torch.backends.cudnn.benchmark = True is detected, comment out the line and provide an explanation for why it was commented out."}
{"number": 1579, "change": "def inv(\n*,\nout: Optional[Union[tf.Tensor, tf.Variable]] = None,\n) -> Union[tf.Tensor, tf.Variable]:\n-    if tf.math.reduce_any(tf.linalg.det(x) == 0):\n+    if tf.math.reduce_any(tf.linalg.det(tf.cast(x, dtype=\"float64\")) == 0):\nret = x\nelse:\nret = tf.linalg.inv(x)\n", "fix_pattern": "if tf.linalg.det(x) is detected, cast the tensor to dtype=\"float64\" before calling tf.linalg.det(x)"}
{"number": 1582, "change": "class Init(InsertPostInitMethodToModuleSubClasses):\n\nsee_memory_usage(f'Before partitioning param {param.ds_id} {param.shape}',\nforce=False)\n-            param.data = torch.ones(1).half().to(param.device)\n+            param.data = torch.ones(partitioned_param_data_shape).half().to(param.device)\nsee_memory_usage(f'After partitioning param {param.ds_id} {param.shape}',\nforce=False)\n", "fix_pattern": "If a parameter is of type torch.HalfTensor, replace torch.ones(1).half() with torch.ones(partitioned_param_data_shape).half()."}
{"number": 1587, "change": "class TorchService(BaseService):\n\n# FLOAT TENSOR FUNCTIONS\ndef hook_float_tensor___init__(service_self):\n-        def new___init__(self, tensor, owner=service_self, *args, **kwargs):\n-            super(torch.FloatTensor, self).__init__(*args, **kwargs)\n-            self = owner.register_object(self, False)\n+        def new___init__(self, *args):\n+            super(torch.FloatTensor, self).__init__()\n+            self = service_self.register_object(self, False)\n\ntorch.FloatTensor.__init__ = new___init__\n", "fix_pattern": "if a custom __init__ method is detected in a class and the owner parameter is removed, replace owner=service_self with *args in the method signature and replace owner.register_object with service_self.register_object"}
{"number": 1591, "change": "def demo_gan(checkpoint_paths):\nimg_list = []\nfixed_noise = torch.randn(64, nz, 1, 1)\nfor path in checkpoint_paths:\n-        netG_path = os.path.join(path, \"checkpoint.pt\")\n+        checkpoint_dict = Checkpoint.from_directory(path).to_dict()\nloadedG = Generator()\n-        loadedG.load_state_dict(torch.load(netG_path)[\"netGmodel\"])\n+        loadedG.load_state_dict(checkpoint_dict[\"netGmodel\"])\nwith torch.no_grad():\nfake = loadedG(fixed_noise).detach().cpu()\nimg_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n", "fix_pattern": "If loading a model using `torch.load()` is detected, replace it with `Checkpoint.from_directory().to_dict()` and use `load_state_dict()` with the corresponding dictionary key."}
{"number": 1592, "change": "class PNAConv(MessagePassing):\nreturn y\n\ndef aggregate(self, inputs, index, dim_size=None):\n-        D = get_degree(inputs, index, self.node_dim, dim_size)\n+        D = get_degree(inputs, index, 0, dim_size)\n\n# aggregators\n-        inputs = torch.cat([aggregator(inputs, index, dim=self.node_dim, dim_size=dim_size)\n+        inputs = torch.cat([aggregator(inputs, index, dim=0, dim_size=dim_size)\nfor aggregator in self.aggregators], dim=-1)\n# scalers\nreturn torch.cat([scaler(inputs, D, self.avg_d) for scaler in self.scalers], dim=-1)\n", "fix_pattern": "if an API call with variable as argument is detected, replace the variable with a specific value"}
{"number": 1596, "change": "class FP16_Optimizer(DeepSpeedOptimizer):\nwill call ``model.load_state_dict()`` before\n``fp16_optimizer_instance.load_state_dict()`` is called.\nExample::\n-            model = torch.nn.Linear(D_in, D_out).cuda().half()\n+            model = torch.nn.Linear(D_in, D_out).to(get_accelerator().device_name()).half()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\noptimizer = FP16_Optimizer(optimizer, static_loss_scale = 128.0)\n...\n", "fix_pattern": "if an API call to cuda() is detected, replace it with .to(device) and obtain the device name using get_accelerator().device_name()"}
{"number": 1604, "change": "def read_state_dict(checkpoint_file, print_global_state=False, map_location=None\nif extension.lower() == \".safetensors\":\ndevice = map_location or shared.weight_load_location\nif device is None:\n-            device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n+            device = devices.get_cuda_device_string() if torch.cuda.is_available() else \"cpu\"\npl_sd = safetensors.torch.load_file(checkpoint_file, device=device)\nelse:\npl_sd = torch.load(checkpoint_file, map_location=map_location or shared.weight_load_location)\n", "fix_pattern": "if device assignment is done using \"cuda:0\" string, replace with devices.get_cuda_device_string()"}
{"number": 1611, "change": "def RemoteTrainer(estimator, metadata, keras_utils, run_id, dataset_idx):\nif LooseVersion(tf.__version__) < LooseVersion(\"2.0.0\"):\nmodel.load_weights(ckpt_file)\nelse:\n-                        model = k.models.load_model(ckpt_file)\n+                        # needs to be deserialized in the with scope\n+                        with k.utils.custom_object_scope(custom_objects):\n+                            model = k.models.load_model(ckpt_file)\nserialized_model = keras_utils.serialize_model(model)\nelse:\nwith open(ckpt_file, 'rb') as f:\n", "fix_pattern": "if loading a model using the keras load_model() function, wrap it in a with statement with custom_object_scope to ensure custom objects are properly deserialized"}
{"number": 1629, "change": "class MultiHeadSelfAttention(nn.Module):\nq = q / math.sqrt(dim_per_head)  # (bs, n_heads, q_length, dim_per_head)\nscores = torch.matmul(q, k.transpose(2, 3))  # (bs, n_heads, q_length, k_length)\nmask = (mask == 0).view(mask_reshp).expand_as(scores)  # (bs, n_heads, q_length, k_length)\n-        scores = scores.masked_fill(mask, -float(\"inf\"))  # (bs, n_heads, q_length, k_length)\n+        scores = scores.masked_fill(mask, torch.tensor(-float(\"inf\")))  # (bs, n_heads, q_length, k_length)\n\nweights = nn.functional.softmax(scores, dim=-1)  # (bs, n_heads, q_length, k_length)\nweights = self.dropout(weights)  # (bs, n_heads, q_length, k_length)\n", "fix_pattern": "if masked_fill() is called with a scalar value -float(\"inf\"), replace it with torch.tensor(-float(\"inf\"))"}
{"number": 1649, "change": "def get_extensions():\nextra_compile_args = {\"cxx\": []}\ndefine_macros = []\n\n-    if torch.cuda.is_available() and CUDA_HOME is not None:\n+    if (torch.cuda.is_available() and CUDA_HOME is not None) or os.getenv(\"FORCE_CUDA\", \"0\") == \"1\":\nextension = CUDAExtension\nsources += source_cuda\ndefine_macros += [(\"WITH_CUDA\", None)]\n", "fix_pattern": "if a check for CUDA availability is detected, add an additional condition (or os.getenv(\"FORCE_CUDA\", \"0\") == \"1\")"}
{"number": 1659, "change": "class AlbertMLMHead(nn.Module):\ndef __init__(self, config):\nsuper().__init__()\n\n-        self.LayerNorm = nn.LayerNorm(config.embedding_size)\n+        self.LayerNorm = nn.LayerNorm(config.embedding_size, eps=config.layer_norm_eps)\nself.bias = nn.Parameter(torch.zeros(config.vocab_size))\nself.dense = nn.Linear(config.hidden_size, config.embedding_size)\nself.decoder = nn.Linear(config.embedding_size, config.vocab_size)\n", "fix_pattern": "if nn.LayerNorm is initialized without an explicit value for eps, add eps=config.layer_norm_eps as a parameter"}
{"number": 1668, "change": "def run(\nseen, windows, dt = 0, [], (Profile(), Profile(), Profile())\nfor path, im, im0s, vid_cap, s in dataset:\nwith dt[0]:\n-            im = im.to(device)\n+            im = torch.Tensor(im).to(device)\nim = im.half() if model.fp16 else im.float()  # uint8 to fp16/32\nif len(im.shape) == 3:\nim = im[None]  # expand for batch dim\n", "fix_pattern": "If an image tensor is detected being moved to a specific device using .to(), change the code to wrap the tensor in the torch.Tensor() call before applying .to(device)."}
{"number": 1680, "change": "class ParameterNoise(Exploration):\nelse:\nfor i in range(len(self.noise)):\nself.noise[i] = torch.normal(\n-                    0.0, self.stddev, size=self.noise[i].size())\n+                    mean=torch.zeros(self.noise[i].size()), std=self.stddev)\n\ndef _tf_sample_new_noise_op(self):\nadded_noises = []\n", "fix_pattern": "if generating noise using torch.randn() with mean and stddev parameters, replace the call with torch.normal(mean, std)"}
{"number": 1685, "change": "class DartsLayerChoice(nn.Module):\nyield name, p\n\ndef export(self):\n-        return torch.argmax(self.alpha).item()\n+        return list(self.op_choices.keys())[torch.argmax(self.alpha).item()]\n\n\nclass DartsInputChoice(nn.Module):\ndef __init__(self, input_choice):\nsuper(DartsInputChoice, self).__init__()\n-        self.name = input_choice.key\n+        self.name = input_choice.label\nself.alpha = nn.Parameter(torch.randn(input_choice.n_candidates) * 1e-3)\nself.n_chosen = input_choice.n_chosen or 1\n", "fix_pattern": "if returning an item from a dictionary is detected, use the list() function to get the key, and update the variable name accordingly."}
{"number": 1697, "change": "class Init(InsertPostInitMethodToModuleSubClasses):\nparam.all_gather()\nreturn param._orig_item()\n\n-        def ds_summary(slf: torch.Tensor) -> dict:\n+        def ds_summary(slf: torch.Tensor, use_debug_name: bool = False) -> dict:\nreturn {\n-                \"id\": slf.ds_id,\n+                \"id\": debug_param2name_id(slf) if use_debug_name else slf.ds_id,\n\"status\": slf.ds_status.name,\n\"numel\": slf.numel(),\n\"ds_numel\": slf.ds_numel,\n", "fix_pattern": "If a new parameter \"use_debug_name\" is added to a function and its default value is False, modify the function definition to include the new parameter with its default value."}
{"number": 1707, "change": "class ScoreSdeVeScheduler(SchedulerMixin, ConfigMixin):\n\n# For small batch sizes, the paper \"suggest replacing norm(z) with sqrt(d), where d is the dim. of z\"\n# sample noise for correction\n-        noise = torch.randn(sample.shape, layout=sample.layout, generator=generator).to(sample.device)\n+        noise = randn_tensor(sample.shape, layout=sample.layout, generator=generator).to(sample.device)\n\n# compute step size from the model_output, the noise, and the snr\ngrad_norm = torch.norm(model_output.reshape(model_output.shape[0], -1), dim=-1).mean()\n", "fix_pattern": "if torch.randn() is detected, replace with randn_tensor()"}
{"number": 1719, "change": "def extract_fbank_features(\nif output_path is not None and output_path.is_file() and not overwrite:\nreturn\n\n-    _waveform = waveform * (2 ** 15)  # Kaldi compliance: 16-bit signed integers\n-    _waveform = _waveform.squeeze().numpy()\n+    _waveform = _convert_to_mono(waveform, sample_rate)\n+    _waveform = _waveform * (2 ** 15)  # Kaldi compliance: 16-bit signed integers\n+    _waveform = _waveform.numpy()\n\nfeatures = _get_kaldi_fbank(_waveform, sample_rate, n_mel_bins)\nif features is None:\n", "fix_pattern": "if a squeeze() operation is detected after the API call, remove it and replace the API call with a new function _convert_to_mono()."}
{"number": 1739, "change": "class DistributionStrategyCheckpointTest(test_utils.TestCase,\n\ndef assertRestoreOnCreateInReplicaContext(self, golden, strategy,\nuse_function):\n+    if self.primary_device == \"GPU\":\n+      self.skipTest(\"Currently not working as expected on multiple devices\")\n+      # TODO(b/134376796) renable this once bug is fixed\nwith strategy.scope():\nmodule = golden.create_module()\n", "fix_pattern": "if a condition is detected to skip a test, add a comment with a TODO to re-enable the test once the bug is fixed."}
{"number": 1742, "change": "def run_modelmerger(primary_model_name, secondary_model_name, teritary_model_nam\nif theta_func1:\nfor key in tqdm.tqdm(theta_1.keys()):\nif 'model' in key:\n-                t2 = theta_2.get(key, torch.zeros_like(theta_1[key]))\n-                theta_1[key] = theta_func1(theta_1[key], t2)\n+                if key in theta_2:\n+                    t2 = theta_2.get(key, torch.zeros_like(theta_1[key]))\n+                    theta_1[key] = theta_func1(theta_1[key], t2)\n+                else:\n+                    theta_1[key] = 0\ndel theta_2, teritary_model\n\nfor key in tqdm.tqdm(theta_0.keys()):\n", "fix_pattern": "if a key is detected in a dictionary, add an if condition to check if the key exists before accessing its value. If the key does not exist, assign a default value to the key."}
{"number": 1744, "change": "def get_lst_from_rank0(lst: List[int]) -> None:\nlst_tensor = torch.tensor(\nlst if dist.get_rank() == 0 else [-1] * len(lst),\ndtype=int,\n-        # device=torch.cuda.current_device(),\n-        device=torch.device('cuda:{}'.format(os.environ[\"LOCAL_RANK\"])),\n+        # device=get_accelerator().current_device_name(),\n+        device=torch.device(get_accelerator().device_name(os.environ[\"LOCAL_RANK\"])),\nrequires_grad=False,\n)\ndist.broadcast(lst_tensor, src=0, async_op=False)\n", "fix_pattern": "if device is set to a specific CUDA device using `torch.cuda.current_device()`, replace it with `torch.device('cuda:{}'.format(os.environ[\"LOCAL_RANK\"]))`\nif device is set using `get_accelerator().current_device_name()`, replace it with `torch.device(get_accelerator().device_name(os.environ[\"LOCAL_RANK\"]))`"}
{"number": 1747, "change": "def wrong_module(modelstore, sklearn_onnx_model):\n)\ndef test_onnx_save_load(metadata, save_proc, modelstore, sklearn_onnx_model):\nmodel, data = sklearn_onnx_model\n-    info = save_proc(metadata)\n-    assert info.metadata is not None\n-    assert_have_file_extension(info.path, \".onnx\")\n+    model = save_proc(metadata)\n+    assert model.info.metadata is not None\n+    assert_have_file_extension(model.path, \".onnx\")\n\nopts = ort.SessionOptions()\nopts.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL\nopts.log_verbosity_level = 1\n-    loaded = bentoml.onnx.load(info.tag, model_store=modelstore, session_options=opts)\n+    loaded = bentoml.onnx.load(model.tag, model_store=modelstore, session_options=opts)\nassert predict_arr(loaded, data)[0] == 0\n", "fix_pattern": "If info variable is changed to model, replace info.metadata with model.info.metadata."}
{"number": 1754, "change": "def _precision_to_scale_tril(P):\n# Ref: https://nbviewer.jupyter.org/gist/fehiepsi/5ef8e09e61604f10607380467eb82006#Precision-to-scale_tril\nLf = torch.linalg.cholesky(torch.flip(P, (-2, -1)))\nL_inv = torch.transpose(torch.flip(Lf, (-2, -1)), -2, -1)\n-    L = torch.triangular_solve(\n-        torch.eye(P.shape[-1], dtype=P.dtype, device=P.device), L_inv, upper=False\n-    )[0]\n+    L = torch.linalg.solve_triangular(\n+        L_inv, torch.eye(P.shape[-1], dtype=P.dtype, device=P.device), upper=False\n+    )\nreturn L\n\n\n+@ignore_torch_deprecation_warnings()\ndef _try_possibly_intractable(fn, *args, **kwargs):\n# Convert ValueError into NotImplementedError.\ntry:\n", "fix_pattern": "if torch.triangular_solve( is detected, replace with torch.linalg.solve_triangular("}
{"number": 1766, "change": "class RandomThinPlateSpline(GeometricAugmentationBase2D):\n\ndef generate_parameters(self, shape: torch.Size) -> Dict[str, Tensor]:\nB, _, _, _ = shape\n-        src = torch.tensor([[[-1.0, -1.0], [-1.0, 1.0], [1.0, -1.0], [1.0, 1.0], [0.0, 0.0]]]).repeat(B, 1, 1)  # Bx5x2\n+        src = torch.tensor([[[-1.0, -1.0], [-1.0, 1.0], [1.0, -1.0], [1.0, 1.0], [0.0, 0.0]]]).expand(B, 5, 2)  # Bx5x2\ndst = src + self.dist.rsample(src.shape)\nreturn dict(src=src, dst=dst)\n", "fix_pattern": "The pattern for fixing the API method problem in the above code change is to replace \"repeat\" with \"expand\" and adjust the arguments accordingly. \n\nExplanation: \nIn the original code, the \"repeat\" method is used to repeat the tensor along the specified dimensions. The new code replaces this with the \"expand\" method, which repeats the tensor but doesn't actually replicate the data. Instead, it creates a view of the tensor with the desired size, without actually copying the data. The arguments in the \"expand\" method are adjusted to match the desired size of the expanded tensor."}
{"number": 1779, "change": "class DepthWarper(nn.Module):\nfactor_y = (self.height - 1) / 2\nfactor_y = factor_y.to(device)\n\n-        z = 1. / flow[:, 2]  # Nx(H*W)\n+        z = 1. / (flow[:, 2] + self.eps)  # Nx(H*W)\nx = (flow[:, 0] * z - factor_x) / factor_x\ny = (flow[:, 1] * z - factor_y) / factor_y\n", "fix_pattern": "if a division operation is performed on a tensor, add a small constant to the denominator to avoid division by zero."}
{"number": 1781, "change": "def result_wrapper(result_fn):\n# Wrapping result in identity so that control dependency between\n# update_op from `update_state` and result works in case result\n# returns a tensor.\n-                return tf.identity(result)\n+                return tf.nest.map_structure(tf.identity, result)\n\n# Wrapping result in merge_call. merge_call is used when we want to\n# leave replica mode and compute a value in cross replica mode.\n", "fix_pattern": "if tf.identity() is used on a nested structure, replace it with tf.nest.map_structure(tf.identity, result)"}
{"number": 1787, "change": "class AdalamFilter:\n)\nk1, k2, d1, d2, o1, o2, s1, s2 = self.__to_torch(k1, k2, d1, d2, o1, o2, s1, s2)\nif len(d2) <= 1:\n-            return _no_match(d1)\n+            idxs, dists = _no_match(d1)\n+            if return_dist:\n+                return idxs, dists\n+            return idxs\ndistmat = dist_matrix(d1, d2, is_normalized=False)\ndd12, nn12 = torch.topk(distmat, k=2, dim=1, largest=False)  # (n1, 2)\n", "fix_pattern": "if a function call returns a single value, return the value directly without assigning it to a variable. \nIf the function call returns multiple values and there is an additional condition (such as `if return_dist`), \nassign the return values to variables and then check the condition."}
{"number": 1795, "change": "def assert_cov_validity(cov, eigenvalue_lbnd=0., condition_number_ubnd=1e6):\n# Symmetry\nassert (cov.t() == cov).all(), 'Covariance must be symmetric!'\n# Precompute eigenvalues for subsequent tests.\n-    ws, _ = torch.symeig(cov)  # The eigenvalues of cov\n+    ws = torch.linalg.eigvalsh(cov)  # The eigenvalues of cov\nw_min = torch.min(ws)\nw_max = torch.max(ws)\n", "fix_pattern": "If the deprecated API torch.symeig( is detected, replace it with torch.linalg.eigvalsh("}
{"number": 1804, "change": "class TestNnUtil(AllenNlpTestCase):\n\"b\": FakeTensor(),\n\"c\": (1, FakeTensor()),\n}\n-        new_device = 4\n+        new_device = torch.device(4)\nmoved_obj = util.move_to_device(structured_obj, new_device)\nassert moved_obj[\"a\"][0].a == 1\nassert moved_obj[\"a\"][0].b._device == new_device\n", "fix_pattern": "If assigning a device using an integer value is detected, replace it with torch.device() and pass the integer value as an argument."}
{"number": 1825, "change": "def test_gaussian_tensordot(dot_dims,\nnb = dot_dims\nnc = y_dim - dot_dims\ntry:\n-        torch.cholesky(x.precision[..., na:, na:] + y.precision[..., :nb, :nb])\n+        torch.linalg.cholesky(x.precision[..., na:, na:] + y.precision[..., :nb, :nb])\nexcept RuntimeError:\npytest.skip(\"Cannot marginalize the common variables of two Gaussians.\")\n", "fix_pattern": "If torch.cholesky() is detected, replace it with torch.linalg.cholesky()."}
{"number": 1859, "change": "class MultiHeadSelfAttention(Seq2SeqEncoder):\nkeys_per_head = keys_per_head.view(batch_size * num_heads, timesteps, int(self._attention_dim/num_heads))\n\n# shape (num_heads * batch_size, timesteps, timesteps)\n-        scaled_similarities = torch.bmm(queries_per_head, keys_per_head.transpose(1, 2)) / self._scale\n+        scaled_similarities = torch.bmm(queries_per_head / self._scale, keys_per_head.transpose(1, 2))\n\n# shape (num_heads * batch_size, timesteps, timesteps)\n# Normalise the distributions, using the same mask for all heads.\n-        attention = masked_softmax(scaled_similarities, mask.repeat(1, num_heads).view(batch_size * num_heads, timesteps))\n+        attention = masked_softmax(scaled_similarities,\n+                                   mask.repeat(1, num_heads).view(batch_size * num_heads, timesteps),\n+                                   memory_efficient=True)\nattention = self._attention_dropout(attention)\n\n# Take a weighted sum of the values with respect to the attention\n", "fix_pattern": "if division is detected in torch.bmm() method, move the division outside the method and multiply one of the inputs by the reciprocal of the divisor\nif masked_softmax() method is used, check if the memory_efficient argument is set to True"}
{"number": 1873, "change": "class TestScalarMix(AllenNlpTestCase):\nfor k in range(3):\nmean = numpy.mean(tensors[k].data.numpy()[numpy_mask == 1])\nstd = numpy.std(tensors[k].data.numpy()[numpy_mask == 1])\n-            normed_tensor = (tensors[k].data.numpy() - mean) / (std + 1e-12)\n+            normed_tensor = (tensors[k].data.numpy() - mean) / (\n+                std + util.tiny_value_of_dtype(torch.float)\n+            )\nexpected_result += normed_tensor * normed_weights[k]\nexpected_result *= 0.5\n", "fix_pattern": "If a numpy array is normalized using mean and standard deviation, replace 1e-12 with util.tiny_value_of_dtype(torch.float)"}
{"number": 1880, "change": "class Finfo:\nreturn float(self._tf_finfo.tiny)\n\n\n-def finfo(datatype_in):\n-    return Finfo(tf.experimental.numpy.finfo(datatype_in))\n+def finfo(type):\n+    return Finfo(tf.experimental.numpy.finfo(dtype_from_str(type)))\n\n\nbackend = 'tensorflow'\n", "fix_pattern": "if a function is called on an API object, remove the API object and replace it with an argument for the function."}
{"number": 1895, "change": "class Finfo:\nreturn self._torch_finfo.tiny\n\n\n-def finfo(datatype_in):\n-    return Finfo(_torch.finfo(datatype_in))\n+def finfo(type):\n+    return Finfo(_torch.finfo(dtype_from_str(type)))\n\n\nbackend = 'torch'\n", "fix_pattern": "if a data type parameter is detected with API call, replace it with dtype_from_str(type)"}
{"number": 1915, "change": "class PipelineModule(nn.Module):\nself.tied_weight_attrs = {}\n\n# Offset the random seed by the stage ID.\n-        #newseed = torch.cuda.initial_seed() + self._grid.get_stage_id()\n+        #newseed = get_accelerator().initial_seed() + self._grid.get_stage_id()\n#ds_utils.set_random_seed(newseed)\n\n-        #with torch.random.fork_rng(devices=[torch.cuda.current_device()]):\n+        #with torch.random.fork_rng(devices=[get_accelerator().current_device_name()]):\nself._build()\n-        self.to(f'cuda:{self.local_rank}')\n+        self.to(get_accelerator().device_name(self.local_rank))\n\nself.tied_comms = self._index_tied_modules()\nself._synchronize_tied_weights()\n", "fix_pattern": "If torch.cuda.initial_seed() is detected, replace with get_accelerator().initial_seed(). \nIf torch.cuda.current_device() is detected, replace with get_accelerator().current_device_name(). \nIf self.to(f'cuda:{self.local_rank}') is detected, replace with self.to(get_accelerator().device_name(self.local_rank))."}
{"number": 1932, "change": "class HFGPTJLayerPolicy(DSPolicy):\nkw = self.client_module.attn.k_proj.weight\nvw = self.client_module.attn.v_proj.weight\n\n-        qkvw = torch.cat((qw, kw, vw), dim=0)\n+        qkvw = Parameter(torch.cat((qw, kw, vw), dim=0))\n\nreturn self.linear_layer, \\\nqkvw, \\\n", "fix_pattern": "if a tensor or variable is detected as a concatenation of multiple tensors, replace it with nn.Parameter(tensor)"}
{"number": 1967, "change": "class Graph:\nif pre_node[temp_id] == temp_id:\nbreak\ntemp_id = pre_node[temp_id]\n-        assert temp_id == pre_node[temp_id]\n+        if temp_id != pre_node[temp_id]:\n+            raise AssertionError(\"Error: main chain end condition not met.\")\nret.reverse()\nreturn ret\n", "fix_pattern": "The pattern for fixing the API method problem in this code change is:\n- If an assertion statement is removed, replace it with an if statement that raises an AssertionError with an appropriate error message."}
{"number": 1988, "change": "class TransformerEncoderLayerBase(nn.Module):\n# the attention weight (before softmax) for some padded element in query\n# will become -inf, which results in NaN in model parameters\nif attn_mask is not None:\n-            attn_mask = attn_mask.masked_fill(attn_mask.to(torch.bool), -1e8)\n+            attn_mask = attn_mask.masked_fill(\n+                attn_mask.to(torch.bool),\n+                -1e8 if x.dtype == torch.float32 else -1e4\n+            )\n\nresidual = x\nif self.normalize_before:\n", "fix_pattern": "if an attn_mask tensor is detected with .to(torch.bool) operation, change the value that is filled in with masked_fill() based on the dtype of the tensor."}
{"number": 1989, "change": "class QModel(Model):\n\n# If loss clipping is used, calculate the huber loss\nif config.clip_loss > 0.0:\n-                huber_loss = tf.where(condition=(tf.abs(delta) < config.clip_loss), x=(0.5 * self.loss_per_instance), y=(tf.abs(delta) - 0.5))\n+                huber_loss = tf.where(condition=(tf.abs(delta) < config.clip_loss), x=(0.5 * self.loss_per_instance),\n+                                      y=config.clip_loss * tf.abs(delta) - 0.5 * config.clip_loss ** 2)\nself.q_loss = tf.reduce_mean(input_tensor=huber_loss, axis=0)\nelse:\nself.q_loss = tf.reduce_mean(input_tensor=self.loss_per_instance, axis=0)\n", "fix_pattern": "if tf.abs(delta) - 0.5 is detected, replace it with config.clip_loss * tf.abs(delta) - 0.5 * config.clip_loss ** 2"}
{"number": 2003, "change": "class DecoderTrainer(nn.Module):\nindex = unet_number - 1\nunet = self.decoder.unets[index]\n\n-        if exists(self.max_grad_norm):\n-            nn.utils.clip_grad_norm_(unet.parameters(), self.max_grad_norm)\n-\noptimizer = getattr(self, f'optim{index}')\nscaler = getattr(self, f'scaler{index}')\n\n+        if exists(self.max_grad_norm):\n+            scaler.unscale_(optimizer)\n+            nn.utils.clip_grad_norm_(unet.parameters(), self.max_grad_norm)\n+\nscaler.step(optimizer)\nscaler.update()\noptimizer.zero_grad()\n", "fix_pattern": "if gradient clipping is performed with nn.utils.clip_grad_norm_, add the line scaler.unscale_(optimizer) before it."}
{"number": 2005, "change": "def get_tiny_config_from_class(configuration_class):\n\ntry:\nmodel_slug = model_type.replace(\"-\", \"_\")\n-        module = importlib.import_module(f\".test_modeling_{model_slug}\", package=f\"tests.{model_slug}\")\n+        module = importlib.import_module(f\".test_modeling_{model_slug}\", package=f\"tests.models.{model_slug}\")\nmodel_tester_class = getattr(module, f\"{camel_case_model_name}ModelTester\", None)\nexcept (ImportError, AttributeError):\nlogger.error(f\"No model tester class for {configuration_class.__name__}\")\n", "fix_pattern": "if package is \"tests\" and module is \"test_modeling_{model_slug}\", change package to \"tests.models\""}
{"number": 2009, "change": "from ray.rllib.utils import try_import_torch\n_, nn = try_import_torch()\n\n\n-class VisionNetwork(TorchModelV2):\n+class VisionNetwork(TorchModelV2, nn.Module):\n\"\"\"Generic vision network.\"\"\"\n\ndef __init__(self, obs_space, action_space, num_outputs, model_config,\nname):\nTorchModelV2.__init__(self, obs_space, action_space, num_outputs,\nmodel_config, name)\n+        nn.Module.__init__(self)\n\nactivation = get_activation_fn(\nmodel_config.get(\"conv_activation\"), framework=\"torch\")\n", "fix_pattern": "If a class inherits from TorchModelV2 but does not inherit from nn.Module, add nn.Module as a parent class and call nn.Module.__init__(self)."}
{"number": 2024, "change": "class BiLSTM_CRF(nn.Module):\ndef _get_lstm_features(self, sentence):\nself.hidden = self.init_hidden()\nembeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n-        lstm_out, self.hidden = self.lstm(embeds)\n+        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\nlstm_out = lstm_out.view(len(sentence), self.hidden_dim)\nlstm_feats = self.hidden2tag(lstm_out)\nreturn lstm_feats\n", "fix_pattern": "if an LSTM module is detected as an argument of the API call, pass the hidden state as an additional argument to the API call."}
{"number": 2033, "change": "def configure_logger(verbose: bool) -> None:\nverbose (bool):\n`True` to use verbose logger, `False` otherwise.\n\"\"\"\n-    tf_logger = tf_logging.get_logger()\n+    tf_logger = tf.get_logger()\ntf_logger.handlers = [handler]\nif verbose:\n-        environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\ntf_logging.set_verbosity(tf_logging.INFO)\nlogger.setLevel(logging.DEBUG)\nelse:\nwarnings.filterwarnings('ignore')\n-        environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\ntf_logging.set_verbosity(tf_logging.ERROR)\n", "fix_pattern": "if deprecated API tf_logging.get_logger() is detected, replace with tf.get_logger()"}
{"number": 2036, "change": "def test(epoch):\noutput = model(batch_data)\ntest_loss += criterion(output, batch_targets)\npred = output.data.max(1)[1]\n-        correct += pred.long().eq(batch_targets.data.long()).sum()\n+        correct += pred.long().eq(batch_targets.data.long()).cpu().sum()\n\ntest_loss = test_loss.data[0]\ntest_loss /= (test_data.size(0) / TEST_BATCH_SIZE) # criterion averages over batch size\n", "fix_pattern": "If CPU operations are followed by .cpu(), remove it"}
{"number": 2049, "change": "class InstanceNormalization(Layer):\n\nreciprocal_stddev = tf.math.rsqrt(x=tf.maximum(x=variance, y=epsilon))\n\n-        x = (x - mean) * reciprocal_stddev\n+        x = (x - tf.stop_gradient(input=mean)) * tf.stop_gradient(input=reciprocal_stddev)\n\nreturn x\n", "fix_pattern": "if stop_gradient is used on a variable, add tf.stop_gradient() around the variable"}
{"number": 2125, "change": "class ClusterLoader(torch.utils.data.DataLoader):\nnode_idx = torch.cat([torch.arange(s, e) for s, e in zip(start, end)])\n\ndata = copy.copy(self.cluster_data.data)\n-        del data.num_nodes\n+        if hasattr(data, '__num_nodes__'):\n+            del data.__num_nodes__\nadj, data.adj = self.cluster_data.data.adj, None\nadj = cat([adj.narrow(0, s, e - s) for s, e in zip(start, end)], dim=0)\nadj = adj.index_select(1, node_idx)\n", "fix_pattern": "if deleting a attribute with variable name, change it to hasattr(attribute_name) and delete the attribute with updated name"}
{"number": 2133, "change": "class Decoder(torch.nn.Module):\nelse:\nlocal_scores = functional.log_softmax(self.output(z_list[-1]), dim=1).data\nif lpz is not None:\n-                    local_att_best_scores, local_att_best_ids = torch.topk(local_scores, int(beam*1.5), dim=1)\n+                    local_att_best_scores, local_att_best_ids = torch.topk(local_scores, int(beam * CTC_SCORING_RATIO), dim=1)\nctc_scores, ctc_states = ctc_prefix_score(hyp['yseq'], local_att_best_ids[0], hyp['ctc_prev'])\n-                    joint_scores = (1. - ctc_weight) * (local_att_best_scores[0].numpy() + hyp['score']) + ctc_weight * ctc_scores\n-                    joint_best_ids = np.argsort(joint_scores)[:-beam-1:-1]\n+                    joint_scores = (1. - ctc_weight) * \\\n+                        (local_att_best_scores[0].numpy() + hyp['score']) + ctc_weight * ctc_scores\n+                    joint_best_ids = np.argsort(joint_scores)[:-beam - 1:-1]\nlocal_best_ids = local_att_best_ids.numpy()[:, joint_best_ids]\nlocal_best_scores = local_att_best_scores.numpy()[:, joint_best_ids]\nelse:\n", "fix_pattern": "If the scalar value `int(beam*1.5)` is detected, replace it with `int(beam * CTC_SCORING_RATIO)`."}
{"number": 2134, "change": "class Random(Exploration):\nif explore:\n# Unsqueeze will be unnecessary, once we support batch/time-aware\n# Spaces.\n-            action = torch.IntTensor(self.action_space.sample()).unsqueeze(0)\n+            action = torch.LongTensor(self.action_space.sample()).unsqueeze(0)\nelse:\n-            action = torch.IntTensor(action_dist.deterministic_sample())\n+            action = torch.LongTensor(action_dist.deterministic_sample())\nlogp = torch.zeros((action.size()[0], ), dtype=torch.float32)\nreturn action, logp\n", "fix_pattern": "if the data type of the tensor is IntTensor, replace it with LongTensor."}
{"number": 2142, "change": "class Trainer:\nfor name, param in self._model.named_parameters():\nparam_updates[name].sub_(param.detach().cpu())\nupdate_norm = torch.norm(param_updates[name].view(-1, ))\n-                    param_norm = torch.norm(param.view(-1, ))\n+                    param_norm = torch.norm(param.view(-1, )).cpu()\nself._tensorboard.add_train_scalar(\"gradient_update/\" + name,\nupdate_norm / (param_norm + 1e-7),\nbatch_num_total)\n", "fix_pattern": "if a tensor operation is followed by .cpu(), add .cpu() to the end of the API call"}
{"number": 2163, "change": "def main():\n\nmodel = BertForSequenceClassification(bert_config, len(label_list))\nif args.init_checkpoint is not None:\n-        model.load_state_dict(torch.load(args.init_checkpoint, map_location='cpu'))\n+        model.bert.load_state_dict(torch.load(args.init_checkpoint, map_location='cpu'))\nmodel.to(device)\n\nif args.local_rank != -1:\n", "fix_pattern": "if a model's state_dict is loaded, the specific model's name should be specified in the code"}
{"number": 2166, "change": "class AdditiveSharingTensor(AbstractTensor):\nmask_pos = x > self.max_value\nmask_neg = x < self.min_value\nif mask_pos.any():\n-                mask_pos = mask_pos.long()\n+                mask_pos = mask_pos.type(self.torch_dtype)\nreturn self.modulo(x - (mask_pos * self.field))\nelif mask_neg.any():\n-                mask_neg = mask_neg.long()\n+                mask_neg = mask_neg.type(self.torch_dtype)\nreturn self.modulo(x + (mask_neg * self.field))\nelse:\nreturn x.type(self.torch_dtype)\n", "fix_pattern": "if the data type of a tensor is being changed, use the type() function with the desired data type to convert the tensor type"}
{"number": 2179, "change": "def test_lite_module_forward_conversion(precision, input_type, expected_type):\nassert precision != 16 or torch.is_autocast_enabled()\nreturn forward_input\n\n-    module = Mock(wraps=torch.nn.Linear(1, 1), side_effect=check_autocast)\n+    module = Mock(wraps=torch.nn.Identity(), side_effect=check_autocast)\nlite_module = _LiteModule(module, lite._precision_plugin).to(device)\n-    out = lite_module(torch.rand(1, dtype=input_type, device=device))\n+    out = lite_module(torch.tensor([1, 2, 3], dtype=input_type, device=device))\nassert module.call_args[0][0].dtype == expected_type\n-    assert out.dtype == torch.get_default_dtype()\n+    assert out.dtype == input_type or out.dtype == torch.get_default_dtype()\n\n\ndef test_lite_dataloader_iterator():\n", "fix_pattern": "if a linear module with dtype input_type is detected, replace it with torch.nn.Identity()"}
{"number": 2233, "change": "class TileLayer(Layer):\n\n@deprecated_alias(layer='prev_layer', end_support_version=1.9)  # TODO remove this line for the 1.9 release\ndef __init__(self, prev_layer, multiples=None, name='tile'):\n+\nsuper(TileLayer, self).__init__(prev_layer=prev_layer, name=name)\n\nlogging.info(\"TileLayer  %s: multiples:%s\" % (name, multiples))\n\n-        self.inputs = prev_layer.outputs\n-\nwith tf.variable_scope(name):\nself.outputs = tf.tile(self.inputs, multiples=multiples)\n\n-        self.all_layers.append(self.outputs)\n+        self._add_layers(self.outputs)\n", "fix_pattern": "if a method named \"add_layers\" is detected, replace it with \"_add_layers\" to indicate it is a private method"}
{"number": 2234, "change": "class Trainer(\nif 'scheduler' not in scheduler:\nraise ValueError(f'Lr scheduler should have key `scheduler`',\n' with item being a lr scheduler')\n-                scheduler['reduce_on_plateau'] = \\\n-                    isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau)\n+                scheduler['reduce_on_plateau'] = isinstance(\n+                    scheduler['scheduler'], optim.lr_scheduler.ReduceLROnPlateau)\n\nlr_schedulers.append({**default_config, **scheduler})\n", "fix_pattern": "if an API call is made directly on a variable instead of its attribute, use the attribute instead."}
{"number": 2264, "change": "class GenerationMixin:\n\n# First if `inputs_embeds` are given, but no `attention_mask` assume that full attention_mask is used\nif inputs_embeds is not None:\n-            return torch.ones((inputs_embeds.shape[0], inputs_embeds.shape[1]), dtype=torch.long)\n+            return torch.ones((inputs_embeds.shape[0], inputs_embeds.shape[1]), dtype=torch.long, device=self.device)\n\n# Otherwise, use `input_ids`\nis_pad_token_in_inputs_ids = (pad_token_id is not None) and (pad_token_id in input_ids)\n", "fix_pattern": "if a tensor is created without a specified device, add \".to(device)\" to the end of the tensor creation line"}
{"number": 2277, "change": "class MishActivation(nn.Module):\n\ndef __init__(self):\nsuper().__init__()\n-        if version.parse(torch.__version__) < version.parse(\"1.9\"):\n+        if version.parse(version.parse(torch.__version__).base_version) < version.parse(\"1.9\"):\nself.act = self._mish_python\nelse:\nself.act = nn.functional.mish\n", "fix_pattern": "if version.parse(torch.__version__) < version.parse(\"X.X\"): - Change it to if version.parse(version.parse(torch.__version__).base_version) < version.parse(\"X.X\"):"}
{"number": 2278, "change": "def Aggregate(dim, dim_out):\nreturn nn.Sequential(\nnn.Conv2d(dim, dim_out, 3, padding = 1),\nChanNorm(dim_out),\n-        nn.MaxPool2d(2)\n+        nn.MaxPool2d(3, stride = 2, padding = 1)\n)\n\nclass Transformer(nn.Module):\n", "fix_pattern": "Replace the existing API call nn.MaxPool2d() with nn.MaxPool2d(kernel_size=3, stride=2, padding=1) to specify the kernel size, stride, and padding for the max pooling operation."}
{"number": 2286, "change": "def predict():\nif __name__ == \"__main__\":\nparser = argparse.ArgumentParser(description=\"Flask API exposing YOLOv5 model\")\nparser.add_argument(\"--port\", default=5000, type=int, help=\"port number\")\n-    args = parser.parse_args()\n+    opt = parser.parse_args()\n+\n+    # Fix known issue urllib.error.HTTPError 403: rate limit exceeded https://github.com/ultralytics/yolov5/pull/7210\n+    torch.hub._validate_not_a_forked_repo = lambda a, b, c: True\n\nmodel = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\", force_reload=True)  # force_reload to recache\n-    app.run(host=\"0.0.0.0\", port=args.port)  # debug=True causes Restarting with stat\n+    app.run(host=\"0.0.0.0\", port=opt.port)  # debug=True causes Restarting with stat\n", "fix_pattern": "if parser.parse_args() is assigned to a variable named 'args', replace 'args' with 'opt' in the app.run() method."}
{"number": 2289, "change": "def synthesis(model,\nstyle_mel = compute_style_mel(style_wav, ap, use_cuda)\n# preprocess the given text\ninputs = text_to_seqvec(text, CONFIG, use_cuda)\n-    speaker_id = speaker_id_var = torch.from_numpy(speaker_id).unsqueeze(0)\n+    speaker_id = np.asarray(speaker_id)\n+    speaker_id = torch.from_numpy(speaker_id).unsqueeze(0)\nif use_cuda:\nspeaker_id.cuda()\n# synthesize voice\ndecoder_output, postnet_output, alignments, stop_tokens = run_model(\n-        model, inputs, CONFIG, truncated, style_mel)\n+        model, inputs, speaker_id, CONFIG, truncated, style_mel)\n# convert outputs to numpy\npostnet_output, decoder_output, alignment = parse_outputs(\npostnet_output, decoder_output, alignments)\n", "fix_pattern": "if speaker_id tensor is detected without a conversion from numpy to torch, add the conversion step before using it in the code"}
{"number": 2305, "change": "class AttentionTest(tf.test.TestCase, parameterized.TestCase):\nattention_layer.concat_score_weight = 1\nattention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))\nattention_layer.scale = 2.\n-    actual = attention_layer._calculate_scores(query=q, key=k)\n+    actual = keras.backend.get_value(\n+            attention_layer._calculate_scores(query=q, key=k))\n\n# Expected tensor of shape [1, 1, 1].\n# expected000 = tanh(2*(1.1+1.6)) = 0.9999592018254402\n", "fix_pattern": "if using a custom backend function to get the value of a tensor, replace it with keras.backend.get_value() function"}
{"number": 2309, "change": "class TensorFlowEstimator(BaseEstimator):\nif not os.path.exists(saver_filename):\nraise ValueError(\"Restore folder doesn't contain saver defintion.\")\nwith open(saver_filename) as fsaver:\n-                saver_def = tf.python.training.saver_pb2.SaverDef()\n+                saver_def = tf.python.training.saver.saver_pb2.SaverDef()\ntext_format.Merge(fsaver.read(), saver_def)\nself._saver = tf.train.Saver(saver_def=saver_def)\n", "fix_pattern": "if a module is imported under a different name, update the import statement to reflect the new name."}
{"number": 2312, "change": "class TFPolicy(Policy):\n\n# TODO(rliaw): Can consider exposing these parameters\nself.sess = tf.Session(graph=self.g, config=tf.ConfigProto(\n-            intra_op_parallelism_threads=1, inter_op_parallelism_threads=2))\n+            intra_op_parallelism_threads=1, inter_op_parallelism_threads=2,\n+            gpu_options=tf.GPUOptions(allow_growth=True)))\nself.variables = ray.experimental.TensorFlowVariables(self.loss,\nself.sess)\nself.sess.run(tf.global_variables_initializer())\n", "fix_pattern": "if the TensorFlow GPUOptions parameter is detected without allow_growth=True, add allow_growth=True to the GPUOptions parameter."}
{"number": 2341, "change": "def subtract(x1: torch.Tensor,\npromoted_type = torch.promote_types(x1.dtype, x2.dtype)\nx1 = x1.to(promoted_type)\nx2 = x2.to(promoted_type)\n-    return torch.subtract(x1, x2, out=out)\n+        return torch.subtract(x1, x2, out=out)\n+    return torch.subtract(x1, x2)\n\n\ndef remainder(x1: torch.Tensor,\n", "fix_pattern": "if an API method is called with an 'out' parameter, ensure that the method is called with 'out' parameter in both cases."}
{"number": 2345, "change": "class GPTNeoForSequenceClassification(GPTNeoPreTrainedModel):\nf\"unexpected if using padding tokens in conjunction with `inputs_embeds.`\"\n)\n\n-        pooled_logits = logits[torch.arange(batch_size), sequence_lengths]\n+        pooled_logits = logits[torch.arange(batch_size, device=self.device), sequence_lengths]\n\nloss = None\nif labels is not None:\n", "fix_pattern": "if an index tensor is detected without specifying the device, add \", device=self.device\" to the end of the tensor declaration"}
{"number": 2376, "change": "def attempt_load(weights, map_location=None, inplace=True):\n# Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a\nmodel = Ensemble()\nfor w in weights if isinstance(weights, list) else [weights]:\n-        attempt_download(w)\n-        ckpt = torch.load(w, map_location=map_location)  # load\n+        ckpt = torch.load(attempt_download(w), map_location=map_location)  # load\nmodel.append(ckpt['ema' if ckpt.get('ema') else 'model'].float().fuse().eval())  # FP32 model\n\n# Compatibility updates\n", "fix_pattern": "if a function call is used as an argument in a method, move the function call outside the method call and replace the argument with the function call"}
{"number": 2386, "change": "class Wavegrad(nn.Module):\nself.noise_level = self.noise_level.to(y_0)\nif len(y_0.shape) == 3:\ny_0 = y_0.squeeze(1)\n-        s = torch.randint(1, self.num_steps + 1, [y_0.shape[0]])\n-        l_a, l_b = self.noise_level[s-1], self.noise_level[s]\n+        s = torch.randint(0, self.num_steps - 1, [y_0.shape[0]])\n+        l_a, l_b = self.noise_level[s], self.noise_level[s+1]\nnoise_scale = l_a + torch.rand(y_0.shape[0]).to(y_0) * (l_b - l_a)\nnoise_scale = noise_scale.unsqueeze(1)\nnoise = torch.randn_like(y_0)\n", "fix_pattern": "If the range of values in the torch.randint function is changed from (1, self.num_steps + 1) to (0, self.num_steps - 1), adjust the indexing in the noise_level list from [s-1] to [s] and [s] to [s+1]."}
{"number": 2410, "change": "from copy import deepcopy\n\nimport numpy as np\nimport torch\n-from torch.cuda import amp\n\nfrom utils.general import LOGGER, colorstr\nfrom utils.torch_utils import profile\n\n\n-def check_train_batch_size(model, imgsz=640):\n+def check_train_batch_size(model, imgsz=640, amp=True):\n# Check YOLOv5 training batch size\n-    with amp.autocast():\n+    with torch.cuda.amp.autocast(amp):\nreturn autobatch(deepcopy(model).train(), imgsz)  # compute optimal batch size\n", "fix_pattern": "if import statement is removed for torch.cuda and amp is used, replace \"from torch.cuda import amp\" with \"import torch.cuda.amp\" and change \"amp.autocast()\" to \"torch.cuda.amp.autocast(amp)\""}
{"number": 2411, "change": "def test_tacotron2_trainable(n_speakers, n_chars, max_input_length, max_mel_leng\npost_mel_preds, \\\nstop_preds, \\\nalignment_history = model(input_ids,\n-                                          tf.constant([max_mel_length, max_mel_length]),\n+                                          tf.constant([max_input_length, max_input_length]),\nspeaker_ids,\nmel_outputs,\n-                                          mel_lengths)\n+                                          mel_lengths,\n+                                          training=True)\nloss_before = tf.keras.losses.MeanSquaredError()(mel_outputs, mel_preds)\nloss_after = tf.keras.losses.MeanSquaredError()(mel_outputs, post_mel_preds)\n", "fix_pattern": "If a constant tensor is detected, and there is a change in the arguments of the API call, update the arguments accordingly."}
{"number": 2412, "change": "def apply_grad_clipping(policy, optimizer, loss):\n\n\ndef atanh(x):\n-    return 0.5 * torch.log((1 + x) / (1 - x))\n+    return 0.5 * torch.log(\n+        (1 + x).clamp(min=SMALL_NUMBER) / (1 - x).clamp(min=SMALL_NUMBER))\n\n\ndef convert_to_non_torch_type(stats):\n", "fix_pattern": "if a mathematical operation like division is present and there is a possibility of division by zero, use the clamp(min=SMALL_NUMBER) function to prevent the division by zero error."}
{"number": 2415, "change": "class Trainer(object):\n# convert logging_outputs to CPU to avoid unnecessary\n# device-to-host transfers in reduce_metrics\nlogging_outputs = utils.apply_to_sample(\n-                lambda t: t.to(device='cpu', non_blocking=True),\n+                lambda t: t.to(device='cpu', non_blocking=True, dtype=torch.double),\nlogging_outputs\n)\n", "fix_pattern": "if a tensor is being modified with .to(device='cpu'), and additional arguments are being added, include them in the .to() call as well."}
{"number": 2428, "change": "def RegNet(\nin_channels = out_channels\n\nif include_top:\n-        x = Head(num_classes=classes)(x)\nimagenet_utils.validate_activation(classifier_activation, weights)\n+        x = Head(\n+            num_classes=classes,\n+            classifier_activation=classifier_activation,\n+            name=model_name,\n+        )(x)\n\nelse:\nif pooling == \"avg\":\n", "fix_pattern": "if the API call has additional arguments/parameters, add them inside the parentheses of the API call."}
{"number": 2461, "change": "class ModelPruning(Callback):\ndef _wrap_pruning_fn(pruning_fn: Callable, **kwargs: Any) -> Callable:\nreturn partial(pruning_fn, **kwargs)\n\n-    def make_pruning_permanent(self, pl_module: LightningModule) -> None:\n+    def make_pruning_permanent(self, module: nn.Module) -> None:\n\"\"\"\nRemoves pruning buffers from any pruned modules\n\nAdapted from https://github.com/pytorch/pytorch/blob/1.7.1/torch/nn/utils/prune.py#L1176-L1180\n\"\"\"\n-        for _, module in pl_module.named_modules():\n+        for _, module in module.named_modules():\nfor k in list(module._forward_pre_hooks):\nhook = module._forward_pre_hooks[k]\nif isinstance(hook, pytorch_prune.BasePruningMethod):\n", "fix_pattern": "if the pl_module parameter is detected in the method signature, rename it to module."}
{"number": 2466, "change": "class Standardize(Preprocessor):\nelse:\naxes = tuple(range(1, util.rank(tensor)))\n\n-        mean, variance = tf.nn.moments(x=tensor, axes=axes)\n-        return (tensor - mean) / tf.maximum(x=variance, y=util.epsilon)\n+        mean, variance = tf.nn.moments(x=tensor, axes=axes, keep_dims=True)\n+        return (tensor - mean) / tf.maximum(x=tf.sqrt(variance), y=util.epsilon)\n", "fix_pattern": "If tf.nn.moments() is detected with the parameter \"axes\" and the parameter \"keep_dims\" is not present or set to False, add \"keep_dims=True\" to the function call. Additionally, replace \"tf.maximum(x=variance, y=util.epsilon)\" with \"tf.sqrt(variance)\" in the return statement."}
{"number": 2511, "change": "def get_perspective_transform(src, dst):\n], dim=1)\n\n# solve the system Ax = b\n-    X, LU = torch.solve(b, A)\n+    X, LU = _torch_solve_cast(b, A)\n\n# create variable to return\nbatch_size = src.shape[0]\n", "fix_pattern": "if torch.solve() API is detected, replace with _torch_solve_cast() API."}
{"number": 2523, "change": "class Estimator(CircularBuffer):\nx=tf.zeros_like(tensor=discounts, dtype=util.tf_dtype(dtype='float')),\ny=discounts\n)\n-            reward = reward + discounts * horizon_estimate\n+            reward = reward + discounts * tf.stop_gradient(input=horizon_estimate)\n# TODO: stop gradients?\n\nreturn reward\n", "fix_pattern": "If the function tf.stop_gradient() is detected, add the input argument 'input=' before the variable name."}
{"number": 2542, "change": "th = TorchHijackForUnet()\n\n# Below are monkey patches to enable upcasting a float16 UNet for float32 sampling\ndef apply_model(orig_func, self, x_noisy, t, cond, **kwargs):\n-    for y in cond.keys():\n-        cond[y] = [x.to(devices.dtype_unet) if isinstance(x, torch.Tensor) else x for x in cond[y]]\n+\n+    if isinstance(cond, dict):\n+        for y in cond.keys():\n+            cond[y] = [x.to(devices.dtype_unet) if isinstance(x, torch.Tensor) else x for x in cond[y]]\n+\nwith devices.autocast():\nreturn orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs).float()\n", "fix_pattern": "if a loop is used to iterate through the keys of a dictionary and modify its values, check if the variable being modified is an instance of a certain data type (e.g. torch.Tensor) and apply a specific operation or conversion (e.g. x.to(device)) if it meets the condition."}
{"number": 2562, "change": "class RENet(torch.nn.Module):\n_, perm = logits.sort(dim=1, descending=True)\nmask = (y.view(-1, 1) == perm)\n\n-        mrr = (1 / (mask.nonzero()[:, -1] + 1).to(torch.float)).mean().item()\n+        nnz = mask.nonzero(as_tuple=False)\n+        mrr = (1 / (nnz[:, -1] + 1).to(torch.float)).mean().item()\nhits1 = mask[:, :1].sum().item() / y.size(0)\nhits3 = mask[:, :3].sum().item() / y.size(0)\nhits10 = mask[:, :10].sum().item() / y.size(0)\n", "fix_pattern": "if .to(torch.float) is used after indexing the tensor, remove it and add it to the end of the API call before indexing the tensor"}
{"number": 2563, "change": "class GaussianChainTests(TestCase):\n(self.N, reparameterized, n_repa_nodes, self.N))\nif self.N < 0:\ndef array_to_string(y):\n-                    return str(map(lambda x: \"%.3f\" % x.data.numpy()[0], y))\n+                    return str(map(lambda x: \"%.3f\" % x.data.cpu().numpy()[0], y))\n\nprint(\"lambdas: \" + array_to_string(self.lambdas))\nprint(\"target_mus: \" + array_to_string(self.target_mus[1:]))\n", "fix_pattern": "if converting a tensor to numpy, replace \".data.numpy()\" with \".data.cpu().numpy()\""}
{"number": 2565, "change": "class PANConv(MessagePassing):\n\ntmp = SparseTensor.eye(adj_t.size(0), adj_t.size(1), has_value=True,\ndtype=dtype, device=adj_t.device())\n-        tmp = tmp.mul_nnz(self.weight[0])\n+        tmp = tmp.mul_nnz(self.weight[0], layout='coo')\n\nouts = [tmp]\nfor i in range(1, self.filter_size + 1):\ntmp = tmp @ adj_t\n-            tmp = tmp.mul_nnz(self.weight[i])\n+            tmp = tmp.mul_nnz(self.weight[i], layout='coo')\nouts += [tmp]\n\nrow = torch.cat([out.storage.row() for out in outs], dim=0)\n", "fix_pattern": "If mul_nnz() method is called with additional arguments, such as layout='coo', add those arguments to the method call."}
{"number": 2581, "change": "class PyramidVisionTransformerV2(nn.Module):\ncur += depths[i]\n\n# classification head\n-        self.head = nn.Linear(embed_dims[3], num_classes) if num_classes > 0 else nn.Identity()\n+        self.num_features = embed_dims[-1]\n+        self.head = nn.Linear(embed_dims[-1], num_classes) if num_classes > 0 else nn.Identity()\n\nself.apply(self._init_weights)\n", "fix_pattern": "if nn.Linear() is called with embed_dims[3], replace it with embed_dims[-1]"}
{"number": 2592, "change": "class SequenceGenerator(nn.Module):\ncum_unfin.append(prev)\ncum_fin_tensor = torch.tensor(cum_unfin, dtype=torch.int).to(bbsz_idx)\n\n-        unfin_idx = bbsz_idx // beam_size\n+        unfin_idx = torch.div(bbsz_idx, beam_size, rounding_mode='trunc')\nsent = unfin_idx + torch.index_select(cum_fin_tensor, 0, unfin_idx)\n\n# Create a set of \"{sent}{unfin_idx}\", where\n", "fix_pattern": "If integer division is detected, replace the '//'' operator with 'torch.div' and add the 'rounding_mode' argument if necessary."}
{"number": 2606, "change": "def test_conditional_whiten(Xnew, X, kernel, f_loc, f_scale_tril, loc, cov):\nloc0, cov0 = conditional(Xnew, X, kernel, f_loc, f_scale_tril, full_cov=True,\nwhiten=False)\nKff = kernel(X) + torch.eye(3) * 1e-6\n-    Lff = Kff.cholesky()\n+    Lff = torch.linalg.cholesky(Kff)\nwhiten_f_loc = Lff.inverse().matmul(f_loc)\nwhiten_f_scale_tril = Lff.inverse().matmul(f_scale_tril)\nloc1, cov1 = conditional(Xnew, X, kernel, whiten_f_loc, whiten_f_scale_tril,\n", "fix_pattern": "if a Cholesky decomposition is performed using the method Kff.cholesky(), replace it with torch.linalg.cholesky(Kff)"}
{"number": 2627, "change": "def accuracy(pr, gt, threshold=0.5, ignore_channels=None):\npr = _threshold(pr, threshold=threshold)\npr, gt = _take_channels(pr, gt, ignore_channels=ignore_channels)\n\n-    tp = torch.sum(gt == pr)\n+    tp = torch.sum(gt == pr, dtype=pr.dtype)\nscore = tp / gt.view(-1).shape[0]\nreturn score\n", "fix_pattern": "if there is a dtype mismatch between the input tensors in a comparison operation, add dtype=pr.dtype to the end of the API call for torch.sum() method"}
{"number": 2636, "change": "def shape(\nas_array: bool = False,\n) -> Union[tf.Tensor, ivy.Shape, ivy.Array]:\nif as_array:\n-        return ivy.array(tf.shape(x))\n+        return ivy.array(tf.shape(x), dtype=ivy.default_int_dtype())\nelse:\nreturn ivy.Shape(x.shape)\n", "fix_pattern": "If an array shape is detected without specifying the data type, add \"dtype=ivy.default_int_dtype()\" to the end of the API call."}
{"number": 2654, "change": "class Entropy(Metric):\ndef __call__(\nself,  # type: ignore\nlogits: torch.Tensor,\n-        mask: Optional[torch.Tensor] = None,\n+        mask: Optional[torch.BoolTensor] = None,\n):\n\"\"\"\n# Parameters\n\nlogits : `torch.Tensor`, required.\nA tensor of unnormalized log probabilities of shape (batch_size, ..., num_classes).\n-        mask : `torch.Tensor`, optional (default = None).\n+        mask : `torch.BoolTensor`, optional (default = None).\nA masking tensor of shape (batch_size, ...).\n\"\"\"\nlogits, mask = self.detach_tensors(logits, mask)\n\nif mask is None:\n-            mask = torch.ones(logits.size()[:-1], device=logits.device)\n+            mask = torch.ones(logits.size()[:-1], device=logits.device).bool()\n\nlog_probs = torch.nn.functional.log_softmax(logits, dim=-1)\nprobabilities = torch.exp(log_probs) * mask.unsqueeze(-1)\n", "fix_pattern": "if a mask tensor is detected with type `torch.Tensor`, replace it with `torch.BoolTensor` and add a `.bool()` at the end of the API call."}
{"number": 2662, "change": "def get_transducer_task_io(\nencoder_out_lens = list(map(int, encoder_out_lens))\n\nt_len = torch.IntTensor(encoder_out_lens).to(device)\n-    u_len = torch.IntTensor([y.size(0) for y in ys]).to(device)\n+    u_len = torch.IntTensor([y.size(0) for y in labels_unpad]).to(device)\n\n-    return target, t_len, u_len\n+    return decoder_in, target, t_len, u_len\n", "fix_pattern": "if a tensor is being moved to a specific device using .to(), and the device is not specified, add .to(device) at the end of the API call"}
{"number": 2663, "change": "def lower_modules_to_accelerator(\nbackend = \"NNPI\"\nbackend_qualifier = \"\"\n\n-        if throughput_optimize:\n+        if throughput_optimize and gelu_clip:\n+            backend_qualifier = \":throughput_optimized_gelu_clip\"\n+        elif throughput_optimize:\nbackend_qualifier = \":throughput_optimized\"\n\nmodules_to_lower = accelerator.get_modules(model, backend + backend_qualifier)\n", "fix_pattern": "if a condition is detected and the code block within the condition has been modified, add an additional condition to the existing if statement"}
{"number": 2685, "change": "class GPTJForSequenceClassification(GPTJPreTrainedModel):\nf\"unexpected if using padding tokens in conjunction with `inputs_embeds.`\"\n)\n\n-        pooled_logits = logits[range(batch_size), sequence_lengths]\n+        pooled_logits = logits[torch.arange(batch_size, device=self.device), sequence_lengths]\n\nloss = None\nif labels is not None:\n", "fix_pattern": "If indexing a tensor with range(batch_size), replace it with torch.arange(batch_size, device=device)."}
{"number": 2727, "change": "class DomainClient(Client):\n\nreturn response\n\n-    def apply_to_network(self, target: str, reason: str):\n+    def apply_to_network(self,\n+            target: str,\n+            reason: str,\n+            route_index: int = 0):\nself.association.create(\ntarget=target,\n-            sender=self.conn.base_url.replace(\"/api/v1\", \"\"),\n+            sender=self.routes[route_index].connection.base_url.replace(\"/api/v1\", \"\"),\nreason=reason,\nnode_name=self.name,\n)\n", "fix_pattern": "if an API method is modified to include an additional parameter, make sure to update the method signature and include the new parameter with its default value"}
{"number": 2783, "change": "class CNNLayerVisualization():\nself.conv_output = x[0, self.selected_filter]\n# Loss function is the mean of the output of the selected layer/filter\n# We try to minimize the mean of the output of that specific filter\n-            loss = torch.mean(self.conv_output)\n-            print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()[0]))\n+            loss = -torch.mean(self.conv_output)\n+            print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n# Backward\nloss.backward()\n# Update image\n", "fix_pattern": "Add a negative sign to the loss calculation and remove the indexing [0] when accessing the `loss.data.numpy()` array."}
{"number": 2784, "change": "class BitEncoder(nn.Module):\ndilation = 1\n\nlayer_dropouts = [\n-            x.tolist() for x in torch.linspace(0, config.drop_path_rate, sum(config.depths)).split(config.depths)\n+            x.tolist()\n+            for x in torch.Tensor(np.linspace(0, config.drop_path_rate, sum(config.depths))).split(config.depths)\n]\n\nfor stage_idx, (current_depth, current_hidden_size, layer_dropout) in enumerate(\n", "fix_pattern": "if a tensor is converted to a list using .tolist() and the tensor is created using torch.linspace(), replace torch.linspace() with np.linspace() and wrap it in torch.Tensor()"}
{"number": 2786, "change": "def absolute_path(path):\nThis implementation avoids calling os.path.abspath(path) if 'path' already\nrepresents an absolute Tensorflow filesystem location (e.g. <fs type>://).\n\"\"\"\n-  return path if \"://\" in str(path) else os.path.abspath(path)\n+  return path if b\"://\" in tf.compat.as_bytes(path) else os.path.abspath(path)\n\n\ndef fc2_implements_resources():\n", "fix_pattern": "if a string path is checked for \"://\" using str(path), replace str(path) with tf.compat.as_bytes(path)"}
{"number": 2791, "change": "def main():\nif requires_preprocessing:\nprepare_input = PREPROCESSING_FUNCTIONS.get(args.model_type)\nprompt_text, model_kwargs = prepare_input(args, model, tokenizer, prompt_text)\n-    encoded_prompt = torch.tensor(tokenizer.encode(prompt_text, add_special_tokens=False)).unsqueeze(0)\n+    encoded_prompt = tokenizer.encode(prompt_text, add_special_tokens=False, return_tensors='pt')\n\noutput_sequences = model.generate(\n-        intput_ids=encoded_prompt,\n-        length=args.length,\n+        input_ids=encoded_prompt,\n+        max_length=args.length,\ntemperature=args.temperature,\ntop_k=args.k,\ntop_p=args.p,\n", "fix_pattern": "if tensor conversion is done manually using torch.tensor, replace it with tokenizer.encode with return_tensors='pt'"}
{"number": 2798, "change": "class PlanTranslatorTorchscript(AbstractPlanTranslator):\ntranslation_plan = self.plan.copy()\ntranslation_plan.forward = None\n\n-        args_shape = translation_plan.get_args_shape()\n-        args = PlaceHolder.create_placeholders(args_shape)\n+        args = translation_plan.create_dummy_args()\n\n-        # To avoid storing Plan state tensors in torchscript, they will be send as parameters\n+        # jit.trace clones input args and can change their type, so we have to skip types check\n+        # TODO see if type check can be made less strict,\n+        #  e.g. tensor/custom tensor/nn.Parameter could be considered same type\n+        translation_plan.validate_input_types = False\n+\n+        # To avoid storing Plan state tensors in torchscript, they will be sent as parameters\n# we trace wrapper func, which accepts state parameters as last arg\n# and sets them into the Plan before executing the Plan\ndef wrap_stateful_plan(*args):\n", "fix_pattern": "If a method call to `translation_plan.get_args_shape()` is detected, replace it with `translation_plan.create_dummy_args()`. Also, set `translation_plan.validate_input_types = False` to skip type checking."}
{"number": 2803, "change": "class TFEmbedding(tf.keras.layers.Embedding):\nsuper().__init__(*args, **kwargs)\n\ndef call(self, inputs):\n-        inputs = tf.cast(tf.expand_dims(inputs, -1), tf.int32)\n-        outputs = tf.gather_nd(self.embeddings, inputs)\n+        inputs = tf.cast(inputs, tf.int32)\n+        outputs = tf.gather(self.embeddings, inputs)\nreturn outputs\n", "fix_pattern": "if tf.expand_dims() is detected, remove it and cast the inputs directly, and change tf.gather_nd() to tf.gather()"}
{"number": 2819, "change": "class Model(object):\nself.deterministic_mode = config.get('deterministic_mode', False)\nself.episode_length = tf.placeholder(tf.int32, (None,), name='episode_length')\n\n-        self.alpha = config.get('alpha', 0.001)\n+        self.learning_rate = config.get('learning_rate', 0.001)\n\noptimizer = config.get('optimizer')\nif not optimizer:\n-            self.optimizer = tf.train.AdamOptimizer(self.alpha)\n+            self.optimizer = tf.train.AdamOptimizer(self.learning_rate)\nelse:\nargs = config.get('optimizer_args', [])\nkwargs = config.get('optimizer_kwargs', {})\noptimizer_cls = get_function(optimizer)\n-            self.optimizer = optimizer_cls(self.alpha, *args, **kwargs)\n+            self.optimizer = optimizer_cls(self.learning_rate, *args, **kwargs)\n\nexploration = config.get('exploration')\nif not exploration:\n", "fix_pattern": "if learning rate is set using the 'alpha' key, change it to 'learning_rate' key"}
{"number": 2827, "change": "class Metric(Registrable):\nraise NotImplementedError\n\n@staticmethod\n-    def unwrap_to_tensors(*tensors: torch.Tensor):\n+    def detach_tensors(*tensors: torch.Tensor) -> Iterable[torch.Tensor]:\n\"\"\"\nIf you actually passed gradient-tracking Tensors to a Metric, there will be\na huge memory leak, because it will prevent garbage collection for the computation\n-        graph. This method ensures that you're using tensors directly and that they are on\n-        the CPU.\n+        graph. This method ensures the tensors are detached.\n\"\"\"\n-        return (x.detach().cpu() if isinstance(x, torch.Tensor) else x for x in tensors)\n+        # Check if it's actually a tensor in case something else was passed.\n+        return (x.detach() if isinstance(x, torch.Tensor) else x for x in tensors)\n", "fix_pattern": "if a function named \"unwrap_to_tensors\" is detected, rename it to \"detach_tensors\" and update the function description to mention that it ensures the tensors are detached."}
{"number": 2841, "change": "class Synthesizer(object):\nsample_rate=self.ap.sample_rate,\n).cuda()\n\n-        check = torch.load(model_file)\n-        self.wavernn.load_state_dict(check['model'], map_location=\"cpu\")\n+        check = torch.load(model_file, map_location=\"cpu\")\n+        self.wavernn.load_state_dict(check['model'])\nif use_cuda:\nself.wavernn.cuda()\nself.wavernn.eval()\n", "fix_pattern": "When using `torch.load()` method, if `map_location` parameter is used, move it inside the method call."}
{"number": 2845, "change": "def floor_divide(\nif (not np.all(x2)) or (np.any(x2) == -0):  # check for division by zero\nret = np.floor_divide(x1, x2)\nelse:\n-        ret = tf.math.floordiv(x1, x2)\n+        ret = tf.experimental.numpy.floor_divide(x1, x2)\n\nif (any(isinf(x1)) and any(isfinite(x2))) or (any(isfinite(x1)) and any(isinf(x2))):\nreturn ivy.full_like(ret, floor(divide(x1, x2)), dtype=ret.dtype)\n", "fix_pattern": "If deprecated API tf.math.floordiv() is detected, replace it with tf.experimental.numpy.floor_divide()."}
{"number": 2859, "change": "class DDIMScheduler(SchedulerMixin, ConfigMixin):\nprev_sample = alpha_prod_t_prev ** (0.5) * pred_original_sample + pred_sample_direction\n\nif eta > 0:\n+            # randn_like does not support generator https://github.com/pytorch/pytorch/issues/27072\ndevice = model_output.device if torch.is_tensor(model_output) else \"cpu\"\n-            noise = torch.randn(model_output.shape, generator=generator).to(device)\n+            noise = torch.randn(model_output.shape, dtype=model_output.dtype, generator=generator).to(device)\nvariance = self._get_variance(timestep, prev_timestep) ** (0.5) * eta * noise\n\nprev_sample = prev_sample + variance\n", "fix_pattern": "if a tensor with random values is created using torch.randn() and the generator keyword argument is used, replace the API call with torch.randn_like() and specify the dtype parameter and generator keyword argument separately"}
{"number": 2883, "change": "class Fixture(object):\n\ndef _convert_logits_to_ps(self, dist_params):\nif 'logits' in dist_params:\n-            logits = torch.Tensor(dist_params.pop('logits'))\n+            logits = Variable(torch.Tensor(dist_params.pop('logits')))\nis_multidimensional = self.get_test_distribution_name() != 'Bernoulli'\nps, _ = get_probs_and_logits(logits=logits, is_multidimensional=is_multidimensional)\ndist_params['ps'] = list(ps.data.cpu().numpy())\n", "fix_pattern": "If a tensor is directly assigned to a variable without any additional operations, wrap the tensor assignment in the Variable() function."}
{"number": 2884, "change": "class GEDDataset(InMemoryDataset):\nxs += [assoc[x]]\nys += [assoc[y]]\ngs += [g]\n-            x, y, g = torch.tensor(xs), torch.tensor(ys), torch.tensor(gs)\n+            x, y = torch.tensor(xs), torch.tensor(ys)\n+            g = torch.tensor(gs, dtype=torch.float)\nmat[x, y], mat[y, x] = g, g\n\npath = osp.join(self.processed_dir, '{}_ged.pt'.format(self.name))\n", "fix_pattern": "if the tensor is created with a specific data type (e.g., dtype=torch.float), add the dtype parameter to the torch.tensor() call."}
{"number": 2888, "change": "def extract_info_from_torch_data(\ninput_types = ifnone(\ninput_types,\n[\n-            \"int\" if isinstance(x.cpu(), torch.LongTensor) else \"float\"\n+            \"int64\"\n+            if isinstance(x.cpu(), torch.LongTensor)\n+            else \"int32\"\n+            if isinstance(x.cpu(), torch.IntTensor)\n+            else \"float32\"\nfor x in input_row\n],\n)\n", "fix_pattern": "if isinstance(x.cpu(), torch.LongTensor) add \"int64\" to the string return value,\nif isinstance(x.cpu(), torch.IntTensor) add \"int32\" to the string return value,\nelse return \"float32\""}
{"number": 2891, "change": "def block(params, scope, past, append_dim, train=False):\ndef model(features, labels, params, mesh, past=None):\n\"\"\"A GPT style model implemented in mesh tensorlfow.\"\"\"\nresults = {}\n+    sequence_dim = mtf.Dimension('sequence', params[\"n_ctx\"])\nif params[\"num_microbatches\"] > 1:\nx = features[\"inputs\"]\nlabels = features[\"labels\"]\nbatch_dim = x.shape[0]\n-\n-\nelse:\n+      batch_dim = mtf.Dimension('batch', params[\"train_batch_size\"])\nx = mtf.import_tf_tensor(mesh, features, mtf.Shape([batch_dim, sequence_dim]))\n# In this case, labels are simply input shifted one token to the right\n# this op is done in the input_fn\n# define mtf dims\n-      batch_dim = mtf.Dimension('batch', params[\"train_batch_size\"])\nlabels = mtf.import_tf_tensor(mesh, labels, mtf.Shape([batch_dim, sequence_dim]))\n\n-    sequence_dim = mtf.Dimension('sequence', params[\"n_ctx\"])\n\n# we need this because gathering when both the args have the same dimension in them it breaks stuff.\n# this dim is specifically for the weights\n", "fix_pattern": "if the order of creating dimensions is changed, the code should be modified to match the new order"}
{"number": 2926, "change": "class CrossAttention(nn.Module):\nkey_slice = key_slice.float()\n\nattn_slice = torch.baddbmm(\n-                torch.empty(slice_size, query.shape[1], key.shape[1], dtype=query.dtype, device=query.device),\n-                query[start_idx:end_idx],\n-                key[start_idx:end_idx].transpose(-1, -2),\n+                torch.empty(slice_size, query.shape[1], key.shape[1], dtype=query_slice.dtype, device=query.device),\n+                query_slice,\n+                key_slice.transpose(-1, -2),\nbeta=0,\nalpha=self.scale,\n)\n", "fix_pattern": "if an empty tensor is detected with dtype and device parameters, replace dtype with the dtype of the sliced tensor (query_slice.dtype) in the first argument of the API call"}
{"number": 2948, "change": "class InMemoryDataset(Dataset):\nfor key in keys:\nitem = data_list[0][key]\nif torch.is_tensor(item):\n-                data[key] = torch.cat(\n-                    data[key], dim=data.__cat_dim__(key, data_list[0][key]))\n+                data[key] = torch.cat(data[key],\n+                                      dim=data.__cat_dim__(key, item))\nelif isinstance(item, int) or isinstance(item, float):\ndata[key] = torch.tensor(data[key])\n", "fix_pattern": "if torch.cat is called on a list of tensors, remove the dim argument and replace it with the __cat_dim__ method of the input data structure."}
{"number": 2956, "change": "class FloatVectorField(Field):\n)\nself.dim_error_check = dim_error_check  # dims in data should match config\nself.dummy_model_input = torch.tensor(\n-            [[1.0] * dim], dtype=torch.float, device=\"cpu\"\n+            [[1.0] * dim, [1.0] * dim], dtype=torch.float, device=\"cpu\"\n)\n\ndef _parse_vector(self, s):\n", "fix_pattern": "if a tensor is detected with the dtype and device specified, add another tensor with the same dtype and device"}
{"number": 2969, "change": "class WGAN_GP(object):\nalpha = tf.random_uniform(shape=self.inputs.get_shape(), minval=0.,maxval=1.)\ndifferences = G - self.inputs # This is different from MAGAN\ninterpolates = self.inputs + (alpha * differences)\n-        D_inter,_,_=self.discriminator(interpolates, is_training=True, reuse=True)\n+        _,D_inter,_=self.discriminator(interpolates, is_training=True, reuse=True)\ngradients = tf.gradients(D_inter, [interpolates])[0]\nslopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\ngradient_penalty = tf.reduce_mean((slopes - 1.) ** 2)\n", "fix_pattern": "if an argument is removed from an API call, remove the corresponding variable assignment"}
{"number": 2971, "change": "class TransferLearningModel(pl.LightningModule):\n# 1. Forward pass:\nx, y = batch\ny_logits = self.forward(x)\n+        y_scores = torch.sigmoid(y_logits)\ny_true = y.view((-1, 1)).type_as(x)\n\n# 2. Compute loss\nself.log(\"val_loss\", self.loss(y_logits, y_true), prog_bar=True)\n\n# 3. Compute accuracy:\n-        self.log(\"val_acc\", self.valid_acc(y_logits, y_true.int()), prog_bar=True)\n+        self.log(\"val_acc\", self.valid_acc(y_scores, y_true.int()), prog_bar=True)\n\ndef configure_optimizers(self):\nparameters = list(self.parameters())\n", "fix_pattern": "If the API call self.valid_acc() is used with logits, replace it with torch.sigmoid(logits) as an intermediate step before calculating the accuracy."}
{"number": 2975, "change": "class Decoder(nn.Module):\nself.attention = inputs.data.new(B, T).zero_()\nself.attention_cum = inputs.data.new(B, T).zero_()\n\n-    def _parse_outputs(self, outputs, stop_tokens, attentions):\n+    def _parse_outputs(self, outputs, attentions, stop_tokens):\n# Back to batch first\nattentions = torch.stack(attentions).transpose(0, 1)\noutputs = torch.stack(outputs).transpose(0, 1).contiguous()\n-        stop_tokens = torch.stack(stop_tokens).transpose(0, 1)\n-        return outputs, stop_tokens, attentions\n+        stop_tokens = torch.stack(stop_tokens).transpose(0, 1).squeeze(-1)\n+        return outputs, attentions, stop_tokens\n\ndef decode(self,\ninputs,\n", "fix_pattern": "if a tensor is transposed, add a squeeze(-1) to the end of the API call"}
{"number": 2978, "change": "class GAE(torch.nn.Module):\ndata.val_pos_edge_index = torch.stack([r, c], dim=0)\nr, c = row[n_v:n_v + n_t], col[n_v:n_v + n_t]\ndata.test_pos_edge_index = torch.stack([r, c], dim=0)\n+\nr, c = row[n_v + n_t:], col[n_v + n_t:]\n-        data.train_pos_edge_index = torch.stack([r, c], dim=0)\n+        edge_index = torch.stack([r, c], dim=0)\n+        data.train_pos_edge_index = to_undirected(edge_index)\n\n# Negative edges.\nnum_nodes = data.num_nodes\n", "fix_pattern": "if a stack operation on tensors is detected, create a variable using the stack operation and then apply the required API function on that variable."}
{"number": 2980, "change": "class LatentDiffusion(DiffusionPipeline):\nnum_trained_timesteps = self.noise_scheduler.timesteps\ninference_step_times = range(0, num_trained_timesteps, num_trained_timesteps // num_inference_steps)\n\n-        image = self.noise_scheduler.sample_noise(\n+        image = torch.randn(\n(batch_size, self.unet.in_channels, self.unet.image_size, self.unet.image_size),\ndevice=torch_device,\ngenerator=generator,\n", "fix_pattern": "if a noise scheduler is detected, replace it with torch.randn("}
{"number": 2995, "change": "class EmpiricalMarginal(Empirical):\nin ``[0, num_chains - 1]``, and there must be equal number\nof samples per chain.\n\"\"\"\n-        weight_type = value.new_empty(1).float().type() if value.dtype in (torch.int32, torch.int64) \\\n-            else value.type()\n# Apply default weight of 1.0.\nif log_weight is None:\n-            log_weight = torch.tensor(0.0).type(weight_type)\n-        if isinstance(log_weight, numbers.Number):\n-            log_weight = torch.tensor(log_weight).type(weight_type)\n-        if self._validate_args and log_weight.dim() > 0:\n+            log_weight = 0.0\n+        if self._validate_args and not isinstance(log_weight, numbers.Number) and log_weight.dim() > 0:\nraise ValueError(\"``weight.dim() > 0``, but weight should be a scalar.\")\n\n# Append to the buffer list\n", "fix_pattern": "if creating a new tensor using torch.tensor(0.0) is detected, replace with assigning a value of 0.0 directly\nif isinstance(log_weight, numbers.Number) is detected, replace with checking if log_weight is not an instance of numbers.Number"}
{"number": 3012, "change": "def _convert_to_tf(x):\nreturn x\n\nif x is not None:\n-        x = tf.nest.map_structure(tf.convert_to_tensor, x)\n+        x = tf.nest.map_structure(\n+            lambda f: tf.convert_to_tensor(f) if f is not None else None, x)\nreturn x\n", "fix_pattern": "if tf.nest.map_structure(tf.convert_to_tensor, x) is detected, replace it with tf.nest.map_structure(lambda f: tf.convert_to_tensor(f) if f is not None else None, x)"}
{"number": 3017, "change": "class CTCPrefixScoreTH(object):\nr_prev, s_prev, f_min_prev, f_max_prev = state\n\n# select input dimensions for scoring\n-        if self.scoring_num > 0 and prep_scores is not None:\n-            scoring_ids = torch.topk(prep_scores, self.scoring_num, 1)[1]\n+        if self.scoring_num > 0 and pre_scores is not None:\n+            pre_scores[:, self.blank] = self.logzero  # ignore blank from pre-selection\n+            scoring_ids = torch.topk(pre_scores, self.scoring_num, 1)[1]\nscoring_idmap = torch.full((self.n_bb, self.odim), -1, dtype=torch.long, device=self.device)\nsnum = scoring_ids.size(1)\nscoring_idmap[self.bb_idx, scoring_ids] = torch.arange(snum, device=self.device)\n", "fix_pattern": "if an API method call has changed and a variable name has been modified, replace the old variable name with the new one.\n\nIn this case, \"prep_scores\" has been changed to \"pre_scores\", so the pattern is to replace the old variable name \"prep_scores\" with the new variable name \"pre_scores\"."}
{"number": 3021, "change": "class MultiHeadedAttention(nn.Module):\n\nscores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)  # (batch, head, time1, time2)\nif mask is not None:\n-            mask.unsqueeze_(1).eq_(0)  # (batch, 1, time1, time2)\n+            mask = mask.unsqueeze(1).eq(0)  # (batch, 1, time1, time2)\nscores = scores.masked_fill(mask, MIN_VALUE)\nself.attn = torch.softmax(scores, dim=-1).masked_fill(mask, 0.0)  # (batch, head, time1, time2)\nelse:\n-            self.attn = torch.softmax(scores, dim=-1)\n+            self.attn = torch.softmax(scores, dim=-1)  # (batch, head, time1, time2)\n\np_attn = self.dropout(self.attn)\nx = torch.matmul(p_attn, v)  # (batch, head, time1, d_k)\n", "fix_pattern": "if inplace operation on a tensor is detected, replace the operation with a non-inplace operation."}
{"number": 3048, "change": "class TopKPooling(torch.nn.Module):\n\nweight = F.normalize(self.weight, p=2, dim=-1)\nscore = (x * weight).sum(dim=-1)\n-        perm = self.topk(score, self.k, batch)\n-\n-        x = x[perm] * self.tanh(score[perm])\n+        perm = self.topk(score, self.ratio, batch)\n+        x = x[perm] * torch.tanh(score[perm]).view(-1, 1)\nbatch = batch[perm]\nedge_index, edge_attr = self.filter_adj(\n-            edge_index, edge_attr, perm, num_nodes=x.size(0))\n+            edge_index, edge_attr, perm, num_nodes=score.size(0))\n\n-        return x, edge_index, edge_attr, batch\n+        return x, edge_index, edge_attr, batch, perm\n\ndef __repr__(self):\nreturn '{}({})'.format(self.__class__.__name__, self.ratio)\n", "fix_pattern": "It is difficult to identify a specific pattern for fixing the API method problem in the provided code change. However, based on the changes made in the code, it seems that the following pattern can be observed:\n\n1. The method `self.topk()` has been replaced with `self.topk(score, self.ratio, batch)`.\n2. The function `torch.tanh()` has been used instead of `self.tanh()`.\n3. The line `edge_index, edge_attr, perm, num_nodes=x.size(0))` has been modified to `edge_index, edge_attr, perm, num_nodes=score.size(0))`.\n4. An additional variable `perm` has been added to the returned values.\n\nBased on this pattern, the possible pattern for fixing the API method problem in this code change could be as follows:\n\n<pattern>:\nIf there is a method `self.topk()` being replaced, replace it with the new method call `self.topk(score, self.ratio, batch)`. If there is a custom method `self.tanh()` being used, replace it with the function `torch.tanh()`. If there is a line with variable assignment `edge_index, edge_attr, perm, num_nodes=x.size(0))`, modify it to `edge_index, edge_attr, perm, num_nodes=score.size(0))`. Additionally, if necessary, add any missing or additional variables to the returned values."}
{"number": 3050, "change": "class HaloAttn(nn.Module):\n\nkv = self.kv(x)\n# FIXME I 'think' this unfold does what I want it to, but I should investigate\n-        k = F.unfold(kv, kernel_size=self.win_size, stride=self.block_size, padding=self.halo_size)\n-        k = k.reshape(\n+        kv = F.unfold(kv, kernel_size=self.win_size, stride=self.block_size, padding=self.halo_size)\n+        kv = kv.reshape(\nB * self.num_heads, self.dim_head + (self.dim_v // self.num_heads), -1, num_blocks).transpose(1, 3)\n-        k, v = torch.split(k, [self.dim_head, self.dim_v // self.num_heads], dim=-1)\n+        k, v = torch.split(kv, [self.dim_head, self.dim_v // self.num_heads], dim=-1)\n\nattn_logits = (q @ k.transpose(-1, -2)) * self.scale  # FIXME should usual attn scale be applied?\nattn_logits = attn_logits + self.pos_embed(q)  # B * num_heads, block_size ** 2, win_size ** 2\n", "fix_pattern": "if variable names k and v are detected, replace them with kv"}
{"number": 3092, "change": "class XLNetRelativeAttention(nn.Module):\n\n# Mask heads if we want to\nif head_mask is not None:\n-            attn_prob = attn_prob * head_mask\n+            attn_prob = attn_prob * torch.einsum('ijbn->bnij', head_mask)\n\n# attention output\nattn_vec = torch.einsum('bnij,jbnd->ibnd', attn_prob, v_head_h)\n", "fix_pattern": "If the head_mask variable is multiplied element-wise with attn_prob, replace it with torch.einsum('ijbn->bnij', head_mask) to change the order of dimensions."}
{"number": 3161, "change": "class LAFOrienter(nn.Module):\nself.patch_size,\nself.patch_size)\nangles_radians: torch.Tensor = self.angle_detector(patches).view(B, N)\n-        laf_out: torch.Tensor = set_laf_orientation(laf, rad2deg(angles_radians))\n+        prev_angle = get_laf_orientation(laf).view_as(angles_radians)\n+        laf_out: torch.Tensor = set_laf_orientation(laf, rad2deg(angles_radians) + prev_angle)\nreturn laf_out\n", "fix_pattern": "if an orientation tensor is detected in the code, modify the function call to add the previous orientation angle to the new angle before setting the orientation"}
{"number": 3177, "change": "def regularize_cost(regex, func, name='regularize_cost'):\nfor p in params:\npara_name = p.name\n# in replicated mode, only regularize variables inside this tower\n-        if ctx.has_own_variables and (not para_name.startswith(ctx.name)):\n+        if ctx.has_own_variables and (not para_name.startswith(ctx.vs_name)):\ncontinue\nif re.search(regex, para_name):\ncosts.append(func(p))\n_log_regularizer(para_name)\nif not costs:\n-        return 0\n+        return tf.constant(0, dtype=tf.float32, name='empty_regularize_cost')\nreturn tf.add_n(costs, name=name)\n", "fix_pattern": "If a TensorFlow API call tf.constant() is detected, replace it with a torch.tensor() call."}
{"number": 3187, "change": "class TFConvBertEmbeddings(tf.keras.layers.Layer):\ntoken_type_ids = tf.fill(dims=input_shape, value=0)\n\nif position_ids is None:\n-            position_ids = tf.expand_dims(tf.range(start=0, limit=input_shape[-1]), axis=0)\n+            position_ids = tf.expand_dims(\n+                tf.range(start=past_key_values_length, limit=input_shape[1] + past_key_values_length), axis=0\n+            )\n\nposition_embeds = tf.gather(params=self.position_embeddings, indices=position_ids)\nposition_embeds = tf.tile(input=position_embeds, multiples=(input_shape[0], 1, 1))\n", "fix_pattern": "If a range of values is detected in the API call, replace the start and limit values with the appropriate variables and update the parameters accordingly."}
{"number": 3205, "change": "class Pipeline(pps_module.Preprocessor):\ntransformed.append(data)\nif len(transformed) == 1:\nreturn transformed[0]\n-        return tuple(transformed)\n+        return tf.data.Dataset.zip(tuple(transformed))\n\ndef save(self, filepath):\nio_utils.save_json(filepath, self.get_config())\n", "fix_pattern": "if returning a tuple of transformed values, wrap the tuple with tf.data.Dataset.zip()"}
{"number": 3220, "change": "class Iterative(Solver):\nnext_step = self.next_step(*args)\nstep = (lambda: self.step(*args))\ndo_nothing = (lambda: args)\n-                args = tf.cond(pred=next_step, true_fn=step, false_fn=do_nothing)\n+                args = self.cond(pred=next_step, true_fn=step, false_fn=do_nothing)\n\nelse:\n# TensorFlow while loop\n-            args = tf.while_loop(\n+            args = self.while_loop(\ncond=self.next_step, body=self.step, loop_vars=args,\nmaximum_iterations=self.max_iterations\n)\n", "fix_pattern": "If TensorFlow's tf.cond and tf.while_loop methods are detected, replace them with the corresponding methods in the class where the code is being modified (in this case, self.cond and self.while_loop)"}
{"number": 3223, "change": "def train(hyp):\nif not opt.evolve:\nplot_results()  # save as results.png\nprint('%g epochs completed in %.3f hours.\\n' % (epoch - start_epoch + 1, (time.time() - t0) / 3600))\n-    dist.destroy_process_group() if torch.cuda.device_count() > 1 else None\n+    dist.destroy_process_group() if device.type != 'cpu' and torch.cuda.device_count() > 1 else None\ntorch.cuda.empty_cache()\nreturn results\n", "fix_pattern": "if dist.destroy_process_group() is called and there are multiple CUDA devices, add a check for device type != 'cpu'"}
{"number": 3238, "change": "class PinholeCamera:\n>>> _ = torch.manual_seed(0)\n>>> x = torch.rand(1, 2)\n>>> depth = torch.ones(1, 1)\n-            >>> I = torch.eye(4)[None]\n+            >>> K = torch.eye(4)[None]\n>>> E = torch.eye(4)[None]\n>>> h = torch.ones(1)\n>>> w = torch.ones(1)\n>>> pinhole = kornia.geometry.camera.PinholeCamera(K, E, h, w)\n-            >>> pinhole.unproject_points(x, depth)\n+            >>> pinhole.unproject(x, depth)\ntensor([[0.4963, 0.7682, 1.0000]])\n\"\"\"\nP = self.intrinsics @ self.extrinsics\n", "fix_pattern": "if a function name contains the word \"unproject_points\", replace it with \"unproject\""}
{"number": 3239, "change": "class TorchHook:\nif type(native_func) in [types.FunctionType, types.BuiltinFunctionType]:\n# 3. Build the hooked function\nnew_func = self.get_hooked_func(native_func)\n-                # 4. Move the native function\n-                setattr(torch_module, f\"native_{func}\", native_func)\n+                # 4. Move the native function to its original module\n+                # /!\\ Can be different from the torch_module!\n+                # Ex: in torch.py `torch.argmax = torch.functional.argmax`\n+                # ... So torch.argmax.__module__ is 'torch.functional' != 'torch'\n+                setattr(eval(native_func.__module__), f\"native_{func}\", native_func)\n# 5. Put instead the hooked one\nsetattr(torch_module, func, new_func)\n", "fix_pattern": "If the native function is being moved to a different module, use the pattern: \nsetattr(eval(native_func.__module__), f\"native_{func}\", native_func)"}
{"number": 3242, "change": "class TowerContext(object):\nglobal _CurrentTowerContext\nassert _CurrentTowerContext is None, \"Cannot nest TowerContext!\"\n_CurrentTowerContext = self\n-        curr_vs = tf.get_variable_scope()\n-        assert curr_vs.name == '', \"Cannot nest TowerContext with an existing variable scope!\"\n+        if self.is_training:\n+            curr_vs = tf.get_variable_scope()\n+            assert curr_vs.name == '', \"In training, cannot nest TowerContext with an existing variable scope!\"\n\nself._ctxs = self._get_scopes()\nself._ctxs.append(self._collection_guard)\n", "fix_pattern": "if the code is inside an if statement checking for a training flag, add the check for the existing variable scope."}
{"number": 3244, "change": "class SelfMultiheadAttn(nn.Module):\nself.register_parameter('lyr_norm_beta_weights', None)\nself.lyr_nrm_gamma_weights = None\nself.lyr_nrm_beta_weights  = None\n-                self.lyr_nrm = torch.nn.LayerNorm(embed_dim)\n+                self.lyr_nrm = FusedLayerNorm(embed_dim)\nself.reset_parameters()\n\nif self.include_norm_add:\n", "fix_pattern": "If torch.nn.LayerNorm is detected, replace with FusedLayerNorm."}
{"number": 3250, "change": "class ScaleSpaceDetector(nn.Module):\nmax_coords_best = _scale_index_to_scale(max_coords_best, sigmas_oct)\n\n# Create local affine frames (LAFs)\n-            rotmat = angle_to_rotation_matrix(torch.zeros(B, N))\n+            rotmat = angle_to_rotation_matrix(torch.zeros(B, N).to(max_coords_best.device).to(max_coords_best.dtype))\ncurrent_lafs = torch.cat([self.mr_size * max_coords_best[:, :, 0].view(B, N, 1, 1) * rotmat,\nmax_coords_best[:, :, 1:3].view(B, N, 2, 1)], dim=3)\n# Normalize LAFs\n", "fix_pattern": "If an input tensor is detected without `.to(device)` or `.to(dtype)` after it, add the desired `.to(device)` or `.to(dtype)` at the end of the API call."}
{"number": 3271, "change": "class T5EncoderModel(T5PreTrainedModel):\nclass PreTrainedModel\n\"\"\"\nfor layer, heads in heads_to_prune.items():\n-            self.encoder.layer[layer].attention.prune_heads(heads)\n+            self.encoder.block[layer].layer[0].SelfAttention.prune_heads(heads)\n\n@add_start_docstrings_to_model_forward(T5_ENCODER_INPUTS_DOCSTRING)\n@replace_return_docstrings(output_type=BaseModelOutput, config_class=_CONFIG_FOR_DOC)\n", "fix_pattern": "if the API call is changed from self.encoder.layer[layer].attention.prune_heads(heads) to self.encoder.block[layer].layer[0].SelfAttention.prune_heads(heads), it indicates that the attention mechanism has been restructured and the attention pruning method has been moved to a different location within the codebase."}
{"number": 3283, "change": "class ResNet_Cifar(ModelDesc):\nce_cost = tf.nn.softmax_cross_entropy_with_logits(labels=label, logits=logits)\nce_cost = tf.reduce_mean(ce_cost, name='cross_entropy_loss')\n\n-        single_label = tf.to_int32(tf.argmax(label, axis=1))\n-        wrong = tf.to_float(tf.logical_not(tf.nn.in_top_k(logits, single_label, 1)), name='wrong_vector')\n+        single_label = tf.cast(tf.argmax(label, axis=1), tf.int32)\n+        wrong = tf.cast(tf.logical_not(tf.nn.in_top_k(logits, single_label, 1)), tf.float32, name='wrong_vector')\n# monitor training error\nadd_moving_summary(tf.reduce_mean(wrong, name='train_error'), ce_cost)\nadd_param_summary(('.*/W', ['histogram']))\n", "fix_pattern": "If tf.to_int32() is detected, replace it with tf.cast() and specify the dtype as tf.int32."}
{"number": 3309, "change": "class PermuteTransform(Transform):\nvector of zeros works.\n\"\"\"\n\n-        return torch.zeros_like(x)\n+        return torch.zeros(x.size()[:-1])\n", "fix_pattern": "If creating a zero tensor with the same shape as x, change torch.zeros_like(x) to torch.zeros(x.size()[:-1]) to create a zero tensor with all dimensions except the last dimension."}
{"number": 3313, "change": "def select_device(device='', batch_size=0, newline=True):\nfor i, d in enumerate(devices):\np = torch.cuda.get_device_properties(i)\ns += f\"{'' if i == 0 else space}CUDA:{d} ({p.name}, {p.total_memory / (1 << 20):.0f}MiB)\\n\"  # bytes to MB\n+    elif mps:\n+        s += 'MPS\\n'\nelse:\ns += 'CPU\\n'\n\nif not newline:\ns = s.rstrip()\nLOGGER.info(s.encode().decode('ascii', 'ignore') if platform.system() == 'Windows' else s)  # emoji-safe\n-    return torch.device('cuda:0' if cuda else 'cpu')\n+    return torch.device('cuda:0' if cuda else 'mps' if mps else 'cpu')\n\n\ndef time_sync():\n", "fix_pattern": "if an mps parameter is detected, add an elif block and append 'MPS\\n' to the string s."}
{"number": 3315, "change": "def _get_cached_vs(name):\n@contextmanager\ndef _enter_vs_reuse_ns(name):\nvs = _get_cached_vs(name)\n+    # XXX Not good to enter the cached vs directly, because this will clean-up custom getter\n+    # with tf.variable_scope(name, reuse=tf.AUTO_REUSE):    # available in 1.4 only\nwith tf.variable_scope(vs):\nwith tf.name_scope(vs.original_name_scope):\nyield vs\n", "fix_pattern": "if tf.variable_scope(name, reuse=tf.AUTO_REUSE) is detected, replace it with tf.compat.v1.variable_scope(name, reuse=tf.compat.v1.AUTO_REUSE)"}
{"number": 3317, "change": "def iou(\n\nExample:\n\n-        >>> target = torch.randint(0, 1, (10, 25, 25))\n+        >>> target = torch.randint(0, 2, (10, 25, 25))\n>>> pred = torch.tensor(target)\n>>> pred[2:5, 7:13, 9:15] = 1 - pred[2:5, 7:13, 9:15]\n>>> iou(pred, target)\n-        tensor(0.4914)\n+        tensor(0.9660)\n\n\"\"\"\nnum_classes = get_num_classes(pred=pred, target=target, num_classes=num_classes)\n", "fix_pattern": "if the integers inside the torch.randint(start, end, shape) function are changed, identify the range of the random integers."}
{"number": 3324, "change": "class E2E(STInterface, torch.nn.Module):\nisinstance(m, MultiHeadedAttention) and m.attn is not None\n):  # skip MHA for submodules\nret[name] = m.attn.cpu().numpy()\n+        self.train()\nreturn ret\n", "fix_pattern": "if the model is being used for training, add self.train() to ensure that the model is in training mode."}
{"number": 3357, "change": "class TestHausdorffLoss:\nassert_close(actual, expected)\n\n@pytest.mark.parametrize(\"hd,shape\", [\n-        [kornia.losses.HausdorffERLoss, (10, 10)],\n-        [kornia.losses.HausdorffERLoss3D, (10, 10, 10)],\n+        [kornia.losses.HausdorffERLoss, (5, 5)],\n+        [kornia.losses.HausdorffERLoss3D, (5, 5, 5)],\n])\n-    @pytest.mark.skip(reason='It passed, but will take too much time to run.')\ndef test_gradcheck(self, hd, shape, device):\nnum_classes = 3\nlogits = torch.rand(2, num_classes, *shape, device=device)\n", "fix_pattern": "if a test is skipped with @pytest.mark.skip and a reason is provided, update the reason and the test configuration"}
{"number": 3362, "change": "class TargetIndegree(object):\n\nif pseudo is not None and self.cat:\npseudo = pseudo.view(-1, 1) if pseudo.dim() == 1 else pseudo\n-            data.weight = torch.cat([pseudo, deg.type_as(pseudo)], dim=-1)\n+            data.edge_attr = torch.cat([pseudo, deg.type_as(pseudo)], dim=-1)\nelse:\n-            data.weight = deg\n+            data.edge_attr = deg\n\nreturn data\n", "fix_pattern": "if a weight tensor is detected, change \"data.weight\" to \"data.edge_attr\""}
{"number": 3372, "change": "class LukeModelIntegrationTests(unittest.TestCase):\nexpected_shape = torch.Size((1, 1, 1024))\nself.assertEqual(outputs.entity_last_hidden_state.shape, expected_shape)\n\n-        expected_slice = torch.tensor([[0.0466, -0.0106, -0.0179]])\n+        expected_slice = torch.tensor([[0.0466, -0.0106, -0.0179]]).to(torch_device)\nself.assertTrue(torch.allclose(outputs.entity_last_hidden_state[0, :3, :3], expected_slice, atol=1e-4))\n", "fix_pattern": "if a tensor is created without specifying a device, add .to(device) to the end of the tensor creation line"}
{"number": 3376, "change": "Returns:\n\"\"\"\n\n\n-class Rouge(nlp.Metric):\n+class Rouge(datasets.Metric):\ndef _info(self):\n-        return nlp.MetricInfo(\n+        return datasets.MetricInfo(\ndescription=_DESCRIPTION,\ncitation=_CITATION,\ninputs_description=_KWARGS_DESCRIPTION,\n-            features=nlp.Features(\n+            features=datasets.Features(\n{\n-                    \"predictions\": nlp.Value(\"string\", id=\"sequence\"),\n-                    \"references\": nlp.Value(\"string\", id=\"sequence\"),\n+                    \"predictions\": datasets.Value(\"string\", id=\"sequence\"),\n+                    \"references\": datasets.Value(\"string\", id=\"sequence\"),\n}\n),\ncodebase_urls=[\"https://github.com/google-research/google-research/tree/master/rouge\"],\n", "fix_pattern": "If an import statement is detected for `nlp.Metric` and the code subsequently references `nlp.MetricInfo` and `nlp.Features`, replace them with `datasets.MetricInfo` and `datasets.Features` respectively."}
{"number": 3383, "change": "class MixedInt8T5Test(unittest.TestCase):\n`flan-t5-small` uses `T5DenseGatedActDense` whereas `t5-small` uses `T5DenseReluDense`. We need to test\nboth cases.\n\"\"\"\n+        import bitsandbytes as bnb\n+\nfrom transformers import T5ForConditionalGeneration\n\n# test with `t5-small`\nmodel = T5ForConditionalGeneration.from_pretrained(self.model_name, load_in_8bit=True, device_map=\"auto\")\n+\n+        # there was a bug with decoders - this test checks that it is fixed\n+        self.assertTrue(isinstance(model.decoder.block[0].layer[0].SelfAttention.q, bnb.nn.Linear8bitLt))\n+\nencoded_input = self.tokenizer(self.input_text, return_tensors=\"pt\").to(0)\n_ = model.generate(**encoded_input)\n", "fix_pattern": "The pattern for fixing the API method problem in the given code change is to import the required module (bitsandbytes) and use the correct module name (bnb) to instantiate the Linear8bitLt object for the decoder."}
{"number": 3384, "change": "sess = tf.InteractiveSession()\nnetwork.print_params(False)\n\nsaver = tf.train.Saver()\n-if not os.path.isfile(\"inception_v3.ckpt\"):\n+if not os.path.isfile(MODEL_PATH):\nraise Exception(\n\"Please download inception_v3 ckpt from https://github.com/tensorflow/models/tree/master/research/slim\"\n)\n\ntry:  # TF12+\n-    saver.restore(sess, \"./inception_v3.ckpt\")\n+    saver.restore(sess, MODEL_PATH)\nexcept Exception:  # TF11\n-    saver.restore(sess, \"inception_v3.ckpt\")\n+    saver.restore(sess, MODEL_PATH)\nprint(\"Model Restored\")\n\ny = network.outputs\n", "fix_pattern": "if os.path.isfile() is detected with a hardcoded file name, replace the file name with a variable or constant."}
{"number": 3392, "change": "class Detect(nn.Module):\ny = torch.cat((xy, wh, conf), 4)\nz.append(y.view(bs, -1, self.no))\n\n-        return x if self.training else (torch.cat(z, 1), x)\n+        return x if self.training else (torch.cat(z, 1),) if self.export else (torch.cat(z, 1), x)\n\ndef _make_grid(self, nx=20, ny=20, i=0):\nd = self.anchors[i].device\n", "fix_pattern": "If a tuple is returned in the \"else\" condition, and \"self.export\" is False, add an additional element to the tuple."}
{"number": 3394, "change": "def benchmark_indices_mapping():\nfunctions = (select, sort, shuffle, train_test_split, shard)\nwith tempfile.TemporaryDirectory() as tmp_dir:\nprint(\"generating dataset\")\n-        features = nlp.Features({\"text\": nlp.Value(\"string\"), \"numbers\": nlp.Value(\"float32\")})\n+        features = datasets.Features({\"text\": datasets.Value(\"string\"), \"numbers\": datasets.Value(\"float32\")})\ndataset = generate_example_dataset(\nos.path.join(tmp_dir, \"dataset.arrow\"), features, num_examples=SPEED_TEST_N_EXAMPLES\n)\n", "fix_pattern": "if nlp.Features is detected, replace with datasets.Features"}
{"number": 3395, "change": "def main():\n# train\nlogging.info('backend = ' + args.backend)\nif args.backend == \"chainer\":\n-        from espnet.lmchainer.asr_chainer import train\n+        from espnet.asr.chainer.asr_chainer import train\ntrain(args)\nelif args.backend == \"pytorch\":\n-        from espnet.lmpytorch.asr_pytorch import train\n+        from espnet.asr.pytorch.asr_pytorch import train\ntrain(args)\nelse:\nraise ValueError(\"Only chainer and pytorch are supported.\")\n", "fix_pattern": "if a module import statement is detected with the old module name, replace it with the new module name"}
{"number": 3406, "change": "def get_checkpoint_path(model_path):\nlogger.warn(\n\"Checkpoint path {} is auto-corrected to {}.\".format(model_path, new_path))\nmodel_path = new_path\n-    assert os.path.isfile(model_path) or os.path.isfile(model_path + '.index'), model_path\n+    assert tf.gfile.Exists(model_path) or tf.gfile.Exists(model_path + '.index'), model_path\nreturn model_path\n", "fix_pattern": "if os.path.isfile() is detected, replace it with tf.gfile.Exists()"}
{"number": 3408, "change": "class TextClassifier(flair.nn.Model):\nself.document_embeddings.embed(sentences)\n\ntext_embedding_list = [sentence.get_embedding().unsqueeze(0) for sentence in sentences]\n-        text_embedding_tensor = torch.cat(text_embedding_list, 0)\n+        text_embedding_tensor = torch.cat(text_embedding_list, 0).to(flair.device)\n\nlabel_scores = self.decoder(text_embedding_tensor)\n", "fix_pattern": "if a tensor is created without specifying a device, add .to(device) to the end of the API call"}
{"number": 3415, "change": "def recog_v2(args):\nfor idx, name in enumerate(js.keys(), 1):\nlogging.info('(%d/%d) decoding ' + name, idx, len(js.keys()))\nbatch = [(name, js[name])]\n-            enc = model.encode(load_inputs_and_targets(batch)[0][0])\n+            feat = load_inputs_and_targets(batch)[0][0]\n+            enc = model.encode(torch.as_tensor(feat).to(device))\nnbest_hyps = beam_search(\nx=enc,\nsos=model.sos,\n", "fix_pattern": "If an input tensor is detected before passing it to the model, use torch.as_tensor() and then call .to(device) on it."}
{"number": 3419, "change": "class DecoderRNNT(torch.nn.Module):\nnormscore = recog_args.score_norm_transducer\n\nz_list, c_list = self.zero_state(h.unsqueeze(0))\n-        eys = torch.zeros((1, self.embed_dim))\n+        eys = to_device(self, torch.zeros((1, self.embed_dim)))\n\n_, (z_list, c_list) = self.rnn_forward(eys, None)\n", "fix_pattern": "if a tensor initialization is detected without specifying the device, add .to(device) after the tensor is created"}
{"number": 3421, "change": "def parse_npz(f):\n\nadj = sp.csr_matrix((f['adj_data'], f['adj_indices'], f['adj_indptr']),\nf['adj_shape']).tocoo()\n-    edge_index = torch.tensor([adj.row, adj.col])\n+    edge_index = torch.tensor([adj.row, adj.col], dtype=torch.long)\nedge_index, _ = remove_self_loops(edge_index)\nedge_index = to_undirected(edge_index, x.size(0))  # Internal coalesce.\n", "fix_pattern": "When converting a list to a tensor, if the dtype is not specified, add the dtype argument to the torch.tensor() call. In this case, the dtype is specified as torch.long."}
{"number": 3441, "change": "class GroupViTTextTransformer(nn.Module):\n\n# text_embeds.shape = [batch_size, sequence_length, transformer.width]\n# take features from the eot embedding (eot_token is the highest number in each sequence)\n-        pooled_output = last_hidden_state[torch.arange(last_hidden_state.shape[0]), input_ids.argmax(dim=-1)]\n+        # casting to torch.int for onnx compatibility: argmax doesn't support int64 inputs with opset 14\n+        pooled_output = last_hidden_state[\n+            torch.arange(last_hidden_state.shape[0]), input_ids.to(torch.int).argmax(dim=-1)\n+        ]\n\nif not return_dict:\nreturn (last_hidden_state, pooled_output) + encoder_outputs[1:]\n", "fix_pattern": "if input_ids is an int64 tensor and argmax doesn't support int64 inputs with opset 14, cast input_ids to torch.int by calling .to(torch.int) before using argmax(dim=-1)"}
{"number": 3442, "change": "def train(args, train_dataset, model, tokenizer, labels, pad_token_label_id):\nif args.fp16:\nwith amp.scale_loss(loss, optimizer) as scaled_loss:\nscaled_loss.backward()\n-                torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\nelse:\nloss.backward()\n-                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n\ntr_loss += loss.item()\nif (step + 1) % args.gradient_accumulation_steps == 0:\n+                if args.fp16:\n+                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n+                else:\n+                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n+\nscheduler.step()  # Update learning rate schedule\noptimizer.step()\nmodel.zero_grad()\n", "fix_pattern": "if there is a conditional statement checking for fp16 usage, move the clipping of gradient norms inside the conditional statement and use amp.master_params(optimizer) for clipping if fp16 is used, otherwise use model.parameters() for clipping."}
{"number": 3452, "change": "class PReluLayer(Layer):\n\n# with tf.name_scope(name) as scope:\nwith tf.variable_scope(name):\n-            alphas = tf.get_variable(name='alphas', shape=w_shape, initializer=a_init, dtype=D_TYPE, **a_init_args)\n+            alphas = tf.get_variable(name='alphas', shape=w_shape, initializer=a_init, dtype=LayersConfig.tf_dtype, **a_init_args)\ntry:  # TF 1.0\nself.outputs = tf.nn.relu(self.inputs) + tf.multiply(alphas, (self.inputs - tf.abs(self.inputs))) * 0.5\nexcept Exception:  # TF 0.12\n", "fix_pattern": "if tf.get_variable is used to define a variable, replace the dtype parameter with LayersConfig.tf_dtype."}
{"number": 3470, "change": "class Input(Layer):\nlogging.info(\"Input  %s: %s\" % (self.name, str(shape)))\n\nshape_without_none = [_ if _ is not None else 1 for _ in shape]\n-        self.outputs = self.forward(tf.initializers.random_normal()(shape_without_none))\n+        self.outputs = self.forward(tf.compat.v1.initializers.random_normal()(shape_without_none))\n\ndef __call__(self, prev_layer):\n# FIXME: better exception raising\n", "fix_pattern": "if an initializer is detected with a deprecated API (e.g., tf.initializers.random_normal()), replace it with the updated API (e.g., tf.compat.v1.initializers.random_normal())"}
{"number": 3477, "change": "class Generator(datasets.GeneratorBasedBuilder):\nreturn datasets.DatasetInfo(features=self.config.features)\n\ndef _split_generators(self, dl_manager):\n-        return [datasets.SplitGenerator(name=datasets.Split.TRAIN, gen_kwargs={})]\n+        return [datasets.SplitGenerator(name=datasets.Split.TRAIN, gen_kwargs=self.config.gen_kwargs)]\n\n-    def _generate_examples(self):\n-        for idx, ex in enumerate(self.config.generator(**self.config.gen_kwargs)):\n+    def _generate_examples(self, **gen_kwargs):\n+        for idx, ex in enumerate(self.config.generator(**gen_kwargs)):\nyield idx, ex\n", "fix_pattern": "if a method signature changes and additional arguments are added, update the method implementation accordingly"}
{"number": 3492, "change": "def run(\nseen, windows, dt = 0, [], (Profile(), Profile(), Profile())\nfor path, im, im0s, vid_cap, s in dataset:\nwith dt[0]:\n-            im = torch.from_numpy(im).to(device)\n+            im = torch.from_numpy(im).to(model.device)\nim = im.half() if model.fp16 else im.float()  # uint8 to fp16/32\nim /= 255  # 0 - 255 to 0.0 - 1.0\nif len(im.shape) == 3:\n", "fix_pattern": "if an input tensor is converted to a PyTorch tensor using the torch.from_numpy() method and then converted to a device using the .to() method, replace the device with the desired device or model.device."}
{"number": 3513, "change": "class OPTAttention(nn.Module):\nattn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len) + attention_mask\nattn_weights = torch.max(attn_weights, torch.tensor(torch.finfo(attn_weights.dtype).min))\nattn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n-            dtype_attn_weights = attn_weights.dtype\n\n# upcast to fp32 if the weights are in fp16. Please see https://github.com/huggingface/transformers/pull/17437\n-        if dtype_attn_weights == torch.float16:\n-            attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(dtype_attn_weights)\n+        if attn_weights.dtype == torch.float16:\n+            attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(torch.float16)\nelse:\nattn_weights = nn.functional.softmax(attn_weights, dim=-1)\n", "fix_pattern": "if an API call is made to change the dtype of a tensor, and the dtype is specified using a variable, replace the variable with the actual dtype in the .to() method."}
{"number": 3531, "change": "class ScoreSdeVpScheduler(SchedulerMixin, ConfigMixin):\nself.discrete_sigmas = None\nself.timesteps = None\n\n-    def set_timesteps(self, num_inference_steps):\n-        self.timesteps = torch.linspace(1, self.config.sampling_eps, num_inference_steps)\n+    def set_timesteps(self, num_inference_steps, device: Union[str, torch.device] = None):\n+        self.timesteps = torch.linspace(1, self.config.sampling_eps, num_inference_steps, device=device)\n\ndef step_pred(self, score, x, t, generator=None):\nif self.timesteps is None:\n", "fix_pattern": "if an API method has an additional argument 'device' with a default value of None, add the 'device' parameter to the method and pass the 'device' argument to the API call"}
{"number": 3533, "change": "class DeepSpeedEngine(Module):\nmodel_dtype = torch.bfloat16\n\nif self._config.grad_accum_dtype == None:\n-            if model_dtype == torch.bfloat16:\n+            if model_dtype == torch.bfloat16 and not self.zero_optimization():\ngrad_accum_dtype = torch.float32\nelse:\ngrad_accum_dtype = model_dtype\n", "fix_pattern": "if checking model dtype with torch.bfloat16 is detected, add \"and not self.zero_optimization()\" to the condition."}
{"number": 3555, "change": "def _create(name, pretrained=True, channels=3, classes=80, autoshape=True, verbo\ncfg = list((Path(__file__).parent / 'models').rglob(f'{name}.yaml'))[0]  # model.yaml path\nmodel = Model(cfg, channels, classes)  # create model\nif pretrained:\n-                attempt_download(fname)  # download if not found locally\n-                ckpt = torch.load(fname, map_location=torch.device('cpu'))  # load\n+                ckpt = torch.load(attempt_download(fname), map_location=torch.device('cpu'))  # load\nmsd = model.state_dict()  # model state_dict\ncsd = ckpt['model'].float().state_dict()  # checkpoint state_dict as FP32\ncsd = {k: v for k, v in csd.items() if msd[k].shape == v.shape}  # filter\n", "fix_pattern": "if an API call is made to download a file and then immediately load it using torch.load(), replace the separate download and load calls with a single call to torch.load()"}
{"number": 3559, "change": "class Model(ModelDesc):\n# For visualization in tensorboard\npadded1 = tf.pad(sampled1, [[0, 0], [HALF_DIFF, HALF_DIFF], [HALF_DIFF, HALF_DIFF], [0, 0]])\npadded2 = tf.pad(sampled2, [[0, 0], [HALF_DIFF, HALF_DIFF], [HALF_DIFF, HALF_DIFF], [0, 0]])\n-        img_orig = tf.concat(1, [image[:, :, :, 0], image[:, :, :, 1]])  # b x 2h  x w\n-        transform1 = tf.concat(1, [padded1[:, :, :, 0], padded1[:, :, :, 1]])\n-        transform2 = tf.concat(1, [padded2[:, :, :, 0], padded2[:, :, :, 1]])\n-        stacked = tf.concat(2, [img_orig, transform1, transform2], 'viz')\n+        img_orig = tf.concat_v2([image[:, :, :, 0], image[:, :, :, 1]], 1)  # b x 2h  x w\n+        transform1 = tf.concat_v2([padded1[:, :, :, 0], padded1[:, :, :, 1]], 1)\n+        transform2 = tf.concat_v2([padded2[:, :, :, 0], padded2[:, :, :, 1]], 1)\n+        stacked = tf.concat_v2([img_orig, transform1, transform2], 2, 'viz')\ntf.summary.image('visualize',\ntf.expand_dims(stacked, -1), max_images=30)\n\n-        sampled = tf.concat(3, [sampled1, sampled2], 'sampled_concat')\n+        sampled = tf.concat_v2([sampled1, sampled2], 3, 'sampled_concat')\nlogits = (LinearWrap(sampled)\n.apply(symbf.batch_flatten)\n.FullyConnected('fc1', out_dim=256, nl=tf.nn.relu)\n", "fix_pattern": "if deprecated API tf.concat( detected, replace with tf.concat_v2("}
{"number": 3567, "change": "def BatchNorm(x, use_local_stat=None, decay=0.9, epsilon=1e-5):\n\nn_out = shape[-1]  # channel\nassert n_out is not None\n-    beta = tf.get_variable('beta', [n_out])\n+    beta = tf.get_variable('beta', [n_out],\n+            initializer=tf.zeros_initializer)\ngamma = tf.get_variable('gamma', [n_out],\n-        initializer=tf.ones_initializer)\n+            initializer=tf.ones_initializer)\n\nif len(shape) == 2:\nbatch_mean, batch_var = tf.nn.moments(x, [0], keep_dims=False)\n", "fix_pattern": "if an initializer is detected as tf.ones_initializer), replace it with tf.zeros_initializer"}
{"number": 3569, "change": "def densenet_block(incoming, nb_layers, growth, bottleneck=True,\n\"\"\"\ndensenet = incoming\n\n-    for i in range(nb_layers):\n+    with tf.variable_scope(scope, default_name=name, values=[incoming],\n+                           reuse=reuse) as scope:\n\n-        with tf.variable_scope(scope, default_name=name, values=[incoming],\n-                               reuse=reuse) as scope:\n+        for i in range(nb_layers):\n\n# Identity\nconn = densenet\n", "fix_pattern": "if the variable scope is defined outside the for loop, move the for loop inside the scope"}
{"number": 3573, "change": "class BertForQuestionAnswering(nn.Module):\ndef compute_loss(logits, positions):\nmax_position = positions.max().item()\none_hot = torch.FloatTensor(batch_size, max(max_position, seq_length) +1, device=input_ids.device).zero_()\n-                one_hot = one_hot.scatter(1, positions, 1)\n+                one_hot = one_hot.scatter(1, positions.cpu(), 1) # Second argument need to be LongTensor and not cuda.LongTensor\none_hot = one_hot[:, :seq_length]\nlog_probs = nn.functional.log_softmax(logits, dim = -1).view(batch_size, seq_length)\nloss = -torch.mean(torch.sum(one_hot*log_probs), dim = -1)\n", "fix_pattern": "If the positions tensor is not a LongTensor, convert it to a LongTensor using the .cpu() method."}
{"number": 3585, "change": "class CrossViT(nn.Module):\n\n# NOTE: was before branch token section, move to here to assure all branch token are before layer norm\nxs = [norm(xs[i]) for i, norm in enumerate(self.norm)]\n-        return [xo[:, 0] for xo in xs]\n+        return xs\n\ndef forward(self, x):\nxs = self.forward_features(x)\n-        ce_logits = [head(xs[i]) for i, head in enumerate(self.head)]\n+        ce_logits = [head(xs[i][:, 0]) for i, head in enumerate(self.head)]\nif not isinstance(self.head[0], nn.Identity):\nce_logits = torch.mean(torch.stack(ce_logits, dim=0), dim=0)\nreturn ce_logits\n", "fix_pattern": "if a list comprehension is used to extract specific elements from a list, change the indexing inside the comprehension to extract the desired elements"}
{"number": 3598, "change": "def coalesce(edge_index, edge_attr=None, num_nodes=None):\n_, perm = unique(index)\nedge_index = edge_index[:, perm]\nelse:\n-        sparse = getattr(torch.sparse, edge_attr.type().split('.')[-1])\n+        t = torch.cuda if edge_attr.is_cuda else torch\n+        sparse = getattr(t.sparse, edge_attr.type().split('.')[-1])\nn = num_nodes\nsize = torch.Size([n, n] + list(edge_attr.size())[1:])\nadj = sparse(edge_index, edge_attr, size).coalesce()\n", "fix_pattern": "if accessing an attribute of torch.sparse is detected, replace it with getattr(torch.sparse, attribute_name) and determine the torch module based on whether the tensor is on cuda or not."}
{"number": 3616, "change": "def md5sum(filename):\n\n\ndef switch_mps_device(model_name, device):\n-    if model_name not in MPS_SUPPORT_MODELS and (\n-        device == \"mps\" or device == torch.device(\"mps\")\n-    ):\n+    if model_name not in MPS_SUPPORT_MODELS and str(device) == \"mps\":\nlogger.info(f\"{model_name} not support mps, switch to cpu\")\nreturn torch.device(\"cpu\")\nreturn device\n", "fix_pattern": "if checking device equality with \"device\" or torch.device(\"device\"), replace with str(device) == \"device\""}
{"number": 3623, "change": "class ImagePreprocessingPass(unittest.TestCase):\nx4 = mb.add(x=x1, y=x3)\nreturn mb.relu(x=x4)\n\n-        proto = converter._convert(prog, inputs=[ImageType(name=\"x\", shape=(10, 20, 30, 3), channel_first=False)], convert_from=\"mil\", convert_to=\"nn_proto\")\n-        model = models.MLModel(proto)\n-        assert model is not None\n-        assert len(model._spec.neuralNetwork.layers) == 3\n+        mlmodel = ct.convert(prog,\n+            inputs=[ImageType(name=\"x\", shape=(10, 20, 30, 3),\n+              channel_first=False)],\n+            source=\"mil\", convert_to=\"nn_proto\")\n+        assert mlmodel is not None\n+        assert len(mlmodel.get_spec().neuralNetwork.layers) == 3\n", "fix_pattern": "If a converter API is detected, replace it with the corresponding coremltools API functions and update the assertion statements accordingly."}
{"number": 3633, "change": "def add_dataset_args(parser, train=False, gen=False):\nreturn group\n\n\n-def add_distributed_training_args(parser):\n+def add_distributed_training_args(parser, default_world_size=None):\ngroup = parser.add_argument_group(\"Distributed training\")\n# fmt: off\n+    if default_world_size is None:\n+        default_world_size = max(1, torch.cuda.device_count())\ngroup.add_argument('--distributed-world-size', type=int, metavar='N',\n-                       default=max(1, torch.cuda.device_count()),\n+                       default=default_world_size,\nhelp='total number of GPUs across all nodes (default: all visible GPUs)')\ngroup.add_argument('--distributed-rank', default=0, type=int,\nhelp='rank of the current worker')\n", "fix_pattern": "if a default value for an argument is set using a function call, modify the function definition to include the argument and set its default value using an if statement."}
{"number": 3660, "change": "class OpenSlr(datasets.GeneratorBasedBuilder):\n# set absolute path for audio file\npath = os.path.join(path_to_datas[i], f\"{filename}.wav\")\ncounter += 1\n-                        yield counter, {\"path\": path, \"sentence\": sentence}\n+                        yield counter, {\"path\": path, \"audio\": path, \"sentence\": sentence}\n", "fix_pattern": "if a dictionary is yielded with missing or additional keys, add or remove the corresponding key-value pairs in the yield statement."}
{"number": 3662, "change": "def find_homography_dlt(\nU, S, V = torch.svd(A)\nexcept:\nwarnings.warn('SVD did not converge', RuntimeWarning)\n-        return torch.empty((points1_norm.size(0), 3, 3), device=points1.device)\n+        return torch.empty((points1_norm.size(0), 3, 3), device=device, dtype=dtype)\n\nH = V[..., -1].view(-1, 3, 3)\nH = transform2.inverse() @ (H @ transform1)\n", "fix_pattern": "If a device is specified in the original code using the `device` parameter, replace `points1.device` with `device` and add a `dtype` parameter to specify the dtype."}
{"number": 3686, "change": "class ESPnetASRMixModel(AbsESPnetModel):\nignore_label=self.ignore_id,\n)\n)\n-        loss_att = torch.mean(loss_att)\n+        loss_att = torch.stack(loss_att, dim=0).mean()\nacc_att = np.mean(acc_att)\n\n# Compute cer/wer using attention-decoder\n", "fix_pattern": "If a loss tensor is computed using torch.mean(), replace it with torch.stack() followed by .mean() to ensure dimensionality is preserved."}
{"number": 3693, "change": "class RagConfig(PretrainedConfig):\ndecoder_config = kwargs.pop(\"generator\")\ndecoder_model_type = decoder_config.pop(\"model_type\")\n\n-        from .configuration_auto import AutoConfig\n+        from ..auto.configuration_auto import AutoConfig\n\nself.question_encoder = AutoConfig.for_model(question_encoder_model_type, **question_encoder_config)\nself.generator = AutoConfig.for_model(decoder_model_type, **decoder_config)\n", "fix_pattern": "if the import path is changed, update the import statement accordingly"}
{"number": 3697, "change": "TENSOR_CLASS_NAMES = (\n\"Tensor\",\n)\n\n-ST = TypeVar(\"ST\")\n+ST = t.TypeVar(\"ST\")\n\n\n-def _isinstance_wrapper(obj: ST, sobj: Union[str, type, Sequence]) -> bool:\n+def _isinstance_wrapper(obj: ST, sobj: t.Union[str, type, t.Sequence]) -> bool:\n\"\"\"\n`isinstance` wrapper to check tensor spec\n", "fix_pattern": "If TypeVar is used without importing it from the typing module, add 't.' before TypeVar."}
{"number": 3705, "change": "class WaveNet(object):\nThe variables are all scoped to the given name.\n'''\nwith tf.variable_scope(name):\n-            input_batch = self.encode(input_batch)\n+            input_batch = mu_law_encode(input_batch,\n+                                        self.quantization_channels)\nencoded = self._one_hot(input_batch)\nraw_output = self._create_network(encoded)\n", "fix_pattern": "if a method call to self.encode() is detected, replace it with mu_law_encode() with additional arguments."}
{"number": 3706, "change": "def tensordot(\nout: Optional[torch.Tensor] = None,\n) -> torch.Tensor:\n# find the type to promote to\n-    dtype = torch.promote_types(x1.dtype, x2.dtype)\n+    dtype = ivy.as_native_dtype(ivy.promote_types(x1.dtype, x2.dtype))\n# type conversion to one that torch.tensordot can work with\nx1, x2 = x1.type(torch.float32), x2.type(torch.float32)\n", "fix_pattern": "if torch.promote_types() is detected, replace it with ivy.promote_types() and add ivy.as_native_dtype() around the entire expression."}
{"number": 3724, "change": "def test_train_step_epoch_end_scalar(tmpdir):\ntrain_step_out = out.training_step_output_for_epoch_end\nassert len(train_step_out) == 1\ntrain_step_out = train_step_out[0][0]\n-    assert isinstance(train_step_out, torch.Tensor)\n-    assert train_step_out.item() == 171\n+    assert isinstance(train_step_out['minimize'], torch.Tensor)\n+    assert train_step_out['minimize'].item() == 171\n\n# make sure the optimizer closure returns the correct things\nopt_closure_result = trainer.train_loop.training_step_and_backward(\n", "fix_pattern": "if the key in the assert statement is changed from \".item()\" to \"['minimize'].item()\""}
{"number": 3780, "change": "class OneHotCategorical(Distribution):\nsample. The last dimension is used for the one-hot encoding.\n:rtype: torch.autograd.Variable.\n\"\"\"\n-        return Variable(torch.stack([t.expand_as(self.ps) for t in torch_eye(*self.event_shape())]))\n+        result = torch.stack([t.expand_as(self.ps) for t in torch_eye(*self.event_shape())])\n+        if self.ps.is_cuda:\n+            result = result.cuda(self.ps.get_device())\n+        return Variable(result)\n\ndef analytic_mean(self):\n\"\"\"\n", "fix_pattern": "if the tensor is created using the torch_eye() function and needs to be expanded, check if the tensor is on GPU (cuda) and if so, move the result tensor to the GPU  \n"}
{"number": 3788, "change": "def bidirectional_rnn(incoming, rnncell_fw, rnncell_bw, return_seq=False,\ntf.add_to_collection(tf.GraphKeys.ACTIVATIONS, outputs[-1])\n\nif dynamic:\n-        outputs = tf.transpose(tf.pack(outputs), [1, 0, 2])\n-        o = advanced_indexing_op(outputs, sequence_length)\n+        if return_seq:\n+            o = outputs\n+        else:\n+            outputs = tf.transpose(tf.pack(outputs), [1, 0, 2])\n+            o = advanced_indexing_op(outputs, sequence_length)\nelse:\no = outputs if return_seq else outputs[-1]\n", "fix_pattern": "if a conditional statement is added to the code, check if the original code should be executed under that condition or if there are any additional steps required."}
{"number": 3813, "change": "\"\\n\",\n\"# For evaluation we use exactly normalized rather than\\n\",\n\"# approximately normalized.\\n\",\n-        \"sts_encode1 = tf.nn.l2_normalize(embed(sts_input1))\\n\",\n-        \"sts_encode2 = tf.nn.l2_normalize(embed(sts_input2))\\n\",\n-        \"sim_scores = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)\"\n+        \"sts_encode1 = tf.nn.l2_normalize(embed(sts_input1), axis=1)\\n\",\n+        \"sts_encode2 = tf.nn.l2_normalize(embed(sts_input2), axis=1)\\n\",\n+        \"sim_scores = -tf.acos(tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1))\"\n]\n},\n{\n", "fix_pattern": "If the tf.nn.l2_normalize() API is detected without an axis parameter, add the axis parameter to normalize along a specific axis."}
{"number": 3831, "change": "class TFFastSpeech2(TFFastSpeech):\nduration_outputs = self.duration_predictor(\n[last_encoder_hidden_states, speaker_ids, attention_mask]\n)  # [batch_size, length]\n-        duration_outputs = tf.math.exp(duration_outputs) - 1.0\n+        duration_outputs = tf.nn.relu(tf.math.exp(duration_outputs) - 1.0)\nduration_outputs = tf.cast(\ntf.math.round(duration_outputs * speed_ratios), tf.int32\n)\n", "fix_pattern": "if a math operation is detected, wrap it with a suitable activation function, e.g., tf.nn.relu()"}
{"number": 3849, "change": "floor_divide.support_native_out = True\n\n\ndef floormod(\n-    x: torch.Tensor, y: torch.Tensor, *, out: Optional[torch.Tensor] = None\n+    x: torch.Tensor, y: torch.Tensor, /, *, out: Optional[torch.Tensor] = None\n) -> torch.Tensor:\n+    x, y = ivy.promote_types_of_inputs(x, y)\nreturn x % y\n", "fix_pattern": "If a function signature contains a special character (\"/\"), move it to a new line and add an import statement for the function."}
{"number": 3880, "change": "def _prepare_output_docstrings(output_type, config_class):\n\n# Add the return introduction\nfull_output_type = f\"{output_type.__module__}.{output_type.__name__}\"\n-    intro = RETURN_INTRODUCTION.format(full_output_type=full_output_type, config_class=config_class)\n+    intro = TF_RETURN_INTRODUCTION if output_type.__name__.startswith(\"TF\") else PT_RETURN_INTRODUCTION\n+    intro = intro.format(full_output_type=full_output_type, config_class=config_class)\nreturn intro + docstrings\n", "fix_pattern": "if a string formatting statement is used to generate the variable intro, check the value of output_type.__name__. If it starts with \"TF\", set intro to TF_RETURN_INTRODUCTION, otherwise set it to PT_RETURN_INTRODUCTION. Finally, format the intro string with the full_output_type and config_class variables."}
{"number": 3915, "change": "class RolloutWorker(EvaluatorInterface, ParallelIteratorWorker):\npolicy_config = policy_config or {}\nif (tf and policy_config.get(\"eager\")\nand not policy_config.get(\"no_eager_on_workers\")):\n-            tf.enable_eager_execution()\n+            # This check is necessary for certain all-framework tests that\n+            # use tf's eager_mode() context generator.\n+            if not tf.executing_eagerly():\n+                tf.enable_eager_execution()\n\nif log_level:\nlogging.getLogger(\"ray.rllib\").setLevel(log_level)\n", "fix_pattern": "if the API call `tf.enable_eager_execution()` is present, add a check using `tf.executing_eagerly()` and enable eager execution if it is not already enabled."}
{"number": 3947, "change": "class Model(object):\n\nelif action_spec['type'] == 'float':\nif 'min_value' in action_spec:\n-                    exploration = tf.clip_by_value(\n+                    exploration_value = tf.clip_by_value(\nt=exploration_value,\nclip_value_min=action_spec['min_value'],\nclip_value_max=action_spec['max_value']\n)\n\n-                action += tf.reshape(exploration, tf.shape(action))\n+                action += tf.reshape(exploration_value, tf.shape(action))\n\nreturn action\n", "fix_pattern": "If tf.clip_by_value() is detected, replace exploration with exploration_value"}
{"number": 3960, "change": "class TestRandomPerspective:\nassert out_perspective[0].shape == x_data.shape\nassert out_perspective[1].shape == (1, 3, 3)\nassert_allclose(out_perspective[0], x_data)\n-        assert_allclose(out_perspective[1], torch.eye(3, device=device))\n+        assert_allclose(out_perspective[1], torch.eye(3, device=device)[None])\n\ndef test_transform_module_should_return_expected_transform(self, device):\ntorch.manual_seed(0)\n", "fix_pattern": "if a tensor is wrapped in a call to assert_allclose() and it is missing [None] at the end, add [None] to the tensor."}
{"number": 3963, "change": "def average_grads(all_grads):\nfor grad_and_vars in zip(*all_grads):\n# Ngpu * 2\nv = grad_and_vars[0][1]\n-            all_grads = [g for (g, _) in grad_and_vars]\n+            grads = [g for (g, _) in grad_and_vars]\n\nwith tf.device(v.device):       # colocate summed grad with var\ngrad = tf.multiply(\n-                    tf.add_n(all_grads), 1.0 / nr_tower)\n+                    tf.add_n(grads), 1.0 / nr_tower)\nret.append((grad, v))\nreturn ret\n", "fix_pattern": "Remove the unnecessary assignment of the list comprehension variable \"all_grads\" and update the parameter name \"all_grads\" to \"grads\" in the function call tf.add_n()."}
{"number": 3982, "change": "from ivy.container import Container\n\n\ndef variable(x):\n-    with ivy.dev(x, as_native=True):\n+    with tf.device(ivy.dev(x, as_native=True)):\nreturn tf.Variable(x, trainable=True)\n", "fix_pattern": "if an ivy.dev() method is detected, replace it with tf.device(ivy.dev())"}
{"number": 3992, "change": "class Deterministic(TFActionDistribution):\nreturn self.inputs\n\n@override(TFActionDistribution)\n-    def sampled_action_logp(self):\n-        return 0.0\n+    def logp(self, x):\n+        return tf.zeros_like(self.inputs)\n\n@override(TFActionDistribution)\ndef _build_sample_op(self):\n", "fix_pattern": "The pattern for fixing the API method problem in the given code change is:\n\nif a method named \"sampled_action_logp\" is detected, replace it with a new method named \"logp\" that returns tf.zeros_like(self.inputs)."}
{"number": 4000, "change": "def test_cholesky_transform(batch_shape, dim, transform):\nassert_close(log_det, torch.slogdet(jacobian)[1])\n\nassert log_det.shape == batch_shape\n-    assert_close(y, x_mat.cholesky())\n+    assert_close(y, torch.linalg.cholesky(x_mat))\nassert_close(transform.inv(y), x_mat)\n", "fix_pattern": "if a cholesky operation on a matrix is detected using the function x_mat.cholesky(), replace it with torch.linalg.cholesky(x_mat)"}
{"number": 4025, "change": "class SimpleTaggerTest(AllenNlpTestCase):\ntraining_arrays = self.dataset.as_arrays()\n\n# TODO(Mark): clean this up once the Trainer is finalised.\n-        sequence = training_arrays[\"tokens\"][0]\n+        sequence = training_arrays[\"tokens\"][\"tokens\"]\ntags = training_arrays[\"tags\"]\n-        training_arrays = {\"tokens\": Variable(torch.from_numpy(sequence)),  # pylint: disable=no-member\n+        training_arrays = {\"tokens\": {\"tokens\": Variable(torch.from_numpy(sequence))},  # pylint: disable=no-member\n\"tags\": Variable(torch.from_numpy(tags))}  # pylint: disable=no-member\n_ = self.model.forward(**training_arrays)\n\ndef test_tag_returns_distributions_per_token(self):\n-        text = TextField([\"This\", \"is\", \"a\", \"sentence\"], token_indexers=[SingleIdTokenIndexer()])\n+        text = TextField([\"This\", \"is\", \"a\", \"sentence\"], token_indexers={\"tokens\": SingleIdTokenIndexer()})\noutput = self.model.tag(text)\npossible_tags = self.vocab.get_index_to_token_vocabulary(\"tags\").values()\nfor tag in output[\"tags\"]:\n", "fix_pattern": "if a dictionary is detected as a value for a key in a dictionary, wrap the value in another dictionary with the same key"}
{"number": 4040, "change": "def main():\nglobal_step += 1\n\n# Save a trained model\n-        logger.info(\"** ** * Saving fine - tuned model ** ** * \")\nmodel_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\noutput_model_file = os.path.join(args.output_dir, WEIGHTS_NAME)\noutput_config_file = os.path.join(args.output_dir, CONFIG_NAME)\n-        if args.do_train:\n+        if args.do_train and torch.distributed.get_rank() == 0:\n+            logger.info(\"** ** * Saving fine - tuned model ** ** * \")\ntorch.save(model_to_save.state_dict(), output_model_file)\nmodel_to_save.config.to_json_file(output_config_file)\ntokenizer.save_vocabulary(args.output_dir)\n", "fix_pattern": "if an if statement checking for args.do_train is present and a rank is being checked using torch.distributed.get_rank(), move the logger inside the if statement"}
{"number": 4067, "change": "def triu_inverse(x):\nB_Dinv = B / x.bottom_diag.unsqueeze(-2)\n\nidentity = torch.eye(head_size, dtype=A.dtype, device=A.device)\n-    top_left = torch.triangular_solve(identity, A, upper=True)[0]\n+    top_left = torch.linalg.solve_triangular(A, identity, upper=True)\ntop_right = -top_left.matmul(B_Dinv)  # complexity: head_size^2 x N\ntop = torch.cat([top_left, top_right], -1)\nbottom_diag = x.bottom_diag.reciprocal()\n", "fix_pattern": "If torch.triangular_solve() method is detected, replace it with torch.linalg.solve_triangular() method and make necessary changes to the arguments."}
{"number": 4068, "change": "def train():\n\n# Compute loss\nloss, loss_items = compute_loss(pred, targets, model)\n+            if torch.isnan(loss):\n+                print('WARNING: nan loss detected, skipping batch ', loss_items)\n+                continue\n\n# Scale loss by nominal batch_size of 64\nloss *= batch_size / 64\n", "fix_pattern": "if a check for a NaN loss is detected, add a warning print statement inside an if statement that skips the batch"}
{"number": 4070, "change": "def concat(\nxs = list(xs)\nhighest_dtype = xs[0].dtype\nfor i in xs:\n-        highest_dtype = tf.experimental.numpy.promote_types(highest_dtype, i.dtype)\n+        highest_dtype = ivy.as_native_dtype(ivy.promote_types(highest_dtype, i.dtype))\n\nfor i in range(len(xs)):\nif is_axis_none:\n", "fix_pattern": "if tf.experimental.numpy.promote_types() is detected, replace it with ivy.promote_types() and add ivy.as_native_dtype() to the beginning of the call."}
{"number": 4072, "change": "else:\nversion_str += f'+{git_hash}'\n\ntorch_version = \".\".join([TORCH_MAJOR, TORCH_MINOR])\n-cuda_version = \".\".join(torch.version.cuda.split('.')[:2])\n+# Set cuda_version to 0.0 if cpu-only\n+cuda_version = \"0.0\"\n+if torch.version.cuda is not None:\n+    cuda_version = \".\".join(torch.version.cuda.split('.')[:2])\ntorch_info = {\"version\": torch_version, \"cuda_version\": cuda_version}\n\nprint(f\"version={version_str}, git_hash={git_hash}, git_branch={git_branch}\")\n", "fix_pattern": "if checking for cuda_version and setting it to a default value of \"0.0\" if cuda is not available"}
{"number": 4084, "change": "class TestElmoTokenRepresentation(ElmoTestCase):\nfor k in range(10):\nchar_indices = indices[\"elmo\"][(k * 50):((k + 1) * 50)]\nsentences.append(\n-                    indexer.pad_token_sequence(\n+                    indexer.as_padded_tensor(\n{'key': char_indices}, desired_num_tokens={'key': 50}, padding_lengths={}\n)['key']\n)\n-        batch = torch.from_numpy(numpy.array(sentences))\n+        batch = torch.stack(sentences)\n\nelmo_token_embedder = _ElmoCharacterEncoder(self.options_file, self.weight_file)\nelmo_token_embedder_output = elmo_token_embedder(batch)\n", "fix_pattern": "if a padding function indexer.pad_token_sequence() is detected, replace it with indexer.as_padded_tensor() and use torch.stack() to stack the sentences together"}
{"number": 4086, "change": "def multiclass_nms(multi_bboxes, multi_scores, score_thr, nms_cfg, max_num=-1):\nelse:\n_bboxes = multi_bboxes[cls_inds, i * 4:(i + 1) * 4]\n_scores = multi_scores[cls_inds, i]\n+        if score_factors is not None:\n+            _scores *= score_factors[cls_inds]\ncls_dets = torch.cat([_bboxes, _scores[:, None]], dim=1)\ncls_dets, _ = nms_op(cls_dets, **nms_cfg_)\n-        cls_labels = multi_bboxes.new_full(\n-            (cls_dets.shape[0], ), i - 1, dtype=torch.long)\n+        cls_labels = multi_bboxes.new_full((cls_dets.shape[0], ),\n+                                           i - 1,\n+                                           dtype=torch.long)\nbboxes.append(cls_dets)\nlabels.append(cls_labels)\nif bboxes:\n", "fix_pattern": "if a tensor is created using the \"new_full\" method and dtype is declared separately, replace the dtype parameter with the desired data type"}
{"number": 4087, "change": "class CommonTestCases:\nmodel = model_class(config)\nself.assertIsInstance(\nmodel.get_input_embeddings(),\n-                    torch.nn.Embedding\n+                    (torch.nn.Embedding, AdaptiveEmbedding)\n)\nmodel.set_input_embeddings(torch.nn.Embedding(10, 10))\nx = model.get_output_embeddings()\n", "fix_pattern": "if a torch.nn.Embedding API is detected, replace it with AdaptiveEmbedding"}
{"number": 4092, "change": "\"@config_enumerate\\n\",\n\"def model(data, num_components=3):\\n\",\n\"    print('Running model with {} data points'.format(len(data)))\\n\",\n-    \"    p = pyro.sample(\\\"p\\\", dist.Dirichlet(0.5 * torch.ones(3)))\\n\",\n+    \"    p = pyro.sample(\\\"p\\\", dist.Dirichlet(0.5 * torch.ones(num_components)))\\n\",\n\"    scale = pyro.sample(\\\"scale\\\", dist.LogNormal(0, num_components))\\n\",\n\"    with pyro.plate(\\\"components\\\", num_components):\\n\",\n\"        loc = pyro.sample(\\\"loc\\\", dist.Normal(0, 10))\\n\",\n", "fix_pattern": "if the dimensions of the tensor passed to dist.Dirichlet API change, update the argument accordingly."}
{"number": 4100, "change": "class DQNTorchModel(TorchModelV2, nn.Module):\nif self.num_atoms > 1:\n# Distributional Q-learning uses a discrete support z\n# to represent the action value distribution\n-            z = torch.range(0.0, self.num_atoms - 1, dtype=torch.float32)\n+            z = torch.range(\n+                0.0, self.num_atoms - 1,\n+                dtype=torch.float32).to(action_scores.device)\nz = self.v_min + \\\nz * (self.v_max - self.v_min) / float(self.num_atoms - 1)\n", "fix_pattern": "if a tensor is created using torch.range() without specifying the device, add .to(device) to the end of the API call to ensure it is placed on the desired device."}
{"number": 4119, "change": "class LocalMetricTest(parameterized.TestCase):\n@slow\ndef test_load_real_metric(self, metric_name):\ndoctest.ELLIPSIS_MARKER = \"[...]\"\n-        metric_module = importlib.import_module(datasets.load.prepare_module(os.path.join(\"metrics\", metric_name))[0])\n+        metric_module = importlib.import_module(\n+            datasets.load.metric_module_factory(os.path.join(\"metrics\", metric_name)).module_path\n+        )\n# run doctest\nwith self.use_local_metrics():\nresults = doctest.testmod(metric_module, verbose=True, raise_on_error=True)\n", "fix_pattern": "If an import module is detected using importlib.import_module with the argument being a concatenated string, replace it with importlib.import_module using the imported metric_module_factory method and the module_path attribute."}
{"number": 4140, "change": "class ModelTesterMixin:\nmodel.to(torch_device)\nmodel.eval()\nwith torch.no_grad():\n-                outputs = model(**inputs_dict)\n+                outputs = model(**self._prepare_for_class(inputs_dict, model_class))\nattentions = outputs[-1]\nself.assertEqual(model.config.output_hidden_states, False)\nself.assertEqual(len(attentions), self.model_tester.num_hidden_layers)\n", "fix_pattern": "if model(**inputs_dict) is replaced with model(**self._prepare_for_class(inputs_dict, model_class))"}
{"number": 4189, "change": "class Embed(base.AbstractModule):\nregularizer=self._regularizers.get(self.EMBEDDINGS, None),\ntrainable=self._trainable)\n\n+    # On the backwards pass, we want to convert the gradient from\n+    # indexed-slices to a regular tensor before sending it back to the\n+    # parameter server. This avoids excess computation on the parameter server.\n+\n+    embeddings = util.convert_gradient_to_tensor(self._embeddings)\n+\n# Lookup embeddings\n-    return tf.nn.embedding_lookup(\n-        self._embeddings, ids, name=\"embedding_lookup\")\n+    return tf.nn.embedding_lookup(embeddings, ids, name=\"embedding_lookup\")\n\n@property\ndef vocab_size(self):\n", "fix_pattern": "if tf.nn.embedding_lookup API call is detected, add a call to util.convert_gradient_to_tensor before the API call."}
{"number": 4192, "change": "def test_hook(history):\ntf.summary.scalar('c1', c1)\nsummary_op = tf.summary.merge_all()\n\n-        hook = wandb_tensorflow.WandbHook(summary_op)\n+        hook = wandb_tensorflow.WandbHook(summary_op, history=history)\nwith tf.train.MonitoredTrainingSession(hooks=[hook]) as sess:\nsummary, acc = sess.run([summary_op, c1])\n\nassert wandb_tensorflow.tf_summary_to_dict(summary) == {'c1': 42.0}\n+    print(history.rows)\n+    # TODO(adrian): there is still some kind of bug here where the history\n+    # is being shared with another test that manages to add rows before this one.\nassert history.rows[0]['c1'] == 42.0\n", "fix_pattern": "if wandb_tensorflow.WandbHook() is detected without the 'history' parameter, add it to the API call"}
{"number": 4214, "change": "class LightweightConvolution2D(nn.Module):\n# convolution along frequency axis\nweight_f = F.softmax(self.weight_f, dim=-1)\nweight_f = F.dropout(weight_f, self.dropout_rate, training=self.training)\n-        weight_new = torch.zeros(B * T, 1, self.kernel_size, device=x.device).copy_(weight_f)\n+        weight_new = torch.zeros(B * T, 1, self.kernel_size, device=x.device, dtype=x.dtype).copy_(weight_f)\nxf = F.conv1d(x.view(1, B * T, C), weight_new, padding=self.padding_size, groups=B * T).view(B, T, C)\n\n# lightconv\n", "fix_pattern": "if an API call includes device=x.device, add dtype=x.dtype to the call."}
{"number": 4221, "change": "class ViltEmbeddings(nn.Module):\nx = x.flatten(2).transpose(1, 2)\n# Set `device` here, otherwise `patch_index` will always be on `CPU` and will fail near the end for torch>=1.13\npatch_index = torch.stack(\n-            torch.meshgrid(torch.arange(x_mask.shape[-2]), torch.arange(x_mask.shape[-1]), indexing=\"ij\"), dim=-1\n+            meshgrid(torch.arange(x_mask.shape[-2]), torch.arange(x_mask.shape[-1]), indexing=\"ij\"), dim=-1\n).to(device=x_mask.device)\npatch_index = patch_index[None, None, :, :, :]\npatch_index = patch_index.expand(x_mask.shape[0], x_mask.shape[1], -1, -1, -1)\n", "fix_pattern": "if torch.meshgrid( is detected, replace with meshgrid("}
{"number": 4247, "change": "def test_multinomial(\n):\nprob_dtype, batch_size, population_size, num_samples, replace, probs = everything\n# tensorflow does not support multinomial without replacement\n-    if backend_fw == \"tensorflow\":\n-        assume(replace is True)\n+    if backend_fw == ivy.functional.backends.tensorflow:\n+        assume(replace)\n\ndef call():\nreturn helpers.test_function(\n", "fix_pattern": "if using a backend name as a string, replace it with the corresponding backend object"}
{"number": 4249, "change": "class MonotoneConvexTest(tf.test.TestCase):\ntest_time = tf.constant([1.1, 2.7], dtype=dtype)\ninterpolated, _ = monotone_convex.interpolate(test_time, interval_values,\ninterval_times)\n-    gradient_1y = self.evaluate(tf.gradients(interpolated[0], knot_1y)[0])\n-    gradient_zero = self.evaluate(tf.gradients(interpolated[1], knot_1y)[0])\n+    gradient_1y = self.evaluate(tf.convert_to_tensor(\n+        tf.gradients(interpolated[0], knot_1y)[0]))\n+    gradient_zero = self.evaluate(tf.convert_to_tensor(\n+        tf.gradients(interpolated[1], knot_1y)[0]))\n+\nself.assertAlmostEqual(gradient_1y[0], 0.42)\nself.assertAlmostEqual(gradient_zero[0], 0.0)\n", "fix_pattern": "if tf.gradients() is detected, replace with tf.convert_to_tensor(tf.gradients())"}
{"number": 4258, "change": "def train(args):\nrnn = RNNLM(args.n_vocab, args.layer, args.unit, args.type, args.dropout_rate)\nmodel = ClassifierWithState(rnn)\nif args.ngpu > 0:\n-        model = torch.nn.DataParallel(model).cuda()\n+        model = torch.nn.DataParallel(model, device_ids=list(range(args.ngpu))).cuda()\nsetattr(model, \"reporter\", model.module.reporter)\ngpu_id = 0\nelse:\n", "fix_pattern": "if `torch.nn.DataParallel(model).cuda()` is detected, replace it with `torch.nn.DataParallel(model, device_ids=list(range(args.ngpu))).cuda()`."}
{"number": 4269, "change": "class PositionalEncoding(nn.Module):\npe[:, 0::2] = torch.sin(position * div_term)\npe[:, 1::2] = torch.cos(position * div_term)\npe = pe.unsqueeze(0).transpose(0, 1)\n-        self.register_buffer('pe', pe)\n+        self.pe = nn.Parameter(pe, requires_grad=False)\n\ndef forward(self, x):\nx = x + self.pe[:x.size(0), :]\n", "fix_pattern": "If a buffer is registered using the self.register_buffer() method, it should be replaced with the self.pe = nn.Parameter(pe, requires_grad=False) line."}
{"number": 4276, "change": "class CTC(torch.nn.Module):\n# expected shape of seqLength x batchSize x alphabet_size\ndtype = ys_hat.dtype\nys_hat = ys_hat.transpose(0, 1)\n-        if self.ctc_type == \"warpctc\":\n+        if self.ctc_type == \"warpctc\" or dtype == torch.float16:\n# warpctc only supports float32\nys_hat = ys_hat.to(dtype=torch.float32)\nelse:\n", "fix_pattern": "if a specific condition is detected, add an additional condition to the if statement"}
{"number": 4282, "change": "class ExpectedRiskMinimization(DecoderTrainer[Callable[[StateType], torch.Tensor\nstate.score,\nstate.action_history):\nif self._normalize_by_length:\n-                    path_length = nn_util.new_variable_with_data(model_score,\n-                                                                 torch.Tensor([len(history)]))\n+                    path_length = Variable(model_score.data.new([len(history)]))\nmodel_score = model_score / path_length\nbatch_scores[batch_index].append(model_score)\nreturn batch_scores\n", "fix_pattern": "if using nn_util.new_variable_with_data() is detected, replace with Variable(model_score.data.new())"}
{"number": 4290, "change": "def test_load_no_dev_data_explicit(tasks_base_path):\n\ndef test_multi_corpus(tasks_base_path):\n\n-    corpus_1 = flair.datasets.NER_GERMAN_GERMEVAL(tasks_base_path)\n+    corpus_1 = flair.datasets.ColumnCorpus(tasks_base_path  / \"germeval_14\", column_format={0: \"text\", 2: \"ner\"})\n\ncorpus_2 = flair.datasets.ColumnCorpus(tasks_base_path / \"fashion\", column_format={0: \"text\", 2: \"ner\"})\n# get two corpora as one\n", "fix_pattern": "If using a pre-defined dataset from the `flair.datasets` module, replace the old dataset API call with the new dataset API call."}
{"number": 4301, "change": "def test_forward(use_token_averaged_energy, reduction_factor):\nes, elens = layer(xs, torch.LongTensor([384, 128]))\nassert es.shape[1] == max(elens)\nelse:\n-        ds = torch.LongTensor([[3, 3, 1], [3, 0, 0]])\n+        ds = torch.LongTensor([[3, 3, 1], [3, 0, 0]]) // reduction_factor\ndlens = torch.LongTensor([3, 1])\nes, _ = layer(\nxs, torch.LongTensor([384, 128]), durations=ds, durations_lengths=dlens\n", "fix_pattern": "There is no specific pattern or fix identified in the code change provided. The removed code snippet and the added code snippet are almost identical except for the addition of \"// reduction_factor\" at the end of the line. This does not indicate a specific problem or fix related to an API method."}
{"number": 4310, "change": "class Loggers():\nif self.wandb:\nself.wandb.log({\"Labels\": [wandb.Image(str(x), caption=x.name) for x in paths]})\n\n-    def on_train_batch_end(self, ni, model, imgs, targets, paths, plots):\n+    def on_train_batch_end(self, ni, model, imgs, targets, paths, plots, sync_bn):\n# Callback runs on train batch end\nif plots:\nif ni == 0:\n-                with warnings.catch_warnings():\n-                    warnings.simplefilter('ignore')  # suppress jit trace warning\n-                    self.tb.add_graph(torch.jit.trace(de_parallel(model), imgs[0:1], strict=False), [])\n+                if not sync_bn:  # tb.add_graph() --sync known issue https://github.com/ultralytics/yolov5/issues/3754\n+                    with warnings.catch_warnings():\n+                        warnings.simplefilter('ignore')  # suppress jit trace warning\n+                        self.tb.add_graph(torch.jit.trace(de_parallel(model), imgs[0:1], strict=False), [])\nif ni < 3:\nf = self.save_dir / f'train_batch{ni}.jpg'  # filename\nThread(target=plot_images, args=(imgs, targets, paths, f), daemon=True).start()\n", "fix_pattern": "If the sync_bn parameter is not None, add an if statement to conditionally execute the code block."}
{"number": 4311, "change": "class Model:\nenc = tf.layers.max_pooling1d(enc, 2, 1, padding=\"same\")  # (N, T, K * E / 2)\n\n### Conv1D projections\n-            enc = conv1d(enc, hp.hidden_units // 2, 3, scope=\"conv1d_1\")  # (N, T, E/2)\n-            enc = normalize(enc, type=hp.norm_type, is_training=self.is_training, activation_fn=tf.nn.relu)\n-            enc = conv1d(enc, hp.hidden_units // 2, 3, scope=\"conv1d_2\")  # (N, T, E/2)\n+            enc = conv1d(enc, hp.hidden_units // 2, 3, scope=\"conv1d_1\", activation_fn=tf.nn.relu)  # (N, T, E/2)\n+            enc = normalize(enc, type=hp.norm_type, is_training=self.is_training)\n+            enc = conv1d(enc, hp.hidden_units // 2, 3, scope=\"conv1d_2\", activation_fn=None)  # (N, T, E/2)\nenc += prenet_out  # (N, T, E/2) # residual connections\n\n### Highway Nets\n", "fix_pattern": "If an activation function is specified in the API call, remove it from the API call and instead include it as a separate statement"}
{"number": 4314, "change": "def build_targets(p, targets, model):\ntcls, tbox, indices, av = [], [], [], []\nreject, use_all_anchors = True, True\ngain = torch.ones(6, device=targets.device)  # normalized to gridspace gain\n+\n+    # m = list(model.modules())[-1]\n+    # for i in range(m.nl):\n+    #     anchor_vec = m.anchor_vec[i]\nmulti_gpu = type(model) in (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel)\nfor i, j in enumerate(model.yolo_layers):\n# get number of grid points and anchor vec for this yolo layer\nanchor_vec = model.module.module_list[j].anchor_vec if multi_gpu else model.module_list[j].anchor_vec\n\n# iou of targets-anchors\n-        gain[2:] = torch.tensor(p[i].shape)[[2, 3, 2, 3]]  # xyxy gain\n+        gain[2:] = torch.tensor(p[i].shape)[[3, 2, 3, 2]]  # xyxy gain\nt, a = targets * gain, []\ngwh = t[:, 4:6]\nif nt:\n", "fix_pattern": "The pattern for fixing the API method problem in the given code change is to change the API call from `torch.tensor(p[i].shape)[[2, 3, 2, 3]]` to `torch.tensor(p[i].shape)[[3, 2, 3, 2]]`."}
{"number": 4318, "change": "def linear_resample(x, num_samples, axis=-1):\nnum_x_dims = len(x_shape)\naxis = axis % num_x_dims\nnum_vals = x.shape[axis]\n-    if x.dtype not in ['float16','float32','float64']:\n-        x=tf.cast(x,tf.float32)\n+    if x.dtype not in [\"float16\", \"float32\", \"float64\"]:\n+        x = tf.cast(x, tf.float32)\nxp = tf.range(num_vals, dtype=tf.float32)\nx_coords = tf.range(num_samples, dtype=tf.float32) * (\n-                (num_vals - 1) / (num_samples - 1)\n+            (num_vals - 1) / (num_samples - 1)\n)\nelse:\nxp = tf.range(num_vals, dtype=x.dtype)\n", "fix_pattern": "if a data type check using the `dtype` attribute of a tensor is detected, change the single quotes to double quotes and format the code for better readability"}
{"number": 4340, "change": "def split(data, batch):\nif data.x is not None:\nslices['x'] = node_slice\nelse:\n-        data.num_nodes = torch.bincount(batch).tolist()\n-        slices['num_nodes'] = torch.arange(len(data.num_nodes) + 1)\n+        # Imitate `collate` functionality:\n+        data._num_nodes = torch.bincount(batch).tolist()\n+        data.num_nodes = batch.numel()\nif data.edge_attr is not None:\nslices['edge_attr'] = edge_slice\nif data.y is not None:\n", "fix_pattern": "if a variable named \"data.num_nodes\" is detected, replace it with \"data._num_nodes\". And if a variable named \"slices['num_nodes']\" is detected, replace it with \"data.num_nodes = batch.numel()\"."}
{"number": 4350, "change": "class CTRLModel(CTRLPreTrainedModel):\ninputs_embeds = self.w(input_ids)\n# inputs_embeds = embedded.unsqueeze(0) if len(input_ids.shape)<2 else embedded\nseq_len = input_ids.shape[-1]\n-        mask = torch.triu(torch.ones(seq_len, seq_len), 1).to(inputs_embeds.device)\n+        mask = torch.triu(torch.ones(seq_len + past_length, seq_len + past_length), 1).to(inputs_embeds.device)\n\ninputs_embeds *= np.sqrt(self.d_model_size)\n", "fix_pattern": "if a tensor is created using torch.ones() and then the device is specified using .to(), and the tensor is modified (e.g., by adding or subtracting values), update the tensor creation to match the modified tensor's dimensions and device specification."}
{"number": 4370, "change": "def test_is_small_dataset(\ndataset_size, config_max_in_memory_dataset_size, env_max_in_memory_dataset_size, monkeypatch\n):\nif config_max_in_memory_dataset_size != \"default\":\n-        monkeypatch.setattr(\n-            datasets.config, \"HF_MAX_IN_MEMORY_DATASET_SIZE_IN_BYTES\", config_max_in_memory_dataset_size\n-        )\n+        monkeypatch.setattr(datasets.config, \"IN_MEMORY_MAX_SIZE\", config_max_in_memory_dataset_size)\n\n-    max_in_memory_dataset_size = datasets.config.HF_MAX_IN_MEMORY_DATASET_SIZE_IN_BYTES\n+    max_in_memory_dataset_size = datasets.config.IN_MEMORY_MAX_SIZE\nif config_max_in_memory_dataset_size == \"default\":\nif env_max_in_memory_dataset_size:\nassert max_in_memory_dataset_size == env_max_in_memory_dataset_size\n", "fix_pattern": "There is no pattern for fixing the API method problem in the given code change. The code change simply replaces `HF_MAX_IN_MEMORY_DATASET_SIZE_IN_BYTES` with `IN_MEMORY_MAX_SIZE` without any modifications or adjustments to the API call."}
{"number": 4378, "change": "def _compute_equalized_tiles(interp_tiles: torch.Tensor, luts: torch.Tensor) ->\ntiles_equalized: torch.Tensor = torch.zeros_like(interp_tiles, dtype=torch.long)\n\n# compute the interpolation weights (shapes are 2 x TH x TW because they must be applied to 2 interp tiles)\n-    ih = torch.arange(2 * th - 1, -1, -1, device=interp_tiles.device).div(2. * th - 1)[None].T.expand(2 * th, tw)\n+    ih = torch.arange(2 * th - 1, -1, -1, device=interp_tiles.device).div(\n+        2. * th - 1)[None].transpose(-2, -1).expand(2 * th, tw)\nih = ih.unfold(0, th, th).unfold(1, tw, tw)  # 2 x 1 x TH x TW\niw = torch.arange(2 * tw - 1, -1, -1, device=interp_tiles.device).div(2. * tw - 1).expand(th, 2 * tw)\niw = iw.unfold(0, th, th).unfold(1, tw, tw)  # 1 x 2 x TH x TW\n", "fix_pattern": "If the transpose function is detected after a tensor creation and the transpose is applied on the last two dimensions (-2, -1), replace it with .transpose(-2, -1)"}
{"number": 4381, "change": "class DeepSpeedEngine(Module):\nif self.zero_optimization_partition_weights() and any(\n[hasattr(param,\n'ds_id') for param in self.module.parameters()]):\n-                assert all([param.dtype == torch.half for param in self.module.parameters()]), f\"Model must initialized in fp16 mode for ZeRO Stage 3.\"\n+                assert all([param.dtype == torch.half for param in self.module.parameters()]), \"fp16 is enabled but one or several model parameters have dtype that is not fp16\"\nself.module.half()\nelse:\n-            assert all([param.dtype == torch.float for param in self.module.parameters()]), f\"fp16 is not enabled but one or several model parameters have dtype of fp16\"\n+            assert all([param.dtype == torch.float for param in self.module.parameters()]), \"fp16 is not enabled but one or several model parameters have dtype of fp16\"\n\nif not self.dont_change_device:\nself.module.to(self.device)\n", "fix_pattern": "If the condition for the assert statement is changed, update the error message accordingly."}
{"number": 4397, "change": "class TrainerTrainLoopMixin(ABC):\nif self.reload_dataloaders_every_epoch:\nself.reset_train_dataloader(self.get_model())\n\n+        # track local dataloader so TPU can wrap each epoch\n+        train_dataloader = self.train_dataloader\n+\n# on TPU we have to wrap it under the ParallelLoader\nif self.use_tpu:\ndevice = xm.xla_device()\n-            self.train_dataloader = xla_pl.ParallelLoader(self.train_dataloader, [device])\n-            self.train_dataloader = self.train_dataloader.per_device_loader(device)\n+            train_dataloader = xla_pl.ParallelLoader(train_dataloader, [device])\n+            train_dataloader = train_dataloader.per_device_loader(device)\n\n# run epoch\nfor batch_idx, batch in self.profiler.profile_iterable(\n-            enumerate(self.train_dataloader), \"get_train_batch\"\n+            enumerate(train_dataloader), \"get_train_batch\"\n):\n# stop epoch if we limited the number of training batches\nif batch_idx >= self.num_training_batches:\n", "fix_pattern": "if the API call is assigned to a variable, remove the variable assignment and directly use the API call."}
{"number": 4407, "change": "class LKJCorrCholesky(TorchDistribution):\nsuper().__init__(torch.Size(), torch.Size((d, d)), validate_args=validate_args)\n\ndef sample(self, sample_shape=torch.Size()):\n-        y = self._gen.sample(sample_shape=self.batch_shape + sample_shape).detach()\n+        with torch.no_grad():\n+            y = self._gen.sample(sample_shape=sample_shape + self.batch_shape)\nz = y.mul(2).add(-1.0)\nreturn _vector_to_l_cholesky(z)\n", "fix_pattern": "if a sample_shape is detected before self.batch_shape, modify the code to sample_shape + self.batch_shape instead of self.batch_shape + sample_shape and wrap the code in with torch.no_grad()."}
{"number": 4429, "change": "def fit_circle_in_2d(\nn_provided = points2d.shape[0]\nif n_provided < 3:\nraise ValueError(f\"{n_provided} points are not enough to determine a circle\")\n-    solution = lstsq(design, rhs)\n-    center = solution[:2] / 2\n-    radius = torch.sqrt(solution[2] + (center ** 2).sum())\n+    solution = lstsq(design, rhs[:, None])\n+    center = solution[:2, 0] / 2\n+    radius = torch.sqrt(solution[2, 0] + (center ** 2).sum())\nif n_points > 0:\nif angles is not None:\nwarnings.warn(\"n_points ignored because angles provided\")\n", "fix_pattern": "if indexing is done on the result of an API call, add a trailing comma after the indexing operation"}
{"number": 4450, "change": "def generate_audio_mask_noise(audio_values, audio_mask=None, mask_ratio=0.75, ma\nif mask_type == \"frame-level\":\nnum_time_patches = seq_len // freq_len\nnoise = (\n-            torch.rand(batch_size, num_time_patches).unsqueeze(-1).repeat(1, 1, freq_len).view(batch_size, seq_len)\n+            torch.rand(batch_size, num_time_patches, device=audio_values.device)\n+            .unsqueeze(-1)\n+            .repeat(1, 1, freq_len)\n+            .view(batch_size, seq_len)\n)  # noise in [0, 1]\nelif mask_type == \"patch-level\":\n-        noise = torch.rand(batch_size, seq_len)  # noise in [0, 1]\n+        noise = torch.rand(batch_size, seq_len, device=audio_values.device)  # noise in [0, 1]\nlen_keep = int(seq_len * (1 - mask_ratio))\nreturn noise, len_keep\n", "fix_pattern": "If a tensor is created with torch.rand(), add the device argument to specify the device where the tensor should be located."}
{"number": 4456, "change": "class TFCvtDropPath(tf.keras.layers.Layer):\nreturn x\nkeep_prob = 1 - self.drop_prob\nshape = (tf.shape(x)[0],) + (1,) * (len(tf.shape(x)) - 1)\n-        random_tensor = keep_prob + tf.random.uniform(shape, 0, 1)\n+        random_tensor = keep_prob + tf.random.uniform(shape, 0, 1, dtype=self.compute_dtype)\nrandom_tensor = tf.floor(random_tensor)\nreturn (x / keep_prob) * random_tensor\n", "fix_pattern": "if the dtype parameter is added to a random generator API, set it equal to self.compute_dtype."}
{"number": 4467, "change": "class CLIPSegTextTransformer(nn.Module):\n# take features from the eot embedding (eot_token is the highest number in each sequence)\n# casting to torch.int for onnx compatibility: argmax doesn't support int64 inputs with opset 14\npooled_output = last_hidden_state[\n-            torch.arange(last_hidden_state.shape[0], device=input_ids.device), input_ids.to(torch.int).argmax(dim=-1)\n+            torch.arange(last_hidden_state.shape[0], device=last_hidden_state.device),\n+            input_ids.to(dtype=torch.int, device=last_hidden_state.device).argmax(dim=-1),\n]\n\nif not return_dict:\n", "fix_pattern": "if a tensor is created using the shape of another tensor with .shape[0] and it is assigned to a device, update the device argument to use the device of the tensor it was created from. Also, update the dtype argument with the desired data type."}
{"number": 4476, "change": "def tversky_loss(input: torch.Tensor, target: torch.Tensor,\n# compute the actual dice score\ndims = (1, 2, 3)\nintersection = torch.sum(input_soft * target_one_hot, dims)\n-    fps = torch.sum(input_soft * (1. - target_one_hot), dims)\n-    fns = torch.sum((1. - input_soft) * target_one_hot, dims)\n+    fps = torch.sum(input_soft * (-target_one_hot + 1.), dims)\n+    fns = torch.sum((-input_soft + 1.) * target_one_hot, dims)\n\nnumerator = intersection\ndenominator = intersection + alpha * fps + beta * fns\ntversky_loss = numerator / (denominator + eps)\n-    return torch.mean(1. - tversky_loss)\n+    return torch.mean(-tversky_loss + 1.)\n\n\nclass TverskyLoss(nn.Module):\n", "fix_pattern": "If a formula contains a subtraction operation between two tensors, replace (1. - target_tensor) with (-target_tensor + 1.) or (-input_tensor + 1.) with the corresponding tensor."}
{"number": 4498, "change": "class Trainer(object):\nlast_optim_state = state.get(\"last_optimizer_state\", None)\nif last_optim_state == -1:\nmaster_path = re.sub(\"shard[0-9]+\", \"shard0\", filename)\n-                    last_optim_state = torch.load(master_path, map_location='cpu')['last_optimizer_state']\n+                    local_master_path = PathManager.get_local_path(master_path)\n+                    last_optim_state = torch.load(local_master_path, map_location='cpu')['last_optimizer_state']\n\n# If doing zero_sharding, do not broadcast global optimizer\n# state. Later we will broadcast sharded states to each rank\n", "fix_pattern": "if loading a saved model or optimizer state, use PathManager.get_local_path() to get the local file path before calling torch.load()"}
{"number": 4507, "change": "def finfo(type: Union[DType, str, tf.Tensor, tf.Variable]) -> Finfo:\nif isinstance(type, tf.Tensor):\ntype = type.dtype\nif ivy.as_native_dtype(type) == tf.bfloat16:\n-        return Finfo(tf.experimental.numpy.finfo(tf.float32))\n+        return Finfo(Bfloat16Finfo())\nreturn Finfo(tf.experimental.numpy.finfo(ivy.as_native_dtype(type)))\n", "fix_pattern": "if an API call to a deprecated function is detected (in this case, tf.experimental.numpy.finfo()), replace it with the updated function call (in this case, Bfloat16Finfo())"}
{"number": 4508, "change": "def segment_diff(x,\n\nneeds_fix = tf.scatter_nd(\nfix_indices,\n-        tf.reshape(tf.ones_like(fix_indices, dtype=tf.bool), [-1]),\n+        # Unfortunately, scatter_nd doesn't support bool on GPUs so we need to\n+        # do ints here and then convert to bool.\n+        tf.reshape(tf.ones_like(fix_indices, dtype=tf.int32), [-1]),\nshape=tf.shape(x))\n# If exclusive is False, then needs_fix means we need to replace the values\n# in raw_diffs at those locations with the values in x.\n+    needs_fix = tf.cast(needs_fix, dtype=tf.bool)\nif not exclusive:\nreturn tf.where(needs_fix, x, raw_diffs)\n", "fix_pattern": "if a bool tensor operation is detected with tf.reshape, replace it with a int32 tensor operation with tf.ones_like and then convert it to bool using tf.cast"}
{"number": 4524, "change": "class HardNet(nn.Module):\n# training totally unstable.\nreturn (x - mp.detach()) / (sp.detach() + eps)\n\n-    def forward(self, input: torch.Tensor) -> torch.Tensor:   # type: ignore\n+    def forward(self, input: torch.Tensor) -> torch.Tensor:\nx_norm: torch.Tensor = self._normalize_input(input)\nx_features: torch.Tensor = self.features(x_norm)\nx_out = x_features.view(x_features.size(0), -1)\n", "fix_pattern": "There is no pattern for fixing API method problems in this code change. The code remains unchanged."}
{"number": 4528, "change": "def do_test_log_likelihood(run,\nlayer_key[0])])\nelse:\nexpected_mean_logstd = fc(\n-                        fc(obs_batch,\n-                           vars[\"_hidden_layers.0._model.0.weight\"]),\n-                        vars[\"_logits._model.0.weight\"])\n+                        fc(\n+                            obs_batch,\n+                            np.transpose(\n+                                vars[\"_hidden_layers.0._model.0.weight\"])),\n+                        np.transpose(vars[\"_logits._model.0.weight\"]))\nmean, log_std = np.split(expected_mean_logstd, 2, axis=-1)\nif logp_func is None:\nexpected_logp = np.log(norm.pdf(a, mean, np.exp(log_std)))\n", "fix_pattern": "if torch tensors are of shape [n, m], replace with numpy arrays of shape [m, n]"}
{"number": 4555, "change": "class roibatchLoader(data.Dataset):\n# for ratio cross 1, we make it to be 1.\ntarget_ratio = 1\n\n-        self.ratio_list_batch[left_idx:(right_idx+1)] = target_ratio\n+        self.ratio_list_batch[left_idx:(right_idx+1)] = torch.tensor(target_ratio.astype(np.float64)) # trainset ratio list ,each batch is same number\n\n\ndef __getitem__(self, index):\n", "fix_pattern": "No pattern is identified for this code change."}
{"number": 4561, "change": "class CapsNet(object):\nassert self.masked_v.get_shape() == [cfg.batch_size, 1, 16, 1]\n# Method 2. masking with true label, default mode\nelse:\n-                self.masked_v = tf.matmul(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, 10, 1)), transpose_a=True)\n+                # self.masked_v = tf.matmul(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, 10, 1)), transpose_a=True)\n+                self.masked_v = tf.multply(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, 10, 1)))\nself.v_length = tf.sqrt(tf.reduce_sum(tf.square(self.caps2), axis=2, keep_dims=True) + epsilon)\n\n# 2. Reconstructe the MNIST images with 3 FC layers\n", "fix_pattern": "if a matrix multiplication using tf.matmul() is detected, replace with element-wise multiplication using tf.multiply()"}
{"number": 4563, "change": "def shift_rgb(image: torch.Tensor, r_shift: torch.Tensor, g_shift: torch.Tensor,\n\nshifts = [r_shift, g_shift, b_shift]\n\n-    shifted = (image + torch.Tensor(shifts).view(1, 3, 1, 1).to(image)).clamp_(min=0, max=1)\n+    shifted = (image + torch.stack(shifts).view(-1, 3, 1, 1).to(image)).clamp_(min=0, max=1)\n\nreturn shifted\n", "fix_pattern": "if a tensor is being added to the image and it has a different shape, use torch.stack() to stack the tensors before adding them to the image."}
{"number": 4564, "change": "class TestImageFeatureEmbeddings(AllenNlpTestCase):\nsuper().__init__()\n\nself.image_embeddings = torch.nn.Linear(feature_size, embedding_size)\n-                self.image_location_embeddings = torch.nn.Linear(4, embedding_size)\n+                self.image_location_embeddings = torch.nn.Linear(4, embedding_size, bias=False)\nself.layer_norm = torch.nn.LayerNorm(embedding_size, eps=1e-12)\nself.dropout = torch.nn.Dropout(dropout)\n", "fix_pattern": "If a torch.nn.Linear API call is detected without the bias parameter, add bias=False to the end of the API call."}
{"number": 4585, "change": "class BooleanAccuracy(Metric):\n\n# We want to skip predictions that are completely masked;\n# so we'll keep predictions that aren't.\n-            keep = mask.view(batch_size, -1).max(dim=1)[0].float()\n+            keep = mask.view(batch_size, -1).max(dim=1)[0]\nelse:\n-            keep = torch.ones(batch_size, device=predictions.device).float()\n+            keep = torch.ones(batch_size, device=predictions.device).bool()\n\npredictions = predictions.view(batch_size, -1)\ngold_labels = gold_labels.view(batch_size, -1)\n", "fix_pattern": "If a float tensor is detected (e.g. .float()) in the API call, replace it with a bool tensor (e.g. .bool())."}
{"number": 4646, "change": "class InvertedResidual(BaseModule):\nout = self.linear_conv(out)\n\nif self.with_res_shortcut:\n-                return x + out\n+                return x + self.drop_path(out)\nelse:\nreturn out\n", "fix_pattern": "if a method call is made on a variable, replace it with self.variable"}
{"number": 4655, "change": "torch_scatter = None\ndef dev(x: torch.Tensor, as_native: bool = False) -> Union[ivy.Device, torch.device]:\ndv = x.device\nif as_native:\n-        return torch.device(dv.replace(\"gpu\", \"cuda\"))\n+        return torch.device(dv.type.replace(\"gpu\", \"cuda\"))\nreturn as_ivy_dev(dv)\n", "fix_pattern": "If a torch.device object is detected and its type is \"gpu\", replace it with \"cuda\""}
{"number": 4708, "change": "class Bernoulli(Distribution):\nself.shape = shape\naction_size = util.prod(self.shape)\n\n-        with tf.name_scope(name=scope):\n-            self.logit = Linear(size=action_size, bias=log(probability), scope='logit')\n+        self.logit = Linear(size=action_size, bias=log(probability), scope='logit')\n\nsuper(Bernoulli, self).__init__(scope, summary_labels)\n", "fix_pattern": "if tf.name_scope(name=scope) is detected, remove the name scope line"}
{"number": 4715, "change": "def adalam_core(\nfinal_matches, idxs, counts = torch.unique(final_matches, dim=0, return_inverse=True, return_counts=True)\n_, ind_sorted = torch.sort(idxs)\ncum_sum = counts.cumsum(0)\n-        cum_sum = torch.cat((torch.tensor([0]), cum_sum[:-1]))\n+        cum_sum = torch.cat((torch.tensor([0], dtype=cum_sum.dtype, device=cum_sum.device), cum_sum[:-1]))\nfirst_indicies = ind_sorted[cum_sum]\naccepted_dist = accepted_dist[first_indicies]\nif return_dist:\n", "fix_pattern": "if a tensor is being concatenated with another tensor, and the tensor being concatenated has a specified dtype and device, add dtype and device arguments to the torch.tensor() call for the concatenated tensor."}
{"number": 4743, "change": "def execute_with_gradients(\nreturn grads\n\nif isinstance(y, ivy.NativeArray):\n-        grads = grad_func(torch.clone(y))\n+        grads = _set_duplicates(\n+            grad_func(torch.clone(y)), required_duplicate_index_chains\n+        )\nelse:\n# ToDo: use functorch.jacrev if it fixes the issue with broken memory reference\narray_idxs = ivy.nested_argwhere(y, lambda x: ivy.is_native_array(x))\n", "fix_pattern": "if grad_func is called on a tensor, wrap the call with _set_duplicates() and pass required_duplicate_index_chains as the second argument."}
{"number": 4780, "change": "def _load_weights(model: VisionTransformer, checkpoint_path: str, prefix: str =\nmodel.pos_embed.copy_(pos_embed_w)\nmodel.norm.weight.copy_(_n2p(w[f'{prefix}Transformer/encoder_norm/scale']))\nmodel.norm.bias.copy_(_n2p(w[f'{prefix}Transformer/encoder_norm/bias']))\n-    if model.head.bias.shape[0] == w[f'{prefix}head/bias'].shape[-1]:\n+    if isinstance(model.head, nn.Linear) and model.head.bias.shape[0] == w[f'{prefix}head/bias'].shape[-1]:\nmodel.head.weight.copy_(_n2p(w[f'{prefix}head/kernel']))\nmodel.head.bias.copy_(_n2p(w[f'{prefix}head/bias']))\nfor i, block in enumerate(model.blocks.children()):\n", "fix_pattern": "if there is a check for model.head.bias.shape[0] and it is followed by a shape comparison, add an additional check for isinstance(model.head, nn.Linear)"}
{"number": 4794, "change": "class MeanSquaredLogError(Metric):\npreds: Predictions from model\ntarget: Ground truth values\n\"\"\"\n-        self._check_same_shape(preds, target)\n-        squared_log_error = torch.pow(torch.log1p(preds) - torch.log1p(target), 2)\n+        sum_squared_log_error, n_obs = _mean_squared_log_error_update(preds, target)\n\n-        self.sum_squared_log_error += torch.sum(squared_log_error)\n-        self.total += target.numel()\n+        self.sum_squared_log_error += sum_squared_log_error\n+        self.total += n_obs\n\ndef compute(self):\n\"\"\"\nCompute mean squared logarithmic error over state.\n\"\"\"\n-        return self.sum_squared_log_error / self.total\n+        return _mean_squared_log_error_compute(self.sum_squared_log_error, self.total)\n", "fix_pattern": "if a calculation involves computing the sum of squared log errors and the total number of observations, refactor the code to use helper functions `_mean_squared_log_error_update` and `_mean_squared_log_error_compute`"}
{"number": 4798, "change": "class Wav2VecCtc(BaseFairseqModel):\n\nif net_output[\"padding_mask\"] is not None and net_output[\"padding_mask\"].any():\nnumber_of_classes = logits.size(-1)\n-            masking_tensor = torch.ones(number_of_classes) * float(\"-inf\")\n-            masking_tensor[0] = float(\"inf\")\n+            masking_tensor = torch.ones(\n+                number_of_classes, device=logits.device\n+            ) * float(\"-inf\")\n+            masking_tensor[0] = 0\nlogits[net_output[\"padding_mask\"].T] = masking_tensor.type_as(logits)\n\nif normalize:\n", "fix_pattern": "if a tensor is initialized without specifying the device, add .to(device) at the end of the API call to ensure it is on the correct device."}
{"number": 4830, "change": "class Trainer:\n\"\"\"\nfor k, v in inputs.items():\nif isinstance(v, torch.Tensor):\n-                inputs[k] = v.to(self.args.device)\n+                kwargs = dict(device=self.args.device)\n+                if self.deepspeed and inputs[k].dtype != torch.int64:\n+                    # NLP models inputs are int64 and those get adjusted to the right dtype of the\n+                    # embedding. Other models such as wav2vec2's inputs are already float and thus\n+                    # may need special handling to match the dtypes of the model\n+                    kwargs.update(dict(dtype=self.args.hf_deepspeed_config.dtype()))\n+\n+                inputs[k] = v.to(**kwargs)\n\nif self.args.past_index >= 0 and self._past is not None:\ninputs[\"mems\"] = self._past\n", "fix_pattern": "if inputs[k] is being transformed to a different device using .to() method, create a dictionary kwargs with the device specified and then use it as **kwargs in the .to() method call. If the model uses deepspeed and the input dtype is not torch.int64, add an additional update to the kwargs dictionary to specify the dtype using the dtype() method from the deepspeed config."}
{"number": 4853, "change": "class QLoss:\n# priority is robust and insensitive to `prioritized_replay_alpha`\nself.td_error = tf.nn.softmax_cross_entropy_with_logits(\nlabels=m, logits=q_logits_t_selected)\n-            self.loss = tf.reduce_mean(self.td_error * importance_weights)\n+            self.loss = tf.reduce_mean(\n+                self.td_error * tf.cast(importance_weights, tf.float32))\nself.stats = {\n# TODO: better Q stats for dist dqn\n\"mean_td_error\": tf.reduce_mean(self.td_error),\n", "fix_pattern": "if tf.reduce_mean() is detected, replace tf.cast(importance_weights, tf.float32) with importance_weights"}
{"number": 4861, "change": "try:\nif _torch_available:\nimport torch\n\n-        if torch.__version__ < version.Version(\"1.12\"):\n+        if version.Version(torch.__version__) < version.Version(\"1.12\"):\nraise ValueError(\"PyTorch should be >= 1.12\")\nlogger.debug(f\"Successfully imported xformers version {_xformers_version}\")\nexcept importlib_metadata.PackageNotFoundError:\n", "fix_pattern": "if the torch version comparison is using the \"less than\" (<) operator, replace torch.__version__ with version.Version(torch.__version__)"}
{"number": 4871, "change": "def move_data_to_device(batch: Any, device: Union[str, torch.device]) -> Any:\n\nkwargs = {}\n# Don't issue non-blocking transfers to CPU\n-        if isinstance(data, Tensor) and device not in _CPU_DEVICES:\n+        # Same with MPS due to a race condition bug: https://github.com/pytorch/pytorch/issues/83015\n+        if isinstance(data, Tensor) and isinstance(device, torch.device) and device.type not in _BLOCKING_DEVICE_TYPES:\nkwargs[\"non_blocking\"] = True\ndata_output = data.to(device, **kwargs)\nif data_output is not None:\n", "fix_pattern": "if isinstance(device, torch.device) and device.type not in _BLOCKING_DEVICE_TYPES: is added to handle a race condition bug."}
{"number": 4874, "change": "def select_device(device='', batch_size=0, newline=True):\nif cpu:\nos.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # force torch.cuda.is_available() = False\nelif device:  # non-cpu device requested\n-        nd = torch.cuda.device_count()  # number of CUDA devices\n-        assert torch.cuda.is_available(), 'CUDA is not available, use `--device cpu` or do not pass a --device'\n+        nd = device_count()  # number of CUDA devices\nassert nd > int(max(device.split(','))), f'Invalid `--device {device}` request, valid devices are 0 - {nd - 1}'\n-        os.environ['CUDA_VISIBLE_DEVICES'] = device  # set environment variable (must be after asserts)\n+        os.environ['CUDA_VISIBLE_DEVICES'] = device  # set environment variable - must be before assert is_available()\n+        assert torch.cuda.is_available(), 'CUDA is not available, use `--device cpu` or do not pass a --device'\n\ncuda = not cpu and torch.cuda.is_available()\nif cuda:\n", "fix_pattern": "if the code contains CUDA related calls or settings:\n1. Change `torch.cuda.device_count()` to `device_count()`\n2. Move the line `os.environ['CUDA_VISIBLE_DEVICES'] = device` before the assert statement `assert torch.cuda.is_available()`\n3. Swap the positions of the assert statement and the device availability check message"}
{"number": 4911, "change": "class TfKerasModelArtifact(Artifact):\ndef model_file_path(self, base_path):\nreturn os.path.join(base_path, self.name + self._model_extension)\n\n-    def pack(self, model):\n+    def pack(self, model):  # pylint:disable=arguments-differ\nself.model = model\n\ndef get(self):\nreturn self.model\n\n-    def load(self, base_path):  # pylint:disable=arguments-differ\n-        from tensorflow.keras.models import load_model\n+    def load(self, base_path):\n+        try:\n+            from tensorflow.keras.models import load_model\n+        except ImportError:\n+            raise ImportError(\"tensorflow package is required to use TfKerasModelArtifact\")\nself.model = load_model(self.model_file_path(base_path))\n\ndef save(self, base_path):\n", "fix_pattern": "if an import for a package is detected within a method, add a try-except block to catch ImportError and raise an appropriate error message"}
{"number": 4952, "change": "class TFMarianSinusoidalPositionalEmbedding(tf.keras.layers.Layer):\nposition_enc = np.array(\n[[pos / np.power(10000, 2 * (j // 2) / dim) for j in range(dim)] for pos in range(n_pos)]\n)\n+        table = np.zeros_like(position_enc)\n# index 0 is all zero\n-        position_enc[:, 0 : dim // 2] = np.sin(position_enc[:, 0::2])\n-        position_enc[:, dim // 2 :] = np.cos(position_enc[:, 1::2])\n+        table[:, 0 : dim // 2] = np.sin(position_enc[:, 0::2])\n+        table[:, dim // 2 :] = np.cos(position_enc[:, 1::2])\n# convert to tensor\n-        table = tf.convert_to_tensor(position_enc)\n+        table = tf.convert_to_tensor(table)\ntf.stop_gradient(table)\nreturn table\n", "fix_pattern": "if a numpy array is detected, create a zero-filled numpy array of the same shape and copy the values from the original array, then convert the array to a tensor using tf.convert_to_tensor()."}
{"number": 5002, "change": "def get_outputs_sizes_torch(\n\n\ndef create_model_inputs_torch(\n-    batch_size: int, input_infos: List[InputInfo]\n+    input_infos: List[InputInfo],\n) -> List[torch.Tensor]:\ninput_tensors = (\n-        torch.randn((batch_size, *input_info.size))\n+        torch.randn(*input_info.size)\nif input_info.dtype is DataType.FLOAT32\nelse torch.randint(\n-            size=(batch_size, *input_info.size),\n+            size=input_info.size,\nlow=input_info.min_value or 0,\nhigh=input_info.max_value or 100,\n)\n", "fix_pattern": "if the input size is specified as a tuple with batch size, remove the batch size from the shape and remove the comma after input_info.size"}
{"number": 5036, "change": "def infer_inputs_from_restored_call_function(fn):\nif isinstance(x, tf.SparseTensorSpec):\nreturn tf.SparseTensorSpec(common_shape, x.dtype)\nelif isinstance(x, tf.RaggedTensorSpec):\n-      return tf.RaggedTensorSpec(common_shape, x.dtype)\n+      return tf.RaggedTensorSpec(\n+          common_shape,\n+          x.dtype,\n+          ragged_rank=x.ragged_rank,\n+          row_splits_dtype=x.row_splits_dtype,\n+          flat_values_spec=x.flat_values_spec)\nreturn tf.TensorSpec(common_shape, x.dtype, x.name)\n\nspec = fn.concrete_functions[0].structured_input_signature\n", "fix_pattern": "if returning tf.RaggedTensorSpec() without additional arguments detected, add additional arguments ragged_rank=x.ragged_rank, row_splits_dtype=x.row_splits_dtype, flat_values_spec=x.flat_values_spec to the API call."}
{"number": 5052, "change": "def _torch_solve_cast(input: torch.Tensor, A: torch.Tensor) -> Tuple[torch.Tenso\nif dtype not in (torch.float32, torch.float64):\ndtype = torch.float32\n\n-    out = solve(A.to(dtype), input.to(dtype))\n+    out = torch.linalg.solve(A.to(dtype), input.to(dtype))\n\nreturn (out.to(input.dtype), out)\n", "fix_pattern": "if the function solve() from the torch.linalg module is used, replace it with torch.linalg.solve()"}
{"number": 5072, "change": "def test_dynamic_quantization(train_dic, recog_dic, quantize_dic):\ntrain_args = get_default_train_args(**train_dic)\nrecog_args = get_default_recog_args(**recog_dic)\n\n+    if not is_torch_1_5_plus:\n+        q_dtype = torch.qint8\n+    else:\n+        q_dtype = quantize_dic[\"mod\"]\n+\nmodel = E2E(idim, odim, train_args)\nmodel = torch.quantization.quantize_dynamic(\n-        model, quantize_dic[\"mod\"], dtype=quantize_dic[\"dtype\"]\n+        model, q_dtype, dtype=quantize_dic[\"dtype\"]\n)\n\nbeam_search = BeamSearchTransducer(\n", "fix_pattern": "if an API call is made to specify the dtype of a model or tensor, replace the previous syntax with the new syntax:\n- replace \"quantize_dic[\"mod\"]\" with \"q_dtype\"\n- replace \"quantize_dic[\"dtype\"]\" with \"dtype\""}
{"number": 5080, "change": "class GNNExplainer(torch.nn.Module):\nif node_idx == -1:\nhard_edge_mask = torch.BoolTensor([True] * edge_index.size(1),\ndevice=edge_mask.device)\n-            subset = torch.arange(\n-                edge_index.max() + 1,\n-                device=edge_index.device if y is None else y.device)\n+            subset = torch.arange(edge_index.max().item() + 1,\n+                                  device=edge_index.device)\n+            y = None\n+\nelse:\n# Only operate on a k-hop subgraph around `node_idx`.\nsubset, edge_index, _, hard_edge_mask = k_hop_subgraph(\n", "fix_pattern": "if device argument is being used based on whether variable `y` is None or not, refactor the code to assign `y` to None before creating the `subset` tensor"}
{"number": 5102, "change": "class FSMTHeadTests(unittest.TestCase):\nconfig, *_ = self._get_config_and_data()\ninput_ids = _long_tensor(([4, 4, 2]))\ndecoder_input_ids = _long_tensor([[26388, 2, config.pad_token_id]])\n-        ignore = float(\"-inf\")\n+        causal_mask_dtype = torch.float32\n+        ignore = torch.finfo(causal_mask_dtype).min\ndecoder_input_ids, decoder_attn_mask, causal_mask = _prepare_fsmt_decoder_inputs(\n-            config, input_ids, decoder_input_ids\n+            config, input_ids, decoder_input_ids, causal_mask_dtype=causal_mask_dtype\n)\nexpected_causal_mask = torch.tensor(\n[[0, ignore, ignore], [0, 0, ignore], [0, 0, 0]]  # never attend to the final token, because its pad\n", "fix_pattern": "if a float value is assigned to a variable using float(\"-inf\"), replace it with torch.finfo(<dtype>).min, and pass the dtype as an argument to the function call"}
{"number": 5106, "change": "def main():\nif args.do_train:\ntorch.save(model_to_save.state_dict(), output_model_file)\n\n-    # Load a trained model that you have fine-tuned\n-    model_state_dict = torch.load(output_model_file)\n-    model = BertForQuestionAnswering.from_pretrained(args.bert_model, state_dict=model_state_dict)\n+        # Load a trained model that you have fine-tuned\n+        model_state_dict = torch.load(output_model_file)\n+        model = BertForQuestionAnswering.from_pretrained(args.bert_model, state_dict=model_state_dict)\n+    else:\n+        model = BertForQuestionAnswering.from_pretrained(args.bert_model)\n+\nmodel.to(device)\n\nif args.do_predict and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n", "fix_pattern": "if a pretrained model is loaded without checking for a specific condition, add an else statement to handle the case where the condition is not met."}
{"number": 5124, "change": "class TFT5ModelIntegrationTests(unittest.TestCase):\nlabels = tokenizer(\"Hi I am\", return_tensors=\"tf\").input_ids\n\nloss = model(input_ids, labels=labels).loss\n-        mtf_score = -tf.math.reduce_sum(loss).numpy()\n+        mtf_score = -tf.math.reduce_mean(loss).numpy()\n\n-        EXPECTED_SCORE = -60.7397\n+        EXPECTED_SCORE = -7.594554\nself.assertTrue(abs(mtf_score - EXPECTED_SCORE) < 1e-4)\n\n@slow\n", "fix_pattern": "if tf.math.reduce_sum() is detected, replace it with tf.math.reduce_mean()"}
{"number": 5177, "change": "class CLIPModelTester:\n\ndef create_and_check_model(self, config, input_ids, attention_mask, pixel_values):\nmodel = CLIPModel(config).to(torch_device).eval()\n-        result = model(input_ids, pixel_values, attention_mask)\n+        with torch.no_grad():\n+            result = model(input_ids, pixel_values, attention_mask)\nself.parent.assertEqual(\nresult.logits_per_image.shape, (self.vision_model_tester.batch_size, self.text_model_tester.batch_size)\n)\n", "fix_pattern": "if a model inference is called without torch.no_grad(), add torch.no_grad() context manager before the model inference call"}
{"number": 5178, "change": "def inverse_pose(pose):\n\npose_inv = pose.clone()\npose_inv[..., :3, 0:3] = torch.transpose(pose[..., :3, :3], 1, 2)\n-    pose_inv[..., :3, 2:3] = torch.matmul(\n-        -1.0 * pose_inv[..., :3, :3], pose[..., :3, 2:3])\n+    pose_inv[..., :3, 3:4] = torch.matmul(\n+        -1.0 * pose_inv[..., :3, :3], pose[..., :3, 3:4])\n\nif len(pose_shape) == 2:\npose_inv = torch.squeeze(pose_inv, dim=0)\n", "fix_pattern": "if a matrix multiplication is detected with negative sign applied,\nchange the index of the matrix to multiply with from 2:3 to 3:4"}
{"number": 5191, "change": "class Input(Layer):\nlogging.info(\"Input  %s: %s\" % (self.name, str(shape)))\n\nshape_without_none = [_ if _ is not None else 1 for _ in shape]\n-        self.outputs = self.forward(tf.initializers.constant(value=0.0)(shape_without_none), is_train=False)\n+        self.outputs = self.forward(tf.initializers.random_normal()(shape_without_none), is_train=False)\n\ndef __call__(self, prev_layer):\n# FIXME: better exception raising\n", "fix_pattern": "if tf.initializers.constant is detected, replace with tf.initializers.random_normal."}
{"number": 5194, "change": "class CascadeRoIHead(BaseRoIHead, BBoxTestMixin, MaskTestMixin):\nms_scores.append(bbox_results['cls_score'])\n\nif i < self.num_stages - 1:\n-                    bbox_label = bbox_results['cls_score'].argmax(dim=1)\n+                    bbox_label = bbox_results['cls_score'][:, :-1].argmax(\n+                        dim=1)\nrois = self.bbox_head[i].regress_by_class(\nrois, bbox_label, bbox_results['bbox_pred'],\nimg_meta[0])\n", "fix_pattern": "if an API method call with dim=1 is detected, modify it to [:, :-1] for excluding the last dimension."}
{"number": 5198, "change": "def test_model_saving_loading():\n# make prediction\n# assert that both predictions are the same\nnew_pred = model_2(x)\n-    assert torch.eq(pred_before_saving, new_pred)\n+    assert torch.all(torch.eq(pred_before_saving, new_pred)).item() == 1\n\nclear_save_dir()\n", "fix_pattern": "if assert statement with torch.eq() is detected, replace with assert statement with torch.all(torch.eq()).item() == 1"}
{"number": 5219, "change": "class TorchCustomLossModel(TorchModelV2, nn.Module):\n\n# Compute the IL loss.\naction_dist = TorchCategorical(logits, self.model_config)\n-        imitation_loss = torch.mean(\n-            -action_dist.logp(torch.from_numpy(batch[\"actions\"])))\n+        imitation_loss = torch.mean(-action_dist.logp(\n+            torch.from_numpy(batch[\"actions\"]).to(policy_loss[0].device)))\nself.imitation_loss_metric = imitation_loss.item()\nself.policy_loss_metric = np.mean([l.item() for l in policy_loss])\n", "fix_pattern": "if a tensor is detected without the .to(device) method, add .to(device) to the end of the API call"}
{"number": 5242, "change": "class TFXLNetMainLayer(tf.keras.layers.Layer):\nassert input_mask is None or attention_mask is None, \"You can only use one of input_mask (uses 1 for padding) \" \\\n\"or attention_mask (uses 0 for padding, added for compatbility with BERT). Please choose one.\"\nif input_mask is None and attention_mask is not None:\n-            input_mask = 1.0 - attention_mask\n+            input_mask = 1.0 - tf.cast(attention_mask, dtype=dtype_float)\nif input_mask is not None and perm_mask is not None:\ndata_mask = input_mask[None] + perm_mask\nelif input_mask is not None and perm_mask is None:\n", "fix_pattern": "if a tensor conversion is detected using tf.cast(), replace with dtype=torch.float"}
{"number": 5247, "change": "from tqdm import tqdm\n\n\ndef download_wmt_dataset(src_lang=\"ro\", tgt_lang=\"en\", dataset=\"wmt16\", save_dir=None) -> None:\n-    \"\"\"Download a dataset using the nlp package and save it to the format expected by finetune.py\n+    \"\"\"Download a dataset using the datasets package and save it to the format expected by finetune.py\nFormat of save_dir: train.source, train.target, val.source, val.target, test.source, test.target.\n\nArgs:\nsrc_lang: <str> source language\ntgt_lang: <str> target language\n-        dataset: <str> wmt16, wmt17, etc. wmt16 is a good start as it's small. To get the full list run `import nlp; print([d.id for d in nlp.list_datasets() if \"wmt\" in d.id])`\n+        dataset: <str> wmt16, wmt17, etc. wmt16 is a good start as it's small. To get the full list run `import datasets; print([d.id for d in datasets.list_datasets() if \"wmt\" in d.id])`\nsave_dir: <str>, where to save the datasets, defaults to f'{dataset}-{src_lang}-{tgt_lang}'\n\nUsage:\n>>> download_wmt_dataset('ro', 'en', dataset='wmt16') # saves to wmt16-ro-en\n\"\"\"\ntry:\n-        import nlp\n+        import datasets\nexcept (ModuleNotFoundError, ImportError):\n-        raise ImportError(\"run pip install nlp\")\n+        raise ImportError(\"run pip install datasets\")\npair = f\"{src_lang}-{tgt_lang}\"\nprint(f\"Converting {dataset}-{pair}\")\n-    ds = nlp.load_dataset(dataset, pair)\n+    ds = datasets.load_dataset(dataset, pair)\nif save_dir is None:\nsave_dir = f\"{dataset}-{pair}\"\nsave_dir = Path(save_dir)\n", "fix_pattern": "If the API module nlp is detected, replace it with datasets."}
{"number": 5277, "change": "class FaceAlignment:\nout += flip(self.face_alignment_net(flip(inp)).detach(), is_label=True)\nout = out.cpu().numpy()\n\n-            pts, pts_img = get_preds_fromhm(out, center, scale)\n-            pts, pts_img = pts.view(68, 2) * 4, pts_img.view(68, 2)\n+            pts, pts_img = get_preds_fromhm(out, center.numpy(), scale)\npts, pts_img = torch.from_numpy(pts), torch.from_numpy(pts_img)\n+            pts, pts_img = pts.view(68, 2) * 4, pts_img.view(68, 2)\n\nif self.landmarks_type == LandmarksType._3D:\nheatmaps = np.zeros((68, 256, 256), dtype=np.float32)\n", "fix_pattern": "if a tensor is converted to a numpy array using .numpy(), change the argument passed into the function to the numpy array."}
{"number": 5310, "change": "class CTCPrefixScorer(PartialScorerInterface):\ndef score_partial(self, y, ids, state, x):\nprev_score, state = state\npresub_score, new_st = self.impl(y.cpu(), ids.cpu(), state)\n-        tscore = torch.as_tensor(presub_score - prev_score, device=y.device)\n+        tscore = torch.as_tensor(presub_score - prev_score, device=x.device, dtype=x.dtype)\nreturn tscore, (presub_score, new_st)\n", "fix_pattern": "If a tensor is detected with a different device or dtype, add the corresponding device or dtype argument to the torch.as_tensor() call."}
{"number": 5314, "change": "class Model(torch.nn.Module, Registrable):\nadd_batch_dimension=True,\ncuda_device=cuda_device,\nfor_training=False)\n-        outputs = self.forward(**model_input)\n+        outputs = self.decode(self.forward(**model_input))\n\nfor name, output in list(outputs.items()):\noutput = output[0]\n", "fix_pattern": "if the model_output is used directly, surround the forward method call with a decode() method call."}
{"number": 5322, "change": "def inplace_update(\nelif ivy.is_ivy_array(x):\nx.data = val_native\nelse:\n-            raise ivy.exceptions.IvyException(\n-                \"TensorFlow does not support inplace updates of the tf.Tensor\"\n-            )\n+            x = ivy.to_ivy(x_native)\nreturn x\nelse:\nreturn val\n", "fix_pattern": "if an exception is raised when trying to update a TensorFlow tensor inplace, use ivy.to_ivy() to convert the tensor to a compatible format."}
{"number": 5337, "change": "class RelationExtractor(flair.nn.DefaultClassifier):\n\nrelation_embeddings.append(embedding)\n\n-            # stack and drop out\n-            all_relations = torch.stack(relation_embeddings)\n+            # stack and drop out (squeeze and unsqueeze)\n+            all_relations = torch.stack(relation_embeddings).unsqueeze(1)\n\nall_relations = self.dropout(all_relations)\nall_relations = self.locked_dropout(all_relations)\nall_relations = self.word_dropout(all_relations)\n\n+            all_relations = all_relations.squeeze(1)\n+\n# send through decoder\nif self.non_linear_decoder:\nsentence_relation_scores = self.decoder_2(self.nonlinearity(self.decoder_1(all_relations)))\n", "fix_pattern": "if torch.stack() is detected, add .unsqueeze(1) before the closing parenthesis and add .squeeze(1) after the API call."}
{"number": 5340, "change": "class HullWhiteBermudanSwaptionTest(parameterized.TestCase, tf.test.TestCase):\nself.float_leg_end_times) - np.array(self.float_leg_start_times)\nself.fixed_leg_daycount_fractions = self.float_leg_daycount_fractions\nself.fixed_leg_coupon = 0.011 * np.ones_like(self.fixed_leg_payment_times)\n-    self.zero_rate_fn = lambda x: 0.01 * tf.ones_like(x)\n+    zero_rate_fn = lambda x: 0.01 * tf.expand_dims(tf.ones_like(x), axis=-1)\n+    self.zero_rate_fn = zero_rate_fn\n\nsuper(HullWhiteBermudanSwaptionTest, self).setUp()\n", "fix_pattern": "If the zero_rate_fn lambda function is detected in the code, replace it with a new lambda function that includes tf.expand_dims and assign it to a variable. Then assign the variable to self.zero_rate_fn."}
{"number": 5347, "change": "class TestSparseClipGrad(AllenNlpTestCase):\n# Now try to clip the gradients.\n_ = sparse_clip_norm([embedding.weight], 1.5)\n# Final norm should be 1.5\n-        grad = embedding.weight.grad.data.coalesce()\n-        self.assertAlmostEqual(grad._values().norm(2.0), 1.5, places=5) # pylint: disable=protected-access\n+        grad = embedding.weight.grad.coalesce()  # pylint: disable=no-member\n+        self.assertAlmostEqual(grad._values().norm(2.0).item(), 1.5, places=5) # pylint: disable=protected-access\n", "fix_pattern": "if a .data attribute is detected after a tensor, remove it \nif a .item() method is detected after a tensor operation, add .item() to the end of the API call"}
{"number": 5370, "change": "class CategoricalOneHotPolicy(StochasticPolicy):\n\ndef __init__(self, network, session, state, random, action_count=1, scope='policy'):\nwith tf.variable_scope(scope):\n-            action_layer = linear(layer_input=network.output, config={'num_outputs': action_count}, scope='outputs')\n-\n-            distribution = tf.nn.softmax(action_layer)\n-            sample = tf.map_fn(lambda t: tf.multinomial(logits=t, num_samples=1), elems=distribution, dtype=tf.int64)\n+            logits = linear(layer_input=network.output, config={'num_outputs': action_count}, scope='outputs')\n+            distribution = tf.nn.softmax(logits)\n+            sample = tf.map_fn(lambda t: tf.multinomial(logits=t, num_samples=1), elems=logits, dtype=tf.int64)\n\nsuper(CategoricalOneHotPolicy, self).__init__(network, [distribution, sample], session, state, random, action_count)\nself.dist = Categorical(random)\n", "fix_pattern": "if a variable name (e.g., action_layer) is detected in an API method, change the variable name to logits and update the API method accordingly."}
{"number": 5398, "change": "def main(args):\n\n# Get input and output tensors\nimages_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n+            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\nembeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\ntpr, fpr, accuracy, val, val_std, far = lfw.validate(sess, paths,\nactual_issame, args.seed, 60,\n-                images_placeholder, embeddings, nrof_folds=args.lfw_nrof_folds)\n+                images_placeholder, phase_train_placeholder, embeddings, nrof_folds=args.lfw_nrof_folds)\nprint('Accuracy: %1.3f+-%1.3f' % (np.mean(accuracy), np.std(accuracy)))\nprint('Validation rate: %2.5f+-%2.5f @ FAR=%2.5f' % (val, val_std, far))\n", "fix_pattern": "If the placeholder for training phase is present, add it as an argument to the API call."}
{"number": 5438, "change": "def train_cifar():\noptimizer = optim.Adam(get_parameters(model), lr=3e-4)\nelse:\n#optimizer = optim.SGD(get_parameters(model), lr=0.001)\n-    optimizer = optim.SGD(get_parameters(model), lr=0.003, momentum=0.85, nesterov=True)\n+    optimizer = optim.SGD(get_parameters(model), lr=Tensor([0.003]).realize(), momentum=0.85, nesterov=True)\n\n# 97 steps in 2 seconds = 20ms / step\n# step is 1163.42 GOPS = 56 TFLOPS!!!, 41% of max 136\n", "fix_pattern": "If a constant tensor is being passed as a parameter to an optimizer (e.g., lr=0.003), wrap it with Tensor() or torch.tensor() to create a tensor object."}
{"number": 5451, "change": "class NCSNpp(ModelMixin, ConfigMixin):\nfor i_level in reversed(range(self.num_resolutions)):\nfor i_block in range(num_res_blocks + 1):\nout_ch = nf * ch_mult[i_level]\n+                in_ch = in_ch + hs_c.pop()\nmodules.append(\nResnetBlock(\n-                        in_channels=in_ch + hs_c.pop(),\n+                        in_channels=in_ch,\nout_channels=out_ch,\ntemb_channels=4 * nf,\noutput_scale_factor=np.sqrt(2.0),\n", "fix_pattern": "if an API call with multiple keyword arguments is detected, remove the keyword argument that is causing the problem and replace it with the corrected value"}
{"number": 5476, "change": "def ga_loc_target(gt_bboxes_list,\nall_ignore_map.append(ignore_map)\nfor img_id in range(img_per_gpu):\ngt_bboxes = gt_bboxes_list[img_id]\n-        scale = torch.sqrt((gt_bboxes[:, 2] - gt_bboxes[:, 0] + 1) *\n-                           (gt_bboxes[:, 3] - gt_bboxes[:, 1] + 1))\n+        scale = torch.sqrt((gt_bboxes[:, 2] - gt_bboxes[:, 0]) *\n+                           (gt_bboxes[:, 3] - gt_bboxes[:, 1]))\nmin_anchor_size = scale.new_full(\n(1, ), float(anchor_scale * anchor_strides[0]))\n# assign gt bboxes to different feature levels w.r.t. their scales\n", "fix_pattern": "if the calculation of the scale factor includes +1 in the width and height expressions, remove the +1 from the calculation."}
{"number": 5478, "change": "def create_model(to_device=True, dim_in=None, dim_out=None):\nif 'classification' in cfg.dataset.task_type and dim_out == 2:\ndim_out = 1\n\n-    model = network_dict[cfg.model.type](dim_in=dim_in, dim_out=dim_out)\n+    model = GraphGymModule(dim_in, dim_out, cfg)\nif to_device:\nmodel.to(torch.device(cfg.device))\nreturn model\n", "fix_pattern": "If a model initialization is detected with the format network_dict[cfg.model.type](dim_in=dim_in, dim_out=dim_out), replace it with GraphGymModule(dim_in, dim_out, cfg) initialization."}
{"number": 5523, "change": "class MapGradient(GradientProcessor):\nfor grad, var in grads:\nif re.match(self.regex, var.op.name):\nmatched = True\n-                with tf.device(grad.device):\n-                    grad = self.func(grad, var)\n+                grad = self.func(grad, var)\nif grad is not None:\nret.append((grad, var))\nelse:\n", "fix_pattern": "Remove the line \"with tf.device(grad.device):\""}
{"number": 5532, "change": "def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int = 256, clip: float = 4\nhistos: torch.Tensor = torch.empty((tiles.shape[0], num_bins), device=tiles.device)\nif not diff:\nfor i in range(tiles.shape[0]):\n-            histos[i] = torch.histc(tiles[i], bins=num_bins, min=0, max=1)\n+            histos[i] = _torch_histc_cast(tiles[i], bins=num_bins, min=0, max=1)\nelse:\nbins: torch.Tensor = torch.linspace(0, 1, num_bins, device=tiles.device)\nhistos = histogram(tiles, bins, torch.tensor(0.001)).squeeze()\n", "fix_pattern": "if torch.histc is replaced with a custom function _torch_histc_cast"}
{"number": 5535, "change": "class DetrEncoderLayer(nn.Module):\nhidden_states = residual + hidden_states\nhidden_states = self.final_layer_norm(hidden_states)\n\n-        if torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any():\n-            clamp_value = torch.finfo(hidden_states.dtype).max - 1000\n-            hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)\n+        if self.training:\n+            if torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any():\n+                clamp_value = torch.finfo(hidden_states.dtype).max - 1000\n+                hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)\n\noutputs = (hidden_states,)\n", "fix_pattern": "To fix the API method problem in the given code change, the pattern is to add a condition to check if the code is running in training mode before executing the API method. The condition can be implemented using an \"if\" statement with \"self.training\" as the condition."}
{"number": 5542, "change": "class StableDiffusionModelHijack:\nif len(emb.shape) == 1:\nemb = emb.unsqueeze(0)\n\n-            self.word_embeddings[name] = emb.detach()\n+            self.word_embeddings[name] = emb.detach().to(device)\nself.word_embeddings_checksums[name] = f'{const_hash(emb.reshape(-1)*100)&0xffff:04x}'\n\nids = tokenizer([name], add_special_tokens=False)['input_ids'][0]\n", "fix_pattern": "if an object is detached using .detach(), add .to(device) to the end of the API call"}
{"number": 5579, "change": "class AdalamFilter:\n\"Please either provide orientations or set 'orientation_difference_threshold' to None to disable orientations filtering\"  # noqa: E501\n)\nk1, k2, d1, d2, o1, o2, s1, s2 = self.__to_torch(k1, k2, d1, d2, o1, o2, s1, s2)\n+        if len(d2) <= 1:\n+            return _no_match(d1)\ndistmat = dist_matrix(d1, d2, is_normalized=False)\ndd12, nn12 = torch.topk(distmat, k=2, dim=1, largest=False)  # (n1, 2)\n", "fix_pattern": "if a condition checking the length of a list or collection is detected, and the code inside the condition returns a specific value, add a return statement with the specific value outside of the condition"}
{"number": 5598, "change": "class Model:\nreturn ppgs, preds_ppg, logits_ppg, pred_spec, pred_mel\n\ndef loss_net2(self):\n-        loss_spec = tf.reduce_mean(tf.abs(self.pred_spec - self.y_spec))\n-        loss_mel = tf.reduce_mean(tf.abs(self.pred_mel - self.y_mel))\n+        loss_spec = tf.reduce_mean(tf.squared_difference(self.pred_spec, self.y_spec))\n+        loss_mel = tf.reduce_mean(tf.squared_difference(self.pred_mel, self.y_mel))\nloss = loss_spec + loss_mel\nreturn loss\n", "fix_pattern": "if tf.reduce_mean(tf.abs( is detected, replace with tf.reduce_mean(tf.squared_difference("}
{"number": 5618, "change": "class Trainer(object):\n\ndef is_consistent(tensor):\nmax_abs_diff = torch.max(torch.abs(tensor - tensor[0]))\n-                return (max_abs_diff / (tensor[0] + 1e-6) < 1e-6).all()\n+                return (\n+                    not torch.isfinite(tensor).any()\n+                    or (max_abs_diff / (tensor[0] + 1e-6) < 1e-6).all()\n+                )\n\nif not is_consistent(self._grad_norm_buf):\npretty_detail = \"\\n\".join(\n", "fix_pattern": "if a condition using torch.isfinite() is detected, add another condition using the logical operator \"or\" before it."}
{"number": 5637, "change": "def normalize_homography3d(dst_pix_trans_src_pix: torch.Tensor,\n# compute the transformation pixel/norm for src/dst\nsrc_norm_trans_src_pix: torch.Tensor = normal_transform_pixel3d(\nsrc_d, src_h, src_w).to(dst_pix_trans_src_pix)\n-    src_pix_trans_src_norm = torch.inverse(src_norm_trans_src_pix)\n+\n+    src_pix_trans_src_norm = _torch_inverse_cast(src_norm_trans_src_pix)\ndst_norm_trans_dst_pix: torch.Tensor = normal_transform_pixel3d(\ndst_d, dst_h, dst_w).to(dst_pix_trans_src_pix)\n# compute chain transformations\n", "fix_pattern": "if an API method torch.inverse() is detected, replace with _torch_inverse_cast()"}
{"number": 5655, "change": "def harmonic_mean(a, weights=None):\nreturn sum(weights) / sum(w/x for x, w in zip(a, weights))\n\n# torch utils\n-def get_optimizer(name, parameters, lr, betas=(0.9, 0.999)):\n+def get_optimizer(name, parameters, lr, betas=(0.9, 0.999), eps=1e-8):\nif name == 'sgd':\nreturn torch.optim.SGD(parameters, lr=lr)\nelif name == 'adagrad':\nreturn torch.optim.Adagrad(parameters, lr=lr)\nelif name == 'adam':\n-        return torch.optim.Adam(parameters, lr=lr, betas=betas) # use default lr\n+        return torch.optim.Adam(parameters, lr=lr, betas=betas, eps=eps)\nelif name == 'adamax':\nreturn torch.optim.Adamax(parameters) # use default lr\nelse:\n", "fix_pattern": "If an epsilon (eps) parameter is detected missing, add the eps parameter with a default value of 1e-8."}
{"number": 5662, "change": "class FlatVarHelper(object):\nself.session = session\nshapes = map(get_shape, variables)\ntotal_size = sum(np.prod(shape) for shape in shapes)\n-        self.theta = theta = tf.placeholder(tf.float32, [total_size])\n+        self.theta = tf.placeholder(tf.float32, [total_size])\nstart = 0\nassigns = []\n\nfor (shape, variable) in zip(shapes, variables):\nsize = np.prod(shape)\n-            assigns.append(tf.assign(variable, tf.reshape(theta[start:start + size], shape)))\n+            assigns.append(tf.assign(variable, tf.reshape(self.theta[start:start + size], shape)))\nstart += size\n\nself.set_op = tf.group(*assigns)\n", "fix_pattern": "if the name of the variable placeholder was changed, update the reference in the tf.assign() function to the new variable name"}
{"number": 5664, "change": "def matmul(\ndtype_from = tf.as_dtype(x1.dtype)\n\nif transpose_a:\n-        x1 = tf.transpose(x1)\n+        x1 = tf.linalg.matrix_transpose(x1)\nif transpose_b:\n-        x2 = tf.transpose(x2)\n+        x2 = tf.linalg.matrix_transpose(x2)\n\nif adjoint_a:\nx1 = tf.linalg.adjoint(x1)\n", "fix_pattern": "If tf.transpose() is detected, replace it with tf.linalg.matrix_transpose()."}
{"number": 5669, "change": "class LongformerOnnxConfig(OnnxConfig):\n)\nimport torch\n\n+        # for some reason, replacing this code by inputs[\"global_attention_mask\"] = torch.randint(2, inputs[\"input_ids\"].shape, dtype=torch.int64)\n+        # makes the export fail randomly\ninputs[\"global_attention_mask\"] = torch.zeros_like(inputs[\"input_ids\"])\n# make every second token global\ninputs[\"global_attention_mask\"][:, ::2] = 1\n+\nreturn inputs\n", "fix_pattern": "There is no identifiable pattern in this code change. It seems to be a specific issue related to the export process. There is no specific pattern mentioned in the code itself to fix the problem. Further investigation or context is needed to determine the cause of the export failure."}
{"number": 5680, "change": "def test_ellipsis_simplify():\ndef test_pointer_tensor_simplify():\n\"\"\"Test the simplification of PointerTensor\"\"\"\n\n-    alice = syft.VirtualWorker(id=\"alice\")\n+    alice = syft.VirtualWorker(syft.torch.hook, id=\"alice\")\ninput_tensor = PointerTensor(id=1000, location=alice, owner=alice)\n\noutput = _simplify(input_tensor)\n", "fix_pattern": "If syft.torch.hook is not imported, add syft.torch.hook as the first argument to the syft.VirtualWorker() call."}
{"number": 5702, "change": "class TFFlaubertMainLayer(TFXLMMainLayer):\nposition_ids = tf.expand_dims(tf.range(slen), axis=0)\nelse:\n# assert shape_list(position_ids) == [bs, slen]  # (slen, bs)\n-            tf.debugging.assert_equal(shape_list(position_ids), [bs, slen])\n+            tf.debugging.assert_equal(\n+                shape_list(position_ids), [bs, slen]\n+            ), f\"Position id shape {shape_list(position_ids)} and input shape {[bs, slen]} mismatched\"\n# position_ids = position_ids.transpose(0, 1)\n\n# langs\nif langs is not None:\n# assert shape_list(langs) == [bs, slen]  # (slen, bs)\n-            tf.debugging.assert_equal(shape_list(langs), [bs, slen])\n+            tf.debugging.assert_equal(\n+                shape_list(langs), [bs, slen]\n+            ), f\"Lang shape {shape_list(langs)} and input shape {[bs, slen]} mismatched\"\n# langs = langs.transpose(0, 1)\n\n# Prepare head mask if needed\n", "fix_pattern": "if a shape assertion is detected, add a custom error message that includes the expected shape and actual shape in the assert_equal() function."}
{"number": 5704, "change": "def get_detector(trained_model, device='cpu'):\nnet.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\nelse:\nnet.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n-        net = torch.nn.DataParallel(net)\n+        net = torch.nn.DataParallel(net).to(device)\ncudnn.benchmark = False\n\nnet.eval()\n", "fix_pattern": "If using DataParallel to parallelize the network model, add .to(device) to the end of the DataParallel API call to specify the device on which the model will be placed."}
{"number": 5723, "change": "class CheckpointMergerPipeline(DiffusionPipeline):\ntheta_0 = theta_0()\n\nupdate_theta_0 = getattr(module, \"load_state_dict\")\n-                    theta_1 = torch.load(checkpoint_path_1)\n+                    theta_1 = torch.load(checkpoint_path_1, map_location=\"cpu\")\n\n-                    theta_2 = torch.load(checkpoint_path_2) if checkpoint_path_2 else None\n+                    theta_2 = torch.load(checkpoint_path_2, map_location=\"cpu\") if checkpoint_path_2 else None\n\nif not theta_0.keys() == theta_1.keys():\nprint(\"SKIPPING ATTR \", attr, \" DUE TO MISMATCH\")\n", "fix_pattern": "if loading a checkpoint with torch.load() and the map_location argument is not specified, add map_location=\"cpu\" to the torch.load() call."}
{"number": 5744, "change": "class TowerContext(object):\nself._ctxs.append(tf.variable_scope(self._name))\nelse:\n# use existing variable scope\n+                reuse = self.index > 0 or (not self.is_training)\nself._ctxs.append(tf.variable_scope(\n-                    tf.get_variable_scope(), reuse=self.index > 0))\n+                    tf.get_variable_scope(), reuse=reuse))\nself._ctxs.append(tf.name_scope(self._name))\nself._ctxs.append(tf.device(self._device))\nfor c in self._ctxs:\n", "fix_pattern": "if a tf.get_variable_scope() is detected with a reuse parameter, add a condition to check if self.index > 0 or (not self.is_training) and assign the result to the reuse parameter."}
{"number": 5785, "change": "class NaturalGradient(Optimizer):\n#     tf.math.reduce_sum(input_tensor=(loss_grad * delta))\n#     for loss_grad, delta in zip(loss_gradients, estimated_deltas.values())\n# ])\n-                return estimated_deltas.fmap(function=tf_util.identity)\n+                return [tf_util.identity(input=delta) for delta in estimated_deltas.values()]\n\nif self.only_positive_updates:\n# Natural gradient step only works if constant > 0 (epsilon to avoid zero division)\n", "fix_pattern": "If the API method `.fmap(function=tf_util.identity)` is detected, replace it with a list comprehension `[tf_util.identity(input=delta) for delta in estimated_deltas.values()]`."}
{"number": 5807, "change": "class BoringModelTPU(BoringModel):\n@pl_multi_process_test\ndef test_model_tpu_one_core():\n\"\"\"Tests if device/debug flag is set correctely when training and after teardown for TPUSpawnPlugin.\"\"\"\n-    trainer = Trainer(tpu_cores=1, fast_dev_run=True, plugin=TPUSpawnPlugin(debug=True))\n+    trainer = Trainer(tpu_cores=1, fast_dev_run=True, strategy=TPUSpawnPlugin(debug=True))\n# assert training type plugin attributes for device setting\nassert isinstance(trainer.training_type_plugin, TPUSpawnPlugin)\nassert not trainer.training_type_plugin.on_gpu\nassert trainer.training_type_plugin.on_tpu\n-    assert trainer.training_type_plugin.root_device == torch.device(\"xla\")\n+    assert trainer.training_type_plugin.root_device == torch.device(\"xla\", index=1)\nmodel = BoringModelTPU()\ntrainer.fit(model)\nassert \"PT_XLA_DEBUG\" not in os.environ\n", "fix_pattern": "If the trainer is created with the `tpu_cores` argument and the `plugin` argument is set to `TPUSpawnPlugin`, add the `strategy` argument with the `TPUSpawnPlugin` value."}
{"number": 5819, "change": "class TestAugmentationSequential:\ndata_keys=[\"input\"],\nrandom_apply=random_apply,\nreturn_transform=return_transform,\n+            same_on_batch=same_on_batch,\n)\nout = aug(inp)\nif aug.return_label:\nout, label = out\nif return_transform and isinstance(out, (tuple, list)):\nout = out[0]\n-        assert out.shape == inp.shape\n+        assert out.shape[-3:] == inp.shape[-3:]\nreproducibility_test(inp, aug)\n\n@pytest.mark.parametrize('random_apply', [1, (2, 2), (1, 2), (2,), 10, True, False])\n", "fix_pattern": "If an assertion is used to compare shapes of tensors, replace the original assert statement with the new assert statement."}
{"number": 5824, "change": "def compute_q_noisy_max_torch(counts, noise_eps):\n\nif type(counts) != torch.tensor:\n\n-        counts = torch.tensor(counts, dtype=torch.float)\n+        counts = torch.tensor(tensors_to_literals(counts), dtype=torch.float)\n\n_, winner = counts.max(0)\ncounts_normalized = noise_eps * (\n", "fix_pattern": "If a tensor is being converted to a literal, use the tensors_to_literals function to convert the tensor before passing it to the torch.tensor() call."}
{"number": 5870, "change": "class Model(ModelDesc):\nisTrain = get_current_tower_context().is_training\nif isTrain:\n# beam search is too slow to run in training\n-            predictions = tf.to_int32(\n-                tf.nn.ctc_greedy_decoder(logits, seqlen)[0][0])\n+            predictions = tf.cast(\n+                tf.nn.ctc_greedy_decoder(logits, seqlen)[0][0], tf.int32)\nelse:\n-            predictions = tf.to_int32(\n-                tf.nn.ctc_beam_search_decoder(logits, seqlen)[0][0])\n+            predictions = tf.cast(\n+                tf.nn.ctc_beam_search_decoder(logits, seqlen)[0][0], tf.int32)\nerr = tf.edit_distance(predictions, label, normalize=True)\nerr.set_shape([None])\nerr = tf.reduce_mean(err, name='error')\n", "fix_pattern": "If tf.to_int32() is detected, replace it with tf.cast(, tf.int32)"}
{"number": 5883, "change": "class PytorchGraphTest(unittest.TestCase):\nclass myLinear(torch.nn.Module):\ndef __init__(self):\nsuper(myLinear, self).__init__()\n-                self.l = torch.nn.Linear(3, 5)\n+                self.linear = torch.nn.Linear(3, 5)\n\ndef forward(self, x):\n-                return self.l(x)\n+                return self.linear(x)\n\nwith SummaryWriter(comment='LinearModel') as w:\nw.add_graph(myLinear(), dummy_input, True)\n\ndef test_wrong_input_size(self):\nprint('expect error here:')\n-        with self.assertRaises(RuntimeError) as e_info:\n+        with self.assertRaises(TypeError):\ndummy_input = torch.rand(1, 9)\nmodel = torch.nn.Linear(3, 5)\nwith SummaryWriter(comment='expect_error') as w:\n", "fix_pattern": "if torch.nn.Linear( detected, replace with self.linear = torch.nn.Linear("}
{"number": 5886, "change": "class MaskRCNN():\n# TODO: can this be optimized to avoid duplicating the anchors?\nanchors = np.broadcast_to(anchors, (config.BATCH_SIZE,) + anchors.shape)\n# A hack to get around Keras's bad support for constants\n-            anchors = KL.Lambda(lambda x: tf.constant(anchors), name=\"anchors\")(input_image)\n+            anchors = KL.Lambda(lambda x: tf.Variable(anchors), name=\"anchors\")(input_image)\nelse:\nanchors = input_anchors\n", "fix_pattern": "If a constant tensor is being created using tf.constant(), replace it with tf.Variable()."}
{"number": 5932, "change": "class InvConvNear(nn.Module):\nreturn z, logdet\n\ndef store_inverse(self):\n-        self.weight_inv = torch.inverse(\n+        weight_inv = torch.inverse(\nself.weight.float()).to(dtype=self.weight.dtype)\n+        self.weight_inv = nn.Parameter(weight_inv, requires_grad=False)\n\n\nclass CouplingBlock(nn.Module):\n", "fix_pattern": "if a tensor is assigned to a variable and then used as an argument in an API call, replace the variable assignment with the API call and assign the result of the API call back to the variable."}
{"number": 6008, "change": "class Imagen(BaseGaussianDiffusion):\ndevice = next(self.parameters()).device\n\nlowres_sample_noise_level = default(lowres_sample_noise_level, self.lowres_sample_noise_level)\n-        lowres_noise_times = torch.full((batch_size,), lowres_sample_noise_level, device = device, dtype = torch.long)\n+        lowres_noise_times = torch.full((batch_size,), int(lowres_sample_noise_level * self.num_timesteps), device = device, dtype = torch.long)\n\nfor unet_number, unet, channel, image_size, learned_variance in tqdm(zip(range(1, len(self.unets) + 1), self.unets, self.sample_channels, self.image_sizes, self.learned_variance)):\n", "fix_pattern": "if device is specified in API call, remove it and add `.to(device)` at the end of the API call"}
{"number": 6026, "change": "def any(\nkeepdims: bool = False,\nout: Optional[torch.Tensor] = None,\n) -> torch.Tensor:\n-    x = ivy.asarray(x).type(torch.bool)\n+    x = torch.as_tensor(x).type(torch.bool)\nif axis is None:\nnum_dims = len(x.shape)\naxis = list(range(num_dims))\n", "fix_pattern": "The pattern for fixing the API method problem in the code change is to replace the deprecated API torch.asscalar() with torch.as_tensor()."}
{"number": 6071, "change": "def batched_forward(\nif st >= end:\ncontinue\nout_list.append(model_dev(data[st:end].to(device), **kwargs))\n-        out = torch.cat(out_list, dim=0)\n+        out = concatenate(out_list, 0)\nreturn out.to(data.device)\nreturn model(data, **kwargs)\n", "fix_pattern": "if torch.cat() API call is detected, replace it with concatenate()"}
{"number": 6080, "change": "class EfficientFormer(nn.Module):\ndef get_classifier(self):\nreturn self.head, self.head_dist\n\n-    def reset_classifier(self, num_classes, global_pool=None, distillation=None):\n+    def reset_classifier(self, num_classes, global_pool=None):\nself.num_classes = num_classes\nif global_pool is not None:\nself.global_pool = global_pool\nself.head = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()\n-        if self.dist:\n-            self.head_dist = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()\n+        self.head_dist = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()\n\n@torch.jit.ignore\ndef set_distilled_training(self, enable=True):\n", "fix_pattern": "if a condition (in this case, `if self.dist:`) is removed from a method, then remove the corresponding code block inside the condition"}
{"number": 6084, "change": "class PretrainedTransformerEmbedder(TokenEmbedder):\ndef get_output_dim(self):\nreturn self.output_dim\n\n-    def forward(self, token_ids: torch.LongTensor) -> torch.Tensor:  # type: ignore\n+    def forward(\n+        self, token_ids: torch.LongTensor, attention_mask: torch.LongTensor\n+    ) -> torch.Tensor:  # type: ignore\n\n-        return self.transformer_model(token_ids)[0]\n+        return self.transformer_model(input_ids=token_ids, attention_mask=attention_mask)[0]\n", "fix_pattern": "if the API method forward() is changed to accept additional arguments, modify the method signature and call the API method with the new arguments"}
{"number": 6099, "change": "torch_scatter = None\ndef dev(x: torch.Tensor, as_native: bool = False) -> Union[ivy.Device, torch.device]:\ndv = x.device\nif as_native:\n-        return torch.device(dv.type.replace(\"gpu\", \"cuda\"))\n+        if isinstance(dv, torch.device):\n+            dv = dv.type\n+        return torch.device(dv.replace(\"gpu\", \"cuda\"))\nreturn as_ivy_dev(dv)\n", "fix_pattern": "if a device type string with \"gpu\" is detected, replace it with \"cuda\""}
{"number": 6112, "change": "def median(\ntemp = input\nif hasattr(axis, \"__iter__\"):\nfor dim in axis:\n-            temp = torch.median(\n+            temp = torch.quantile(\ntemp,\n+                0.5,\ndim=dim,\nkeepdim=keepdims,\n)[0]\n-        return input\n+        return temp\nelse:\n-        return torch.median(\n+        return torch.quantile(\ninput,\n+            0.5,\ndim=axis,\nkeepdim=keepdims,\n)[0]\n", "fix_pattern": "if torch.median( is detected, replace with torch.quantile("}
{"number": 6121, "change": "def test_welford_dense(n_samples, dim_size):\nsamples.append(sample)\nw.update(sample)\n\n-    sample_cov = np.cov(torch.stack(samples).data.numpy(), bias=False, rowvar=False)\n-    estimates = w.get_covariance(regularize=False).data.numpy()\n+    sample_cov = np.cov(torch.stack(samples).data.cpu().numpy(), bias=False, rowvar=False)\n+    estimates = w.get_covariance(regularize=False).data.cpu().numpy()\nassert_equal(estimates, sample_cov)\n", "fix_pattern": "if a tensor is converted to a numpy array using .data.numpy(), add .cpu() before .numpy() to move the tensor to the CPU before conversion"}
{"number": 6133, "change": "def mean_iou(\n# TODO: is it possible to vectorize this ?\n# iterate over classes\nfor class_id in range(num_classes):\n-        tp: torch.Tensor = conf_mat[..., class_id, class_id].float()\n+        tp: torch.Tensor = conf_mat[..., None, class_id, class_id]\ntotal = torch.sum(conf_mat[..., class_id, :], dim=-1, keepdim=True) + \\\ntorch.sum(conf_mat[..., :, class_id], dim=-1, keepdim=True)\niou_val: torch.Tensor = tp / (total.float() - tp + 1e-6)\n", "fix_pattern": "if a tensor access operation is detected with the index as specified in the code removed section, add an additional indexing operation with None to add a new dimension to the tensor access."}
{"number": 6219, "change": "class BeamSearch(Search):\nscores_buf = top_prediction[0]\nindices_buf = top_prediction[1]\n# Project back into relative indices and beams\n-        beams_buf = indices_buf // vocab_size\n+        beams_buf = torch.div(indices_buf, vocab_size, rounding_mode='trunc')\nindices_buf = indices_buf.fmod(vocab_size)\n\n# At this point, beams_buf and indices_buf are single-dim and contain relative indices\n", "fix_pattern": "if an integer division is detected using // operator, replace it with torch.div() method, and specify rounding_mode='trunc' parameter"}
{"number": 6260, "change": "class NanDetector:\ndef _detect(self, tensor, name, backward):\nerr = None\nif (\n-            tensor.numel() >= 2\n-        ):  # single value tensors (like the loss) will not provide much info\n+            torch.is_floating_point(tensor)\n+            # single value tensors (like the loss) will not provide much info\n+            and tensor.numel() >= 2\n+        ):\nwith torch.no_grad():\nif torch.isnan(tensor).any():\nerr = \"NaN\"\n", "fix_pattern": "if a condition is added after the API call, replace the condition with an \"and\" statement and move it inside the API call"}
{"number": 6262, "change": "class MetaLayer(torch.nn.Module):\n# u: [B, F_u]\n# batch: [N] with max entry B - 1.\nrow, col = edge_index\n-                out = torch.cat([x[col], edge_attr], dim=1)\n+                out = torch.cat([x[row], edge_attr], dim=1)\nout = self.node_mlp_1(out)\n-                out = scatter_mean(out, row, dim=0, dim_size=x.size(0))\n+                out = scatter_mean(out, col, dim=0, dim_size=x.size(0))\nout = torch.cat([x, out, u[batch]], dim=1)\nreturn self.node_mlp_2(out)\n", "fix_pattern": "If scatter_mean() is detected, swap the row and col arguments."}
{"number": 6277, "change": "def mu_law_encode(audio, quantization_channels):\nwith tf.name_scope('encode'):\nmu = quantization_channels - 1\n# Perform mu-law companding transformation (ITU-T, 1988).\n-        magnitude = tf.log(1 + mu * tf.abs(audio)) / tf.log(1. + mu)\n+        # Minimum operation is here to deal with rare large amplitudes caused by resampling.\n+        magnitude = tf.log(1 + mu * tf.minimum(tf.abs(audio), 1.0)) / tf.log(1. + mu)\nsignal = tf.sign(audio) * magnitude\n# Quantize signal to the specified number of levels.\nreturn tf.cast((signal + 1) / 2 * mu + 0.5, tf.int32)\n", "fix_pattern": "if logarithmic operation is performed on an input tensor, use tf.minimum(tensor, max_value) to handle rare large values caused by resampling."}
{"number": 6316, "change": "class GARPNHead(GuidedAnchorHead):\nif cfg.min_bbox_size > 0:\nw = proposals[:, 2] - proposals[:, 0]\nh = proposals[:, 3] - proposals[:, 1]\n-                valid_inds = torch.nonzero((w >= cfg.min_bbox_size) &\n-                                           (h >= cfg.min_bbox_size)).squeeze()\n+                valid_inds = torch.nonzero(\n+                    (w >= cfg.min_bbox_size) & (h >= cfg.min_bbox_size),\n+                    as_tuple=False).squeeze()\nproposals = proposals[valid_inds, :]\nscores = scores[valid_inds]\nproposals = torch.cat([proposals, scores.unsqueeze(-1)], dim=-1)\n", "fix_pattern": "if the \"as_tuple\" parameter is specified in torch.nonzero(), set it to \"as_tuple=False\""}
{"number": 6376, "change": "class VideoSequential(ImageSequential):\ndata_format: str = \"BTCHW\",\nsame_on_frame: bool = True,\nrandom_apply: Union[int, bool, Tuple[int, int]] = False,\n+        random_apply_weights: Optional[List[float]] = None,\n) -> None:\n-        super().__init__(*args, same_on_batch=None, return_transform=None, keepdim=None, random_apply=random_apply)\n+        super().__init__(\n+            *args, same_on_batch=None, return_transform=None, keepdim=None, random_apply=random_apply,\n+            random_apply_weights=random_apply_weights\n+        )\nself.same_on_frame = same_on_frame\nself.data_format = data_format.upper()\nif self.data_format not in [\"BCTHW\", \"BTCHW\"]:\n", "fix_pattern": "if a new optional parameter is added to the API call, add it to the end of the parameter list."}
{"number": 6382, "change": "def model(X, params, mesh, labels=None, past=None, scope='model', reuse=False, t\n# wpe has shape [ctx, embd]\n# positions_for would have shape [batch, seq]\n# h has shape [batch, seq, embd]\n-        zerodim = mtf.Dimension('singleton', 0)\n\n-        h = mtf.gather(wte, X, zerodim) + mtf.gather(wpe, positions_for(X, past_length, batch_dim), zerodim)\n+        h = mtf.gather(wte, X, vocab_dim) + mtf.gather(wpe, positions_for(X, past_length, batch_dim), vocab_dim)\n\n# Transformer\npresents = []\n", "fix_pattern": "if mtf.Dimension('singleton', 0) is detected, replace it with vocab_dim"}
{"number": 6415, "change": "def run_api_experiment(input_features, output_features, dataset, **kwargs):\nloaded_state = loaded_model.model.state_dict()\nbcast_state = hvd.broadcast_object(loaded_state)\nfor loaded, bcast in zip(loaded_state.values(), bcast_state.values()):\n-            assert np.allclose(loaded, bcast)\n+            assert torch.allclose(loaded, bcast)\nfinally:\nif output_dir:\nshutil.rmtree(output_dir, ignore_errors=True)\n", "fix_pattern": "If `np.allclose` is detected, replace it with `torch.allclose`."}
{"number": 6447, "change": "import logging\nlogger = logging.getLogger(__name__)\n\nTorchTrainer = None\n-TorchTrainable = None\nTrainingOperator = None\n+BaseTorchTrainable = None\n\ntry:\nimport torch  # noqa: F401\n\n-    from ray.util.sgd.torch.torch_trainer import (TorchTrainer, TorchTrainable)\n+    from ray.util.sgd.torch.torch_trainer import (TorchTrainer,\n+                                                  BaseTorchTrainable)\n\nfrom ray.util.sgd.torch.training_operator import TrainingOperator\n\n-    __all__ = [\"TorchTrainer\", \"TorchTrainable\", \"TrainingOperator\"]\n+    __all__ = [\"TorchTrainer\", \"BaseTorchTrainable\", \"TrainingOperator\"]\nexcept ImportError:\nlogger.warning(\"PyTorch not found. TorchTrainer will not be available\")\n", "fix_pattern": "If a variable named `TorchTrainable` is imported from the module `ray.util.sgd.torch.torch_trainer`, and it is used in the code, and then it is replaced or removed, the following pattern should be applied:\n\n- Rename `TorchTrainable` to `BaseTorchTrainable` in the import statement.\n- Add `BaseTorchTrainable` to the list of imported variables in `__all__`.\n\nThis pattern is used to reflect the change in the imported variable and update its usage in the code."}
{"number": 6455, "change": "def rand_segments(\nT = segment_size\nif _x_lenghts is None:\n_x_lenghts = T\n-    len_diff = _x_lenghts - segment_size + 1\n+    len_diff = _x_lenghts - segment_size\nif let_short_samples:\n_x_lenghts[len_diff < 0] = segment_size\n-        len_diff = _x_lenghts - segment_size + 1\n+        len_diff = _x_lenghts - segment_size\nelse:\nassert all(\nlen_diff > 0\n), f\" [!] At least one sample is shorter than the segment size ({segment_size}). \\n {_x_lenghts}\"\n-    segment_indices = (torch.rand([B]).type_as(x) * len_diff).long()\n-    ret = segment(x, segment_indices, segment_size)\n+    segment_indices = (torch.rand([B]).type_as(x) * (len_diff + 1)).long()\n+    ret = segment(x, segment_indices, segment_size, pad_short=pad_short)\nreturn ret, segment_indices\n", "fix_pattern": "if there is an API call with a tensor multiplication and addition, and the addition involves a constant value, change the addition to add one to the constant value"}
{"number": 6467, "change": "def log_tensorboard_graph(tb, model, imgsz=(640, 640)):\ntry:\np = next(model.parameters())  # for device, type\nimgsz = (imgsz, imgsz) if isinstance(imgsz, int) else imgsz  # expand\n-        im = torch.empty((1, 3, *imgsz)).to(p.device).type_as(p)  # input image\n+        im = torch.zeros((1, 3, *imgsz)).to(p.device).type_as(p)  # input image (WARNING: must be zeros, not empty)\nwith warnings.catch_warnings():\nwarnings.simplefilter('ignore')  # suppress jit trace warning\ntb.add_graph(torch.jit.trace(de_parallel(model), im, strict=False), [])\n", "fix_pattern": "if an empty tensor is detected, replace with torch.zeros() and include a warning comment (if necessary)"}
{"number": 6489, "change": "class LayerNorm2d(nn.LayerNorm):\nreturn F.layer_norm(\nx.permute(0, 2, 3, 1), self.normalized_shape, self.weight, self.bias, self.eps).permute(0, 3, 1, 2)\nelse:\n-            s, u = torch.var_mean(x, dim=1, keepdim=True)\n+            s, u = torch.var_mean(x, dim=1, unbiased=False, keepdim=True)\nx = (x - u) * torch.rsqrt(s + self.eps)\nx = x * self.weight[:, None, None] + self.bias[:, None, None]\nreturn x\n", "fix_pattern": "if a parameter \"unbiased\" is added to the API call, set it to the desired value"}
{"number": 6504, "change": "def build_lm_labels(sequence, pad_token):\ndef build_mask(sequence, pad_token):\n\"\"\" Builds the mask. The attention mechanism will only attend to positions\nwith value 1. \"\"\"\n-    mask = sequence.clone()\n-    mask[mask != pad_token] = 1\n-    mask[mask == pad_token] = 0\n+    mask = torch.ones_like(sequence)\n+    idx_pad_tokens = (sequence == pad_token)\n+    mask[idx_pad_tokens] = 0\nreturn mask\n", "fix_pattern": "If a mask tensor is created by cloning another tensor and then modifying its values, replace the cloning and modification code with creating a tensor of ones using `torch.ones_like()` and then modifying the values using boolean indexing."}
{"number": 6508, "change": "class TFTransfoXLMainLayer(tf.keras.layers.Layer):\n\n# There are `mlen + qlen` steps that can be cached into mems\nnew_mems = []\n-        end_idx = mlen + max(0, qlen)\n-        beg_idx = max(0, end_idx - self.mem_len)\n+        end_idx = mlen + tf.math.maximum(0, qlen)\n+        beg_idx = tf.math.maximum(0, end_idx - tf.convert_to_tensor(self.mem_len))\nfor i in range(len(hids)):\n\ncat = tf.concat([mems[i], hids[i]], axis=0)\n", "fix_pattern": "if the function or method being used is from a different library or framework, change the API call to the corresponding function or method from the desired library or framework."}
{"number": 6517, "change": "def from_tfds_to_path(tfds_dataset_name: str, split: str, hub_ds_path: str, batc\nreturn from_tfds(tfds_ds=tfds_ds, ds=ds)\n\n\n-def from_tfds(tfds_ds: (tensorflow.data.Dataset), ds: (Dataset)):\n+def from_tfds(tfds_ds: tensorflow.data.Dataset, ds: Dataset):\n+    \"\"\"Converts a tfds dataset to hub dataset\n+    Args:\n+        tfds_ds (tensorflow.data.Dataset): A tfds_dataset object.\n+        ds (Dataset) : A Hub dataset object where Tensor will be created.\n+    Returns:\n+        A hub dataset\n+    \"\"\"\ntfds_numpy = tfds.as_numpy(tfds_ds)  # Convert `tf.data.Dataset` to Python generator\n\nfor ex in tqdm(tfds_numpy):\n", "fix_pattern": "If a type hint for TensorFlow data.Dataset is used, replace the type hint with the fully qualified name \"tensorflow.data.Dataset\". Also, add a docstring that describes the purpose of the function and its arguments."}
{"number": 6546, "change": "def unpackbits_masks(masks):\nunpacked = tf.bitwise.bitwise_and(tf.expand_dims(masks, -1), bits) > 0\nunpacked = tf.reshape(\nunpacked,\n-        tf.concat([tf.shape(masks)[:-1], [-1]], axis=0))\n+        tf.concat([tf.shape(masks)[:-1], [8 * tf.shape(masks)[-1]]], axis=0))\nreturn unpacked\n", "fix_pattern": "if tf.shape(masks)[-1] is multiplied by a number and added to the tensor, replace the number with the multiplication of the original tf.shape(masks)[-1] value and the desired number"}
{"number": 6551, "change": "def _take_channels(*xs, ignore_channels=None):\nreturn xs\nelse:\nchannels = [channel for channel in range(xs[0].shape[1]) if channel not in ignore_channels]\n-        xs = [torch.index_select(x, dim=1, index=torch.tensor(channels)) for x in xs]\n+        xs = [torch.index_select(x, dim=1, index=torch.tensor(channels).to(x.device)) for x in xs]\nreturn xs\n", "fix_pattern": "If torch.tensor(channels).to(x.device) is detected, add .to(x.device) at the end of the API call."}
{"number": 6613, "change": "class TokenCharactersEncoder(TokenEmbedder):\nself._dropout = lambda x: x\n\ndef get_output_dim(self) -> int:\n-        return self._encoder._module.get_output_dim()  # pylint: disable=protected-access\n+        return self._encoder._module.get_output_dim()\n\n-    def forward(self, token_characters: torch.Tensor) -> torch.Tensor:  # pylint: disable=arguments-differ\n+    def forward(self, token_characters: torch.Tensor) -> torch.Tensor:\nmask = (token_characters != 0).long()\nreturn self._dropout(self._encoder(self._embedding(token_characters), mask))\n\n# The setdefault requires a custom from_params\n@classmethod\ndef from_params(cls, vocab: Vocabulary, params: Params) -> 'TokenCharactersEncoder':  # type: ignore\n-        # pylint: disable=arguments-differ\n+\nembedding_params: Params = params.pop(\"embedding\")\n# Embedding.from_params() uses \"tokens\" as the default namespace, but we need to change\n# that to be \"token_characters\" by default. If num_embeddings is present, set default namespace\n", "fix_pattern": "if a method override is detected and the parent method has a parameter with pylint disable, add the same pylint disable comment to the child method."}
{"number": 6629, "change": "class Normalize(Preprocessor):\n\"\"\"\n\ndef __init__(self, scope='normalize', summary_labels=()):\n-        super(Normalize).__init__(scope, summary_labels)\n+        super(Normalize, self).__init__(scope=scope, summary_labels=summary_labels)\n\ndef tf_process(self, tensor):\n# Min/max across every axis except batch dimension.\n-        min = tf.reduce_min(input_tensor=tensor, axis=np.arange(1, util.rank(tensor)))\n-        max = tf.reduce_max(input_tensor=tensor, axis=np.arange(1, util.rank(tensor)))\n+        min_value = tf.reduce_min(input_tensor=tensor, axis=np.arange(1, util.rank(tensor)))\n+        max_value = tf.reduce_max(input_tensor=tensor, axis=np.arange(1, util.rank(tensor)))\n\n-        return (tensor - min) / (max - min + util.epsilon)\n+        return (tensor - min_value) / (max_value - min_value + util.epsilon)\n", "fix_pattern": "if a TensorFlow API call with deprecated arguments or attributes is detected:\n1. Replace the deprecated attribute or argument with the correct one.\n2. Make sure to use the correct format for the API call with the updated arguments or attributes."}
{"number": 6695, "change": "class Conv(Layer):\ninputs = tf.pad(inputs, self._compute_causal_padding(inputs))\n\nif self.groups > 1:\n-            outputs = self._jit_compiled_convolution_op(inputs, self.kernel)\n+            outputs = self._jit_compiled_convolution_op(\n+                inputs, tf.convert_to_tensor(self.kernel)\n+            )\nelse:\noutputs = self.convolution_op(inputs, self.kernel)\n", "fix_pattern": "if a tensor input is passed into an API method that expects a tensor, use tf.convert_to_tensor() to convert the input before passing it to the API method"}
{"number": 6714, "change": "def main():\n'op_names': ['features.6', 'features.9', 'features.13', 'features.16', 'features.20', 'classifier.2', 'classifier.5']\n}]\n\n-    quantizer = BNNQuantizer(model, configure_list)\n+    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n+    quantizer = BNNQuantizer(model, configure_list, optimizer)\nmodel = quantizer.compress()\n\nprint('=' * 10 + 'train' + '=' * 10)\n-    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\nbest_top1 = 0\nfor epoch in range(400):\nprint('# Epoch {} #'.format(epoch))\n", "fix_pattern": "if an optimizer is being created before the quantizer, move the creation of the optimizer after the quantizer creation."}
{"number": 6720, "change": "class Dataset(DatasetInfoMixin, IndexableMixin):\n- if `dataset_path` is a path of a dataset dict directory: a :class:`DatasetDict` with each split.\n\"\"\"\n# copies file from filesystem if it is remote filesystem to local filesystem and modifies dataset_path to temp directory containing local copies\n+        fs = fsspec.filesystem(\"file\") if fs is None else fs\n+        dataset_dict_json_path = Path(dataset_path, config.DATASETDICT_JSON_FILENAME).as_posix()\n+        dataset_info_path = Path(dataset_path, config.DATASET_INFO_FILENAME).as_posix()\n+        if not fs.isfile(dataset_info_path) and fs.isfile(dataset_dict_json_path):\n+            raise FileNotFoundError(\n+                f\"No such file or directory: '{dataset_info_path}'. Expected to load a Dataset object, but got a DatasetDict. Please use datasets.load_from_disk instead.\"\n+            )\n+\nif is_remote_filesystem(fs):\nsrc_dataset_path = extract_path_from_uri(dataset_path)\ntmp_dir = tempfile.TemporaryDirectory()\n", "fix_pattern": "If `dataset_path` is a path of a dataset dict directory, check if the dataset_info_path file exists. If it doesn't exist and the dataset_dict_json_path file exists, raise a FileNotFoundError with a specific message asking to use `datasets.load_from_disk` instead."}
{"number": 6759, "change": "def test_graph_store():\ndef test_graph_store_conversion():\ngraph_store = MyGraphStore()\n\n-    coo = (row, col) = get_edge_index(100, 100, 300)\n+    coo = (row, col) = get_random_edge_index(100, 100, 300)\nadj = SparseTensor(row=row, col=col, sparse_sizes=(100, 100))\ncsr, csc = adj.csr()[:2], adj.csc()[:2][::-1]\n", "fix_pattern": "if an API method used in the code is replaced with a different method, replace the old method name with the new method name."}
{"number": 6763, "change": "class StableDiffusionInpaintPipelineLegacy(DiffusionPipeline):\ninit_latents_orig = init_latents\n\n# add noise to latents using the timesteps\n-        noise = torch.randn(init_latents.shape, generator=generator, device=self.device, dtype=dtype)\n+        noise = randn_tensor(init_latents.shape, generator=generator, device=self.device, dtype=dtype)\ninit_latents = self.scheduler.add_noise(init_latents, noise, timestep)\nlatents = init_latents\nreturn latents, init_latents_orig, noise\n", "fix_pattern": "if torch.randn() is detected, replace with randn_tensor()"}
{"number": 6803, "change": "def fully_connected_with_w(x, use_bias=True, sn=False, reuse=False, scope='linea\nif sn :\nw = tf.get_variable(\"kernel\", [channels, 1], tf.float32,\ninitializer=weight_init, regularizer=weight_regularizer)\n+            w = spectral_norm(w)\n+\nif use_bias :\nbias = tf.get_variable(\"bias\", [1],\ninitializer=tf.constant_initializer(0.0))\n\n-                x = tf.matmul(x, spectral_norm(w)) + bias\n+                x = tf.matmul(x, w) + bias\nelse :\n-                x = tf.matmul(x, spectral_norm(w))\n+                x = tf.matmul(x, w)\n+\nelse :\nx = tf.layers.dense(x, units=1, kernel_initializer=weight_init, kernel_regularizer=weight_regularizer, use_bias=use_bias)\n", "fix_pattern": "If the API call for spectral normalization (spectral_norm()) is detected, move the call to a separate line before using it in tf.matmul() operations."}
{"number": 6811, "change": "def audio_config():\n@pytest.mark.parametrize(\"encoder\", [\"rnn\", \"stacked_cnn\", \"parallel_cnn\", \"stacked_parallel_cnn\", \"rnn\", \"cnnrnn\"])\ndef test_audio_input_feature(audio_config: Dict, encoder: str) -> None:\naudio_config.update({\"encoder\": encoder})\n-    audio_input_feature = AudioInputFeature(audio_config)\n-    audio_tensor = torch.randn([BATCH_SIZE, SEQ_SIZE, AUDIO_W_SIZE], dtype=torch.float32)\n+    audio_input_feature = AudioInputFeature(audio_config).to(DEVICE)\n+    audio_tensor = torch.randn([BATCH_SIZE, SEQ_SIZE, AUDIO_W_SIZE], dtype=torch.float32).to(DEVICE)\nencoder_output = audio_input_feature(audio_tensor)\n-    assert encoder_output[\"encoder_output\"].shape[1:] == audio_input_feature.encoder_obj.output_shape\n+    assert encoder_output[\"encoder_output\"].shape[1:] == audio_input_feature.output_shape\n", "fix_pattern": "If a tensor is created without specifying the device, add .to(DEVICE) to the end of the API call."}
{"number": 6839, "change": "def trunc(\nelif not (\"int\" in str(x.dtype)):\nif not ret.get_shape().ndims == 0:\nret = tf.tensor_scatter_nd_update(\n-                x, tf.where(tf.greater(x, 0)), tf.math.floor(x[x > 0])\n+                x, tf.where(tf.greater_equal(x, 0)), tf.math.floor(x[x >= 0])\n)\nret = tf.tensor_scatter_nd_update(\nret, tf.where(tf.less(x, 0)), tf.math.ceil(x[x < 0])\n)\nelse:\n-            ret = (tf.math.floor if ret > 0 else tf.math.ceil)(ret)\n+            ret = (tf.math.floor if ret >= 0 else tf.math.ceil)(ret)\nreturn ret\n", "fix_pattern": "if tf.greater(x, 0) is detected, replace with tf.greater_equal(x, 0)\nif x[x > 0] is detected, replace with x[x >= 0]\nif ret > 0 is detected, replace with ret >= 0\nif tf.math.floor if ret > 0 else tf.math.ceil is detected, replace with tf.math.floor if ret >= 0 else tf.math.ceil"}
{"number": 6843, "change": "class FocalLoss(nn.Module):\ndevice=input.device, dtype=input.dtype)\n\n# compute the actual focal loss\n-        prob = input_soft * target_one_hot\n+        prob = input_soft * target_one_hot + self.eps\nfocal = -torch.log(prob) * self.alpha * (1. - prob) ** self.gamma\n-        loss_tmp = 1. - torch.sum(focal, dim=1)\n+        loss_tmp = torch.sum(focal, dim=1)\n\nloss = -1\nif self.reduction == 'none':\n", "fix_pattern": "If a tensor is being multiplied element-wise by another tensor and then summed along a certain dimension, and a constant value is being added to the result of the multiplication, the pattern is to add the constant value directly to the result of the multiplication."}
{"number": 6895, "change": "class InMemoryDataset(Dataset):\n\nfor item, key in product(data_list, keys):\ndata[key].append(item[key])\n-            s = slices[key][-1] + item[key].size(item.cat_dim(key))\n+            s = slices[key][-1] + item[key].size(item.cat_dim(key, item))\nslices[key].append(s)\n\nfor key in keys:\n-            data[key] = torch.cat(data[key], dim=data_list[0].cat_dim(key))\n+            data[key] = torch.cat(\n+                data[key], dim=data_list[0].cat_dim(key, item))\nslices[key] = torch.LongTensor(slices[key])\n\nreturn data, slices\n", "fix_pattern": "if the cat_dim() method is called on an object, pass the object as an argument to the cat_dim() method."}
{"number": 6896, "change": "class CLIPModel(CLIPPreTrainedModel):\n\nself.visual_projection = nn.Linear(self.vision_embed_dim, self.projection_dim, bias=False)\nself.text_projection = nn.Linear(self.text_embed_dim, self.projection_dim, bias=False)\n-        self.logit_scale = nn.Parameter(torch.ones([]))\n+        self.logit_scale = nn.Parameter(torch.ones([]) * self.config.logit_scale_init_value)\n\nself.init_weights()\n", "fix_pattern": "To fix the API method problem in the given code change, the pattern is to add self.config.logit_scale_init_value to the nn.Parameter(torch.ones([]))."}
{"number": 6898, "change": "class BBoxHead(nn.Module):\nkeep_inds = pos_is_gts_.new_ones(num_rois)\nkeep_inds[:len(pos_is_gts_)] = pos_keep\n\n-            bboxes_list.append(bboxes[keep_inds])\n+            bboxes_list.append(bboxes[keep_inds.type(torch.bool)])\n\nreturn bboxes_list\n", "fix_pattern": "if using indexing with a boolean tensor (keep_inds.type(torch.bool)), and keep_inds is not already a boolean tensor, convert keep_inds to a boolean tensor using the .type(torch.bool) method"}
{"number": 6930, "change": "class BloomForSequenceClassification(BloomPreTrainedModel):\nsequence_lengths = -1\nelse:\nif input_ids is not None:\n-                sequence_lengths = torch.ne(input_ids, self.config.pad_token_id).sum(dim=-1) - 1\n+                sequence_lengths = (torch.ne(input_ids, self.config.pad_token_id).sum(-1) - 1).to(logits.device)\nelse:\nsequence_lengths = -1\nlogger.warning(\n", "fix_pattern": "if a tensor is used in a calculation and the result needs to be on a specific device, add .to(device) to the end of the API call"}
{"number": 6965, "change": "class RecurrentTFModelV2(TFModelV2):\nshape=(None, obs_space.shape[0]))\nstate_in_h = tf.keras.layers.Input(shape=(256, ))\nstate_in_c = tf.keras.layers.Input(shape=(256, ))\n-                seq_in = tf.keras.layers.Input(shape=())\n+                seq_in = tf.keras.layers.Input(shape=(), dtype=tf.int32)\n\n# Send to LSTM cell\nlstm_out, state_h, state_c = tf.keras.layers.LSTM(\n", "fix_pattern": "If the shape of the input tensor is specified without specifying the data type, add dtype=tf.int32 to the API call."}
{"number": 6975, "change": "logger = logging.getLogger(__name__)  # pylint: disable=invalid-name\n\ntry:\nimport tensorflow as tf\n-    assert int(tf.__version__[0]) >= 2\n+    assert hasattr(tf, '__version__') and int(tf.__version__[0]) >= 2\n_tf_available = True  # pylint: disable=invalid-name\nlogger.info(\"TensorFlow version {} available.\".format(tf.__version__))\nexcept (ImportError, AssertionError):\n", "fix_pattern": "if assert statement checking the version of a library detected, replace `tf.__version__[0]` with `hasattr(tf, '__version__') and int(tf.__version__[0])`"}
{"number": 6979, "change": "class ModelCheckpoint(Callback):\n\n# do not save nan, replace with +/- inf\nif isinstance(current, torch.Tensor) and torch.isnan(current):\n-            current = torch.tensor(float(\"inf\" if self.mode == \"min\" else \"-inf\"))\n+            current = torch.tensor(float(\"inf\" if self.mode == \"min\" else \"-inf\"), device=current.device)\n\nfilepath = self._get_metric_interpolated_filepath_name(monitor_candidates, trainer, del_filepath)\n", "fix_pattern": "if a tensor is initialized with torch.tensor() without specifying a device, add \", device=current.device\" to the end of the API call."}
{"number": 6981, "change": "class QNAFModel(QModel):\nl_matrix = flat_stddev\nl_matrix = tf.exp(l_matrix)\nelse:\n-            l_matrix = tf.map_fn(fn=tf.diag, elems=flat_stddev)\n+            l_matrix = tf.linalg.diag(diagonal=flat_stddev)\n\nl_entries = self.l_entries[name].apply(x=embedding)\nl_entries = tf.exp(l_entries)\n", "fix_pattern": "If tf.map_fn(fn=tf.diag, elems=flat_stddev) is detected, replace with tf.linalg.diag(diagonal=flat_stddev)."}
{"number": 7035, "change": "def bag_config():\n@pytest.mark.parametrize(\"encoder\", [\"embed\"])\ndef test_bag_input_feature(bag_config: Dict, encoder: str) -> None:\nbag_config.update({\"encoder\": encoder})\n-    bag_input_feature = BagInputFeature(bag_config)\n-    bag_tensor = torch.randn([BATCH_SIZE, SEQ_SIZE, BAG_W_SIZE], dtype=torch.float32)\n+    bag_input_feature = BagInputFeature(bag_config).to(DEVICE)\n+    bag_tensor = torch.randn([BATCH_SIZE, SEQ_SIZE, BAG_W_SIZE], dtype=torch.float32).to(DEVICE)\nencoder_output = bag_input_feature(bag_tensor)\n-    assert encoder_output[\"encoder_output\"].shape[1:][1:] == bag_input_feature.encoder_obj.output_shape\n+    assert encoder_output[\"encoder_output\"].shape[1:][1:] == bag_input_feature.output_shape\n", "fix_pattern": "if tensor variables are initialized without .to(device), add .to(device) to the end of the variable initialization line"}
{"number": 7045, "change": "def test_auto_scale_batch_size_set_model_attribute(tmpdir, use_hparams):\n\ntrainer = Trainer(default_root_dir=tmpdir, max_epochs=1, auto_scale_batch_size=True)\ntrainer.tune(model, datamodule_fit)\n-    assert trainer.datamodule == datamodule_fit\nafter_batch_size = model.hparams.batch_size if use_hparams else model.batch_size\n+    assert trainer.datamodule == datamodule_fit\nassert before_batch_size != after_batch_size\n+    assert after_batch_size <= len(trainer.train_dataloader.dataset)\nassert datamodule_fit.batch_size == after_batch_size\n# should be left unchanged, since it was not passed to .tune()\nassert datamodule_model.batch_size == 111\n", "fix_pattern": "if an assert statement is detected, add another assert statement immediately afterwards to validate another condition."}
{"number": 7063, "change": "class PytorchBackendCompiler(Compiler):\ninput_sample = input_data.get_list(1)[0]\nif self.device is Device.GPU:\nif quantization_type is QuantizationType.HALF:\n-                input_sample = [t.cuda().half() for t in input_sample]\n+                input_sample = [\n+                    t.cuda().half() if torch.is_floating_point(t) else t.cuda()\n+                    for t in input_sample\n+                ]\nelse:\ninput_sample = [t.cuda() for t in input_sample]\n", "fix_pattern": "If .cuda() is called on a tensor, add a condition to check if the tensor is of floating point type using torch.is_floating_point(t), and if it is, call .half() on the tensor. Otherwise, call .cuda() on the tensor."}
{"number": 7079, "change": "def test_api_training_determinism(csv_filename):\n\ndivergence = False\nfor weight_1, weight_2 in zip(model_weights_1, model_weights_2):\n-            if not np.allclose(weight_1, weight_2):\n+            if not torch.allclose(weight_1, weight_2):\ndivergence = True\nbreak\nassert divergence, 'model_1 and model_2 have identical weights with different seeds!'\n\nfor weight_1, weight_3 in zip(model_weights_1, model_weights_3):\n-            assert np.allclose(weight_1, weight_3)\n+            assert torch.allclose(weight_1, weight_3)\n\n\ndef run_api_commands(\n", "fix_pattern": "if numpy.allclose() is used for element-wise comparison of two arrays, replace it with torch.allclose() for PyTorch tensors."}
{"number": 7109, "change": "class TFOptimizer(Optimizer):\narguments: Dict of arguments for passing to fn_loss as **kwargs.\nfn_loss: A callable taking arguments as kwargs and returning the loss op.\n\"\"\"\n-        loss = fn_loss(**arguments)\n+        # Trivial operation to enforce control dependency\n+        previous_variables = [util.identity_operation(x=variable) for variable in variables]\n\n# Force loss value to be calculated.\n-        with tf.control_dependencies(control_inputs=(loss,)):\n-            # Trivial operation to enforce control dependency\n-            previous_variables = [util.identity_operation(x=variable) for variable in variables]\n+        with tf.control_dependencies(control_inputs=previous_variables):\n+            loss = fn_loss(**arguments)\n\n# The actual tensorflow minimize op.\n-        with tf.control_dependencies(control_inputs=previous_variables):\n+        with tf.control_dependencies(control_inputs=(loss,)):\n# colocate_gradients_with_ops=True\napplied = self.optimizer.minimize(loss=loss, var_list=variables)\n", "fix_pattern": "The pattern for fixing the API method problem in this code change is to move the declaration and assignment of \"loss = fn_loss(**arguments)\" after the \"with tf.control_dependencies(control_inputs=previous_variables):\" block."}
{"number": 7132, "change": "class Trainer(Registrable):\nself.optimizer.zero_grad()\n\nloss = self.batch_loss(batch, for_training=True)\n+            if torch.isnan(loss):\n+                raise ValueError(\"nan loss encountered\")\n+\nloss.backward()\n\ntrain_loss += loss.item()\n", "fix_pattern": "If a check for NaN loss is detected, add a conditional statement and raise a ValueError with an appropriate error message."}
{"number": 7145, "change": "def patch_tf_keras():\nfrom tensorflow.python.keras.engine import training_arrays\nfrom tensorflow.python.keras.engine import training_generator\n\n-    training_v2 = wandb.util.import_module('tensorflow.python.keras.engine.training_v2')\n+    training_v2 = wandb.util.get_module('tensorflow.python.keras.engine.training_v2')\nold_arrays = training_arrays.fit_loop\nold_generator = training_generator.fit_generator\nif training_v2:\n", "fix_pattern": "if wandb.util.import_module() is detected, replace it with wandb.util.get_module()"}
{"number": 7154, "change": "def corr2d(X, K):  #@save\nY = tf.Variable(tf.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1)))\nfor i in range(Y.shape[0]):\nfor j in range(Y.shape[1]):\n-            Y[i, j].assign(tf.reduce_sum(X[i: i + h, j: j + w] * K))\n+            Y[i, j].assign(tf.cast(tf.reduce_sum(\n+                X[i: i + h, j: j + w] * K), dtype=tf.float32))\nreturn Y\n", "fix_pattern": "If a tf.reduce_sum() operation is detected without tf.cast() for dtype conversion, add tf.cast() with the appropriate dtype to the API call."}
{"number": 7185, "change": "def get_item(\nx: torch.Tensor,\nquery: torch.Tensor,\n) -> torch.Tensor:\n-    if ivy.dtype(query, as_native=True) is torch.bool:\n-        return x.__getitem__(query)\n-    return x.__getitem__(query.to(torch.int64))\n+    if ivy.is_array(query) and ivy.dtype(query, as_native=True) is not torch.bool:\n+        return x.__getitem__(query.to(torch.int64))\n+    return x.__getitem__(query)\n\n\ndef to_numpy(x: torch.Tensor, /, *, copy: bool = True) -> np.ndarray:\n", "fix_pattern": "if ivy.dtype(query, as_native=True) is torch.bool, change it to if ivy.is_array(query) and ivy.dtype(query, as_native=True) is not torch.bool"}
{"number": 7191, "change": "class PulsarPointsRenderer(nn.Module):\nraster_rad = self.rasterizer.raster_settings.radius\nif kwargs.get(\"radius_world\", False):\nreturn raster_rad\n-        if isinstance(raster_rad, torch.Tensor) and raster_rad.numel() > 1:\n+        if (\n+            isinstance(raster_rad, torch.Tensor)\n+            and raster_rad.numel() > 1\n+            and raster_rad.ndim > 1\n+        ):\n# In this case it must be a batched torch tensor.\nraster_rad = raster_rad[cloud_idx]\nif orthogonal_projection:\n", "fix_pattern": "If \"raster_rad\" is a torch.Tensor and has more than 1 element, and has more than 1 dimension, then"}
{"number": 7215, "change": "class GPTNeoXForCausalLM(GPTNeoXPreTrainedModel):\nattention_mask = input_ids.new_ones(input_shape)\n\n# cut decoder_input_ids if past is used\n-        if past is not None:\n+        if past and past[0] is not None:\ninput_ids = input_ids[:, -1:]\n\nreturn {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"past_key_values\": past}\n", "fix_pattern": "if a variable named \"past\" is detected in the if statement and is followed by \"is not None\", replace \"past is not None\" with \"past and past[0] is not None\""}
{"number": 7261, "change": "class PolicyGradientModel(Model):\n\nwith tf.variable_scope('distribution'):\nfor action, distribution in self.distribution.items():\n-                distribution.create_tf_operations(x=self.network.output, deterministic=self.deterministic)\n+                with tf.variable_scope(action):\n+                    distribution.create_tf_operations(x=self.network.output, deterministic=self.deterministic)\nself.action_taken[action] = distribution.sample()\n\nif self.baseline:\n", "fix_pattern": "if distribution.create_tf_operations() is called within a tf.variable_scope(), add the tf.variable_scope() wrapper around the code block that contains the method call."}
{"number": 7271, "change": "def generate_examples(features: dict, num_examples=100, seq_shapes=None):\ndef generate_example_dataset(dataset_path, features, num_examples=100, seq_shapes=None):\ndummy_data = generate_examples(features, num_examples=num_examples, seq_shapes=seq_shapes)\n\n-    writer = datasets.ArrowWriter(features=features, path=dataset_path)\n-    for key, record in dummy_data:\n-        example = features.encode_example(record)\n-        writer.write(example)\n+    with datasets.ArrowWriter(features=features, path=dataset_path) as writer:\n+        for key, record in dummy_data:\n+            example = features.encode_example(record)\n+            writer.write(example)\n\n-    num_final_examples, num_bytes = writer.finalize()\n+        num_final_examples, num_bytes = writer.finalize()\n\nassert (\nnum_final_examples == num_examples\n", "fix_pattern": "if datasets.ArrowWriter is used to create an object writer, wrap the code block that utilizes the writer object with a \"with\" statement to ensure proper resource management."}
{"number": 7293, "change": "class DistributedModel(object):\n\ngrad_var_list = list(zip(self.gradients, self.global_network.get_variables()))\n\n-            global_step_inc = self.global_step.assign_add(self.batch_size)\n+            global_step_inc = self.global_step.assign_add(tf.shape(self.state)[0])\n\nself.assign_global_to_local = tf.group(*[v1.assign(v2) for v1, v2 in\nzip(self.local_network.get_variables(),\n", "fix_pattern": "If the global step is incremented by the batch size, replace it with tf.shape(state)[0]."}
{"number": 7298, "change": "class Model(ModelDesc):\nfor idx, b in enumerate([b1, b2, b3, b4, b5, final_map]):\noutput = tf.nn.sigmoid(b, name='output{}'.format(idx+1))\nxentropy = class_balanced_sigmoid_cross_entropy(\n-                b, edgemap,\n+                tf.squeeze(b, [3]), edgemap,\nname='xentropy{}'.format(idx+1))\ncosts.append(xentropy)\n", "fix_pattern": "if an API call is using torch.squeeze() with a dimension argument, replace it with tf.squeeze()"}
{"number": 7333, "change": "class TensorBoard(Callback):\nembedding_input = tf.reshape(embedding_input,\n(step, int(embedding_size)))\nshape = (self.embeddings_data[0].shape[0], int(embedding_size))\n-                    embedding = tf.Variable(tf.zeros(shape),\n-                                            name=layer.name + '_embedding')\n+                    embedding = K.variable(K.zeros(shape),\n+                                           name=layer.name + '_embedding')\nembeddings_vars[layer.name] = embedding\nbatch = tf.assign(embedding[batch_id:batch_id + step],\nembedding_input)\n", "fix_pattern": "if a tf.Variable() call is detected, replace it with K.variable()"}
{"number": 7336, "change": "def build_targets(p, targets, model):\nif use_all_anchors:\nna = anchor_vec.shape[0]  # number of anchors\na = torch.arange(na).view(-1, 1).repeat(1, nt).view(-1)\n-                t = targets.repeat(na, 1)\n+                t = t.repeat(na, 1)\nelse:  # use best anchor only\niou, a = iou.max(0)  # best iou and anchor\n", "fix_pattern": "if a tensor is detected without the source variable name and .repeat() is called on it, replace the tensor name with the source variable name"}
{"number": 7364, "change": "def zca_mean(inp: torch.Tensor, dim: int = 0,\nelse:\ncov = cov / float(N)\n\n-    U, S, _ = torch.svd(cov)\n+    U, S, _ = _torch_svd_cast(cov)\n\nS = S.reshape(-1, 1)\nS_inv_root: torch.Tensor = torch.rsqrt(S + eps)\n", "fix_pattern": "if a torch function is detected with a leading underscore (_) in the name, replace it with the corresponding non-underscore function call."}
{"number": 7375, "change": "class PretrainedTransformerMismatchedEmbedder(TokenEmbedder):\nspan_embeddings_sum = span_embeddings.sum(2)\nspan_embeddings_len = span_mask.sum(2)\n# Shape: (batch_size, num_orig_tokens, embedding_size)\n-        orig_embeddings = span_embeddings_sum / span_embeddings_len\n+        orig_embeddings = span_embeddings_sum / torch.clamp_min(span_embeddings_len, 1)\n\n# All the places where the span length is zero, write in zeros.\norig_embeddings[(span_embeddings_len == 0).expand(orig_embeddings.shape)] = 0\n", "fix_pattern": "if division by a variable is detected, add a clamp_min() function to the denominator with a minimum value of 1"}
{"number": 7386, "change": "class PipelineTesterMixin:\n\nwith tempfile.TemporaryDirectory() as tmpdir:\npipe.save_pretrained(tmpdir)\n-            pipe_loaded = self.pipeline_class.from_pretrained(tmpdir)\n+            pipe_loaded = self.pipeline_class.from_pretrained(tmpdir, torch_dtype=torch.float16)\npipe_loaded.to(torch_device)\npipe_loaded.set_progress_bar_config(disable=None)\n", "fix_pattern": "if an additional argument for the API method is detected, add it to the end of the API call"}
{"number": 7392, "change": "def main():\n# train\nlogging.info('backend = ' + args.backend)\nif args.backend == \"chainer\":\n-        from espnet.lm.chain.lm_chainer import train\n+        from espnet.lm.chain.lm import train\ntrain(args)\nelif args.backend == \"pytorch\":\n-        from espnet.lm.pytorch.lm_pytorch import train\n+        from espnet.lm.pytorch.lm import train\ntrain(args)\nelse:\nraise ValueError(\"Only chainer and pytorch are supported.\")\n", "fix_pattern": "The pattern for fixing the API method problem in the given code change is to remove the \".chainer\" and \".pytorch\" components from the import statements."}
{"number": 7443, "change": "class SimpleSummarizationPipelineTests(unittest.TestCase):\n# Bias output towards L\nV, C = model.lm_head.weight.shape\n\n-        bias = torch.zeros(V, requires_grad=True)\n+        bias = torch.zeros(V)\nbias[76] = 10\n\nmodel.lm_head.bias = torch.nn.Parameter(bias)\n", "fix_pattern": "If a tensor is required to have requires_grad=True but it is not set in the code, remove requires_grad=True from the tensor initialization."}
{"number": 7451, "change": "def to_hetero(module: Module, metadata: Metadata, aggr: str = \"sum\",\nimport torch\nfrom torch_geometric.nn import SAGEConv, to_hetero\n\n-        Net(torch.nn.Module):\n+        class GNN(torch.nn.Module):\ndef __init__(self):\n-                self.conv1 = SAGEConv(-1, 16)\n-                self.conv2 = SAGEConv(16, 16)\n+                self.conv1 = SAGEConv((-1, -1), 32)\n+                self.conv2 = SAGEConv((32, 32), 32)\n\ndef forward(self, x, edge_index):\nx = self.conv1(x, edge_index).relu()\nx = self.conv2(x, edge_index).relu()\nreturn x\n\n-        model = Net()\n+        model = GNN()\n\nnode_types = ['paper', 'author']\nedge_types = [\n", "fix_pattern": "if an invalid input dimension is detected in the API call, replace it with the correct input dimension"}
{"number": 7456, "change": "def get_batch_statistics(outputs, targets, iou_threshold):\ncontinue\n\n# Filter target_boxes by pred_label so that we only match against boxes of our own label\n-                filtered_target_position, filtered_targets = zip(*filter(lambda x: target_labels[x] == pred_label, enumerate(target_boxes)))\n-\n+                filtered_target_position, filtered_targets = zip(*filter(lambda x: target_labels[x[0]] == pred_label, enumerate(target_boxes)))\n+\n# Find the best matching target for our predicted box\n-                iou, box_filtered_index = bbox_iou(pred_box.unsqueeze(0), filtered_targets).max(0)\n-\n+                iou, box_filtered_index = bbox_iou(pred_box.unsqueeze(0), torch.stack(filtered_targets)).max(0)\n+\n# Remap the index in the list of filtered targets for that label to the index in the list with all targets.\nbox_index = filtered_target_position[box_filtered_index]\n", "fix_pattern": "If working with filtered targets, change the type of filtered_targets from a tuple to a torch.Tensor by using torch.stack(filtered_targets) instead of filtered_targets."}
{"number": 7493, "change": "class XLNetRelativeAttention(nn.Module):\nattn_vec = torch.einsum('bnij,jbnd->ibnd', attn_prob, v_head_h)\n\nif self.output_attentions:\n-            return attn_vec, attn_prob\n+            return attn_vec, torch.einsum('bnij->ijbn', attn_prob)\n\nreturn attn_vec\n", "fix_pattern": "if the return statement includes a torch.einsum operation on the attention probability tensor, transpose the dimensions by using the torch.einsum operation with the desired permutation"}
{"number": 7499, "change": "class VGG(Model):\n\ninputs = inputs * 255 - np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape([1, 1, 1, 3])\n\n-        out = self.layers(inputs)\n+        out = self.layers.forward(inputs)\nreturn out\n", "fix_pattern": "if a method call is detected without .forward(), add .forward() to the end of the API call"}
{"number": 7519, "change": "class CapsNet(object):\nelse:\n# self.masked_v = tf.matmul(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, 10, 1)), transpose_a=True)\nself.masked_v = tf.multiply(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, 10, 1)))\n-                self.v_length = tf.sqrt(tf.reduce_sum(tf.square(self.caps2), axis=2, keep_dims=True) + epsilon)\n+                self.v_length = tf.sqrt(reduce_sum(tf.square(self.caps2), axis=2, keepdims=True) + epsilon)\n\n# 2. Reconstructe the MNIST images with 3 FC layers\n# [batch_size, 1, 16, 1] => [batch_size, 16] => [batch_size, 512]\n", "fix_pattern": "if TensorFlow API tf.reduce_sum() is detected, change it to reduce_sum() without the tf. prefix"}
{"number": 7528, "change": "class Uniform(Distribution):\nif x.size != a.size():\na = a.expand_as(x)\nb = b.expand_as(x)\n-        l = x.ge(a).type_as(a)\n-        u = x.le(b).type_as(b)\n+        lb = x.ge(a).type_as(a)\n+        ub = x.le(b).type_as(b)\nbatch_log_pdf_shape = self.batch_shape(a, b) + (1,)\n-        return torch.sum(torch.log(l.mul(u)) - torch.log(b - a), -1).contiguous().view(batch_log_pdf_shape)\n+        return torch.sum(torch.log(lb.mul(ub)) - torch.log(b - a), -1).contiguous().view(batch_log_pdf_shape)\n\ndef analytic_mean(self, a=None, b=None):\na, b = self._sanitize_input(a, b)\n", "fix_pattern": "if a logical operation (e.g. .ge(), .le()) is performed on a tensor, use a more descriptive variable name (e.g. l -> lb, u -> ub)"}
{"number": 7559, "change": "class SSIMLoss(torch.nn.Module):\n\nif ssim_loss.item() > 1.0:\nprint(f\" > SSIM loss is out-of-range {ssim_loss.item()}, setting it 1.0\")\n-            ssim_loss = torch.tensor([1.0])\n+            ssim_loss = torch.tensor([1.0], device=ssim_loss.device)\n\nif ssim_loss.item() < 0.0:\nprint(f\" > SSIM loss is out-of-range {ssim_loss.item()}, setting it 0.0\")\n-            ssim_loss = torch.tensor([0.0])\n+            ssim_loss = torch.tensor([0.0], device=ssim_loss.device)\n\nreturn ssim_loss\n", "fix_pattern": "<pattern>: If a tensor is detected that is used for device placement, add the device argument to the tensor creation. In this case, the device argument is added to the torch.tensor() call."}
{"number": 7597, "change": "class LstmTagger(Model):\n\ndef forward(self,\nsentence: Dict[str, torch.Tensor],\n-                labels: torch.Tensor = None) -> torch.Tensor:\n+                labels: torch.Tensor = None) -> Dict[str, torch.Tensor]:\nmask = get_text_field_mask(sentence)\nembeddings = self.word_embeddings(sentence)\nencoder_out = self.encoder(embeddings, mask)\n", "fix_pattern": "if the return type of a method is changed from torch.Tensor to Dict[str, torch.Tensor], update the method signature accordingly"}
{"number": 7601, "change": "class TensorFlowEstimator(BaseEstimator):\n# Set up a single operator to merge all the summaries\nsummary_op = tf.merge_all_summaries()\n# Set up summary writer to a tmp directory\n-        self._summary_writer = tf.train.SummaryWriter('/tmp/tensorflow_logs', graph_def=sess.graph_def)\n+        self._summary_writer = tf.train.SummaryWriter('/tmp/tensorflow_logs', graph_def=self._session.graph_def)\n\ndef fit(self, X, y):\n\"\"\"Builds a neural network model given provided `model_fn` and training\n", "fix_pattern": "if sess is used as the session object, replace sess.graph_def with self._session.graph_def"}
{"number": 7602, "change": "def test_inputs(framework: str | None) -> list[tuple[ModuleType, FrameworkTestMo\n)\nexcept ModuleNotFoundError as e:\nlogger.warning(\n-                f\"Failed to find test module for framework {framework_name} (tests.integration.frameworks.models.{framework_name})\"\n+                f\"Failed to find test module for framework {framework_name} (tests.integration.frameworks.models.{framework_name}): {e}\"\n)\n\nreturn [\n", "fix_pattern": "if an exception variable (e) is detected in the code block, add it to the end of the error message string"}
{"number": 7619, "change": "class Trainer(\n)\nreturn {}\n\n-            ckpt = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n+            ckpt = pl_load(ckpt_path, map_location=lambda storage, loc: storage)\nmodel.load_state_dict(ckpt['state_dict'])\n\n# attach dataloaders\n", "fix_pattern": "use pl_load() instead of torch.load() to load the checkpoint"}
{"number": 7621, "change": "def from_networkx(G):\n\nG = nx.convert_node_labels_to_integers(G)\nG = G.to_directed() if not nx.is_directed(G) else G\n-    edge_index = torch.tensor(list(G.edges)).t().contiguous()\n+    edge_index = torch.LongTensor(list(G.edges)).t().contiguous()\n\ndata = {}\n", "fix_pattern": "If a tensor conversion operation is detected (e.g., converting a list to a tensor) without specifying the desired data type, add a data type specification (e.g., torch.LongTensor) to the API call."}
{"number": 7643, "change": "class AttentionDecoder(RNNDecoder):\nlogits=self.vocab_size,\npredicted_ids=tf.TensorShape([]),\ncell_output=self.cell.output_size,\n-        attention_scores=tf.concat([0, self.attention_values[1:-1]], 0),\n+        attention_scores=tf.concat(\n+            [[0], tf.shape(self.attention_values)[1:-1]], 0),\nattention_context=self.attention_values.get_shape()[-1])\n\n@property\n", "fix_pattern": "If using tf.concat() to concatenate tensors, use square brackets and tf.shape() to create a tensor of the correct shape."}
{"number": 7658, "change": "def convert_points_from_homogeneous(points: torch.Tensor,\n\n# we check for points at infinity\nz_vec: torch.Tensor = points[..., -1:]\n-    scale: torch.Tensor = 1. / torch.clamp(z_vec, eps)\n+    scale: torch.Tensor = torch.tensor(1.) / torch.clamp(z_vec, eps)\n\nreturn scale * points[..., :-1]\n", "fix_pattern": "if a division operation with a scalar value (e.g., 1.) and a tensor is detected, replace the scalar value with a tensor value (e.g., torch.tensor(1.))"}
{"number": 7719, "change": "class MeanAbsoluteError(Metric):\npreds: Predictions from model\ntarget: Ground truth values\n\"\"\"\n-        self._check_same_shape(preds, target)\n-        abs_error = torch.abs(preds - target)\n+        sum_abs_error, n_obs = _mean_absolute_error_update(preds, target)\n\n-        self.sum_abs_error += torch.sum(abs_error)\n-        self.total += target.numel()\n+        self.sum_abs_error += sum_abs_error\n+        self.total += n_obs\n\ndef compute(self):\n\"\"\"\nComputes mean absolute error over state.\n\"\"\"\n-        return self.sum_abs_error / self.total\n+        return _mean_absolute_error_compute(self.sum_abs_error, self.total)\n", "fix_pattern": "if an error calculation function is detected (e.g., calculating absolute error), replace the code with an external function for updating and computing the error values"}
{"number": 7723, "change": "class RandomSampler(BaseSampler):\nelse:\ndevice = 'cpu'\ngallery = torch.tensor(gallery, dtype=torch.long, device=device)\n-        perm = torch.randperm(gallery.numel(), device=gallery.device)[:num]\n+        # This is a temporary fix. We can revert the following code\n+        # when PyTorch fixes the abnormal return of torch.randperm.\n+        # See: https://github.com/open-mmlab/mmdetection/pull/5014\n+        perm = torch.randperm(gallery.numel())[:num].to(device=gallery.device)\nrand_inds = gallery[perm]\nif not is_tensor:\nrand_inds = rand_inds.cpu().numpy()\n", "fix_pattern": "if torch.randperm() API is detected, add .to(device=device_name) to the end of the API call"}
{"number": 7739, "change": "class Stft(torch.nn.Module, InversibleInterface):\npad = self.n_fft // 2\nilens = ilens + 2 * pad\n\n-            olens = torch.div((ilens - self.n_fft), self.hop_length) + 1\n+            olens = (\n+                torch.div((ilens - self.n_fft), self.hop_length, rounding_mode=\"floor\")\n+                + 1\n+            )\noutput.masked_fill_(make_pad_mask(olens, output, 1), 0.0)\nelse:\nolens = None\n", "fix_pattern": "If a rounding mode is specified in the API call, it should be included in the code change. In this case, \"rounding_mode='floor'\" was added to the torch.div() call."}
{"number": 7781, "change": "class ImageInputFeature(ImageFeatureMixin, InputFeature):\n)\n\ndef forward(self, inputs: torch.Tensor) -> torch.Tensor:\n-        assert isinstance(inputs, torch.Tensor)\n-        assert inputs.dtype in [torch.float32]\n+        assert isinstance(inputs, torch.Tensor), f\"inputs to image feature must be a torch tensor, got {type(inputs)}\"\n+        assert inputs.dtype in [torch.float32], f\"inputs to image feature must be a float32 tensor, got {inputs.dtype}\"\n\ninputs_encoded = self.encoder_obj(inputs)\n", "fix_pattern": "if assert statement is used to check the type and data type of the input, then modify the assert statement to include a detailed error message."}
{"number": 7789, "change": "def test_hetero_to_undirected():\ndata['v', 'w'].edge_weight = edge_weight\ndata['v', 'w'].edge_attr = edge_attr\n\n+    from torch_geometric.transforms import ToUndirected\ndata = ToUndirected()(data)\n-    assert data['v', 'v'].edge_index.tolist() == [[0, 0, 1, 2, 2, 3],\n-                                                  [1, 2, 0, 0, 3, 2]]\n+    assert data['v', 'v'].edge_index.tolist() == [[0, 1, 2, 3], [1, 0, 3, 2]]\nassert data['v', 'v'].edge_weight.tolist() == edge_weight[perm].tolist()\nassert data['v', 'v'].edge_attr.tolist() == edge_attr[perm].tolist()\nassert data['v', 'w'].edge_index.tolist() == edge_index.tolist()\nassert data['v', 'w'].edge_weight.tolist() == edge_weight.tolist()\nassert data['v', 'w'].edge_attr.tolist() == edge_attr.tolist()\n-    assert data['w', 'v'].edge_index.tolist() == [[3, 1, 0], [2, 0, 2]]\n+    assert data['w', 'v'].edge_index.tolist() == [[3, 1], [2, 0]]\nassert data['w', 'v'].edge_weight.tolist() == edge_weight.tolist()\nassert data['w', 'v'].edge_attr.tolist() == edge_attr.tolist()\n", "fix_pattern": "if a transform from the torch_geometric.transforms module is detected, import it and apply the transform before asserting the edge_index values"}
{"number": 7809, "change": "if __name__ == '__main__':\n\n# Load pytorch model\ngoogle_utils.attempt_download(opt.weights)\n-    model = torch.load(opt.weights, map_location=torch.device('cpu'))['model']\n+    model = torch.load(opt.weights, map_location=torch.device('cpu'))['model'].float()\nmodel.eval()\nmodel.fuse()\n", "fix_pattern": "if loading a model from a file and the model is not of type 'float', add .float() to the end of the model variable definition"}
{"number": 7821, "change": "def test_forward(use_token_averaged_energy):\n)\nxs = torch.randn(2, 256)\nif not use_token_averaged_energy:\n-        layer(xs, torch.LongTensor([256, 128]))\n+        es, elens = layer(xs, torch.LongTensor([256, 128]))\n+        assert es.shape[1] == max(elens)\nelse:\nds = torch.LongTensor([[3, 0, 2], [3, 0, 0]])\ndlens = torch.LongTensor([3, 1])\n", "fix_pattern": "The pattern for fixing the API method problem in the code change is:\n\nIf the API method is called with a Tensor argument and the method is expecting a LongTensor argument, convert the argument to a LongTensor by using the torch.LongTensor() function."}
{"number": 7866, "change": "from .degree import DegreeAdj\n\nclass DegreeTest(TestCase):\ndef test_degree_adj(self):\n+        index = torch.LongTensor([[0, 0, 1, 2], [1, 2, 0, 1]])\nweight = torch.FloatTensor([2, 3, 4, 6])\n-        edge = torch.LongTensor([[0, 0, 1, 2], [1, 2, 0, 1]])\n-        adj = torch.sparse.FloatTensor(edge, weight, torch.Size([3, 3]))\n+        adj = torch.sparse.FloatTensor(index, weight, torch.Size([3, 3]))\n\ntransform = DegreeAdj()\n\n-        _, adj = transform((None, adj))\n+        _, adj, _ = transform((None, adj, None))\nadj = adj.to_dense()\n\nexpected_adj_out = [\n", "fix_pattern": "If a sparse tensor creation using the `torch.LongTensor()` method is detected, replace `torch.LongTensor()` with `torch.sparse.LongTensor()`."}
{"number": 7912, "change": "class Trainer:\nelse:\ntr_loss_step = self.training_step(model, inputs)\n\n-                if args.logging_nan_inf_filter and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step)):\n-                    # if loss is nan or inf simply add the average of previous logged losses\n-                    tr_loss += tr_loss / (1 + self.state.global_step - self._globalstep_last_logged)\n+                if args.logging_nan_inf_filter and not is_torch_tpu_available():\n+                    if torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step):\n+                        # if loss is nan or inf simply add the average of previous logged losses\n+                        tr_loss += tr_loss / (1 + self.state.global_step - self._globalstep_last_logged)\nelse:\ntr_loss += tr_loss_step\n", "fix_pattern": "If args.logging_nan_inf_filter is detected and torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step) is detected, and is_torch_tpu_available() is not detected, then the if statement is split into two separate if statements. The original if statement is nested inside the new if statement."}
{"number": 7948, "change": "class SGD(base.Module):\noptimizer_utils.check_same_dtype(update, parameter)\nlearning_rate = tf.cast(self.learning_rate, update.dtype.base_dtype)\nif isinstance(update, tf.IndexedSlices):\n-          parameter.scatter_nd_sub(\n-              update.indices, update.values * learning_rate)\n+          parameter.scatter_sub(\n+              tf.IndexedSlices(update.values * learning_rate, update.indices))\nelse:\nparameter.assign_sub(update * learning_rate)\n", "fix_pattern": "if scatter_nd_sub() method is detected, replace it with scatter_sub() method and pass an instance of tf.IndexedSlices as the first argument to scatter_sub()."}
{"number": 7954, "change": "for it in range(1000000):\nT_sample = T(torch.cat([X, z_sample], 1))\n\ndisc = torch.mean(-T_sample)\n-    loglike = -nn.binary_cross_entropy(X_sample, X)\n+    loglike = -nn.binary_cross_entropy(X_sample, X, size_average=False) / mb_size\n\nelbo = -(disc + loglike)\n", "fix_pattern": "If the size_average argument is set to False in nn.binary_cross_entropy(), divide the result by the batch size (mb_size) to get the average loss."}
{"number": 7961, "change": "class SamplePoints(object):\npos = pos / pos_max\n\narea = (pos[face[1]] - pos[face[0]]).cross(pos[face[2]] - pos[face[0]])\n-        area = torch.sqrt((area**2).sum(dim=-1)) / 2\n+        area = area.norm(p=2, dim=1) / 2\n\nprob = area / area.sum()\nsample = torch.multinomial(prob, self.num, replacement=True)\n", "fix_pattern": "If torch.sqrt((area**2).sum(dim=-1)) / 2 is detected, replace it with area.norm(p=2, dim=1) / 2."}
{"number": 7968, "change": "class PaintByExamplePipeline(DiffusionPipeline):\nimage_embeddings = image_embeddings.view(bs_embed * num_images_per_prompt, seq_len, -1)\n\nif do_classifier_free_guidance:\n-            uncond_embeddings = uncond_embeddings.repeat(1, image_embeddings.shape[0], 1)\n-            uncond_embeddings = uncond_embeddings.view(bs_embed * num_images_per_prompt, 1, -1)\n+            negative_prompt_embeds = negative_prompt_embeds.repeat(1, image_embeddings.shape[0], 1)\n+            negative_prompt_embeds = negative_prompt_embeds.view(bs_embed * num_images_per_prompt, 1, -1)\n\n# For classifier free guidance, we need to do two forward passes.\n# Here we concatenate the unconditional and text embeddings into a single batch\n# to avoid doing two forward passes\n-            image_embeddings = torch.cat([uncond_embeddings, image_embeddings])\n+            image_embeddings = torch.cat([negative_prompt_embeds, image_embeddings])\n\nreturn image_embeddings\n", "fix_pattern": "If a tensor named \"uncond_embeddings\" is detected, replace it with \"negative_prompt_embeds\" and adjust the subsequent code accordingly."}
{"number": 7977, "change": "class SequenceGenerator(nn.Module):\ncand_size = 2 * beam_size  # 2 x beam size in case half are EOS\n\n# offset arrays for converting between different indexing schemes\n-        bbsz_offsets = (torch.arange(0, bsz) * beam_size).unsqueeze(1).type_as(tokens)\n-        cand_offsets = torch.arange(0, cand_size).type_as(tokens)\n+        bbsz_offsets = (torch.arange(0, bsz) * beam_size).unsqueeze(1).type_as(tokens).to(src_tokens.device)\n+        cand_offsets = torch.arange(0, cand_size).type_as(tokens).to(src_tokens.device)\n\nreorder_state: Optional[Tensor] = None\nbatch_idxs: Optional[Tensor] = None\n", "fix_pattern": "if an offset tensor is detected without .to(), add .to(device) to the end of the API call"}
{"number": 8014, "change": "class MeanSquaredError(Metric):\npreds: Predictions from model\ntarget: Ground truth values\n\"\"\"\n-        self._check_same_shape(preds, target)\n-        squared_error = torch.pow(preds - target, 2)\n+        sum_squared_error, n_obs = _mean_squared_error_update(preds, target)\n\n-        self.sum_squared_error += torch.sum(squared_error)\n-        self.total += target.numel()\n+        self.sum_squared_error += sum_squared_error\n+        self.total += n_obs\n\ndef compute(self):\n\"\"\"\nComputes mean squared error over state.\n\"\"\"\n-        return self.sum_squared_error / self.total\n+        return _mean_squared_error_compute(self.sum_squared_error, self.total)\n", "fix_pattern": "The pattern for fixing the API method problem in the given code change is:\n\nReplace the deprecated API method `_check_same_shape` with `_mean_squared_error_update` for updating the sum of squared error and the number of observations, and replace `torch.pow` with `_mean_squared_error_compute` for computing the mean squared error."}
{"number": 8045, "change": "def test_unnormalized_normal(kernel, jit):\nposterior.append(samples)\n\nposterior = torch.stack([sample[\"z\"] for sample in posterior])\n-    assert_equal(torch.mean(posterior), true_mean, prec=0.1)\n-    assert_equal(torch.std(posterior), true_std, prec=0.1)\n+    assert_close(torch.mean(posterior), true_mean, rtol=0.05)\n+    assert_close(torch.std(posterior), true_std, rtol=0.05)\n", "fix_pattern": "if assert_equal() function is detected with torch.mean() or torch.std() as arguments, replace with assert_close() function and use rtol=0.05 for precision of 0.1"}
{"number": 8166, "change": "def bjerksund_stensland(*,\nvolatilities=volatilities,\nstrikes=strikes,\nexpiries=expiries,\n-                forwards=forwards,\n+                spots=spots,\ndiscount_rates=discount_rates,\ncost_of_carries=cost_of_carries,\nis_call_options=is_call_options),\n# For put options, adjust inputs according to call-put transformation\n# function:  P(S, X, T, r, b, sigma) = C(X, S, T, r - b, -b, sigma)\ntf.where(is_call_options,\n-                bjerksund_stensland_model(forwards, strikes, expiries, discount_rates,\n+                bjerksund_stensland_model(spots, strikes, expiries, discount_rates,\ncost_of_carries, volatilities),\n-                bjerksund_stensland_model(strikes, forwards, expiries, discount_rates -\n+                bjerksund_stensland_model(strikes, spots, expiries, discount_rates -\ncost_of_carries, -cost_of_carries, volatilities)))\n\nreturn american_prices\n", "fix_pattern": "If bjerksund_stensland_model API call is detected with forwards, strikes, expiries, discount_rates as arguments, replace the order of arguments with spots, strikes, expiries, discount_rates."}
{"number": 8205, "change": "def model(y):\n# Vector of variances for each of the d variables\ntheta = pyro.sample(\"theta\", dist.HalfCauchy(torch.ones(d, **options)))\n# Lower cholesky factor of a correlation matrix\n-    eta = torch.ones(1, **options)  # Implies a uniform distribution over correlation matrices\n-    L_omega = pyro.sample(\"L_omega\", dist.LKJCorrCholesky(d, eta))\n+    concentration = torch.ones((), **options)  # Implies a uniform distribution over correlation matrices\n+    L_omega = pyro.sample(\"L_omega\", dist.LKJCholesky(d, concentration))\n# Lower cholesky factor of the covariance matrix\nL_Omega = torch.mm(torch.diag(theta.sqrt()), L_omega)\n# For inference with SVI, one might prefer to use torch.bmm(theta.sqrt().diag_embed(), L_omega)\n", "fix_pattern": "if dist.LKJCorrCholesky is detected, replace with dist.LKJCholesky and change eta to concentration"}
{"number": 8242, "change": "class DistilBertModelIntergrationTest(unittest.TestCase):\nmodel = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\ninput_ids = torch.tensor([[0, 345, 232, 328, 740, 140, 1695, 69, 6078, 1588, 2]])\nattention_mask = torch.tensor([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n-        output = model(input_ids, attention_mask=attention_mask)[0]\n+        with torch.no_grad():\n+            output = model(input_ids, attention_mask=attention_mask)[0]\nexpected_shape = torch.Size((1, 11, 768))\nself.assertEqual(output.shape, expected_shape)\nexpected_slice = torch.tensor(\n", "fix_pattern": "if a model output is used for inference and no gradients need to be computed, add \"with torch.no_grad():\" before using the model"}
{"number": 8259, "change": "class Model(object):\nelse:\nassert not config.global_model and config.session is None\ntf.reset_default_graph()\n-            self.session = tf.Session()\n+            self.session = config.session = tf.Session()\n\nif config.distributed and not config.global_model:\n# Global and local model for asynchronous updates\n", "fix_pattern": "if a tf.Session() is instantiated, assign it to a variable in the configuration"}
{"number": 8273, "change": "def test(loader):\ntarget = batch['user', 'item'].edge_label.long().cpu()\n\npreds.append(pred)\n-        targets.append(pred)\n+        targets.append(target)\n\npred = torch.cat(preds, dim=0).numpy()\n-    target = torch.cat(target, dim=0).numpy()\n+    target = torch.cat(targets, dim=0).numpy()\n\n+    pred = pred > 0.5\nacc = accuracy_score(target, pred)\nprec = precision_score(target, pred)\nrec = recall_score(target, pred)\n", "fix_pattern": "if appending an element to a list is detected, replace the element being appended with the correct value and update the list accordingly."}
{"number": 8283, "change": "from ray.rllib.optimizers import SampleBatch, TFMultiGPUSupport\nclass DQNEvaluator(TFMultiGPUSupport):\n\"\"\"The base DQN Evaluator that does not include the replay buffer.\"\"\"\n\n-    def __init__(self, env_creator, config, logdir):\n+    def __init__(self, registry, env_creator, config, logdir):\nenv = env_creator()\n-        env = wrap_dqn(env, config[\"model\"])\n+        env = wrap_dqn(registry, env, config[\"model\"])\nself.env = env\nself.config = config\n\ntf_config = tf.ConfigProto(**config[\"tf_session_args\"])\nself.sess = tf.Session(config=tf_config)\n-        self.dqn_graph = models.DQNGraph(env, config, logdir)\n+        self.dqn_graph = models.DQNGraph(registry, env, config, logdir)\n\n# Create the schedule for exploration starting from 1.\nself.exploration = LinearSchedule(\n", "fix_pattern": "if an additional parameter (registry) is added to the function definition, include it as an argument in the function call as well."}
{"number": 8296, "change": "def ctc_label_dense_to_sparse(labels, label_lengths):\nmax_num_labels_tns = tf.pack([label_shape[1]])\n\ndef range_less_than(previous_state, current_input):\n-        return tf.expand_dims(tf.range(label_shape[1]), 0) < current_input\n+        return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(max_num_labels_tns, current_input)\n\n-    init = tf.cast(tf.fill(max_num_labels_tns, 0), tf.bool)\n+    init = tf.cast(tf.fill([1, label_shape[1]], 0), tf.bool)\ndense_mask = functional_ops.scan(range_less_than, label_lengths,\ninitializer=init, parallel_iterations=1)\ndense_mask = dense_mask[:, 0, :]\n", "fix_pattern": "if a tensor is being filled with a scalar value, replace the syntax tf.fill(shape, scalar_value) with tf.fill(shape, tf.scalar(value))"}
{"number": 8304, "change": "class PreTrainedModel(nn.Module, ModuleUtilsMixin, GenerationMixin, PushToHubMix\n)\n\n# Build new embeddings\n-        new_embeddings = nn.Embedding(new_num_tokens, old_embedding_dim).to(self.device)\n+        new_embeddings = nn.Embedding(new_num_tokens, old_embedding_dim).to(\n+            self.device, dtype=old_embeddings.weight.dtype\n+        )\n\n# initialize all new embeddings (in particular added tokens)\nself._init_weights(new_embeddings)\n", "fix_pattern": "if an object is detected without .to(device), add .to(device) at the end of the API call. Additionally, if dtype is specified, add .to(device, dtype=) to the end of the API call."}
{"number": 8311, "change": "def resize_images(X, height_factor, width_factor, dim_ordering):\npositive integers.\n'''\nif dim_ordering == 'th':\n+        original_shape = int_shape(X)\nnew_shape = tf.shape(X)[2:]\nnew_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\nX = permute_dimensions(X, [0, 2, 3, 1])\nX = tf.image.resize_nearest_neighbor(X, new_shape)\n-        return permute_dimensions(X, [0, 3, 1, 2])\n+        X = permute_dimensions(X, [0, 3, 1, 2])\n+        X.set_shape((None, None, original_shape[2] * height_factor, original_shape[3] * width_factor))\n+        return X\nelif dim_ordering == 'tf':\n+        original_shape = int_shape(X)\nnew_shape = tf.shape(X)[1:3]\nnew_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n-        return tf.image.resize_nearest_neighbor(X, new_shape)\n+        X = tf.image.resize_nearest_neighbor(X, new_shape)\n+        X.set_shape((None, original_shape[1] * height_factor, original_shape[2] * width_factor, None))\n+        return X\nelse:\nraise Exception('Invalid dim_ordering: ' + dim_ordering)\n", "fix_pattern": "if permute_dimensions(X, [0, 3, 1, 2]) is detected, it should be replaced with:\n1. original_shape = int_shape(X)\n2. X = permute_dimensions(X, [0, 3, 1, 2])\n3. X.set_shape((None, None, original_shape[2] * height_factor, original_shape[3] * width_factor))\n4. return X\n\nif tf.image.resize_nearest_neighbor(X, new_shape) is detected, it should be replaced with:\n1. original_shape = int_shape(X)\n2. X = tf.image.resize_nearest_neighbor(X, new_shape)\n3. X.set_shape((None, original_shape[1] * height_factor, original_shape[2] * width_factor, None))\n4. return X"}
{"number": 8319, "change": "class BaseModel():\nsave_filename = '%s_net_%s.pth' % (which_epoch, name)\nsave_path = os.path.join(self.save_dir, save_filename)\nnet = getattr(self, 'net' + name)\n-                torch.module.save(net.cpu().state_dict(), save_path)\n+                torch.save(net.module.cpu().state_dict(), save_path)\nif len(self.gpu_ids) and torch.cuda.is_available():\nnet.cuda(self.gpu_ids[0])\n", "fix_pattern": "if torch.module.save is detected, replace it with torch.save and add .module.cpu() before state_dict()"}
{"number": 8358, "change": "def clip(\n*,\nout: Optional[Union[tf.Tensor, tf.Variable]] = None,\n) -> Union[tf.Tensor, tf.Variable]:\n+    assert tf.reduce_all(tf.less(x_min, x_max)), \"Min value must be less than max.\"\nif hasattr(x_min, \"dtype\") and hasattr(x_max, \"dtype\"):\npromoted_type = tf.experimental.numpy.promote_types(x.dtype, x_min.dtype)\npromoted_type = tf.experimental.numpy.promote_types(promoted_type, x_max.dtype)\n", "fix_pattern": "No pattern identified."}
{"number": 8385, "change": "class DiceCoeff(Function):\n\ndef forward(self, input, target):\nself.save_for_backward(input, target)\n-        self.inter = torch.dot(input.view(-1), target.view(-1)) + 0.0001\n-        self.union = torch.sum(input) + torch.sum(target) + 0.0001\n+        eps = 0.0001\n+        self.inter = torch.dot(input.view(-1), target.view(-1))\n+        self.union = torch.sum(input) + torch.sum(target) + eps\n\n-        t = 2 * self.inter.float() / self.union.float()\n+        t = (2 * self.inter.float() + eps) / self.union.float()\nreturn t\n\n# This function has only a single output, so it gets only one gradient\n", "fix_pattern": "If a constant value (in this case, 0.0001) is added to a computation, remove the constant value and store it as a separate variable (in this case, eps), and then add the eps variable to the computation."}
{"number": 8394, "change": "def cross_entropy_seq(logits, target_seqs):#, batch_size=1, num_steps=None):\nloss = sequence_loss_by_example_fn(\n[logits],\n[tf.reshape(target_seqs, [-1])],\n-        [tf.ones_like(tf.reshape(targets, [-1]), dtype=tf.float32)])\n+        [tf.ones_like(tf.reshape(target_seqs, [-1]), dtype=tf.float32)])\n# [tf.ones([batch_size * num_steps])])\n-    cost = tf.reduce_sum(loss) / batch_size\n+    cost = tf.reduce_sum(loss) #/ batch_size\nreturn cost\n", "fix_pattern": "if tf.reduce_sum(loss) / batch_size is detected, remove the division by batch_size"}
{"number": 8440, "change": "def stats(policy: Policy, train_batch: SampleBatch):\nstats_dict[\"var_IS\"] = is_stat_var\n\nif policy.config[\"use_kl_loss\"]:\n-        stats_dict[\"kl\"] = policy.get_tower_stats(\"mean_kl_loss\")\n+        stats_dict[\"kl\"] = torch.mean(\n+            torch.stack(policy.get_tower_stats(\"mean_kl_loss\")))\nstats_dict[\"KL_Coeff\"] = policy.kl_coeff\n\nreturn stats_dict\n", "fix_pattern": "If there is a call to a policy method that returns a list, wrap the list with torch.stack() and then take the mean with torch.mean()."}
{"number": 8475, "change": "class BertModel(BertPreTrainedModel):\nseq_ids = torch.arange(seq_length, device=device)\ncausal_mask = seq_ids[None, None, :].repeat(batch_size, seq_length, 1) <= seq_ids[None, :, None]\ncausal_mask = causal_mask.to(\n-                    torch.long\n-                )  # not converting to long will cause errors with pytorch version < 1.3\n+                    attention_mask.dtype\n+                )  # causal and attention masks must have same type with pytorch version < 1.3\nextended_attention_mask = causal_mask[:, None, :, :] * attention_mask[:, None, None, :]\nelse:\nextended_attention_mask = attention_mask[:, None, None, :]\n", "fix_pattern": "If an API call is made with a torch.dtype without converting it to the desired type (e.g., torch.long), it can cause errors with PyTorch versions prior to 1.3. The pattern for fixing this is to explicitly convert the torch.dtype to the desired type."}
{"number": 8538, "change": "class Module(object):\nuse_while_v2=False\n):\nModule.global_scope.append('while')\n-        if maximum_iterations is not None and maximum_iterations.dtype not in (tf.int32, tf.int64):\n+        if maximum_iterations is not None and maximum_iterations.dtype is not tf.int32:\nmaximum_iterations = tf.dtypes.cast(x=maximum_iterations, dtype=tf.int32)\nif use_while_v2:\nx = while_v2.while_loop(\n", "fix_pattern": "If checking the dtype of a variable is done using `is not` and the dtype is expected to be a specific type, replace `is not` with `is not tf.int32`."}
{"number": 8551, "change": "class PartialFC(Module):\nlogits.backward(grad)\nif total_features.grad is not None:\ntotal_features.grad.detach_()\n-        x_grad: torch.Tensor = torch.zeros_like(features)\n-        x_grad.mul_(self.world_size)\n-\n+        x_grad: torch.Tensor = torch.zeros_like(features, requires_grad=True)\n# feature gradient all-reduce\ndist.reduce_scatter(x_grad, list(total_features.grad.chunk(self.world_size, dim=0)))\n+        x_grad = x_grad * self.world_size\n# backward backbone\nreturn x_grad, loss_v\n", "fix_pattern": "If torch.zeros_like() is used and the tensor requires gradient, add requires_grad=True to the torch.zeros_like() function, and use the multiplication operator (*) instead of the mul_() function."}
{"number": 8686, "change": "class TransfoXLModel(TransfoXLPreTrainedModel):\nelse:\nmask_shift_len = qlen\ndec_attn_mask = (torch.triu(all_ones, 1+mlen)\n-                    + torch.tril(all_ones, -mask_shift_len)).byte()[:, :, None] # -1\n+                    + torch.tril(all_ones, -mask_shift_len)).bool()[:, :, None] # -1\nelse:\ndec_attn_mask = torch.triu(\n-                word_emb.new_ones(qlen, klen), diagonal=1+mlen).byte()[:,:,None]\n+                word_emb.new_ones(qlen, klen), diagonal=1+mlen).bool()[:,:,None]\n\nhids = []\nattentions = []\n", "fix_pattern": "if a byte() type tensor is detected, replace it with bool() type tensor"}
{"number": 8693, "change": "class EarlyStopping(Callback):\nf\" {self.monitor} = {current} {self.order_dict[self.mode]} {self.divergence_threshold}.\"\n\" Signaling Trainer to stop.\"\n)\n-        elif self.monitor_op(current - self.min_delta, self.best_score.to(trainer.lightning_module.device)):\n+        elif self.monitor_op(current - self.min_delta, self.best_score.to(current.device)):\nshould_stop = False\nreason = self._improvement_message(current)\nself.best_score = current\n", "fix_pattern": "If using a tensor in a comparison operation, replace \"self.best_score.to(trainer.lightning_module.device)\" with \"self.best_score.to(current.device)\""}
{"number": 8698, "change": "def tensordot(\nout: Optional[Union[tf.Tensor, tf.Variable]] = None,\n) -> Union[tf.Tensor, tf.Variable]:\n# find type to promote to\n-    dtype = tf.experimental.numpy.promote_types(x1.dtype, x2.dtype)\n+    dtype = ivy.as_native_dtype(ivy.promote_types(x1.dtype, x2.dtype))\n\n# type casting to float32 which is acceptable for tf.tensordot\nx1, x2 = tf.cast(x1, tf.float32), tf.cast(x2, tf.float32)\n", "fix_pattern": "Replace tf.experimental.numpy.promote_types() with ivy.promote_types() and add ivy.as_native_dtype()"}
{"number": 8699, "change": "def log_cosh(y_true, y_pred):\n>>> x = y_pred - y_true\n>>> assert np.allclose(\n...     loss.numpy(),\n-  ...     np.mean(x + np.log(np.exp(-2. * x) + 1.) - math_ops.log(2.), axis=-1),\n+  ...     np.mean(x + np.log(np.exp(-2. * x) + 1.) - tf.math.log(2.), axis=-1),\n...     atol=1e-5)\n\nArgs:\n", "fix_pattern": "if a function from the \"math_ops\" module is detected, replace it with the corresponding function from the \"tf.math\" module."}
{"number": 8738, "change": "class EntityLinker(flair.nn.DefaultClassifier[Sentence, Span]):\n)\n\ndef emb_mean(self, span, embedding_names):\n-        return torch.mean(torch.cat([token.get_embedding(embedding_names) for token in span], 0), 0)\n+        return torch.mean(torch.stack([token.get_embedding(embedding_names) for token in span], 0), 0)\n\ndef _get_data_points_from_sentence(self, sentence: Sentence) -> List[Span]:\nreturn sentence.get_spans(self.label_type)\n", "fix_pattern": "if concatenating tensors using torch.cat(), replace it with torch.stack()"}
{"number": 8745, "change": "def finish_episode():\nrewards = torch.Tensor(rewards)\nrewards = (rewards - rewards.mean()) / (rewards.std() + np.finfo(np.float32).eps)\nfor (log_prob, value), r in zip(saved_actions, rewards):\n-        reward = r - value.data[0, 0]\n+        reward = r - value.data[0]\npolicy_losses.append(-log_prob * reward)\nvalue_losses.append(F.smooth_l1_loss(value, Variable(torch.Tensor([r]))))\noptimizer.zero_grad()\n-    loss = torch.cat(policy_losses).sum() + torch.cat(value_losses).sum()\n+    loss = torch.stack(policy_losses).sum() + torch.stack(value_losses).sum()\nloss.backward()\noptimizer.step()\ndel model.rewards[:]\n", "fix_pattern": "If accessing a specific element of a tensor using indexing, replace `.data[0, 0]` with `.data[0]`. If concatenating tensors using `torch.cat()`, replace it with `torch.stack()`."}
{"number": 8748, "change": "def _get_random_features_initializer(initializer, shape):\nrandom_features_initializer = initializer\nif isinstance(initializer, str):\nif initializer.lower() == 'gaussian':\n-      random_features_initializer = tf.compat.v1.random_normal_initializer(\n-          stddev=1.0)\n+      random_features_initializer = initializers.RandomNormal(stddev=1.0)\nelif initializer.lower() == 'laplacian':\n-      random_features_initializer = tf.compat.v1.constant_initializer(\n+      random_features_initializer = initializers.Constant(\n_get_cauchy_samples(loc=0.0, scale=1.0, shape=shape))\n\nelse:\n", "fix_pattern": "if tf.compat.v1 API call for initializer is detected, replace with initializers module from tf.keras"}
{"number": 8765, "change": "class SyncMultiGPUTrainer(MultiGPUTrainer,\nsuper(SyncMultiGPUTrainer, self)._setup()\ngrad_list = MultiGPUTrainer._multi_tower_grads(\nself.config.tower, lambda: self._get_cost_and_grad()[1])\n+\n+        # debug tower performance:\n+        #ops = [k[0] for k in grad_list[1]] + [k[0] for k in grad_list[0]]\n+        #self.train_op = tf.group(*ops)\n+        #return\n+\ngrads = SyncMultiGPUTrainer._average_grads(grad_list)\ngrads = apply_grad_processors(grads, self.model.get_gradient_processor())\n", "fix_pattern": "This code change involves removing and adding commented lines of code. There is no specific pattern to identify for fixing API method problems in this case."}
{"number": 8824, "change": "def _replace_global_by_local(kwargs):\nif 'collections' in kwargs:\ncollections = kwargs['collections']\nif not collections:\n-        collections = {tf.GraphKeys.GLOBAL_VARIABLES}\n+        collections = {tfv1.GraphKeys.GLOBAL_VARIABLES}\nelse:\ncollections = set(collections.copy())\n-    collections.remove(tf.GraphKeys.GLOBAL_VARIABLES)\n-    collections.add(tf.GraphKeys.LOCAL_VARIABLES)\n+    collections.remove(tfv1.GraphKeys.GLOBAL_VARIABLES)\n+    collections.add(tfv1.GraphKeys.LOCAL_VARIABLES)\nkwargs['collections'] = list(collections)\n", "fix_pattern": "if a deprecated API tf.GraphKeys is detected, replace with tfv1.GraphKeys"}
{"number": 8832, "change": "class OrthogonalRegularizer(Regularizer):\nsize = inputs.shape[1]\nproduct_no_diagonal = product * (1. - tf.eye(size, dtype=inputs.dtype))\nnum_pairs = size * (size - 1.) / 2.\n-    return self.factor * 0.5 * tf.reduce_sum(product_no_diagonal) / num_pairs\n+    return self.factor * 0.5 * tf.reduce_sum(tf.abs(product_no_diagonal)) / num_pairs\n\ndef get_config(self):\nreturn {'factor': float(self.factor), 'mode': self.mode}\n", "fix_pattern": "change tf.reduce_sum(product_no_diagonal) to tf.reduce_sum(tf.abs(product_no_diagonal))"}
{"number": 8901, "change": "def test(data,\n\n# Load model\ngoogle_utils.attempt_download(weights)\n-        model = torch.load(weights, map_location=device)['model'].float().fuse()  # load to FP32\n+        model = torch.load(weights, map_location=device)['model'].float().fuse().to(device)  # load to FP32\nimgsz = check_img_size(imgsz, s=model.stride.max())  # check img_size\n\n# Multi-GPU disabled, incompatible with .half() https://github.com/ultralytics/yolov5/issues/99\n", "fix_pattern": "if a model is loaded and then converted to a specific data type (e.g., float) or fused, add .to(device) to the end of the API call to move the model to the specified device."}
{"number": 8947, "change": "class TorchDiagGaussian(TorchDistributionWrapper):\n@override(ActionDistribution)\ndef __init__(self, inputs, model):\nsuper().__init__(inputs, model)\n-        mean, log_std = torch.chunk(inputs, 2, dim=1)\n+        mean, log_std = torch.chunk(self.inputs, 2, dim=1)\nself.dist = torch.distributions.normal.Normal(mean, torch.exp(log_std))\n\n@override(ActionDistribution)\n", "fix_pattern": "if an attribute or variable is detected instead of a tensor as the first argument in an API call, use self. to access the tensor within the class"}
{"number": 8951, "change": "def clip(\n*,\nout: Optional[torch.Tensor] = None,\n) -> torch.Tensor:\n+    assert torch.all(torch.less(x_min, x_max)), \"Min value must be less than max.\"\nif hasattr(x_min, \"dtype\"):\npromoted_type = torch.promote_types(x_min.dtype, x_max.dtype)\npromoted_type = torch.promote_types(promoted_type, x.dtype)\n", "fix_pattern": "<pattern>: if there is an assert statement checking a condition, add a corresponding error message after the condition"}
{"number": 8997, "change": "def train(args, logdir):\nsteps_per_epoch=hp.train1.steps_per_epoch,\n# session_config=session_conf\n)\n-    ckpt = args.ckpt if args.ckpt else tf.train.latest_checkpoint(logdir)\n+    ckpt = '{}/{}'.format(logdir, args.ckpt) if args.ckpt else tf.train.latest_checkpoint(logdir)\nif ckpt:\ntrain_conf.session_init = SaverRestore(ckpt)\n", "fix_pattern": "if a file path is detected in an API call, use string formatting to concatenate the path with the file name"}
{"number": 9026, "change": "def is_variable(x):\n\n\ndef execute_with_gradients(func, xs, retain_grads=False):\n-    with _tf.GradientTape() as tape:\n+    with _tf.GradientTape(persistent=retain_grads, watch_accessed_variables=False) as tape:\n+        tape.watch(xs)\nfunc_ret = func(xs)\nif isinstance(func_ret, tuple):\ny = func_ret[0]\n", "fix_pattern": "if _tf.GradientTape() is detected, replace it with _tf.GradientTape(persistent=retain_grads, watch_accessed_variables=False) and add tape.watch(xs) at the end of the with statement."}
{"number": 9048, "change": "def test_sequence_tagger_param_selector(results_base_path, tasks_base_path):\n\n@pytest.mark.integration\ndef test_text_classifier_param_selector(results_base_path, tasks_base_path):\n-    corpus = flair.datasets.ClassificationCorpus(tasks_base_path / \"imdb\")\n+    corpus = flair.datasets.ClassificationCorpus(tasks_base_path / \"imdb\", label_type=\"sentiment\")\nlabel_type = \"sentiment\"\n\nsearch_space = SearchSpace()\n\n# document embeddings parameter\n-    search_space.add(Parameter.TRANSFORMER_MODEL, hp.choice, options=[\"albert-base-v1\"])\n+    search_space.add(Parameter.TRANSFORMER_MODEL, hp.choice, options=[\"sshleifer/tiny-distilbert-base-cased\"])\nsearch_space.add(Parameter.LAYERS, hp.choice, options=[\"-1\", \"-2\"])\n\n# training parameter\n", "fix_pattern": "if label_type argument is missing in the API call to flair.datasets.ClassificationCorpus(), add label_type argument with the correct value"}
{"number": 9098, "change": "\"\\n\",\n\"\\n\",\n\"\\\"\\\"\\\"fm part\\\"\\\"\\\"\\n\",\n-    \"fm_first_order = tf.nn.embedding_lookup(weights['feature_embeddings'],feat_index)\\n\",\n+    \"fm_first_order = tf.nn.embedding_lookup(weights['feature_bias'],feat_index)\\n\",\n\"fm_first_order = tf.reduce_sum(tf.multiply(fm_first_order,reshaped_feat_value),2)\\n\",\n\"\\n\",\n\"summed_features_emb = tf.reduce_sum(embeddings,1)\\n\",\n", "fix_pattern": "if tf.nn.embedding_lookup() is used on weights['feature_embeddings'], replace it with weights['feature_bias']"}
{"number": 9197, "change": "class Seq2SeqModel(ModelBase):\nif \"embedding\" in variable.name:\ntmp = tf.clip_by_norm(\ngradient.values, self.params[\"optimizer.clip_embed_gradients\"])\n-        grad = tf.IndexedSlices(tmp, gradient.indices, gradient.dense_shape)\n+        gradient = tf.IndexedSlices(tmp, gradient.indices, gradient.dense_shape)\nclipped_gradients.append(gradient)\nvariables.append(variable)\nreturn list(zip(clipped_gradients, variables))\n", "fix_pattern": "if an API method call is detected without any changes, remove it."}
{"number": 9236, "change": "def median(\nkeepdims: Optional[bool] = False,\nout: Optional[torch.tensor] = None,\n) -> torch.tensor:\n+    temp = input\nif hasattr(axis, \"__iter__\"):\nfor dim in axis:\n-            input = torch.median(\n-                input,\n+            temp = torch.median(\n+                temp,\ndim=dim,\nkeepdim=keepdims,\n)[0]\n", "fix_pattern": "if an API call is made on a variable, assign the variable to a temp variable and make the API call on the temp variable."}
{"number": 9246, "change": "class Dropout(Layer):\n\nskip_dropout = tf.math.logical_not(x=Module.retrieve_tensor(name='update'))\nzero = tf.constant(value=0.0, dtype=util.tf_dtype(dtype='float'))\n-        skip_dropout = tf.math.logical_or(x=apply_dropout, y=tf.math.equal(x=rate, y=zero))\n+        skip_dropout = tf.math.logical_or(x=skip_dropout, y=tf.math.equal(x=rate, y=zero))\nreturn self.cond(pred=skip_dropout, true_fn=no_dropout, false_fn=apply_dropout)\n", "fix_pattern": "if a logical operation is performed on a variable with the condition, change the variable name to the left side of the equality"}
{"number": 9260, "change": "def test_cpu_amp_precision_context_manager(tmpdir):\nassert not hasattr(plugin, \"scaler\")\ncontext_manager = plugin.autocast_context_manager()\nassert isinstance(context_manager, torch.cpu.amp.autocast)\n-    assert context_manager.dtype == torch.bfloat16\n+    assert context_manager.fast_dtype == torch.bfloat16\n\n\n@pytest.mark.skipif(not _TORCH_CPU_AMP_AVAILABLE, reason=\"Torch CPU AMP is not available.\")\n", "fix_pattern": "if a dtype detection API is detected, change it to the equivalent dtype API"}
{"number": 9270, "change": "class Model(ModelDesc):\nzc = tf.one_hot(ids, 10, name='zc_train')\nzc = tf.placeholder_with_default(zc, [None, 10], name='zc')\n\n-        z = tf.random_uniform(tf.pack([tf.shape(zc)[0], 90]), -1, 1, name='z_train')\n+        z = tf.random_uniform(tf.stack([tf.shape(zc)[0], 90]), -1, 1, name='z_train')\nz = tf.placeholder_with_default(z, [None, 90], name='z')\n-        z = tf.concat(1, [zc, z], name='fullz')\n+        z = tf.concat_v2([zc, z], 1, name='fullz')\n\nwith argscope([Conv2D, Deconv2D, FullyConnected],\nW_init=tf.truncated_normal_initializer(stddev=0.02)):\n", "fix_pattern": "if deprecated API tf.pack() or tf.concat() detected, replace with tf.stack() or tf.concat_v2() respectively"}
{"number": 9328, "change": "class SignatureDict(NestedDict):\nassert isinstance(arg, TensorDict)\nargs.append(spec.kwargs_to_args(kwargs=arg))\nelse:\n-                assert isinstance(arg, (tf.IndexedSlices, tf.Tensor, tf.Variable))\n+                assert isinstance(arg, (tf.IndexedSlices, tf.Tensor, tf.Variable)), (name, spec, arg)\nargs.append(arg)\nreturn args\n", "fix_pattern": "if an assert statement is used to check the type of an argument, add ', (name, spec, arg)' to the end of the assert statement"}
{"number": 9412, "change": "def collect_env():\nenv_info['GCC'] = gcc\n\nenv_info['PyTorch'] = torch.__version__\n-    env_info['PyTorch compiling details'] = torch.__config__.show()\n+    env_info['PyTorch compiling details'] = get_build_config()\n\nenv_info['TorchVision'] = torchvision.__version__\n", "fix_pattern": "If accessing compilation details using `torch.__config__.show()` is detected, replace it with `get_build_config()`."}
{"number": 9490, "change": "class LabelSmoother:\n# will ignore them in any case.\nlabels.clamp_min_(0)\nnll_loss = log_probs.gather(dim=-1, index=labels)\n-        smoothed_loss = log_probs.sum(dim=-1, keepdim=True)\n+        # works for fp16 input tensor too, by internally upcasting it to fp32\n+        smoothed_loss = log_probs.sum(dim=-1, keepdim=True, dtype=torch.float32)\n\nnll_loss.masked_fill_(padding_mask, 0.0)\nsmoothed_loss.masked_fill_(padding_mask, 0.0)\n", "fix_pattern": "If the dtype parameter is used in the API call with a value of torch.float32, it means that the API call works for fp16 input tensors as well by internally upcasting them to fp32."}
{"number": 9535, "change": "def prod(\ndtype = tf.uint64\nif ivy.exists(out):\nreturn ivy.inplace_update(\n-            out, tf.experimental.numpy.prod(x, axis=axis, keepdims=keepdims)\n+            out,\n+            tf.experimental.numpy.prod(x, axis=axis, dtype=dtype, keepdims=keepdims),\n)\nelse:\nreturn tf.experimental.numpy.prod(x, axis, dtype, keepdims)\n", "fix_pattern": "if tf.experimental.numpy.prod() is used without specifying the dtype parameter, add dtype=dtype to the API call."}
{"number": 9575, "change": "def is_cuda_available() -> bool:\nUnlike :func:`torch.cuda.is_available`, this function will do its best not to create a CUDA context for fork\nsupport, if the platform allows it.\n\"\"\"\n-    if \"fork\" not in torch.multiprocessing.get_all_start_methods():\n+    if \"fork\" not in torch.multiprocessing.get_all_start_methods() or _is_forking_disabled():\nreturn torch.cuda.is_available()\nwith multiprocessing.get_context(\"fork\").Pool(1) as pool:\nreturn pool.apply(torch.cuda.is_available)\n", "fix_pattern": "if a check for \"fork\" not in torch.multiprocessing.get_all_start_methods() is detected, add or _is_forking_disabled() to the condition"}
{"number": 9631, "change": "class ConditionalDetrModelIntegrationTests(unittest.TestCase):\nresults = feature_extractor.post_process_object_detection(\noutputs, threshold=0.3, target_sizes=[image.size[::-1]]\n)[0]\n-        expected_scores = torch.tensor([0.8330, 0.8313, 0.8039, 0.6829, 0.5355])\n+        expected_scores = torch.tensor([0.8330, 0.8313, 0.8039, 0.6829, 0.5355]).to(torch_device)\nexpected_labels = [75, 17, 17, 75, 63]\n-        expected_slice_boxes = torch.tensor([38.3089, 72.1022, 177.6293, 118.4512])\n+        expected_slice_boxes = torch.tensor([38.3089, 72.1022, 177.6293, 118.4512]).to(torch_device)\n\nself.assertEqual(len(results[\"scores\"]), 5)\nself.assertTrue(torch.allclose(results[\"scores\"], expected_scores, atol=1e-4))\n", "fix_pattern": "if a tensor is created and not assigned to any device, add .to(device) at the end of each tensor creation line."}
{"number": 9633, "change": "class GraphVarParam(HyperParam):\nself._readable_name, self.var_name = get_op_var_name(name)\n\ndef setup_graph(self):\n-        all_vars = tf.all_variables()\n+        try:\n+            all_vars = tf.global_variables()\n+        except:\n+            # TODO\n+            all_vars = tf.all_variables()\n+\nfor v in all_vars:\nif v.name == self.var_name:\nself.var = v\n", "fix_pattern": "if an API call to tf.all_variables() is detected, replace it with tf.global_variables(). If an exception is raised, handle it appropriately."}
{"number": 9636, "change": "class FAUST(Dataset):\nindex = self.index[:, i]\nweight = torch.FloatTensor(index.size(1)).fill_(1)\ninput = torch.FloatTensor(position.size(0)).fill_(1)\n-        adj = torch.sparse.FloatTensor(index, weight, torch.Size([75, 75]))\n+        adj = torch.sparse.FloatTensor(index, weight, torch.Size([6890, 6890]))\ndata = (input, adj, position)\n\nif self.correspondence:\n", "fix_pattern": "The pattern for fixing the API method problem in the given code change is to replace the torch.Size() with the appropriate size."}
{"number": 9698, "change": "class TestElmo(AllenNlpTestCase):\ndataset = Dataset(instances)\nvocab = Vocabulary()\ndataset.index_instances(vocab)\n-        character_ids = dataset.as_array_dict()['elmo']['character_ids']\n+        character_ids = dataset.as_tensor_dict()['elmo']['character_ids']\n\n-        output = elmo(Variable(torch.from_numpy(character_ids)))\n+        output = elmo(character_ids)\nelmo_representations = output['elmo_representations']\nmask = output['mask']\n", "fix_pattern": "if the dataset is a dictionary, replace as_array_dict() with as_tensor_dict() and remove the Variable() wrapper when passing the input to the model."}

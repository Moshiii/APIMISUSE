[
    {
        "number": 5,
        "change": [
            "class AlbertEmbeddings(nn.Module):",
            "# position_ids (1, len position emb) is contiguous in memory and exported when serialized",
            "self.register_buffer(\"position_ids\", torch.arange(config.max_position_embeddings).expand((1, -1)))",
            "self.position_embedding_type = getattr(config, \"position_embedding_type\", \"absolute\")",
            "-        if version.parse(torch.__version__) > version.parse(\"1.6.0\"):",
            "+        if is_torch_greater_than_1_6:",
            "self.register_buffer(",
            "\"token_type_ids\",",
            "torch.zeros(self.position_ids.size(), dtype=torch.long),"
        ],
        "comments": "add condition check for version fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 7,
        "change": [
            "def test_quantile():",
            "",
            "",
            "def test_pi():",
            "-    x = torch.empty(1000).log_normal_(0, 1)",
            "+    x = torch.randn(1000).exp()",
            "assert_equal(pi(x, prob=0.8), quantile(x, probs=[0.1, 0.9]))"
        ],
        "comments": "change API call for math fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 8,
        "change": [
            "class TPUAccelerator(Accelerator):",
            "Return:",
            "A tensor of shape (world_size, batch, ...)",
            "\"\"\"",
            "-        return xm.all_gather(tensor, group=group, sync_grads=sync_grads)",
            "+        # todo: Add support for backward with all_gather",
            "+        if torch.distributed.is_initialized():",
            "+            return xm.all_gather(tensor, group=group, sync_grads=sync_grads)",
            "+        return tensor"
        ],
        "comments": "add condition check for state fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 12,
        "change": [
            "def get_rotation_matrix2d(",
            "",
            "# create output tensor",
            "batch_size: int = center.shape[0]",
            "-    one = torch.tensor(1.).to(center.device)",
            "+    one = torch.tensor(1., device=center.device, dtype=center.dtype)",
            "M: torch.Tensor = torch.zeros(",
            "batch_size, 2, 3, device=center.device, dtype=center.dtype)",
            "M[..., 0:2, 0:2] = scaled_rotation"
        ],
        "comments": "add param for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 15,
        "change": [
            "class Trainer(TrainerBase):",
            "break",
            "sys.stdout.flush()",
            "",
            "-        model.load_state_dict(torch.load(best_model_path))",
            "+        if rank == 0:",
            "+            model.load_state_dict(torch.load(best_model_path))",
            "return model, best_metric",
            "",
            "def _run_epoch("
        ],
        "comments": "add condition check for state fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 23,
        "change": [
            "class TacotronTrainTest(unittest.TestCase):",
            "optimizer = optim.Adam(model.parameters(), lr=c.lr)",
            "for i in range(5):",
            "mel_out, linear_out, align, stop_tokens = model.forward(",
            "-                input, input_lengths, mel_spec)",
            "+                input, input_lengths, mel_spec, speaker_ids)",
            "optimizer.zero_grad()",
            "loss = criterion(mel_out, mel_spec, mel_lengths)",
            "stop_loss = criterion_st(stop_tokens, stop_targets)"
        ],
        "comments": "add param for version fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 24,
        "change": [
            "def evaluate(args, model, tokenizer, prefix=\"\", test=False):",
            "eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)",
            "",
            "# multi-gpu evaluate",
            "-        if args.n_gpu > 1:",
            "+        if args.n_gpu > 1 and not isinstance(model, torch.nn.DataParallel):",
            "model = torch.nn.DataParallel(model)",
            "",
            "# Eval!"
        ],
        "comments": "add condition check for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 25,
        "change": [
            "class TestMotionBlur:",
            ") -> torch.Tensor:",
            "return kornia.filters.motion_blur(input, ksize, angle, direction)",
            "",
            "-        img = torch.rand(2, 3, 4, 5)",
            "+        img = torch.rand(2, 3, 4, 5).to(device)",
            "ksize = 5",
            "angle = 65.",
            "direction = .1"
        ],
        "comments": "add API call for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 30,
        "change": [
            "class _Seq2VecWrapper:",
            "def from_params(self, params: Params) -> PytorchSeq2VecWrapper:",
            "if not params.pop('batch_first', True):",
            "raise ConfigurationError(\"Our encoder semantics assumes batch is always first!\")",
            "-        params['batch_first'] = True",
            "+        if self._module_class in self.PYTORCH_MODELS:",
            "+            params['batch_first'] = True",
            "module = self._module_class(**params.as_dict())",
            "return PytorchSeq2VecWrapper(module)"
        ],
        "comments": "add condition check for math fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 31,
        "change": [
            "class StableDiffusionProcessingTxt2Img(StableDiffusionProcessing):",
            "return samples",
            "",
            "x = create_random_tensors([opt_C, self.firstphase_height // opt_f, self.firstphase_width // opt_f], seeds=seeds, subseeds=subseeds, subseed_strength=self.subseed_strength, seed_resize_from_h=self.seed_resize_from_h, seed_resize_from_w=self.seed_resize_from_w, p=self)",
            "-        samples = self.sampler.sample(self, x, conditioning, unconditional_conditioning, image_conditioning=self.create_dummy_mask(x))",
            "+        samples = self.sampler.sample(self, x, conditioning, unconditional_conditioning, image_conditioning=self.create_dummy_mask(x, first_phase=True))",
            "",
            "samples = samples[:, :, self.truncate_y//2:samples.shape[2]-self.truncate_y//2, self.truncate_x//2:samples.shape[3]-self.truncate_x//2]"
        ],
        "comments": "add param for argument fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 40,
        "change": [
            "def makenp(x, modality=None):",
            "",
            "def pytorch_np(x, modality):",
            "import torch",
            "-    if isinstance(x, torch.autograd.variable.Variable):",
            "+    if isinstance(x, torch.autograd.Variable):",
            "x = x.data",
            "x = x.cpu().numpy()",
            "if modality == 'IMG':"
        ],
        "comments": "update param for refactor fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 43,
        "change": [
            "class TrainingTypePlugin(ABC):",
            "self.lr_schedulers = schedulers",
            "",
            "def _move_optimizer_state(self, device: Optional[torch.device] = None) -> None:",
            "-        \"\"\"Moves the state of the optimizers to the GPU if needed.\"\"\"",
            "-        device = device or self.root_device",
            "+        \"\"\"Moves the state of the optimizers to the appropriate device if needed.\"\"\"",
            "for opt in self.optimizers:",
            "for p, v in opt.state.items():",
            "-                opt.state[p] = apply_to_collection(v, torch.Tensor, move_data_to_device, device)",
            "+                # `self.root_device` would raise error if called outside the spawn process",
            "+                # while training on 8 and more cores.",
            "+                opt.state[p] = apply_to_collection(v, torch.Tensor, move_data_to_device, device or self.root_device)",
            "",
            "def optimizer_state(self, optimizer: Optimizer) -> Dict[str, Tensor]:",
            "\"\"\"Returns state of an optimizer."
        ],
        "comments": "change param for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 50,
        "change": [
            "class GraphConv(MessagePassing):",
            "self.lin.reset_parameters()",
            "",
            "def forward(self, x, edge_index):",
            "+        if isinstance(x, Tensor):",
            "+            x = (x, x)",
            "return self.propagate(edge_index, x=(self.lin(x[0]), x[1]))"
        ],
        "comments": "add condition check for shape fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 53,
        "change": [
            "class Trainer:",
            ").to(self.args.device)",
            "",
            "elif is_sagemaker_dp_enabled():",
            "-            model = DDP(model, device_ids=[dist.get_local_rank()], broadcast_buffers=False)",
            "+            model = nn.parallel.DistributedDataParallel(",
            "+                model, device_ids=[int(os.getenv(\"SMDATAPARALLEL_LOCAL_RANK\"))]",
            "+            )",
            "elif self.args.local_rank != -1:",
            "kwargs = {}",
            "if self.args.ddp_find_unused_parameters is not None:"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 55,
        "change": [
            "class RNN(torch.nn.Module):",
            "if not isinstance(ilens, torch.Tensor):",
            "ilens = torch.tensor(ilens)",
            "xs_pack = pack_padded_sequence(xs_pad, ilens.cpu(), batch_first=True)",
            "-        self.nbrnn.flatten_parameters()",
            "+        if self.training:",
            "+            self.nbrnn.flatten_parameters()",
            "if prev_state is not None and self.nbrnn.bidirectional:",
            "# We assume that when previous state is passed,",
            "# it means that we're streaming the input"
        ],
        "comments": "add condition check for state fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 56,
        "change": [
            "class TFXLNetModelTest(TFModelTesterMixin, unittest.TestCase):",
            "# Send to model",
            "loss = model(tuple_input[:-1])[0]",
            "",
            "-                self.assertEqual(loss.shape, [loss_size])",
            "+                self.assertEqual(loss.shape.as_list(), expected_loss_size)",
            "",
            "",
            "@require_tf"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 58,
        "change": [
            "def sigmoid_example(design):",
            "torch.tensor([[-1.5, 0.5], [1.5, 0.]])",
            "),",
            "(",
            "-        known_covariance_linear_model(torch.tensor([1., -1.]), torch.tensor(10.), torch.tensor(1.)),",
            "+        known_covariance_linear_model(torch.tensor([1., -1.]), torch.tensor([10., 10.]), torch.tensor(1.)),",
            "nz_lm_2p_10_10_1,",
            "torch.tensor([[-1., 0.5], [2.5, -2.]])",
            "),"
        ],
        "comments": "change param for shape fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Argument Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Argument Error"
    },
    {
        "number": 59,
        "change": [
            "class DetaModel(DetaPreTrainedModel):",
            "scale = 2 * math.pi",
            "",
            "dim_t = torch.arange(num_pos_feats, dtype=torch.float32, device=proposals.device)",
            "-        dim_t = temperature ** (2 * (dim_t // 2) / num_pos_feats)",
            "+        dim_t = temperature ** (2 * torch.div(dim_t, 2) / num_pos_feats)",
            "# batch_size, num_queries, 4",
            "proposals = proposals.sigmoid() * scale",
            "# batch_size, num_queries, 4, 128"
        ],
        "comments": "add API call for math fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 61,
        "change": [
            "class LxmertAttention(nn.Module):",
            "attention_scores = attention_scores + attention_mask",
            "",
            "# Normalize the attention scores to probabilities.",
            "-        attention_probs = nn.Softmax(dim=-1)(attention_scores)",
            "+        attention_probs = nn.functional.softmax(attention_scores, dim=-1)",
            "",
            "# This is actually dropping out entire tokens to attend to, which might",
            "# seem a bit unusual, but is taken from the original Transformer paper."
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Deprecation Management Error"
    },
    {
        "number": 68,
        "change": [
            "class Gru(TransformationBase):",
            "",
            "def tf_apply(self, x, sequence_length=None):",
            "x, state = tf.nn.dynamic_rnn(",
            "-            cell=self.cell, inputs=x, sequence_length=sequence_length, dtype=tf.float32,",
            "+            cell=self.cell, inputs=x, sequence_length=sequence_length, initial_state=None,",
            "+            dtype=util.tf_dtype(dtype='float'),",
            "# Weird TensorFlow behavior? (https://github.com/tensorflow/tensorflow/issues/15874)",
            "parallel_iterations=(self.input_spec['shape'][0] + 1)",
            ")"
        ],
        "comments": "add param for argument fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 71,
        "change": [
            "class DeepSpeedSelfAttention(nn.Module):",
            "data_type_fp = torch.half if config.fp16 else torch.float",
            "self.config.layer_id = DeepSpeedSelfAttention.num_layers",
            "DeepSpeedSelfAttention.num_layers = DeepSpeedSelfAttention.num_layers + 1",
            "-        device = torch.cuda.current_device() if config.bigscience_bloom else 'cpu'",
            "+        device = torch.cuda.current_device()  #if config.bigscience_bloom else 'cpu'",
            "qkv_size_per_partition = (self.config.hidden_size // self.config.mp_size) * 3",
            "self.attn_qkvw = nn.Parameter(torch.empty(self.config.hidden_size,",
            "qkv_size_per_partition,"
        ],
        "comments": "remove condition check for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 76,
        "change": [
            "def main(args):",
            "bob_decision = Marginal(Search(bob))",
            "",
            "# Here Alice and Bob slightly prefer one location over the other a priori",
            "-    shared_preference = Variable(torch.Tensor([args.preference]))",
            "+    shared_preference = torch.tensor([args.preference])",
            "",
            "bob_depth = args.depth",
            "num_samples = args.num_samples"
        ],
        "comments": "remove API call for version fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 81,
        "change": [
            "class Planetoid(Dataset):",
            "# Create unweighted sparse adjacency matrix.",
            "weight = torch.ones(index.size(1))",
            "n = input.size(0)",
            "-        adj = torch.sparse.FloatTensor(index, weight, torch.Size([n, n]))",
            "+        adj = SparseTensor(index, weight, torch.Size([n, n]))",
            "",
            "# Bundle graph to data object.",
            "-        self.data = Data(input, adj, position=None, target=target)",
            "+        self.data = Data(input, adj, position=None, target=target.long())",
            "",
            "def __getitem__(self, index):",
            "data = self.data"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 84,
        "change": [
            "class Tacotron2(TTSInterface, torch.nn.Module):",
            "",
            "def __init__(self, idim, odim, args):",
            "super(Tacotron2, self).__init__()",
            "+        torch.nn.Module.__init__(self)",
            "# store hyperparameters",
            "self.idim = idim",
            "self.odim = odim"
        ],
        "comments": "add API call for state fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 85,
        "change": [
            "\"import sys\\n\",",
            "\"sys.path.append(f'{os.getcwd()}/SentEval')\\n\",",
            "\"\\n\",",
            "-        \"import tensorflow_hub as hub\\n\",",
            "\"import tensorflow as tf\\n\",",
            "+        \"\\n\",",
            "+        \"# Prevent TF from claiming all GPU memory so there is some left for pytorch.\\n\",",
            "+        \"gpus = tf.config.list_physical_devices('GPU')\\n\",",
            "+        \"if gpus:\\n\",",
            "+        \"  # Memory growth needs to be the same across GPUs.\\n\",",
            "+        \"  for gpu in gpus:\\n\",",
            "+        \"    tf.config.experimental.set_memory_growth(gpu, True)\\n\",",
            "+        \"\\n\",",
            "+        \"import tensorflow_hub as hub\\n\",",
            "\"import tensorflow_text\\n\",",
            "\"import senteval\\n\",",
            "\"import time\\n\","
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 86,
        "change": [
            "class Encoder(torch.nn.Module):",
            "self.embed = Conv2dSubsampling(idim, attention_dim, dropout_rate)",
            "elif input_layer == \"embed\":",
            "self.embed = torch.nn.Sequential(",
            "-                torch.nn.Embedding(idim, attention_dim),",
            "+                torch.nn.Embedding(idim, attention_dim, padding_idx=padding_idx),",
            "pos_enc_class(attention_dim, positional_dropout_rate)",
            ")",
            "elif isinstance(input_layer, torch.nn.Module):"
        ],
        "comments": "add param for argument fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 88,
        "change": [
            "def create_checkerboard(h, w, nw):",
            "",
            "",
            "# TODO: Isn't this function duplicated with eye_like?",
            "-def create_eye_batch(batch_size, eye_size):",
            "+def create_eye_batch(batch_size, eye_size, device=None, dtype=None):",
            "\"\"\"Creates a batch of identity matrices of shape Bx3x3",
            "\"\"\"",
            "-    return torch.eye(eye_size).view(",
            "+    return torch.eye(eye_size, device=device, dtype=dtype).view(",
            "1, eye_size, eye_size).expand(batch_size, -1, -1)"
        ],
        "comments": "add param for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 91,
        "change": [
            "class TransformerSeparator(AbsSeparator):",
            "",
            "# if complex spectrum,",
            "if isinstance(input, ComplexTensor) or (",
            "-            is_torch_1_8_plus and torch.is_complex(input)",
            "+            is_torch_1_9_plus and torch.is_complex(input)",
            "):",
            "feature = abs(input)",
            "else:"
        ],
        "comments": "change condition check for version fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Condition",
        "Action_Element": "Replace API Condition",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 97,
        "change": [
            "def _get_ort_session_options() -> ort.SessionOptions:",
            "if not torch.cuda.is_available():",
            "sess_options.execution_mode = ort.ExecutionMode.ORT_PARALLEL",
            "sess_options.inter_op_num_threads = 1",
            "-        sess_options.intra_op_num_threads = max(torch.get_num_threads(), 1)",
            "+        sess_options.intra_op_num_threads = max(",
            "+            int(",
            "+                os.environ.get(\"NEBULLVM_THREADS_PER_MODEL\")",
            "+                or torch.get_num_threads()",
            "+            ),",
            "+            1,",
            "+        )",
            "return sess_options"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 100,
        "change": [
            "class TFFlaubertMainLayer(tf.keras.layers.Layer):",
            "tensor_normalized = self.layer_norm2[i](tensor)",
            "tensor = tensor + self.ffns[i](tensor_normalized)",
            "",
            "-            tensor = tensor * mask[..., tf.newaxis]",
            "+            tensor = tensor * tf.expand_dims(mask, axis=-1)",
            "",
            "# Add last hidden state",
            "if inputs[\"output_hidden_states\"]:"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 101,
        "change": [
            "def _replace_global_by_local(kwargs):",
            "if 'collections' in kwargs:",
            "collections = kwargs['collections']",
            "if not collections:",
            "-        collections = set(tf.GraphKeys.GLOBAL_VARIABLES)",
            "+        collections = {tf.GraphKeys.GLOBAL_VARIABLES}",
            "else:",
            "collections = set(collections.copy())",
            "collections.remove(tf.GraphKeys.GLOBAL_VARIABLES)"
        ],
        "comments": "change API call for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 103,
        "change": [
            "class ReformerLayer(nn.Module):",
            "\"\"\"",
            "# randomize seeds",
            "# use cuda generator if available",
            "-        if len(torch.cuda.default_generators) > 0:",
            "+        if hasattr(torch.cuda, \"default_generators\") and len(torch.cuda.default_generators) > 0:",
            "# GPU",
            "device_idx = torch.cuda.current_device()",
            "self.feed_forward_seed = torch.cuda.default_generators[device_idx].seed()"
        ],
        "comments": "change condition check for null fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 104,
        "change": [
            "def get_projective_transform(center: torch.Tensor, angles: torch.Tensor) -> torc",
            "",
            "# create rotation matrix",
            "angle_axis_rad: torch.Tensor = K.deg2rad(angles)",
            "-    rmat: torch.Tensor = K.angle_axis_to_rotation_matrix(angle_axis_rad)  # Bx3x3",
            "+    rmat: torch.Tensor = K.angle_axis_to_rotation_matrix(angle_axis_rad) * scales.view(-1, 1, 1)  # Bx3x3",
            "",
            "# define matrix to move forth and back to origin",
            "from_origin_mat = torch.eye(4)[None].repeat(rmat.shape[0], 1, 1).type_as(center)  # Bx4x4"
        ],
        "comments": "add API call for shape fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 105,
        "change": [
            "class FQETorchModel:",
            "q_values, _ = self.q_model({\"obs\": obs}, [], None)",
            "if actions is not None:",
            "actions = torch.tensor(actions, device=self.device, dtype=int)",
            "-            q_values = torch.gather(q_values, -1, actions.unsqueeze(-1)).squeeze()",
            "+            q_values = torch.gather(q_values, -1, actions.unsqueeze(-1)).squeeze(-1)",
            "return q_values.detach()",
            "",
            "def estimate_v("
        ],
        "comments": "add param for math fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 107,
        "change": [
            "class ModelCatalog:",
            "model_name (str): Name to register the model under.",
            "model_class (type): Python class of the model.",
            "\"\"\"",
            "-        if issubclass(model_class, tf.keras.Model):",
            "-            deprecation_warning(old=\"register_custom_model\", error=False)",
            "+        if tf is not None:",
            "+            if issubclass(model_class, tf.keras.Model):",
            "+                deprecation_warning(old=\"register_custom_model\", error=False)",
            "_global_registry.register(RLLIB_MODEL, model_name, model_class)",
            "",
            "@staticmethod"
        ],
        "comments": "add condition check for refactor fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 109,
        "change": [
            "class DLA(nn.Module):",
            "if self.drop_rate > 0.:",
            "x = F.dropout(x, p=self.drop_rate, training=self.training)",
            "x = self.fc(x)",
            "-        if not self.global_pool.is_identity():",
            "-            x = x.flatten(1)  # conv classifier, flatten if pooling isn't pass-through (disabled)",
            "+        x = self.flatten(x)",
            "return x"
        ],
        "comments": "remove condition check for shape fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 110,
        "change": [
            "class OnlineLinearRegression(tf.Module if tf else object):",
            "x = tf.squeeze(x, axis=0)",
            "y = y[0]",
            "self.time += 1",
            "-        self.delta_f += y * x",
            "+        self.delta_f += tf.cast(y, tf.float32) * x",
            "self.delta_b += tf.tensordot(x, x, axes=0)",
            "# Can follow an update schedule if not doing sherman morison updates",
            "if self.time % self.update_schedule == 0:"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 112,
        "change": [
            "class Trainer(",
            "",
            "results = self.predict_loop.on_predict_epoch_end()",
            "self.predict_loop.on_predict_end()",
            "+",
            "+        # re-enable grads",
            "+        torch.set_grad_enabled(True)",
            "+",
            "return results",
            "",
            "def run_sanity_check(self, ref_model):"
        ],
        "comments": "add API call for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 113,
        "change": [
            "def filter2d(",
            "input = input.view(-1, tmp_kernel.size(0), input.size(-2), input.size(-1))",
            "",
            "# convolve the tensor with the kernel.",
            "-    output = F.conv2d(input, tmp_kernel, groups=tmp_kernel.size(0), padding=0, stride=1)",
            "+    # NOTE: type(...) to fix getting `torch.bfloat16` type.",
            "+    # TODO: @johnnv1, fix it through the Augmentation Base.",
            "+    output = F.conv2d(input, tmp_kernel, groups=tmp_kernel.size(0), padding=0, stride=1).type(input.dtype)",
            "",
            "if padding == 'same':",
            "out = output.view(b, c, h, w)"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 114,
        "change": [
            "def remainder(",
            "res_floored = torch.where(res >= 0, torch.floor(res), torch.ceil(res))",
            "diff = res - res_floored",
            "diff, x2 = ivy.promote_types_of_inputs(diff, x2)",
            "-        return torch.mul(diff, x2, out=out)",
            "+        return torch.mul(diff, x2, out=out).to(x1.dtype)",
            "return torch.remainder(x1, x2, out=out)"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 115,
        "change": [
            "class GoalOrientedBotNetwork(TFModel):",
            "name='features')",
            "self._action = tf.placeholder(tf.int32, [1, None],",
            "name='ground_truth_action')",
            "-        self._action_mask = tf.placeholder(tf.float32, [1, None, self.n_actions],",
            "+        self._action_mask = tf.placeholder(tf.float32, [None, None, self.n_actions],",
            "name='action_mask')",
            "",
            "def _build_body(self):"
        ],
        "comments": "change param for math fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 116,
        "change": [
            "class EpsilonGreedy(Exploration):",
            "torch.multinomial(random_valid_action_logits, 1), axis=1)",
            "# Pick either random or greedy.",
            "action = torch.where(",
            "-                torch.empty((batch_size, )).uniform_() < epsilon,",
            "+                torch.empty(",
            "+                    (batch_size, )).uniform_().to(self.device) < epsilon,",
            "random_actions, exploit_action)",
            "",
            "return action, action_logp"
        ],
        "comments": "add API call for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 118,
        "change": [
            "class Delta(TorchDistribution):",
            "",
            "def expand(self, batch_shape):",
            "validate_args = self.__dict__.get('_validate_args')",
            "+        batch_shape = torch.Size(batch_shape)",
            "v = self.v.expand(batch_shape + self.event_shape)",
            "log_density = self.log_density.expand(batch_shape)",
            "return Delta(v, log_density, self.event_dim, validate_args=validate_args)"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 119,
        "change": [
            "def main():",
            "",
            "pruner = AGP_Pruner(model, configure_list)",
            "model = pruner.compress()",
            "-",
            "+    model = model.to(device)",
            "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)",
            "for epoch in range(10):",
            "pruner.update_epoch(epoch)",
            "print('# Epoch {} #'.format(epoch))",
            "train(model, device, train_loader, optimizer)",
            "test(model, device, test_loader)",
            "-    pruner.export_model('model.pth', 'mask.pth', 'model.onnx', [1, 1, 28, 28])",
            "+    pruner.export_model('model.pth', 'mask.pth', 'model.onnx', [1, 1, 28, 28], device)",
            "",
            "",
            "if __name__ == '__main__':"
        ],
        "comments": "add API call for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 120,
        "change": [
            "class TestBidirectionalLanguageModelTransformer(AllenNlpTestCase):",
            "input_dim=32, hidden_dim=64, num_layers=2",
            ")",
            "",
            "-        mask = torch.ones(3, 6).int()",
            "-        mask[0, 3:] = 0",
            "-        mask[1, 5:] = 0",
            "+        mask = torch.ones(3, 6).bool()",
            "+        mask[0, 3:] = False",
            "+        mask[1, 5:] = False",
            "",
            "forward_mask, backward_mask = transformer_encoder.get_attention_masks(mask)"
        ],
        "comments": "change API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 121,
        "change": [
            "from ray.air.config import ScalingConfig",
            "",
            "",
            "def mnist_dataset(batch_size: int) -> tf.data.Dataset:",
            "-    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()",
            "+    with FileLock(os.path.expanduser(\"~/.mnist_lock\")):",
            "+        (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()",
            "# The `x` arrays are in uint8 and have values in the [0, 255] range.",
            "# You need to convert them to float32 with values in the [0, 1] range.",
            "x_train = x_train / np.float32(255)"
        ],
        "comments": "add API call for state fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 122,
        "change": [
            "def rnn_model(X, y):",
            "# Given encoding of RNN, take encoding of last step (e.g hidden size of the",
            "# neural network of last step) and pass it as features for logistic",
            "# regression over output classes.",
            "-    return skflow.models.logistic_regression(encoding[-1], y)",
            "+    return skflow.models.logistic_regression(encoding, y)",
            "",
            "classifier = skflow.TensorFlowEstimator(model_fn=rnn_model, n_classes=15,",
            "steps=1000, optimizer='Adam', learning_rate=0.01, continue_training=True)"
        ],
        "comments": "change param for math fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 126,
        "change": [
            "def main_fun(argv, ctx):",
            "grads = average_gradients(tower_grads)",
            "",
            "# Add a summary to track the learning rate.",
            "-      summaries.append(tf.scalar_summary('learning_rate', lr))",
            "+      summaries.append(tf.summary.scalar('learning_rate', lr))",
            "",
            "# Add histograms for gradients.",
            "for grad, var in grads:",
            "if grad is not None:",
            "summaries.append(",
            "-              tf.histogram_summary(var.op.name + '/gradients', grad))",
            "+              tf.summary.histogram(var.op.name + '/gradients', grad))",
            "",
            "# Apply the gradients to adjust the shared variables.",
            "apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)",
            "",
            "# Add histograms for trainable variables.",
            "for var in tf.trainable_variables():",
            "-        summaries.append(tf.histogram_summary(var.op.name, var))",
            "+        summaries.append(tf.summary.histogram(var.op.name, var))",
            "",
            "# Track the moving averages of all trainable variables.",
            "variable_averages = tf.train.ExponentialMovingAverage("
        ],
        "comments": "update API call for version fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 127,
        "change": [
            "class Trainer(TrainerBase):",
            "",
            "@timing.time(\"Trainer.test\")",
            "def test(self, test_iter, model, metric_reporter: MetricReporter):",
            "+        if cuda.CUDA_ENABLED:",
            "+            model = model.cuda()",
            "+",
            "model.eval()",
            "with torch.no_grad():",
            "test_metric = self._run_epoch("
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 128,
        "change": [
            "class TrainingArguments:",
            "@torch_required",
            "def _setup_devices(self) -> \"torch.device\":",
            "logger.info(\"PyTorch: setting up devices\")",
            "-        if torch.distributed.is_initialized() and self.local_rank == -1:",
            "+        if torch.distributed.is_available() and torch.distributed.is_initialized() and self.local_rank == -1:",
            "logger.warning(",
            "\"torch.distributed process group is initialized, but local_rank == -1. \"",
            "\"In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\""
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 131,
        "change": [
            "with tf.Graph().as_default():",
            "checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")",
            "if not os.path.exists(checkpoint_dir):",
            "os.makedirs(checkpoint_dir)",
            "-        saver = tf.train.Saver(tf.all_variables())",
            "+        saver = tf.train.Saver(tf.global_variables())",
            "",
            "# Write vocabulary",
            "vocab_processor.save(os.path.join(out_dir, \"vocab\"))",
            "",
            "# Initialize all variables",
            "-        sess.run(tf.initialize_all_variables())",
            "+        sess.run(tf.global_variables_initializer())",
            "",
            "def train_step(x_batch, y_batch):",
            "\"\"\""
        ],
        "comments": "update API call for version fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 132,
        "change": [
            "class CLIPTextTransformer(nn.Module):",
            "attentions=encoder_outputs.attentions,",
            ")",
            "",
            "-    def _build_causal_attention_mask(self, bsz, seq_len):",
            "+    def _build_causal_attention_mask(self, bsz, seq_len, dtype):",
            "# lazily create causal attention mask, with full attention between the vision tokens",
            "# pytorch uses additive attention mask; fill with -inf",
            "-        mask = torch.empty(bsz, seq_len, seq_len)",
            "-        mask.fill_(torch.tensor(float(\"-inf\")))",
            "+        mask = torch.empty(bsz, seq_len, seq_len, dtype=dtype)",
            "+        mask.fill_(torch.tensor(torch.finfo(dtype).min))",
            "mask.triu_(1)  # zero out the lower diagonal",
            "mask = mask.unsqueeze(1)  # expand mask",
            "return mask"
        ],
        "comments": "add param for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 135,
        "change": [
            "def get_mini_batch(mini_batch_indices, sequences, seq_lengths, cuda=False):",
            "# get mask for mini-batch",
            "mini_batch_mask = get_mini_batch_mask(mini_batch, sorted_seq_lengths)",
            "",
            "-    # wrap in PyTorch Variables",
            "-    mini_batch = Variable(torch.Tensor(mini_batch))",
            "-    mini_batch_reversed = Variable(torch.Tensor(mini_batch_reversed))",
            "-    mini_batch_mask = Variable(torch.Tensor(mini_batch_mask))",
            "+    # wrap in PyTorch Tensors",
            "+    mini_batch = torch.tensor(mini_batch)",
            "+    mini_batch_reversed = torch.tensor(mini_batch_reversed)",
            "+    mini_batch_mask = torch.tensor(mini_batch_mask)",
            "",
            "# cuda() here because need to cuda() before packing",
            "if cuda:"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 137,
        "change": [
            "class FlopsProfiler(object):",
            "start_time_hook)",
            "",
            "def end_time_hook(module, input, output):",
            "-                torch.cuda.synchronize()",
            "+                get_accelerator().synchronize()",
            "module.__duration__ += time.time() - module.__start_time__",
            "",
            "if not hasattr(module, \"__end_time_hook_handle__\"):"
        ],
        "comments": "change API call for version fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 151,
        "change": [
            "def main(args):",
            "# CNN will transform a high dimension image into a low dimension 2D tensors for RBF kernel.",
            "# This kernel accepts inputs are inputs of CNN and gives outputs are covariance matrix of RBF on",
            "# outputs of CNN.",
            "-    kernel = gp.kernels.RBF(input_dim=10, lengthscale=torch.ones(10)).warp(iwarping_fn=cnn_fn)",
            "+    kernel = gp.kernels.Warp(gp.kernels.RBF(input_dim=10, lengthscale=torch.ones(10)),",
            "+                             iwarping_fn=cnn_fn)",
            "",
            "# init inducing points (taken randomly from dataset)",
            "Xu = next(iter(train_loader))[0][:args.num_inducing]"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 153,
        "change": [
            "def linspace_helper(start, stop, num, axis=None, *, device):",
            "else:",
            "res = [linspace_method(start, stp, num, device=device) for stp in stop]",
            "else:",
            "-        return linspace_method(start, stop, num, device=device)",
            "+        return linspace_method(start, stop, num, dtype=torch.float64, device=device)",
            "res = torch.cat(res, -1).reshape(sos_shape + [num])",
            "if axis is not None:",
            "res = torch.transpose(res, axis, -1)"
        ],
        "comments": "add param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 156,
        "change": [
            "class UnittestBase(object):",
            "datetime.now().strftime('%H:%M:%S'), self.__class__.__name__[4:], name",
            "))",
            "sys.stdout.flush()",
            "+        tf.compat.v1.reset_default_graph()",
            "",
            "def finished_test(self, assertion=None):",
            "\"\"\""
        ],
        "comments": "add API call for state fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 158,
        "change": [
            "class GPTNeoXModel(GPTNeoXPreTrainedModel):",
            "# Since we are adding it to the raw scores before the softmax, this is",
            "# effectively the same as removing these entirely.",
            "attention_mask = attention_mask.to(dtype=self.dtype)  # fp16 compatibility",
            "-            attention_mask = (1.0 - attention_mask) * -10000.0",
            "+            attention_mask = (1.0 - attention_mask) * torch.finfo(self.dtype).min",
            "",
            "# Prepare head mask if needed",
            "# 1.0 in head_mask indicate we keep the head"
        ],
        "comments": "change param for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 160,
        "change": [
            "def compute_tf_latency(",
            "with tf.device(device):",
            "for _ in range(steps):",
            "starting_time = time.time()",
            "-            _ = model(x)",
            "+            _ = model(*xs)",
            "latencies.append(time.time() - starting_time)",
            "latency = sum(latencies) / steps",
            "return latency, latencies"
        ],
        "comments": "add param for argument fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 163,
        "change": [
            "def non_max_suppression(prediction, conf_thres=0.1, iou_thres=0.6, classes=None,",
            "merge = False  # use merge-NMS",
            "",
            "t = time.time()",
            "-    output = [torch.zeros(0, 6)] * prediction.shape[0]",
            "+    output = [torch.zeros((0, 6), device=prediction.device)] * prediction.shape[0]",
            "for xi, x in enumerate(prediction):  # image index, image inference",
            "# Apply constraints",
            "# x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height"
        ],
        "comments": "add param for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 166,
        "change": [
            "class DartsTrainer(BaseOneShotTrainer):",
            "p += e * d",
            "",
            "_, loss = self._logits_and_loss(trn_X, trn_y)",
            "-            dalphas.append(torch.autograd.grad(loss, [c.alpha for c in self.nas_modules]))",
            "+            dalphas.append(torch.autograd.grad(loss, [c.alpha for _, c in self.nas_modules]))",
            "",
            "dalpha_pos, dalpha_neg = dalphas  # dalpha { L_trn(w+) }, # dalpha { L_trn(w-) }",
            "hessian = [(p - n) / (2. * eps) for p, n in zip(dalpha_pos, dalpha_neg)]"
        ],
        "comments": "add param for argument fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 167,
        "change": [
            "def subtract(",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "x1, x2 = ivy.promote_types_of_inputs(x1, x2)",
            "-    return tf.subtract(x1, x2)",
            "+    return tf.experimental.numpy.subtract(x1, x2)",
            "",
            "",
            "def tan("
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 169,
        "change": [
            "class XDropout(torch.autograd.Function):",
            "# Once https://github.com/pytorch/pytorch/issues/78391 is fixed, do something like:",
            "# if opset_version < 12:",
            "#   return torch.onnx.symbolic_opset9.dropout(g, input, dropout_p, train)",
            "-        return torch.onnx.symbolic_opset12.dropout(g, input, dropout_p, train)",
            "+        return symbolic_opset12.dropout(g, input, dropout_p, train)",
            "",
            "",
            "# Copied from transformers.models.deberta.modeling_deberta.StableDropout"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 170,
        "change": [
            "class Parquet(datasets.ArrowBasedBuilder):",
            "BUILDER_CONFIG_CLASS = ParquetConfig",
            "",
            "def _info(self):",
            "-        if version.parse(pa.__version__) < version.parse(\"3.0.0\"):",
            "+        if datasets.config.PYARROW_VERSION.major < 3:",
            "raise ImportError(",
            "\"PyArrow >= 3.0.0 is required to used the Parquet dataset builder: pip install --upgrade pyarrow\"",
            ")"
        ],
        "comments": "change condition check for version fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 171,
        "change": [
            "class RPCPlugin(DDPPlugin):",
            "world_size: int) -> None:",
            "os.environ['MASTER_PORT'] = os.getenv('RPC_MASTER_PORT', '15000')",
            "rpc.init_rpc(f\"worker{global_rank}\", rank=global_rank, world_size=world_size)",
            "+        rpc._set_rpc_timeout(self.rpc_timeout_sec)",
            "self.rpc_initialized = True",
            "",
            "def rpc_save_model(self,"
        ],
        "comments": "add API call for state fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 172,
        "change": [
            "class SimpleSeq2SeqTest(ModelTestCase):",
            "state = self.model._init_decoder_state(state)",
            "batch_size = state[\"source_mask\"].size()[0]",
            "start_predictions = state[\"source_mask\"].new_full(",
            "-            (batch_size,), fill_value=self.model._start_index",
            "+            (batch_size,), fill_value=self.model._start_index, dtype=torch.long",
            ")",
            "all_top_k_predictions, _ = beam_search.search(",
            "start_predictions, state, self.model.take_step"
        ],
        "comments": "add param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 174,
        "change": [
            "class StableDiffusionDepth2ImgPipeline(DiffusionPipeline):",
            "`pipeline.enable_sequential_cpu_offload()` the execution device can only be inferred from Accelerate's module",
            "hooks.",
            "\"\"\"",
            "-        if self.device != torch.device(\"meta\") or not hasattr(self.unet, \"_hf_hook\"):",
            "+        if not hasattr(self.unet, \"_hf_hook\"):",
            "return self.device",
            "for module in self.unet.modules():",
            "if ("
        ],
        "comments": "remove condition check for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 177,
        "change": [
            "class IvyModule(ivy.Module):",
            "if ivy.array_mode():",
            "a, kw = ivy.args_to_native(*a, **kw)",
            "# noinspection PyUnresolvedReferences",
            "-        params_hk = self._native_module.init(ivy.functional.core.random.RNG, *a, **kw)",
            "+        params_hk = self._native_module.init(ivy.random.RNG, *a, **kw)",
            "params_dict = _hk_flat_map_to_dict(params_hk)",
            "self._hk_params = ivy.Container(params_dict)",
            "param_iterator = self._hk_params.to_iterator()"
        ],
        "comments": "update param for refactor fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 179,
        "change": [
            "class DataParallel(torch.nn.DataParallel):",
            "Batch.from_data_list(data_list[split[i]:split[i + 1]],",
            "follow_batch=self.follow_batch,",
            "exclude_keys=self.exclude_keys).to(",
            "-                                     torch.device('cuda:{}'.format(",
            "-                                         device_ids[i])))",
            "+                                     torch.device(f'cuda:{device_ids[i]}'))",
            "for i in range(len(split) - 1)",
            "]"
        ],
        "comments": "remove API call for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 180,
        "change": [
            "class ProjectedAdaptiveLogSoftmax(nn.Module):",
            "d_emb_i = d_embed // (div_val ** i)",
            "",
            "self.out_projs.append(",
            "-                    nn.Parameter(torch.Tensor(d_proj, d_emb_i))",
            "+                    nn.Parameter(torch.FloatTensor(d_proj, d_emb_i))",
            ")",
            "",
            "self.out_layers.append(nn.Linear(d_emb_i, r_idx-l_idx))"
        ],
        "comments": "change API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 181,
        "change": [
            "class TensorFlowEstimator(BaseEstimator):",
            "raise NotFittedError()",
            "predict_data_feeder = setup_predict_data_feeder(X)",
            "preds = []",
            "-        dropouts = tf.get_collection(DROPOUTS)",
            "-        feed_dict = {prob: 0.0 for prob in dropouts}",
            "+        dropouts = self._graph.get_collection(DROPOUTS)",
            "+        feed_dict = {prob: 1.0 for prob in dropouts}",
            "for data in predict_data_feeder:",
            "feed_dict[self._inp] = data",
            "preds.append(self._session.run("
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Unexpected Output|Device Management Error"
    },
    {
        "number": 187,
        "change": [
            "class Pix2PixModel(BaseModel):",
            "def backward_D(self):",
            "# Fake",
            "# stop backprop to the generator by detaching fake_B",
            "-        fake_AB = self.fake_AB_pool.query(torch.cat((self.real_A, self.fake_B), 1))",
            "+        fake_AB = self.fake_AB_pool.query(torch.cat((self.real_A, self.fake_B), 1).data)",
            "pred_fake = self.netD.forward(fake_AB.detach())",
            "self.loss_D_fake = self.criterionGAN(pred_fake, False)",
            "",
            "# Real",
            "real_AB = torch.cat((self.real_A, self.real_B), 1)",
            "pred_real = self.netD.forward(real_AB)",
            "-        self.loss_D_real = self.criterionGAN(self.pred_real, True)",
            "+        self.loss_D_real = self.criterionGAN(pred_real, True)",
            "",
            "# Combined loss",
            "self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 189,
        "change": [
            "class Trainer:",
            "transformer_cls_to_wrap = get_module_class_from_name(",
            "model, self.args.fsdp_transformer_layer_cls_to_wrap",
            ")",
            "+                    if transformer_cls_to_wrap is None:",
            "+                        raise Exception(\"Could not find the transformer layer class to wrap in the model.\")",
            "auto_wrap_policy = functools.partial(",
            "transformer_auto_wrap_policy,",
            "# Transformer layer class to wrap"
        ],
        "comments": "add condition check for null fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Null Reference Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Program Crash|Null Reference Error"
    },
    {
        "number": 193,
        "change": [
            "class tensorflow_extractor(base_extractor):",
            "writer.close()",
            "sess.run(init)",
            "saver = tf.train.Saver()",
            "+            tf.train.export_meta_graph(\"kit.meta\", as_text=True)",
            "saver.restore(sess, path + cls.architecture_map[architecture]['filename'])",
            "save_path = saver.save(sess, path + \"imagenet_{}.ckpt\".format(architecture))",
            "print(\"Model saved in file: %s\" % save_path)"
        ],
        "comments": "add API call for shape fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Null Reference Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Null Reference Error"
    },
    {
        "number": 194,
        "change": [
            "def test_auto_diagonal_gaussians(auto_class, Elbo):",
            "guide = auto_class(model, rank=1)",
            "else:",
            "guide = auto_class(model)",
            "-    adam = optim.Adam({\"lr\": .001, \"betas\": (0.95, 0.999)})",
            "+    adam = optim.ClippedAdam({\"lr\": .01, \"betas\": (0.95, 0.999),",
            "+                              \"lrd\": 0.1 ** (1 / n_steps)})",
            "svi = SVI(model, guide, adam, loss=Elbo())",
            "",
            "for k in range(n_steps):"
        ],
        "comments": "change API call for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 195,
        "change": [
            "def test_frontend_backward_multi_channel(train, use_wpe, use_beamformer):",
            "frontend.train()",
            "else:",
            "frontend.eval()",
            "+    torch.random.manual_seed(14)",
            "x = torch.randn(2, 1000, 2, requires_grad=True)",
            "x_lengths = torch.LongTensor([1000, 980])",
            "y, y_lengths = frontend(x, x_lengths)"
        ],
        "comments": "add param for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Null Reference Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Null Reference Error"
    },
    {
        "number": 199,
        "change": [
            "class EulerSamplingTest(tf.test.TestCase, parameterized.TestCase):",
            "times=times,",
            "num_samples=num_samples,",
            "initial_state=x0,",
            "-            random_type=tff.math.random.RandomType.SOBOL,",
            "+            random_type=tff.math.random.RandomType.HALTON,",
            "time_step=0.01,",
            "-            seed=12134))",
            "+            seed=12134,",
            "+            skip=100,",
            "+            dtype=tf.float32))",
            "",
            "-    self.assertAllClose(paths.shape, (num_samples, 5, 2), atol=0)",
            "+    self.assertAllClose(paths.shape, (num_samples, 3, 2), atol=0)",
            "means = np.mean(paths, axis=0)",
            "times = np.reshape(times, [-1, 1])",
            "expected_means = x0 + (2.0 / 3.0) * mu * np.power(times, 1.5)"
        ],
        "comments": "add param for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 203,
        "change": [
            "class BatchNorm(TransformModule):",
            "if self.training:",
            "mean, var = y.mean(0), y.var(0)",
            "",
            "-            # NOTE: The momentum variable agrees with the definition in e.g. `torch.nn.BatchNorm1d`",
            "-            self.moving_mean.mul_(1 - self.momentum).add_(mean * self.momentum)",
            "-            self.moving_variance.mul_(1 - self.momentum).add_(var * self.momentum)",
            "+            with torch.no_grad():",
            "+                # NOTE: The momentum variable agrees with the definition in e.g. `torch.nn.BatchNorm1d`",
            "+                self.moving_mean.mul_(1 - self.momentum).add_(mean * self.momentum)",
            "+                self.moving_variance.mul_(1 - self.momentum).add_(var * self.momentum)",
            "",
            "# During test time, use smoothed averages rather than the sample ones",
            "else:"
        ],
        "comments": "add API call for state fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "State Handling Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|State Handling Error"
    },
    {
        "number": 205,
        "change": [
            "class RNNLM(nn.Module):",
            "",
            "def forward(self, state, x):",
            "h0 = self.embed(x)",
            "-        h1, c1 = self.l1(F.dropout(h0), (state['h1'], state['c1']))",
            "-        h2, c2 = self.l2(F.dropout(h1), (state['h2'], state['c2']))",
            "-        y = self.lo(F.dropout(h2))",
            "+        h1, c1 = self.l1(self.d0(h0), (state['h1'], state['c1']))",
            "+        h2, c2 = self.l2(self.d1(h1), (state['h2'], state['c2']))",
            "+        y = self.lo(self.d2(h2))",
            "state = {'c1': c1, 'h1': h1, 'c2': c2, 'h2': h2}",
            "return state, y"
        ],
        "comments": "remove API call for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 208,
        "change": [
            "def reportScore(name, scoreTotal, wordsTotal):",
            "def main():",
            "opt = parser.parse_args()",
            "opt.cuda = opt.gpu > -1",
            "-    torch.cuda.set_device(opt.gpu)",
            "+    if opt.cuda:",
            "+        torch.cuda.set_device(opt.gpu)",
            "",
            "translator = onmt.Translator(opt)"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 209,
        "change": [
            "class Conv2dStaticSamePadding(nn.Conv2d):",
            "pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)",
            "pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)",
            "if pad_h > 0 or pad_w > 0:",
            "-            self.static_padding = nn.ZeroPad2d((pad_w - pad_w // 2, pad_w - pad_w // 2,",
            "-                                                pad_h - pad_h // 2, pad_h - pad_h // 2))",
            "+            self.static_padding = nn.ZeroPad2d((pad_w // 2, pad_w - pad_w // 2,",
            "+                                                pad_h // 2, pad_h - pad_h // 2))",
            "else:",
            "self.static_padding = nn.Identity()"
        ],
        "comments": "change param for math fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 213,
        "change": [
            "class SpeedySpeech(BaseTTS):",
            "outputs = {\"model_outputs\": o_de.transpose(1, 2), \"durations_log\": o_dr_log.squeeze(1), \"alignments\": attn}",
            "return outputs",
            "",
            "+    @torch.no_grad()",
            "def inference(self, x, aux_input={\"d_vectors\": None, \"speaker_ids\": None}):  # pylint: disable=unused-argument",
            "\"\"\"",
            "Shapes:"
        ],
        "comments": "add API call for state fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 214,
        "change": [
            "class KerasBackend(AbstractBackend):",
            "return keras",
            "",
            "def einsum(self, pattern, *x):",
            "-        return self.tf.einsum(pattern, *x)",
            "+        return self.tf.vectorized_map(",
            "+            functools.partial(self.tf.einsum, pattern),",
            "+            *x",
            "+        )",
            "",
            "",
            "class OneFlowBackend(AbstractBackend):"
        ],
        "comments": "add API call for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 215,
        "change": [
            "def run_modelmerger(primary_model_name, secondary_model_name, teritary_model_nam",
            "t2 = theta_2.get(key, torch.zeros_like(theta_1[key]))",
            "theta_1[key] = theta_func1(theta_1[key], t2)",
            "else:",
            "-                    theta_1[key] = 0",
            "+                    theta_1[key] = torch.zeros_like(theta_1[key])",
            "del theta_2, teritary_model",
            "",
            "for key in tqdm.tqdm(theta_0.keys()):"
        ],
        "comments": "add API call for math fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 216,
        "change": [
            "class DefaultClassifier(Classifier):",
            "",
            "def _calculate_loss(self, scores, labels):",
            "",
            "-        if len(labels) == 0: return torch.tensor(0., requires_grad=True), 1",
            "+        if len(labels) == 0: return torch.tensor(0., requires_grad=True, device=flair.device), 1",
            "",
            "if self.multi_label:",
            "labels = torch.tensor([[1 if l in all_labels_for_point else 0 for l in self.label_dictionary.get_items()]"
        ],
        "comments": "add param for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 217,
        "change": [
            "class EmbeddingLayer(nn.Module):",
            "torch.empty(weight_shape[0],",
            "weight_shape[1],",
            "dtype=dtype,",
            "-                        device=torch.cuda.current_device()))",
            "+                        device=get_accelerator().current_device_name()))",
            "",
            "def forward(self, input):",
            "return F.embedding(input, self.weight)"
        ],
        "comments": "change API call for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 218,
        "change": [
            "class MultiActionDistribution(ActionDistribution):",
            "",
            "def logp(self, x):",
            "\"\"\"The log-likelihood of the action distribution.\"\"\"",
            "-        split_list = self.reshaper.split_tensor(x)",
            "+        split_list = tf.split(x, len(self.input_lens), axis=1)",
            "for i, distribution in enumerate(self.child_distributions):",
            "# Remove extra categorical dimension",
            "if isinstance(distribution, Categorical):"
        ],
        "comments": "change API call for version fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 219,
        "change": [
            "class CategoricalOneHotPolicy(StochasticPolicy):",
            "def __init__(self, network, session, state, random, action_count=1, scope='policy'):",
            "with tf.variable_scope(scope):",
            "action_layer = linear(layer_input=network.output, config={'num_outputs': action_count}, scope='outputs')",
            "+            action_layer = tf.reshape(action_layer, [-1, action_count])",
            "+",
            "distribution = tf.nn.softmax(action_layer)",
            "sample = tf.multinomial(distribution, 1)"
        ],
        "comments": "add API call for math fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 222,
        "change": [
            "def test(data,",
            "else:  # called by train.py",
            "training = True",
            "device = next(model.parameters()).device  # get model device",
            "-        half = device.type != 'cpu'  # half precision only supported on CUDA",
            "+        half = device.type != 'cpu' and torch.cuda.device_count() == 1  # half precision only supported on single-GPU",
            "if half:",
            "model.half()  # to FP16"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Condition",
        "Action_Element": "Replace API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 223,
        "change": [
            "class MobileNetV3LargeEncoder(MobileNetV3):",
            ")",
            "",
            "if pretrained:",
            "-            self.load_state_dict(load_state_dict_from_url(",
            "+            self.load_state_dict(torch.hub.load_state_dict_from_url(",
            "'https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth'))",
            "",
            "del self.avgpool"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 224,
        "change": [
            "def make_non_pad_mask(lengths):",
            "\"\"\"",
            "bs = int(len(lengths))",
            "maxlen = int(max(lengths))",
            "-    mask = torch.zeros(bs, maxlen).byte()",
            "+    mask = torch.zeros(bs, maxlen, dtype=torch.uint8)",
            "for i, l in enumerate(lengths):",
            "mask[i, :l] = 1"
        ],
        "comments": "add param for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 229,
        "change": [
            "class TFXGLMPreTrainedModel(TFPreTrainedModel):",
            "@tf.function(",
            "input_signature=[",
            "{",
            "-                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),",
            "-                \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),",
            "+                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),",
            "+                \"attention_mask\": tf.TensorSpec((None, None), tf.int64, name=\"attention_mask\"),",
            "}",
            "]",
            ")"
        ],
        "comments": "change param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 233,
        "change": [
            "class TacotronTrainTest(unittest.TestCase):",
            "optimizer = optim.Adam(model.parameters(), lr=c.lr)",
            "for i in range(5):",
            "mel_out, linear_out, align, stop_tokens = model.forward(",
            "-                input, mel_spec)",
            "+                input, input_lengths, mel_spec)",
            "assert stop_tokens.data.max() <= 1.0",
            "assert stop_tokens.data.min() >= 0.0",
            "optimizer.zero_grad()"
        ],
        "comments": "add param for argument fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 234,
        "change": [
            "class EulerAncestralDiscreteScheduler(SchedulerMixin, ConfigMixin):",
            "",
            "prev_sample = sample + derivative * dt",
            "",
            "-        device = model_output.device if torch.is_tensor(model_output) else torch.device(\"cpu\")",
            "+        device = model_output.device",
            "if device.type == \"mps\":",
            "# randn does not work reproducibly on mps",
            "noise = torch.randn(model_output.shape, dtype=model_output.dtype, device=\"cpu\", generator=generator).to("
        ],
        "comments": "remove condition check for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 244,
        "change": [
            "def test_runway_sd_1_5_negative_prompt(sd_device, strategy, sampler):",
            "def test_cv2(strategy, cv2_flag, cv2_radius):",
            "model = ModelManager(",
            "name=\"cv2\",",
            "-        device=device,",
            "+        device=torch.device(device),",
            ")",
            "cfg = get_config(strategy, cv2_flag=cv2_flag, cv2_radius=cv2_radius)",
            "assert_equal("
        ],
        "comments": "update API call for version fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 250,
        "change": [
            "def train_cnn_and_compute_accuracy(params, steps, train_images, train_labels, va",
            "# Do the training and evaluation.",
            "with tf.Session() as sess:",
            "# Initialize the network weights.",
            "-    sess.run(tf.initialize_all_variables())",
            "+    sess.run(tf.global_variables_initializer())",
            "for i in range(1, steps + 1):",
            "# Fetch the next batch of data.",
            "image_batch = get_batch(train_images, i, batch_size)"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 251,
        "change": [
            "def actor_critic_loss(policy, model, dist_class, train_batch):",
            "values = model.value_function()",
            "dist = dist_class(logits, model)",
            "log_probs = dist.logp(train_batch[SampleBatch.ACTIONS])",
            "-    policy.entropy = dist.entropy().mean()",
            "+    policy.entropy = dist.entropy().sum()",
            "policy.pi_err = -train_batch[Postprocessing.ADVANTAGES].dot(",
            "log_probs.reshape(-1))",
            "-    policy.value_err = nn.functional.mse_loss(",
            "-        values.reshape(-1), train_batch[Postprocessing.VALUE_TARGETS])",
            "+    policy.value_err = torch.sum(",
            "+        torch.pow(",
            "+            values.reshape(-1) - train_batch[Postprocessing.VALUE_TARGETS],",
            "+            2.0))",
            "overall_err = sum([",
            "policy.pi_err,",
            "policy.config[\"vf_loss_coeff\"] * policy.value_err,"
        ],
        "comments": "change API call for math fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 252,
        "change": [
            "class DeepSpeedDataLoader(object):",
            "else:",
            "if data_sampler is None:",
            "data_sampler = RandomSampler(dataset)",
            "-                device_count = torch.cuda.device_count()",
            "+                device_count = get_accelerator().device_count()",
            "batch_size *= device_count",
            "",
            "if num_local_io_workers is None:"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 258,
        "change": [
            "class StopwatchMeter(Meter):",
            "if self.start_time is not None:",
            "delta = time.perf_counter() - self.start_time",
            "self.sum = self.sum + delta",
            "-            self.n = self.n + n",
            "+            self.n = type_as(self.n, n) + n",
            "",
            "def reset(self):",
            "self.sum = 0  # cumulative time during which stopwatch was active"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 259,
        "change": [
            "class RagTokenForGeneration(RagPreTrainedModel):",
            "n_docs = n_docs if n_docs is not None else self.config.n_docs",
            "",
            "# RAG-token marginalization",
            "-        seq_logprobs = torch.nn.functional.log_softmax(seq_logits, dim=-1).view(",
            "+        seq_logprobs = nn.functional.log_softmax(seq_logits, dim=-1).view(",
            "seq_logits.shape[0] // n_docs, n_docs, -1, seq_logits.size(-1)",
            ")",
            "doc_logprobs = torch.log_softmax(doc_scores, dim=1)"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 265,
        "change": [
            "class HorovodTrainer(DataParallelTrainer):",
            "),",
            ")",
            "train_dataset = ray.data.from_items([{\"x\": x, \"y\": x + 1} for x in range(32)])",
            "-        scaling_config = ScalingConfig(num_workers=3)",
            "-        # If using GPUs, use the below scaling config instead.",
            "-        # scaling_config = ScalingConfig(num_workers=3, use_gpu=True)",
            "+        scaling_config = ScalingConfig(num_workers=3, use_gpu=use_gpu)",
            "trainer = HorovodTrainer(",
            "train_loop_per_worker=train_loop_per_worker,",
            "scaling_config=scaling_config,"
        ],
        "comments": "add param for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 267,
        "change": [
            "def qr(A: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:  # pragma: no cove",
            "\"\"\"",
            "Like torch.linalg.qr.",
            "\"\"\"",
            "-    if hasattr(torch.linalg, \"qr\"):",
            "+    if hasattr(torch, \"linalg\") and hasattr(torch.linalg, \"qr\"):",
            "# PyTorch version >= 1.9",
            "return torch.linalg.qr(A)",
            "return torch.qr(A)"
        ],
        "comments": "change condition check for version fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 268,
        "change": [
            "def prepare_bart_inputs_dict(",
            "if decoder_attention_mask is None:",
            "decoder_attention_mask = decoder_input_ids.ne(config.pad_token_id)",
            "if head_mask is None:",
            "-        head_mask = torch.ones(config.encoder_layers, config.encoder_attention_heads)",
            "+        head_mask = torch.ones(config.encoder_layers, config.encoder_attention_heads, device=torch_device)",
            "if decoder_head_mask is None:",
            "-        decoder_head_mask = torch.ones(config.decoder_layers, config.decoder_attention_heads)",
            "+        decoder_head_mask = torch.ones(config.decoder_layers, config.decoder_attention_heads, device=torch_device)",
            "return {",
            "\"input_ids\": input_ids,",
            "\"decoder_input_ids\": decoder_input_ids,"
        ],
        "comments": "add param for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 271,
        "change": [
            "class Plan(Serializable):",
            "# prevent circular dependency",
            "# syft relative",
            "from ...core.node.vm.vm import VirtualMachine  # noqa: F401",
            "+        if self.local_executor is not None:",
            "+            # this is necessary for syfts nn.module, because the plan contains state from the module",
            "+            # in order to use this state, we first need to send the model, and then execute te plan",
            "+            return self.local_executor(**kwargs)",
            "",
            "alice = VirtualMachine(name=\"plan_executor\")",
            "alice_client: client.Client = alice.get_client()"
        ],
        "comments": "add condition check for null fix",
        "Symptom": "Program Crash",
        "Root_Cause": "State Handling Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|State Handling Error"
    },
    {
        "number": 272,
        "change": [
            "class GradTTS(DiffusionPipeline):",
            "mu_y = mu_y.transpose(1, 2)",
            "",
            "# Sample latent representation from terminal distribution N(mu_y, I)",
            "-        z = mu_y + torch.randn_like(mu_y, device=mu_y.device) / temperature",
            "+        z = mu_y + torch.randn(mu_y.shape, device=mu_y.device, generator=generator) / temperature",
            "",
            "xt = z * y_mask",
            "h = 1.0 / num_inference_steps"
        ],
        "comments": "change API call for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 273,
        "change": [
            "class NanDetector:",
            "gradients = {}",
            "for name, param in self.named_parameters:",
            "if param.grad is not None:",
            "-                grad_norm = torch.norm(param.grad.data, p=2, dtype=torch.float32)",
            "+                grad_norm = torch.norm(param.grad.data.float(), p=2)",
            "norm[name] = grad_norm.item()",
            "if torch.isnan(grad_norm).any() or torch.isinf(grad_norm).any():",
            "gradients[name] = param.grad.data"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 274,
        "change": [
            "def create_loader(",
            "# of samples per-process, will slightly alter validation results",
            "sampler = OrderedDistributedSampler(dataset)",
            "",
            "+    if collate_fn is None:",
            "+        collate_fn = fast_collate if use_prefetcher else torch.utils.data.dataloader.default_collate",
            "+",
            "loader = torch.utils.data.DataLoader(",
            "dataset,",
            "batch_size=batch_size,",
            "shuffle=sampler is None and is_training,",
            "num_workers=num_workers,",
            "sampler=sampler,",
            "-        collate_fn=fast_collate if use_prefetcher else torch.utils.data.dataloader.default_collate,",
            "+        collate_fn=collate_fn,",
            "drop_last=is_training,",
            ")",
            "if use_prefetcher:"
        ],
        "comments": "add condition check for null fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 278,
        "change": [
            "def mesh_laplacian_smoothing(meshes, method: str = \"uniform\"):",
            "elif method == \"cot\":",
            "loss = L.mm(verts_packed) * norm_w - verts_packed",
            "elif method == \"cotcurv\":",
            "-        loss = (L.mm(verts_packed) - verts_packed) * norm_w",
            "+        loss = (L.mm(verts_packed) - L_sum * verts_packed) * norm_w",
            "loss = loss.norm(dim=1)",
            "",
            "loss = loss * weights"
        ],
        "comments": "change param for math fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 280,
        "change": [
            "class AsyncMultiGPUTrainer(MultiGPUTrainer,",
            "",
            "self._setup_predictor_factory(predict_tower)",
            "self._average_gradient = average_gradient",
            "+        assert tf.test.is_gpu_available()",
            "",
            "def _setup(self):",
            "super(AsyncMultiGPUTrainer, self)._setup()"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 282,
        "change": [
            "class GCNConv(MessagePassing):",
            "x = torch.matmul(x, self.weight)",
            "",
            "if not self.cached or self.cached_result is None:",
            "-            edge_index, norm = GCNConv.norm(edge_index,",
            "-                                            x.size(0), edge_weight,",
            "+            edge_index, norm = GCNConv.norm(edge_index, x.size(0), edge_weight,",
            "self.improved, x.dtype)",
            "self.cached_result = edge_index, norm"
        ],
        "comments": "add param for argument fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 283,
        "change": [
            "class CTC(torch.nn.Module):",
            "if self.ctc_type == \"builtin\":",
            "olens = to_device(ys_hat, torch.LongTensor([len(s) for s in ys]))",
            "hlens = hlens.long()",
            "+            ys_pad = torch.cat(ys)  # without this the code breaks for asr_mix",
            "self.loss = self.loss_fn(ys_hat, ys_pad, hlens, olens)",
            "else:",
            "self.loss = None"
        ],
        "comments": "add API call for shape fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 296,
        "change": [
            "class DeformableDetrModelIntegrationTests(unittest.TestCase):",
            "results = feature_extractor.post_process_object_detection(",
            "outputs, threshold=0.3, target_sizes=[image.size[::-1]]",
            ")[0]",
            "-        expected_scores = torch.tensor([0.7999, 0.7894, 0.6331, 0.4720, 0.4382])",
            "+        expected_scores = torch.tensor([0.7999, 0.7894, 0.6331, 0.4720, 0.4382]).to(torch_device)",
            "expected_labels = [17, 17, 75, 75, 63]",
            "-        expected_slice_boxes = torch.tensor([16.5028, 52.8390, 318.2544, 470.7841])",
            "+        expected_slice_boxes = torch.tensor([16.5028, 52.8390, 318.2544, 470.7841]).to(torch_device)",
            "",
            "self.assertEqual(len(results[\"scores\"]), 5)",
            "self.assertTrue(torch.allclose(results[\"scores\"], expected_scores, atol=1e-4))"
        ],
        "comments": "add API call for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 297,
        "change": [
            "class Critic(object):",
            "n = InputLayer(self.s, name='in')",
            "n = DenseLayer(n, n_units=30, act=tf.nn.relu6, W_init=tf.random_uniform_initializer(0, 0.01), name='hidden')",
            "# n = DenseLayer(n, n_units=5, act=tf.nn.relu, W_init=tf.random_uniform_initializer(0, 0.01), name='hidden2')",
            "-            n = DenseLayer(n, n_units=1, act=tf.identity, name='V')",
            "+            n = DenseLayer(n, n_units=1, act=None, name='V')",
            "self.v = n.outputs",
            "",
            "with tf.variable_scope('squared_TD_error'):"
        ],
        "comments": "change param for math fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Null Reference Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Null Reference Error"
    },
    {
        "number": 298,
        "change": [
            "class TensorflowBackendInferenceLearner(TensorflowBaseInferenceLearner):",
            "metadata = LearnerMetadata.read(path)",
            "network_parameters = ModelParams(**metadata.network_parameters)",
            "input_tfms = metadata.input_tfms",
            "-        model = nebullvm.operations.inference_learners.utils.load_model(",
            "+        model = tf.keras.models.load_model(",
            "path / TENSORFLOW_BACKEND_FILENAMES[\"tf_model\"]",
            ")",
            "device = Device(metadata.device)"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 300,
        "change": [
            "FileType = Any",
            "# Represents the result dict returned by Trainer.train().",
            "ResultDict = dict",
            "",
            "+# A tf or torch local optimizer object.",
            "+LocalOptimizer = Union[\"tf.keras.optimizers.Optimizer\",",
            "+                       \"torch.optim.Optimizer\"]",
            "+",
            "# Dict of tensors returned by compute gradients on the policy, e.g.,",
            "# {\"td_error\": [...], \"learner_stats\": {\"vf_loss\": ..., ...}}, for multi-agent,",
            "# {\"policy1\": {\"learner_stats\": ..., }, \"policy2\": ...}."
        ],
        "comments": "add API call for state fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 305,
        "change": [
            "def ones_like(x, name=None):",
            "[ 1.,  1.,  1.]], dtype=float32)",
            "```",
            "\"\"\"",
            "-    return tf.ones_like(x, name=name)",
            "+    return tf.ones_like(x, dtype=dtype, name=name)",
            "",
            "",
            "def random_uniform_variable(shape, low, high, dtype=None,"
        ],
        "comments": "add param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 307,
        "change": [
            "from allennlp.common.params import Params",
            "",
            "class TestStackedBidirectionalLstm(AllenNlpTestCase):",
            "def test_stacked_bidirectional_lstm_completes_forward_pass(self):",
            "-        input_tensor = torch.autograd.Variable(torch.rand(4, 5, 3))",
            "+        input_tensor = torch.rand(4, 5, 3)",
            "input_tensor[1, 4:, :] = 0.",
            "input_tensor[2, 2:, :] = 0.",
            "input_tensor[3, 1:, :] = 0."
        ],
        "comments": "remove API call for version fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Deprecation Management Error"
    },
    {
        "number": 309,
        "change": [
            "class TFCTRLMainLayer(tf.keras.layers.Layer):",
            "token_type_embeds = 0",
            "position_ids = tf.reshape(position_ids, [-1, shape_list(position_ids)[-1]])",
            "",
            "-        inputs_embeds = self.w(input_ids)",
            "+        inputs_embeds = self.w(input_ids, mode='embedding')",
            "# x = embedded.unsqueeze(0) if len(input_ids.shape)<2 else embedded",
            "seq_len = input_shape[-1]",
            "mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)"
        ],
        "comments": "add param for argument fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 315,
        "change": [
            "class TFWav2Vec2MainLayer(tf.keras.layers.Layer):",
            "if inputs[\"attention_mask\"] is not None:",
            "# compute real output lengths according to convolution formula",
            "output_lengths = self._get_feat_extract_output_lengths(tf.reduce_sum(inputs[\"attention_mask\"], -1))",
            "-            attention_mask = tf.sequence_mask(output_lengths, dtype=hidden_states.dtype)",
            "+",
            "+            attention_mask = tf.sequence_mask(",
            "+                output_lengths, maxlen=shape_list(hidden_states)[1], dtype=hidden_states.dtype",
            "+            )",
            "",
            "hidden_states = self.feature_projection(hidden_states, training=inputs[\"training\"])"
        ],
        "comments": "add param for argument fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 323,
        "change": [
            "class BaseModel():",
            "save_filename = '%s_net_%s.pth' % (which_epoch, name)",
            "save_path = os.path.join(self.save_dir, save_filename)",
            "net = getattr(self, 'net' + name)",
            "-                net.load_state_dict(torch.load(save_path))",
            "+                net.module.load_state_dict(torch.load(save_path))",
            "",
            "# print network information",
            "def print_networks(self, verbose):"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 324,
        "change": [
            "class SpeedsterRootOp(Operation):",
            ") -> List[BaseInferenceLearner]:",
            "if self.orig_latency_measure_op.get_result() is not None:",
            "model_outputs = self.orig_latency_measure_op.get_result()[0]",
            "-            if isinstance(model, Module):",
            "+            if isinstance(model, torch.nn.Module):",
            "optimization_op = self.torch_optimization_op",
            "elif isinstance(model, tf.Module) and model is not None:",
            "optimization_op = self.tensorflow_optimization_op"
        ],
        "comments": "change param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Condition",
        "Action_Element": "Replace API Condition",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 328,
        "change": [
            "class UNet2DConditionModel(ModelMixin, ConfigMixin):",
            "if not torch.is_tensor(timesteps):",
            "timesteps = torch.tensor([timesteps], dtype=torch.long, device=sample.device)",
            "elif torch.is_tensor(timesteps) and len(timesteps.shape) == 0:",
            "-            timesteps = timesteps[None].to(sample.device)",
            "+            timesteps = timesteps.to(dtype=torch.float32)",
            "+            timesteps = timesteps[None].to(device=sample.device)",
            "",
            "# broadcast to batch dimension in a way that's compatible with ONNX/Core ML",
            "timesteps = timesteps.expand(sample.shape[0])"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 333,
        "change": [
            "class BilinearSimilarity(SimilarityFunction):",
            "self.reset_parameters()",
            "",
            "def reset_parameters(self):",
            "-        torch.nn.init.xavier_uniform(self._weight_matrix)",
            "+        torch.nn.init.xavier_uniform_(self._weight_matrix)",
            "self._bias.data.fill_(0)",
            "",
            "@overrides"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 335,
        "change": [
            "class AdaptiveEmbedding(nn.Module):",
            "",
            "inp_i = inp_flat.index_select(0, indices_i) - l_idx",
            "emb_i = self.emb_layers[i](inp_i)",
            "-                emb_i = F.linear(emb_i, self.emb_projs[i])",
            "+                emb_i = nn.functional.linear(emb_i, self.emb_projs[i])",
            "",
            "emb_flat.index_copy_(0, indices_i, emb_i)"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 337,
        "change": [
            "class Residual(tf.keras.Model):  #@save",
            "if self.conv3 is not None:",
            "X = self.conv3(X)",
            "Y += X",
            "-        return tf.keras.activations.relu(Y + X)",
            "+        return tf.keras.activations.relu(Y)"
        ],
        "comments": "change param for math fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Null Reference Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Null Reference Error"
    },
    {
        "number": 341,
        "change": [
            "for m in model_list:",
            "data_root=os.environ.get('IMAGENET_DIR', './imagenet')",
            ")",
            "",
            "+    torch.cuda.empty_cache()",
            "+"
        ],
        "comments": "add API call for state fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 342,
        "change": [
            "class TFMLP(tf.keras.layers.Layer):",
            "nx = config.n_embd",
            "self.c_fc = TFConv1D(n_state, nx, initializer_range=config.initializer_range, name=\"c_fc\")",
            "self.c_proj = TFConv1D(nx, n_state, initializer_range=config.initializer_range, name=\"c_proj\")",
            "-        self.act = gelu",
            "+        self.act = get_tf_activation(\"gelu\")",
            "self.dropout = tf.keras.layers.Dropout(config.resid_pdrop)",
            "",
            "def call(self, x, training=False):"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 347,
        "change": [
            "class TacotronAbstract(ABC, nn.Module):",
            "def _backward_pass(self, mel_specs, encoder_outputs, mask):",
            "\"\"\" Run backwards decoder \"\"\"",
            "decoder_outputs_b, alignments_b, _ = self.decoder_backward(",
            "-            encoder_outputs, torch.flip(mel_specs, dims=(1,)), mask,",
            "-            self.speaker_embeddings_projected)",
            "+            encoder_outputs, torch.flip(mel_specs, dims=(1,)), mask)",
            "decoder_outputs_b = decoder_outputs_b.transpose(1, 2).contiguous()",
            "return decoder_outputs_b, alignments_b"
        ],
        "comments": "remove param for math fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 348,
        "change": [
            "def main():",
            "model = MMDataParallel(model, device_ids=[0])",
            "outputs = single_gpu_test(model, data_loader, args.show)",
            "else:",
            "-        model = MMDistributedDataParallel(model.cuda())",
            "+        model = MMDistributedDataParallel(",
            "+            model.cuda(),",
            "+            device_ids=[torch.cuda.current_device()],",
            "+            broadcast_buffers=False)",
            "outputs = multi_gpu_test(model, data_loader, args.tmpdir,",
            "args.gpu_collect)"
        ],
        "comments": "add param for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 357,
        "change": [
            "class Tester(unittest.TestCase):",
            "# generate input data",
            "batch_size = 1",
            "center = torch.zeros(batch_size, 2)",
            "-        angle = torch.ones(batch_size, 1)",
            "-        scale = torch.ones(batch_size, 1)",
            "+        angle = torch.ones(batch_size)",
            "+        scale = torch.ones(batch_size)",
            "",
            "center = utils.tensor_to_gradcheck_var(center)  # to var",
            "angle = utils.tensor_to_gradcheck_var(angle)  # to var"
        ],
        "comments": "remove param for shape fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 360,
        "change": [
            "class Trainer:",
            "return type(data)(self._prepare_input(v) for v in data)",
            "elif isinstance(data, torch.Tensor):",
            "kwargs = {\"device\": self.args.device}",
            "-            if self.deepspeed and data.dtype != torch.int64:",
            "-                # NLP models inputs are int64 and those get adjusted to the right dtype of the",
            "+            if self.deepspeed and (torch.is_floating_point(data) or torch.is_complex(data)):",
            "+                # NLP models inputs are int/uint and those get adjusted to the right dtype of the",
            "# embedding. Other models such as wav2vec2's inputs are already float and thus",
            "# may need special handling to match the dtypes of the model",
            "kwargs.update({\"dtype\": self.args.hf_deepspeed_config.dtype()})"
        ],
        "comments": "change condition check for state fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Condition",
        "Action_Element": "Replace API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 362,
        "change": [
            "class DeformableDetrImageProcessor(BaseImageProcessor):",
            "img_w = torch.Tensor([i[1] for i in target_sizes])",
            "else:",
            "img_h, img_w = target_sizes.unbind(1)",
            "-        scale_fct = torch.stack([img_w, img_h, img_w, img_h], dim=1)",
            "+        scale_fct = torch.stack([img_w, img_h, img_w, img_h], dim=1).to(boxes.device)",
            "boxes = boxes * scale_fct[:, None, :]",
            "",
            "results = []"
        ],
        "comments": "add API call for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 363,
        "change": [
            "class SpanBasedF1Test(AllenNlpTestCase):",
            "gold_indices = [self.vocab.get_token_index(x, \"tags\") for x in bio_tags]",
            "gold_tensor = torch.tensor([gold_indices], device=device)",
            "prediction_tensor = torch.rand([1, 6, self.vocab.get_vocab_size(\"tags\")], device=device)",
            "-        mask = torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]], device=device)",
            "+        mask = torch.BoolTensor(",
            "+            [[True, True, True, True, True, True, True, True, True]], device=device",
            "+        )",
            "",
            "# Make prediction so that it is exactly correct.",
            "for i, tag_index in enumerate(gold_indices):"
        ],
        "comments": "change API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 364,
        "change": [
            "class TowerContext(object):",
            "self._ctxs = []",
            "if len(self._name):",
            "if self.has_own_variables:",
            "-                # open new variable scopes",
            "-                self._ctxs.append(tf.variable_scope(self._name))",
            "+                if self.vs_name:",
            "+                    self._ctxs.append(tf.variable_scope(self.vs_name))",
            "else:",
            "# use existing variable scope",
            "reuse = self.index > 0 or (not self.is_training)"
        ],
        "comments": "add condition check for null fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 367,
        "change": [
            "class _BinaryPostprocessing(torch.nn.Module):",
            "predictions = [self.bool2str.get(pred, self.bool2str[0]) for pred in predictions]",
            "",
            "probs = preds[self.probabilities_key]",
            "-        probs = torch.dstack(1 - probs, probs)",
            "+        probs = torch.stack([1 - probs, probs], dim=-1)",
            "",
            "return {",
            "self.predictions_key: predictions,"
        ],
        "comments": "add param for shape fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 368,
        "change": [
            "if __name__ == \"__main__\":",
            "exp = get_exp(args.exp_file, args.name)",
            "exp.merge(args.opts)",
            "",
            "-    num_gpu = get_num_devices() if args.devices is None else args.devices",
            "-    assert num_gpu <= get_num_devices()",
            "+    num_gpu = torch.cuda.device_count() if args.devices is None else args.devices",
            "+    assert num_gpu <= torch.cuda.device_count()",
            "",
            "dist_url = \"auto\" if args.dist_url is None else args.dist_url",
            "launch("
        ],
        "comments": "change API call for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 370,
        "change": [
            "def test_log_prob_eta1(d):",
            "assert (lps_less_ladj - lps_less_ladj.min()).abs().sum() < 1e-4",
            "",
            "",
            "-@pytest.mark.parametrize(\"eta\", [.1, .5, 1, 2, 5])",
            "+@pytest.mark.parametrize(\"eta\", [.1, .5, 1., 2., 5.])",
            "def test_log_prob_d2(eta):",
            "-    dist = LKJCorrCholesky(2, torch.DoubleTensor([eta]))",
            "+    dist = LKJCorrCholesky(2, torch.tensor([eta]))",
            "test_dist = TransformedDistribution(Beta(eta, eta), AffineTransform(loc=-1., scale=2.0))",
            "",
            "samples = dist.sample(torch.Size([100]))"
        ],
        "comments": "change API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 375,
        "change": [
            "def corr2d(X, K):  #@save",
            "",
            "# Defined in file: ./chapter_convolutional-neural-networks/lenet.md",
            "def evaluate_accuracy_gpu(net, data_iter, device=None): #@save",
            "+    net.eval()  # Set the model to evaluation mode",
            "if not device:",
            "device = next(iter(net.parameters())).device",
            "metric = d2l.Accumulator(2)  # num_corrected_examples, num_examples"
        ],
        "comments": "add API call for state fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 376,
        "change": [
            "class VideoSequential(ImageSequential):",
            "# Size of T",
            "frame_num = input.size(self._temporal_channel)",
            "# Got param generation shape to (B, C, H, W). Ignoring T.",
            "-        batch_shape = self.__infer_channel_exclusive_batch_shape__(input)",
            "+        batch_shape = self.__infer_channel_exclusive_batch_shape__(input, self._temporal_channel)",
            "input = self._input_shape_convert_in(input)",
            "input = input.reshape(-1, *batch_shape[1:])",
            "if not self.same_on_frame:"
        ],
        "comments": "add param for argument fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 377,
        "change": [
            "def create_dataloader(path, imgsz, batch_size, stride, single_cls=False, hyp=Non",
            "prefix=prefix)",
            "",
            "batch_size = min(batch_size, len(dataset))",
            "-    nw = min([os.cpu_count() // DEVICE_COUNT, batch_size if batch_size > 1 else 0, workers])  # number of workers",
            "+    nd = torch.cuda.device_count()  # number of CUDA devices",
            "+    nw = min([os.cpu_count() // max(nd, 1), batch_size if batch_size > 1 else 0, workers])  # number of workers",
            "sampler = None if rank == -1 else distributed.DistributedSampler(dataset, shuffle=shuffle)",
            "loader = DataLoader if image_weights else InfiniteDataLoader  # only DataLoader allows for attribute updates",
            "return loader(dataset,"
        ],
        "comments": "add param for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 384,
        "change": [
            "def array(object_in, dtype: Optional[str] = None, dev: Optional[str] = None):",
            "dev = default_device(dev)",
            "dtype = dtype_from_str(default_dtype(dtype, object_in))",
            "if isinstance(object_in, np.ndarray):",
            "-        return _torch.Tensor(object_in).to(dev_from_str(dev))",
            "+        return torch.Tensor(object_in).to(dev_from_str(dev))",
            "if dtype is not None:",
            "-        return _torch.tensor(object_in, dtype=dtype, device=dev_from_str(dev))",
            "-    elif isinstance(object_in, _torch.Tensor):",
            "+        return torch.tensor(object_in, dtype=dtype, device=dev_from_str(dev))",
            "+    elif isinstance(object_in, torch.Tensor):",
            "return object_in.to(dev_from_str(dev))",
            "else:",
            "-        return _torch.tensor(object_in, device=dev_from_str(dev))",
            "+        return torch.tensor(object_in, device=dev_from_str(dev))",
            "",
            "asarray = array"
        ],
        "comments": "update API call for type fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 387,
        "change": [
            "class Trainer(",
            "self.gpus = gpus",
            "self.data_parallel_device_ids = parse_gpu_ids(self.gpus)",
            "self.root_gpu = determine_root_gpu_device(self.data_parallel_device_ids)",
            "+        self.root_device = torch.device(\"cpu\")",
            "",
            "# tpu state flags",
            "self.use_tpu = False"
        ],
        "comments": "add API call for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 390,
        "change": [
            "def _calculate_expected_result(",
            "aggregation_op_only_probs = gumbel_dist.sample()",
            "else:",
            "# <float32>[batch_size, num_aggregation_labels - 1]",
            "-        aggregation_op_only_probs = torch.nn.functional.softmax(",
            "+        aggregation_op_only_probs = nn.functional.softmax(",
            "logits_aggregation[:, 1:] / config.aggregation_temperature, dim=-1",
            ")"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 394,
        "change": [
            "if torch_available and torch.cuda.is_available():",
            "if rocm_major <= 4:",
            "cupy = f\"cupy-rocm-{rocm_major}-{rocm_minor}\"",
            "else:",
            "-        cupy = f\"cupy-cuda{torch.version.cuda.replace('.','')[:3]}\"",
            "+        cupy = f\"cupy-cuda{''.join(map(str,installed_cuda_version()))}\"",
            "if cupy:",
            "extras_require['1bit'].append(cupy)",
            "extras_require['1bit_mpi'].append(cupy)"
        ],
        "comments": "update API call for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 397,
        "change": [
            "def spatial_soft_argmax2d(",
            ">>> coords = kornia.spatial_soft_argmax2d(input, False)",
            "tensor([[[1.0000, 1.0000]]])",
            "\"\"\"",
            "-    input_soft: torch.Tensor = dsnt.spatial_softmax_2d(input, temperature)",
            "-    output: torch.Tensor = dsnt.spatial_softargmax_2d(input_soft,",
            "-                                                      normalized_coordinates)",
            "+    input_soft: torch.Tensor = spatial_softmax_2d(input, temperature)",
            "+    output: torch.Tensor = spatial_softargmax_2d(input_soft,",
            "+                                                 normalized_coordinates)",
            "return output"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 401,
        "change": [
            "def test_torch_instance_to(",
            "frontend,",
            "):",
            "input_dtype, x, method_num_positional_args, method_all_as_kwargs_np = args_kwargs",
            "+    method_flags.num_positional_args = method_num_positional_args",
            "helpers.test_frontend_method(",
            "init_input_dtypes=input_dtype,",
            "init_all_as_kwargs_np={"
        ],
        "comments": "add param for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 407,
        "change": [
            "class UnigramRecall(Metric):",
            "A tensor of predictions of shape (batch_size, k, sequence_length).",
            "gold_labels : `torch.Tensor`, required.",
            "A tensor of integer class label of shape (batch_size, sequence_length).",
            "-        mask : `torch.Tensor`, optional (default = None).",
            "+        mask : `torch.BoolTensor`, optional (default = None).",
            "A masking tensor the same size as `gold_labels`.",
            "\"\"\"",
            "predictions, gold_labels, mask = self.detach_tensors(predictions, gold_labels, mask)"
        ],
        "comments": "update param for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 408,
        "change": [
            "\"        # compute the gating function and one minus the gating function\\n\",",
            "\"        gate_intermediate = self.relu(self.lin_gate_z_to_hidden(z_t_1))\\n\",",
            "\"        gate = self.sigmoid(self.lin_gate_hidden_to_z(gate_intermediate))\\n\",",
            "-    \"        one_minus_gate = ng_ones(gate.size()).type_as(gate) - gate\\n\",",
            "+    \"        one_minus_gate = torch.ones(gate.size()).type_as(gate) - gate\\n\",",
            "\"        # compute the 'proposed mean'\\n\",",
            "\"        proposed_mean_intermediate = self.relu(self.lin_proposed_mean_z_to_hidden(z_t_1))\\n\",",
            "\"        proposed_mean = self.lin_proposed_mean_hidden_to_z(proposed_mean_intermediate)\\n\","
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 410,
        "change": [
            "def rotation_matrix_to_quaternion(",
            "return torch.cat([qx, qy, qz, qw], dim=-1)",
            "",
            "def cond_3():",
            "-        sq = torch.sqrt(trace + 1.0 + m00 - m11 - m22) * 2.  # sq = 4 * qw.",
            "+        sq = torch.sqrt(1.0 + m00 - m11 - m22 + eps) * 2.  # sq = 4 * qw.",
            "qw = safe_zero_division(m10 - m01, sq)",
            "qx = safe_zero_division(m02 - m20, sq)",
            "qy = safe_zero_division(m12 - m21, sq)"
        ],
        "comments": "change param for math fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 417,
        "change": [
            "class Model(ModelDesc):",
            "if get_current_tower_context().is_training:",
            "wd_w = tf.train.exponential_decay(2e-4, get_global_step_var(),",
            "80000, 0.7, True)",
            "-            wd_cost = tf.mul(wd_w, regularize_cost('.*/W', tf.nn.l2_loss), name='wd_cost')",
            "+            wd_cost = tf.multiply(wd_w, regularize_cost('.*/W', tf.nn.l2_loss), name='wd_cost')",
            "costs.append(wd_cost)",
            "",
            "add_param_summary(('.*/W', ['histogram']))   # monitor W"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 418,
        "change": [
            "if __name__ == '__main__':",
            "loss_values.clear()",
            "accuracies.clear()",
            "if step % 100 == 0:",
            "-            vis.draw_projections(embeds.detach().cpu().numpy(), utterances_per_speaker, step)",
            "+            vis.draw_projections(embeds.detach().numpy(), utterances_per_speaker, step)"
        ],
        "comments": "remove API call for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 419,
        "change": [
            "class ScoreSdeVpScheduler(SchedulerMixin, ConfigMixin):",
            "x_mean = x + drift * dt",
            "",
            "# add noise",
            "-        noise = torch.randn(x.shape, layout=x.layout, generator=generator).to(x.device)",
            "+        noise = randn_tensor(x.shape, layout=x.layout, generator=generator, device=x.device, dtype=x.dtype)",
            "x = x_mean + diffusion * math.sqrt(-dt) * noise",
            "",
            "return x, x_mean"
        ],
        "comments": "change API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 422,
        "change": [
            "def get_keras_model():",
            "M.add(KL.Conv2D(32, 3, padding='same', activation='relu'))",
            "M.add(KL.Flatten())",
            "M.add(KL.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(1e-5)))",
            "-        M.add(KL.Dropout(0.5))",
            "+        M.add(KL.Dropout(rate=0.5))",
            "M.add(KL.Dense(10, activation=None, kernel_regularizer=keras.regularizers.l2(1e-5)))",
            "return M"
        ],
        "comments": "update param for math fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 424,
        "change": [
            "def main(parsed_args):",
            "",
            "def cli_main():",
            "parser = options.get_eval_lm_parser()",
            "+    add_distributed_training_args(parser)",
            "args = options.parse_args_and_arch(parser)",
            "-    main(args)",
            "+    distributed_utils.call_main(args, main)",
            "",
            "",
            "if __name__ == '__main__':"
        ],
        "comments": "change API call for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 425,
        "change": [
            "def degree(index, num_nodes=None, dtype=None, device=None):",
            "tensor([3., 1., 1.])",
            "\"\"\"",
            "num_nodes = maybe_num_nodes(index, num_nodes)",
            "-    out = torch.zeros((num_nodes), dtype=dtype, device=device)",
            "+    out = torch.zeros((num_nodes), dtype=dtype, device=index.device)",
            "return out.scatter_add_(0, index, out.new_ones((index.size(0))))"
        ],
        "comments": "add param for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 426,
        "change": [
            "class TransducerTasks(torch.nn.Module):",
            "if ctc_loss:",
            "self.ctc_lin = torch.nn.Linear(encoder_dim, output_dim)",
            "",
            "-            if LooseVersion(torch.__version__) < LooseVersion(\"1.7.0\"):",
            "+            if LooseVersion(torch.__version__) > LooseVersion(\"1.0.1\"):",
            "self.ctc_loss = torch.nn.CTCLoss(",
            "blank=blank_id,",
            "reduction=\"sum\","
        ],
        "comments": "change condition check for version fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 429,
        "change": [
            "class RandomThinPlateSpline(AugmentationBase2D):",
            "",
            "def generate_parameters(self, shape: torch.Size) -> Dict[str, Tensor]:",
            "B, _, _, _ = shape",
            "-        src = torch.tensor([[[-1.0, -1.0], [-1.0, 1.0], [1.0, -1.0], [1.0, 1.0], [0.0, 0.0]]]).expand(B, 5, 2)  # Bx5x2",
            "+        src = tensor([[[-1.0, -1.0], [-1.0, 1.0], [1.0, -1.0], [1.0, 1.0], [0.0, 0.0]]]).expand(B, 5, 2)  # Bx5x2",
            "dst = src + self.dist.rsample(src.shape)",
            "return dict(src=src, dst=dst)"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 433,
        "change": [
            "def HomographyRegressionApp():",
            "[-1, 1],  # top-right",
            "]]).to(dst_homo_src.device)",
            "# transform points",
            "-            pts_dst = dgm.transform_points(dgm.inverse(dst_homo_src), pts_src)",
            "+            pts_dst = dgm.transform_points(torch.inverse(dst_homo_src), pts_src)",
            "",
            "def compute_factor(size):",
            "return 1.0 * size / 2"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 436,
        "change": [
            "class Highway(torch.nn.Module):",
            "# above, too.",
            "nonlinear_part, gate = projected_input.chunk(2, dim=-1)",
            "nonlinear_part = self._activation(nonlinear_part)",
            "-            gate = torch.nn.functional.sigmoid(gate)",
            "+            gate = torch.sigmoid(gate)",
            "current_input = gate * linear_part + (1 - gate) * nonlinear_part",
            "return current_input"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 437,
        "change": [
            "class Model(object):",
            "\"It should be either Tensor or a list of Tensor.\"",
            ")",
            "for idx in range(len(check_argu)):",
            "-                        if not isinstance(check_argu[idx], tf_ops._TensorLike) or not tf_ops.is_dense_tensor_like(",
            "+                        if not isinstance(check_argu[idx], [tf.Tensor, tf.SparseTensor, tf.Variable]) or not tf_ops.is_dense_tensor_like(",
            "check_argu[idx]):",
            "raise TypeError(",
            "\"The argument `%s` should be either Tensor or a list of Tensor \" % (check_order[co]) +"
        ],
        "comments": "change param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 446,
        "change": [
            "class Csv(datasets.ArrowBasedBuilder):",
            "if schema is not None",
            "else None",
            ")",
            "-        for file_idx, file in enumerate(files):",
            "+        for file_idx, file in enumerate(itertools.chain.from_iterable(files)):",
            "csv_file_reader = pd.read_csv(file, iterator=True, dtype=dtype, **self.config.read_csv_kwargs)",
            "try:",
            "for batch_idx, df in enumerate(csv_file_reader):"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 448,
        "change": [
            "class ARMAConv(MessagePassing):",
            "if self.bias is not None:",
            "out += self.bias[0 if self.shared_weights else t]",
            "",
            "-            if t < self.num_layers - 1:",
            "+            if self.act is not None and t < self.num_layers - 1:",
            "out = self.act(out)",
            "",
            "return out.mean(dim=-3)"
        ],
        "comments": "add condition check for null fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Algorithm Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Program Crash|Algorithm Error"
    },
    {
        "number": 449,
        "change": [
            "class DependencyParser(flair.nn.Model):",
            "sentence_tensor = self.word_dropout(sentence_tensor)",
            "",
            "if self.use_rnn:",
            "-            sentence_tensor = pack_padded_sequence(sentence_tensor, lengths, True, False)",
            "+            sentence_sequence = pack_padded_sequence(sentence_tensor, torch.IntTensor(lengths), True, False)",
            "",
            "-            sentence_tensor, _ = self.lstm(sentence_tensor)",
            "-            sentence_tensor, _ = pad_packed_sequence(sentence_tensor, True, total_length=seq_len)",
            "+            sentence_sequence, _ = self.lstm(sentence_sequence)",
            "+            sentence_tensor, _ = pad_packed_sequence(sentence_sequence, True, total_length=seq_len)",
            "",
            "# apply MLPs for arc and relations to the BiLSTM output states",
            "arc_h = self.mlp_arc_h(sentence_tensor)"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 451,
        "change": [
            "def testtanh():",
            "",
            "Ptensor = PolynomialTensor()",
            "",
            "-    x = torch.linspace(-3, 3, steps=10)",
            "+    x = torch.tensor(np.linspace(-3, 3, 10))",
            "expected = torch.tensor(",
            "[",
            "-3.3883e02,"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 452,
        "change": [
            "class BartTranslationTests(unittest.TestCase):",
            "with torch.no_grad():",
            "logits, *other_stuff = model(**self.net_input)",
            "",
            "-        expected_slice = torch.tensor([9.0078, 10.1113, 14.4787])",
            "+        expected_slice = torch.tensor([9.0078, 10.1113, 14.4787], device=torch_device)",
            "result_slice = logits[0][0][:3]",
            "self.assertTrue(torch.allclose(expected_slice, result_slice, atol=TOLERANCE))"
        ],
        "comments": "add param for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 453,
        "change": [
            "def test_dc_crn_separator_invalid_type():",
            "def test_dc_crn_separator_output():",
            "real = torch.rand(2, 10, 17)",
            "imag = torch.rand(2, 10, 17)",
            "-    x = ComplexTensor(real, imag) if is_torch_1_9_plus else torch.complex(real, imag)",
            "+    x = torch.complex(real, imag) if is_torch_1_9_plus else ComplexTensor(real, imag)",
            "x_lens = torch.tensor([10, 8], dtype=torch.long)",
            "",
            "for num_spk in range(1, 3):"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 457,
        "change": [
            "def multilevel_roi_align(features, rcnn_boxes, resolution):",
            "all_rois = tf.concat(all_rois, axis=0)  # NCHW",
            "# Unshuffle to the original order, to match the original samples",
            "level_id_perm = tf.concat(level_ids, axis=0)  # A permutation of 1~N",
            "-    level_id_invert_perm = tf.invert_permutation(level_id_perm)",
            "+    level_id_invert_perm = tf.math.invert_permutation(level_id_perm)",
            "all_rois = tf.gather(all_rois, level_id_invert_perm, name=\"output\")",
            "return all_rois"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 458,
        "change": [
            "def SoftMax(x, use_temperature=False, temperature_init=1.0):",
            ":param x: a 2D tensor",
            "\"\"\"",
            "if use_temperature:",
            "-        t = tf.get_variable('temp', [1],",
            "+        t = tf.get_variable('invtemp', [],",
            "initializer=tf.constant_initializer(1.0 / float(temperature_init)))",
            "x = x * t",
            "return tf.nn.softmax(x, name='output')"
        ],
        "comments": "change param for math fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 459,
        "change": [
            "def _preprocess_deconv_output_shape(x, shape, dim_ordering):",
            "shape = (shape[0], shape[2], shape[3], shape[1])",
            "",
            "if shape[0] is None:",
            "-        shape = (tf.shape(x)[0], ) + shape[1:]",
            "+        shape = (tf.shape(x)[0], ) + tuple(shape[1:])",
            "return shape"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 462,
        "change": [
            "class RGCNConv(MessagePassing):",
            "return out if edge_norm is None else out * edge_norm.view(-1, 1)",
            "",
            "def update(self, aggr_out, x):",
            "-        if x.dtype == torch.long:",
            "+        if x is None:",
            "out = aggr_out + self.root",
            "else:",
            "out = aggr_out + torch.matmul(x, self.root)"
        ],
        "comments": "change condition check for null fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Null Reference Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Program Crash|Null Reference Error"
    },
    {
        "number": 470,
        "change": [
            "class DenseGCNConv(torch.nn.Module):",
            "idx = torch.arange(N, dtype=torch.long, device=adj.device)",
            "adj[:, idx, idx] = 1 if not self.improved else 2",
            "",
            "-        out = self.lin(x)",
            "+        out = torch.matmul(x, self.weight)",
            "deg_inv_sqrt = adj.sum(dim=-1).clamp(min=1).pow(-0.5)",
            "",
            "adj = deg_inv_sqrt.unsqueeze(-1) * adj * deg_inv_sqrt.unsqueeze(-2)"
        ],
        "comments": "change API call for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 472,
        "change": [
            "class GradientsTest(tf.test.TestCase):",
            "",
            "",
            "if __name__ == \"__main__\":",
            "-  tf.test.main()",
            "+  if tf.__internal__.tf2.enabled():",
            "+    tf.test.main()"
        ],
        "comments": "add condition check for state fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 473,
        "change": [
            "class Model(ModelDesc):",
            "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)",
            "cost = tf.reduce_mean(cost, name='cross_entropy_loss')",
            "",
            "-        acc = tf.to_float(tf.nn.in_top_k(logits, label, 1))",
            "+        acc = tf.cast(tf.nn.in_top_k(logits, label, 1), tf.float32)",
            "",
            "acc = tf.reduce_mean(acc, name='accuracy')",
            "summary.add_moving_summary(acc)"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 476,
        "change": [
            "class TFCoreModelTesterMixin:",
            "",
            "self.assertIsNotNone(outputs)",
            "",
            "-        tf.keras.mixed_precision.experimental.set_policy(\"float32\")",
            "+        tf.keras.mixed_precision.set_global_policy(\"float32\")",
            "",
            "@slow",
            "def test_train_pipeline_custom_model(self):"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 479,
        "change": [
            "class TFMBartForConditionalGeneration(TFMBartPreTrainedModel, TFCausalLanguageMo",
            "if labels is not None:",
            "labels = tf.where(",
            "labels == self.config.pad_token_id,",
            "-                tf.fill(shape_list(labels), -100),",
            "+                tf.cast(tf.fill(shape_list(labels), -100), labels.dtype),",
            "labels,",
            ")",
            "use_cache = False"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 481,
        "change": [
            "def main():",
            "# Setup CUDA, GPU & distributed training",
            "if args.local_rank == -1 or args.no_cuda:",
            "device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")",
            "-        args.n_gpu = torch.cuda.device_count()",
            "+        args.n_gpu = 0 if args.no_cuda else torch.cuda.device_count()",
            "else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs",
            "torch.cuda.set_device(args.local_rank)",
            "device = torch.device(\"cuda\", args.local_rank)"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 482,
        "change": [
            "class Pandas(datasets.ArrowBasedBuilder):",
            "return pa_table",
            "",
            "def _generate_tables(self, files):",
            "-        for i, file in enumerate(files):",
            "+        for i, file in enumerate(itertools.chain.from_iterable(files)):",
            "with open(file, \"rb\") as f:",
            "pa_table = pa.Table.from_pandas(pd.read_pickle(f))",
            "yield i, self._cast_table(pa_table)"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 483,
        "change": [
            "class DiceLoss(nn.Module):",
            "cardinality = torch.sum(input_soft + target_one_hot, dims)",
            "",
            "dice_score = 2. * intersection / (cardinality + self.eps)",
            "-        return torch.mean(1. - dice_score)",
            "+        return torch.mean(torch.tensor(1.) - dice_score)",
            "",
            "",
            "######################"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 488,
        "change": [
            "class SageMakerTrainingArguments(TrainingArguments):",
            "# Here, we'll use torch.distributed.",
            "# Initializes the distributed backend which will take care of synchronizing nodes/GPUs",
            "if not torch.distributed.is_initialized():",
            "-                torch.distributed.init_process_group(backend=\"nccl\")",
            "+                torch.distributed.init_process_group(backend=\"nccl\", timeout=self.ddp_timeout_delta)",
            "device = torch.device(\"cuda\", self.local_rank)",
            "self._n_gpu = 1"
        ],
        "comments": "add param for state fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 489,
        "change": [
            "def main(_):",
            "# net = tl.layers.ReshapeLayer(net,",
            "#       shape=[-1, int(net.outputs._shape[-1])], name='reshape')",
            "net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop3')",
            "-            net = tl.layers.DenseLayer(net, vocab_size, W_init=init, b_init=init, act=tf.identity, name='output')",
            "+            net = tl.layers.DenseLayer(net, vocab_size, W_init=init, b_init=init, act=None, name='output')",
            "return net, lstm1, lstm2",
            "",
            "# Inference for Training"
        ],
        "comments": "change param for null fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 494,
        "change": [
            "class DecoderLayer(nn.Module):",
            "self.sublayer = nn_util.clone(SublayerConnection(size, dropout), 3)",
            "",
            "def forward(",
            "-        self, x: torch.Tensor, memory: torch.Tensor, src_mask: torch.Tensor, tgt_mask: torch.Tensor",
            "+        self,",
            "+        x: torch.Tensor,",
            "+        memory: torch.Tensor,",
            "+        src_mask: torch.BoolTensor,",
            "+        tgt_mask: torch.BoolTensor,",
            ") -> torch.Tensor:",
            "# Follow Figure 1 (right) for connections.",
            "x = self.sublayer[0](x, lambda y: self.self_attn(y, y, y, tgt_mask))"
        ],
        "comments": "update param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 497,
        "change": [
            "class EvalbBracketingScorer(Metric):",
            "shutil.rmtree(tempdir)",
            "",
            "if is_distributed():",
            "-            # Setting the device to CPU since this metric is not expected to run on GPUs.",
            "-            device = torch.device(\"cpu\")",
            "+            device = torch.device(\"cuda\" if dist.get_backend() == \"nccl\" else \"cpu\")",
            "correct_predicted_brackets = torch.tensor(_correct_predicted_brackets).to(device)",
            "predicted_brackets = torch.tensor(_predicted_brackets).to(device)",
            "gold_brackets = torch.tensor(_gold_brackets).to(device)"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 501,
        "change": [
            "class E2E(torch.nn.Module):",
            "# Neither CPUTensor nor float/int value can be used",
            "# because NCCL communicates between GPU devices.",
            "device = next(self.parameters()).device",
            "-        acc = torch.tensor([acc], device=device)",
            "+",
            "+        acc = torch.tensor([acc], device=device) if acc is not None else None",
            "cer = torch.tensor([cer], device=device)",
            "wer = torch.tensor([wer], device=device)",
            "return self.loss, loss_ctc, loss_att, acc, cer, wer"
        ],
        "comments": "add condition check for null fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Null Reference Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Null Reference Error"
    },
    {
        "number": 502,
        "change": [
            "class DeepQNetwork(ValueFunction):",
            "\"\"\"",
            "",
            "# Compute estimated future value",
            "-        float_terminals = tf.to_float(batch['terminals'])",
            "+        float_terminals = batch['terminals'].astype(float)",
            "q_targets = batch['rewards'] + (1. - float_terminals) \\",
            "* self.gamma * self.get_target_values(batch['next_states'])"
        ],
        "comments": "remove API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 508,
        "change": [
            "class DistributedFusedAdam(torch.optim.Optimizer):",
            "grp = torch.distributed.new_group(ranks=ranks)",
            "if torch.distributed.get_rank() in ranks:",
            "self._rs_pg.append(grp)",
            "-            if self._compute_L2_grad_norm and torch.distributed.get_rank() in ranks:",
            "-                self._l2_grad_norm_pg = torch.distributed.new_group(ranks=ranks)",
            "-                torch.distributed.all_reduce(self._overflow_buf,group=self._l2_grad_norm_pg)",
            "+            if self._compute_L2_grad_norm:",
            "+                l2_grad_norm_pg = torch.distributed.new_group(ranks=ranks)",
            "+                if torch.distributed.get_rank() in ranks:",
            "+                    self._l2_grad_norm_pg = l2_grad_norm_pg",
            "+                    torch.distributed.all_reduce(self._overflow_buf,group=self._l2_grad_norm_pg)",
            "self._rs_st = [torch.cuda.Stream() for _ in range(self._num_rs_pg)]",
            "for rs_pg in self._rs_pg:",
            "torch.distributed.all_reduce(self._overflow_buf,group=rs_pg)"
        ],
        "comments": "remove condition check for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 510,
        "change": [
            "def cartesian_product_of_parameters(**possible_parameters):",
            "",
            "",
            "def default_with_one_parameter_changed(*, default={}, **possible_parameters):",
            "-    assert isinstance(default, dict), f\"default should be a dict not a {type(default)}\"",
            "+    if not isinstance(default, dict):",
            "+        raise AssertionError(f\"default should be a dict not a {type(default)}\")",
            "",
            "for parameter_name, possible_values in possible_parameters.items():",
            "for v in possible_values:"
        ],
        "comments": "add condition check for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Argument Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Program Crash|Argument Error"
    },
    {
        "number": 516,
        "change": [
            "class Speech2Text2SinusoidalPositionalEmbedding(nn.Module):",
            "emb = torch.cat([emb, torch.zeros(num_embeddings, 1)], dim=1)",
            "if padding_idx is not None:",
            "emb[padding_idx, :] = 0",
            "-        return emb",
            "+        return emb.to(torch.get_default_dtype())",
            "",
            "@torch.no_grad()",
            "def forward(self, input_ids: torch.Tensor, past_key_values_length: int = 0):"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 518,
        "change": [
            "class EulerAncestralDiscreteScheduler(SchedulerMixin, ConfigMixin):",
            "",
            "prev_sample = sample + derivative * dt",
            "",
            "-        device = model_output.device if torch.is_tensor(model_output) else \"cpu\"",
            "-        if str(device) == \"mps\":",
            "+        device = model_output.device if torch.is_tensor(model_output) else torch.device(\"cpu\")",
            "+        if device.type == \"mps\":",
            "# randn does not work reproducibly on mps",
            "noise = torch.randn(model_output.shape, dtype=model_output.dtype, device=\"cpu\", generator=generator).to(",
            "device"
        ],
        "comments": "add API call for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 519,
        "change": [
            "class AutoRegressiveNN(nn.Module):",
            "",
            "if permutation is None:",
            "# By default set a random permutation of variables, which is important for performance with multiple steps",
            "-            self.permutation = torch.randperm(input_dim)",
            "+            self.permutation = torch.randperm(input_dim, device='cpu').to(torch.Tensor().device)",
            "else:",
            "# The permutation is chosen by the user",
            "self.permutation = permutation.type(dtype=torch.int64)"
        ],
        "comments": "add API call for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 522,
        "change": [
            "class StableDiffusionInpaintPipeline(DiffusionPipeline):",
            "else:",
            "raise ImportError(\"Please install accelerate via `pip install accelerate`\")",
            "",
            "-        device = torch.device(\"cuda\")",
            "+        device = torch.device(f\"cuda:{gpu_id}\")",
            "",
            "for cpu_offloaded_model in [self.unet, self.text_encoder, self.vae, self.safety_checker]:",
            "if cpu_offloaded_model is not None:"
        ],
        "comments": "change param for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 524,
        "change": [
            "class TwoStageDetector(BaseDetector, RPNTestMixin, BBoxTestMixin,",
            "if self.with_rpn:",
            "rpn_outs = self.rpn_head(x)",
            "outs = outs + (rpn_outs, )",
            "-        proposals = torch.randn(1000, 4).cuda()",
            "+        proposals = torch.randn(1000, 4).to(device=img.device)",
            "# bbox head",
            "rois = bbox2roi([proposals])",
            "if self.with_bbox:"
        ],
        "comments": "change API call for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 526,
        "change": [
            "class PGModel(Model):",
            "actions = np.concatenate([path['actions'] for path in batch])",
            "batch_advantage = np.concatenate([path[\"advantage\"] for path in batch])",
            "batch_advantage = zero_mean_unit_variance(batch_advantage)",
            "+        batch_advantage = np.expand_dims(batch_advantage, axis=1)",
            "states = np.concatenate([path['states'] for path in batch])",
            "",
            "return action_log_stds, action_means, actions, batch_advantage, states"
        ],
        "comments": "add API call for shape fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 529,
        "change": [
            "class Categorical(Distribution):",
            "elif one_hot:",
            "boolean_mask = x",
            "else:",
            "-                boolean_mask = torch.zeros(ps.size()).scatter_(-1, x.data.long(), 1)",
            "+                boolean_mask = torch_zeros_like(ps.data).scatter_(-1, x.data.long(), 1)",
            "# apply log function to masked probability tensor",
            "return torch.log(ps.masked_select(boolean_mask.byte()).contiguous().view(*batch_pdf_size))"
        ],
        "comments": "change API call for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 530,
        "change": [
            "class ViTMAEModelIntegrationTest(unittest.TestCase):",
            "",
            "# forward pass",
            "with torch.no_grad():",
            "-            outputs = model(**inputs, noise=torch.from_numpy(noise))",
            "+            outputs = model(**inputs, noise=torch.from_numpy(noise).to(device=torch_device))",
            "",
            "# verify the logits",
            "expected_shape = torch.Size((1, 196, 768))"
        ],
        "comments": "add API call for resource fixfor resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 532,
        "change": [
            "def initialize_vocabulary(vocabulary_path):",
            "rev_vocab = []",
            "with gfile.GFile(vocabulary_path, mode=\"rb\") as f:",
            "rev_vocab.extend(f.readlines())",
            "-    rev_vocab = [line.strip() for line in rev_vocab]",
            "+    rev_vocab = [tf.compat.as_bytes(line.strip()) for line in rev_vocab]",
            "vocab = dict([(x, y) for (y, x) in enumerate(rev_vocab)])",
            "return vocab, rev_vocab",
            "else:"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 534,
        "change": [
            "class ConformerSeparator(AbsSeparator):",
            "\"\"\"",
            "",
            "# if complex spectrum,",
            "-        if isinstance(input, ComplexTensor):",
            "+        if isinstance(input, ComplexTensor) or (",
            "+            is_torch_1_8_plus and torch.is_complex(input)",
            "+        ):",
            "feature = abs(input)",
            "else:",
            "feature = input"
        ],
        "comments": "add condition check for version fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Condition",
        "Action_Element": "Replace API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 537,
        "change": [
            "def batch_flatten(x):",
            "'''Turn a n-D tensor into a 2D tensor where",
            "the first dimension is conserved.",
            "'''",
            "-    x = tf.reshape(x, [-1, prod(shape(x)[1:])])",
            "+    x = tf.reshape(x, tf.pack([-1, prod(shape(x)[1:])]))",
            "return x"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 538,
        "change": [
            "def distributed_train(local_rank: int, main_address: str, main_port: int, num_no",
            "# 2. PREPARE DISTRIBUTED MODEL",
            "model = torch.nn.Linear(32, 2)",
            "device = torch.device(f\"cuda:{local_rank}\") if torch.cuda.is_available() else torch.device(\"cpu\")",
            "-    model = DistributedDataParallel(model, device_ids=[local_rank]).to(device)",
            "+    model = DistributedDataParallel(model, device_ids=[local_rank] if torch.cuda.is_available() else None).to(device)",
            "",
            "# 3. SETUP LOSS AND OPTIMIZER",
            "criterion = torch.nn.MSELoss()"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 545,
        "change": [
            "if __name__ == '__main__':",
            "",
            "# dataset = roiLoader(roidb, imdb.num_classes)",
            "dataset = roibatchLoader(roidb, imdb.num_classes)",
            "-  dataloader = torch.utils.data.DataLoader(dataset, batch_size=cfg.TRAIN.IMS_PER_BATCH,",
            "+  dataloader = torch.utils.data.DataLoader(dataset, batch_size=8,",
            "shuffle=False, num_workers=5)",
            "",
            "# initilize the tensor holder here."
        ],
        "comments": "change param for shape fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 548,
        "change": [
            "class VisionTransformer(nn.Module):",
            "",
            "def forward(self, x):",
            "x = self.forward_features(x)",
            "-        if isinstance(x, tuple):",
            "-            x, x_dist = self.head(x[0]), self.head_dist(x[1])",
            "+        if self.head_dist is not None:",
            "+            x, x_dist = self.head(x[0]), self.head_dist(x[1])  # x must be a tuple",
            "if self.training and not torch.jit.is_scripting():",
            "# during inference, return the average of both classifier predictions",
            "return x, x_dist"
        ],
        "comments": "change condition check for null fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Condition",
        "Action_Element": "Replace API Condition",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 549,
        "change": [
            "class TFKerasUtil(object):",
            "",
            "dataset = dataset.batch(batch_size).map(prep_data_tf_keras)",
            "return dataset",
            "-        return fn",
            "+        return tf.autograph.experimental.do_not_convert(fn) if _HAS_AUTOGRAPH else fn",
            "",
            "@staticmethod",
            "def get_horovod():"
        ],
        "comments": "add condition check for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 554,
        "change": [
            "with tf.device('/cpu:0'):",
            "net = FlattenLayer(net, name='flatten')",
            "net = DenseLayer(net, 384, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='d1relu')",
            "net = DenseLayer(net, 192, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='d2relu')",
            "-            net = DenseLayer(net, n_units=10, act=tf.identity, W_init=W_init2, name='output')",
            "+            net = DenseLayer(net, n_units=10, act=None, W_init=W_init2, name='output')",
            "y = net.outputs",
            "",
            "ce = tl.cost.cross_entropy(y, y_, name='cost')"
        ],
        "comments": "change param for null fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 557,
        "change": [
            "class up(nn.Module):",
            "if bilinear:",
            "self.up = nn.UpsamplingBilinear2d(scale_factor=2)",
            "else:",
            "-            self.up = nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2)",
            "+            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)",
            "",
            "self.conv = double_conv(in_ch, out_ch)"
        ],
        "comments": "change param for math fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Device Management Error"
    },
    {
        "number": 559,
        "change": [
            "class Metric(nn.Module, ABC):",
            "Automatically calls ``update()``. Returns the metric value over inputs if ``compute_on_step`` is True.",
            "\"\"\"",
            "# add current step",
            "-        self.update(*args, **kwargs)",
            "+        with torch.no_grad():",
            "+            self.update(*args, **kwargs)",
            "self._forward_cache = None",
            "",
            "if self.compute_on_step:"
        ],
        "comments": "add API call for state fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "State Handling Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Unexpected Output|State Handling Error"
    },
    {
        "number": 560,
        "change": [
            "temperature = max(args.temperature, 1e-3)",
            "with open(args.outf, 'w') as outf:",
            "for i in range(args.nwords):",
            "",
            "-        output, hidden = model(Variable(input, requires_grad=False), hidden)",
            "-        gen = torch.multinomial(output[0].data.cpu().div(temperature).exp(), 1)[0][0] # FIXME: no multinomial on GPU?",
            "+        output, hidden = model(Variable(input, volatile=True), hidden)",
            "+        gen = torch.multinomial(output[0].data.div(temperature).exp().cpu(), 1)[0][0] # FIXME: multinomial is only for CPU",
            "input.fill_(gen)",
            "word = corpus.dic.idx2word[gen]",
            "outf.write(word)"
        ],
        "comments": "change API call for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 561,
        "change": [
            "class TFFunnelForMultipleChoice(TFFunnelPreTrainedModel, TFMultipleChoiceLoss):",
            "@tf.function(",
            "input_signature=[",
            "{",
            "-                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),",
            "+                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),",
            "\"attention_mask\": tf.TensorSpec((None, None), tf.float32, name=\"attention_mask\"),",
            "-                \"token_type_ids\": tf.TensorSpec((None, None), tf.int64, name=\"token_type_ids\"),",
            "+                \"token_type_ids\": tf.TensorSpec((None, None), tf.int32, name=\"token_type_ids\"),",
            "}",
            "]",
            ")"
        ],
        "comments": "change param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 566,
        "change": [
            "class ModelSaver(Callback):",
            "self.var_collections = var_collections",
            "if checkpoint_dir is None:",
            "checkpoint_dir = logger.get_logger_dir()",
            "-        assert checkpoint_dir is not None",
            "-        if not tf.gfile.IsDirectory(checkpoint_dir):",
            "-            tf.gfile.MakeDirs(checkpoint_dir)",
            "+        if checkpoint_dir is not None:",
            "+            if not tf.gfile.IsDirectory(checkpoint_dir):",
            "+                tf.gfile.MakeDirs(checkpoint_dir)",
            "self.checkpoint_dir = checkpoint_dir",
            "",
            "def _setup_graph(self):",
            "+        assert self.checkpoint_dir is not None, \\",
            "+            \"ModelSaver() doesn't have a valid checkpoint directory.\"",
            "vars = []",
            "for key in self.var_collections:",
            "vars.extend(tf.get_collection(key))"
        ],
        "comments": "change condition check for null fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 571,
        "change": [
            "class ModelCheckpoint(Callback):",
            "self.best_k_models.pop(del_filepath)",
            "",
            "# do not save nan, replace with +/- inf",
            "-        if torch.isnan(current):",
            "+        if isinstance(current, torch.Tensor) and torch.isnan(current):",
            "current = torch.tensor(float('inf' if self.mode == \"min\" else '-inf'))",
            "",
            "filepath = self._get_metric_interpolated_filepath_name(ckpt_name_metrics, epoch, step, del_filepath)"
        ],
        "comments": "change condition check for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 574,
        "change": [
            "class Graph(kerastuner.HyperModel, serializable.Serializable):",
            "",
            "def build(self, hp):",
            "\"\"\"Build the HyperModel into a Keras Model.\"\"\"",
            "-        tf.keras.backend.clear_session()",
            "self._register_hps(hp)",
            "self.compile()",
            "real_nodes = {}"
        ],
        "comments": "remove API call for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 575,
        "change": [
            "class TensorflowONNXTensorRTInferenceLearner(",
            "else None",
            ")",
            "out_arrays = self._predict_array(cuda_input_arrays, input_shapes)",
            "-        return tuple(tf.convert_to_tensor(array) for array in out_arrays)",
            "+        return tuple(tf.convert_to_tensor(array[0]) for array in out_arrays)",
            "",
            "",
            "class NumpyONNXTensorRTInferenceLearner("
        ],
        "comments": "change param for shape fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 578,
        "change": [
            "class GroupViTVisionTransformer(nn.Module):",
            "",
            "self.embeddings = GroupViTVisionEmbeddings(config)",
            "self.encoder = GroupViTVisionEncoder(config)",
            "-        self.layernorm = nn.LayerNorm(embed_dim)",
            "+        self.layernorm = nn.LayerNorm(embed_dim, eps=config.layer_norm_eps)",
            "",
            "@add_start_docstrings_to_model_forward(GROUPVIT_VISION_INPUTS_DOCSTRING)",
            "@replace_return_docstrings(output_type=BaseModelOutputWithPooling, config_class=GroupViTVisionConfig)"
        ],
        "comments": "add param for math fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 585,
        "change": [
            "class TestTrainSampleHook(tf.test.TestCase):",
            "pred_dict = {}",
            "pred_dict[\"predicted_tokens\"] = tf.constant([[\"Hello\", \"World\", \"笑w\"]])",
            "pred_dict[\"labels.target_tokens\"] = tf.constant([[\"Hello\", \"World\", \"笑w\"]])",
            "-    pred_dict[\"labels.target_len\"] = tf.constant([2]),",
            "+    pred_dict[\"labels.target_len\"] = tf.constant(2),",
            "graph_utils.add_dict_to_collection(pred_dict, \"predictions\")",
            "",
            "def tearDown(self):"
        ],
        "comments": "change param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 587,
        "change": [
            "class VonMises(TorchDistribution):",
            "\"\"\"",
            "shape = self._extended_shape(sample_shape)",
            "x = torch.empty(shape, dtype=self.loc.dtype, device=self.loc.device)",
            "-        done = torch.zeros(shape, dtype=self.loc.dtype, device=self.loc.device).byte()",
            "+        done = torch.zeros(shape, dtype=self.loc.dtype, device=self.loc.device).bool()",
            "while not done.all():",
            "u = torch.rand((3,) + shape, dtype=self.loc.dtype, device=self.loc.device)",
            "u1, u2, u3 = u.unbind()"
        ],
        "comments": "change API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 591,
        "change": [
            "class Model(ModelDesc):",
            "self.last_state = tf.identity(last_state, 'last_state')",
            "",
            "# seqlen x (Bxrnnsize)",
            "-        output = tf.reshape(tf.concat(1, outputs), [-1, param.rnn_size])  # (Bxseqlen) x rnnsize",
            "+        output = tf.reshape(tf.concat_v2(outputs, 1), [-1, param.rnn_size])  # (Bxseqlen) x rnnsize",
            "logits = FullyConnected('fc', output, param.vocab_size, nl=tf.identity)",
            "self.prob = tf.nn.softmax(logits / param.softmax_temprature)"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 595,
        "change": [
            "def fit_line(points: Tensor, weights: Optional[Tensor] = None) -> ParametrizedLi",
            "A = A.transpose(-2, -1) @ A",
            "",
            "# NOTE: not optimal for 2d points, but for now works for other dimensions",
            "-    _, _, V = torch.linalg.svd(A)",
            "+    _, _, V = _torch_svd_cast(A)",
            "+    V = V.transpose(-2, -1)",
            "",
            "# the first left eigenvector is the direction on the fited line",
            "direction = V[..., 0, :]  # BxD"
        ],
        "comments": "change API call for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 596,
        "change": [
            "def ndim(x):",
            "'''Returns the number of axes in a tensor, as an integer.",
            "'''",
            "if is_sparse(x):",
            "-        return int(x.shape.get_shape()[0])",
            "+        return x._dims",
            "",
            "dims = x.get_shape()._dims",
            "if dims is not None:"
        ],
        "comments": "change API call for shape fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 599,
        "change": [
            "def convert_pandas_to_tf_tensor(",
            "# them. If the columns contain different types (for example, `float32`s",
            "# and `int32`s), then `tf.concat` raises an error.",
            "dtype: np.dtype = np.find_common_type(df.dtypes, [])",
            "+",
            "+            # if the columns are `ray.data.extensions.tensor_extension.TensorArray`,",
            "+            # the dtype will be `object`. In this case, we need to set the dtype to",
            "+            # none, and use the automatic type casting of `tf.convert_to_tensor`.",
            "+            if isinstance(dtype, object):",
            "+                dtype = None",
            "+",
            "except TypeError:",
            "# `find_common_type` fails if a series has `TensorDtype`. In this case,",
            "# don't cast any of the series and continue."
        ],
        "comments": "add condition check for null fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 600,
        "change": [
            "def initialize(model: torch.nn.Module, init: str):",
            "",
            "# reset some modules with default init",
            "for m in model.modules():",
            "-            if isinstance(m, (torch.nn.Embedding, torch.nn.LayerNorm)):",
            "+            if isinstance(m, (torch.nn.Embedding, torch.nn.LayerNorm, torch.nn.GroupNorm)):",
            "m.reset_parameters()",
            "if hasattr(m, \"espnet_initialization_fn\"):",
            "m.espnet_initialization_fn()"
        ],
        "comments": "add param for argument fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 601,
        "change": [
            "class Model(ModelDesc):",
            "input_list = tf.unstack(input_feature, axis=1)  # seqlen x (Bxrnnsize)",
            "",
            "# seqlen is 1 in inference. don't need loop_function",
            "-        outputs, last_state = tf.nn.rnn(cell, input_list, initial, scope='rnnlm')",
            "+        outputs, last_state = tf.contrib.rnn.static_rnn(cell, input_list, initial, scope='rnnlm')",
            "self.last_state = tf.identity(last_state, 'last_state')",
            "",
            "# seqlen x (Bxrnnsize)"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 611,
        "change": [
            "class Attention(nn.Module):",
            "query, processed_inputs)",
            "# apply masking",
            "if mask is not None:",
            "-            attention.data.masked_fill_(torch.bitwise_not(mask), self._mask_value)",
            "+            attention.data.masked_fill_(~mask, self._mask_value)",
            "# apply windowing - only in eval mode",
            "if not self.training and self.windowing:",
            "attention = self.apply_windowing(attention, inputs)"
        ],
        "comments": "remove API call for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 613,
        "change": [
            "class EarlyStopping(Callback):",
            "f\" {self.monitor} = {current} {self.order_dict[self.mode]} {self.divergence_threshold}.\"",
            "\" Signaling Trainer to stop.\"",
            ")",
            "-        elif self.monitor_op(current - self.min_delta, self.best_score):",
            "+        elif self.monitor_op(current - self.min_delta, self.best_score.to(trainer.lightning_module.device)):",
            "should_stop = False",
            "reason = self._improvement_message(current)",
            "self.best_score = current"
        ],
        "comments": "add API call for resource fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Device Management Error"
    },
    {
        "number": 614,
        "change": [
            "class LSTM(Model):",
            "last_layer = add_time_dimension(features, self.seq_lens)",
            "",
            "# Setup the LSTM cell",
            "-        lstm = rnn.BasicLSTMCell(cell_size, state_is_tuple=True)",
            "+        lstm = tf.nn.rnn_cell.LSTMCell(cell_size, state_is_tuple=True)",
            "self.state_init = [",
            "np.zeros(lstm.state_size.c, np.float32),",
            "np.zeros(lstm.state_size.h, np.float32)"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 615,
        "change": [
            "class XGLMModel(XGLMPreTrainedModel):",
            "",
            "hidden_states = inputs_embeds + positions",
            "",
            "-        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)",
            "+        hidden_states = nn.functional.dropout(hidden_states, p=float(self.dropout), training=self.training)",
            "",
            "# decoder layers",
            "all_hidden_states = () if output_hidden_states else None"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 619,
        "change": [
            "class Imagen(nn.Module):",
            "text_embeds, text_masks = t5_encode_text(texts, name = self.text_encoder_name, return_attn_mask = True)",
            "text_embeds, text_masks = map(lambda t: t.to(images.device), (text_embeds, text_masks))",
            "",
            "-        text_masks = default(text_masks, lambda: torch.any(text_embeds != 0., dim = -1))",
            "+        if not self.unconditional:",
            "+            text_masks = default(text_masks, lambda: torch.any(text_embeds != 0., dim = -1))",
            "",
            "assert not (self.condition_on_text and not exists(text_embeds)), 'text or text encodings must be passed into decoder if specified'",
            "assert not (not self.condition_on_text and exists(text_embeds)), 'decoder specified not to be conditioned on text, yet it is presented'"
        ],
        "comments": "add condition check for math fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 621,
        "change": [
            "def conditional(",
            "if f_scale_tril is not None:",
            "pack = torch.cat((pack, f_scale_tril_2D), dim=1)",
            "",
            "-        Lffinv_pack = pack.triangular_solve(Lff, upper=False)[0]",
            "+        Lffinv_pack = torch.linalg.solve_triangular(Lff, pack, upper=False)",
            "# unpack",
            "v_2D = Lffinv_pack[:, : f_loc_2D.size(1)]",
            "W = Lffinv_pack[:, f_loc_2D.size(1) : f_loc_2D.size(1) + M].t()"
        ],
        "comments": "change API call for refactor fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 623,
        "change": [
            "class Model(ModelDesc):",
            "wrong = prediction_incorrect(logits, label, 5, name='wrong-top5')",
            "add_moving_summary(tf.reduce_mean(wrong, name='train-error-top5'))",
            "",
            "-        wd_cost = tf.mul(1e-4, regularize_cost('.*/W', tf.nn.l2_loss), name='l2_regularize_loss')",
            "+        wd_cost = regularize_cost('.*/W', l2_regularizer(1e-4), name='l2_regularize_loss')",
            "add_moving_summary(loss, wd_cost)",
            "self.cost = tf.add_n([loss, wd_cost], name='cost')"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 627,
        "change": [
            "class Optimizer:",
            "g = [dev_grads[dev][var_idx][0] for dev in devices]",
            "",
            "if np.prod(grad_shape):  # nccl does not support zero-sized tensors",
            "-                            g = tf.contrib.nccl.all_sum(g)",
            "+                            g = nccl_ops.all_sum(g)",
            "",
            "for dev, gg in zip(devices, g):",
            "dev_grads[dev][var_idx] = (gg, dev_grads[dev][var_idx][1])"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 633,
        "change": [
            "class Decoder(torch.nn.Module, ScorerInterface):",
            "",
            "if self.labeldist is not None:",
            "if self.vlabeldist is None:",
            "-                self.vlabeldist = to_device(hs_pad, torch.from_numpy(self.labeldist))",
            "+                self.vlabeldist = to_device(hs_pad[0], torch.from_numpy(self.labeldist))",
            "loss_reg = -torch.sum(",
            "(F.log_softmax(y_all, dim=1) * self.vlabeldist).view(-1), dim=0",
            ") / len(ys_in)"
        ],
        "comments": "change param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 635,
        "change": [
            "class TransformerModel(nn.Module):",
            "def init_weights(self):",
            "initrange = 0.1",
            "nn.init.uniform_(self.encoder.weight, -initrange, initrange)",
            "-        nn.init.zeros_(self.decoder.weight)",
            "+        nn.init.zeros_(self.decoder.bias)",
            "nn.init.uniform_(self.decoder.weight, -initrange, initrange)",
            "",
            "def forward(self, src, has_mask=True):"
        ],
        "comments": "change param for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 637,
        "change": [
            "import syft",
            "def model():",
            "l_in, l_h, l_out = 32, 16, 2",
            "model = crypten.nn.Sequential(",
            "-        [crypten.nn.Linear(l_in, l_h), crypten.nn.ReLU(), crypten.nn.Linear(l_h, l_out)]",
            "+        crypten.nn.Linear(l_in, l_h), crypten.nn.ReLU(), crypten.nn.Linear(l_h, l_out)",
            ")",
            "return model"
        ],
        "comments": "change param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 639,
        "change": [
            "class LinearModel(object):",
            "return self.sess.run(self.cross_entropy_grads, feed_dict={self.x: xs, self.y_: ys})",
            "",
            "def net_initialization():",
            "-  return LinearModel([784,10])",
            "+  with tf.Graph().as_default():",
            "+    return LinearModel([784,10])",
            "",
            "# By default, when an environment variable is used by a remote function, the",
            "# initialization code will be rerun at the end of the remote task to ensure"
        ],
        "comments": "add API call for state fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 641,
        "change": [
            "class LinearRegression(d2l.Module):",
            "def __init__(self, lr):",
            "super().__init__()",
            "self.save_hyperparameters()",
            "-        self.net = tf.keras.layers.Dense(1)",
            "+        initializer = tf.initializers.RandomNormal(stddev=0.01)",
            "+        self.net = tf.keras.layers.Dense(1, kernel_initializer=initializer)",
            "",
            "def forward(self, X):",
            "\"\"\"The linear regression model."
        ],
        "comments": "add param for argument fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 642,
        "change": [
            "class TorchCategorical(TorchDistributionWrapper):",
            "\"\"\"Wrapper class for PyTorch Categorical distribution.\"\"\"",
            "",
            "@override(ActionDistribution)",
            "-    def __init__(self, inputs, model):",
            "-        super().__init__(inputs, model)",
            "-        self.dist = torch.distributions.categorical.Categorical(logits=inputs)",
            "+    def __init__(self, inputs, model=None, temperature=1.0):",
            "+        assert temperature > 0.0, \"Categorical `temperature` must be > 0.0!\"",
            "+        super().__init__(inputs / temperature, model)",
            "+        self.dist = torch.distributions.categorical.Categorical(",
            "+            logits=self.inputs)",
            "",
            "@override(ActionDistribution)",
            "def deterministic_sample(self):"
        ],
        "comments": "add param for version fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 643,
        "change": [
            "class TestPretrainedTransformerEmbedder(AllenNlpTestCase):",
            "def test_xlnet_token_type_ids(self):",
            "token_embedder = PretrainedTransformerEmbedder(\"xlnet-base-cased\")",
            "token_ids = torch.LongTensor([[1, 2, 3], [2, 3, 4]])",
            "-        mask = torch.ones_like(token_ids)",
            "+        mask = torch.ones_like(token_ids).bool()",
            "type_ids = torch.zeros_like(token_ids)",
            "type_ids[1, 1] = 1",
            "token_embedder(token_ids, mask, type_ids)"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 645,
        "change": [
            "class Block(Layer):",
            "layer_counter[layer_type] += 1",
            "",
            "# layer_name = self.name + '-' + layer_name",
            "-            self.layers[n] = self.submodule(",
            "+            layer = self.submodule(",
            "name=layer_name, module=layer_spec, modules=tensorforce.core.layer_modules,",
            "input_spec=self._input_spec",
            ")",
            "-            self._input_spec = self.layers[n].output_spec()",
            "-",
            "+            self.layers.append(layer)",
            "+            self._input_spec = layer.output_spec()",
            "",
            "return self.layers[0].input_spec.copy()"
        ],
        "comments": "change param for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 648,
        "change": [
            "def model():",
            "",
            "if sd_vae_approx_model is None:",
            "sd_vae_approx_model = VAEApprox()",
            "-        sd_vae_approx_model.load_state_dict(torch.load(os.path.join(paths.models_path, \"VAE-approx\", \"model.pt\")))",
            "+        sd_vae_approx_model.load_state_dict(torch.load(os.path.join(paths.models_path, \"VAE-approx\", \"model.pt\"), map_location='cpu' if devices.device.type != 'cuda' else None))",
            "sd_vae_approx_model.eval()",
            "sd_vae_approx_model.to(devices.device, devices.dtype)"
        ],
        "comments": "add param for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 654,
        "change": [
            "class FP16_DeepSpeedZeroOptimizer(object):",
            "\"\"\" Perform all reduce within model parallel group, if any.",
            "\"\"\"",
            "if self.model_parallel_group is None:",
            "-            torch.distributed.all_reduce(tensor=tensor, op=op)",
            "+            pass",
            "else:",
            "torch.distributed.all_reduce(tensor=tensor,",
            "op=op,"
        ],
        "comments": "remove API call for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 655,
        "change": [
            "class {{cookiecutter.camelcase_modelname}}EncoderLayer(nn.Module):",
            "hidden_states = residual + hidden_states",
            "hidden_states = self.final_layer_norm(hidden_states)",
            "",
            "-        if torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any():",
            "+        if hidden_states.dtype == torch.float16 and (torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any()):",
            "clamp_value = torch.finfo(hidden_states.dtype).max - 1000",
            "hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)"
        ],
        "comments": "change condition check for state fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Null Reference Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Program Crash|Null Reference Error"
    },
    {
        "number": 656,
        "change": [
            "class LabelSmoother:",
            "",
            "def __call__(self, model_output, labels):",
            "logits = model_output[\"logits\"] if isinstance(model_output, dict) else model_output[0]",
            "-        log_probs = -torch.nn.functional.log_softmax(logits, dim=-1)",
            "+        log_probs = -nn.functional.log_softmax(logits, dim=-1)",
            "if labels.dim() == log_probs.dim() - 1:",
            "labels = labels.unsqueeze(-1)"
        ],
        "comments": "change API call for refactor fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 657,
        "change": [
            "class NonMaximaSuppression2d(nn.Module):",
            "def forward(self, x: torch.Tensor) -> torch.Tensor:  # type: ignore",
            "assert len(x.shape) == 4, x.shape",
            "# find local maximum values",
            "-        x_max: torch.Tensor = self.max_pool2d(x)",
            "+        x_max: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]] = \\",
            "+            self.max_pool2d(x)",
            "",
            "# create mask for maximums in the original map",
            "x_mask: torch.Tensor = torch.where("
        ],
        "comments": "add API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 659,
        "change": [
            "class ImageFeatureEmbeddings(Embeddings):",
            "",
            "def __init__(self, feature_size: int, embedding_size: int, dropout: float = 0.0):",
            "image_embeddings = torch.nn.Linear(feature_size, embedding_size)",
            "-        location_embeddings = torch.nn.Linear(4, embedding_size)",
            "+        location_embeddings = torch.nn.Linear(4, embedding_size, bias=False)",
            "embeddings = torch.nn.ModuleDict(",
            "{\"image_embeddings\": image_embeddings, \"location_embeddings\": location_embeddings}",
            ")"
        ],
        "comments": "add param for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 661,
        "change": [
            "class Model(ModelDesc):",
            ".apply(fg)",
            ".BatchNorm('bn5').apply(activate)",
            "# 5",
            "-                      .tf.nn.dropout(0.5 if is_training else 1.0)",
            "+                      .Dropout(rate=0.5 if is_training else 0.0)",
            ".Conv2D('conv6', 512, 5, padding='VALID')",
            ".apply(fg).BatchNorm('bn6')",
            ".apply(nonlin)"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Algorithm Error"
    },
    {
        "number": 665,
        "change": [
            "class BLEU(Metric):",
            "return math.exp(1.0 - self._reference_lengths / self._prediction_lengths)",
            "",
            "def _get_valid_tokens_mask(self, tensor: torch.LongTensor) -> torch.ByteTensor:",
            "-        valid_tokens_mask = torch.ones(tensor.size(), dtype=torch.uint8)",
            "+        valid_tokens_mask = torch.ones(tensor.size(), dtype=torch.bool)",
            "for index in self._exclude_indices:",
            "valid_tokens_mask = valid_tokens_mask & (tensor != index)",
            "return valid_tokens_mask"
        ],
        "comments": "change param for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 674,
        "change": [
            "class DecoderLayer(nn.Module):",
            "if self.normalize_before:",
            "x = self.norm2(x)",
            "if self.concate_after:",
            "-            x_concat = torch.cat(x, self.src_attn(x, memory, memory, memory_mask))",
            "+            x_concat = torch.cat((x, self.src_attn(x, memory, memory, memory_mask)), dim=-1)",
            "x = residual + self.concate_linear2(x_concat)",
            "else:",
            "x = residual + self.dropout(self.src_attn(x, memory, memory, memory_mask))"
        ],
        "comments": "add param for shape fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 676,
        "change": [
            "class RoBERTaEncoder(Encoder):",
            "@property",
            "def output_shape(self) -> torch.Size:",
            "if self.reduce_output is None:",
            "-            return torch.Size([self.max_sequence_length, self.transformer.module.config.hidden_size])",
            "+            return torch.Size([self.max_sequence_length - 2, self.transformer.module.config.hidden_size])",
            "return torch.Size([self.transformer.module.config.hidden_size])",
            "",
            "@property"
        ],
        "comments": "change param for math fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 677,
        "change": [
            "def clip(",
            "*,",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "-    assert torch.all(torch.less(x_min, x_max)), \"Min value must be less than max.\"",
            "+    assert torch.all(",
            "+        torch.less(torch.tensor(x_min), x_max)",
            "+    ), \"Min value must be less than max.\"",
            "if hasattr(x_min, \"dtype\"):",
            "promoted_type = torch.promote_types(x_min.dtype, x_max.dtype)",
            "promoted_type = torch.promote_types(promoted_type, x.dtype)"
        ],
        "comments": "change API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 678,
        "change": [
            "class TFTokenClassificationLoss:",
            ")",
            "# make sure only labels that are not equal to -100",
            "# are taken into account as loss",
            "-        if tf.math.reduce_any(labels == -1).numpy() is True:",
            "+        if tf.math.reduce_any(labels == -1):",
            "warnings.warn(\"Using `-1` to mask the loss for the token is deprecated. Please use `-100` instead.\")",
            "active_loss = tf.reshape(labels, (-1,)) != -1",
            "else:"
        ],
        "comments": "remove API call for type fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 681,
        "change": [
            "class LayoutLMv3Model(LayoutLMv3PreTrainedModel):",
            "position_ids = position_ids.expand_as(input_ids)",
            "final_position_ids = position_ids",
            "",
            "-        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(attention_mask, None, device)",
            "+        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(",
            "+            attention_mask, None, device, dtype=embedding_output.dtype",
            "+        )",
            "",
            "# Prepare head mask if needed",
            "# 1.0 in head_mask indicate we keep the head"
        ],
        "comments": "add param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 683,
        "change": [
            "class StableDiffusionKDiffusionPipeline(DiffusionPipeline):",
            "return_tensors=\"pt\",",
            ")",
            "text_input_ids = text_inputs.input_ids",
            "-        untruncated_ids = self.tokenizer(prompt, padding=\"max_length\", return_tensors=\"pt\").input_ids",
            "+        untruncated_ids = self.tokenizer(prompt, padding=\"longest\", return_tensors=\"pt\").input_ids",
            "",
            "-        if not torch.equal(text_input_ids, untruncated_ids):",
            "+        if untruncated_ids.shape[-1] >= text_input_ids.shape[-1] and not torch.equal(text_input_ids, untruncated_ids):",
            "removed_text = self.tokenizer.batch_decode(untruncated_ids[:, self.tokenizer.model_max_length - 1 : -1])",
            "logger.warning(",
            "\"The following part of your input was truncated because CLIP can only handle sequences up to\""
        ],
        "comments": "change condition check for shape fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 685,
        "change": [
            "def to_tf_values(result, path):",
            "",
            "class TFLogger(Logger):",
            "def _init(self):",
            "-        logger.info(",
            "-            \"Initializing TFLogger instead of TF2Logger. We recommend \"",
            "-            \"migrating to TF2.0. This class will be removed in the future.\")",
            "-        self._file_writer = tf.summary.FileWriter(self.logdir)",
            "+        logger.info(\"Initializing TFLogger instead of TF2Logger.\")",
            "+        self._file_writer = tf.compat.v1.summary.FileWriter(self.logdir)",
            "",
            "def on_result(self, result):",
            "tmp = result.copy()"
        ],
        "comments": "change API call for refactor fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 693,
        "change": [
            "class Ensemble(nn.ModuleList):",
            "",
            "",
            "def attempt_load(weights, device=None, inplace=True, fuse=True):",
            "+    # Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a",
            "from models.yolo import Detect, Model",
            "",
            "-    # Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a",
            "model = Ensemble()",
            "for w in weights if isinstance(weights, list) else [weights]:",
            "-        ckpt = torch.load(attempt_download(w), map_location=device)",
            "-        ckpt = (ckpt.get('ema') or ckpt['model']).float()  # FP32 model",
            "+        ckpt = torch.load(attempt_download(w), map_location='cpu')  # load",
            "+        ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model",
            "model.append(ckpt.fuse().eval() if fuse else ckpt.eval())  # fused or un-fused model in eval mode",
            "",
            "# Compatibility updates"
        ],
        "comments": "change param for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 694,
        "change": [
            "class Conv2dSubsampling6(torch.nn.Module):",
            "torch.nn.ReLU(),",
            ")",
            "self.out = torch.nn.Sequential(",
            "-            torch.nn.Linear(odim * (((idim - 1) // 2 - 1) // 3), odim),",
            "+            torch.nn.Linear(odim * (((idim - 1) // 2 - 2) // 3), odim),",
            "PositionalEncoding(odim, dropout_rate),",
            ")"
        ],
        "comments": "change param for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 707,
        "change": [
            "class TFLiteBackendInferenceLearner(TensorflowBaseInferenceLearner):",
            "self.interpreter.set_tensor(i, input_tensor)",
            "self.interpreter.invoke()",
            "return tuple(",
            "-            self.interpreter.get_tensor(output_detail[\"index\"])",
            "+            tf.convert_to_tensor(",
            "+                self.interpreter.get_tensor(output_detail[\"index\"])",
            "+            )",
            "for output_detail in output_details",
            ")"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 710,
        "change": [
            "class Model(ModelDesc):",
            ".Conv2D('conv3.1', filters=128, padding='VALID') \\",
            ".Conv2D('conv3.2', filters=128, padding='VALID') \\",
            ".FullyConnected('fc0', 1024 + 512, activation=tf.nn.relu) \\",
            "-                .tf.nn.dropout(keep_prob) \\",
            "+                .Dropout(rate=drop_rate) \\",
            ".FullyConnected('fc1', 512, activation=tf.nn.relu) \\",
            ".FullyConnected('linear', out_dim=self.cifar_classnum)()"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 720,
        "change": [
            "class CustomConverter(object):",
            "xs_pad = pad_list([torch.from_numpy(x).float() for x in xs], 0).to(device, dtype=self.dtype)",
            "",
            "ilens = torch.from_numpy(ilens).to(device)",
            "-        # NOTE: this is for multi-task learning (e.g., speech translation)",
            "-        ys_pad = pad_list([torch.from_numpy(np.array(y[0]) if isinstance(y, tuple) else y).long()",
            "+        # NOTE: this is for multi-output (e.g., speech translation)",
            "+        ys_pad = pad_list([torch.from_numpy(np.array(y[0][:]) if isinstance(y, tuple) else y).long()",
            "for y in ys], self.ignore_id).to(device)",
            "",
            "return xs_pad, ilens, ys_pad"
        ],
        "comments": "change param for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 725,
        "change": [
            "def run_benchmark(state):",
            "",
            "",
            "def on_state_reset():",
            "-    tf.keras.backend.set_value(model.optimizer.lr, lr * hvd.size())",
            "+    opt.lr.assign(lr * hvd.size())",
            "",
            "",
            "state = hvd.elastic.TensorFlowKerasState(model, opt, img_secs=[], iter=0, batch=0, warm=False)"
        ],
        "comments": "change API call for version fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 727,
        "change": [
            "def _interpret_blender_cameras(",
            "",
            "Rpt3, Tpt3 = mtx[:, :3].split([3, 1], dim=0)",
            "",
            "-        focal_length_pt3 = torch.FloatTensor([[-focal, focal]])",
            "-        principal_point_pt3 = torch.FloatTensor([[W / 2, H / 2]])",
            "+        focal_length_pt3 = torch.FloatTensor([[focal, focal]])",
            "+        principal_point_pt3 = torch.FloatTensor([[0.0, 0.0]])",
            "",
            "cameras = PerspectiveCameras(",
            "focal_length=focal_length_pt3,"
        ],
        "comments": "change param for math fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 728,
        "change": [
            "def vector_to_skew_symmetric_matrix(",
            "a2s = vector_expanded[..., 1:2, :]",
            "a3s = vector_expanded[..., 2:3, :]",
            "# BS x 1 x 1",
            "-    zs = torch.zeros(batch_shape + [1, 1], device=vector.device)",
            "+    zs = torch.zeros(batch_shape + [1, 1], device=vector.device, dtype=vector.dtype)",
            "# BS x 1 x 3",
            "row1 = torch.cat((zs, -a3s, a2s), -1)",
            "row2 = torch.cat((a3s, zs, -a1s), -1)"
        ],
        "comments": "add param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 730,
        "change": [
            "from pyro.ops.einsum import contract",
            "def _finfo(tensor):",
            "# This can be replaced with torch.finfo once it is available",
            "# https://github.com/pytorch/pytorch/issues/10742",
            "-    return np.finfo(torch.empty(torch.Size(), dtype=tensor.dtype).numpy().dtype)",
            "+    return np.finfo(torch.empty(torch.Size(), dtype=tensor.dtype, device=\"cpu\").numpy().dtype)",
            "",
            "",
            "def _check_batch_dims_are_sensible(output_dims, nonoutput_ordinal):"
        ],
        "comments": "add param for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 733,
        "change": [
            "try:",
            "with torch.cuda.device(x.device):",
            "return super().forward(x)",
            "",
            "+",
            "except ImportError:",
            "has_fused_layernorm = False",
            "",
            "",
            "def LayerNorm(normalized_shape, eps=1e-5, elementwise_affine=True, export=False):",
            "-    if torch.jit.is_scripting():",
            "+    if torch.jit.is_scripting() or torch.jit.is_tracing():",
            "export = True",
            "if not export and torch.cuda.is_available() and has_fused_layernorm:",
            "return FusedLayerNorm(normalized_shape, eps, elementwise_affine)"
        ],
        "comments": "add condition check for state fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 735,
        "change": [
            "class TRPOModel(PolicyGradientModel):",
            ":param batch:",
            ":return:",
            "\"\"\"",
            "+        super(TRPOModel, self).update(batch)",
            "+",
            "self.feed_dict = {state: batch['states'][name] for name, state in self.state.items()}",
            "self.feed_dict.update({action: batch['actions'][name] for name, action in self.action.items()})",
            "self.feed_dict[self.reward] = batch['rewards']"
        ],
        "comments": "add API call for state fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Null Reference Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Null Reference Error"
    },
    {
        "number": 740,
        "change": [
            "def spline_gcn(",
            "row = row.view(-1, 1).expand(row.size(0), output.size(1))",
            "output = zero.scatter_add_(0, row, output)",
            "",
            "-    # Weighten root node features by multiplying with the meaned weights at the",
            "-    # origin.",
            "-    index = torch.arange(0, kernel_size[-1]).long()",
            "+    # Weighten root node features by multiplying with the meaned weights from",
            "+    # the origin.",
            "+    index = torch.arange(0, reduce(lambda x, y: x * y, kernel_size[1:])).long()",
            "root_weight = weight[index].mean(0)",
            "output += torch.mm(features, root_weight)"
        ],
        "comments": "change param for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Algorithm Error"
    },
    {
        "number": 742,
        "change": [
            "def stats(policy, train_batch):",
            "\"cur_lr\": tf.cast(policy.cur_lr, tf.float64),",
            "\"policy_loss\": policy.loss.pi_loss,",
            "\"entropy\": policy.loss.entropy,",
            "-        \"var_gnorm\": tf.global_norm(policy.model.trainable_variables()),",
            "+        \"var_gnorm\": tf.linalg.global_norm(policy.model.trainable_variables()),",
            "\"vf_loss\": policy.loss.vf_loss,",
            "\"vf_explained_var\": explained_variance(",
            "tf.reshape(policy.loss.value_targets, [-1]),"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 743,
        "change": [
            "def test_tensorrt_torch(",
            "res_orig = tuple(model(*inputs_example))",
            "assert all(",
            "[",
            "-                    torch.allclose(res_tensor, res_orig_tensor, rtol=1e-01)",
            "+                    torch.allclose(",
            "+                        res_tensor.float(), res_orig_tensor, rtol=1e-01",
            "+                    )",
            "for (res_tensor, res_orig_tensor) in zip(res, res_orig)",
            "]",
            ")"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 744,
        "change": [
            "class Attention(nn.Module):",
            "# Apply the attention mask",
            "w = w + attention_mask",
            "",
            "-        w = nn.Softmax(dim=-1)(w)",
            "+        w = nn.functional.softmax(w, dim=-1)",
            "w = self.attn_dropout(w)",
            "",
            "# Mask heads if we want to"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Deprecation Management Error"
    },
    {
        "number": 752,
        "change": [
            "class DistributedGroupSampler(Sampler):",
            "if size > 0:",
            "indice = np.where(self.flag == i)[0]",
            "assert len(indice) == size",
            "-                indice = indice[list(torch.randperm(int(size),",
            "-                                                    generator=g))].tolist()",
            "+                # add .numpy() to avoid bug when selecting indice in parrots.",
            "+                # TODO: check whether torch.randperm() can be replaced by",
            "+                # numpy.random.permutation().",
            "+                indice = indice[list(",
            "+                    torch.randperm(int(size), generator=g).numpy())].tolist()",
            "extra = int(",
            "math.ceil(",
            "size * 1.0 / self.samples_per_gpu / self.num_replicas)"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 759,
        "change": [
            "def test_pair_norm(scale_individually):",
            "assert out1.size() == (100, 16)",
            "",
            "out2 = norm(torch.cat([x, x], dim=0), torch.cat([batch, batch + 1], dim=0))",
            "-    assert torch.allclose(out1, out2[:100])",
            "-    assert torch.allclose(out1, out2[100:])",
            "+    assert torch.allclose(out1, out2[:100], atol=1e-6)",
            "+    assert torch.allclose(out1, out2[100:], atol=1e-6)"
        ],
        "comments": "add param for math fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 764,
        "change": [
            "class BlenderbotSmallEncoderLayer(nn.Module):",
            "hidden_states = residual + hidden_states",
            "hidden_states = self.final_layer_norm(hidden_states)",
            "",
            "-        if torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any():",
            "+        if hidden_states.dtype == torch.float16 and (",
            "+            torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any()",
            "+        ):",
            "clamp_value = torch.finfo(hidden_states.dtype).max - 1000",
            "hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)"
        ],
        "comments": "add condition check for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 774,
        "change": [
            "class QuantLinear(nn.Module):",
            "x_int = x / prev_act_scaling_factor",
            "",
            "return (",
            "-            F.linear(x_int, weight=self.weight_integer, bias=self.bias_integer) * bias_scaling_factor,",
            "+            nn.functional.linear(x_int, weight=self.weight_integer, bias=self.bias_integer) * bias_scaling_factor,",
            "bias_scaling_factor,",
            ")"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 779,
        "change": [
            "class Importance(TracePosterior):",
            "\"\"\"",
            "if self.log_weights:",
            "log_w_norm = self.get_normalized_weights(log_scale=True)",
            "-            ess = torch.exp(-logsumexp(2*log_w_norm, 0))",
            "+            ess = torch.exp(-torch.logsumexp(2*log_w_norm, 0))",
            "else:",
            "warnings.warn(\"The log_weights list is empty, effective sample size is zero.\")",
            "ess = 0"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 780,
        "change": [
            "for epoch in range(opt.niter):",
            "vutils.save_image(fake.data, 'fake_samples.png')",
            "",
            "# do checkpointing",
            "-    torch.save(netG.parameter_dict(), 'netG_epoch_%d.pth' % epoch)",
            "-    torch.save(netD.parameter_dict(), 'netD_epoch_%d.pth' % epoch)",
            "+    torch.save(netG.state_dict(), 'netG_epoch_%d.pth' % epoch)",
            "+    torch.save(netD.state_dict(), 'netD_epoch_%d.pth' % epoch)"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 782,
        "change": [
            "def dnn(tensor_in, hidden_units, activation=tf.nn.relu, keep_prob=None):",
            "with tf.variable_scope('dnn'):",
            "for i, n_units in enumerate(hidden_units):",
            "with tf.variable_scope('layer%d' % i):",
            "-                tensor_in = linear.linear(tensor_in, n_units, True)",
            "+                tensor_in = linear(tensor_in, n_units, True)",
            "tensor_in = activation(tensor_in)",
            "if keep_prob:",
            "tensor_in = tf.nn.dropout(tensor_in, keep_prob)"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 783,
        "change": [
            "class DSClipEncoder(torch.nn.Module):",
            "seq_len,",
            "seq_len,",
            "dtype=dtype,",
            "-                           device=torch.cuda.current_device())",
            "+                           device=get_accelerator().current_device_name())",
            "mask.fill_(torch.tensor(torch.finfo(dtype).min))",
            "mask.triu_(1)",
            "mask = mask.unsqueeze(1)"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 785,
        "change": [
            "class CTC(torch.nn.Module):",
            "if self.ctc_type == \"warpctc\":",
            "# warpctc only supports float32",
            "ys_hat = ys_hat.to(dtype=torch.float32)",
            "+        else:",
            "+            # use GPU when using the cuDNN implementation",
            "+            ys_true = to_device(self, ys_true)",
            "self.loss = to_device(self, self.loss_fn(ys_hat, ys_true, hlens, olens)).to(dtype=dtype)",
            "if self.reduce:",
            "# NOTE: sum() is needed to keep consistency since warpctc return as tensor w/ shape (1,)"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 789,
        "change": [
            "class AttentionDecoder(DecoderBase):",
            "])",
            "else:",
            "attention_context = output.attention_context",
            "-    return tf.concat(1, [next_input, attention_context])",
            "+    return tf.concat_v2([next_input, attention_context], 1)",
            "",
            "def _pad_att_scores(self, scores):",
            "\"\"\"Pads attention scores to fixed length. This is a hack because raw_rnn"
        ],
        "comments": "change API call for version fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 792,
        "change": [
            "class GPTJAttention(nn.Module):",
            "):",
            "# compute causal mask from causal mask buffer",
            "query_length, key_length = query.size(-2), key.size(-2)",
            "-        causal_mask = self.bias[:, :, key_length - query_length : key_length, :key_length].to(torch.bool)",
            "+        causal_mask = self.bias[:, :, key_length - query_length : key_length, :key_length]",
            "",
            "# Keep the attention weights computation in fp32 to avoid overflow issues",
            "query = query.to(torch.float32)"
        ],
        "comments": "remove API call for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 800,
        "change": [
            "class GeneralizedChannelPermute(ConditionedGeneralizedChannelPermute, TransformM",
            "self.__delattr__('permutation')",
            "",
            "# Sample a random orthogonal matrix",
            "-        W, _ = torch.qr(torch.randn(channels, channels))",
            "+        W, _ = torch.linalg.qr(torch.randn(channels, channels))",
            "",
            "# Construct the partially pivoted LU-form and the pivots",
            "LU, pivots = W.lu()"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 802,
        "change": [
            "class TestConfusionMatrix:",
            "conf_mat = kornia.utils.metrics.confusion_matrix(",
            "predicted, actual, num_classes)",
            "conf_mat_real = torch.tensor(",
            "-            [[[3, 1],",
            "-              [0, 4]]], dtype=torch.float32)",
            "+            [",
            "+                [[3, 1], [0, 4]],",
            "+                [[3, 1], [0, 4]]",
            "+            ], dtype=torch.float32)",
            "assert_allclose(conf_mat, conf_mat_real)",
            "",
            "def test_three_classes(self):"
        ],
        "comments": "change param for shape fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 803,
        "change": [
            "def model(x, is_train, reuse):",
            "# nt = Conv2d(nin, 16, (3, 3), (2, 2), act=tf.nn.relu, padding='SAME', name='tc1')",
            "# nt = Conv2d(nt, 8, (3, 3), (2, 2), act=tf.nn.relu, padding='SAME', name='tc2')",
            "## 2. Spatial transformer module (sampler)",
            "-        n = tl.layers.SpatialTransformer2dAffineLayer(nin, theta_layer=nt, out_size=[40, 40], name='spatial')",
            "+        n = tl.layers.SpatialTransformer2dAffineLayer(nin, theta_layer=nt, out_size=(40, 40), name='spatial')",
            "s = n",
            "## 3. Classifier",
            "n = tl.layers.Conv2d("
        ],
        "comments": "update param for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 804,
        "change": [
            "class DeiTPreTrainedModel(PreTrainedModel):",
            "def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> None:",
            "\"\"\"Initialize the weights\"\"\"",
            "if isinstance(module, (nn.Linear, nn.Conv2d)):",
            "-            # Slightly different from the TF version which uses truncated_normal for initialization",
            "-            # cf https://github.com/pytorch/pytorch/pull/5617",
            "-            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)",
            "+            module.weight.data = nn.init.trunc_normal_(module.weight.data, mean=0.0, std=self.config.initializer_range)",
            "if module.bias is not None:",
            "module.bias.data.zero_()",
            "elif isinstance(module, nn.LayerNorm):"
        ],
        "comments": "change API call for shape fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 808,
        "change": [
            "class DisentangledSelfAttention(nn.Module):",
            "dim=-1,",
            "index=p2c_pos.squeeze(0).expand([query_layer.size(0), key_layer.size(-2), key_layer.size(-2)]),",
            ").transpose(-1, -2)",
            "-            score += p2c_att / scale",
            "+            score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)",
            "",
            "return score"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 812,
        "change": [
            "def evaluate(model, data_loader, device):",
            "image = list(img.to(device) for img in image)",
            "targets = [{k: v.to(device) for k, v in t.items()} for t in targets]",
            "",
            "-        torch.cuda.synchronize(device)",
            "+        # 当使用CPU时，跳过GPU相关指令",
            "+        if device != torch.device(\"cpu\"):",
            "+            torch.cuda.synchronize(device)",
            "+",
            "model_time = time.time()",
            "outputs = model(image)"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 813,
        "change": [
            "class Layer_Lambda_Test(CustomTestCase):",
            "self.dense1 = tl.layers.Dense(in_channels=1, n_units=5)",
            "self.dense2 = tl.layers.Dense(in_channels=1, n_units=5)",
            "self.dense3 = tl.layers.Dense(in_channels=1, n_units=5)",
            "-                self.lambdalayer = tl.layers.ElementwiseLambda(customize_func, fn_weights=[], fn_args={'foo': 1024})",
            "+                self.lambdalayer = tl.layers.ElementwiseLambda(customize_func, fn_args={'foo': 1024})",
            "",
            "def forward(self, x, bar=None):",
            "noise = self.dense1(x)"
        ],
        "comments": "remove param for argument fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 821,
        "change": [
            "def clip_grad_norm_(params, max_norm, aggregate_norm_fn=None) -> torch.Tensor:",
            "if multi_tensor_l2norm_available:",
            "total_norm = multi_tensor_total_norm(grads)",
            "else:",
            "-            warnings.warn(",
            "-                \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"",
            "-                \"you may get better performance by installing NVIDIA's apex library\"",
            "-            )",
            "+            if torch.cuda.is_available():",
            "+                warnings.warn(",
            "+                    \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"",
            "+                    \"you may get better performance by installing NVIDIA's apex library\"",
            "+                )",
            "total_norm = torch.norm(",
            "torch.stack([torch.norm(g, p=2, dtype=torch.float32) for g in grads])",
            ")"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 823,
        "change": [
            "class ModelSpeedupTensorRT(BaseModelSpeedup):",
            "Model input tensor",
            "\"\"\"",
            "# convert pytorch tensor to numpy darray",
            "+        if test_data.device != torch.device(\"cpu\"):",
            "+            test_data = test_data.to(\"cpu\")",
            "test_data = test_data.numpy()",
            "# Numpy dtype should be float32",
            "assert test_data.dtype == np.float32"
        ],
        "comments": "add condition check for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 828,
        "change": [
            "def main():",
            "if utils.is_primary(args):",
            "_logger.info('Using NVIDIA APEX AMP. Training in mixed precision.')",
            "elif use_amp == 'native':",
            "-        amp_autocast = partial(torch.autocast, device_type=device.type, dtype=amp_dtype)",
            "-        if device.type == 'cuda':",
            "+        try:",
            "+            amp_autocast = partial(torch.autocast, device_type=device.type, dtype=amp_dtype)",
            "+        except (AttributeError, TypeError):",
            "+            # fallback to CUDA only AMP for PyTorch < 1.10",
            "+            assert device.type == 'cuda'",
            "+            amp_autocast = torch.cuda.amp.autocast",
            "+        if device.type == 'cuda' and amp_dtype == torch.float16:",
            "+            # loss scaler only used for float16 (half) dtype, bfloat16 does not need it",
            "loss_scaler = NativeScaler()",
            "if utils.is_primary(args):",
            "_logger.info('Using native Torch AMP. Training in mixed precision.')"
        ],
        "comments": "add condition check for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 829,
        "change": [
            "class AutoOutsideCompilationWithKerasTest(tf.test.TestCase):",
            "",
            "",
            "if __name__ == '__main__':",
            "-  tf.compat.v1.enable_eager_execution()",
            "tf.test.main()"
        ],
        "comments": "remove API call for version fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 837,
        "change": [
            "class Encoder(torch.nn.Module):",
            "pos_enc_class(attention_dim, positional_dropout_rate),",
            ")",
            "elif input_layer is None:",
            "-            self.embed = pos_enc_class(attention_dim, positional_dropout_rate)",
            "+            self.embed = torch.nn.Sequential(",
            "+                pos_enc_class(attention_dim, positional_dropout_rate)",
            "+            )",
            "else:",
            "raise ValueError(\"unknown input_layer: \" + input_layer)",
            "self.normalize_before = normalize_before"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 838,
        "change": [
            "class ChineseCLIPVisionTransformer(nn.Module):",
            "embed_dim = config.hidden_size",
            "",
            "self.embeddings = ChineseCLIPVisionEmbeddings(config)",
            "-        self.pre_layrnorm = nn.LayerNorm(embed_dim)",
            "+        self.pre_layrnorm = nn.LayerNorm(embed_dim, eps=config.layer_norm_eps)",
            "self.encoder = ChineseCLIPVisionEncoder(config)",
            "-        self.post_layernorm = nn.LayerNorm(embed_dim)",
            "+        self.post_layernorm = nn.LayerNorm(embed_dim, eps=config.layer_norm_eps)",
            "",
            "@add_start_docstrings_to_model_forward(CHINESE_CLIP_VISION_INPUTS_DOCSTRING)",
            "@replace_return_docstrings(output_type=BaseModelOutputWithPooling, config_class=ChineseCLIPVisionConfig)"
        ],
        "comments": "add param for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Algorithm Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Algorithm Error"
    },
    {
        "number": 840,
        "change": [
            "class TestSolveCast:",
            "",
            "class TestSolveWithMask:",
            "def test_smoke(self, device, dtype):",
            "+        torch.manual_seed(0)  # issue kornia#2027",
            "A = torch.randn(2, 3, 1, 4, 4, device=device, dtype=dtype)",
            "B = torch.randn(2, 3, 1, 4, 6, device=device, dtype=dtype)"
        ],
        "comments": "add API call for math fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 842,
        "change": [
            "class TFHubertPreTrainedModel(TFPreTrainedModel):",
            "input_signature=[",
            "{",
            "\"input_values\": tf.TensorSpec((None, None), tf.float32, name=\"input_values\"),",
            "-                \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),",
            "-                \"token_type_ids\": tf.TensorSpec((None, None), tf.int32, name=\"token_type_ids\"),",
            "+                \"attention_mask\": tf.TensorSpec((None, None), tf.int64, name=\"attention_mask\"),",
            "+                \"token_type_ids\": tf.TensorSpec((None, None), tf.int64, name=\"token_type_ids\"),",
            "}",
            "]",
            ")"
        ],
        "comments": "change param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 845,
        "change": [
            "def test_maskctc(encoder_arch, interctc_layer_idx, interctc_use_conditioning):",
            "inputs = dict(",
            "speech=torch.randn(2, 10, 20, requires_grad=True),",
            "speech_lengths=torch.tensor([10, 8], dtype=torch.long),",
            "-        text=torch.randint(0, vocab_size + 1, [2, 4], dtype=torch.long),",
            "+        text=torch.randint(2, 4, [2, 4], dtype=torch.long),",
            "text_lengths=torch.tensor([4, 3], dtype=torch.long),",
            ")",
            "loss, *_ = model(**inputs)"
        ],
        "comments": "change param for math fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 847,
        "change": [
            "def _add_gradients_summaries(grads_and_vars):",
            "grad_values = grad.values",
            "else:",
            "grad_values = grad",
            "-      summaries.append(tf.histogram_summary(var.op.name + ':gradient',",
            "+      summaries.append(tf.summary.histogram(var.op.name + ':gradient',",
            "grad_values))",
            "-      summaries.append(tf.histogram_summary(var.op.name + ':gradient_norm',",
            "+      summaries.append(tf.summary.histogram(var.op.name + ':gradient_norm',",
            "tf.global_norm([grad_values])))",
            "else:",
            "tf.logging.info('Var %s has no gradient', var.op.name)"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 849,
        "change": [
            "class QM9(InMemoryDataset):",
            "edge_type += 2 * [self.bonds[bond.GetBondType()]]",
            "",
            "edge_index = torch.tensor([row, col], dtype=torch.long)",
            "-            edge_type = torch.tensor(edge_type)",
            "-            edge_attr = F.one_hot(torch.tensor(edge_type),",
            "+            edge_type = torch.tensor(edge_type, dtype=torch.long)",
            "+            edge_attr = F.one_hot(edge_type,",
            "num_classes=len(self.bonds)).to(torch.float)",
            "",
            "perm = (edge_index[0] * N + edge_index[1]).argsort()"
        ],
        "comments": "add param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 854,
        "change": [
            "class MinSaver(Callback):",
            "newname = os.path.join(logger.LOG_DIR,",
            "self.filename or",
            "('max-' + self.monitor_stat if self.reverse else 'min-' + self.monitor_stat))",
            "-        files_to_copy = glob.glob(path + '*')",
            "+        files_to_copy = tf.gfile.Glob(path + '*')",
            "for file_to_copy in files_to_copy:",
            "-            shutil.copy(file_to_copy, file_to_copy.replace(path, newname))",
            "+            tf.gfile.Copy(file_to_copy, file_to_copy.replace(path, newname), overwrite=True)",
            "logger.info(\"Model with {} '{}' saved.\".format(",
            "'maximum' if self.reverse else 'minimum', self.monitor_stat))"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 855,
        "change": [
            "class Evaluator(object):",
            "The mean average result per tensor over the entire dataset.",
            "",
            "\"\"\"",
            "+        tflearn.is_training(False, self.session)",
            "coord = tf.train.Coordinator()",
            "inputs = tf.get_collection(tf.GraphKeys.INPUTS)",
            "# Data Preprocessing"
        ],
        "comments": "add API call for state fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 857,
        "change": [
            "class Lamb(Optimizer):",
            "global_grad_norm.add_(grad.pow(2).sum())",
            "",
            "global_grad_norm = torch.sqrt(global_grad_norm)",
            "-        max_grad_norm = self.defaults['max_grad_norm']",
            "+        # FIXME it'd be nice to remove explicit tensor conversion of scalars when torch.where promotes",
            "+        # scalar types properly https://github.com/pytorch/pytorch/issues/9190",
            "+        max_grad_norm = torch.tensor(self.defaults['max_grad_norm'], device=device)",
            "clip_global_grad_norm = torch.where(",
            "global_grad_norm > max_grad_norm,",
            "global_grad_norm / max_grad_norm,"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 860,
        "change": [
            "class ModelCatalogTest(unittest.TestCase):",
            "def testCustomModel(self):",
            "ray.init()",
            "ModelCatalog.register_custom_model(\"foo\", CustomModel)",
            "-        p1 = ModelCatalog.get_model(1, 5, {\"custom_model\": \"foo\"})",
            "+        p1 = ModelCatalog.get_model(",
            "+            tf.constant([1, 2, 3]), 5, {\"custom_model\": \"foo\"})",
            "self.assertEqual(str(type(p1)), str(CustomModel))"
        ],
        "comments": "add API call for math fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 862,
        "change": [
            "class _netD(nn.Module):",
            "",
            "def forward(self, input):",
            "gpu_ids = None",
            "-        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:",
            "+        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > =1:",
            "gpu_ids = range(self.ngpu)",
            "output = nn.parallel.data_parallel(self.main, input, gpu_ids)",
            "return output.view(-1, 1)"
        ],
        "comments": "change condition check for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Condition",
        "Action_Element": "Replace API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 864,
        "change": [
            "from nebullvm.transformations.base import BaseTransformation",
            "",
            "",
            "class VerifyContiguity(BaseTransformation):",
            "-    def _transform(self, _input: torch.Tensor, **kwargs) -> Any:",
            "+    def _transform(self, _input: Any, **kwargs) -> Any:",
            "+        if not isinstance(_input, torch.Tensor):",
            "+            return _input",
            "if not _input.is_contiguous():",
            "_input = _input.contiguous()",
            "return _input"
        ],
        "comments": "add condition check for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 865,
        "change": [
            "from tests import utils",
            "def test_image_classifier(tmp_path):",
            "train_x = utils.generate_data(num_instances=320, shape=(32, 32, 3))",
            "train_y = utils.generate_one_hot_labels(num_instances=320, num_classes=10)",
            "-    clf = ak.ImageClassifier(directory=tmp_path, max_trials=2, seed=utils.SEED)",
            "+    clf = ak.ImageClassifier(",
            "+        directory=tmp_path,",
            "+        max_trials=2,",
            "+        seed=utils.SEED,",
            "+        distribution_strategy=tf.distribute.MirroredStrategy(),",
            "+    )",
            "clf.fit(train_x, train_y, epochs=1, validation_split=0.2)",
            "keras_model = clf.export_model()",
            "clf.evaluate(train_x, train_y)"
        ],
        "comments": "add param for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 867,
        "change": [
            "def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),",
            "output_shape[3],",
            "output_shape[1])",
            "if output_shape[0] is None:",
            "-        output_shape = (tf.shape(x)[0],) + tuple(output_shape[1:])",
            "-        output_shape = tf.stack(list(output_shape))",
            "+        output_shape = (shape(x)[0],) + tuple(output_shape[1:])",
            "+",
            "+    output_shape = tf.stack(list(output_shape))",
            "",
            "padding = _preprocess_padding(padding)",
            "if tf_data_format == 'NHWC':"
        ],
        "comments": "remove API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 868,
        "change": [
            "class TestRasterizeMeshes(TestCaseMixin, unittest.TestCase):",
            "], dtype=torch.int64, device=device)",
            "# fmt: on",
            "",
            "-        pix_to_face_padded = -torch.ones_like(pix_to_face_frontface)",
            "+        pix_to_face_padded = -(torch.ones_like(pix_to_face_frontface))",
            "# Run with and without culling",
            "# Without culling, for k=0, the front face (i.e. face 2) is",
            "# rasterized and for k=1, the back face (i.e. face 3) is"
        ],
        "comments": "add API call for math fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 871,
        "change": [
            "class PipelineTest(test.SparkTest):",
            "import tensorflow as tf",
            "from tensorflowonspark import TFNode",
            "",
            "+      tf.compat.v1.disable_eager_execution()",
            "tf.compat.v1.reset_default_graph()",
            "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()"
        ],
        "comments": "add API call for state fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 875,
        "change": [
            "class SparkKerasTests(tf.test.TestCase):",
            "",
            "def test_fit_model_multiclass(self):",
            "model = create_mnist_model()",
            "-        if version.parse(tf.keras.__version__) < version.parse(\"2.11\"):",
            "+        if version.parse(tf.keras.__version__.replace(\"-tf\", \"+tf\")) < version.parse(\"2.11\"):",
            "optimizer = tf.keras.optimizers.Adadelta(1.0)",
            "else:",
            "optimizer = tf.keras.optimizers.legacy.Adadelta(1.0)"
        ],
        "comments": "change condition check for version fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 880,
        "change": [
            "def create_meshgrid(height, width, normalized_coordinates=True):",
            "else:",
            "xs = torch.linspace(0, width - 1, width)",
            "ys = torch.linspace(0, height - 1, height)",
            "-    return torch.stack(torch.meshgrid([ys, xs])).view(1, 2, -1)",
            "+    return torch.stack(torch.meshgrid([ys, xs])).view(1, 2, -1)[:, (1, 0), :]",
            "",
            "",
            "class HomographyWarper(nn.Module):"
        ],
        "comments": "change param for shape fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 882,
        "change": [
            "def main():",
            "# download url: https://download.pytorch.org/models/resnet34-333f7ec4.pth",
            "model_weight_path = \"./resnet34-pre.pth\"",
            "assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)",
            "-    net.load_state_dict(torch.load(model_weight_path, map_location=device))",
            "+    net.load_state_dict(torch.load(model_weight_path, map_location='cpu'))",
            "# for param in net.parameters():",
            "#     param.requires_grad = False"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 883,
        "change": [
            "def triangular_solve(x, y, upper=False, transpose=False):",
            "",
            "",
            "def precision_to_scale_tril(P):",
            "-    Lf = torch.cholesky(torch.flip(P, (-2, -1)))",
            "+    Lf = torch.linalg.cholesky(torch.flip(P, (-2, -1)))",
            "L_inv = torch.transpose(torch.flip(Lf, (-2, -1)), -2, -1)",
            "L = torch.triangular_solve(torch.eye(P.shape[-1], dtype=P.dtype, device=P.device),",
            "L_inv, upper=False)[0]"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 887,
        "change": [
            "def _to_ivy(x: Any) -> Any:",
            "",
            "",
            "def _to_ivy_array(x: Any) -> ivy.Array:",
            "-    if isinstance(x, (torch.Tensor, tf.Tensor, jnp.numpy.DeviceArray, numpy.ndarray)):",
            "+    if isinstance(x, (torch.Tensor, tf.Tensor, jnp.DeviceArray, numpy.ndarray)):",
            "return ivy.array(numpy.array(x))",
            "return x"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 888,
        "change": [
            "def vecdot(",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "dtype = ivy.as_native_dtype(ivy.promote_types(x1.dtype, x2.dtype))",
            "-    x1, x2 = tf.cast(x1, tf.float32), tf.cast(x2, tf.float32)",
            "+    if dtype != \"float64\":",
            "+        x1, x2 = tf.cast(x1, tf.float32), tf.cast(x2, tf.float32)",
            "ret = tf.cast(tf.tensordot(x1, x2, axes=(axis, axis)), dtype)",
            "return ret"
        ],
        "comments": "add condition check for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 895,
        "change": [
            "class SinusoidalPositionalEmbedding(nn.Module):",
            "self.embedding_dim,",
            "self.padding_idx,",
            ").type_as(self.weights)",
            "+        self.weights = self.weights.type_as(self._float_tensor)",
            "weights = Variable(self.weights)",
            "",
            "if incremental_state is not None:"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 901,
        "change": [
            "class AdditiveSharingTensor(AbstractTensor):",
            "random_shares = [random_type(secret.shape) for _ in range(n_workers - 1)]",
            "",
            "for share in random_shares:",
            "-            share.random_(-field, field)",
            "+            share.random_(int(-field/2), int(field/2)-1)",
            "",
            "shares = []",
            "for i in range(n_workers):"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 902,
        "change": [
            "class PipelineEngine(DeepSpeedEngine):",
            "mem_cached = new_cached",
            "mem_alloced = new_alloced",
            "",
            "-        max_alloced = torch.cuda.max_memory_allocated()",
            "-        max_cached = torch.cuda.max_memory_cached()",
            "+        max_alloced = get_accelerator().max_memory_allocated()",
            "+        max_cached = get_accelerator().max_memory_cached()",
            "",
            "# convert to GB for printing",
            "new_alloced /= 1024**3"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Deprecation Management Error"
    },
    {
        "number": 903,
        "change": [
            "def torch_multinomial(input, num_samples, replacement=False):",
            "Does not support keyword argument `out`.",
            "\"\"\"",
            "if input.is_cuda:",
            "-        return torch_multinomial(input.cpu(), num_samples, replacement).cuda()",
            "+        return torch.multinomial(input.cpu(), num_samples, replacement).cuda(input.get_device())",
            "else:",
            "return torch.multinomial(input, num_samples, replacement)"
        ],
        "comments": "add param for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 904,
        "change": [
            "def test_delete_entire_dataset(domain_owner, cleanup_storage):",
            "assert domain_owner.datasets[0].name == \"Dataset_1\"",
            "assert domain_owner.datasets[1].name == \"Dataset_2\"",
            "",
            "-    domain_owner.datasets.delete(dataset_id=domain_owner.datasets[0].id)",
            "+    domain_owner.datasets.delete(",
            "+        dataset_id=domain_owner.datasets[0].id, skip_checks=True",
            "+    )",
            "",
            "# Check if the number of available datasets has been decreased",
            "assert len(domain_owner.datasets) == 1"
        ],
        "comments": "add param for argument fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 905,
        "change": [
            "def logspace(",
            "base=10.0,",
            "axis=None,",
            "*,",
            "+    dtype: torch.dtype,",
            "device: torch.device,",
            "out: Optional[torch.Tensor] = None,",
            "):",
            "-    power_seq = linspace(",
            "-        start, stop, num, axis, dtype=None, device=default_device(device)",
            "+    power_seq = ivy.linspace(",
            "+        start, stop, num, axis, dtype=dtype, device=ivy.default_device(device)",
            ")",
            "return base**power_seq"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 908,
        "change": [
            "def pack(",
            "try:",
            "import torch",
            "",
            "-        meta_objs.update(torch=torch.__version__)",
            "+        meta_objs.update(torch=str(torch.__version__))",
            "except ImportError:",
            "pass",
            "try:"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 909,
        "change": [
            "def main():",
            "# recog",
            "logging.info('backend = ' + args.backend)",
            "if args.backend == \"chainer\":",
            "-        from espnet.lmchainer.asr_chainer import recog",
            "+        from espnet.asr.chainer.asr_chainer import recog",
            "recog(args)",
            "elif args.backend == \"pytorch\":",
            "-        from espnet.lmpytorch.asr_pytorch import recog",
            "+        from espnet.asr.pytorch.asr_pytorch import recog",
            "recog(args)",
            "else:",
            "raise ValueError(\"Only chainer and pytorch are supported.\")"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 910,
        "change": [
            "class Schedule(metaclass=ABCMeta):",
            "raise NotImplementedError",
            "",
            "def value(self, t):",
            "-        if self.framework == \"tf\" and tf.executing_eagerly() is False:",
            "+        if self.framework == \"tf\":",
            "return tf.cast(",
            "-                tf.py_func(self._value, [t], tf.float64),",
            "+                tf.py_function(self._value, [t], tf.float64),",
            "tf.float32,",
            "-                name=\"schedule-value\")",
            "+                name=\"schedule_value\")",
            "return self._value(t)",
            "",
            "def __call__(self, t):"
        ],
        "comments": "change API call for version fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 912,
        "change": [
            "class FeedForwardTransformer(TTSInterface, torch.nn.Module):",
            "",
            "# concat speaker embedding",
            "if self.spk_embed_dim is not None:",
            "-            spembs = torch.nn.functional.normalize(spembs).unsqueeze(1).expand(-1, hs.size(1), -1)",
            "-            hs = self.projection(torch.cat([hs, spembs], dim=-1))",
            "+            spembs_ = F.normalize(spembs).unsqueeze(1).expand(-1, hs.size(1), -1)",
            "+            hs = self.projection(torch.cat([hs, spembs_], dim=-1))",
            "",
            "# forward duration predictor and length regulator",
            "d_masks = make_pad_mask(ilens).to(xs.device)"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 919,
        "change": [
            "def image_histogram2d(",
            "hist = hist.squeeze()",
            "elif image.dim() == 3:",
            "hist = hist.squeeze(0)",
            "-    return hist, torch.zeros_like(hist, dtype=hist.dtype, device=device)",
            "+    return hist, torch.zeros_like(hist, dtype=hist.dtype, device=hist.device)"
        ],
        "comments": "update param for version fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 920,
        "change": [
            "class FeedForwardEncoder(Seq2SeqEncoder):",
            "return self._feedforward(inputs)",
            "else:",
            "outputs = self._feedforward(inputs)",
            "-            return outputs * mask.unsqueeze(dim=-1).float()",
            "+            return outputs * mask.unsqueeze(dim=-1)"
        ],
        "comments": "remove API call for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 921,
        "change": [
            "def elastic_transform2d(",
            "sigma_t = sigma.to(device=device, dtype=dtype)",
            "",
            "# Get Gaussian kernel for 'y' and 'x' displacement",
            "-    kernel_x: torch.Tensor = get_gaussian_kernel2d_t(kernel_size, sigma_t[0].expand(2).unsqueeze(0))",
            "-    kernel_y: torch.Tensor = get_gaussian_kernel2d_t(kernel_size, sigma_t[1].expand(2).unsqueeze(0))",
            "+    kernel_x: torch.Tensor = get_gaussian_kernel2d(kernel_size, sigma_t[0].expand(2).unsqueeze(0))",
            "+    kernel_y: torch.Tensor = get_gaussian_kernel2d(kernel_size, sigma_t[1].expand(2).unsqueeze(0))",
            "",
            "# Convolve over a random displacement matrix and scale them with 'alpha'",
            "disp_x: torch.Tensor = noise[:, :1]"
        ],
        "comments": "change API call for type fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 929,
        "change": [
            "def rand_like_with_shape(shape, ori_t):",
            "higher_bound = torch.max(ori_t)",
            "",
            "if dtype in [torch.uint8, torch.int16, torch.short, torch.int16, torch.long, torch.bool]:",
            "-        return torch.randint(lower_bound, higher_bound+1, shape, dtype=dtype, device=device)",
            "+        return torch.randint(lower_bound.long(), higher_bound.long() + 1, shape, dtype=dtype, device=device)",
            "else:",
            "return torch.rand(shape, dtype=dtype, device=device, requires_grad=require_grad)"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 933,
        "change": [
            "class SelfAttnFunc(torch.autograd.Function):",
            "values_grads   = torch.bmm(dropout_results.transpose(1,2), output_lin_grads, out=values_grads.transpose(0,1))",
            "",
            "# Mask and Scaling for Dropout (not a publically documented op)",
            "-        dropout_grads = torch._masked_scale(matmul2_dgrad1, dropout_mask, dropout_prob_t[0])",
            "+        dropout_grads = torch._masked_scale(matmul2_dgrad1, dropout_mask, 1.0/(1.0-dropout_prob_t[0]))",
            "",
            "# Softmax Grad (not a publically documented op)",
            "softmax_grads = torch._softmax_backward_data(dropout_grads, softmax_results, -1, softmax_results)"
        ],
        "comments": "change param for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Algorithm Error"
    },
    {
        "number": 934,
        "change": [
            "class ValidationEpochEndVariations(ABC):",
            "",
            "val_acc_mean += val_acc",
            "",
            "-        val_loss_mean /= len(outputs)",
            "-        val_acc_mean /= len(outputs)",
            "+        if outputs:  # skip zero divisions",
            "+            val_loss_mean /= len(outputs)",
            "+            val_acc_mean /= len(outputs)",
            "",
            "metrics_dict = {'val_loss': val_loss_mean.item(), 'val_acc': val_acc_mean.item()}",
            "results = {'progress_bar': metrics_dict, 'log': metrics_dict}"
        ],
        "comments": "add condition check for null fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Null Reference Error",
        "Action": "Replace",
        "Element": "API Condition",
        "Action_Element": "Replace API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Null Reference Error"
    },
    {
        "number": 935,
        "change": [
            "class AutoShape(nn.Module):",
            "#   multiple:        = [Image.open('image1.jpg'), Image.open('image2.jpg'), ...]  # list of images",
            "",
            "t = [time_sync()]",
            "-        p = next(self.model.parameters()) if self.pt else torch.zeros(1)  # for device and type",
            "+        p = next(self.model.parameters()) if self.pt else torch.zeros(1, device=self.model.device)  # for device, type",
            "autocast = self.amp and (p.device.type != 'cpu')  # Automatic Mixed Precision (AMP) inference",
            "if isinstance(imgs, torch.Tensor):  # torch",
            "with amp.autocast(autocast):"
        ],
        "comments": "add param for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 936,
        "change": [
            "class CycleDiffusionPipeline(DiffusionPipeline):",
            "",
            "device = torch.device(f\"cuda:{gpu_id}\")",
            "",
            "-        for cpu_offloaded_model in [self.unet, self.text_encoder, self.vae, self.safety_checker]:",
            "+        for cpu_offloaded_model in [self.unet, self.text_encoder, self.vae]:",
            "if cpu_offloaded_model is not None:",
            "cpu_offload(cpu_offloaded_model, device)",
            "",
            "+        if self.safety_checker is not None:",
            "+            # TODO(Patrick) - there is currently a bug with cpu offload of nn.Parameter in accelerate",
            "+            # fix by only offloading self.safety_checker for now",
            "+            cpu_offload(self.safety_checker.vision_model)",
            "+",
            "@property",
            "# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline._execution_device",
            "def _execution_device(self):"
        ],
        "comments": "add condition check for null fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 937,
        "change": [
            "def shift_tokens_right(input_ids: tf.Tensor, pad_token_id: int, decoder_start_to",
            "",
            "if tf.executing_eagerly():",
            "# \"Verify that `labels` has only positive values and -100\"",
            "-        assert_gte0 = tf.debugging.assert_greater_equal(shifted_input_ids, tf.constant(0))",
            "+        assert_gte0 = tf.debugging.assert_greater_equal(shifted_input_ids, tf.constant(0, dtype=input_ids.dtype))",
            "",
            "# Make sure the assertion op is called by wrapping the result in an identity no-op",
            "with tf.control_dependencies([assert_gte0]):"
        ],
        "comments": "add param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 940,
        "change": [
            "def arange(start, stop=None, step=1, dtype=None, dev=None):",
            "if dtype in [torch.int8, torch.uint8, torch.int16]:",
            "return torch.arange(start, stop, step=step, dtype=torch.int64, device=dev).to(dtype)",
            "else:",
            "-            return torch.range(start, stop, step=step, dtype=dtype, device=dev)",
            "+            return torch.arange(start, stop, step=step, dtype=dtype, device=dev)"
        ],
        "comments": "change API call for math fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 944,
        "change": [
            "def _apply_affine(input: torch.Tensor,",
            "",
            "height, width = x_data.shape[-2:]",
            "transform: torch.Tensor = params['transform'].to(device, dtype)",
            "-",
            "-    out_data: torch.Tensor = warp_perspective(x_data, transform, (height, width))",
            "+    out_data: torch.Tensor = warp_affine(x_data, transform[:, :2, :], (height, width))",
            "",
            "if return_transform:",
            "return out_data.view_as(input), transform"
        ],
        "comments": "change API call for shape fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 946,
        "change": [
            "class GPTNeoAttentionMixin:",
            "else:",
            "raise ValueError(f\"Input tensor rank should be one of [2, 3], but is: {len(tensor.shape)}\")",
            "",
            "-        padded_tensor = F.pad(tensor, padding_side, value=pad_value)",
            "+        padded_tensor = nn.functional.pad(tensor, padding_side, value=pad_value)",
            "padded_tensor = padded_tensor.unfold(dimension=1, size=window_size + block_length, step=block_length)",
            "",
            "if is_key_value:"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 949,
        "change": [
            "class TFTransfoXLPreTrainedModel(TFPreTrainedModel):",
            "@tf.function(",
            "input_signature=[",
            "{",
            "-                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),",
            "+                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),",
            "}",
            "]",
            ")"
        ],
        "comments": "change param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 951,
        "change": [
            "class BiattentiveClassificationNetwork(Model):",
            "# Create ELMo embeddings if applicable",
            "if self._elmo:",
            "if elmo_tokens is not None:",
            "-                elmo_representations = self._elmo(elmo_tokens)[\"elmo_representations\"]",
            "+                elmo_representations = self._elmo(elmo_tokens[\"tokens\"])[\"elmo_representations\"]",
            "# Pop from the end is more performant with list",
            "if self._use_integrator_output_elmo:",
            "integrator_output_elmo = elmo_representations.pop()"
        ],
        "comments": "change param for argument fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 957,
        "change": [
            "class Function(object):",
            "if is_sparse(tensor):",
            "sparse_coo = value.tocoo()",
            "indices = np.concatenate((np.expand_dims(sparse_coo.row, 1), np.expand_dims(sparse_coo.col, 1)), 1)",
            "-                value = (indices, value.data, value.shape)",
            "+                value = (indices, sparse_coo.data, sparse_coo.shape)",
            "feed_dict[tensor] = value",
            "session = get_session()",
            "updated = session.run(self.outputs + [self.updates_op], feed_dict=feed_dict)"
        ],
        "comments": "change param for refactor fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 960,
        "change": [
            "def test_transformer_trainable_and_decodable(model_dict):",
            "attn_dict = model.calculate_all_attentions(",
            "x[0:1], ilens[0:1], y_tgt[0:1], y_src[0:1]",
            ")",
            "-    plot.plot_multi_head_attention(data, attn_dict, \"\", savefn=_savefn)",
            "+    plot.plot_multi_head_attention(data, uttid_list, attn_dict, \"\", savefn=_savefn)",
            "",
            "# test CTC plot",
            "ctc_probs = model.calculate_all_ctc_probs("
        ],
        "comments": "add param for argument fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Null Reference Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Null Reference Error"
    },
    {
        "number": 961,
        "change": [
            "class TFLayoutLMv3PreTrainedModel(TFPreTrainedModel):",
            "@tf.function(",
            "input_signature=[",
            "{",
            "-                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),",
            "-                \"bbox\": tf.TensorSpec((None, None, 4), tf.int32, name=\"bbox\"),",
            "+                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),",
            "+                \"bbox\": tf.TensorSpec((None, None, 4), tf.int64, name=\"bbox\"),",
            "\"pixel_values\": tf.TensorSpec((None, None, None, None), tf.float32, name=\"pixel_values\"),",
            "-                \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),",
            "+                \"attention_mask\": tf.TensorSpec((None, None), tf.int64, name=\"attention_mask\"),",
            "}",
            "]",
            ")"
        ],
        "comments": "change param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 962,
        "change": [
            "class DecisionTransformerGPT2Attention(nn.Module):",
            "# Need to be a tensor, otherwise we get error: `RuntimeError: expected scalar type float but found double`.",
            "# Need to be on the same device, otherwise `RuntimeError: ..., x and y to be on the same device`",
            "mask_value = torch.full([], mask_value, dtype=attn_weights.dtype).to(attn_weights.device)",
            "-            attn_weights = torch.where(causal_mask, attn_weights, mask_value)",
            "+            attn_weights = torch.where(causal_mask, attn_weights.to(attn_weights.dtype), mask_value)",
            "",
            "if attention_mask is not None:",
            "# Apply the attention mask"
        ],
        "comments": "add API call for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 963,
        "change": [
            "def load_tf_graph(graph_file):",
            "\"\"\"",
            "# We load the protobuf file from the disk and parse it to retrieve the",
            "# unserialized graph_def",
            "-    with tf.gfile.GFile(graph_file, \"rb\") as f:",
            "-        graph_def = tf.GraphDef()",
            "+    with tf.io.gfile.GFile(graph_file, \"rb\") as f:",
            "+        graph_def = tf.compat.v1.GraphDef()",
            "graph_def.ParseFromString(f.read())",
            "",
            "# Then, we import the graph_def into a new Graph and returns it"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 967,
        "change": [
            "class TestScalarMix(AllenNlpTestCase):",
            "tensors = [torch.randn([3, 4, 5]) for _ in range(3)]",
            "numpy_mask = numpy.ones((3, 4), dtype=\"int32\")",
            "numpy_mask[1, 2:] = 0",
            "-        mask = torch.from_numpy(numpy_mask)",
            "+        mask = torch.from_numpy(numpy_mask).bool()",
            "",
            "weights = [0.1, 0.2, 0.3]",
            "for k in range(3):"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 968,
        "change": [
            "def get_global_step_var():",
            "with tf.variable_scope(scope, reuse=False), \\",
            "tf.name_scope(None):",
            "var = tf.get_variable(GLOBAL_STEP_OP_NAME,",
            "-                                  initializer=0,",
            "-                                  trainable=False, dtype=tf.int32)",
            "+                                  initializer=tf.constant(0, dtype=tf.int64),",
            "+                                  trainable=False, dtype=tf.int64)",
            "return var"
        ],
        "comments": "change param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 969,
        "change": [
            "class SequenceFeatureExtractionTestMixin(FeatureExtractionSavingTestMixin):",
            "input_np = feat_extract.pad(processed_features, padding=\"longest\", return_tensors=\"np\")[input_name]",
            "input_tf = feat_extract.pad(processed_features, padding=\"longest\", return_tensors=\"tf\")[input_name]",
            "",
            "-        self.assertTrue(abs(input_np.sum() - input_tf.numpy().sum()) < 1e-2)",
            "+        self.assertTrue(abs(input_np.astype(np.float32).sum() - input_tf.numpy().sum()) < 1e-2)",
            "",
            "def test_attention_mask(self):",
            "feat_dict = self.feat_extract_dict"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 972,
        "change": [
            "class SSIM(nn.Module):",
            "ssim_map = ((2 * mu1_mu2 + self.C1) * (2 * sigma12 + self.C2)) / \\",
            "((mu1_sq + mu2_sq + self.C1) * (sigma1_sq + sigma2_sq + self.C2))",
            "",
            "-        loss = torch.clamp(1. - ssim_map, min=0, max=1) / 2.",
            "+        loss = torch.clamp(torch.tensor(1.) - ssim_map, min=0, max=1) / 2.",
            "",
            "if self.reduction == 'mean':",
            "loss = torch.mean(loss)"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 974,
        "change": [
            "def rpn_losses(anchor_labels, anchor_boxes, label_logits, box_logits):",
            "placeholder = 1.",
            "label_loss = tf.nn.sigmoid_cross_entropy_with_logits(",
            "labels=tf.to_float(valid_anchor_labels), logits=valid_label_logits)",
            "-    label_loss = label_loss * (1. / config.RPN_BATCH_PER_IM)",
            "+    label_loss = tf.reduce_sum(label_loss) * (1. / config.RPN_BATCH_PER_IM)",
            "label_loss = tf.where(tf.equal(nr_valid, 0), placeholder, label_loss, name='label_loss')",
            "",
            "pos_anchor_boxes = tf.boolean_mask(anchor_boxes, pos_mask)"
        ],
        "comments": "add API call for math fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 975,
        "change": [
            "def test_beamformer_net_wpe_output(ch, num_spk, use_dnn_mask_for_wpe):",
            "def test_beamformer_net_bf_output(num_spk):",
            "ch = 3",
            "inputs = torch.randn(2, 16, ch)",
            "+    inputs = inputs.float()",
            "ilens = torch.LongTensor([16, 12])",
            "model = BeamformerNet(",
            "n_fft=8,"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 976,
        "change": [
            "from allennlp.common.testing import AllenNlpTestCase",
            "",
            "class TestElmoLstmCell(AllenNlpTestCase):",
            "def test_elmo_lstm(self):",
            "-        input_tensor = Variable(torch.rand(4, 5, 3))",
            "+        input_tensor = torch.rand(4, 5, 3)",
            "input_tensor[1, 4:, :] = 0.",
            "input_tensor[2, 2:, :] = 0.",
            "input_tensor[3, 1:, :] = 0.",
            "-        mask = Variable(torch.ones([4, 5]))",
            "+        mask = torch.ones([4, 5])",
            "mask[1, 4:] = 0.",
            "mask[2, 2:] = 0.",
            "mask[3, 1:] = 0."
        ],
        "comments": "remove API call for version fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 977,
        "change": [
            "class TpuStrategyTest(tf.test.TestCase):",
            "serving_fn = create_serving_signature(model)",
            "",
            "saved_model_dir = tempfile.mkdtemp(dir=self.get_temp_dir())",
            "-      tf.saved_model.save(",
            "-          model, saved_model_dir, signatures={\"serving_default\": serving_fn})",
            "+      model.save(saved_model_dir, save_format=\"tf\",",
            "+                 signatures={\"serving_default\": serving_fn})",
            "",
            "# Test the saved_model.",
            "loaded_serving_fn = tf.keras.models.load_model("
        ],
        "comments": "update API call for version fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 984,
        "change": [
            "def _preprocess_conv3d_input(x, data_format):",
            "# Returns",
            "A tensor.",
            "\"\"\"",
            "-    if dtype(x) == 'float64':",
            "+    # tensorflow doesn't support float64 for conv layer before 1.8.0",
            "+    if (dtype(x) == 'float64'",
            "+            and StrictVersion(tf.__version__) < StrictVersion('1.8.0')):",
            "x = tf.cast(x, 'float32')",
            "tf_data_format = 'NDHWC'",
            "if data_format == 'channels_first':"
        ],
        "comments": "add condition check for version fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 987,
        "change": [
            "class SingleRoIExtractor(BaseRoIExtractor):",
            "num_levels = len(feats)",
            "roi_feats = feats[0].new_zeros(",
            "rois.size(0), self.out_channels, *out_size)",
            "+        # TODO: remove this when parrots supports",
            "+        if torch.__version__ == 'parrots':",
            "+            roi_feats.requires_grad = True",
            "",
            "if num_levels == 1:",
            "if len(rois) == 0:"
        ],
        "comments": "add condition check for version fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 988,
        "change": [
            "def main(args):",
            "accelerator.clip_grad_norm_(params_to_clip, args.max_grad_norm)",
            "optimizer.step()",
            "lr_scheduler.step()",
            "-                optimizer.zero_grad()",
            "+                optimizer.zero_grad(set_to_none=args.set_grads_to_none)",
            "",
            "# Checks if the accelerator has performed an optimization step behind the scenes",
            "if accelerator.sync_gradients:"
        ],
        "comments": "add param for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 989,
        "change": [
            "class Tagger(nn.Module):",
            "# criterion",
            "self.crit = nn.CrossEntropyLoss(ignore_index=0) # ignore padding",
            "",
            "-        self.drop = Dropout(args['dropout'])",
            "+        self.drop = nn.Dropout(args['dropout'])",
            "self.worddrop = WordDropout(args['word_dropout'])",
            "",
            "def forward(self, word, word_mask, wordchars, wordchars_mask, upos, xpos, ufeats, pretrained, word_orig_idx, sentlens, wordlens):"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Low Efficiency|Deprecation Management Error"
    },
    {
        "number": 991,
        "change": [
            "def build_linear_positions(index_dims, output_range=(-1.0, 1.0)):",
            "return torch.linspace(start=output_range[0], end=output_range[1], steps=n_xels_per_dim, dtype=torch.float32)",
            "",
            "dim_ranges = [_linspace(n_xels_per_dim) for n_xels_per_dim in index_dims]",
            "-    array_index_grid = torch.meshgrid(*dim_ranges)",
            "+    array_index_grid = meshgrid(*dim_ranges, indexing=\"ij\")",
            "",
            "return torch.stack(array_index_grid, dim=-1)"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Deprecation Management Error"
    },
    {
        "number": 1007,
        "change": [
            "class GPT2Attention(nn.Module):",
            "# Apply the attention mask",
            "attn_weights = attn_weights + attention_mask",
            "",
            "-        attn_weights = nn.Softmax(dim=-1)(attn_weights)",
            "+        attn_weights = nn.functional.softmax(attn_weights, dim=-1)",
            "",
            "# Downcast (if necessary) back to V's dtype (if in mixed-precision) -- No-Op if otherwise",
            "if attn_weights.dtype != torch.float32:"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 1008,
        "change": [
            "class BidirectionalEndpointSpanExtractor(SpanExtractor):",
            "sequence_lengths = util.get_lengths_from_binary_sequence_mask(sequence_mask)",
            "else:",
            "# shape (batch_size), filled with the sequence length size of the sequence_tensor.",
            "-            sequence_lengths = util.ones_like(sequence_tensor[:, 0, 0]).long() * sequence_tensor.size(1)",
            "+            sequence_lengths = (torch.ones_like(sequence_tensor[:, 0, 0], dtype=torch.long) *",
            "+                                sequence_tensor.size(1))",
            "",
            "# shape (batch_size, num_spans, 1)",
            "end_sentinel_mask = (exclusive_span_ends == sequence_lengths.unsqueeze(-1)).long().unsqueeze(-1)"
        ],
        "comments": "add param for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 1013,
        "change": [
            "class ARSTFPolicy:",
            "self.num_params = sum(",
            "np.prod(variable.shape.as_list())",
            "for _, variable in self.variables.variables.items())",
            "-        self.sess.run(tf.global_variables_initializer())",
            "+        self.sess.run(tf1.global_variables_initializer())",
            "",
            "def compute_actions(self,",
            "observation,"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 1016,
        "change": [
            "class LanguageModel(nn.Module):",
            "",
            "for i in range(number_of_characters):",
            "",
            "-                if torch.cuda.is_available():",
            "-                    input = input.cuda()",
            "+                input = input.to(flair.device)",
            "",
            "# get predicted weights",
            "prediction, _, hidden = self.forward(input, hidden)"
        ],
        "comments": "change API call for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1024,
        "change": [
            "class MultiCategorical(TFActionDistribution):",
            "",
            "@override(ActionDistribution)",
            "def multi_kl(self, other):",
            "-        return [cat.kl(oth_cat) for cat, oth_cat in zip(self.cats, other.cats)]",
            "+        return tf.stack(",
            "+            [cat.kl(oth_cat) for cat, oth_cat in zip(self.cats, other.cats)],",
            "+            axis=1)",
            "",
            "@override(ActionDistribution)",
            "def kl(self, other):"
        ],
        "comments": "add API call for shape fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Algorithm Error"
    },
    {
        "number": 1027,
        "change": [
            "class Trainer:",
            "if self.args.past_index >= 0:",
            "inputs[\"mems\"] = past",
            "# Our model outputs do not work with DataParallel, so forcing return tuple.",
            "-            if self.args.n_gpu > 1:",
            "+            if isinstance(model, nn.DataParallel):",
            "inputs[\"return_tuple\"] = True",
            "",
            "with torch.no_grad():"
        ],
        "comments": "change condition check for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1028,
        "change": [
            "class PolicyWithValue:",
            "def sample(logits, mask_npinf):",
            "new_logits = tf.math.add(logits, mask_npinf)",
            "u = tf.random_uniform(tf.shape(new_logits), dtype=logits.dtype)",
            "-            return tf.argmax(new_logits - tf.log(-tf.log(u)), axis=-1)",
            "+            return tf.argmax(new_logits - tf.log(-1*tf.log(u)), axis=-1)",
            "",
            "def neglogp(logits, x):",
            "# return tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.logits, labels=x)"
        ],
        "comments": "change param for math fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 1030,
        "change": [
            "def Conv2DTranspose(",
            "if get_tf_version_tuple() <= (1, 12):",
            "kernel_initializer = tf.contrib.layers.variance_scaling_initializer(2.0),",
            "else:",
            "-            kernel_initializer = tf.keras.initializers.VarianceScaling(2.0)",
            "+            kernel_initializer = tf.keras.initializers.VarianceScaling(2.0, distribution='untruncated_normal')",
            "",
            "with rename_get_variable({'kernel': 'W', 'bias': 'b'}):",
            "layer = tf.layers.Conv2DTranspose("
        ],
        "comments": "add param for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 1033,
        "change": [
            "def make_batches(lines, args, task, max_positions, encode_fn):",
            ").long()",
            "for src_str in lines",
            "]",
            "-    lengths = torch.LongTensor([t.numel() for t in tokens])",
            "+    lengths = [t.numel() for t in tokens]",
            "itr = task.get_batch_iterator(",
            "dataset=task.build_dataset_for_inference(tokens, lengths),",
            "max_tokens=args.max_tokens,"
        ],
        "comments": "remove API call for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 1034,
        "change": [
            "class EarlyStopping(Callback):",
            "",
            "if trainer.use_tpu:",
            "stop = torch.tensor(int(trainer.should_stop), device=pl_module.device, dtype=torch.int32)",
            "-            stop = xm.mesh_reduce(\"stop_signal\", stop, torch.cat)",
            "+            stop = xm.mesh_reduce(\"stop_signal\", stop, sum)",
            "torch_xla.core.xla_model.rendezvous(\"pl.EarlyStoppingCallback.stop_distributed_training_check\")",
            "trainer.should_stop = int(stop.item()) == trainer.world_size"
        ],
        "comments": "add param for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1035,
        "change": [
            "class Entropy(Metric):",
            "mask : `torch.Tensor`, optional (default = None).",
            "A masking tensor of shape (batch_size, ...).",
            "\"\"\"",
            "-        logits, mask = self.unwrap_to_tensors(logits, mask)",
            "+        logits, mask = self.detach_tensors(logits, mask)",
            "",
            "if mask is None:",
            "-            mask = torch.ones(logits.size()[:-1])",
            "+            mask = torch.ones(logits.size()[:-1], device=logits.device)",
            "",
            "log_probs = torch.nn.functional.log_softmax(logits, dim=-1)",
            "probabilities = torch.exp(log_probs) * mask.unsqueeze(-1)"
        ],
        "comments": "change API call for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 1039,
        "change": [
            "class ImageEmbedder(nn.Module):",
            "",
            "self.to_patch_embedding = nn.Sequential(",
            "Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_size, p2 = patch_size),",
            "+            nn.LayerNorm(patch_dim),",
            "nn.Linear(patch_dim, dim),",
            "+            nn.LayerNorm(dim)",
            ")",
            "",
            "self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1043,
        "change": [
            "class BertForSequenceClassification(BertPreTrainedModel):",
            "",
            "self.bert = BertModel(config)",
            "self.dropout = nn.Dropout(config.hidden_dropout_prob)",
            "-        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)",
            "+        self.classifier = nn.Linear(config.hidden_size, config.num_labels)",
            "",
            "self.init_weights()"
        ],
        "comments": "change param for refactor fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 1044,
        "change": [
            "def fmod(",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "result = tf.math.floormod(x1, x2, name=None)",
            "-    temp = (result, x1)",
            "-    return tf.map_fn(lambda x: x[0] if (x[0] * x[1] >= 0) else (-1 * x[0]), temp)",
            "+    temp = [result, x1]",
            "+    return tf.map_fn(lambda x: x[0] if (x[0] * x[1] >= 0) else (-1 * x[0]), temp, fn_output_signature=result.dtype)",
            "",
            "",
            "def fmax("
        ],
        "comments": "add param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 1046,
        "change": [
            "class MT5DenseGatedActDense(nn.Module):",
            "# To make 8bit quantization work for google/flan-t5-xxl, self.wo is kept in float32.",
            "# See https://github.com/huggingface/transformers/issues/20287",
            "# we also make sure the weights are not in `int8` in case users will force `_keep_in_fp32_modules` to be `None``",
            "-        if hidden_states.dtype != self.wo.weight.dtype and self.wo.weight.dtype != torch.int8:",
            "+        if (",
            "+            isinstance(self.wo.weight, torch.Tensor)",
            "+            and hidden_states.dtype != self.wo.weight.dtype",
            "+            and self.wo.weight.dtype != torch.int8",
            "+        ):",
            "hidden_states = hidden_states.to(self.wo.weight.dtype)",
            "",
            "hidden_states = self.wo(hidden_states)"
        ],
        "comments": "change condition check for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 1048,
        "change": [
            "def vector_to_skew_symmetric_matrix(vector):",
            "a2s = vector_expanded[..., 1:2, :]",
            "a3s = vector_expanded[..., 2:3, :]",
            "# BS x 1 x 1",
            "-    zs = torch.zeros(batch_shape + [1, 1])",
            "+    zs = torch.zeros(batch_shape + [1, 1], device=vector.device)",
            "# BS x 1 x 3",
            "row1 = torch.cat((zs, -a3s, a2s), -1)",
            "row2 = torch.cat((a3s, zs, -a1s), -1)"
        ],
        "comments": "add param for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1050,
        "change": [
            "class PointAssigner(BaseAssigner):",
            "",
            "if gt_labels is not None:",
            "assigned_labels = assigned_gt_inds.new_full((num_points, ), -1)",
            "-            pos_inds = torch.nonzero(assigned_gt_inds > 0).squeeze()",
            "+            pos_inds = torch.nonzero(",
            "+                assigned_gt_inds > 0, as_tuple=False).squeeze()",
            "if pos_inds.numel() > 0:",
            "assigned_labels[pos_inds] = gt_labels[",
            "assigned_gt_inds[pos_inds] - 1]"
        ],
        "comments": "add param for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Device Management Error"
    },
    {
        "number": 1052,
        "change": [
            "def att_to_numpy(att_ws, att):",
            "att_ws = torch.stack([aw[:, -1] for aw in att_ws], dim=1).cpu().numpy()",
            "elif isinstance(att, (AttCov, AttCovLoc)):",
            "# att_ws => list of list of previous attentions",
            "-        att_ws = torch.stack([aw[-1] for aw in att_ws], dim=1).cpu().numpy()",
            "+        att_ws = torch.stack([aw[idx] for idx, aw in enumerate(att_ws)], dim=1).cpu().numpy()",
            "elif isinstance(att, AttLocRec):",
            "# att_ws => list of tuple of attention and hidden states",
            "att_ws = torch.stack([aw[0] for aw in att_ws], dim=1).cpu().numpy()"
        ],
        "comments": "change param for shape fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 1054,
        "change": [
            "class HestonModel(generic_ito_process.GenericItoProcess):",
            "drift = tf.stack([log_spot_drift, var_drift], -1)",
            "return drift",
            "",
            "-    super(HestonModel, self).__init__(2, _drift_fn, _vol_fn, dtype, name)",
            "+    super(HestonModel, self).__init__(2, _drift_fn, _vol_fn, self._dtype, name)",
            "",
            "def sample_paths(self,",
            "times: types.RealTensor,"
        ],
        "comments": "change param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 1056,
        "change": [
            "class SimilarityLearner(flair.nn.Model):",
            "epoch_results_str,",
            "detailed_results,",
            "),",
            "-            0,",
            "+            torch.tensor(0),",
            ")",
            "",
            "def _get_state_dict(self):"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 1059,
        "change": [
            "class TFOPTDecoder(tf.keras.layers.Layer):",
            "if output_attentions:",
            "all_self_attns += (layer_self_attn,)",
            "",
            "+        if self.final_layer_norm is not None:",
            "+            hidden_states = self.final_layer_norm(hidden_states)",
            "+",
            "if self.project_out is not None:",
            "hidden_states = self.project_out(hidden_states)"
        ],
        "comments": "add condition check for null fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1060,
        "change": [
            "def convert_examples_to_features(examples, seq_length, tokenizer):",
            "if ex_index < 5:",
            "tf.logging.info(\"*** Example ***\")",
            "tf.logging.info(\"unique_id: %s\" % (example.unique_id))",
            "-      tf.logging.info(\"tokens: %s\" % \" \".join([str(x) for x in tokens]))",
            "+      tf.logging.info(\"tokens: %s\" % \" \".join(",
            "+          [tokenization.printable_text(x) for x in tokens]))",
            "tf.logging.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))",
            "tf.logging.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))",
            "tf.logging.info("
        ],
        "comments": "change API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 1064,
        "change": [
            "def load_model(filepath, custom_optimizers=None, custom_objects=None, compressio",
            "\"\"\"",
            "def wrap_optimizer(cls):",
            "return lambda **kwargs: DistributedOptimizer(cls(**kwargs), compression=compression)",
            "-    return _impl.load_model(keras, wrap_optimizer, filepath, custom_optimizers, custom_objects)",
            "+    optimizer_modules = {keras.optimizers.Optimizer.__module__}",
            "+    return _impl.load_model(keras, wrap_optimizer, optimizer_modules, filepath, custom_optimizers, custom_objects)"
        ],
        "comments": "add param for argument fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 1065,
        "change": [
            "class ParabolicEquationStepperTest(tf.test.TestCase, parameterized.TestCase):",
            "second_order_coeff_fn=second_order_coeff_fn,",
            "inner_first_order_coeff_fn=inner_first_order_coeff_fn)[0]",
            "",
            "-    true_values = tf.math.exp(final_t + grid[0])",
            "+    true_values = tf.expand_dims(tf.math.exp(final_t + grid[0]), axis=0)",
            "self.assertAllClose(",
            "est_values, true_values, atol=1e-2, rtol=1e-2)"
        ],
        "comments": "add API call for shape fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 1066,
        "change": [
            "class LocalMultiGPUOptimizer(PolicyOptimizer):",
            "else:",
            "rnn_inputs = []",
            "self.par_opt = LocalSyncParallelOptimizer(",
            "-                        tf.train.AdamOptimizer(",
            "-                            self.sgd_stepsize), self.devices,",
            "+                        self.policy.optimizer(), self.devices,",
            "[v for _, v in self.policy.loss_inputs()], rnn_inputs,",
            "self.per_device_batch_size, self.policy.copy,",
            "os.getcwd())"
        ],
        "comments": "change API call for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1067,
        "change": [
            "class DistributedReplicatedBuilder(DataParallelBuilder):",
            "return grads",
            "",
            "# Ngpu * Nvar * 2",
            "-        grad_list = self.build_on_multi_tower(",
            "-            get_grads,",
            "+        grad_list = DataParallelBuilder.build_on_towers(",
            "+            self.towers, get_grads,",
            "devices=self.raw_devices,",
            "use_vs=[True] * len(self.towers))  # open vs at each tower",
            "DataParallelBuilder._check_grad_list(grad_list)"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 1069,
        "change": [
            "class OPTForSequenceClassification(OPTPreTrainedModel):",
            "sequence_lengths = -1",
            "else:",
            "if input_ids is not None:",
            "-                sequence_lengths = torch.ne(input_ids, self.config.pad_token_id).sum(-1) - 1",
            "+                sequence_lengths = (torch.ne(input_ids, self.config.pad_token_id).sum(-1) - 1).to(logits.device)",
            "else:",
            "sequence_lengths = -1",
            "logger.warning("
        ],
        "comments": "add API call for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1072,
        "change": [
            "def test_discrete_parallel(continuous_class):",
            "",
            "def model(data):",
            "weights = pyro.sample('weights', dist.Dirichlet(0.5 * torch.ones(K)))",
            "-        locs = pyro.sample('locs', dist.Normal(0, 10).reshape([K], extra_event_dims=1))",
            "+        locs = pyro.sample('locs', dist.Normal(0, 10).expand_by([K]).independent(1))",
            "scale = pyro.sample('scale', dist.LogNormal(0, 1))",
            "",
            "with pyro.iarange('data', len(data)):"
        ],
        "comments": "change API call for math fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 1077,
        "change": [
            "class MaskTokensDataset(BaseWrapperDataset):",
            "if self.mask_whole_words is not None:",
            "mask = np.repeat(mask, word_lens)",
            "new_item = np.full(len(mask), self.pad_idx)",
            "-                new_item[mask] = item[torch.from_numpy(mask)]",
            "+                new_item[mask] = item[torch.from_numpy(mask.astype(np.uint8))]",
            "return torch.from_numpy(new_item)",
            "",
            "# decide unmasking and random replacement"
        ],
        "comments": "add API call for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 1079,
        "change": [
            "def _sample_coalescent_times(leaf_times):",
            "coal_times.append(t)",
            "coal_times.reverse()",
            "",
            "-    return torch.tensor(coal_times)",
            "+    return proto.new_tensor(coal_times)"
        ],
        "comments": "change API call for refactor fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 1083,
        "change": [
            "class CategoricalAccuracy(Metric):",
            "# ith entry in gold_labels points to index (0-num_classes) for ith row in max_predictions",
            "# For each row check if index pointed by gold_label is was 1 or not (among max scored classes)",
            "correct = max_predictions_mask[",
            "-                torch.arange(gold_labels.numel()).long(), gold_labels",
            "+                torch.arange(gold_labels.numel(), device=gold_labels.device).long(), gold_labels",
            "].float()",
            "tie_counts = max_predictions_mask.sum(-1)",
            "correct /= tie_counts.float()"
        ],
        "comments": "add param for resource fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1091,
        "change": [
            "class Model(ModelDesc):",
            ".GlobalAvgPooling('gap')",
            ".FullyConnected('linear', 1000, nl=tf.identity)())",
            "",
            "-        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, label)",
            "+        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)",
            "loss = tf.reduce_mean(loss, name='xentropy-loss')",
            "",
            "wrong = prediction_incorrect(logits, label, 1, name='wrong-top1')"
        ],
        "comments": "add param for argument fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Argument Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Argument Error"
    },
    {
        "number": 1094,
        "change": [
            "def batchnorm_example(optimizer_fn,",
            "for z in range(batch_per_epoch)]).repeat()",
            "",
            "optimizer = optimizer_fn()",
            "-  batchnorm = tf.compat.v1.layers.BatchNormalization(",
            "+  batchnorm = normalization.BatchNormalization(",
            "renorm=renorm, momentum=momentum, fused=False)",
            "-  layer = tf.compat.v1.layers.Dense(1, use_bias=False)",
            "+  layer = core.Dense(1, use_bias=False)",
            "",
            "def model_fn(x):",
            "\"\"\"A model that uses batchnorm.\"\"\""
        ],
        "comments": "change API call for version fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 1104,
        "change": [
            "class EpsilonDecay(Exploration):",
            "",
            "pred = tf.logical_or(x=(timestep < self.start_timestep),",
            "y=(timestep > self.start_timestep + int(self.timesteps)))",
            "-        return tf.cond(pred=pred, true_fn=true_fn, false_fn=false_fn)",
            "+        return tf.fill(dims=shape, value=tf.cond(pred=pred, true_fn=true_fn, false_fn=false_fn))"
        ],
        "comments": "change API call for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1114,
        "change": [
            "class Stft(torch.nn.Module, InversibleInterface):",
            "pad = self.n_fft // 2",
            "ilens = ilens + 2 * pad",
            "",
            "-            olens = (",
            "-                torch.div((ilens - self.n_fft), self.hop_length, rounding_mode=\"floor\")",
            "-                + 1",
            "-            )",
            "+            olens = torch.div((ilens - self.n_fft), self.hop_length) + 1",
            "output.masked_fill_(make_pad_mask(olens, output, 1), 0.0)",
            "else:",
            "olens = None"
        ],
        "comments": "remove param for math fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 1118,
        "change": [
            "def _scale_channel(im: torch.Tensor) -> torch.Tensor:",
            "# and then normalization by step.",
            "lut = (torch.cumsum(histo, 0) + (step // 2)) // step",
            "# Shift lut, prepending with 0.",
            "-        lut = torch.cat([torch.zeros(1, device=lut.device), lut[:-1]])",
            "+        lut = torch.cat([torch.zeros(1, device=lut.device, dtype=lut.dtype), lut[:-1]])",
            "# Clip the counts to be in range.  This is done",
            "# in the C code for image.point.",
            "return torch.clamp(lut, 0, 255)"
        ],
        "comments": "add param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 1122,
        "change": [
            "class DonutSwinLayer(nn.Module):",
            "# partition windows",
            "hidden_states_windows = window_partition(shifted_hidden_states, self.window_size)",
            "hidden_states_windows = hidden_states_windows.view(-1, self.window_size * self.window_size, channels)",
            "-        attn_mask = self.get_attn_mask(height_pad, width_pad)",
            "+        attn_mask = self.get_attn_mask(height_pad, width_pad, dtype=hidden_states.dtype)",
            "if attn_mask is not None:",
            "attn_mask = attn_mask.to(hidden_states_windows.device)"
        ],
        "comments": "add param for type fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 1126,
        "change": [
            "for it in range(1000000):",
            "D_reg = D(G_sample_reg)",
            "",
            "mse = torch.sum((X - G_sample_reg)**2, 1)",
            "-    E_loss = torch.mean(lam1 * mse + lam2 * D_reg)",
            "+    E_loss = torch.mean(lam1 * mse + lam2 * log(D_reg))",
            "",
            "E_loss.backward()",
            "E_solver.step()"
        ],
        "comments": "add API call for math fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Algorithm Error"
    },
    {
        "number": 1127,
        "change": [
            "class VisualBertEmbeddings(nn.Module):",
            "inputs_embeds = self.word_embeddings(input_ids)",
            "",
            "if token_type_ids is None:",
            "-            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.input_embeds.device)",
            "+            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.position_ids.device)",
            "",
            "token_type_embeddings = self.token_type_embeddings(token_type_ids)"
        ],
        "comments": "change param for resource fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 1128,
        "change": [
            "class BCELossMasked(nn.Module):",
            "Returns:",
            "loss: An average loss value in range [0, 1] masked by the length.",
            "\"\"\"",
            "-        # mask: (batch, max_len, 1)",
            "target.requires_grad = False",
            "if length is not None:",
            "-            mask = sequence_mask(sequence_length=length, max_len=target.size(1)).float()",
            "-            x = x * mask",
            "-            target = target * mask",
            "+            # mask: (batch, max_len, 1)",
            "+            mask = sequence_mask(sequence_length=length, max_len=target.size(1))",
            "num_items = mask.sum()",
            "+            loss = functional.binary_cross_entropy_with_logits(x.masked_select(mask), target.masked_select(mask), pos_weight=self.pos_weight, reduction=\"sum\")",
            "else:",
            "+            loss = functional.binary_cross_entropy_with_logits(x, target, pos_weight=self.pos_weight, reduction=\"sum\")",
            "num_items = torch.numel(x)",
            "-        loss = functional.binary_cross_entropy_with_logits(x, target, pos_weight=self.pos_weight, reduction=\"sum\")",
            "loss = loss / num_items",
            "return loss"
        ],
        "comments": "remove API call for type fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 1132,
        "change": [
            "class TFFastSpeech(tf.keras.Model):",
            "== config.decoder_self_attention_params.hidden_size,",
            "name=\"decoder\",",
            ")",
            "-        self.mel_dense = tf.keras.layers.Dense(units=config.num_mels, name=\"mel_before\")",
            "-        self.postnet = TFTacotronPostnet(config=config, name=\"postnet\")",
            "+        self.mel_dense = tf.keras.layers.Dense(units=config.num_mels, dtype=tf.float32, name=\"mel_before\")",
            "+        self.postnet = TFTacotronPostnet(config=config, dtype=tf.float32, name=\"postnet\")",
            "",
            "self.setup_inference_fn()"
        ],
        "comments": "add param for type fix",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 1140,
        "change": [
            "class Model(object):",
            "#     raise TensorForceError(\"Invalid model directory/file.\")",
            "",
            "self.saver.restore(sess=self.session, save_path=file)",
            "+        self.session.run(self.buffer_index_reset_op)",
            "",
            "def get_components(self):",
            "\"\"\""
        ],
        "comments": "add API call for state fix",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 1142,
        "change": [
            "class TexturesAtlas(TexturesBase):",
            "# pyre-fixme[16]: `bool` has no attribute `__getitem__`.",
            "mask = (pix_to_face < 0)[..., None]",
            "bary_w01 = torch.where(mask, torch.zeros_like(bary_w01), bary_w01)",
            "-        w_xy = (bary_w01 * R).to(torch.int64)  # (N, H, W, K, 2)",
            "+        # If barycentric coordinates are > 1.0 (in the case of",
            "+        # blur_radius > 0.0), wxy might be > R. We need to clamp this",
            "+        # index to R-1 to index into the texture atlas.",
            "+        w_xy = (bary_w01 * R).to(torch.int64).clamp(max=R - 1)  # (N, H, W, K, 2)",
            "",
            "below_diag = (",
            "bary_w01.sum(dim=-1) * R - w_xy.float().sum(dim=-1)"
        ],
        "comments": "add API call for math fix",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 1144,
        "change": [
            "class VariationalSparseGP(GPModel):",
            "M = self.Xu.size(0)",
            "Kuu = self.kernel(self.Xu).contiguous()",
            "Kuu.view(-1)[::M + 1] += self.jitter  # add jitter to the diagonal",
            "-        Luu = Kuu.cholesky()",
            "+        Luu = torch.linalg.cholesky(Kuu)",
            "",
            "zero_loc = self.Xu.new_zeros(self.u_loc.shape)",
            "if self.whiten:"
        ],
        "comments": "update API call for version fix",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 1148,
        "change": [
            "def _matvecmul(x, y):",
            "",
            "",
            "def _cholesky(x):",
            "-    return x.sqrt() if x.dim() == 1 else x.cholesky()",
            "+    return x.sqrt() if x.dim() == 1 else torch.linalg.cholesky(x)",
            "",
            "",
            "def _transpose(x):"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 1152,
        "change": [
            "def rnn(step_function, inputs, initial_states,",
            "new_states = []",
            "",
            "# all this circus is to recover the last vector in the sequence.",
            "-        begin = tf.pack([tf.shape(outputs)[0] - 1] + [0] * (ndim - 1))",
            "-        size = tf.pack([1] + [-1] * (ndim - 1))",
            "-        last_output = tf.slice(outputs, begin, size)",
            "+        slice_begin = tf.pack([tf.shape(outputs)[0] - 1] + [0] * (ndim - 1))",
            "+        slice_size = tf.pack([1] + [-1] * (ndim - 1))",
            "+        last_output = tf.slice(outputs, slice_begin, slice_size)",
            "last_output = tf.squeeze(last_output, [0])",
            "",
            "axes = [1, 0] + list(range(2, len(outputs.get_shape())))"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 1190,
        "change": [
            "class TorchCheckpointWrapper(CheckpointWrapper):",
            "#  --> https://github.com/facebookresearch/fairscale/blob/1e4a503cda8571851a68effd6e504a192838ab06/fairscale/nn/checkpoint/checkpoint_activations.py#L145-L153  # noqa: E501",
            "# We just patch the forward method to avoid having to proxy all the fields and other methods.",
            "# The use of weakref here is to prevent creating a ref cycle: m -> m.forward -> m.",
            "+",
            "+        assert len(kwargs) == 0  # This way of wrapping only works for positional arguments.",
            "+",
            "module.forward = functools.partial(  # type: ignore[assignment]",
            "_checkpointed_forward, type(module).forward, weakref.ref(module)",
            ")"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1193,
        "change": [
            "class RNN(torch.nn.Module):",
            "def __init__(self, idim, elayers, cdim, hdim, dropout, typ=\"blstm\"):",
            "super(RNN, self).__init__()",
            "bidir = typ[0] == \"b\"",
            "-        self.nblstm = torch.nn.LSTM(idim, cdim, elayers, batch_first=True,",
            "-                                    dropout=dropout, bidirectional=bidir) if \"lstm\" in typ \\",
            "+        self.nbrnn = torch.nn.LSTM(idim, cdim, elayers, batch_first=True,",
            "+                                   dropout=dropout, bidirectional=bidir) if \"lstm\" in typ \\",
            "else torch.nn.GRU(idim, cdim, elayers, batch_first=True, dropout=dropout,",
            "bidirectional=bidir)",
            "if bidir:"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 1200,
        "change": [
            "class TokenCharactersIndexer(TokenIndexer[List[int]]):",
            "# Removes the \"dummy token\".",
            "padded_tokens.pop()",
            "# Truncates all the tokens to the desired length, and return the result.",
            "-        return {key: [list(token[:desired_token_length]) for token in padded_tokens]}",
            "+        return {key: torch.LongTensor([list(token[:desired_token_length])",
            "+                                       for token in padded_tokens])}"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 1201,
        "change": [
            "class LKJCorrCholesky(TorchDistribution):",
            "Km1 = self._d - 1",
            "",
            "log_diagonals = x.diagonal(offset=0, dim1=-1, dim2=-2)[..., 1:].log()",
            "+        # TODO: Figure out why the `device` kwarg to torch.linspace seems to not work in certain situations,",
            "+        # and a seemingly redundant .to(x.device) is needed below.",
            "values = log_diagonals * torch.linspace(start=Km1 - 1, end=0, steps=Km1,",
            "dtype=x.dtype,",
            "-                                                device=x.device).expand_as(log_diagonals)",
            "+                                                device=x.device).expand_as(log_diagonals).to(x.device)",
            "",
            "values += log_diagonals.mul(eta.mul(2).add(-2.0))",
            "values = values.sum(-1) + lp"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1215,
        "change": [
            "class EKFState(object):",
            "S = H.mm(P).mm(H.transpose(-1, -2)) + R  # innovation cov",
            "",
            "K_prefix = self._cov.mm(H.transpose(-1, -2))",
            "-        dx = K_prefix.mm(torch.gesv(dz, S)[0]).squeeze(1)  # K*dz",
            "+        dx = K_prefix.mm(torch.gesv(dz.unsqueeze(1), S)[0]).squeeze(1)  # K*dz",
            "x = self._dynamic_model.geodesic_difference(x, -dx)",
            "",
            "I = eye_like(x, self._dynamic_model.dimension)  # noqa: E741"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 1230,
        "change": [
            "class patch_submodule:",
            "Examples:",
            "",
            ">>> import importlib",
            "-        >>> from datasets.load import prepare_module",
            "+        >>> from datasets.load import dataset_module_factory",
            ">>> from datasets.streaming import patch_submodule, xjoin",
            ">>>",
            "-        >>> snli_module_path, _ = prepare_module(\"snli\")",
            "-        >>> snli_module = importlib.import_module(snli_module_path)",
            "+        >>> dataset_module = dataset_module_factory(\"snli\")",
            "+        >>> snli_module = importlib.import_module(dataset_module.module_path)",
            ">>> patcher = patch_submodule(snli_module, \"os.path.join\", xjoin)",
            ">>> patcher.start()",
            ">>> assert snli_module.os.path.join is xjoin"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Deprecation Management Error"
    },
    {
        "number": 1248,
        "change": [
            "class DeepSpeedZeRoOffload(object):",
            "self._prefetch_bucket_sz = int(prefetch_bucket_size)",
            "self._max_reuse_distance_in_numel = int(max_reuse_distance)",
            "self._max_available_parameters_in_numel = int(max_live_parameters)",
            "-        self.__allgather_stream = Stream(",
            "-        ) if overlap_comm else torch.cuda.default_stream()",
            "+        self.__allgather_stream = get_accelerator().Stream(",
            "+        ) if overlap_comm else get_accelerator().default_stream()",
            "",
            "self.forward_hooks = []",
            "self.backward_hooks = []"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1257,
        "change": [
            "class Module(tf.Module):",
            "elif initializer == 'ones':",
            "initializer = tf_util.ones(shape=spec.shape, dtype=spec.type)",
            "elif initializer == 'constant':",
            "-            initializer = tf_util.fill(dims=spec.shape, value=self.initialization_scale)",
            "+            initializer = tf.fill(",
            "+                dims=spec.shape, value=tf_util.constant(value=initialization_scale, dtype=spec.type)",
            "+            )",
            "",
            "# Variable",
            "variable = tf.Variable("
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 1266,
        "change": [
            "PT_SEQUENCE_CLASSIFICATION_SAMPLE = r\"\"\"",
            "...     \"{checkpoint}\", num_labels=num_labels, problem_type=\"multi_label_classification\"",
            "... )",
            "",
            "-    >>> labels = torch.nn.functional.one_hot(torch.tensor(predicted_class_ids), num_classes=num_labels).to(torch.float)",
            "+    >>> labels = torch.sum(",
            "+    ...     torch.nn.functional.one_hot(predicted_class_ids[None, :].clone(), num_classes=num_labels), dim=1",
            "+    ... ).to(torch.float)",
            ">>> loss = model(**inputs, labels=labels).loss",
            "```",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1294,
        "change": [
            "class SCSEModule(nn.Module):",
            "nn.Conv2d(in_channels // reduction, in_channels, 1),",
            "nn.Sigmoid(),",
            ")",
            "-        self.sSE = nn.Sequential(nn.Conv2d(in_channels, in_channels, 1), nn.Sigmoid())",
            "+        self.sSE = nn.Sequential(nn.Conv2d(in_channels, 1, 1), nn.Sigmoid())",
            "",
            "def forward(self, x):",
            "return x * self.cSE(x) + x * self.sSE(x)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1302,
        "change": [
            "def main(args):  # pylint: disable=redefined-outer-name",
            "pos_weight=torch.tensor(10)) if c.stopnet else None",
            "",
            "if args.restore_path:",
            "-        checkpoint = torch.load(args.restore_path)",
            "+        checkpoint = torch.load(args.restore_path, map_location='cpu')",
            "try:",
            "# TODO: fix optimizer init, model.cuda() needs to be called before",
            "# optimizer restore"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 1308,
        "change": [
            "def count_nonzero(",
            "def _dtype_count_nonzero(a, axis, dtype):",
            "if dtype is None:",
            "return torch.count_nonzero(a, dim=axis)",
            "-        return torch.tensor(torch.count_nonzero(a, dim=axis), dtype=dtype)",
            "+        return torch.tensor(torch.count_nonzero(a, dim=axis),",
            "+                            dtype=ivy.as_native_dtype(dtype))",
            "",
            "x = _dtype_count_nonzero(a, axis, dtype)",
            "if not keepdims:"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 1312,
        "change": [
            "class TorchTensor(AbstractTensor):",
            "",
            "\"\"\"",
            "",
            "-        assert isinstance(self.child, PointerTensor)",
            "+        if not isinstance(self.child, PointerTensor):",
            "+            raise TypeError(\"child should be a PointerTensor\")",
            "",
            "ps = list(pointers)",
            "ps.append(self)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 1313,
        "change": [
            "def unravel_index(",
            "for dim in reversed(shape):",
            "output.append(temp % dim)",
            "temp = temp // dim",
            "-    return tuple(reversed(output))",
            "+    return torch.tensor(reversed(output))",
            "",
            "",
            "unravel_index.support_native_out = False"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 1315,
        "change": [
            "class CanineSelfAttention(nn.Module):",
            "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for",
            "# masked positions, this operation will create a tensor which is 0.0 for",
            "# positions we want to attend and -10000.0 for masked positions.",
            "-                attention_mask = (1.0 - attention_mask.float()) * -10000.0",
            "+                attention_mask = (1.0 - attention_mask.float()) * torch.finfo(attention_scores.dtype).min",
            "# Apply the attention mask (precomputed for all layers in CanineModel forward() function)",
            "attention_scores = attention_scores + attention_mask"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 1323,
        "change": [
            "class TFModel(NNModel, metaclass=TfModelMeta):",
            "opt_scope = tf.variable_scope(optimizer_scope_name)",
            "with opt_scope:",
            "if learnable_scopes is None:",
            "-                variables_to_train = tf.trainable_variables()",
            "+                variables_to_train = tf.global_variables()",
            "else:",
            "variables_to_train = []",
            "for scope_name in learnable_scopes:",
            "-                    for var in tf.trainable_variables():",
            "+                    for var in tf.global_variables():",
            "if scope_name in var.name:",
            "variables_to_train.append(var)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1338,
        "change": [
            "class EncdecMultiheadAttn(nn.Module):",
            "",
            "def reset_parameters(self):",
            "nn.init.xavier_uniform_(self.in_proj_weight_q)",
            "-        nn.init.xavier_uniform_(self.in_proj_weight_kv)",
            "+        # in_proj_weight_kv has shape [2 * hidden, hidden] but it should be",
            "+        # initialized like a [hidden, hidden] matrix.",
            "+        # sqrt(6 / (hidden + hidden)) / sqrt(6 / (2 * hidden + hidden)) = sqrt(1.5)",
            "+        # therefore xavier_uniform gain should be set to sqrt(1.5).",
            "+        nn.init.xavier_uniform_(self.in_proj_weight_kv, gain=math.sqrt(1.5))",
            "nn.init.xavier_uniform_(self.out_proj_weight)",
            "if self.bias:",
            "nn.init.constant_(self.in_proj_bias_q, 0.)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 1363,
        "change": [
            "def get_timestep_embedding(",
            "assert len(timesteps.shape) == 1, \"Timesteps should be a 1d-array\"",
            "",
            "half_dim = embedding_dim // 2",
            "-    exponent = -math.log(max_period) * torch.arange(start=0, end=half_dim, dtype=torch.float32)",
            "+    exponent = -math.log(max_period) * torch.arange(",
            "+        start=0, end=half_dim, dtype=torch.float32, device=timesteps.device",
            "+    )",
            "exponent = exponent / (half_dim - downscale_freq_shift)",
            "",
            "-    emb = torch.exp(exponent).to(device=timesteps.device)",
            "+    emb = torch.exp(exponent)",
            "emb = timesteps[:, None].float() * emb[None, :]",
            "",
            "# scale embeddings"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1373,
        "change": [
            "def train_func(config):",
            "train_dataset = Subset(train_dataset, list(range(64)))",
            "validation_dataset = Subset(validation_dataset, list(range(64)))",
            "",
            "-    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"])",
            "-    validation_loader = DataLoader(validation_dataset, batch_size=config[\"batch_size\"])",
            "+    worker_batch_size = config[\"batch_size\"] // train.world_size()",
            "+",
            "+    train_loader = DataLoader(train_dataset, batch_size=worker_batch_size)",
            "+    validation_loader = DataLoader(validation_dataset, batch_size=worker_batch_size)",
            "",
            "train_loader = train.torch.prepare_data_loader(train_loader)",
            "validation_loader = train.torch.prepare_data_loader(validation_loader)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1397,
        "change": [
            "def binary_config():",
            "def test_binary_input_feature(binary_config: Dict, encoder: str) -> None:",
            "binary_config.update({\"encoder\": encoder})",
            "binary_input_feature = BinaryInputFeature(binary_config)",
            "-    binary_tensor = torch.randn([SEQ_SIZE, BINARY_W_SIZE], dtype=torch.float32)",
            "+    binary_tensor = torch.randn([SEQ_SIZE, BINARY_W_SIZE], dtype=torch.float32).to(DEVICE)",
            "encoder_output = binary_input_feature(binary_tensor)",
            "assert encoder_output[\"encoder_output\"].shape[1:] == binary_input_feature.output_shape"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1399,
        "change": [
            "class TestEulerFromQuaternion(BaseTester):",
            "def test_module(self, device, dtype):",
            "pass",
            "",
            "-    def test_jit(self, device, dtype):",
            "+    def test_dynamo(self, device, dtype, torch_optimizer):",
            "q = Quaternion.random(batch_size=1)",
            "q = q.to(device, dtype)",
            "op = euler_from_quaternion",
            "-        op_jit = torch.jit.script(op)",
            "-        assert_close(op(q.w, q.x, q.y, q.z), op_jit(q.w, q.x, q.y, q.z))",
            "+        op_optimized = torch_optimizer(op)",
            "+        assert_close(op(q.w, q.x, q.y, q.z), op_optimized(q.w, q.x, q.y, q.z))",
            "",
            "def test_forth_and_back(self, device, dtype):",
            "q = Quaternion.random(batch_size=2)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1405,
        "change": [
            "def run(",
            "seen, windows, dt = 0, [], (Profile(), Profile(), Profile())",
            "for path, im, im0s, vid_cap, s in dataset:",
            "with dt[0]:",
            "-            im = torch.Tensor(im).to(device)",
            "+            im = torch.Tensor(im).to(model.device)",
            "im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32",
            "if len(im.shape) == 3:",
            "im = im[None]  # expand for batch dim"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1415,
        "change": [
            "class SwapBufferManager(object):",
            "self.count = count",
            "self.dtype = dtype",
            "self.all_buffers = [",
            "-            torch.zeros(num_elems,",
            "-                        device='cpu',",
            "-                        dtype=dtype).pin_memory() for _ in range(count)",
            "+            get_accelerator().pin_memory(",
            "+                torch.zeros(num_elems,",
            "+                            device='cpu',",
            "+                            dtype=dtype)) for _ in range(count)",
            "]",
            "self.free_buffer_index = [i for i in range(count)]",
            "self.used_buffer_index = {}"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1427,
        "change": [
            "def test_gcn2_conv():",
            "",
            "t = '(Tensor, Tensor, SparseTensor, OptTensor) -> Tensor'",
            "jit = torch.jit.script(conv.jittable(t))",
            "-    assert torch.allclose(conv(x, x_0, adj1.t()), out1, atol=1e-6)",
            "-    assert torch.allclose(conv(x, x_0, adj2.t()), out2, atol=1e-6)",
            "+    assert torch.allclose(jit(x, x_0, adj1.t()), out1, atol=1e-6)",
            "+    assert torch.allclose(jit(x, x_0, adj2.t()), out2, atol=1e-6)",
            "",
            "conv.cached = True",
            "conv(x, x_0, edge_index)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1435,
        "change": [
            "def test_load_dataset_streaming(dataset_loading_script_dir, data_dir):",
            "def test_loading_from_the_datasets_hub():",
            "with tempfile.TemporaryDirectory() as tmp_dir:",
            "dataset = load_dataset(SAMPLE_DATASET_IDENTIFIER, cache_dir=tmp_dir)",
            "-        assert len(dataset[\"train\"]), 2",
            "-        assert len(dataset[\"validation\"]), 3",
            "+        assert len(dataset[\"train\"]) == 2",
            "+        assert len(dataset[\"validation\"]) == 3",
            "del dataset"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 1450,
        "change": [
            "class BertForQuestionAnswering(nn.Module):",
            "",
            "def compute_loss(logits, positions):",
            "max_position = positions.max().item()",
            "-                one_hot = torch.FloatTensor(batch_size, max(max_position, seq_length) +1, device=input_ids.device).zero_()",
            "+                one_hot = torch.FloatTensor(batch_size, max(max_position, seq_length) +1).zero_()",
            "one_hot = one_hot.scatter(1, positions.cpu(), 1) # Second argument need to be LongTensor and not cuda.LongTensor",
            "-                one_hot = one_hot[:, :seq_length]",
            "+                one_hot = one_hot[:, :seq_length].to(input_ids.device)",
            "log_probs = nn.functional.log_softmax(logits, dim = -1).view(batch_size, seq_length)",
            "loss = -torch.mean(torch.sum(one_hot*log_probs), dim = -1)",
            "return loss"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 1463,
        "change": [
            "def main():",
            "",
            "# Save the result as an audio summary.",
            "datestring = str(datetime.now()).replace(' ', 'T')",
            "-    writer = tf.train.SummaryWriter(logdir)",
            "-    tf.audio_summary('generated', decode, wavenet_params['sample_rate'])",
            "-    summaries = tf.merge_all_summaries()",
            "+    writer = tf.summary.FileWriter(logdir)",
            "+    tf.summary.audio('generated', decode, wavenet_params['sample_rate'])",
            "+    summaries = tf.summary.merge_all()",
            "summary_out = sess.run(summaries,",
            "feed_dict={samples: np.reshape(waveform, [-1, 1])})",
            "writer.add_summary(summary_out)"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 1465,
        "change": [
            "def load_indexes():",
            "",
            "@st.cache(allow_output_mutation=True)",
            "def load_train_data():",
            "-    eli5 = nlp.load_dataset(\"eli5\", name=\"LFQA_reddit\")",
            "+    eli5 = datasets.load_dataset(\"eli5\", name=\"LFQA_reddit\")",
            "eli5_train = eli5[\"train_eli5\"]",
            "eli5_train_q_reps = np.memmap(",
            "\"eli5_questions_reps.dat\", dtype=\"float32\", mode=\"r\", shape=(eli5_train.num_rows, 128)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 1466,
        "change": [
            "def depthwise_conv2d(",
            "dilations: Optional[Union[int, Tuple[int, int]]] = 1,",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "-    x = torch.tensor(x)",
            "-    filters = torch.tensor(filters)",
            "+    x = torch.as_tensor(x)",
            "+    filters = torch.as_tensor(filters)",
            "strides = [strides] * 2 if isinstance(strides, int) else strides",
            "strides = [strides[1], strides[2]] if len(strides) == 4 else strides",
            "dilations = [dilations] * 2 if isinstance(dilations, int) else dilations",
            "-    filters = ivy.squeeze(filters, 3) if filters.ndim == 4 else filters",
            "+    filters = ivy.squeeze(filters, 3).to_native() if filters.ndim == 4 else filters",
            "",
            "f_w_after_dilation = filters.shape[1] + (",
            "(dilations[1] - 1) * (filters.shape[1] - 1)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 1477,
        "change": [
            "class RandomMutator(Mutator):",
            "result = dict()",
            "for mutable in self.mutables:",
            "if isinstance(mutable, LayerChoice):",
            "-                gen_index = torch.randint(high=mutable.length, size=(1, ))",
            "-                result[mutable.key] = F.one_hot(gen_index, num_classes=mutable.length).view(-1).bool()",
            "+                gen_index = torch.randint(high=len(mutable), size=(1, ))",
            "+                result[mutable.key] = F.one_hot(gen_index, num_classes=len(mutable)).view(-1).bool()",
            "elif isinstance(mutable, InputChoice):",
            "if mutable.n_chosen is None:",
            "result[mutable.key] = torch.randint(high=2, size=(mutable.n_candidates,)).view(-1).bool()"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1507,
        "change": [
            "def indices_where(",
            "def shape(",
            "x: Union[tf.Tensor, tf.Variable],",
            "as_array: bool = False,",
            "-) -> Union[tf.Tensor, tf.Variable, TensorShape]:",
            "+) -> Union[tf.Tensor, ivy.Shape, ivy.Array]:",
            "if as_array:",
            "-        return tf.shape(x)",
            "+        return ivy.array(tf.shape(x))",
            "else:",
            "-        return tuple(x.shape)",
            "+        return ivy.Shape(x.shape)",
            "",
            "",
            "def get_num_dims(x, as_tensor=False):"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 1532,
        "change": [
            "def remainder(",
            "res_floored = torch.where(res >= 0, torch.floor(res), torch.ceil(res))",
            "diff = res - res_floored",
            "diff, x2 = ivy.promote_types_of_inputs(diff, x2)",
            "-        return torch.mul(diff, x2, out=out).to(x1.dtype)",
            "+        return torch.round(torch.mul(diff, x2, out=out), out=out).to(x1.dtype)",
            "return torch.remainder(x1, x2, out=out)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 1535,
        "change": [
            "def guide(observed_data):",
            "",
            "# do variational inference using KL_QP",
            "print(\"doing inference with simulated data\")",
            "-verbose = False",
            "+verbose = True",
            "n_steps = 3001",
            "kl_optim = KL_QP(model, guide, pyro.optim(optim.Adam, {\"lr\": 0.003, \"betas\": (0.93, 0.993)}))",
            "for step in range(n_steps):",
            "loss = kl_optim.step(observed_data)",
            "if step % 100 == 0:",
            "if verbose:",
            "-            print(\"[epoch %d] mean_mu: %.3f\" % (step, pyro.param(\"mean_mu\").data[0, 0]))",
            "+            print(\"[epoch %d] mean_mu: %.3f\" % (step, pyro.param(\"mean_mu\").data[0]))",
            "print(\"[epoch %d] sigma_mu: %.3f\" % (step,",
            "-                                                 torch.exp(pyro.param(\"log_sigma_mu\")).data[0, 0]))",
            "+                                                 torch.exp(pyro.param(\"log_sigma_mu\")).data[0]))",
            "else:",
            "print(\".\", end='')",
            "sys.stdout.flush()"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1538,
        "change": [
            "class UNet2DConditionModel(ModelMixin, ConfigMixin):",
            "# TODO: this requires sync between CPU and GPU. So try to pass timesteps as tensors if you can",
            "# This would be a good case for the `match` statement (Python 3.10+)",
            "is_mps = sample.device.type == \"mps\"",
            "-            if torch.is_floating_point(timesteps):",
            "+            if isinstance(timestep, float):",
            "dtype = torch.float32 if is_mps else torch.float64",
            "else:",
            "dtype = torch.int32 if is_mps else torch.int64"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Condition",
        "Action_Element": "Replace API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1543,
        "change": [
            "def test_utilities(head_size):",
            "mask[head_size:, head_size:] = 0.",
            "mask.view(-1)[::size + 1][head_size:] = 1.",
            "arrowhead_full = mask * cov",
            "-    expected = torch.flip(torch.flip(arrowhead_full, (-2, -1)).cholesky(), (-2, -1))",
            "+    expected = torch.flip(",
            "+        torch.linalg.cholesky(torch.flip(arrowhead_full, (-2, -1))), (-2, -1)",
            "+    )",
            "# test if those flip ops give expected upper triangular values",
            "assert_close(expected.triu(), expected)",
            "assert_close(expected.matmul(expected.t()), arrowhead_full)"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 1565,
        "change": [
            "class CharacterEmbeddings(TokenEmbeddings):",
            "longest_token_in_sentence = max(chars2_length)",
            "tokens_mask = torch.zeros((len(tokens_sorted_by_length), longest_token_in_sentence),",
            "dtype=torch.long, device=flair.device)",
            "+",
            "for i, c in enumerate(tokens_sorted_by_length):",
            "-                tokens_mask[i, :chars2_length[i]] = c",
            "+                tokens_mask[i, :chars2_length[i]] = torch.tensor(c, dtype=torch.long, device=flair.device)",
            "",
            "# chars for rnn processing",
            "chars = tokens_mask"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 1576,
        "change": [
            "def init_seeds(seed=0, deterministic=False):",
            "torch.manual_seed(seed)",
            "torch.cuda.manual_seed(seed)",
            "torch.cuda.manual_seed_all(seed)  # for Multi-GPU, exception safe",
            "-    torch.backends.cudnn.benchmark = True  # for faster training",
            "+    # torch.backends.cudnn.benchmark = True  # AutoBatch problem https://github.com/ultralytics/yolov5/issues/9287",
            "if deterministic and check_version(torch.__version__, '1.12.0'):  # https://github.com/ultralytics/yolov5/pull/8213",
            "torch.use_deterministic_algorithms(True)",
            "torch.backends.cudnn.deterministic = True"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1579,
        "change": [
            "def inv(",
            "*,",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "-    if tf.math.reduce_any(tf.linalg.det(x) == 0):",
            "+    if tf.math.reduce_any(tf.linalg.det(tf.cast(x, dtype=\"float64\")) == 0):",
            "ret = x",
            "else:",
            "ret = tf.linalg.inv(x)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 1582,
        "change": [
            "class Init(InsertPostInitMethodToModuleSubClasses):",
            "",
            "see_memory_usage(f'Before partitioning param {param.ds_id} {param.shape}',",
            "force=False)",
            "-            param.data = torch.ones(1).half().to(param.device)",
            "+            param.data = torch.ones(partitioned_param_data_shape).half().to(param.device)",
            "see_memory_usage(f'After partitioning param {param.ds_id} {param.shape}',",
            "force=False)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 1587,
        "change": [
            "class TorchService(BaseService):",
            "",
            "# FLOAT TENSOR FUNCTIONS",
            "def hook_float_tensor___init__(service_self):",
            "-        def new___init__(self, tensor, owner=service_self, *args, **kwargs):",
            "-            super(torch.FloatTensor, self).__init__(*args, **kwargs)",
            "-            self = owner.register_object(self, False)",
            "+        def new___init__(self, *args):",
            "+            super(torch.FloatTensor, self).__init__()",
            "+            self = service_self.register_object(self, False)",
            "",
            "torch.FloatTensor.__init__ = new___init__"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 1591,
        "change": [
            "def demo_gan(checkpoint_paths):",
            "img_list = []",
            "fixed_noise = torch.randn(64, nz, 1, 1)",
            "for path in checkpoint_paths:",
            "-        netG_path = os.path.join(path, \"checkpoint.pt\")",
            "+        checkpoint_dict = Checkpoint.from_directory(path).to_dict()",
            "loadedG = Generator()",
            "-        loadedG.load_state_dict(torch.load(netG_path)[\"netGmodel\"])",
            "+        loadedG.load_state_dict(checkpoint_dict[\"netGmodel\"])",
            "with torch.no_grad():",
            "fake = loadedG(fixed_noise).detach().cpu()",
            "img_list.append(vutils.make_grid(fake, padding=2, normalize=True))"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1592,
        "change": [
            "class PNAConv(MessagePassing):",
            "return y",
            "",
            "def aggregate(self, inputs, index, dim_size=None):",
            "-        D = get_degree(inputs, index, self.node_dim, dim_size)",
            "+        D = get_degree(inputs, index, 0, dim_size)",
            "",
            "# aggregators",
            "-        inputs = torch.cat([aggregator(inputs, index, dim=self.node_dim, dim_size=dim_size)",
            "+        inputs = torch.cat([aggregator(inputs, index, dim=0, dim_size=dim_size)",
            "for aggregator in self.aggregators], dim=-1)",
            "# scalers",
            "return torch.cat([scaler(inputs, D, self.avg_d) for scaler in self.scalers], dim=-1)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 1596,
        "change": [
            "class FP16_Optimizer(DeepSpeedOptimizer):",
            "will call ``model.load_state_dict()`` before",
            "``fp16_optimizer_instance.load_state_dict()`` is called.",
            "Example::",
            "-            model = torch.nn.Linear(D_in, D_out).cuda().half()",
            "+            model = torch.nn.Linear(D_in, D_out).to(get_accelerator().device_name()).half()",
            "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)",
            "optimizer = FP16_Optimizer(optimizer, static_loss_scale = 128.0)",
            "..."
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 1604,
        "change": [
            "def read_state_dict(checkpoint_file, print_global_state=False, map_location=None",
            "if extension.lower() == \".safetensors\":",
            "device = map_location or shared.weight_load_location",
            "if device is None:",
            "-            device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"",
            "+            device = devices.get_cuda_device_string() if torch.cuda.is_available() else \"cpu\"",
            "pl_sd = safetensors.torch.load_file(checkpoint_file, device=device)",
            "else:",
            "pl_sd = torch.load(checkpoint_file, map_location=map_location or shared.weight_load_location)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1611,
        "change": [
            "def RemoteTrainer(estimator, metadata, keras_utils, run_id, dataset_idx):",
            "if LooseVersion(tf.__version__) < LooseVersion(\"2.0.0\"):",
            "model.load_weights(ckpt_file)",
            "else:",
            "-                        model = k.models.load_model(ckpt_file)",
            "+                        # needs to be deserialized in the with scope",
            "+                        with k.utils.custom_object_scope(custom_objects):",
            "+                            model = k.models.load_model(ckpt_file)",
            "serialized_model = keras_utils.serialize_model(model)",
            "else:",
            "with open(ckpt_file, 'rb') as f:"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1629,
        "change": [
            "class MultiHeadSelfAttention(nn.Module):",
            "q = q / math.sqrt(dim_per_head)  # (bs, n_heads, q_length, dim_per_head)",
            "scores = torch.matmul(q, k.transpose(2, 3))  # (bs, n_heads, q_length, k_length)",
            "mask = (mask == 0).view(mask_reshp).expand_as(scores)  # (bs, n_heads, q_length, k_length)",
            "-        scores = scores.masked_fill(mask, -float(\"inf\"))  # (bs, n_heads, q_length, k_length)",
            "+        scores = scores.masked_fill(mask, torch.tensor(-float(\"inf\")))  # (bs, n_heads, q_length, k_length)",
            "",
            "weights = nn.functional.softmax(scores, dim=-1)  # (bs, n_heads, q_length, k_length)",
            "weights = self.dropout(weights)  # (bs, n_heads, q_length, k_length)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 1649,
        "change": [
            "def get_extensions():",
            "extra_compile_args = {\"cxx\": []}",
            "define_macros = []",
            "",
            "-    if torch.cuda.is_available() and CUDA_HOME is not None:",
            "+    if (torch.cuda.is_available() and CUDA_HOME is not None) or os.getenv(\"FORCE_CUDA\", \"0\") == \"1\":",
            "extension = CUDAExtension",
            "sources += source_cuda",
            "define_macros += [(\"WITH_CUDA\", None)]"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 1659,
        "change": [
            "class AlbertMLMHead(nn.Module):",
            "def __init__(self, config):",
            "super().__init__()",
            "",
            "-        self.LayerNorm = nn.LayerNorm(config.embedding_size)",
            "+        self.LayerNorm = nn.LayerNorm(config.embedding_size, eps=config.layer_norm_eps)",
            "self.bias = nn.Parameter(torch.zeros(config.vocab_size))",
            "self.dense = nn.Linear(config.hidden_size, config.embedding_size)",
            "self.decoder = nn.Linear(config.embedding_size, config.vocab_size)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Algorithm Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Algorithm Error"
    },
    {
        "number": 1668,
        "change": [
            "def run(",
            "seen, windows, dt = 0, [], (Profile(), Profile(), Profile())",
            "for path, im, im0s, vid_cap, s in dataset:",
            "with dt[0]:",
            "-            im = im.to(device)",
            "+            im = torch.Tensor(im).to(device)",
            "im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32",
            "if len(im.shape) == 3:",
            "im = im[None]  # expand for batch dim"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 1680,
        "change": [
            "class ParameterNoise(Exploration):",
            "else:",
            "for i in range(len(self.noise)):",
            "self.noise[i] = torch.normal(",
            "-                    0.0, self.stddev, size=self.noise[i].size())",
            "+                    mean=torch.zeros(self.noise[i].size()), std=self.stddev)",
            "",
            "def _tf_sample_new_noise_op(self):",
            "added_noises = []"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 1685,
        "change": [
            "class DartsLayerChoice(nn.Module):",
            "yield name, p",
            "",
            "def export(self):",
            "-        return torch.argmax(self.alpha).item()",
            "+        return list(self.op_choices.keys())[torch.argmax(self.alpha).item()]",
            "",
            "",
            "class DartsInputChoice(nn.Module):",
            "def __init__(self, input_choice):",
            "super(DartsInputChoice, self).__init__()",
            "-        self.name = input_choice.key",
            "+        self.name = input_choice.label",
            "self.alpha = nn.Parameter(torch.randn(input_choice.n_candidates) * 1e-3)",
            "self.n_chosen = input_choice.n_chosen or 1"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 1697,
        "change": [
            "class Init(InsertPostInitMethodToModuleSubClasses):",
            "param.all_gather()",
            "return param._orig_item()",
            "",
            "-        def ds_summary(slf: torch.Tensor) -> dict:",
            "+        def ds_summary(slf: torch.Tensor, use_debug_name: bool = False) -> dict:",
            "return {",
            "-                \"id\": slf.ds_id,",
            "+                \"id\": debug_param2name_id(slf) if use_debug_name else slf.ds_id,",
            "\"status\": slf.ds_status.name,",
            "\"numel\": slf.numel(),",
            "\"ds_numel\": slf.ds_numel,"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Argument Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Argument Error"
    },
    {
        "number": 1707,
        "change": [
            "class ScoreSdeVeScheduler(SchedulerMixin, ConfigMixin):",
            "",
            "# For small batch sizes, the paper \"suggest replacing norm(z) with sqrt(d), where d is the dim. of z\"",
            "# sample noise for correction",
            "-        noise = torch.randn(sample.shape, layout=sample.layout, generator=generator).to(sample.device)",
            "+        noise = randn_tensor(sample.shape, layout=sample.layout, generator=generator).to(sample.device)",
            "",
            "# compute step size from the model_output, the noise, and the snr",
            "grad_norm = torch.norm(model_output.reshape(model_output.shape[0], -1), dim=-1).mean()"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 1719,
        "change": [
            "def extract_fbank_features(",
            "if output_path is not None and output_path.is_file() and not overwrite:",
            "return",
            "",
            "-    _waveform = waveform * (2 ** 15)  # Kaldi compliance: 16-bit signed integers",
            "-    _waveform = _waveform.squeeze().numpy()",
            "+    _waveform = _convert_to_mono(waveform, sample_rate)",
            "+    _waveform = _waveform * (2 ** 15)  # Kaldi compliance: 16-bit signed integers",
            "+    _waveform = _waveform.numpy()",
            "",
            "features = _get_kaldi_fbank(_waveform, sample_rate, n_mel_bins)",
            "if features is None:"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 1739,
        "change": [
            "class DistributionStrategyCheckpointTest(test_utils.TestCase,",
            "",
            "def assertRestoreOnCreateInReplicaContext(self, golden, strategy,",
            "use_function):",
            "+    if self.primary_device == \"GPU\":",
            "+      self.skipTest(\"Currently not working as expected on multiple devices\")",
            "+      # TODO(b/134376796) renable this once bug is fixed",
            "with strategy.scope():",
            "module = golden.create_module()"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 1742,
        "change": [
            "def run_modelmerger(primary_model_name, secondary_model_name, teritary_model_nam",
            "if theta_func1:",
            "for key in tqdm.tqdm(theta_1.keys()):",
            "if 'model' in key:",
            "-                t2 = theta_2.get(key, torch.zeros_like(theta_1[key]))",
            "-                theta_1[key] = theta_func1(theta_1[key], t2)",
            "+                if key in theta_2:",
            "+                    t2 = theta_2.get(key, torch.zeros_like(theta_1[key]))",
            "+                    theta_1[key] = theta_func1(theta_1[key], t2)",
            "+                else:",
            "+                    theta_1[key] = 0",
            "del theta_2, teritary_model",
            "",
            "for key in tqdm.tqdm(theta_0.keys()):"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Null Reference Error",
        "Action": "Replace",
        "Element": "API Condition",
        "Action_Element": "Replace API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Null Reference Error"
    },
    {
        "number": 1744,
        "change": [
            "def get_lst_from_rank0(lst: List[int]) -> None:",
            "lst_tensor = torch.tensor(",
            "lst if dist.get_rank() == 0 else [-1] * len(lst),",
            "dtype=int,",
            "-        # device=torch.cuda.current_device(),",
            "-        device=torch.device('cuda:{}'.format(os.environ[\"LOCAL_RANK\"])),",
            "+        # device=get_accelerator().current_device_name(),",
            "+        device=torch.device(get_accelerator().device_name(os.environ[\"LOCAL_RANK\"])),",
            "requires_grad=False,",
            ")",
            "dist.broadcast(lst_tensor, src=0, async_op=False)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1747,
        "change": [
            "def wrong_module(modelstore, sklearn_onnx_model):",
            ")",
            "def test_onnx_save_load(metadata, save_proc, modelstore, sklearn_onnx_model):",
            "model, data = sklearn_onnx_model",
            "-    info = save_proc(metadata)",
            "-    assert info.metadata is not None",
            "-    assert_have_file_extension(info.path, \".onnx\")",
            "+    model = save_proc(metadata)",
            "+    assert model.info.metadata is not None",
            "+    assert_have_file_extension(model.path, \".onnx\")",
            "",
            "opts = ort.SessionOptions()",
            "opts.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL",
            "opts.log_verbosity_level = 1",
            "-    loaded = bentoml.onnx.load(info.tag, model_store=modelstore, session_options=opts)",
            "+    loaded = bentoml.onnx.load(model.tag, model_store=modelstore, session_options=opts)",
            "assert predict_arr(loaded, data)[0] == 0"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 1754,
        "change": [
            "def _precision_to_scale_tril(P):",
            "# Ref: https://nbviewer.jupyter.org/gist/fehiepsi/5ef8e09e61604f10607380467eb82006#Precision-to-scale_tril",
            "Lf = torch.linalg.cholesky(torch.flip(P, (-2, -1)))",
            "L_inv = torch.transpose(torch.flip(Lf, (-2, -1)), -2, -1)",
            "-    L = torch.triangular_solve(",
            "-        torch.eye(P.shape[-1], dtype=P.dtype, device=P.device), L_inv, upper=False",
            "-    )[0]",
            "+    L = torch.linalg.solve_triangular(",
            "+        L_inv, torch.eye(P.shape[-1], dtype=P.dtype, device=P.device), upper=False",
            "+    )",
            "return L",
            "",
            "",
            "+@ignore_torch_deprecation_warnings()",
            "def _try_possibly_intractable(fn, *args, **kwargs):",
            "# Convert ValueError into NotImplementedError.",
            "try:"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 1766,
        "change": [
            "class RandomThinPlateSpline(GeometricAugmentationBase2D):",
            "",
            "def generate_parameters(self, shape: torch.Size) -> Dict[str, Tensor]:",
            "B, _, _, _ = shape",
            "-        src = torch.tensor([[[-1.0, -1.0], [-1.0, 1.0], [1.0, -1.0], [1.0, 1.0], [0.0, 0.0]]]).repeat(B, 1, 1)  # Bx5x2",
            "+        src = torch.tensor([[[-1.0, -1.0], [-1.0, 1.0], [1.0, -1.0], [1.0, 1.0], [0.0, 0.0]]]).expand(B, 5, 2)  # Bx5x2",
            "dst = src + self.dist.rsample(src.shape)",
            "return dict(src=src, dst=dst)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1779,
        "change": [
            "class DepthWarper(nn.Module):",
            "factor_y = (self.height - 1) / 2",
            "factor_y = factor_y.to(device)",
            "",
            "-        z = 1. / flow[:, 2]  # Nx(H*W)",
            "+        z = 1. / (flow[:, 2] + self.eps)  # Nx(H*W)",
            "x = (flow[:, 0] * z - factor_x) / factor_x",
            "y = (flow[:, 1] * z - factor_y) / factor_y"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 1781,
        "change": [
            "def result_wrapper(result_fn):",
            "# Wrapping result in identity so that control dependency between",
            "# update_op from `update_state` and result works in case result",
            "# returns a tensor.",
            "-                return tf.identity(result)",
            "+                return tf.nest.map_structure(tf.identity, result)",
            "",
            "# Wrapping result in merge_call. merge_call is used when we want to",
            "# leave replica mode and compute a value in cross replica mode."
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 1787,
        "change": [
            "class AdalamFilter:",
            ")",
            "k1, k2, d1, d2, o1, o2, s1, s2 = self.__to_torch(k1, k2, d1, d2, o1, o2, s1, s2)",
            "if len(d2) <= 1:",
            "-            return _no_match(d1)",
            "+            idxs, dists = _no_match(d1)",
            "+            if return_dist:",
            "+                return idxs, dists",
            "+            return idxs",
            "distmat = dist_matrix(d1, d2, is_normalized=False)",
            "dd12, nn12 = torch.topk(distmat, k=2, dim=1, largest=False)  # (n1, 2)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Null Reference Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Null Reference Error"
    },
    {
        "number": 1795,
        "change": [
            "def assert_cov_validity(cov, eigenvalue_lbnd=0., condition_number_ubnd=1e6):",
            "# Symmetry",
            "assert (cov.t() == cov).all(), 'Covariance must be symmetric!'",
            "# Precompute eigenvalues for subsequent tests.",
            "-    ws, _ = torch.symeig(cov)  # The eigenvalues of cov",
            "+    ws = torch.linalg.eigvalsh(cov)  # The eigenvalues of cov",
            "w_min = torch.min(ws)",
            "w_max = torch.max(ws)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 1804,
        "change": [
            "class TestNnUtil(AllenNlpTestCase):",
            "\"b\": FakeTensor(),",
            "\"c\": (1, FakeTensor()),",
            "}",
            "-        new_device = 4",
            "+        new_device = torch.device(4)",
            "moved_obj = util.move_to_device(structured_obj, new_device)",
            "assert moved_obj[\"a\"][0].a == 1",
            "assert moved_obj[\"a\"][0].b._device == new_device"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 1825,
        "change": [
            "def test_gaussian_tensordot(dot_dims,",
            "nb = dot_dims",
            "nc = y_dim - dot_dims",
            "try:",
            "-        torch.cholesky(x.precision[..., na:, na:] + y.precision[..., :nb, :nb])",
            "+        torch.linalg.cholesky(x.precision[..., na:, na:] + y.precision[..., :nb, :nb])",
            "except RuntimeError:",
            "pytest.skip(\"Cannot marginalize the common variables of two Gaussians.\")"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 1859,
        "change": [
            "class MultiHeadSelfAttention(Seq2SeqEncoder):",
            "keys_per_head = keys_per_head.view(batch_size * num_heads, timesteps, int(self._attention_dim/num_heads))",
            "",
            "# shape (num_heads * batch_size, timesteps, timesteps)",
            "-        scaled_similarities = torch.bmm(queries_per_head, keys_per_head.transpose(1, 2)) / self._scale",
            "+        scaled_similarities = torch.bmm(queries_per_head / self._scale, keys_per_head.transpose(1, 2))",
            "",
            "# shape (num_heads * batch_size, timesteps, timesteps)",
            "# Normalise the distributions, using the same mask for all heads.",
            "-        attention = masked_softmax(scaled_similarities, mask.repeat(1, num_heads).view(batch_size * num_heads, timesteps))",
            "+        attention = masked_softmax(scaled_similarities,",
            "+                                   mask.repeat(1, num_heads).view(batch_size * num_heads, timesteps),",
            "+                                   memory_efficient=True)",
            "attention = self._attention_dropout(attention)",
            "",
            "# Take a weighted sum of the values with respect to the attention"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1873,
        "change": [
            "class TestScalarMix(AllenNlpTestCase):",
            "for k in range(3):",
            "mean = numpy.mean(tensors[k].data.numpy()[numpy_mask == 1])",
            "std = numpy.std(tensors[k].data.numpy()[numpy_mask == 1])",
            "-            normed_tensor = (tensors[k].data.numpy() - mean) / (std + 1e-12)",
            "+            normed_tensor = (tensors[k].data.numpy() - mean) / (",
            "+                std + util.tiny_value_of_dtype(torch.float)",
            "+            )",
            "expected_result += normed_tensor * normed_weights[k]",
            "expected_result *= 0.5"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 1880,
        "change": [
            "class Finfo:",
            "return float(self._tf_finfo.tiny)",
            "",
            "",
            "-def finfo(datatype_in):",
            "-    return Finfo(tf.experimental.numpy.finfo(datatype_in))",
            "+def finfo(type):",
            "+    return Finfo(tf.experimental.numpy.finfo(dtype_from_str(type)))",
            "",
            "",
            "backend = 'tensorflow'"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 1895,
        "change": [
            "class Finfo:",
            "return self._torch_finfo.tiny",
            "",
            "",
            "-def finfo(datatype_in):",
            "-    return Finfo(_torch.finfo(datatype_in))",
            "+def finfo(type):",
            "+    return Finfo(_torch.finfo(dtype_from_str(type)))",
            "",
            "",
            "backend = 'torch'"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 1915,
        "change": [
            "class PipelineModule(nn.Module):",
            "self.tied_weight_attrs = {}",
            "",
            "# Offset the random seed by the stage ID.",
            "-        #newseed = torch.cuda.initial_seed() + self._grid.get_stage_id()",
            "+        #newseed = get_accelerator().initial_seed() + self._grid.get_stage_id()",
            "#ds_utils.set_random_seed(newseed)",
            "",
            "-        #with torch.random.fork_rng(devices=[torch.cuda.current_device()]):",
            "+        #with torch.random.fork_rng(devices=[get_accelerator().current_device_name()]):",
            "self._build()",
            "-        self.to(f'cuda:{self.local_rank}')",
            "+        self.to(get_accelerator().device_name(self.local_rank))",
            "",
            "self.tied_comms = self._index_tied_modules()",
            "self._synchronize_tied_weights()"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 1932,
        "change": [
            "class HFGPTJLayerPolicy(DSPolicy):",
            "kw = self.client_module.attn.k_proj.weight",
            "vw = self.client_module.attn.v_proj.weight",
            "",
            "-        qkvw = torch.cat((qw, kw, vw), dim=0)",
            "+        qkvw = Parameter(torch.cat((qw, kw, vw), dim=0))",
            "",
            "return self.linear_layer, \\",
            "qkvw, \\"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 1967,
        "change": [
            "class Graph:",
            "if pre_node[temp_id] == temp_id:",
            "break",
            "temp_id = pre_node[temp_id]",
            "-        assert temp_id == pre_node[temp_id]",
            "+        if temp_id != pre_node[temp_id]:",
            "+            raise AssertionError(\"Error: main chain end condition not met.\")",
            "ret.reverse()",
            "return ret"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Condition",
        "Action_Element": "Replace API Condition",
        "Symptom_Root_Cause": "Program Crash|Algorithm Error"
    },
    {
        "number": 1988,
        "change": [
            "class TransformerEncoderLayerBase(nn.Module):",
            "# the attention weight (before softmax) for some padded element in query",
            "# will become -inf, which results in NaN in model parameters",
            "if attn_mask is not None:",
            "-            attn_mask = attn_mask.masked_fill(attn_mask.to(torch.bool), -1e8)",
            "+            attn_mask = attn_mask.masked_fill(",
            "+                attn_mask.to(torch.bool),",
            "+                -1e8 if x.dtype == torch.float32 else -1e4",
            "+            )",
            "",
            "residual = x",
            "if self.normalize_before:"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 1989,
        "change": [
            "class QModel(Model):",
            "",
            "# If loss clipping is used, calculate the huber loss",
            "if config.clip_loss > 0.0:",
            "-                huber_loss = tf.where(condition=(tf.abs(delta) < config.clip_loss), x=(0.5 * self.loss_per_instance), y=(tf.abs(delta) - 0.5))",
            "+                huber_loss = tf.where(condition=(tf.abs(delta) < config.clip_loss), x=(0.5 * self.loss_per_instance),",
            "+                                      y=config.clip_loss * tf.abs(delta) - 0.5 * config.clip_loss ** 2)",
            "self.q_loss = tf.reduce_mean(input_tensor=huber_loss, axis=0)",
            "else:",
            "self.q_loss = tf.reduce_mean(input_tensor=self.loss_per_instance, axis=0)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 2003,
        "change": [
            "class DecoderTrainer(nn.Module):",
            "index = unet_number - 1",
            "unet = self.decoder.unets[index]",
            "",
            "-        if exists(self.max_grad_norm):",
            "-            nn.utils.clip_grad_norm_(unet.parameters(), self.max_grad_norm)",
            "-",
            "optimizer = getattr(self, f'optim{index}')",
            "scaler = getattr(self, f'scaler{index}')",
            "",
            "+        if exists(self.max_grad_norm):",
            "+            scaler.unscale_(optimizer)",
            "+            nn.utils.clip_grad_norm_(unet.parameters(), self.max_grad_norm)",
            "+",
            "scaler.step(optimizer)",
            "scaler.update()",
            "optimizer.zero_grad()"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 2005,
        "change": [
            "def get_tiny_config_from_class(configuration_class):",
            "",
            "try:",
            "model_slug = model_type.replace(\"-\", \"_\")",
            "-        module = importlib.import_module(f\".test_modeling_{model_slug}\", package=f\"tests.{model_slug}\")",
            "+        module = importlib.import_module(f\".test_modeling_{model_slug}\", package=f\"tests.models.{model_slug}\")",
            "model_tester_class = getattr(module, f\"{camel_case_model_name}ModelTester\", None)",
            "except (ImportError, AttributeError):",
            "logger.error(f\"No model tester class for {configuration_class.__name__}\")"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 2009,
        "change": [
            "from ray.rllib.utils import try_import_torch",
            "_, nn = try_import_torch()",
            "",
            "",
            "-class VisionNetwork(TorchModelV2):",
            "+class VisionNetwork(TorchModelV2, nn.Module):",
            "\"\"\"Generic vision network.\"\"\"",
            "",
            "def __init__(self, obs_space, action_space, num_outputs, model_config,",
            "name):",
            "TorchModelV2.__init__(self, obs_space, action_space, num_outputs,",
            "model_config, name)",
            "+        nn.Module.__init__(self)",
            "",
            "activation = get_activation_fn(",
            "model_config.get(\"conv_activation\"), framework=\"torch\")"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 2024,
        "change": [
            "class BiLSTM_CRF(nn.Module):",
            "def _get_lstm_features(self, sentence):",
            "self.hidden = self.init_hidden()",
            "embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)",
            "-        lstm_out, self.hidden = self.lstm(embeds)",
            "+        lstm_out, self.hidden = self.lstm(embeds, self.hidden)",
            "lstm_out = lstm_out.view(len(sentence), self.hidden_dim)",
            "lstm_feats = self.hidden2tag(lstm_out)",
            "return lstm_feats"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 2033,
        "change": [
            "def configure_logger(verbose: bool) -> None:",
            "verbose (bool):",
            "`True` to use verbose logger, `False` otherwise.",
            "\"\"\"",
            "-    tf_logger = tf_logging.get_logger()",
            "+    tf_logger = tf.get_logger()",
            "tf_logger.handlers = [handler]",
            "if verbose:",
            "-        environ['TF_CPP_MIN_LOG_LEVEL'] = '1'",
            "tf_logging.set_verbosity(tf_logging.INFO)",
            "logger.setLevel(logging.DEBUG)",
            "else:",
            "warnings.filterwarnings('ignore')",
            "-        environ['TF_CPP_MIN_LOG_LEVEL'] = '3'",
            "tf_logging.set_verbosity(tf_logging.ERROR)"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 2036,
        "change": [
            "def test(epoch):",
            "output = model(batch_data)",
            "test_loss += criterion(output, batch_targets)",
            "pred = output.data.max(1)[1]",
            "-        correct += pred.long().eq(batch_targets.data.long()).sum()",
            "+        correct += pred.long().eq(batch_targets.data.long()).cpu().sum()",
            "",
            "test_loss = test_loss.data[0]",
            "test_loss /= (test_data.size(0) / TEST_BATCH_SIZE) # criterion averages over batch size"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Device Management Error"
    },
    {
        "number": 2049,
        "change": [
            "class InstanceNormalization(Layer):",
            "",
            "reciprocal_stddev = tf.math.rsqrt(x=tf.maximum(x=variance, y=epsilon))",
            "",
            "-        x = (x - mean) * reciprocal_stddev",
            "+        x = (x - tf.stop_gradient(input=mean)) * tf.stop_gradient(input=reciprocal_stddev)",
            "",
            "return x"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Algorithm Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Low Efficiency|Algorithm Error"
    },
    {
        "number": 2125,
        "change": [
            "class ClusterLoader(torch.utils.data.DataLoader):",
            "node_idx = torch.cat([torch.arange(s, e) for s, e in zip(start, end)])",
            "",
            "data = copy.copy(self.cluster_data.data)",
            "-        del data.num_nodes",
            "+        if hasattr(data, '__num_nodes__'):",
            "+            del data.__num_nodes__",
            "adj, data.adj = self.cluster_data.data.adj, None",
            "adj = cat([adj.narrow(0, s, e - s) for s, e in zip(start, end)], dim=0)",
            "adj = adj.index_select(1, node_idx)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Null Reference Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Null Reference Error"
    },
    {
        "number": 2133,
        "change": [
            "class Decoder(torch.nn.Module):",
            "else:",
            "local_scores = functional.log_softmax(self.output(z_list[-1]), dim=1).data",
            "if lpz is not None:",
            "-                    local_att_best_scores, local_att_best_ids = torch.topk(local_scores, int(beam*1.5), dim=1)",
            "+                    local_att_best_scores, local_att_best_ids = torch.topk(local_scores, int(beam * CTC_SCORING_RATIO), dim=1)",
            "ctc_scores, ctc_states = ctc_prefix_score(hyp['yseq'], local_att_best_ids[0], hyp['ctc_prev'])",
            "-                    joint_scores = (1. - ctc_weight) * (local_att_best_scores[0].numpy() + hyp['score']) + ctc_weight * ctc_scores",
            "-                    joint_best_ids = np.argsort(joint_scores)[:-beam-1:-1]",
            "+                    joint_scores = (1. - ctc_weight) * \\",
            "+                        (local_att_best_scores[0].numpy() + hyp['score']) + ctc_weight * ctc_scores",
            "+                    joint_best_ids = np.argsort(joint_scores)[:-beam - 1:-1]",
            "local_best_ids = local_att_best_ids.numpy()[:, joint_best_ids]",
            "local_best_scores = local_att_best_scores.numpy()[:, joint_best_ids]",
            "else:"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 2134,
        "change": [
            "class Random(Exploration):",
            "if explore:",
            "# Unsqueeze will be unnecessary, once we support batch/time-aware",
            "# Spaces.",
            "-            action = torch.IntTensor(self.action_space.sample()).unsqueeze(0)",
            "+            action = torch.LongTensor(self.action_space.sample()).unsqueeze(0)",
            "else:",
            "-            action = torch.IntTensor(action_dist.deterministic_sample())",
            "+            action = torch.LongTensor(action_dist.deterministic_sample())",
            "logp = torch.zeros((action.size()[0], ), dtype=torch.float32)",
            "return action, logp"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 2142,
        "change": [
            "class Trainer:",
            "for name, param in self._model.named_parameters():",
            "param_updates[name].sub_(param.detach().cpu())",
            "update_norm = torch.norm(param_updates[name].view(-1, ))",
            "-                    param_norm = torch.norm(param.view(-1, ))",
            "+                    param_norm = torch.norm(param.view(-1, )).cpu()",
            "self._tensorboard.add_train_scalar(\"gradient_update/\" + name,",
            "update_norm / (param_norm + 1e-7),",
            "batch_num_total)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 2163,
        "change": [
            "def main():",
            "",
            "model = BertForSequenceClassification(bert_config, len(label_list))",
            "if args.init_checkpoint is not None:",
            "-        model.load_state_dict(torch.load(args.init_checkpoint, map_location='cpu'))",
            "+        model.bert.load_state_dict(torch.load(args.init_checkpoint, map_location='cpu'))",
            "model.to(device)",
            "",
            "if args.local_rank != -1:"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 2166,
        "change": [
            "class AdditiveSharingTensor(AbstractTensor):",
            "mask_pos = x > self.max_value",
            "mask_neg = x < self.min_value",
            "if mask_pos.any():",
            "-                mask_pos = mask_pos.long()",
            "+                mask_pos = mask_pos.type(self.torch_dtype)",
            "return self.modulo(x - (mask_pos * self.field))",
            "elif mask_neg.any():",
            "-                mask_neg = mask_neg.long()",
            "+                mask_neg = mask_neg.type(self.torch_dtype)",
            "return self.modulo(x + (mask_neg * self.field))",
            "else:",
            "return x.type(self.torch_dtype)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 2179,
        "change": [
            "def test_lite_module_forward_conversion(precision, input_type, expected_type):",
            "assert precision != 16 or torch.is_autocast_enabled()",
            "return forward_input",
            "",
            "-    module = Mock(wraps=torch.nn.Linear(1, 1), side_effect=check_autocast)",
            "+    module = Mock(wraps=torch.nn.Identity(), side_effect=check_autocast)",
            "lite_module = _LiteModule(module, lite._precision_plugin).to(device)",
            "-    out = lite_module(torch.rand(1, dtype=input_type, device=device))",
            "+    out = lite_module(torch.tensor([1, 2, 3], dtype=input_type, device=device))",
            "assert module.call_args[0][0].dtype == expected_type",
            "-    assert out.dtype == torch.get_default_dtype()",
            "+    assert out.dtype == input_type or out.dtype == torch.get_default_dtype()",
            "",
            "",
            "def test_lite_dataloader_iterator():"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 2233,
        "change": [
            "class TileLayer(Layer):",
            "",
            "@deprecated_alias(layer='prev_layer', end_support_version=1.9)  # TODO remove this line for the 1.9 release",
            "def __init__(self, prev_layer, multiples=None, name='tile'):",
            "+",
            "super(TileLayer, self).__init__(prev_layer=prev_layer, name=name)",
            "",
            "logging.info(\"TileLayer  %s: multiples:%s\" % (name, multiples))",
            "",
            "-        self.inputs = prev_layer.outputs",
            "-",
            "with tf.variable_scope(name):",
            "self.outputs = tf.tile(self.inputs, multiples=multiples)",
            "",
            "-        self.all_layers.append(self.outputs)",
            "+        self._add_layers(self.outputs)"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 2234,
        "change": [
            "class Trainer(",
            "if 'scheduler' not in scheduler:",
            "raise ValueError(f'Lr scheduler should have key `scheduler`',",
            "' with item being a lr scheduler')",
            "-                scheduler['reduce_on_plateau'] = \\",
            "-                    isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau)",
            "+                scheduler['reduce_on_plateau'] = isinstance(",
            "+                    scheduler['scheduler'], optim.lr_scheduler.ReduceLROnPlateau)",
            "",
            "lr_schedulers.append({**default_config, **scheduler})"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Null Reference Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Null Reference Error"
    },
    {
        "number": 2264,
        "change": [
            "class GenerationMixin:",
            "",
            "# First if `inputs_embeds` are given, but no `attention_mask` assume that full attention_mask is used",
            "if inputs_embeds is not None:",
            "-            return torch.ones((inputs_embeds.shape[0], inputs_embeds.shape[1]), dtype=torch.long)",
            "+            return torch.ones((inputs_embeds.shape[0], inputs_embeds.shape[1]), dtype=torch.long, device=self.device)",
            "",
            "# Otherwise, use `input_ids`",
            "is_pad_token_in_inputs_ids = (pad_token_id is not None) and (pad_token_id in input_ids)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 2277,
        "change": [
            "class MishActivation(nn.Module):",
            "",
            "def __init__(self):",
            "super().__init__()",
            "-        if version.parse(torch.__version__) < version.parse(\"1.9\"):",
            "+        if version.parse(version.parse(torch.__version__).base_version) < version.parse(\"1.9\"):",
            "self.act = self._mish_python",
            "else:",
            "self.act = nn.functional.mish"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Condition",
        "Action_Element": "Replace API Condition",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 2278,
        "change": [
            "def Aggregate(dim, dim_out):",
            "return nn.Sequential(",
            "nn.Conv2d(dim, dim_out, 3, padding = 1),",
            "ChanNorm(dim_out),",
            "-        nn.MaxPool2d(2)",
            "+        nn.MaxPool2d(3, stride = 2, padding = 1)",
            ")",
            "",
            "class Transformer(nn.Module):"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 2286,
        "change": [
            "def predict():",
            "if __name__ == \"__main__\":",
            "parser = argparse.ArgumentParser(description=\"Flask API exposing YOLOv5 model\")",
            "parser.add_argument(\"--port\", default=5000, type=int, help=\"port number\")",
            "-    args = parser.parse_args()",
            "+    opt = parser.parse_args()",
            "+",
            "+    # Fix known issue urllib.error.HTTPError 403: rate limit exceeded https://github.com/ultralytics/yolov5/pull/7210",
            "+    torch.hub._validate_not_a_forked_repo = lambda a, b, c: True",
            "",
            "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\", force_reload=True)  # force_reload to recache",
            "-    app.run(host=\"0.0.0.0\", port=args.port)  # debug=True causes Restarting with stat",
            "+    app.run(host=\"0.0.0.0\", port=opt.port)  # debug=True causes Restarting with stat"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 2289,
        "change": [
            "def synthesis(model,",
            "style_mel = compute_style_mel(style_wav, ap, use_cuda)",
            "# preprocess the given text",
            "inputs = text_to_seqvec(text, CONFIG, use_cuda)",
            "-    speaker_id = speaker_id_var = torch.from_numpy(speaker_id).unsqueeze(0)",
            "+    speaker_id = np.asarray(speaker_id)",
            "+    speaker_id = torch.from_numpy(speaker_id).unsqueeze(0)",
            "if use_cuda:",
            "speaker_id.cuda()",
            "# synthesize voice",
            "decoder_output, postnet_output, alignments, stop_tokens = run_model(",
            "-        model, inputs, CONFIG, truncated, style_mel)",
            "+        model, inputs, speaker_id, CONFIG, truncated, style_mel)",
            "# convert outputs to numpy",
            "postnet_output, decoder_output, alignment = parse_outputs(",
            "postnet_output, decoder_output, alignments)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 2305,
        "change": [
            "class AttentionTest(tf.test.TestCase, parameterized.TestCase):",
            "attention_layer.concat_score_weight = 1",
            "attention_layer.build(input_shape=([1, 1, 1], [1, 1, 1]))",
            "attention_layer.scale = 2.",
            "-    actual = attention_layer._calculate_scores(query=q, key=k)",
            "+    actual = keras.backend.get_value(",
            "+            attention_layer._calculate_scores(query=q, key=k))",
            "",
            "# Expected tensor of shape [1, 1, 1].",
            "# expected000 = tanh(2*(1.1+1.6)) = 0.9999592018254402"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 2309,
        "change": [
            "class TensorFlowEstimator(BaseEstimator):",
            "if not os.path.exists(saver_filename):",
            "raise ValueError(\"Restore folder doesn't contain saver defintion.\")",
            "with open(saver_filename) as fsaver:",
            "-                saver_def = tf.python.training.saver_pb2.SaverDef()",
            "+                saver_def = tf.python.training.saver.saver_pb2.SaverDef()",
            "text_format.Merge(fsaver.read(), saver_def)",
            "self._saver = tf.train.Saver(saver_def=saver_def)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 2312,
        "change": [
            "class TFPolicy(Policy):",
            "",
            "# TODO(rliaw): Can consider exposing these parameters",
            "self.sess = tf.Session(graph=self.g, config=tf.ConfigProto(",
            "-            intra_op_parallelism_threads=1, inter_op_parallelism_threads=2))",
            "+            intra_op_parallelism_threads=1, inter_op_parallelism_threads=2,",
            "+            gpu_options=tf.GPUOptions(allow_growth=True)))",
            "self.variables = ray.experimental.TensorFlowVariables(self.loss,",
            "self.sess)",
            "self.sess.run(tf.global_variables_initializer())"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 2341,
        "change": [
            "def subtract(x1: torch.Tensor,",
            "promoted_type = torch.promote_types(x1.dtype, x2.dtype)",
            "x1 = x1.to(promoted_type)",
            "x2 = x2.to(promoted_type)",
            "-    return torch.subtract(x1, x2, out=out)",
            "+        return torch.subtract(x1, x2, out=out)",
            "+    return torch.subtract(x1, x2)",
            "",
            "",
            "def remainder(x1: torch.Tensor,"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 2345,
        "change": [
            "class GPTNeoForSequenceClassification(GPTNeoPreTrainedModel):",
            "f\"unexpected if using padding tokens in conjunction with `inputs_embeds.`\"",
            ")",
            "",
            "-        pooled_logits = logits[torch.arange(batch_size), sequence_lengths]",
            "+        pooled_logits = logits[torch.arange(batch_size, device=self.device), sequence_lengths]",
            "",
            "loss = None",
            "if labels is not None:"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 2376,
        "change": [
            "def attempt_load(weights, map_location=None, inplace=True):",
            "# Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a",
            "model = Ensemble()",
            "for w in weights if isinstance(weights, list) else [weights]:",
            "-        attempt_download(w)",
            "-        ckpt = torch.load(w, map_location=map_location)  # load",
            "+        ckpt = torch.load(attempt_download(w), map_location=map_location)  # load",
            "model.append(ckpt['ema' if ckpt.get('ema') else 'model'].float().fuse().eval())  # FP32 model",
            "",
            "# Compatibility updates"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 2386,
        "change": [
            "class Wavegrad(nn.Module):",
            "self.noise_level = self.noise_level.to(y_0)",
            "if len(y_0.shape) == 3:",
            "y_0 = y_0.squeeze(1)",
            "-        s = torch.randint(1, self.num_steps + 1, [y_0.shape[0]])",
            "-        l_a, l_b = self.noise_level[s-1], self.noise_level[s]",
            "+        s = torch.randint(0, self.num_steps - 1, [y_0.shape[0]])",
            "+        l_a, l_b = self.noise_level[s], self.noise_level[s+1]",
            "noise_scale = l_a + torch.rand(y_0.shape[0]).to(y_0) * (l_b - l_a)",
            "noise_scale = noise_scale.unsqueeze(1)",
            "noise = torch.randn_like(y_0)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 2410,
        "change": [
            "from copy import deepcopy",
            "",
            "import numpy as np",
            "import torch",
            "-from torch.cuda import amp",
            "",
            "from utils.general import LOGGER, colorstr",
            "from utils.torch_utils import profile",
            "",
            "",
            "-def check_train_batch_size(model, imgsz=640):",
            "+def check_train_batch_size(model, imgsz=640, amp=True):",
            "# Check YOLOv5 training batch size",
            "-    with amp.autocast():",
            "+    with torch.cuda.amp.autocast(amp):",
            "return autobatch(deepcopy(model).train(), imgsz)  # compute optimal batch size"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 2411,
        "change": [
            "def test_tacotron2_trainable(n_speakers, n_chars, max_input_length, max_mel_leng",
            "post_mel_preds, \\",
            "stop_preds, \\",
            "alignment_history = model(input_ids,",
            "-                                          tf.constant([max_mel_length, max_mel_length]),",
            "+                                          tf.constant([max_input_length, max_input_length]),",
            "speaker_ids,",
            "mel_outputs,",
            "-                                          mel_lengths)",
            "+                                          mel_lengths,",
            "+                                          training=True)",
            "loss_before = tf.keras.losses.MeanSquaredError()(mel_outputs, mel_preds)",
            "loss_after = tf.keras.losses.MeanSquaredError()(mel_outputs, post_mel_preds)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 2412,
        "change": [
            "def apply_grad_clipping(policy, optimizer, loss):",
            "",
            "",
            "def atanh(x):",
            "-    return 0.5 * torch.log((1 + x) / (1 - x))",
            "+    return 0.5 * torch.log(",
            "+        (1 + x).clamp(min=SMALL_NUMBER) / (1 - x).clamp(min=SMALL_NUMBER))",
            "",
            "",
            "def convert_to_non_torch_type(stats):"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 2415,
        "change": [
            "class Trainer(object):",
            "# convert logging_outputs to CPU to avoid unnecessary",
            "# device-to-host transfers in reduce_metrics",
            "logging_outputs = utils.apply_to_sample(",
            "-                lambda t: t.to(device='cpu', non_blocking=True),",
            "+                lambda t: t.to(device='cpu', non_blocking=True, dtype=torch.double),",
            "logging_outputs",
            ")"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 2428,
        "change": [
            "def RegNet(",
            "in_channels = out_channels",
            "",
            "if include_top:",
            "-        x = Head(num_classes=classes)(x)",
            "imagenet_utils.validate_activation(classifier_activation, weights)",
            "+        x = Head(",
            "+            num_classes=classes,",
            "+            classifier_activation=classifier_activation,",
            "+            name=model_name,",
            "+        )(x)",
            "",
            "else:",
            "if pooling == \"avg\":"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Null Reference Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Null Reference Error"
    },
    {
        "number": 2461,
        "change": [
            "class ModelPruning(Callback):",
            "def _wrap_pruning_fn(pruning_fn: Callable, **kwargs: Any) -> Callable:",
            "return partial(pruning_fn, **kwargs)",
            "",
            "-    def make_pruning_permanent(self, pl_module: LightningModule) -> None:",
            "+    def make_pruning_permanent(self, module: nn.Module) -> None:",
            "\"\"\"",
            "Removes pruning buffers from any pruned modules",
            "",
            "Adapted from https://github.com/pytorch/pytorch/blob/1.7.1/torch/nn/utils/prune.py#L1176-L1180",
            "\"\"\"",
            "-        for _, module in pl_module.named_modules():",
            "+        for _, module in module.named_modules():",
            "for k in list(module._forward_pre_hooks):",
            "hook = module._forward_pre_hooks[k]",
            "if isinstance(hook, pytorch_prune.BasePruningMethod):"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 2466,
        "change": [
            "class Standardize(Preprocessor):",
            "else:",
            "axes = tuple(range(1, util.rank(tensor)))",
            "",
            "-        mean, variance = tf.nn.moments(x=tensor, axes=axes)",
            "-        return (tensor - mean) / tf.maximum(x=variance, y=util.epsilon)",
            "+        mean, variance = tf.nn.moments(x=tensor, axes=axes, keep_dims=True)",
            "+        return (tensor - mean) / tf.maximum(x=tf.sqrt(variance), y=util.epsilon)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 2511,
        "change": [
            "def get_perspective_transform(src, dst):",
            "], dim=1)",
            "",
            "# solve the system Ax = b",
            "-    X, LU = torch.solve(b, A)",
            "+    X, LU = _torch_solve_cast(b, A)",
            "",
            "# create variable to return",
            "batch_size = src.shape[0]"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 2523,
        "change": [
            "class Estimator(CircularBuffer):",
            "x=tf.zeros_like(tensor=discounts, dtype=util.tf_dtype(dtype='float')),",
            "y=discounts",
            ")",
            "-            reward = reward + discounts * horizon_estimate",
            "+            reward = reward + discounts * tf.stop_gradient(input=horizon_estimate)",
            "# TODO: stop gradients?",
            "",
            "return reward"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 2542,
        "change": [
            "th = TorchHijackForUnet()",
            "",
            "# Below are monkey patches to enable upcasting a float16 UNet for float32 sampling",
            "def apply_model(orig_func, self, x_noisy, t, cond, **kwargs):",
            "-    for y in cond.keys():",
            "-        cond[y] = [x.to(devices.dtype_unet) if isinstance(x, torch.Tensor) else x for x in cond[y]]",
            "+",
            "+    if isinstance(cond, dict):",
            "+        for y in cond.keys():",
            "+            cond[y] = [x.to(devices.dtype_unet) if isinstance(x, torch.Tensor) else x for x in cond[y]]",
            "+",
            "with devices.autocast():",
            "return orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs).float()"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 2562,
        "change": [
            "class RENet(torch.nn.Module):",
            "_, perm = logits.sort(dim=1, descending=True)",
            "mask = (y.view(-1, 1) == perm)",
            "",
            "-        mrr = (1 / (mask.nonzero()[:, -1] + 1).to(torch.float)).mean().item()",
            "+        nnz = mask.nonzero(as_tuple=False)",
            "+        mrr = (1 / (nnz[:, -1] + 1).to(torch.float)).mean().item()",
            "hits1 = mask[:, :1].sum().item() / y.size(0)",
            "hits3 = mask[:, :3].sum().item() / y.size(0)",
            "hits10 = mask[:, :10].sum().item() / y.size(0)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 2563,
        "change": [
            "class GaussianChainTests(TestCase):",
            "(self.N, reparameterized, n_repa_nodes, self.N))",
            "if self.N < 0:",
            "def array_to_string(y):",
            "-                    return str(map(lambda x: \"%.3f\" % x.data.numpy()[0], y))",
            "+                    return str(map(lambda x: \"%.3f\" % x.data.cpu().numpy()[0], y))",
            "",
            "print(\"lambdas: \" + array_to_string(self.lambdas))",
            "print(\"target_mus: \" + array_to_string(self.target_mus[1:]))"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 2565,
        "change": [
            "class PANConv(MessagePassing):",
            "",
            "tmp = SparseTensor.eye(adj_t.size(0), adj_t.size(1), has_value=True,",
            "dtype=dtype, device=adj_t.device())",
            "-        tmp = tmp.mul_nnz(self.weight[0])",
            "+        tmp = tmp.mul_nnz(self.weight[0], layout='coo')",
            "",
            "outs = [tmp]",
            "for i in range(1, self.filter_size + 1):",
            "tmp = tmp @ adj_t",
            "-            tmp = tmp.mul_nnz(self.weight[i])",
            "+            tmp = tmp.mul_nnz(self.weight[i], layout='coo')",
            "outs += [tmp]",
            "",
            "row = torch.cat([out.storage.row() for out in outs], dim=0)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 2581,
        "change": [
            "class PyramidVisionTransformerV2(nn.Module):",
            "cur += depths[i]",
            "",
            "# classification head",
            "-        self.head = nn.Linear(embed_dims[3], num_classes) if num_classes > 0 else nn.Identity()",
            "+        self.num_features = embed_dims[-1]",
            "+        self.head = nn.Linear(embed_dims[-1], num_classes) if num_classes > 0 else nn.Identity()",
            "",
            "self.apply(self._init_weights)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 2592,
        "change": [
            "class SequenceGenerator(nn.Module):",
            "cum_unfin.append(prev)",
            "cum_fin_tensor = torch.tensor(cum_unfin, dtype=torch.int).to(bbsz_idx)",
            "",
            "-        unfin_idx = bbsz_idx // beam_size",
            "+        unfin_idx = torch.div(bbsz_idx, beam_size, rounding_mode='trunc')",
            "sent = unfin_idx + torch.index_select(cum_fin_tensor, 0, unfin_idx)",
            "",
            "# Create a set of \"{sent}{unfin_idx}\", where"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 2606,
        "change": [
            "def test_conditional_whiten(Xnew, X, kernel, f_loc, f_scale_tril, loc, cov):",
            "loc0, cov0 = conditional(Xnew, X, kernel, f_loc, f_scale_tril, full_cov=True,",
            "whiten=False)",
            "Kff = kernel(X) + torch.eye(3) * 1e-6",
            "-    Lff = Kff.cholesky()",
            "+    Lff = torch.linalg.cholesky(Kff)",
            "whiten_f_loc = Lff.inverse().matmul(f_loc)",
            "whiten_f_scale_tril = Lff.inverse().matmul(f_scale_tril)",
            "loc1, cov1 = conditional(Xnew, X, kernel, whiten_f_loc, whiten_f_scale_tril,"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 2627,
        "change": [
            "def accuracy(pr, gt, threshold=0.5, ignore_channels=None):",
            "pr = _threshold(pr, threshold=threshold)",
            "pr, gt = _take_channels(pr, gt, ignore_channels=ignore_channels)",
            "",
            "-    tp = torch.sum(gt == pr)",
            "+    tp = torch.sum(gt == pr, dtype=pr.dtype)",
            "score = tp / gt.view(-1).shape[0]",
            "return score"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 2636,
        "change": [
            "def shape(",
            "as_array: bool = False,",
            ") -> Union[tf.Tensor, ivy.Shape, ivy.Array]:",
            "if as_array:",
            "-        return ivy.array(tf.shape(x))",
            "+        return ivy.array(tf.shape(x), dtype=ivy.default_int_dtype())",
            "else:",
            "return ivy.Shape(x.shape)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 2654,
        "change": [
            "class Entropy(Metric):",
            "def __call__(",
            "self,  # type: ignore",
            "logits: torch.Tensor,",
            "-        mask: Optional[torch.Tensor] = None,",
            "+        mask: Optional[torch.BoolTensor] = None,",
            "):",
            "\"\"\"",
            "# Parameters",
            "",
            "logits : `torch.Tensor`, required.",
            "A tensor of unnormalized log probabilities of shape (batch_size, ..., num_classes).",
            "-        mask : `torch.Tensor`, optional (default = None).",
            "+        mask : `torch.BoolTensor`, optional (default = None).",
            "A masking tensor of shape (batch_size, ...).",
            "\"\"\"",
            "logits, mask = self.detach_tensors(logits, mask)",
            "",
            "if mask is None:",
            "-            mask = torch.ones(logits.size()[:-1], device=logits.device)",
            "+            mask = torch.ones(logits.size()[:-1], device=logits.device).bool()",
            "",
            "log_probs = torch.nn.functional.log_softmax(logits, dim=-1)",
            "probabilities = torch.exp(log_probs) * mask.unsqueeze(-1)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 2662,
        "change": [
            "def get_transducer_task_io(",
            "encoder_out_lens = list(map(int, encoder_out_lens))",
            "",
            "t_len = torch.IntTensor(encoder_out_lens).to(device)",
            "-    u_len = torch.IntTensor([y.size(0) for y in ys]).to(device)",
            "+    u_len = torch.IntTensor([y.size(0) for y in labels_unpad]).to(device)",
            "",
            "-    return target, t_len, u_len",
            "+    return decoder_in, target, t_len, u_len"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 2663,
        "change": [
            "def lower_modules_to_accelerator(",
            "backend = \"NNPI\"",
            "backend_qualifier = \"\"",
            "",
            "-        if throughput_optimize:",
            "+        if throughput_optimize and gelu_clip:",
            "+            backend_qualifier = \":throughput_optimized_gelu_clip\"",
            "+        elif throughput_optimize:",
            "backend_qualifier = \":throughput_optimized\"",
            "",
            "modules_to_lower = accelerator.get_modules(model, backend + backend_qualifier)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 2685,
        "change": [
            "class GPTJForSequenceClassification(GPTJPreTrainedModel):",
            "f\"unexpected if using padding tokens in conjunction with `inputs_embeds.`\"",
            ")",
            "",
            "-        pooled_logits = logits[range(batch_size), sequence_lengths]",
            "+        pooled_logits = logits[torch.arange(batch_size, device=self.device), sequence_lengths]",
            "",
            "loss = None",
            "if labels is not None:"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Device Management Error"
    },
    {
        "number": 2727,
        "change": [
            "class DomainClient(Client):",
            "",
            "return response",
            "",
            "-    def apply_to_network(self, target: str, reason: str):",
            "+    def apply_to_network(self,",
            "+            target: str,",
            "+            reason: str,",
            "+            route_index: int = 0):",
            "self.association.create(",
            "target=target,",
            "-            sender=self.conn.base_url.replace(\"/api/v1\", \"\"),",
            "+            sender=self.routes[route_index].connection.base_url.replace(\"/api/v1\", \"\"),",
            "reason=reason,",
            "node_name=self.name,",
            ")"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Argument Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Argument Error"
    },
    {
        "number": 2783,
        "change": [
            "class CNNLayerVisualization():",
            "self.conv_output = x[0, self.selected_filter]",
            "# Loss function is the mean of the output of the selected layer/filter",
            "# We try to minimize the mean of the output of that specific filter",
            "-            loss = torch.mean(self.conv_output)",
            "-            print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()[0]))",
            "+            loss = -torch.mean(self.conv_output)",
            "+            print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))",
            "# Backward",
            "loss.backward()",
            "# Update image"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 2784,
        "change": [
            "class BitEncoder(nn.Module):",
            "dilation = 1",
            "",
            "layer_dropouts = [",
            "-            x.tolist() for x in torch.linspace(0, config.drop_path_rate, sum(config.depths)).split(config.depths)",
            "+            x.tolist()",
            "+            for x in torch.Tensor(np.linspace(0, config.drop_path_rate, sum(config.depths))).split(config.depths)",
            "]",
            "",
            "for stage_idx, (current_depth, current_hidden_size, layer_dropout) in enumerate("
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 2786,
        "change": [
            "def absolute_path(path):",
            "This implementation avoids calling os.path.abspath(path) if 'path' already",
            "represents an absolute Tensorflow filesystem location (e.g. <fs type>://).",
            "\"\"\"",
            "-  return path if \"://\" in str(path) else os.path.abspath(path)",
            "+  return path if b\"://\" in tf.compat.as_bytes(path) else os.path.abspath(path)",
            "",
            "",
            "def fc2_implements_resources():"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 2791,
        "change": [
            "def main():",
            "if requires_preprocessing:",
            "prepare_input = PREPROCESSING_FUNCTIONS.get(args.model_type)",
            "prompt_text, model_kwargs = prepare_input(args, model, tokenizer, prompt_text)",
            "-    encoded_prompt = torch.tensor(tokenizer.encode(prompt_text, add_special_tokens=False)).unsqueeze(0)",
            "+    encoded_prompt = tokenizer.encode(prompt_text, add_special_tokens=False, return_tensors='pt')",
            "",
            "output_sequences = model.generate(",
            "-        intput_ids=encoded_prompt,",
            "-        length=args.length,",
            "+        input_ids=encoded_prompt,",
            "+        max_length=args.length,",
            "temperature=args.temperature,",
            "top_k=args.k,",
            "top_p=args.p,"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 2798,
        "change": [
            "class PlanTranslatorTorchscript(AbstractPlanTranslator):",
            "translation_plan = self.plan.copy()",
            "translation_plan.forward = None",
            "",
            "-        args_shape = translation_plan.get_args_shape()",
            "-        args = PlaceHolder.create_placeholders(args_shape)",
            "+        args = translation_plan.create_dummy_args()",
            "",
            "-        # To avoid storing Plan state tensors in torchscript, they will be send as parameters",
            "+        # jit.trace clones input args and can change their type, so we have to skip types check",
            "+        # TODO see if type check can be made less strict,",
            "+        #  e.g. tensor/custom tensor/nn.Parameter could be considered same type",
            "+        translation_plan.validate_input_types = False",
            "+",
            "+        # To avoid storing Plan state tensors in torchscript, they will be sent as parameters",
            "# we trace wrapper func, which accepts state parameters as last arg",
            "# and sets them into the Plan before executing the Plan",
            "def wrap_stateful_plan(*args):"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 2803,
        "change": [
            "class TFEmbedding(tf.keras.layers.Embedding):",
            "super().__init__(*args, **kwargs)",
            "",
            "def call(self, inputs):",
            "-        inputs = tf.cast(tf.expand_dims(inputs, -1), tf.int32)",
            "-        outputs = tf.gather_nd(self.embeddings, inputs)",
            "+        inputs = tf.cast(inputs, tf.int32)",
            "+        outputs = tf.gather(self.embeddings, inputs)",
            "return outputs"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 2819,
        "change": [
            "class Model(object):",
            "self.deterministic_mode = config.get('deterministic_mode', False)",
            "self.episode_length = tf.placeholder(tf.int32, (None,), name='episode_length')",
            "",
            "-        self.alpha = config.get('alpha', 0.001)",
            "+        self.learning_rate = config.get('learning_rate', 0.001)",
            "",
            "optimizer = config.get('optimizer')",
            "if not optimizer:",
            "-            self.optimizer = tf.train.AdamOptimizer(self.alpha)",
            "+            self.optimizer = tf.train.AdamOptimizer(self.learning_rate)",
            "else:",
            "args = config.get('optimizer_args', [])",
            "kwargs = config.get('optimizer_kwargs', {})",
            "optimizer_cls = get_function(optimizer)",
            "-            self.optimizer = optimizer_cls(self.alpha, *args, **kwargs)",
            "+            self.optimizer = optimizer_cls(self.learning_rate, *args, **kwargs)",
            "",
            "exploration = config.get('exploration')",
            "if not exploration:"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 2827,
        "change": [
            "class Metric(Registrable):",
            "raise NotImplementedError",
            "",
            "@staticmethod",
            "-    def unwrap_to_tensors(*tensors: torch.Tensor):",
            "+    def detach_tensors(*tensors: torch.Tensor) -> Iterable[torch.Tensor]:",
            "\"\"\"",
            "If you actually passed gradient-tracking Tensors to a Metric, there will be",
            "a huge memory leak, because it will prevent garbage collection for the computation",
            "-        graph. This method ensures that you're using tensors directly and that they are on",
            "-        the CPU.",
            "+        graph. This method ensures the tensors are detached.",
            "\"\"\"",
            "-        return (x.detach().cpu() if isinstance(x, torch.Tensor) else x for x in tensors)",
            "+        # Check if it's actually a tensor in case something else was passed.",
            "+        return (x.detach() if isinstance(x, torch.Tensor) else x for x in tensors)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 2841,
        "change": [
            "class Synthesizer(object):",
            "sample_rate=self.ap.sample_rate,",
            ").cuda()",
            "",
            "-        check = torch.load(model_file)",
            "-        self.wavernn.load_state_dict(check['model'], map_location=\"cpu\")",
            "+        check = torch.load(model_file, map_location=\"cpu\")",
            "+        self.wavernn.load_state_dict(check['model'])",
            "if use_cuda:",
            "self.wavernn.cuda()",
            "self.wavernn.eval()"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 2845,
        "change": [
            "def floor_divide(",
            "if (not np.all(x2)) or (np.any(x2) == -0):  # check for division by zero",
            "ret = np.floor_divide(x1, x2)",
            "else:",
            "-        ret = tf.math.floordiv(x1, x2)",
            "+        ret = tf.experimental.numpy.floor_divide(x1, x2)",
            "",
            "if (any(isinf(x1)) and any(isfinite(x2))) or (any(isfinite(x1)) and any(isinf(x2))):",
            "return ivy.full_like(ret, floor(divide(x1, x2)), dtype=ret.dtype)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 2859,
        "change": [
            "class DDIMScheduler(SchedulerMixin, ConfigMixin):",
            "prev_sample = alpha_prod_t_prev ** (0.5) * pred_original_sample + pred_sample_direction",
            "",
            "if eta > 0:",
            "+            # randn_like does not support generator https://github.com/pytorch/pytorch/issues/27072",
            "device = model_output.device if torch.is_tensor(model_output) else \"cpu\"",
            "-            noise = torch.randn(model_output.shape, generator=generator).to(device)",
            "+            noise = torch.randn(model_output.shape, dtype=model_output.dtype, generator=generator).to(device)",
            "variance = self._get_variance(timestep, prev_timestep) ** (0.5) * eta * noise",
            "",
            "prev_sample = prev_sample + variance"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 2883,
        "change": [
            "class Fixture(object):",
            "",
            "def _convert_logits_to_ps(self, dist_params):",
            "if 'logits' in dist_params:",
            "-            logits = torch.Tensor(dist_params.pop('logits'))",
            "+            logits = Variable(torch.Tensor(dist_params.pop('logits')))",
            "is_multidimensional = self.get_test_distribution_name() != 'Bernoulli'",
            "ps, _ = get_probs_and_logits(logits=logits, is_multidimensional=is_multidimensional)",
            "dist_params['ps'] = list(ps.data.cpu().numpy())"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 2884,
        "change": [
            "class GEDDataset(InMemoryDataset):",
            "xs += [assoc[x]]",
            "ys += [assoc[y]]",
            "gs += [g]",
            "-            x, y, g = torch.tensor(xs), torch.tensor(ys), torch.tensor(gs)",
            "+            x, y = torch.tensor(xs), torch.tensor(ys)",
            "+            g = torch.tensor(gs, dtype=torch.float)",
            "mat[x, y], mat[y, x] = g, g",
            "",
            "path = osp.join(self.processed_dir, '{}_ged.pt'.format(self.name))"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 2888,
        "change": [
            "def extract_info_from_torch_data(",
            "input_types = ifnone(",
            "input_types,",
            "[",
            "-            \"int\" if isinstance(x.cpu(), torch.LongTensor) else \"float\"",
            "+            \"int64\"",
            "+            if isinstance(x.cpu(), torch.LongTensor)",
            "+            else \"int32\"",
            "+            if isinstance(x.cpu(), torch.IntTensor)",
            "+            else \"float32\"",
            "for x in input_row",
            "],",
            ")"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 2891,
        "change": [
            "def block(params, scope, past, append_dim, train=False):",
            "def model(features, labels, params, mesh, past=None):",
            "\"\"\"A GPT style model implemented in mesh tensorlfow.\"\"\"",
            "results = {}",
            "+    sequence_dim = mtf.Dimension('sequence', params[\"n_ctx\"])",
            "if params[\"num_microbatches\"] > 1:",
            "x = features[\"inputs\"]",
            "labels = features[\"labels\"]",
            "batch_dim = x.shape[0]",
            "-",
            "-",
            "else:",
            "+      batch_dim = mtf.Dimension('batch', params[\"train_batch_size\"])",
            "x = mtf.import_tf_tensor(mesh, features, mtf.Shape([batch_dim, sequence_dim]))",
            "# In this case, labels are simply input shifted one token to the right",
            "# this op is done in the input_fn",
            "# define mtf dims",
            "-      batch_dim = mtf.Dimension('batch', params[\"train_batch_size\"])",
            "labels = mtf.import_tf_tensor(mesh, labels, mtf.Shape([batch_dim, sequence_dim]))",
            "",
            "-    sequence_dim = mtf.Dimension('sequence', params[\"n_ctx\"])",
            "",
            "# we need this because gathering when both the args have the same dimension in them it breaks stuff.",
            "# this dim is specifically for the weights"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 2926,
        "change": [
            "class CrossAttention(nn.Module):",
            "key_slice = key_slice.float()",
            "",
            "attn_slice = torch.baddbmm(",
            "-                torch.empty(slice_size, query.shape[1], key.shape[1], dtype=query.dtype, device=query.device),",
            "-                query[start_idx:end_idx],",
            "-                key[start_idx:end_idx].transpose(-1, -2),",
            "+                torch.empty(slice_size, query.shape[1], key.shape[1], dtype=query_slice.dtype, device=query.device),",
            "+                query_slice,",
            "+                key_slice.transpose(-1, -2),",
            "beta=0,",
            "alpha=self.scale,",
            ")"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 2948,
        "change": [
            "class InMemoryDataset(Dataset):",
            "for key in keys:",
            "item = data_list[0][key]",
            "if torch.is_tensor(item):",
            "-                data[key] = torch.cat(",
            "-                    data[key], dim=data.__cat_dim__(key, data_list[0][key]))",
            "+                data[key] = torch.cat(data[key],",
            "+                                      dim=data.__cat_dim__(key, item))",
            "elif isinstance(item, int) or isinstance(item, float):",
            "data[key] = torch.tensor(data[key])"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 2956,
        "change": [
            "class FloatVectorField(Field):",
            ")",
            "self.dim_error_check = dim_error_check  # dims in data should match config",
            "self.dummy_model_input = torch.tensor(",
            "-            [[1.0] * dim], dtype=torch.float, device=\"cpu\"",
            "+            [[1.0] * dim, [1.0] * dim], dtype=torch.float, device=\"cpu\"",
            ")",
            "",
            "def _parse_vector(self, s):"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 2969,
        "change": [
            "class WGAN_GP(object):",
            "alpha = tf.random_uniform(shape=self.inputs.get_shape(), minval=0.,maxval=1.)",
            "differences = G - self.inputs # This is different from MAGAN",
            "interpolates = self.inputs + (alpha * differences)",
            "-        D_inter,_,_=self.discriminator(interpolates, is_training=True, reuse=True)",
            "+        _,D_inter,_=self.discriminator(interpolates, is_training=True, reuse=True)",
            "gradients = tf.gradients(D_inter, [interpolates])[0]",
            "slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))",
            "gradient_penalty = tf.reduce_mean((slopes - 1.) ** 2)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 2971,
        "change": [
            "class TransferLearningModel(pl.LightningModule):",
            "# 1. Forward pass:",
            "x, y = batch",
            "y_logits = self.forward(x)",
            "+        y_scores = torch.sigmoid(y_logits)",
            "y_true = y.view((-1, 1)).type_as(x)",
            "",
            "# 2. Compute loss",
            "self.log(\"val_loss\", self.loss(y_logits, y_true), prog_bar=True)",
            "",
            "# 3. Compute accuracy:",
            "-        self.log(\"val_acc\", self.valid_acc(y_logits, y_true.int()), prog_bar=True)",
            "+        self.log(\"val_acc\", self.valid_acc(y_scores, y_true.int()), prog_bar=True)",
            "",
            "def configure_optimizers(self):",
            "parameters = list(self.parameters())"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 2975,
        "change": [
            "class Decoder(nn.Module):",
            "self.attention = inputs.data.new(B, T).zero_()",
            "self.attention_cum = inputs.data.new(B, T).zero_()",
            "",
            "-    def _parse_outputs(self, outputs, stop_tokens, attentions):",
            "+    def _parse_outputs(self, outputs, attentions, stop_tokens):",
            "# Back to batch first",
            "attentions = torch.stack(attentions).transpose(0, 1)",
            "outputs = torch.stack(outputs).transpose(0, 1).contiguous()",
            "-        stop_tokens = torch.stack(stop_tokens).transpose(0, 1)",
            "-        return outputs, stop_tokens, attentions",
            "+        stop_tokens = torch.stack(stop_tokens).transpose(0, 1).squeeze(-1)",
            "+        return outputs, attentions, stop_tokens",
            "",
            "def decode(self,",
            "inputs,"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 2978,
        "change": [
            "class GAE(torch.nn.Module):",
            "data.val_pos_edge_index = torch.stack([r, c], dim=0)",
            "r, c = row[n_v:n_v + n_t], col[n_v:n_v + n_t]",
            "data.test_pos_edge_index = torch.stack([r, c], dim=0)",
            "+",
            "r, c = row[n_v + n_t:], col[n_v + n_t:]",
            "-        data.train_pos_edge_index = torch.stack([r, c], dim=0)",
            "+        edge_index = torch.stack([r, c], dim=0)",
            "+        data.train_pos_edge_index = to_undirected(edge_index)",
            "",
            "# Negative edges.",
            "num_nodes = data.num_nodes"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 2980,
        "change": [
            "class LatentDiffusion(DiffusionPipeline):",
            "num_trained_timesteps = self.noise_scheduler.timesteps",
            "inference_step_times = range(0, num_trained_timesteps, num_trained_timesteps // num_inference_steps)",
            "",
            "-        image = self.noise_scheduler.sample_noise(",
            "+        image = torch.randn(",
            "(batch_size, self.unet.in_channels, self.unet.image_size, self.unet.image_size),",
            "device=torch_device,",
            "generator=generator,"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 2995,
        "change": [
            "class EmpiricalMarginal(Empirical):",
            "in ``[0, num_chains - 1]``, and there must be equal number",
            "of samples per chain.",
            "\"\"\"",
            "-        weight_type = value.new_empty(1).float().type() if value.dtype in (torch.int32, torch.int64) \\",
            "-            else value.type()",
            "# Apply default weight of 1.0.",
            "if log_weight is None:",
            "-            log_weight = torch.tensor(0.0).type(weight_type)",
            "-        if isinstance(log_weight, numbers.Number):",
            "-            log_weight = torch.tensor(log_weight).type(weight_type)",
            "-        if self._validate_args and log_weight.dim() > 0:",
            "+            log_weight = 0.0",
            "+        if self._validate_args and not isinstance(log_weight, numbers.Number) and log_weight.dim() > 0:",
            "raise ValueError(\"``weight.dim() > 0``, but weight should be a scalar.\")",
            "",
            "# Append to the buffer list"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 3012,
        "change": [
            "def _convert_to_tf(x):",
            "return x",
            "",
            "if x is not None:",
            "-        x = tf.nest.map_structure(tf.convert_to_tensor, x)",
            "+        x = tf.nest.map_structure(",
            "+            lambda f: tf.convert_to_tensor(f) if f is not None else None, x)",
            "return x"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 3017,
        "change": [
            "class CTCPrefixScoreTH(object):",
            "r_prev, s_prev, f_min_prev, f_max_prev = state",
            "",
            "# select input dimensions for scoring",
            "-        if self.scoring_num > 0 and prep_scores is not None:",
            "-            scoring_ids = torch.topk(prep_scores, self.scoring_num, 1)[1]",
            "+        if self.scoring_num > 0 and pre_scores is not None:",
            "+            pre_scores[:, self.blank] = self.logzero  # ignore blank from pre-selection",
            "+            scoring_ids = torch.topk(pre_scores, self.scoring_num, 1)[1]",
            "scoring_idmap = torch.full((self.n_bb, self.odim), -1, dtype=torch.long, device=self.device)",
            "snum = scoring_ids.size(1)",
            "scoring_idmap[self.bb_idx, scoring_ids] = torch.arange(snum, device=self.device)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 3021,
        "change": [
            "class MultiHeadedAttention(nn.Module):",
            "",
            "scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)  # (batch, head, time1, time2)",
            "if mask is not None:",
            "-            mask.unsqueeze_(1).eq_(0)  # (batch, 1, time1, time2)",
            "+            mask = mask.unsqueeze(1).eq(0)  # (batch, 1, time1, time2)",
            "scores = scores.masked_fill(mask, MIN_VALUE)",
            "self.attn = torch.softmax(scores, dim=-1).masked_fill(mask, 0.0)  # (batch, head, time1, time2)",
            "else:",
            "-            self.attn = torch.softmax(scores, dim=-1)",
            "+            self.attn = torch.softmax(scores, dim=-1)  # (batch, head, time1, time2)",
            "",
            "p_attn = self.dropout(self.attn)",
            "x = torch.matmul(p_attn, v)  # (batch, head, time1, d_k)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 3048,
        "change": [
            "class TopKPooling(torch.nn.Module):",
            "",
            "weight = F.normalize(self.weight, p=2, dim=-1)",
            "score = (x * weight).sum(dim=-1)",
            "-        perm = self.topk(score, self.k, batch)",
            "-",
            "-        x = x[perm] * self.tanh(score[perm])",
            "+        perm = self.topk(score, self.ratio, batch)",
            "+        x = x[perm] * torch.tanh(score[perm]).view(-1, 1)",
            "batch = batch[perm]",
            "edge_index, edge_attr = self.filter_adj(",
            "-            edge_index, edge_attr, perm, num_nodes=x.size(0))",
            "+            edge_index, edge_attr, perm, num_nodes=score.size(0))",
            "",
            "-        return x, edge_index, edge_attr, batch",
            "+        return x, edge_index, edge_attr, batch, perm",
            "",
            "def __repr__(self):",
            "return '{}({})'.format(self.__class__.__name__, self.ratio)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 3050,
        "change": [
            "class HaloAttn(nn.Module):",
            "",
            "kv = self.kv(x)",
            "# FIXME I 'think' this unfold does what I want it to, but I should investigate",
            "-        k = F.unfold(kv, kernel_size=self.win_size, stride=self.block_size, padding=self.halo_size)",
            "-        k = k.reshape(",
            "+        kv = F.unfold(kv, kernel_size=self.win_size, stride=self.block_size, padding=self.halo_size)",
            "+        kv = kv.reshape(",
            "B * self.num_heads, self.dim_head + (self.dim_v // self.num_heads), -1, num_blocks).transpose(1, 3)",
            "-        k, v = torch.split(k, [self.dim_head, self.dim_v // self.num_heads], dim=-1)",
            "+        k, v = torch.split(kv, [self.dim_head, self.dim_v // self.num_heads], dim=-1)",
            "",
            "attn_logits = (q @ k.transpose(-1, -2)) * self.scale  # FIXME should usual attn scale be applied?",
            "attn_logits = attn_logits + self.pos_embed(q)  # B * num_heads, block_size ** 2, win_size ** 2"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 3092,
        "change": [
            "class XLNetRelativeAttention(nn.Module):",
            "",
            "# Mask heads if we want to",
            "if head_mask is not None:",
            "-            attn_prob = attn_prob * head_mask",
            "+            attn_prob = attn_prob * torch.einsum('ijbn->bnij', head_mask)",
            "",
            "# attention output",
            "attn_vec = torch.einsum('bnij,jbnd->ibnd', attn_prob, v_head_h)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3161,
        "change": [
            "class LAFOrienter(nn.Module):",
            "self.patch_size,",
            "self.patch_size)",
            "angles_radians: torch.Tensor = self.angle_detector(patches).view(B, N)",
            "-        laf_out: torch.Tensor = set_laf_orientation(laf, rad2deg(angles_radians))",
            "+        prev_angle = get_laf_orientation(laf).view_as(angles_radians)",
            "+        laf_out: torch.Tensor = set_laf_orientation(laf, rad2deg(angles_radians) + prev_angle)",
            "return laf_out"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 3177,
        "change": [
            "def regularize_cost(regex, func, name='regularize_cost'):",
            "for p in params:",
            "para_name = p.name",
            "# in replicated mode, only regularize variables inside this tower",
            "-        if ctx.has_own_variables and (not para_name.startswith(ctx.name)):",
            "+        if ctx.has_own_variables and (not para_name.startswith(ctx.vs_name)):",
            "continue",
            "if re.search(regex, para_name):",
            "costs.append(func(p))",
            "_log_regularizer(para_name)",
            "if not costs:",
            "-        return 0",
            "+        return tf.constant(0, dtype=tf.float32, name='empty_regularize_cost')",
            "return tf.add_n(costs, name=name)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 3187,
        "change": [
            "class TFConvBertEmbeddings(tf.keras.layers.Layer):",
            "token_type_ids = tf.fill(dims=input_shape, value=0)",
            "",
            "if position_ids is None:",
            "-            position_ids = tf.expand_dims(tf.range(start=0, limit=input_shape[-1]), axis=0)",
            "+            position_ids = tf.expand_dims(",
            "+                tf.range(start=past_key_values_length, limit=input_shape[1] + past_key_values_length), axis=0",
            "+            )",
            "",
            "position_embeds = tf.gather(params=self.position_embeddings, indices=position_ids)",
            "position_embeds = tf.tile(input=position_embeds, multiples=(input_shape[0], 1, 1))"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 3205,
        "change": [
            "class Pipeline(pps_module.Preprocessor):",
            "transformed.append(data)",
            "if len(transformed) == 1:",
            "return transformed[0]",
            "-        return tuple(transformed)",
            "+        return tf.data.Dataset.zip(tuple(transformed))",
            "",
            "def save(self, filepath):",
            "io_utils.save_json(filepath, self.get_config())"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 3220,
        "change": [
            "class Iterative(Solver):",
            "next_step = self.next_step(*args)",
            "step = (lambda: self.step(*args))",
            "do_nothing = (lambda: args)",
            "-                args = tf.cond(pred=next_step, true_fn=step, false_fn=do_nothing)",
            "+                args = self.cond(pred=next_step, true_fn=step, false_fn=do_nothing)",
            "",
            "else:",
            "# TensorFlow while loop",
            "-            args = tf.while_loop(",
            "+            args = self.while_loop(",
            "cond=self.next_step, body=self.step, loop_vars=args,",
            "maximum_iterations=self.max_iterations",
            ")"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 3223,
        "change": [
            "def train(hyp):",
            "if not opt.evolve:",
            "plot_results()  # save as results.png",
            "print('%g epochs completed in %.3f hours.\\n' % (epoch - start_epoch + 1, (time.time() - t0) / 3600))",
            "-    dist.destroy_process_group() if torch.cuda.device_count() > 1 else None",
            "+    dist.destroy_process_group() if device.type != 'cpu' and torch.cuda.device_count() > 1 else None",
            "torch.cuda.empty_cache()",
            "return results"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3238,
        "change": [
            "class PinholeCamera:",
            ">>> _ = torch.manual_seed(0)",
            ">>> x = torch.rand(1, 2)",
            ">>> depth = torch.ones(1, 1)",
            "-            >>> I = torch.eye(4)[None]",
            "+            >>> K = torch.eye(4)[None]",
            ">>> E = torch.eye(4)[None]",
            ">>> h = torch.ones(1)",
            ">>> w = torch.ones(1)",
            ">>> pinhole = kornia.geometry.camera.PinholeCamera(K, E, h, w)",
            "-            >>> pinhole.unproject_points(x, depth)",
            "+            >>> pinhole.unproject(x, depth)",
            "tensor([[0.4963, 0.7682, 1.0000]])",
            "\"\"\"",
            "P = self.intrinsics @ self.extrinsics"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 3239,
        "change": [
            "class TorchHook:",
            "if type(native_func) in [types.FunctionType, types.BuiltinFunctionType]:",
            "# 3. Build the hooked function",
            "new_func = self.get_hooked_func(native_func)",
            "-                # 4. Move the native function",
            "-                setattr(torch_module, f\"native_{func}\", native_func)",
            "+                # 4. Move the native function to its original module",
            "+                # /!\\ Can be different from the torch_module!",
            "+                # Ex: in torch.py `torch.argmax = torch.functional.argmax`",
            "+                # ... So torch.argmax.__module__ is 'torch.functional' != 'torch'",
            "+                setattr(eval(native_func.__module__), f\"native_{func}\", native_func)",
            "# 5. Put instead the hooked one",
            "setattr(torch_module, func, new_func)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 3242,
        "change": [
            "class TowerContext(object):",
            "global _CurrentTowerContext",
            "assert _CurrentTowerContext is None, \"Cannot nest TowerContext!\"",
            "_CurrentTowerContext = self",
            "-        curr_vs = tf.get_variable_scope()",
            "-        assert curr_vs.name == '', \"Cannot nest TowerContext with an existing variable scope!\"",
            "+        if self.is_training:",
            "+            curr_vs = tf.get_variable_scope()",
            "+            assert curr_vs.name == '', \"In training, cannot nest TowerContext with an existing variable scope!\"",
            "",
            "self._ctxs = self._get_scopes()",
            "self._ctxs.append(self._collection_guard)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 3244,
        "change": [
            "class SelfMultiheadAttn(nn.Module):",
            "self.register_parameter('lyr_norm_beta_weights', None)",
            "self.lyr_nrm_gamma_weights = None",
            "self.lyr_nrm_beta_weights  = None",
            "-                self.lyr_nrm = torch.nn.LayerNorm(embed_dim)",
            "+                self.lyr_nrm = FusedLayerNorm(embed_dim)",
            "self.reset_parameters()",
            "",
            "if self.include_norm_add:"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3250,
        "change": [
            "class ScaleSpaceDetector(nn.Module):",
            "max_coords_best = _scale_index_to_scale(max_coords_best, sigmas_oct)",
            "",
            "# Create local affine frames (LAFs)",
            "-            rotmat = angle_to_rotation_matrix(torch.zeros(B, N))",
            "+            rotmat = angle_to_rotation_matrix(torch.zeros(B, N).to(max_coords_best.device).to(max_coords_best.dtype))",
            "current_lafs = torch.cat([self.mr_size * max_coords_best[:, :, 0].view(B, N, 1, 1) * rotmat,",
            "max_coords_best[:, :, 1:3].view(B, N, 2, 1)], dim=3)",
            "# Normalize LAFs"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3271,
        "change": [
            "class T5EncoderModel(T5PreTrainedModel):",
            "class PreTrainedModel",
            "\"\"\"",
            "for layer, heads in heads_to_prune.items():",
            "-            self.encoder.layer[layer].attention.prune_heads(heads)",
            "+            self.encoder.block[layer].layer[0].SelfAttention.prune_heads(heads)",
            "",
            "@add_start_docstrings_to_model_forward(T5_ENCODER_INPUTS_DOCSTRING)",
            "@replace_return_docstrings(output_type=BaseModelOutput, config_class=_CONFIG_FOR_DOC)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 3283,
        "change": [
            "class ResNet_Cifar(ModelDesc):",
            "ce_cost = tf.nn.softmax_cross_entropy_with_logits(labels=label, logits=logits)",
            "ce_cost = tf.reduce_mean(ce_cost, name='cross_entropy_loss')",
            "",
            "-        single_label = tf.to_int32(tf.argmax(label, axis=1))",
            "-        wrong = tf.to_float(tf.logical_not(tf.nn.in_top_k(logits, single_label, 1)), name='wrong_vector')",
            "+        single_label = tf.cast(tf.argmax(label, axis=1), tf.int32)",
            "+        wrong = tf.cast(tf.logical_not(tf.nn.in_top_k(logits, single_label, 1)), tf.float32, name='wrong_vector')",
            "# monitor training error",
            "add_moving_summary(tf.reduce_mean(wrong, name='train_error'), ce_cost)",
            "add_param_summary(('.*/W', ['histogram']))"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 3309,
        "change": [
            "class PermuteTransform(Transform):",
            "vector of zeros works.",
            "\"\"\"",
            "",
            "-        return torch.zeros_like(x)",
            "+        return torch.zeros(x.size()[:-1])"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3313,
        "change": [
            "def select_device(device='', batch_size=0, newline=True):",
            "for i, d in enumerate(devices):",
            "p = torch.cuda.get_device_properties(i)",
            "s += f\"{'' if i == 0 else space}CUDA:{d} ({p.name}, {p.total_memory / (1 << 20):.0f}MiB)\\n\"  # bytes to MB",
            "+    elif mps:",
            "+        s += 'MPS\\n'",
            "else:",
            "s += 'CPU\\n'",
            "",
            "if not newline:",
            "s = s.rstrip()",
            "LOGGER.info(s.encode().decode('ascii', 'ignore') if platform.system() == 'Windows' else s)  # emoji-safe",
            "-    return torch.device('cuda:0' if cuda else 'cpu')",
            "+    return torch.device('cuda:0' if cuda else 'mps' if mps else 'cpu')",
            "",
            "",
            "def time_sync():"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3315,
        "change": [
            "def _get_cached_vs(name):",
            "@contextmanager",
            "def _enter_vs_reuse_ns(name):",
            "vs = _get_cached_vs(name)",
            "+    # XXX Not good to enter the cached vs directly, because this will clean-up custom getter",
            "+    # with tf.variable_scope(name, reuse=tf.AUTO_REUSE):    # available in 1.4 only",
            "with tf.variable_scope(vs):",
            "with tf.name_scope(vs.original_name_scope):",
            "yield vs"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3317,
        "change": [
            "def iou(",
            "",
            "Example:",
            "",
            "-        >>> target = torch.randint(0, 1, (10, 25, 25))",
            "+        >>> target = torch.randint(0, 2, (10, 25, 25))",
            ">>> pred = torch.tensor(target)",
            ">>> pred[2:5, 7:13, 9:15] = 1 - pred[2:5, 7:13, 9:15]",
            ">>> iou(pred, target)",
            "-        tensor(0.4914)",
            "+        tensor(0.9660)",
            "",
            "\"\"\"",
            "num_classes = get_num_classes(pred=pred, target=target, num_classes=num_classes)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 3324,
        "change": [
            "class E2E(STInterface, torch.nn.Module):",
            "isinstance(m, MultiHeadedAttention) and m.attn is not None",
            "):  # skip MHA for submodules",
            "ret[name] = m.attn.cpu().numpy()",
            "+        self.train()",
            "return ret"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "State Handling Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|State Handling Error"
    },
    {
        "number": 3357,
        "change": [
            "class TestHausdorffLoss:",
            "assert_close(actual, expected)",
            "",
            "@pytest.mark.parametrize(\"hd,shape\", [",
            "-        [kornia.losses.HausdorffERLoss, (10, 10)],",
            "-        [kornia.losses.HausdorffERLoss3D, (10, 10, 10)],",
            "+        [kornia.losses.HausdorffERLoss, (5, 5)],",
            "+        [kornia.losses.HausdorffERLoss3D, (5, 5, 5)],",
            "])",
            "-    @pytest.mark.skip(reason='It passed, but will take too much time to run.')",
            "def test_gradcheck(self, hd, shape, device):",
            "num_classes = 3",
            "logits = torch.rand(2, num_classes, *shape, device=device)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3362,
        "change": [
            "class TargetIndegree(object):",
            "",
            "if pseudo is not None and self.cat:",
            "pseudo = pseudo.view(-1, 1) if pseudo.dim() == 1 else pseudo",
            "-            data.weight = torch.cat([pseudo, deg.type_as(pseudo)], dim=-1)",
            "+            data.edge_attr = torch.cat([pseudo, deg.type_as(pseudo)], dim=-1)",
            "else:",
            "-            data.weight = deg",
            "+            data.edge_attr = deg",
            "",
            "return data"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 3372,
        "change": [
            "class LukeModelIntegrationTests(unittest.TestCase):",
            "expected_shape = torch.Size((1, 1, 1024))",
            "self.assertEqual(outputs.entity_last_hidden_state.shape, expected_shape)",
            "",
            "-        expected_slice = torch.tensor([[0.0466, -0.0106, -0.0179]])",
            "+        expected_slice = torch.tensor([[0.0466, -0.0106, -0.0179]]).to(torch_device)",
            "self.assertTrue(torch.allclose(outputs.entity_last_hidden_state[0, :3, :3], expected_slice, atol=1e-4))"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3376,
        "change": [
            "Returns:",
            "\"\"\"",
            "",
            "",
            "-class Rouge(nlp.Metric):",
            "+class Rouge(datasets.Metric):",
            "def _info(self):",
            "-        return nlp.MetricInfo(",
            "+        return datasets.MetricInfo(",
            "description=_DESCRIPTION,",
            "citation=_CITATION,",
            "inputs_description=_KWARGS_DESCRIPTION,",
            "-            features=nlp.Features(",
            "+            features=datasets.Features(",
            "{",
            "-                    \"predictions\": nlp.Value(\"string\", id=\"sequence\"),",
            "-                    \"references\": nlp.Value(\"string\", id=\"sequence\"),",
            "+                    \"predictions\": datasets.Value(\"string\", id=\"sequence\"),",
            "+                    \"references\": datasets.Value(\"string\", id=\"sequence\"),",
            "}",
            "),",
            "codebase_urls=[\"https://github.com/google-research/google-research/tree/master/rouge\"],"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 3383,
        "change": [
            "class MixedInt8T5Test(unittest.TestCase):",
            "`flan-t5-small` uses `T5DenseGatedActDense` whereas `t5-small` uses `T5DenseReluDense`. We need to test",
            "both cases.",
            "\"\"\"",
            "+        import bitsandbytes as bnb",
            "+",
            "from transformers import T5ForConditionalGeneration",
            "",
            "# test with `t5-small`",
            "model = T5ForConditionalGeneration.from_pretrained(self.model_name, load_in_8bit=True, device_map=\"auto\")",
            "+",
            "+        # there was a bug with decoders - this test checks that it is fixed",
            "+        self.assertTrue(isinstance(model.decoder.block[0].layer[0].SelfAttention.q, bnb.nn.Linear8bitLt))",
            "+",
            "encoded_input = self.tokenizer(self.input_text, return_tensors=\"pt\").to(0)",
            "_ = model.generate(**encoded_input)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 3384,
        "change": [
            "sess = tf.InteractiveSession()",
            "network.print_params(False)",
            "",
            "saver = tf.train.Saver()",
            "-if not os.path.isfile(\"inception_v3.ckpt\"):",
            "+if not os.path.isfile(MODEL_PATH):",
            "raise Exception(",
            "\"Please download inception_v3 ckpt from https://github.com/tensorflow/models/tree/master/research/slim\"",
            ")",
            "",
            "try:  # TF12+",
            "-    saver.restore(sess, \"./inception_v3.ckpt\")",
            "+    saver.restore(sess, MODEL_PATH)",
            "except Exception:  # TF11",
            "-    saver.restore(sess, \"inception_v3.ckpt\")",
            "+    saver.restore(sess, MODEL_PATH)",
            "print(\"Model Restored\")",
            "",
            "y = network.outputs"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 3392,
        "change": [
            "class Detect(nn.Module):",
            "y = torch.cat((xy, wh, conf), 4)",
            "z.append(y.view(bs, -1, self.no))",
            "",
            "-        return x if self.training else (torch.cat(z, 1), x)",
            "+        return x if self.training else (torch.cat(z, 1),) if self.export else (torch.cat(z, 1), x)",
            "",
            "def _make_grid(self, nx=20, ny=20, i=0):",
            "d = self.anchors[i].device"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Return Warning|Data Conversion Error"
    },
    {
        "number": 3394,
        "change": [
            "def benchmark_indices_mapping():",
            "functions = (select, sort, shuffle, train_test_split, shard)",
            "with tempfile.TemporaryDirectory() as tmp_dir:",
            "print(\"generating dataset\")",
            "-        features = nlp.Features({\"text\": nlp.Value(\"string\"), \"numbers\": nlp.Value(\"float32\")})",
            "+        features = datasets.Features({\"text\": datasets.Value(\"string\"), \"numbers\": datasets.Value(\"float32\")})",
            "dataset = generate_example_dataset(",
            "os.path.join(tmp_dir, \"dataset.arrow\"), features, num_examples=SPEED_TEST_N_EXAMPLES",
            ")"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 3395,
        "change": [
            "def main():",
            "# train",
            "logging.info('backend = ' + args.backend)",
            "if args.backend == \"chainer\":",
            "-        from espnet.lmchainer.asr_chainer import train",
            "+        from espnet.asr.chainer.asr_chainer import train",
            "train(args)",
            "elif args.backend == \"pytorch\":",
            "-        from espnet.lmpytorch.asr_pytorch import train",
            "+        from espnet.asr.pytorch.asr_pytorch import train",
            "train(args)",
            "else:",
            "raise ValueError(\"Only chainer and pytorch are supported.\")"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 3406,
        "change": [
            "def get_checkpoint_path(model_path):",
            "logger.warn(",
            "\"Checkpoint path {} is auto-corrected to {}.\".format(model_path, new_path))",
            "model_path = new_path",
            "-    assert os.path.isfile(model_path) or os.path.isfile(model_path + '.index'), model_path",
            "+    assert tf.gfile.Exists(model_path) or tf.gfile.Exists(model_path + '.index'), model_path",
            "return model_path"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 3408,
        "change": [
            "class TextClassifier(flair.nn.Model):",
            "self.document_embeddings.embed(sentences)",
            "",
            "text_embedding_list = [sentence.get_embedding().unsqueeze(0) for sentence in sentences]",
            "-        text_embedding_tensor = torch.cat(text_embedding_list, 0)",
            "+        text_embedding_tensor = torch.cat(text_embedding_list, 0).to(flair.device)",
            "",
            "label_scores = self.decoder(text_embedding_tensor)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3415,
        "change": [
            "def recog_v2(args):",
            "for idx, name in enumerate(js.keys(), 1):",
            "logging.info('(%d/%d) decoding ' + name, idx, len(js.keys()))",
            "batch = [(name, js[name])]",
            "-            enc = model.encode(load_inputs_and_targets(batch)[0][0])",
            "+            feat = load_inputs_and_targets(batch)[0][0]",
            "+            enc = model.encode(torch.as_tensor(feat).to(device))",
            "nbest_hyps = beam_search(",
            "x=enc,",
            "sos=model.sos,"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3419,
        "change": [
            "class DecoderRNNT(torch.nn.Module):",
            "normscore = recog_args.score_norm_transducer",
            "",
            "z_list, c_list = self.zero_state(h.unsqueeze(0))",
            "-        eys = torch.zeros((1, self.embed_dim))",
            "+        eys = to_device(self, torch.zeros((1, self.embed_dim)))",
            "",
            "_, (z_list, c_list) = self.rnn_forward(eys, None)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3421,
        "change": [
            "def parse_npz(f):",
            "",
            "adj = sp.csr_matrix((f['adj_data'], f['adj_indices'], f['adj_indptr']),",
            "f['adj_shape']).tocoo()",
            "-    edge_index = torch.tensor([adj.row, adj.col])",
            "+    edge_index = torch.tensor([adj.row, adj.col], dtype=torch.long)",
            "edge_index, _ = remove_self_loops(edge_index)",
            "edge_index = to_undirected(edge_index, x.size(0))  # Internal coalesce."
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 3441,
        "change": [
            "class GroupViTTextTransformer(nn.Module):",
            "",
            "# text_embeds.shape = [batch_size, sequence_length, transformer.width]",
            "# take features from the eot embedding (eot_token is the highest number in each sequence)",
            "-        pooled_output = last_hidden_state[torch.arange(last_hidden_state.shape[0]), input_ids.argmax(dim=-1)]",
            "+        # casting to torch.int for onnx compatibility: argmax doesn't support int64 inputs with opset 14",
            "+        pooled_output = last_hidden_state[",
            "+            torch.arange(last_hidden_state.shape[0]), input_ids.to(torch.int).argmax(dim=-1)",
            "+        ]",
            "",
            "if not return_dict:",
            "return (last_hidden_state, pooled_output) + encoder_outputs[1:]"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 3442,
        "change": [
            "def train(args, train_dataset, model, tokenizer, labels, pad_token_label_id):",
            "if args.fp16:",
            "with amp.scale_loss(loss, optimizer) as scaled_loss:",
            "scaled_loss.backward()",
            "-                torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)",
            "else:",
            "loss.backward()",
            "-                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)",
            "",
            "tr_loss += loss.item()",
            "if (step + 1) % args.gradient_accumulation_steps == 0:",
            "+                if args.fp16:",
            "+                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)",
            "+                else:",
            "+                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)",
            "+",
            "scheduler.step()  # Update learning rate schedule",
            "optimizer.step()",
            "model.zero_grad()"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 3452,
        "change": [
            "class PReluLayer(Layer):",
            "",
            "# with tf.name_scope(name) as scope:",
            "with tf.variable_scope(name):",
            "-            alphas = tf.get_variable(name='alphas', shape=w_shape, initializer=a_init, dtype=D_TYPE, **a_init_args)",
            "+            alphas = tf.get_variable(name='alphas', shape=w_shape, initializer=a_init, dtype=LayersConfig.tf_dtype, **a_init_args)",
            "try:  # TF 1.0",
            "self.outputs = tf.nn.relu(self.inputs) + tf.multiply(alphas, (self.inputs - tf.abs(self.inputs))) * 0.5",
            "except Exception:  # TF 0.12"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 3470,
        "change": [
            "class Input(Layer):",
            "logging.info(\"Input  %s: %s\" % (self.name, str(shape)))",
            "",
            "shape_without_none = [_ if _ is not None else 1 for _ in shape]",
            "-        self.outputs = self.forward(tf.initializers.random_normal()(shape_without_none))",
            "+        self.outputs = self.forward(tf.compat.v1.initializers.random_normal()(shape_without_none))",
            "",
            "def __call__(self, prev_layer):",
            "# FIXME: better exception raising"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 3477,
        "change": [
            "class Generator(datasets.GeneratorBasedBuilder):",
            "return datasets.DatasetInfo(features=self.config.features)",
            "",
            "def _split_generators(self, dl_manager):",
            "-        return [datasets.SplitGenerator(name=datasets.Split.TRAIN, gen_kwargs={})]",
            "+        return [datasets.SplitGenerator(name=datasets.Split.TRAIN, gen_kwargs=self.config.gen_kwargs)]",
            "",
            "-    def _generate_examples(self):",
            "-        for idx, ex in enumerate(self.config.generator(**self.config.gen_kwargs)):",
            "+    def _generate_examples(self, **gen_kwargs):",
            "+        for idx, ex in enumerate(self.config.generator(**gen_kwargs)):",
            "yield idx, ex"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 3492,
        "change": [
            "def run(",
            "seen, windows, dt = 0, [], (Profile(), Profile(), Profile())",
            "for path, im, im0s, vid_cap, s in dataset:",
            "with dt[0]:",
            "-            im = torch.from_numpy(im).to(device)",
            "+            im = torch.from_numpy(im).to(model.device)",
            "im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32",
            "im /= 255  # 0 - 255 to 0.0 - 1.0",
            "if len(im.shape) == 3:"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3513,
        "change": [
            "class OPTAttention(nn.Module):",
            "attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len) + attention_mask",
            "attn_weights = torch.max(attn_weights, torch.tensor(torch.finfo(attn_weights.dtype).min))",
            "attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
            "-            dtype_attn_weights = attn_weights.dtype",
            "",
            "# upcast to fp32 if the weights are in fp16. Please see https://github.com/huggingface/transformers/pull/17437",
            "-        if dtype_attn_weights == torch.float16:",
            "-            attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(dtype_attn_weights)",
            "+        if attn_weights.dtype == torch.float16:",
            "+            attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(torch.float16)",
            "else:",
            "attn_weights = nn.functional.softmax(attn_weights, dim=-1)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 3531,
        "change": [
            "class ScoreSdeVpScheduler(SchedulerMixin, ConfigMixin):",
            "self.discrete_sigmas = None",
            "self.timesteps = None",
            "",
            "-    def set_timesteps(self, num_inference_steps):",
            "-        self.timesteps = torch.linspace(1, self.config.sampling_eps, num_inference_steps)",
            "+    def set_timesteps(self, num_inference_steps, device: Union[str, torch.device] = None):",
            "+        self.timesteps = torch.linspace(1, self.config.sampling_eps, num_inference_steps, device=device)",
            "",
            "def step_pred(self, score, x, t, generator=None):",
            "if self.timesteps is None:"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3533,
        "change": [
            "class DeepSpeedEngine(Module):",
            "model_dtype = torch.bfloat16",
            "",
            "if self._config.grad_accum_dtype == None:",
            "-            if model_dtype == torch.bfloat16:",
            "+            if model_dtype == torch.bfloat16 and not self.zero_optimization():",
            "grad_accum_dtype = torch.float32",
            "else:",
            "grad_accum_dtype = model_dtype"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Condition",
        "Action_Element": "Replace API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Device Management Error"
    },
    {
        "number": 3555,
        "change": [
            "def _create(name, pretrained=True, channels=3, classes=80, autoshape=True, verbo",
            "cfg = list((Path(__file__).parent / 'models').rglob(f'{name}.yaml'))[0]  # model.yaml path",
            "model = Model(cfg, channels, classes)  # create model",
            "if pretrained:",
            "-                attempt_download(fname)  # download if not found locally",
            "-                ckpt = torch.load(fname, map_location=torch.device('cpu'))  # load",
            "+                ckpt = torch.load(attempt_download(fname), map_location=torch.device('cpu'))  # load",
            "msd = model.state_dict()  # model state_dict",
            "csd = ckpt['model'].float().state_dict()  # checkpoint state_dict as FP32",
            "csd = {k: v for k, v in csd.items() if msd[k].shape == v.shape}  # filter"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Null Reference Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Null Reference Error"
    },
    {
        "number": 3559,
        "change": [
            "class Model(ModelDesc):",
            "# For visualization in tensorboard",
            "padded1 = tf.pad(sampled1, [[0, 0], [HALF_DIFF, HALF_DIFF], [HALF_DIFF, HALF_DIFF], [0, 0]])",
            "padded2 = tf.pad(sampled2, [[0, 0], [HALF_DIFF, HALF_DIFF], [HALF_DIFF, HALF_DIFF], [0, 0]])",
            "-        img_orig = tf.concat(1, [image[:, :, :, 0], image[:, :, :, 1]])  # b x 2h  x w",
            "-        transform1 = tf.concat(1, [padded1[:, :, :, 0], padded1[:, :, :, 1]])",
            "-        transform2 = tf.concat(1, [padded2[:, :, :, 0], padded2[:, :, :, 1]])",
            "-        stacked = tf.concat(2, [img_orig, transform1, transform2], 'viz')",
            "+        img_orig = tf.concat_v2([image[:, :, :, 0], image[:, :, :, 1]], 1)  # b x 2h  x w",
            "+        transform1 = tf.concat_v2([padded1[:, :, :, 0], padded1[:, :, :, 1]], 1)",
            "+        transform2 = tf.concat_v2([padded2[:, :, :, 0], padded2[:, :, :, 1]], 1)",
            "+        stacked = tf.concat_v2([img_orig, transform1, transform2], 2, 'viz')",
            "tf.summary.image('visualize',",
            "tf.expand_dims(stacked, -1), max_images=30)",
            "",
            "-        sampled = tf.concat(3, [sampled1, sampled2], 'sampled_concat')",
            "+        sampled = tf.concat_v2([sampled1, sampled2], 3, 'sampled_concat')",
            "logits = (LinearWrap(sampled)",
            ".apply(symbf.batch_flatten)",
            ".FullyConnected('fc1', out_dim=256, nl=tf.nn.relu)"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 3567,
        "change": [
            "def BatchNorm(x, use_local_stat=None, decay=0.9, epsilon=1e-5):",
            "",
            "n_out = shape[-1]  # channel",
            "assert n_out is not None",
            "-    beta = tf.get_variable('beta', [n_out])",
            "+    beta = tf.get_variable('beta', [n_out],",
            "+            initializer=tf.zeros_initializer)",
            "gamma = tf.get_variable('gamma', [n_out],",
            "-        initializer=tf.ones_initializer)",
            "+            initializer=tf.ones_initializer)",
            "",
            "if len(shape) == 2:",
            "batch_mean, batch_var = tf.nn.moments(x, [0], keep_dims=False)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3569,
        "change": [
            "def densenet_block(incoming, nb_layers, growth, bottleneck=True,",
            "\"\"\"",
            "densenet = incoming",
            "",
            "-    for i in range(nb_layers):",
            "+    with tf.variable_scope(scope, default_name=name, values=[incoming],",
            "+                           reuse=reuse) as scope:",
            "",
            "-        with tf.variable_scope(scope, default_name=name, values=[incoming],",
            "-                               reuse=reuse) as scope:",
            "+        for i in range(nb_layers):",
            "",
            "# Identity",
            "conn = densenet"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3573,
        "change": [
            "class BertForQuestionAnswering(nn.Module):",
            "def compute_loss(logits, positions):",
            "max_position = positions.max().item()",
            "one_hot = torch.FloatTensor(batch_size, max(max_position, seq_length) +1, device=input_ids.device).zero_()",
            "-                one_hot = one_hot.scatter(1, positions, 1)",
            "+                one_hot = one_hot.scatter(1, positions.cpu(), 1) # Second argument need to be LongTensor and not cuda.LongTensor",
            "one_hot = one_hot[:, :seq_length]",
            "log_probs = nn.functional.log_softmax(logits, dim = -1).view(batch_size, seq_length)",
            "loss = -torch.mean(torch.sum(one_hot*log_probs), dim = -1)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 3585,
        "change": [
            "class CrossViT(nn.Module):",
            "",
            "# NOTE: was before branch token section, move to here to assure all branch token are before layer norm",
            "xs = [norm(xs[i]) for i, norm in enumerate(self.norm)]",
            "-        return [xo[:, 0] for xo in xs]",
            "+        return xs",
            "",
            "def forward(self, x):",
            "xs = self.forward_features(x)",
            "-        ce_logits = [head(xs[i]) for i, head in enumerate(self.head)]",
            "+        ce_logits = [head(xs[i][:, 0]) for i, head in enumerate(self.head)]",
            "if not isinstance(self.head[0], nn.Identity):",
            "ce_logits = torch.mean(torch.stack(ce_logits, dim=0), dim=0)",
            "return ce_logits"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 3598,
        "change": [
            "def coalesce(edge_index, edge_attr=None, num_nodes=None):",
            "_, perm = unique(index)",
            "edge_index = edge_index[:, perm]",
            "else:",
            "-        sparse = getattr(torch.sparse, edge_attr.type().split('.')[-1])",
            "+        t = torch.cuda if edge_attr.is_cuda else torch",
            "+        sparse = getattr(t.sparse, edge_attr.type().split('.')[-1])",
            "n = num_nodes",
            "size = torch.Size([n, n] + list(edge_attr.size())[1:])",
            "adj = sparse(edge_index, edge_attr, size).coalesce()"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 3616,
        "change": [
            "def md5sum(filename):",
            "",
            "",
            "def switch_mps_device(model_name, device):",
            "-    if model_name not in MPS_SUPPORT_MODELS and (",
            "-        device == \"mps\" or device == torch.device(\"mps\")",
            "-    ):",
            "+    if model_name not in MPS_SUPPORT_MODELS and str(device) == \"mps\":",
            "logger.info(f\"{model_name} not support mps, switch to cpu\")",
            "return torch.device(\"cpu\")",
            "return device"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3623,
        "change": [
            "class ImagePreprocessingPass(unittest.TestCase):",
            "x4 = mb.add(x=x1, y=x3)",
            "return mb.relu(x=x4)",
            "",
            "-        proto = converter._convert(prog, inputs=[ImageType(name=\"x\", shape=(10, 20, 30, 3), channel_first=False)], convert_from=\"mil\", convert_to=\"nn_proto\")",
            "-        model = models.MLModel(proto)",
            "-        assert model is not None",
            "-        assert len(model._spec.neuralNetwork.layers) == 3",
            "+        mlmodel = ct.convert(prog,",
            "+            inputs=[ImageType(name=\"x\", shape=(10, 20, 30, 3),",
            "+              channel_first=False)],",
            "+            source=\"mil\", convert_to=\"nn_proto\")",
            "+        assert mlmodel is not None",
            "+        assert len(mlmodel.get_spec().neuralNetwork.layers) == 3"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 3633,
        "change": [
            "def add_dataset_args(parser, train=False, gen=False):",
            "return group",
            "",
            "",
            "-def add_distributed_training_args(parser):",
            "+def add_distributed_training_args(parser, default_world_size=None):",
            "group = parser.add_argument_group(\"Distributed training\")",
            "# fmt: off",
            "+    if default_world_size is None:",
            "+        default_world_size = max(1, torch.cuda.device_count())",
            "group.add_argument('--distributed-world-size', type=int, metavar='N',",
            "-                       default=max(1, torch.cuda.device_count()),",
            "+                       default=default_world_size,",
            "help='total number of GPUs across all nodes (default: all visible GPUs)')",
            "group.add_argument('--distributed-rank', default=0, type=int,",
            "help='rank of the current worker')"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3660,
        "change": [
            "class OpenSlr(datasets.GeneratorBasedBuilder):",
            "# set absolute path for audio file",
            "path = os.path.join(path_to_datas[i], f\"{filename}.wav\")",
            "counter += 1",
            "-                        yield counter, {\"path\": path, \"sentence\": sentence}",
            "+                        yield counter, {\"path\": path, \"audio\": path, \"sentence\": sentence}"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 3662,
        "change": [
            "def find_homography_dlt(",
            "U, S, V = torch.svd(A)",
            "except:",
            "warnings.warn('SVD did not converge', RuntimeWarning)",
            "-        return torch.empty((points1_norm.size(0), 3, 3), device=points1.device)",
            "+        return torch.empty((points1_norm.size(0), 3, 3), device=device, dtype=dtype)",
            "",
            "H = V[..., -1].view(-1, 3, 3)",
            "H = transform2.inverse() @ (H @ transform1)"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Return Warning|Data Conversion Error"
    },
    {
        "number": 3686,
        "change": [
            "class ESPnetASRMixModel(AbsESPnetModel):",
            "ignore_label=self.ignore_id,",
            ")",
            ")",
            "-        loss_att = torch.mean(loss_att)",
            "+        loss_att = torch.stack(loss_att, dim=0).mean()",
            "acc_att = np.mean(acc_att)",
            "",
            "# Compute cer/wer using attention-decoder"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Algorithm Error"
    },
    {
        "number": 3693,
        "change": [
            "class RagConfig(PretrainedConfig):",
            "decoder_config = kwargs.pop(\"generator\")",
            "decoder_model_type = decoder_config.pop(\"model_type\")",
            "",
            "-        from .configuration_auto import AutoConfig",
            "+        from ..auto.configuration_auto import AutoConfig",
            "",
            "self.question_encoder = AutoConfig.for_model(question_encoder_model_type, **question_encoder_config)",
            "self.generator = AutoConfig.for_model(decoder_model_type, **decoder_config)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 3697,
        "change": [
            "TENSOR_CLASS_NAMES = (",
            "\"Tensor\",",
            ")",
            "",
            "-ST = TypeVar(\"ST\")",
            "+ST = t.TypeVar(\"ST\")",
            "",
            "",
            "-def _isinstance_wrapper(obj: ST, sobj: Union[str, type, Sequence]) -> bool:",
            "+def _isinstance_wrapper(obj: ST, sobj: t.Union[str, type, t.Sequence]) -> bool:",
            "\"\"\"",
            "`isinstance` wrapper to check tensor spec"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 3705,
        "change": [
            "class WaveNet(object):",
            "The variables are all scoped to the given name.",
            "'''",
            "with tf.variable_scope(name):",
            "-            input_batch = self.encode(input_batch)",
            "+            input_batch = mu_law_encode(input_batch,",
            "+                                        self.quantization_channels)",
            "encoded = self._one_hot(input_batch)",
            "raw_output = self._create_network(encoded)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 3706,
        "change": [
            "def tensordot(",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "# find the type to promote to",
            "-    dtype = torch.promote_types(x1.dtype, x2.dtype)",
            "+    dtype = ivy.as_native_dtype(ivy.promote_types(x1.dtype, x2.dtype))",
            "# type conversion to one that torch.tensordot can work with",
            "x1, x2 = x1.type(torch.float32), x2.type(torch.float32)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 3724,
        "change": [
            "def test_train_step_epoch_end_scalar(tmpdir):",
            "train_step_out = out.training_step_output_for_epoch_end",
            "assert len(train_step_out) == 1",
            "train_step_out = train_step_out[0][0]",
            "-    assert isinstance(train_step_out, torch.Tensor)",
            "-    assert train_step_out.item() == 171",
            "+    assert isinstance(train_step_out['minimize'], torch.Tensor)",
            "+    assert train_step_out['minimize'].item() == 171",
            "",
            "# make sure the optimizer closure returns the correct things",
            "opt_closure_result = trainer.train_loop.training_step_and_backward("
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Condition",
        "Action_Element": "Replace API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 3780,
        "change": [
            "class OneHotCategorical(Distribution):",
            "sample. The last dimension is used for the one-hot encoding.",
            ":rtype: torch.autograd.Variable.",
            "\"\"\"",
            "-        return Variable(torch.stack([t.expand_as(self.ps) for t in torch_eye(*self.event_shape())]))",
            "+        result = torch.stack([t.expand_as(self.ps) for t in torch_eye(*self.event_shape())])",
            "+        if self.ps.is_cuda:",
            "+            result = result.cuda(self.ps.get_device())",
            "+        return Variable(result)",
            "",
            "def analytic_mean(self):",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 3788,
        "change": [
            "def bidirectional_rnn(incoming, rnncell_fw, rnncell_bw, return_seq=False,",
            "tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, outputs[-1])",
            "",
            "if dynamic:",
            "-        outputs = tf.transpose(tf.pack(outputs), [1, 0, 2])",
            "-        o = advanced_indexing_op(outputs, sequence_length)",
            "+        if return_seq:",
            "+            o = outputs",
            "+        else:",
            "+            outputs = tf.transpose(tf.pack(outputs), [1, 0, 2])",
            "+            o = advanced_indexing_op(outputs, sequence_length)",
            "else:",
            "o = outputs if return_seq else outputs[-1]"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3813,
        "change": [
            "\"\\n\",",
            "\"# For evaluation we use exactly normalized rather than\\n\",",
            "\"# approximately normalized.\\n\",",
            "-        \"sts_encode1 = tf.nn.l2_normalize(embed(sts_input1))\\n\",",
            "-        \"sts_encode2 = tf.nn.l2_normalize(embed(sts_input2))\\n\",",
            "-        \"sim_scores = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)\"",
            "+        \"sts_encode1 = tf.nn.l2_normalize(embed(sts_input1), axis=1)\\n\",",
            "+        \"sts_encode2 = tf.nn.l2_normalize(embed(sts_input2), axis=1)\\n\",",
            "+        \"sim_scores = -tf.acos(tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1))\"",
            "]",
            "},",
            "{"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Algorithm Error"
    },
    {
        "number": 3831,
        "change": [
            "class TFFastSpeech2(TFFastSpeech):",
            "duration_outputs = self.duration_predictor(",
            "[last_encoder_hidden_states, speaker_ids, attention_mask]",
            ")  # [batch_size, length]",
            "-        duration_outputs = tf.math.exp(duration_outputs) - 1.0",
            "+        duration_outputs = tf.nn.relu(tf.math.exp(duration_outputs) - 1.0)",
            "duration_outputs = tf.cast(",
            "tf.math.round(duration_outputs * speed_ratios), tf.int32",
            ")"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Null Reference Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Null Reference Error"
    },
    {
        "number": 3849,
        "change": [
            "floor_divide.support_native_out = True",
            "",
            "",
            "def floormod(",
            "-    x: torch.Tensor, y: torch.Tensor, *, out: Optional[torch.Tensor] = None",
            "+    x: torch.Tensor, y: torch.Tensor, /, *, out: Optional[torch.Tensor] = None",
            ") -> torch.Tensor:",
            "+    x, y = ivy.promote_types_of_inputs(x, y)",
            "return x % y"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 3880,
        "change": [
            "def _prepare_output_docstrings(output_type, config_class):",
            "",
            "# Add the return introduction",
            "full_output_type = f\"{output_type.__module__}.{output_type.__name__}\"",
            "-    intro = RETURN_INTRODUCTION.format(full_output_type=full_output_type, config_class=config_class)",
            "+    intro = TF_RETURN_INTRODUCTION if output_type.__name__.startswith(\"TF\") else PT_RETURN_INTRODUCTION",
            "+    intro = intro.format(full_output_type=full_output_type, config_class=config_class)",
            "return intro + docstrings"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 3915,
        "change": [
            "class RolloutWorker(EvaluatorInterface, ParallelIteratorWorker):",
            "policy_config = policy_config or {}",
            "if (tf and policy_config.get(\"eager\")",
            "and not policy_config.get(\"no_eager_on_workers\")):",
            "-            tf.enable_eager_execution()",
            "+            # This check is necessary for certain all-framework tests that",
            "+            # use tf's eager_mode() context generator.",
            "+            if not tf.executing_eagerly():",
            "+                tf.enable_eager_execution()",
            "",
            "if log_level:",
            "logging.getLogger(\"ray.rllib\").setLevel(log_level)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3947,
        "change": [
            "class Model(object):",
            "",
            "elif action_spec['type'] == 'float':",
            "if 'min_value' in action_spec:",
            "-                    exploration = tf.clip_by_value(",
            "+                    exploration_value = tf.clip_by_value(",
            "t=exploration_value,",
            "clip_value_min=action_spec['min_value'],",
            "clip_value_max=action_spec['max_value']",
            ")",
            "",
            "-                action += tf.reshape(exploration, tf.shape(action))",
            "+                action += tf.reshape(exploration_value, tf.shape(action))",
            "",
            "return action"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Deprecation Management Error"
    },
    {
        "number": 3960,
        "change": [
            "class TestRandomPerspective:",
            "assert out_perspective[0].shape == x_data.shape",
            "assert out_perspective[1].shape == (1, 3, 3)",
            "assert_allclose(out_perspective[0], x_data)",
            "-        assert_allclose(out_perspective[1], torch.eye(3, device=device))",
            "+        assert_allclose(out_perspective[1], torch.eye(3, device=device)[None])",
            "",
            "def test_transform_module_should_return_expected_transform(self, device):",
            "torch.manual_seed(0)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 3963,
        "change": [
            "def average_grads(all_grads):",
            "for grad_and_vars in zip(*all_grads):",
            "# Ngpu * 2",
            "v = grad_and_vars[0][1]",
            "-            all_grads = [g for (g, _) in grad_and_vars]",
            "+            grads = [g for (g, _) in grad_and_vars]",
            "",
            "with tf.device(v.device):       # colocate summed grad with var",
            "grad = tf.multiply(",
            "-                    tf.add_n(all_grads), 1.0 / nr_tower)",
            "+                    tf.add_n(grads), 1.0 / nr_tower)",
            "ret.append((grad, v))",
            "return ret"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3982,
        "change": [
            "from ivy.container import Container",
            "",
            "",
            "def variable(x):",
            "-    with ivy.dev(x, as_native=True):",
            "+    with tf.device(ivy.dev(x, as_native=True)):",
            "return tf.Variable(x, trainable=True)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 3992,
        "change": [
            "class Deterministic(TFActionDistribution):",
            "return self.inputs",
            "",
            "@override(TFActionDistribution)",
            "-    def sampled_action_logp(self):",
            "-        return 0.0",
            "+    def logp(self, x):",
            "+        return tf.zeros_like(self.inputs)",
            "",
            "@override(TFActionDistribution)",
            "def _build_sample_op(self):"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Null Reference Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Null Reference Error"
    },
    {
        "number": 4000,
        "change": [
            "def test_cholesky_transform(batch_shape, dim, transform):",
            "assert_close(log_det, torch.slogdet(jacobian)[1])",
            "",
            "assert log_det.shape == batch_shape",
            "-    assert_close(y, x_mat.cholesky())",
            "+    assert_close(y, torch.linalg.cholesky(x_mat))",
            "assert_close(transform.inv(y), x_mat)"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 4025,
        "change": [
            "class SimpleTaggerTest(AllenNlpTestCase):",
            "training_arrays = self.dataset.as_arrays()",
            "",
            "# TODO(Mark): clean this up once the Trainer is finalised.",
            "-        sequence = training_arrays[\"tokens\"][0]",
            "+        sequence = training_arrays[\"tokens\"][\"tokens\"]",
            "tags = training_arrays[\"tags\"]",
            "-        training_arrays = {\"tokens\": Variable(torch.from_numpy(sequence)),  # pylint: disable=no-member",
            "+        training_arrays = {\"tokens\": {\"tokens\": Variable(torch.from_numpy(sequence))},  # pylint: disable=no-member",
            "\"tags\": Variable(torch.from_numpy(tags))}  # pylint: disable=no-member",
            "_ = self.model.forward(**training_arrays)",
            "",
            "def test_tag_returns_distributions_per_token(self):",
            "-        text = TextField([\"This\", \"is\", \"a\", \"sentence\"], token_indexers=[SingleIdTokenIndexer()])",
            "+        text = TextField([\"This\", \"is\", \"a\", \"sentence\"], token_indexers={\"tokens\": SingleIdTokenIndexer()})",
            "output = self.model.tag(text)",
            "possible_tags = self.vocab.get_index_to_token_vocabulary(\"tags\").values()",
            "for tag in output[\"tags\"]:"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 4040,
        "change": [
            "def main():",
            "global_step += 1",
            "",
            "# Save a trained model",
            "-        logger.info(\"** ** * Saving fine - tuned model ** ** * \")",
            "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self",
            "output_model_file = os.path.join(args.output_dir, WEIGHTS_NAME)",
            "output_config_file = os.path.join(args.output_dir, CONFIG_NAME)",
            "-        if args.do_train:",
            "+        if args.do_train and torch.distributed.get_rank() == 0:",
            "+            logger.info(\"** ** * Saving fine - tuned model ** ** * \")",
            "torch.save(model_to_save.state_dict(), output_model_file)",
            "model_to_save.config.to_json_file(output_config_file)",
            "tokenizer.save_vocabulary(args.output_dir)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 4067,
        "change": [
            "def triu_inverse(x):",
            "B_Dinv = B / x.bottom_diag.unsqueeze(-2)",
            "",
            "identity = torch.eye(head_size, dtype=A.dtype, device=A.device)",
            "-    top_left = torch.triangular_solve(identity, A, upper=True)[0]",
            "+    top_left = torch.linalg.solve_triangular(A, identity, upper=True)",
            "top_right = -top_left.matmul(B_Dinv)  # complexity: head_size^2 x N",
            "top = torch.cat([top_left, top_right], -1)",
            "bottom_diag = x.bottom_diag.reciprocal()"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 4068,
        "change": [
            "def train():",
            "",
            "# Compute loss",
            "loss, loss_items = compute_loss(pred, targets, model)",
            "+            if torch.isnan(loss):",
            "+                print('WARNING: nan loss detected, skipping batch ', loss_items)",
            "+                continue",
            "",
            "# Scale loss by nominal batch_size of 64",
            "loss *= batch_size / 64"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Return Warning|Algorithm Error"
    },
    {
        "number": 4070,
        "change": [
            "def concat(",
            "xs = list(xs)",
            "highest_dtype = xs[0].dtype",
            "for i in xs:",
            "-        highest_dtype = tf.experimental.numpy.promote_types(highest_dtype, i.dtype)",
            "+        highest_dtype = ivy.as_native_dtype(ivy.promote_types(highest_dtype, i.dtype))",
            "",
            "for i in range(len(xs)):",
            "if is_axis_none:"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 4072,
        "change": [
            "else:",
            "version_str += f'+{git_hash}'",
            "",
            "torch_version = \".\".join([TORCH_MAJOR, TORCH_MINOR])",
            "-cuda_version = \".\".join(torch.version.cuda.split('.')[:2])",
            "+# Set cuda_version to 0.0 if cpu-only",
            "+cuda_version = \"0.0\"",
            "+if torch.version.cuda is not None:",
            "+    cuda_version = \".\".join(torch.version.cuda.split('.')[:2])",
            "torch_info = {\"version\": torch_version, \"cuda_version\": cuda_version}",
            "",
            "print(f\"version={version_str}, git_hash={git_hash}, git_branch={git_branch}\")"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 4084,
        "change": [
            "class TestElmoTokenRepresentation(ElmoTestCase):",
            "for k in range(10):",
            "char_indices = indices[\"elmo\"][(k * 50):((k + 1) * 50)]",
            "sentences.append(",
            "-                    indexer.pad_token_sequence(",
            "+                    indexer.as_padded_tensor(",
            "{'key': char_indices}, desired_num_tokens={'key': 50}, padding_lengths={}",
            ")['key']",
            ")",
            "-        batch = torch.from_numpy(numpy.array(sentences))",
            "+        batch = torch.stack(sentences)",
            "",
            "elmo_token_embedder = _ElmoCharacterEncoder(self.options_file, self.weight_file)",
            "elmo_token_embedder_output = elmo_token_embedder(batch)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 4086,
        "change": [
            "def multiclass_nms(multi_bboxes, multi_scores, score_thr, nms_cfg, max_num=-1):",
            "else:",
            "_bboxes = multi_bboxes[cls_inds, i * 4:(i + 1) * 4]",
            "_scores = multi_scores[cls_inds, i]",
            "+        if score_factors is not None:",
            "+            _scores *= score_factors[cls_inds]",
            "cls_dets = torch.cat([_bboxes, _scores[:, None]], dim=1)",
            "cls_dets, _ = nms_op(cls_dets, **nms_cfg_)",
            "-        cls_labels = multi_bboxes.new_full(",
            "-            (cls_dets.shape[0], ), i - 1, dtype=torch.long)",
            "+        cls_labels = multi_bboxes.new_full((cls_dets.shape[0], ),",
            "+                                           i - 1,",
            "+                                           dtype=torch.long)",
            "bboxes.append(cls_dets)",
            "labels.append(cls_labels)",
            "if bboxes:"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 4087,
        "change": [
            "class CommonTestCases:",
            "model = model_class(config)",
            "self.assertIsInstance(",
            "model.get_input_embeddings(),",
            "-                    torch.nn.Embedding",
            "+                    (torch.nn.Embedding, AdaptiveEmbedding)",
            ")",
            "model.set_input_embeddings(torch.nn.Embedding(10, 10))",
            "x = model.get_output_embeddings()"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 4092,
        "change": [
            "\"@config_enumerate\\n\",",
            "\"def model(data, num_components=3):\\n\",",
            "\"    print('Running model with {} data points'.format(len(data)))\\n\",",
            "-    \"    p = pyro.sample(\\\"p\\\", dist.Dirichlet(0.5 * torch.ones(3)))\\n\",",
            "+    \"    p = pyro.sample(\\\"p\\\", dist.Dirichlet(0.5 * torch.ones(num_components)))\\n\",",
            "\"    scale = pyro.sample(\\\"scale\\\", dist.LogNormal(0, num_components))\\n\",",
            "\"    with pyro.plate(\\\"components\\\", num_components):\\n\",",
            "\"        loc = pyro.sample(\\\"loc\\\", dist.Normal(0, 10))\\n\","
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 4100,
        "change": [
            "class DQNTorchModel(TorchModelV2, nn.Module):",
            "if self.num_atoms > 1:",
            "# Distributional Q-learning uses a discrete support z",
            "# to represent the action value distribution",
            "-            z = torch.range(0.0, self.num_atoms - 1, dtype=torch.float32)",
            "+            z = torch.range(",
            "+                0.0, self.num_atoms - 1,",
            "+                dtype=torch.float32).to(action_scores.device)",
            "z = self.v_min + \\",
            "z * (self.v_max - self.v_min) / float(self.num_atoms - 1)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 4119,
        "change": [
            "class LocalMetricTest(parameterized.TestCase):",
            "@slow",
            "def test_load_real_metric(self, metric_name):",
            "doctest.ELLIPSIS_MARKER = \"[...]\"",
            "-        metric_module = importlib.import_module(datasets.load.prepare_module(os.path.join(\"metrics\", metric_name))[0])",
            "+        metric_module = importlib.import_module(",
            "+            datasets.load.metric_module_factory(os.path.join(\"metrics\", metric_name)).module_path",
            "+        )",
            "# run doctest",
            "with self.use_local_metrics():",
            "results = doctest.testmod(metric_module, verbose=True, raise_on_error=True)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 4140,
        "change": [
            "class ModelTesterMixin:",
            "model.to(torch_device)",
            "model.eval()",
            "with torch.no_grad():",
            "-                outputs = model(**inputs_dict)",
            "+                outputs = model(**self._prepare_for_class(inputs_dict, model_class))",
            "attentions = outputs[-1]",
            "self.assertEqual(model.config.output_hidden_states, False)",
            "self.assertEqual(len(attentions), self.model_tester.num_hidden_layers)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Device Management Error"
    },
    {
        "number": 4189,
        "change": [
            "class Embed(base.AbstractModule):",
            "regularizer=self._regularizers.get(self.EMBEDDINGS, None),",
            "trainable=self._trainable)",
            "",
            "+    # On the backwards pass, we want to convert the gradient from",
            "+    # indexed-slices to a regular tensor before sending it back to the",
            "+    # parameter server. This avoids excess computation on the parameter server.",
            "+",
            "+    embeddings = util.convert_gradient_to_tensor(self._embeddings)",
            "+",
            "# Lookup embeddings",
            "-    return tf.nn.embedding_lookup(",
            "-        self._embeddings, ids, name=\"embedding_lookup\")",
            "+    return tf.nn.embedding_lookup(embeddings, ids, name=\"embedding_lookup\")",
            "",
            "@property",
            "def vocab_size(self):"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 4192,
        "change": [
            "def test_hook(history):",
            "tf.summary.scalar('c1', c1)",
            "summary_op = tf.summary.merge_all()",
            "",
            "-        hook = wandb_tensorflow.WandbHook(summary_op)",
            "+        hook = wandb_tensorflow.WandbHook(summary_op, history=history)",
            "with tf.train.MonitoredTrainingSession(hooks=[hook]) as sess:",
            "summary, acc = sess.run([summary_op, c1])",
            "",
            "assert wandb_tensorflow.tf_summary_to_dict(summary) == {'c1': 42.0}",
            "+    print(history.rows)",
            "+    # TODO(adrian): there is still some kind of bug here where the history",
            "+    # is being shared with another test that manages to add rows before this one.",
            "assert history.rows[0]['c1'] == 42.0"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Null Reference Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Null Reference Error"
    },
    {
        "number": 4214,
        "change": [
            "class LightweightConvolution2D(nn.Module):",
            "# convolution along frequency axis",
            "weight_f = F.softmax(self.weight_f, dim=-1)",
            "weight_f = F.dropout(weight_f, self.dropout_rate, training=self.training)",
            "-        weight_new = torch.zeros(B * T, 1, self.kernel_size, device=x.device).copy_(weight_f)",
            "+        weight_new = torch.zeros(B * T, 1, self.kernel_size, device=x.device, dtype=x.dtype).copy_(weight_f)",
            "xf = F.conv1d(x.view(1, B * T, C), weight_new, padding=self.padding_size, groups=B * T).view(B, T, C)",
            "",
            "# lightconv"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 4221,
        "change": [
            "class ViltEmbeddings(nn.Module):",
            "x = x.flatten(2).transpose(1, 2)",
            "# Set `device` here, otherwise `patch_index` will always be on `CPU` and will fail near the end for torch>=1.13",
            "patch_index = torch.stack(",
            "-            torch.meshgrid(torch.arange(x_mask.shape[-2]), torch.arange(x_mask.shape[-1]), indexing=\"ij\"), dim=-1",
            "+            meshgrid(torch.arange(x_mask.shape[-2]), torch.arange(x_mask.shape[-1]), indexing=\"ij\"), dim=-1",
            ").to(device=x_mask.device)",
            "patch_index = patch_index[None, None, :, :, :]",
            "patch_index = patch_index.expand(x_mask.shape[0], x_mask.shape[1], -1, -1, -1)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 4247,
        "change": [
            "def test_multinomial(",
            "):",
            "prob_dtype, batch_size, population_size, num_samples, replace, probs = everything",
            "# tensorflow does not support multinomial without replacement",
            "-    if backend_fw == \"tensorflow\":",
            "-        assume(replace is True)",
            "+    if backend_fw == ivy.functional.backends.tensorflow:",
            "+        assume(replace)",
            "",
            "def call():",
            "return helpers.test_function("
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Device Management Error"
    },
    {
        "number": 4249,
        "change": [
            "class MonotoneConvexTest(tf.test.TestCase):",
            "test_time = tf.constant([1.1, 2.7], dtype=dtype)",
            "interpolated, _ = monotone_convex.interpolate(test_time, interval_values,",
            "interval_times)",
            "-    gradient_1y = self.evaluate(tf.gradients(interpolated[0], knot_1y)[0])",
            "-    gradient_zero = self.evaluate(tf.gradients(interpolated[1], knot_1y)[0])",
            "+    gradient_1y = self.evaluate(tf.convert_to_tensor(",
            "+        tf.gradients(interpolated[0], knot_1y)[0]))",
            "+    gradient_zero = self.evaluate(tf.convert_to_tensor(",
            "+        tf.gradients(interpolated[1], knot_1y)[0]))",
            "+",
            "self.assertAlmostEqual(gradient_1y[0], 0.42)",
            "self.assertAlmostEqual(gradient_zero[0], 0.0)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 4258,
        "change": [
            "def train(args):",
            "rnn = RNNLM(args.n_vocab, args.layer, args.unit, args.type, args.dropout_rate)",
            "model = ClassifierWithState(rnn)",
            "if args.ngpu > 0:",
            "-        model = torch.nn.DataParallel(model).cuda()",
            "+        model = torch.nn.DataParallel(model, device_ids=list(range(args.ngpu))).cuda()",
            "setattr(model, \"reporter\", model.module.reporter)",
            "gpu_id = 0",
            "else:"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 4269,
        "change": [
            "class PositionalEncoding(nn.Module):",
            "pe[:, 0::2] = torch.sin(position * div_term)",
            "pe[:, 1::2] = torch.cos(position * div_term)",
            "pe = pe.unsqueeze(0).transpose(0, 1)",
            "-        self.register_buffer('pe', pe)",
            "+        self.pe = nn.Parameter(pe, requires_grad=False)",
            "",
            "def forward(self, x):",
            "x = x + self.pe[:x.size(0), :]"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 4276,
        "change": [
            "class CTC(torch.nn.Module):",
            "# expected shape of seqLength x batchSize x alphabet_size",
            "dtype = ys_hat.dtype",
            "ys_hat = ys_hat.transpose(0, 1)",
            "-        if self.ctc_type == \"warpctc\":",
            "+        if self.ctc_type == \"warpctc\" or dtype == torch.float16:",
            "# warpctc only supports float32",
            "ys_hat = ys_hat.to(dtype=torch.float32)",
            "else:"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 4282,
        "change": [
            "class ExpectedRiskMinimization(DecoderTrainer[Callable[[StateType], torch.Tensor",
            "state.score,",
            "state.action_history):",
            "if self._normalize_by_length:",
            "-                    path_length = nn_util.new_variable_with_data(model_score,",
            "-                                                                 torch.Tensor([len(history)]))",
            "+                    path_length = Variable(model_score.data.new([len(history)]))",
            "model_score = model_score / path_length",
            "batch_scores[batch_index].append(model_score)",
            "return batch_scores"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 4290,
        "change": [
            "def test_load_no_dev_data_explicit(tasks_base_path):",
            "",
            "def test_multi_corpus(tasks_base_path):",
            "",
            "-    corpus_1 = flair.datasets.NER_GERMAN_GERMEVAL(tasks_base_path)",
            "+    corpus_1 = flair.datasets.ColumnCorpus(tasks_base_path  / \"germeval_14\", column_format={0: \"text\", 2: \"ner\"})",
            "",
            "corpus_2 = flair.datasets.ColumnCorpus(tasks_base_path / \"fashion\", column_format={0: \"text\", 2: \"ner\"})",
            "# get two corpora as one"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 4301,
        "change": [
            "def test_forward(use_token_averaged_energy, reduction_factor):",
            "es, elens = layer(xs, torch.LongTensor([384, 128]))",
            "assert es.shape[1] == max(elens)",
            "else:",
            "-        ds = torch.LongTensor([[3, 3, 1], [3, 0, 0]])",
            "+        ds = torch.LongTensor([[3, 3, 1], [3, 0, 0]]) // reduction_factor",
            "dlens = torch.LongTensor([3, 1])",
            "es, _ = layer(",
            "xs, torch.LongTensor([384, 128]), durations=ds, durations_lengths=dlens"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 4310,
        "change": [
            "class Loggers():",
            "if self.wandb:",
            "self.wandb.log({\"Labels\": [wandb.Image(str(x), caption=x.name) for x in paths]})",
            "",
            "-    def on_train_batch_end(self, ni, model, imgs, targets, paths, plots):",
            "+    def on_train_batch_end(self, ni, model, imgs, targets, paths, plots, sync_bn):",
            "# Callback runs on train batch end",
            "if plots:",
            "if ni == 0:",
            "-                with warnings.catch_warnings():",
            "-                    warnings.simplefilter('ignore')  # suppress jit trace warning",
            "-                    self.tb.add_graph(torch.jit.trace(de_parallel(model), imgs[0:1], strict=False), [])",
            "+                if not sync_bn:  # tb.add_graph() --sync known issue https://github.com/ultralytics/yolov5/issues/3754",
            "+                    with warnings.catch_warnings():",
            "+                        warnings.simplefilter('ignore')  # suppress jit trace warning",
            "+                        self.tb.add_graph(torch.jit.trace(de_parallel(model), imgs[0:1], strict=False), [])",
            "if ni < 3:",
            "f = self.save_dir / f'train_batch{ni}.jpg'  # filename",
            "Thread(target=plot_images, args=(imgs, targets, paths, f), daemon=True).start()"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 4311,
        "change": [
            "class Model:",
            "enc = tf.layers.max_pooling1d(enc, 2, 1, padding=\"same\")  # (N, T, K * E / 2)",
            "",
            "### Conv1D projections",
            "-            enc = conv1d(enc, hp.hidden_units // 2, 3, scope=\"conv1d_1\")  # (N, T, E/2)",
            "-            enc = normalize(enc, type=hp.norm_type, is_training=self.is_training, activation_fn=tf.nn.relu)",
            "-            enc = conv1d(enc, hp.hidden_units // 2, 3, scope=\"conv1d_2\")  # (N, T, E/2)",
            "+            enc = conv1d(enc, hp.hidden_units // 2, 3, scope=\"conv1d_1\", activation_fn=tf.nn.relu)  # (N, T, E/2)",
            "+            enc = normalize(enc, type=hp.norm_type, is_training=self.is_training)",
            "+            enc = conv1d(enc, hp.hidden_units // 2, 3, scope=\"conv1d_2\", activation_fn=None)  # (N, T, E/2)",
            "enc += prenet_out  # (N, T, E/2) # residual connections",
            "",
            "### Highway Nets"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Null Reference Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Null Reference Error"
    },
    {
        "number": 4314,
        "change": [
            "def build_targets(p, targets, model):",
            "tcls, tbox, indices, av = [], [], [], []",
            "reject, use_all_anchors = True, True",
            "gain = torch.ones(6, device=targets.device)  # normalized to gridspace gain",
            "+",
            "+    # m = list(model.modules())[-1]",
            "+    # for i in range(m.nl):",
            "+    #     anchor_vec = m.anchor_vec[i]",
            "multi_gpu = type(model) in (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel)",
            "for i, j in enumerate(model.yolo_layers):",
            "# get number of grid points and anchor vec for this yolo layer",
            "anchor_vec = model.module.module_list[j].anchor_vec if multi_gpu else model.module_list[j].anchor_vec",
            "",
            "# iou of targets-anchors",
            "-        gain[2:] = torch.tensor(p[i].shape)[[2, 3, 2, 3]]  # xyxy gain",
            "+        gain[2:] = torch.tensor(p[i].shape)[[3, 2, 3, 2]]  # xyxy gain",
            "t, a = targets * gain, []",
            "gwh = t[:, 4:6]",
            "if nt:"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 4318,
        "change": [
            "def linear_resample(x, num_samples, axis=-1):",
            "num_x_dims = len(x_shape)",
            "axis = axis % num_x_dims",
            "num_vals = x.shape[axis]",
            "-    if x.dtype not in ['float16','float32','float64']:",
            "-        x=tf.cast(x,tf.float32)",
            "+    if x.dtype not in [\"float16\", \"float32\", \"float64\"]:",
            "+        x = tf.cast(x, tf.float32)",
            "xp = tf.range(num_vals, dtype=tf.float32)",
            "x_coords = tf.range(num_samples, dtype=tf.float32) * (",
            "-                (num_vals - 1) / (num_samples - 1)",
            "+            (num_vals - 1) / (num_samples - 1)",
            ")",
            "else:",
            "xp = tf.range(num_vals, dtype=x.dtype)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 4340,
        "change": [
            "def split(data, batch):",
            "if data.x is not None:",
            "slices['x'] = node_slice",
            "else:",
            "-        data.num_nodes = torch.bincount(batch).tolist()",
            "-        slices['num_nodes'] = torch.arange(len(data.num_nodes) + 1)",
            "+        # Imitate `collate` functionality:",
            "+        data._num_nodes = torch.bincount(batch).tolist()",
            "+        data.num_nodes = batch.numel()",
            "if data.edge_attr is not None:",
            "slices['edge_attr'] = edge_slice",
            "if data.y is not None:"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 4350,
        "change": [
            "class CTRLModel(CTRLPreTrainedModel):",
            "inputs_embeds = self.w(input_ids)",
            "# inputs_embeds = embedded.unsqueeze(0) if len(input_ids.shape)<2 else embedded",
            "seq_len = input_ids.shape[-1]",
            "-        mask = torch.triu(torch.ones(seq_len, seq_len), 1).to(inputs_embeds.device)",
            "+        mask = torch.triu(torch.ones(seq_len + past_length, seq_len + past_length), 1).to(inputs_embeds.device)",
            "",
            "inputs_embeds *= np.sqrt(self.d_model_size)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 4370,
        "change": [
            "def test_is_small_dataset(",
            "dataset_size, config_max_in_memory_dataset_size, env_max_in_memory_dataset_size, monkeypatch",
            "):",
            "if config_max_in_memory_dataset_size != \"default\":",
            "-        monkeypatch.setattr(",
            "-            datasets.config, \"HF_MAX_IN_MEMORY_DATASET_SIZE_IN_BYTES\", config_max_in_memory_dataset_size",
            "-        )",
            "+        monkeypatch.setattr(datasets.config, \"IN_MEMORY_MAX_SIZE\", config_max_in_memory_dataset_size)",
            "",
            "-    max_in_memory_dataset_size = datasets.config.HF_MAX_IN_MEMORY_DATASET_SIZE_IN_BYTES",
            "+    max_in_memory_dataset_size = datasets.config.IN_MEMORY_MAX_SIZE",
            "if config_max_in_memory_dataset_size == \"default\":",
            "if env_max_in_memory_dataset_size:",
            "assert max_in_memory_dataset_size == env_max_in_memory_dataset_size"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 4378,
        "change": [
            "def _compute_equalized_tiles(interp_tiles: torch.Tensor, luts: torch.Tensor) ->",
            "tiles_equalized: torch.Tensor = torch.zeros_like(interp_tiles, dtype=torch.long)",
            "",
            "# compute the interpolation weights (shapes are 2 x TH x TW because they must be applied to 2 interp tiles)",
            "-    ih = torch.arange(2 * th - 1, -1, -1, device=interp_tiles.device).div(2. * th - 1)[None].T.expand(2 * th, tw)",
            "+    ih = torch.arange(2 * th - 1, -1, -1, device=interp_tiles.device).div(",
            "+        2. * th - 1)[None].transpose(-2, -1).expand(2 * th, tw)",
            "ih = ih.unfold(0, th, th).unfold(1, tw, tw)  # 2 x 1 x TH x TW",
            "iw = torch.arange(2 * tw - 1, -1, -1, device=interp_tiles.device).div(2. * tw - 1).expand(th, 2 * tw)",
            "iw = iw.unfold(0, th, th).unfold(1, tw, tw)  # 1 x 2 x TH x TW"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 4381,
        "change": [
            "class DeepSpeedEngine(Module):",
            "if self.zero_optimization_partition_weights() and any(",
            "[hasattr(param,",
            "'ds_id') for param in self.module.parameters()]):",
            "-                assert all([param.dtype == torch.half for param in self.module.parameters()]), f\"Model must initialized in fp16 mode for ZeRO Stage 3.\"",
            "+                assert all([param.dtype == torch.half for param in self.module.parameters()]), \"fp16 is enabled but one or several model parameters have dtype that is not fp16\"",
            "self.module.half()",
            "else:",
            "-            assert all([param.dtype == torch.float for param in self.module.parameters()]), f\"fp16 is not enabled but one or several model parameters have dtype of fp16\"",
            "+            assert all([param.dtype == torch.float for param in self.module.parameters()]), \"fp16 is not enabled but one or several model parameters have dtype of fp16\"",
            "",
            "if not self.dont_change_device:",
            "self.module.to(self.device)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 4397,
        "change": [
            "class TrainerTrainLoopMixin(ABC):",
            "if self.reload_dataloaders_every_epoch:",
            "self.reset_train_dataloader(self.get_model())",
            "",
            "+        # track local dataloader so TPU can wrap each epoch",
            "+        train_dataloader = self.train_dataloader",
            "+",
            "# on TPU we have to wrap it under the ParallelLoader",
            "if self.use_tpu:",
            "device = xm.xla_device()",
            "-            self.train_dataloader = xla_pl.ParallelLoader(self.train_dataloader, [device])",
            "-            self.train_dataloader = self.train_dataloader.per_device_loader(device)",
            "+            train_dataloader = xla_pl.ParallelLoader(train_dataloader, [device])",
            "+            train_dataloader = train_dataloader.per_device_loader(device)",
            "",
            "# run epoch",
            "for batch_idx, batch in self.profiler.profile_iterable(",
            "-            enumerate(self.train_dataloader), \"get_train_batch\"",
            "+            enumerate(train_dataloader), \"get_train_batch\"",
            "):",
            "# stop epoch if we limited the number of training batches",
            "if batch_idx >= self.num_training_batches:"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 4407,
        "change": [
            "class LKJCorrCholesky(TorchDistribution):",
            "super().__init__(torch.Size(), torch.Size((d, d)), validate_args=validate_args)",
            "",
            "def sample(self, sample_shape=torch.Size()):",
            "-        y = self._gen.sample(sample_shape=self.batch_shape + sample_shape).detach()",
            "+        with torch.no_grad():",
            "+            y = self._gen.sample(sample_shape=sample_shape + self.batch_shape)",
            "z = y.mul(2).add(-1.0)",
            "return _vector_to_l_cholesky(z)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 4429,
        "change": [
            "def fit_circle_in_2d(",
            "n_provided = points2d.shape[0]",
            "if n_provided < 3:",
            "raise ValueError(f\"{n_provided} points are not enough to determine a circle\")",
            "-    solution = lstsq(design, rhs)",
            "-    center = solution[:2] / 2",
            "-    radius = torch.sqrt(solution[2] + (center ** 2).sum())",
            "+    solution = lstsq(design, rhs[:, None])",
            "+    center = solution[:2, 0] / 2",
            "+    radius = torch.sqrt(solution[2, 0] + (center ** 2).sum())",
            "if n_points > 0:",
            "if angles is not None:",
            "warnings.warn(\"n_points ignored because angles provided\")"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 4450,
        "change": [
            "def generate_audio_mask_noise(audio_values, audio_mask=None, mask_ratio=0.75, ma",
            "if mask_type == \"frame-level\":",
            "num_time_patches = seq_len // freq_len",
            "noise = (",
            "-            torch.rand(batch_size, num_time_patches).unsqueeze(-1).repeat(1, 1, freq_len).view(batch_size, seq_len)",
            "+            torch.rand(batch_size, num_time_patches, device=audio_values.device)",
            "+            .unsqueeze(-1)",
            "+            .repeat(1, 1, freq_len)",
            "+            .view(batch_size, seq_len)",
            ")  # noise in [0, 1]",
            "elif mask_type == \"patch-level\":",
            "-        noise = torch.rand(batch_size, seq_len)  # noise in [0, 1]",
            "+        noise = torch.rand(batch_size, seq_len, device=audio_values.device)  # noise in [0, 1]",
            "len_keep = int(seq_len * (1 - mask_ratio))",
            "return noise, len_keep"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 4456,
        "change": [
            "class TFCvtDropPath(tf.keras.layers.Layer):",
            "return x",
            "keep_prob = 1 - self.drop_prob",
            "shape = (tf.shape(x)[0],) + (1,) * (len(tf.shape(x)) - 1)",
            "-        random_tensor = keep_prob + tf.random.uniform(shape, 0, 1)",
            "+        random_tensor = keep_prob + tf.random.uniform(shape, 0, 1, dtype=self.compute_dtype)",
            "random_tensor = tf.floor(random_tensor)",
            "return (x / keep_prob) * random_tensor"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 4467,
        "change": [
            "class CLIPSegTextTransformer(nn.Module):",
            "# take features from the eot embedding (eot_token is the highest number in each sequence)",
            "# casting to torch.int for onnx compatibility: argmax doesn't support int64 inputs with opset 14",
            "pooled_output = last_hidden_state[",
            "-            torch.arange(last_hidden_state.shape[0], device=input_ids.device), input_ids.to(torch.int).argmax(dim=-1)",
            "+            torch.arange(last_hidden_state.shape[0], device=last_hidden_state.device),",
            "+            input_ids.to(dtype=torch.int, device=last_hidden_state.device).argmax(dim=-1),",
            "]",
            "",
            "if not return_dict:"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 4476,
        "change": [
            "def tversky_loss(input: torch.Tensor, target: torch.Tensor,",
            "# compute the actual dice score",
            "dims = (1, 2, 3)",
            "intersection = torch.sum(input_soft * target_one_hot, dims)",
            "-    fps = torch.sum(input_soft * (1. - target_one_hot), dims)",
            "-    fns = torch.sum((1. - input_soft) * target_one_hot, dims)",
            "+    fps = torch.sum(input_soft * (-target_one_hot + 1.), dims)",
            "+    fns = torch.sum((-input_soft + 1.) * target_one_hot, dims)",
            "",
            "numerator = intersection",
            "denominator = intersection + alpha * fps + beta * fns",
            "tversky_loss = numerator / (denominator + eps)",
            "-    return torch.mean(1. - tversky_loss)",
            "+    return torch.mean(-tversky_loss + 1.)",
            "",
            "",
            "class TverskyLoss(nn.Module):"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 4498,
        "change": [
            "class Trainer(object):",
            "last_optim_state = state.get(\"last_optimizer_state\", None)",
            "if last_optim_state == -1:",
            "master_path = re.sub(\"shard[0-9]+\", \"shard0\", filename)",
            "-                    last_optim_state = torch.load(master_path, map_location='cpu')['last_optimizer_state']",
            "+                    local_master_path = PathManager.get_local_path(master_path)",
            "+                    last_optim_state = torch.load(local_master_path, map_location='cpu')['last_optimizer_state']",
            "",
            "# If doing zero_sharding, do not broadcast global optimizer",
            "# state. Later we will broadcast sharded states to each rank"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 4507,
        "change": [
            "def finfo(type: Union[DType, str, tf.Tensor, tf.Variable]) -> Finfo:",
            "if isinstance(type, tf.Tensor):",
            "type = type.dtype",
            "if ivy.as_native_dtype(type) == tf.bfloat16:",
            "-        return Finfo(tf.experimental.numpy.finfo(tf.float32))",
            "+        return Finfo(Bfloat16Finfo())",
            "return Finfo(tf.experimental.numpy.finfo(ivy.as_native_dtype(type)))"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 4508,
        "change": [
            "def segment_diff(x,",
            "",
            "needs_fix = tf.scatter_nd(",
            "fix_indices,",
            "-        tf.reshape(tf.ones_like(fix_indices, dtype=tf.bool), [-1]),",
            "+        # Unfortunately, scatter_nd doesn't support bool on GPUs so we need to",
            "+        # do ints here and then convert to bool.",
            "+        tf.reshape(tf.ones_like(fix_indices, dtype=tf.int32), [-1]),",
            "shape=tf.shape(x))",
            "# If exclusive is False, then needs_fix means we need to replace the values",
            "# in raw_diffs at those locations with the values in x.",
            "+    needs_fix = tf.cast(needs_fix, dtype=tf.bool)",
            "if not exclusive:",
            "return tf.where(needs_fix, x, raw_diffs)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 4524,
        "change": [
            "class HardNet(nn.Module):",
            "# training totally unstable.",
            "return (x - mp.detach()) / (sp.detach() + eps)",
            "",
            "-    def forward(self, input: torch.Tensor) -> torch.Tensor:   # type: ignore",
            "+    def forward(self, input: torch.Tensor) -> torch.Tensor:",
            "x_norm: torch.Tensor = self._normalize_input(input)",
            "x_features: torch.Tensor = self.features(x_norm)",
            "x_out = x_features.view(x_features.size(0), -1)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 4528,
        "change": [
            "def do_test_log_likelihood(run,",
            "layer_key[0])])",
            "else:",
            "expected_mean_logstd = fc(",
            "-                        fc(obs_batch,",
            "-                           vars[\"_hidden_layers.0._model.0.weight\"]),",
            "-                        vars[\"_logits._model.0.weight\"])",
            "+                        fc(",
            "+                            obs_batch,",
            "+                            np.transpose(",
            "+                                vars[\"_hidden_layers.0._model.0.weight\"])),",
            "+                        np.transpose(vars[\"_logits._model.0.weight\"]))",
            "mean, log_std = np.split(expected_mean_logstd, 2, axis=-1)",
            "if logp_func is None:",
            "expected_logp = np.log(norm.pdf(a, mean, np.exp(log_std)))"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 4555,
        "change": [
            "class roibatchLoader(data.Dataset):",
            "# for ratio cross 1, we make it to be 1.",
            "target_ratio = 1",
            "",
            "-        self.ratio_list_batch[left_idx:(right_idx+1)] = target_ratio",
            "+        self.ratio_list_batch[left_idx:(right_idx+1)] = torch.tensor(target_ratio.astype(np.float64)) # trainset ratio list ,each batch is same number",
            "",
            "",
            "def __getitem__(self, index):"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 4561,
        "change": [
            "class CapsNet(object):",
            "assert self.masked_v.get_shape() == [cfg.batch_size, 1, 16, 1]",
            "# Method 2. masking with true label, default mode",
            "else:",
            "-                self.masked_v = tf.matmul(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, 10, 1)), transpose_a=True)",
            "+                # self.masked_v = tf.matmul(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, 10, 1)), transpose_a=True)",
            "+                self.masked_v = tf.multply(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, 10, 1)))",
            "self.v_length = tf.sqrt(tf.reduce_sum(tf.square(self.caps2), axis=2, keep_dims=True) + epsilon)",
            "",
            "# 2. Reconstructe the MNIST images with 3 FC layers"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 4563,
        "change": [
            "def shift_rgb(image: torch.Tensor, r_shift: torch.Tensor, g_shift: torch.Tensor,",
            "",
            "shifts = [r_shift, g_shift, b_shift]",
            "",
            "-    shifted = (image + torch.Tensor(shifts).view(1, 3, 1, 1).to(image)).clamp_(min=0, max=1)",
            "+    shifted = (image + torch.stack(shifts).view(-1, 3, 1, 1).to(image)).clamp_(min=0, max=1)",
            "",
            "return shifted"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 4564,
        "change": [
            "class TestImageFeatureEmbeddings(AllenNlpTestCase):",
            "super().__init__()",
            "",
            "self.image_embeddings = torch.nn.Linear(feature_size, embedding_size)",
            "-                self.image_location_embeddings = torch.nn.Linear(4, embedding_size)",
            "+                self.image_location_embeddings = torch.nn.Linear(4, embedding_size, bias=False)",
            "self.layer_norm = torch.nn.LayerNorm(embedding_size, eps=1e-12)",
            "self.dropout = torch.nn.Dropout(dropout)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 4585,
        "change": [
            "class BooleanAccuracy(Metric):",
            "",
            "# We want to skip predictions that are completely masked;",
            "# so we'll keep predictions that aren't.",
            "-            keep = mask.view(batch_size, -1).max(dim=1)[0].float()",
            "+            keep = mask.view(batch_size, -1).max(dim=1)[0]",
            "else:",
            "-            keep = torch.ones(batch_size, device=predictions.device).float()",
            "+            keep = torch.ones(batch_size, device=predictions.device).bool()",
            "",
            "predictions = predictions.view(batch_size, -1)",
            "gold_labels = gold_labels.view(batch_size, -1)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 4646,
        "change": [
            "class InvertedResidual(BaseModule):",
            "out = self.linear_conv(out)",
            "",
            "if self.with_res_shortcut:",
            "-                return x + out",
            "+                return x + self.drop_path(out)",
            "else:",
            "return out"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Null Reference Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Null Reference Error"
    },
    {
        "number": 4655,
        "change": [
            "torch_scatter = None",
            "def dev(x: torch.Tensor, as_native: bool = False) -> Union[ivy.Device, torch.device]:",
            "dv = x.device",
            "if as_native:",
            "-        return torch.device(dv.replace(\"gpu\", \"cuda\"))",
            "+        return torch.device(dv.type.replace(\"gpu\", \"cuda\"))",
            "return as_ivy_dev(dv)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Device Management Error"
    },
    {
        "number": 4708,
        "change": [
            "class Bernoulli(Distribution):",
            "self.shape = shape",
            "action_size = util.prod(self.shape)",
            "",
            "-        with tf.name_scope(name=scope):",
            "-            self.logit = Linear(size=action_size, bias=log(probability), scope='logit')",
            "+        self.logit = Linear(size=action_size, bias=log(probability), scope='logit')",
            "",
            "super(Bernoulli, self).__init__(scope, summary_labels)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 4715,
        "change": [
            "def adalam_core(",
            "final_matches, idxs, counts = torch.unique(final_matches, dim=0, return_inverse=True, return_counts=True)",
            "_, ind_sorted = torch.sort(idxs)",
            "cum_sum = counts.cumsum(0)",
            "-        cum_sum = torch.cat((torch.tensor([0]), cum_sum[:-1]))",
            "+        cum_sum = torch.cat((torch.tensor([0], dtype=cum_sum.dtype, device=cum_sum.device), cum_sum[:-1]))",
            "first_indicies = ind_sorted[cum_sum]",
            "accepted_dist = accepted_dist[first_indicies]",
            "if return_dist:"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 4743,
        "change": [
            "def execute_with_gradients(",
            "return grads",
            "",
            "if isinstance(y, ivy.NativeArray):",
            "-        grads = grad_func(torch.clone(y))",
            "+        grads = _set_duplicates(",
            "+            grad_func(torch.clone(y)), required_duplicate_index_chains",
            "+        )",
            "else:",
            "# ToDo: use functorch.jacrev if it fixes the issue with broken memory reference",
            "array_idxs = ivy.nested_argwhere(y, lambda x: ivy.is_native_array(x))"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 4780,
        "change": [
            "def _load_weights(model: VisionTransformer, checkpoint_path: str, prefix: str =",
            "model.pos_embed.copy_(pos_embed_w)",
            "model.norm.weight.copy_(_n2p(w[f'{prefix}Transformer/encoder_norm/scale']))",
            "model.norm.bias.copy_(_n2p(w[f'{prefix}Transformer/encoder_norm/bias']))",
            "-    if model.head.bias.shape[0] == w[f'{prefix}head/bias'].shape[-1]:",
            "+    if isinstance(model.head, nn.Linear) and model.head.bias.shape[0] == w[f'{prefix}head/bias'].shape[-1]:",
            "model.head.weight.copy_(_n2p(w[f'{prefix}head/kernel']))",
            "model.head.bias.copy_(_n2p(w[f'{prefix}head/bias']))",
            "for i, block in enumerate(model.blocks.children()):"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Null Reference Error",
        "Action": "Replace",
        "Element": "API Condition",
        "Action_Element": "Replace API Condition",
        "Symptom_Root_Cause": "Program Crash|Null Reference Error"
    },
    {
        "number": 4794,
        "change": [
            "class MeanSquaredLogError(Metric):",
            "preds: Predictions from model",
            "target: Ground truth values",
            "\"\"\"",
            "-        self._check_same_shape(preds, target)",
            "-        squared_log_error = torch.pow(torch.log1p(preds) - torch.log1p(target), 2)",
            "+        sum_squared_log_error, n_obs = _mean_squared_log_error_update(preds, target)",
            "",
            "-        self.sum_squared_log_error += torch.sum(squared_log_error)",
            "-        self.total += target.numel()",
            "+        self.sum_squared_log_error += sum_squared_log_error",
            "+        self.total += n_obs",
            "",
            "def compute(self):",
            "\"\"\"",
            "Compute mean squared logarithmic error over state.",
            "\"\"\"",
            "-        return self.sum_squared_log_error / self.total",
            "+        return _mean_squared_log_error_compute(self.sum_squared_log_error, self.total)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Algorithm Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Algorithm Error"
    },
    {
        "number": 4798,
        "change": [
            "class Wav2VecCtc(BaseFairseqModel):",
            "",
            "if net_output[\"padding_mask\"] is not None and net_output[\"padding_mask\"].any():",
            "number_of_classes = logits.size(-1)",
            "-            masking_tensor = torch.ones(number_of_classes) * float(\"-inf\")",
            "-            masking_tensor[0] = float(\"inf\")",
            "+            masking_tensor = torch.ones(",
            "+                number_of_classes, device=logits.device",
            "+            ) * float(\"-inf\")",
            "+            masking_tensor[0] = 0",
            "logits[net_output[\"padding_mask\"].T] = masking_tensor.type_as(logits)",
            "",
            "if normalize:"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 4830,
        "change": [
            "class Trainer:",
            "\"\"\"",
            "for k, v in inputs.items():",
            "if isinstance(v, torch.Tensor):",
            "-                inputs[k] = v.to(self.args.device)",
            "+                kwargs = dict(device=self.args.device)",
            "+                if self.deepspeed and inputs[k].dtype != torch.int64:",
            "+                    # NLP models inputs are int64 and those get adjusted to the right dtype of the",
            "+                    # embedding. Other models such as wav2vec2's inputs are already float and thus",
            "+                    # may need special handling to match the dtypes of the model",
            "+                    kwargs.update(dict(dtype=self.args.hf_deepspeed_config.dtype()))",
            "+",
            "+                inputs[k] = v.to(**kwargs)",
            "",
            "if self.args.past_index >= 0 and self._past is not None:",
            "inputs[\"mems\"] = self._past"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 4853,
        "change": [
            "class QLoss:",
            "# priority is robust and insensitive to `prioritized_replay_alpha`",
            "self.td_error = tf.nn.softmax_cross_entropy_with_logits(",
            "labels=m, logits=q_logits_t_selected)",
            "-            self.loss = tf.reduce_mean(self.td_error * importance_weights)",
            "+            self.loss = tf.reduce_mean(",
            "+                self.td_error * tf.cast(importance_weights, tf.float32))",
            "self.stats = {",
            "# TODO: better Q stats for dist dqn",
            "\"mean_td_error\": tf.reduce_mean(self.td_error),"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 4861,
        "change": [
            "try:",
            "if _torch_available:",
            "import torch",
            "",
            "-        if torch.__version__ < version.Version(\"1.12\"):",
            "+        if version.Version(torch.__version__) < version.Version(\"1.12\"):",
            "raise ValueError(\"PyTorch should be >= 1.12\")",
            "logger.debug(f\"Successfully imported xformers version {_xformers_version}\")",
            "except importlib_metadata.PackageNotFoundError:"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Condition",
        "Action_Element": "Replace API Condition",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 4871,
        "change": [
            "def move_data_to_device(batch: Any, device: Union[str, torch.device]) -> Any:",
            "",
            "kwargs = {}",
            "# Don't issue non-blocking transfers to CPU",
            "-        if isinstance(data, Tensor) and device not in _CPU_DEVICES:",
            "+        # Same with MPS due to a race condition bug: https://github.com/pytorch/pytorch/issues/83015",
            "+        if isinstance(data, Tensor) and isinstance(device, torch.device) and device.type not in _BLOCKING_DEVICE_TYPES:",
            "kwargs[\"non_blocking\"] = True",
            "data_output = data.to(device, **kwargs)",
            "if data_output is not None:"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 4874,
        "change": [
            "def select_device(device='', batch_size=0, newline=True):",
            "if cpu:",
            "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # force torch.cuda.is_available() = False",
            "elif device:  # non-cpu device requested",
            "-        nd = torch.cuda.device_count()  # number of CUDA devices",
            "-        assert torch.cuda.is_available(), 'CUDA is not available, use `--device cpu` or do not pass a --device'",
            "+        nd = device_count()  # number of CUDA devices",
            "assert nd > int(max(device.split(','))), f'Invalid `--device {device}` request, valid devices are 0 - {nd - 1}'",
            "-        os.environ['CUDA_VISIBLE_DEVICES'] = device  # set environment variable (must be after asserts)",
            "+        os.environ['CUDA_VISIBLE_DEVICES'] = device  # set environment variable - must be before assert is_available()",
            "+        assert torch.cuda.is_available(), 'CUDA is not available, use `--device cpu` or do not pass a --device'",
            "",
            "cuda = not cpu and torch.cuda.is_available()",
            "if cuda:"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 4911,
        "change": [
            "class TfKerasModelArtifact(Artifact):",
            "def model_file_path(self, base_path):",
            "return os.path.join(base_path, self.name + self._model_extension)",
            "",
            "-    def pack(self, model):",
            "+    def pack(self, model):  # pylint:disable=arguments-differ",
            "self.model = model",
            "",
            "def get(self):",
            "return self.model",
            "",
            "-    def load(self, base_path):  # pylint:disable=arguments-differ",
            "-        from tensorflow.keras.models import load_model",
            "+    def load(self, base_path):",
            "+        try:",
            "+            from tensorflow.keras.models import load_model",
            "+        except ImportError:",
            "+            raise ImportError(\"tensorflow package is required to use TfKerasModelArtifact\")",
            "self.model = load_model(self.model_file_path(base_path))",
            "",
            "def save(self, base_path):"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 4952,
        "change": [
            "class TFMarianSinusoidalPositionalEmbedding(tf.keras.layers.Layer):",
            "position_enc = np.array(",
            "[[pos / np.power(10000, 2 * (j // 2) / dim) for j in range(dim)] for pos in range(n_pos)]",
            ")",
            "+        table = np.zeros_like(position_enc)",
            "# index 0 is all zero",
            "-        position_enc[:, 0 : dim // 2] = np.sin(position_enc[:, 0::2])",
            "-        position_enc[:, dim // 2 :] = np.cos(position_enc[:, 1::2])",
            "+        table[:, 0 : dim // 2] = np.sin(position_enc[:, 0::2])",
            "+        table[:, dim // 2 :] = np.cos(position_enc[:, 1::2])",
            "# convert to tensor",
            "-        table = tf.convert_to_tensor(position_enc)",
            "+        table = tf.convert_to_tensor(table)",
            "tf.stop_gradient(table)",
            "return table"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 5002,
        "change": [
            "def get_outputs_sizes_torch(",
            "",
            "",
            "def create_model_inputs_torch(",
            "-    batch_size: int, input_infos: List[InputInfo]",
            "+    input_infos: List[InputInfo],",
            ") -> List[torch.Tensor]:",
            "input_tensors = (",
            "-        torch.randn((batch_size, *input_info.size))",
            "+        torch.randn(*input_info.size)",
            "if input_info.dtype is DataType.FLOAT32",
            "else torch.randint(",
            "-            size=(batch_size, *input_info.size),",
            "+            size=input_info.size,",
            "low=input_info.min_value or 0,",
            "high=input_info.max_value or 100,",
            ")"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 5036,
        "change": [
            "def infer_inputs_from_restored_call_function(fn):",
            "if isinstance(x, tf.SparseTensorSpec):",
            "return tf.SparseTensorSpec(common_shape, x.dtype)",
            "elif isinstance(x, tf.RaggedTensorSpec):",
            "-      return tf.RaggedTensorSpec(common_shape, x.dtype)",
            "+      return tf.RaggedTensorSpec(",
            "+          common_shape,",
            "+          x.dtype,",
            "+          ragged_rank=x.ragged_rank,",
            "+          row_splits_dtype=x.row_splits_dtype,",
            "+          flat_values_spec=x.flat_values_spec)",
            "return tf.TensorSpec(common_shape, x.dtype, x.name)",
            "",
            "spec = fn.concrete_functions[0].structured_input_signature"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 5052,
        "change": [
            "def _torch_solve_cast(input: torch.Tensor, A: torch.Tensor) -> Tuple[torch.Tenso",
            "if dtype not in (torch.float32, torch.float64):",
            "dtype = torch.float32",
            "",
            "-    out = solve(A.to(dtype), input.to(dtype))",
            "+    out = torch.linalg.solve(A.to(dtype), input.to(dtype))",
            "",
            "return (out.to(input.dtype), out)"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 5072,
        "change": [
            "def test_dynamic_quantization(train_dic, recog_dic, quantize_dic):",
            "train_args = get_default_train_args(**train_dic)",
            "recog_args = get_default_recog_args(**recog_dic)",
            "",
            "+    if not is_torch_1_5_plus:",
            "+        q_dtype = torch.qint8",
            "+    else:",
            "+        q_dtype = quantize_dic[\"mod\"]",
            "+",
            "model = E2E(idim, odim, train_args)",
            "model = torch.quantization.quantize_dynamic(",
            "-        model, quantize_dic[\"mod\"], dtype=quantize_dic[\"dtype\"]",
            "+        model, q_dtype, dtype=quantize_dic[\"dtype\"]",
            ")",
            "",
            "beam_search = BeamSearchTransducer("
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 5080,
        "change": [
            "class GNNExplainer(torch.nn.Module):",
            "if node_idx == -1:",
            "hard_edge_mask = torch.BoolTensor([True] * edge_index.size(1),",
            "device=edge_mask.device)",
            "-            subset = torch.arange(",
            "-                edge_index.max() + 1,",
            "-                device=edge_index.device if y is None else y.device)",
            "+            subset = torch.arange(edge_index.max().item() + 1,",
            "+                                  device=edge_index.device)",
            "+            y = None",
            "+",
            "else:",
            "# Only operate on a k-hop subgraph around `node_idx`.",
            "subset, edge_index, _, hard_edge_mask = k_hop_subgraph("
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 5102,
        "change": [
            "class FSMTHeadTests(unittest.TestCase):",
            "config, *_ = self._get_config_and_data()",
            "input_ids = _long_tensor(([4, 4, 2]))",
            "decoder_input_ids = _long_tensor([[26388, 2, config.pad_token_id]])",
            "-        ignore = float(\"-inf\")",
            "+        causal_mask_dtype = torch.float32",
            "+        ignore = torch.finfo(causal_mask_dtype).min",
            "decoder_input_ids, decoder_attn_mask, causal_mask = _prepare_fsmt_decoder_inputs(",
            "-            config, input_ids, decoder_input_ids",
            "+            config, input_ids, decoder_input_ids, causal_mask_dtype=causal_mask_dtype",
            ")",
            "expected_causal_mask = torch.tensor(",
            "[[0, ignore, ignore], [0, 0, ignore], [0, 0, 0]]  # never attend to the final token, because its pad"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 5106,
        "change": [
            "def main():",
            "if args.do_train:",
            "torch.save(model_to_save.state_dict(), output_model_file)",
            "",
            "-    # Load a trained model that you have fine-tuned",
            "-    model_state_dict = torch.load(output_model_file)",
            "-    model = BertForQuestionAnswering.from_pretrained(args.bert_model, state_dict=model_state_dict)",
            "+        # Load a trained model that you have fine-tuned",
            "+        model_state_dict = torch.load(output_model_file)",
            "+        model = BertForQuestionAnswering.from_pretrained(args.bert_model, state_dict=model_state_dict)",
            "+    else:",
            "+        model = BertForQuestionAnswering.from_pretrained(args.bert_model)",
            "+",
            "model.to(device)",
            "",
            "if args.do_predict and (args.local_rank == -1 or torch.distributed.get_rank() == 0):"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 5124,
        "change": [
            "class TFT5ModelIntegrationTests(unittest.TestCase):",
            "labels = tokenizer(\"Hi I am\", return_tensors=\"tf\").input_ids",
            "",
            "loss = model(input_ids, labels=labels).loss",
            "-        mtf_score = -tf.math.reduce_sum(loss).numpy()",
            "+        mtf_score = -tf.math.reduce_mean(loss).numpy()",
            "",
            "-        EXPECTED_SCORE = -60.7397",
            "+        EXPECTED_SCORE = -7.594554",
            "self.assertTrue(abs(mtf_score - EXPECTED_SCORE) < 1e-4)",
            "",
            "@slow"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Algorithm Error"
    },
    {
        "number": 5177,
        "change": [
            "class CLIPModelTester:",
            "",
            "def create_and_check_model(self, config, input_ids, attention_mask, pixel_values):",
            "model = CLIPModel(config).to(torch_device).eval()",
            "-        result = model(input_ids, pixel_values, attention_mask)",
            "+        with torch.no_grad():",
            "+            result = model(input_ids, pixel_values, attention_mask)",
            "self.parent.assertEqual(",
            "result.logits_per_image.shape, (self.vision_model_tester.batch_size, self.text_model_tester.batch_size)",
            ")"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 5178,
        "change": [
            "def inverse_pose(pose):",
            "",
            "pose_inv = pose.clone()",
            "pose_inv[..., :3, 0:3] = torch.transpose(pose[..., :3, :3], 1, 2)",
            "-    pose_inv[..., :3, 2:3] = torch.matmul(",
            "-        -1.0 * pose_inv[..., :3, :3], pose[..., :3, 2:3])",
            "+    pose_inv[..., :3, 3:4] = torch.matmul(",
            "+        -1.0 * pose_inv[..., :3, :3], pose[..., :3, 3:4])",
            "",
            "if len(pose_shape) == 2:",
            "pose_inv = torch.squeeze(pose_inv, dim=0)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 5191,
        "change": [
            "class Input(Layer):",
            "logging.info(\"Input  %s: %s\" % (self.name, str(shape)))",
            "",
            "shape_without_none = [_ if _ is not None else 1 for _ in shape]",
            "-        self.outputs = self.forward(tf.initializers.constant(value=0.0)(shape_without_none), is_train=False)",
            "+        self.outputs = self.forward(tf.initializers.random_normal()(shape_without_none), is_train=False)",
            "",
            "def __call__(self, prev_layer):",
            "# FIXME: better exception raising"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 5194,
        "change": [
            "class CascadeRoIHead(BaseRoIHead, BBoxTestMixin, MaskTestMixin):",
            "ms_scores.append(bbox_results['cls_score'])",
            "",
            "if i < self.num_stages - 1:",
            "-                    bbox_label = bbox_results['cls_score'].argmax(dim=1)",
            "+                    bbox_label = bbox_results['cls_score'][:, :-1].argmax(",
            "+                        dim=1)",
            "rois = self.bbox_head[i].regress_by_class(",
            "rois, bbox_label, bbox_results['bbox_pred'],",
            "img_meta[0])"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 5198,
        "change": [
            "def test_model_saving_loading():",
            "# make prediction",
            "# assert that both predictions are the same",
            "new_pred = model_2(x)",
            "-    assert torch.eq(pred_before_saving, new_pred)",
            "+    assert torch.all(torch.eq(pred_before_saving, new_pred)).item() == 1",
            "",
            "clear_save_dir()"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 5219,
        "change": [
            "class TorchCustomLossModel(TorchModelV2, nn.Module):",
            "",
            "# Compute the IL loss.",
            "action_dist = TorchCategorical(logits, self.model_config)",
            "-        imitation_loss = torch.mean(",
            "-            -action_dist.logp(torch.from_numpy(batch[\"actions\"])))",
            "+        imitation_loss = torch.mean(-action_dist.logp(",
            "+            torch.from_numpy(batch[\"actions\"]).to(policy_loss[0].device)))",
            "self.imitation_loss_metric = imitation_loss.item()",
            "self.policy_loss_metric = np.mean([l.item() for l in policy_loss])"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 5242,
        "change": [
            "class TFXLNetMainLayer(tf.keras.layers.Layer):",
            "assert input_mask is None or attention_mask is None, \"You can only use one of input_mask (uses 1 for padding) \" \\",
            "\"or attention_mask (uses 0 for padding, added for compatbility with BERT). Please choose one.\"",
            "if input_mask is None and attention_mask is not None:",
            "-            input_mask = 1.0 - attention_mask",
            "+            input_mask = 1.0 - tf.cast(attention_mask, dtype=dtype_float)",
            "if input_mask is not None and perm_mask is not None:",
            "data_mask = input_mask[None] + perm_mask",
            "elif input_mask is not None and perm_mask is None:"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 5247,
        "change": [
            "from tqdm import tqdm",
            "",
            "",
            "def download_wmt_dataset(src_lang=\"ro\", tgt_lang=\"en\", dataset=\"wmt16\", save_dir=None) -> None:",
            "-    \"\"\"Download a dataset using the nlp package and save it to the format expected by finetune.py",
            "+    \"\"\"Download a dataset using the datasets package and save it to the format expected by finetune.py",
            "Format of save_dir: train.source, train.target, val.source, val.target, test.source, test.target.",
            "",
            "Args:",
            "src_lang: <str> source language",
            "tgt_lang: <str> target language",
            "-        dataset: <str> wmt16, wmt17, etc. wmt16 is a good start as it's small. To get the full list run `import nlp; print([d.id for d in nlp.list_datasets() if \"wmt\" in d.id])`",
            "+        dataset: <str> wmt16, wmt17, etc. wmt16 is a good start as it's small. To get the full list run `import datasets; print([d.id for d in datasets.list_datasets() if \"wmt\" in d.id])`",
            "save_dir: <str>, where to save the datasets, defaults to f'{dataset}-{src_lang}-{tgt_lang}'",
            "",
            "Usage:",
            ">>> download_wmt_dataset('ro', 'en', dataset='wmt16') # saves to wmt16-ro-en",
            "\"\"\"",
            "try:",
            "-        import nlp",
            "+        import datasets",
            "except (ModuleNotFoundError, ImportError):",
            "-        raise ImportError(\"run pip install nlp\")",
            "+        raise ImportError(\"run pip install datasets\")",
            "pair = f\"{src_lang}-{tgt_lang}\"",
            "print(f\"Converting {dataset}-{pair}\")",
            "-    ds = nlp.load_dataset(dataset, pair)",
            "+    ds = datasets.load_dataset(dataset, pair)",
            "if save_dir is None:",
            "save_dir = f\"{dataset}-{pair}\"",
            "save_dir = Path(save_dir)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 5277,
        "change": [
            "class FaceAlignment:",
            "out += flip(self.face_alignment_net(flip(inp)).detach(), is_label=True)",
            "out = out.cpu().numpy()",
            "",
            "-            pts, pts_img = get_preds_fromhm(out, center, scale)",
            "-            pts, pts_img = pts.view(68, 2) * 4, pts_img.view(68, 2)",
            "+            pts, pts_img = get_preds_fromhm(out, center.numpy(), scale)",
            "pts, pts_img = torch.from_numpy(pts), torch.from_numpy(pts_img)",
            "+            pts, pts_img = pts.view(68, 2) * 4, pts_img.view(68, 2)",
            "",
            "if self.landmarks_type == LandmarksType._3D:",
            "heatmaps = np.zeros((68, 256, 256), dtype=np.float32)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 5310,
        "change": [
            "class CTCPrefixScorer(PartialScorerInterface):",
            "def score_partial(self, y, ids, state, x):",
            "prev_score, state = state",
            "presub_score, new_st = self.impl(y.cpu(), ids.cpu(), state)",
            "-        tscore = torch.as_tensor(presub_score - prev_score, device=y.device)",
            "+        tscore = torch.as_tensor(presub_score - prev_score, device=x.device, dtype=x.dtype)",
            "return tscore, (presub_score, new_st)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 5314,
        "change": [
            "class Model(torch.nn.Module, Registrable):",
            "add_batch_dimension=True,",
            "cuda_device=cuda_device,",
            "for_training=False)",
            "-        outputs = self.forward(**model_input)",
            "+        outputs = self.decode(self.forward(**model_input))",
            "",
            "for name, output in list(outputs.items()):",
            "output = output[0]"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 5322,
        "change": [
            "def inplace_update(",
            "elif ivy.is_ivy_array(x):",
            "x.data = val_native",
            "else:",
            "-            raise ivy.exceptions.IvyException(",
            "-                \"TensorFlow does not support inplace updates of the tf.Tensor\"",
            "-            )",
            "+            x = ivy.to_ivy(x_native)",
            "return x",
            "else:",
            "return val"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 5337,
        "change": [
            "class RelationExtractor(flair.nn.DefaultClassifier):",
            "",
            "relation_embeddings.append(embedding)",
            "",
            "-            # stack and drop out",
            "-            all_relations = torch.stack(relation_embeddings)",
            "+            # stack and drop out (squeeze and unsqueeze)",
            "+            all_relations = torch.stack(relation_embeddings).unsqueeze(1)",
            "",
            "all_relations = self.dropout(all_relations)",
            "all_relations = self.locked_dropout(all_relations)",
            "all_relations = self.word_dropout(all_relations)",
            "",
            "+            all_relations = all_relations.squeeze(1)",
            "+",
            "# send through decoder",
            "if self.non_linear_decoder:",
            "sentence_relation_scores = self.decoder_2(self.nonlinearity(self.decoder_1(all_relations)))"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 5340,
        "change": [
            "class HullWhiteBermudanSwaptionTest(parameterized.TestCase, tf.test.TestCase):",
            "self.float_leg_end_times) - np.array(self.float_leg_start_times)",
            "self.fixed_leg_daycount_fractions = self.float_leg_daycount_fractions",
            "self.fixed_leg_coupon = 0.011 * np.ones_like(self.fixed_leg_payment_times)",
            "-    self.zero_rate_fn = lambda x: 0.01 * tf.ones_like(x)",
            "+    zero_rate_fn = lambda x: 0.01 * tf.expand_dims(tf.ones_like(x), axis=-1)",
            "+    self.zero_rate_fn = zero_rate_fn",
            "",
            "super(HullWhiteBermudanSwaptionTest, self).setUp()"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 5347,
        "change": [
            "class TestSparseClipGrad(AllenNlpTestCase):",
            "# Now try to clip the gradients.",
            "_ = sparse_clip_norm([embedding.weight], 1.5)",
            "# Final norm should be 1.5",
            "-        grad = embedding.weight.grad.data.coalesce()",
            "-        self.assertAlmostEqual(grad._values().norm(2.0), 1.5, places=5) # pylint: disable=protected-access",
            "+        grad = embedding.weight.grad.coalesce()  # pylint: disable=no-member",
            "+        self.assertAlmostEqual(grad._values().norm(2.0).item(), 1.5, places=5) # pylint: disable=protected-access"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 5370,
        "change": [
            "class CategoricalOneHotPolicy(StochasticPolicy):",
            "",
            "def __init__(self, network, session, state, random, action_count=1, scope='policy'):",
            "with tf.variable_scope(scope):",
            "-            action_layer = linear(layer_input=network.output, config={'num_outputs': action_count}, scope='outputs')",
            "-",
            "-            distribution = tf.nn.softmax(action_layer)",
            "-            sample = tf.map_fn(lambda t: tf.multinomial(logits=t, num_samples=1), elems=distribution, dtype=tf.int64)",
            "+            logits = linear(layer_input=network.output, config={'num_outputs': action_count}, scope='outputs')",
            "+            distribution = tf.nn.softmax(logits)",
            "+            sample = tf.map_fn(lambda t: tf.multinomial(logits=t, num_samples=1), elems=logits, dtype=tf.int64)",
            "",
            "super(CategoricalOneHotPolicy, self).__init__(network, [distribution, sample], session, state, random, action_count)",
            "self.dist = Categorical(random)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 5398,
        "change": [
            "def main(args):",
            "",
            "# Get input and output tensors",
            "images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")",
            "+            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")",
            "embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")",
            "tpr, fpr, accuracy, val, val_std, far = lfw.validate(sess, paths,",
            "actual_issame, args.seed, 60,",
            "-                images_placeholder, embeddings, nrof_folds=args.lfw_nrof_folds)",
            "+                images_placeholder, phase_train_placeholder, embeddings, nrof_folds=args.lfw_nrof_folds)",
            "print('Accuracy: %1.3f+-%1.3f' % (np.mean(accuracy), np.std(accuracy)))",
            "print('Validation rate: %2.5f+-%2.5f @ FAR=%2.5f' % (val, val_std, far))"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 5438,
        "change": [
            "def train_cifar():",
            "optimizer = optim.Adam(get_parameters(model), lr=3e-4)",
            "else:",
            "#optimizer = optim.SGD(get_parameters(model), lr=0.001)",
            "-    optimizer = optim.SGD(get_parameters(model), lr=0.003, momentum=0.85, nesterov=True)",
            "+    optimizer = optim.SGD(get_parameters(model), lr=Tensor([0.003]).realize(), momentum=0.85, nesterov=True)",
            "",
            "# 97 steps in 2 seconds = 20ms / step",
            "# step is 1163.42 GOPS = 56 TFLOPS!!!, 41% of max 136"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 5451,
        "change": [
            "class NCSNpp(ModelMixin, ConfigMixin):",
            "for i_level in reversed(range(self.num_resolutions)):",
            "for i_block in range(num_res_blocks + 1):",
            "out_ch = nf * ch_mult[i_level]",
            "+                in_ch = in_ch + hs_c.pop()",
            "modules.append(",
            "ResnetBlock(",
            "-                        in_channels=in_ch + hs_c.pop(),",
            "+                        in_channels=in_ch,",
            "out_channels=out_ch,",
            "temb_channels=4 * nf,",
            "output_scale_factor=np.sqrt(2.0),"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 5476,
        "change": [
            "def ga_loc_target(gt_bboxes_list,",
            "all_ignore_map.append(ignore_map)",
            "for img_id in range(img_per_gpu):",
            "gt_bboxes = gt_bboxes_list[img_id]",
            "-        scale = torch.sqrt((gt_bboxes[:, 2] - gt_bboxes[:, 0] + 1) *",
            "-                           (gt_bboxes[:, 3] - gt_bboxes[:, 1] + 1))",
            "+        scale = torch.sqrt((gt_bboxes[:, 2] - gt_bboxes[:, 0]) *",
            "+                           (gt_bboxes[:, 3] - gt_bboxes[:, 1]))",
            "min_anchor_size = scale.new_full(",
            "(1, ), float(anchor_scale * anchor_strides[0]))",
            "# assign gt bboxes to different feature levels w.r.t. their scales"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 5478,
        "change": [
            "def create_model(to_device=True, dim_in=None, dim_out=None):",
            "if 'classification' in cfg.dataset.task_type and dim_out == 2:",
            "dim_out = 1",
            "",
            "-    model = network_dict[cfg.model.type](dim_in=dim_in, dim_out=dim_out)",
            "+    model = GraphGymModule(dim_in, dim_out, cfg)",
            "if to_device:",
            "model.to(torch.device(cfg.device))",
            "return model"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 5523,
        "change": [
            "class MapGradient(GradientProcessor):",
            "for grad, var in grads:",
            "if re.match(self.regex, var.op.name):",
            "matched = True",
            "-                with tf.device(grad.device):",
            "-                    grad = self.func(grad, var)",
            "+                grad = self.func(grad, var)",
            "if grad is not None:",
            "ret.append((grad, var))",
            "else:"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 5532,
        "change": [
            "def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int = 256, clip: float = 4",
            "histos: torch.Tensor = torch.empty((tiles.shape[0], num_bins), device=tiles.device)",
            "if not diff:",
            "for i in range(tiles.shape[0]):",
            "-            histos[i] = torch.histc(tiles[i], bins=num_bins, min=0, max=1)",
            "+            histos[i] = _torch_histc_cast(tiles[i], bins=num_bins, min=0, max=1)",
            "else:",
            "bins: torch.Tensor = torch.linspace(0, 1, num_bins, device=tiles.device)",
            "histos = histogram(tiles, bins, torch.tensor(0.001)).squeeze()"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 5535,
        "change": [
            "class DetrEncoderLayer(nn.Module):",
            "hidden_states = residual + hidden_states",
            "hidden_states = self.final_layer_norm(hidden_states)",
            "",
            "-        if torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any():",
            "-            clamp_value = torch.finfo(hidden_states.dtype).max - 1000",
            "-            hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)",
            "+        if self.training:",
            "+            if torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any():",
            "+                clamp_value = torch.finfo(hidden_states.dtype).max - 1000",
            "+                hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)",
            "",
            "outputs = (hidden_states,)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 5542,
        "change": [
            "class StableDiffusionModelHijack:",
            "if len(emb.shape) == 1:",
            "emb = emb.unsqueeze(0)",
            "",
            "-            self.word_embeddings[name] = emb.detach()",
            "+            self.word_embeddings[name] = emb.detach().to(device)",
            "self.word_embeddings_checksums[name] = f'{const_hash(emb.reshape(-1)*100)&0xffff:04x}'",
            "",
            "ids = tokenizer([name], add_special_tokens=False)['input_ids'][0]"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 5579,
        "change": [
            "class AdalamFilter:",
            "\"Please either provide orientations or set 'orientation_difference_threshold' to None to disable orientations filtering\"  # noqa: E501",
            ")",
            "k1, k2, d1, d2, o1, o2, s1, s2 = self.__to_torch(k1, k2, d1, d2, o1, o2, s1, s2)",
            "+        if len(d2) <= 1:",
            "+            return _no_match(d1)",
            "distmat = dist_matrix(d1, d2, is_normalized=False)",
            "dd12, nn12 = torch.topk(distmat, k=2, dim=1, largest=False)  # (n1, 2)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Null Reference Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Program Crash|Null Reference Error"
    },
    {
        "number": 5598,
        "change": [
            "class Model:",
            "return ppgs, preds_ppg, logits_ppg, pred_spec, pred_mel",
            "",
            "def loss_net2(self):",
            "-        loss_spec = tf.reduce_mean(tf.abs(self.pred_spec - self.y_spec))",
            "-        loss_mel = tf.reduce_mean(tf.abs(self.pred_mel - self.y_mel))",
            "+        loss_spec = tf.reduce_mean(tf.squared_difference(self.pred_spec, self.y_spec))",
            "+        loss_mel = tf.reduce_mean(tf.squared_difference(self.pred_mel, self.y_mel))",
            "loss = loss_spec + loss_mel",
            "return loss"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Algorithm Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Low Efficiency|Algorithm Error"
    },
    {
        "number": 5618,
        "change": [
            "class Trainer(object):",
            "",
            "def is_consistent(tensor):",
            "max_abs_diff = torch.max(torch.abs(tensor - tensor[0]))",
            "-                return (max_abs_diff / (tensor[0] + 1e-6) < 1e-6).all()",
            "+                return (",
            "+                    not torch.isfinite(tensor).any()",
            "+                    or (max_abs_diff / (tensor[0] + 1e-6) < 1e-6).all()",
            "+                )",
            "",
            "if not is_consistent(self._grad_norm_buf):",
            "pretty_detail = \"\\n\".join("
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 5637,
        "change": [
            "def normalize_homography3d(dst_pix_trans_src_pix: torch.Tensor,",
            "# compute the transformation pixel/norm for src/dst",
            "src_norm_trans_src_pix: torch.Tensor = normal_transform_pixel3d(",
            "src_d, src_h, src_w).to(dst_pix_trans_src_pix)",
            "-    src_pix_trans_src_norm = torch.inverse(src_norm_trans_src_pix)",
            "+",
            "+    src_pix_trans_src_norm = _torch_inverse_cast(src_norm_trans_src_pix)",
            "dst_norm_trans_dst_pix: torch.Tensor = normal_transform_pixel3d(",
            "dst_d, dst_h, dst_w).to(dst_pix_trans_src_pix)",
            "# compute chain transformations"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 5655,
        "change": [
            "def harmonic_mean(a, weights=None):",
            "return sum(weights) / sum(w/x for x, w in zip(a, weights))",
            "",
            "# torch utils",
            "-def get_optimizer(name, parameters, lr, betas=(0.9, 0.999)):",
            "+def get_optimizer(name, parameters, lr, betas=(0.9, 0.999), eps=1e-8):",
            "if name == 'sgd':",
            "return torch.optim.SGD(parameters, lr=lr)",
            "elif name == 'adagrad':",
            "return torch.optim.Adagrad(parameters, lr=lr)",
            "elif name == 'adam':",
            "-        return torch.optim.Adam(parameters, lr=lr, betas=betas) # use default lr",
            "+        return torch.optim.Adam(parameters, lr=lr, betas=betas, eps=eps)",
            "elif name == 'adamax':",
            "return torch.optim.Adamax(parameters) # use default lr",
            "else:"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Algorithm Error"
    },
    {
        "number": 5662,
        "change": [
            "class FlatVarHelper(object):",
            "self.session = session",
            "shapes = map(get_shape, variables)",
            "total_size = sum(np.prod(shape) for shape in shapes)",
            "-        self.theta = theta = tf.placeholder(tf.float32, [total_size])",
            "+        self.theta = tf.placeholder(tf.float32, [total_size])",
            "start = 0",
            "assigns = []",
            "",
            "for (shape, variable) in zip(shapes, variables):",
            "size = np.prod(shape)",
            "-            assigns.append(tf.assign(variable, tf.reshape(theta[start:start + size], shape)))",
            "+            assigns.append(tf.assign(variable, tf.reshape(self.theta[start:start + size], shape)))",
            "start += size",
            "",
            "self.set_op = tf.group(*assigns)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Null Reference Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Null Reference Error"
    },
    {
        "number": 5664,
        "change": [
            "def matmul(",
            "dtype_from = tf.as_dtype(x1.dtype)",
            "",
            "if transpose_a:",
            "-        x1 = tf.transpose(x1)",
            "+        x1 = tf.linalg.matrix_transpose(x1)",
            "if transpose_b:",
            "-        x2 = tf.transpose(x2)",
            "+        x2 = tf.linalg.matrix_transpose(x2)",
            "",
            "if adjoint_a:",
            "x1 = tf.linalg.adjoint(x1)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 5669,
        "change": [
            "class LongformerOnnxConfig(OnnxConfig):",
            ")",
            "import torch",
            "",
            "+        # for some reason, replacing this code by inputs[\"global_attention_mask\"] = torch.randint(2, inputs[\"input_ids\"].shape, dtype=torch.int64)",
            "+        # makes the export fail randomly",
            "inputs[\"global_attention_mask\"] = torch.zeros_like(inputs[\"input_ids\"])",
            "# make every second token global",
            "inputs[\"global_attention_mask\"][:, ::2] = 1",
            "+",
            "return inputs"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 5680,
        "change": [
            "def test_ellipsis_simplify():",
            "def test_pointer_tensor_simplify():",
            "\"\"\"Test the simplification of PointerTensor\"\"\"",
            "",
            "-    alice = syft.VirtualWorker(id=\"alice\")",
            "+    alice = syft.VirtualWorker(syft.torch.hook, id=\"alice\")",
            "input_tensor = PointerTensor(id=1000, location=alice, owner=alice)",
            "",
            "output = _simplify(input_tensor)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 5702,
        "change": [
            "class TFFlaubertMainLayer(TFXLMMainLayer):",
            "position_ids = tf.expand_dims(tf.range(slen), axis=0)",
            "else:",
            "# assert shape_list(position_ids) == [bs, slen]  # (slen, bs)",
            "-            tf.debugging.assert_equal(shape_list(position_ids), [bs, slen])",
            "+            tf.debugging.assert_equal(",
            "+                shape_list(position_ids), [bs, slen]",
            "+            ), f\"Position id shape {shape_list(position_ids)} and input shape {[bs, slen]} mismatched\"",
            "# position_ids = position_ids.transpose(0, 1)",
            "",
            "# langs",
            "if langs is not None:",
            "# assert shape_list(langs) == [bs, slen]  # (slen, bs)",
            "-            tf.debugging.assert_equal(shape_list(langs), [bs, slen])",
            "+            tf.debugging.assert_equal(",
            "+                shape_list(langs), [bs, slen]",
            "+            ), f\"Lang shape {shape_list(langs)} and input shape {[bs, slen]} mismatched\"",
            "# langs = langs.transpose(0, 1)",
            "",
            "# Prepare head mask if needed"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 5704,
        "change": [
            "def get_detector(trained_model, device='cpu'):",
            "net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))",
            "else:",
            "net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))",
            "-        net = torch.nn.DataParallel(net)",
            "+        net = torch.nn.DataParallel(net).to(device)",
            "cudnn.benchmark = False",
            "",
            "net.eval()"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 5723,
        "change": [
            "class CheckpointMergerPipeline(DiffusionPipeline):",
            "theta_0 = theta_0()",
            "",
            "update_theta_0 = getattr(module, \"load_state_dict\")",
            "-                    theta_1 = torch.load(checkpoint_path_1)",
            "+                    theta_1 = torch.load(checkpoint_path_1, map_location=\"cpu\")",
            "",
            "-                    theta_2 = torch.load(checkpoint_path_2) if checkpoint_path_2 else None",
            "+                    theta_2 = torch.load(checkpoint_path_2, map_location=\"cpu\") if checkpoint_path_2 else None",
            "",
            "if not theta_0.keys() == theta_1.keys():",
            "print(\"SKIPPING ATTR \", attr, \" DUE TO MISMATCH\")"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 5744,
        "change": [
            "class TowerContext(object):",
            "self._ctxs.append(tf.variable_scope(self._name))",
            "else:",
            "# use existing variable scope",
            "+                reuse = self.index > 0 or (not self.is_training)",
            "self._ctxs.append(tf.variable_scope(",
            "-                    tf.get_variable_scope(), reuse=self.index > 0))",
            "+                    tf.get_variable_scope(), reuse=reuse))",
            "self._ctxs.append(tf.name_scope(self._name))",
            "self._ctxs.append(tf.device(self._device))",
            "for c in self._ctxs:"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 5785,
        "change": [
            "class NaturalGradient(Optimizer):",
            "#     tf.math.reduce_sum(input_tensor=(loss_grad * delta))",
            "#     for loss_grad, delta in zip(loss_gradients, estimated_deltas.values())",
            "# ])",
            "-                return estimated_deltas.fmap(function=tf_util.identity)",
            "+                return [tf_util.identity(input=delta) for delta in estimated_deltas.values()]",
            "",
            "if self.only_positive_updates:",
            "# Natural gradient step only works if constant > 0 (epsilon to avoid zero division)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 5807,
        "change": [
            "class BoringModelTPU(BoringModel):",
            "@pl_multi_process_test",
            "def test_model_tpu_one_core():",
            "\"\"\"Tests if device/debug flag is set correctely when training and after teardown for TPUSpawnPlugin.\"\"\"",
            "-    trainer = Trainer(tpu_cores=1, fast_dev_run=True, plugin=TPUSpawnPlugin(debug=True))",
            "+    trainer = Trainer(tpu_cores=1, fast_dev_run=True, strategy=TPUSpawnPlugin(debug=True))",
            "# assert training type plugin attributes for device setting",
            "assert isinstance(trainer.training_type_plugin, TPUSpawnPlugin)",
            "assert not trainer.training_type_plugin.on_gpu",
            "assert trainer.training_type_plugin.on_tpu",
            "-    assert trainer.training_type_plugin.root_device == torch.device(\"xla\")",
            "+    assert trainer.training_type_plugin.root_device == torch.device(\"xla\", index=1)",
            "model = BoringModelTPU()",
            "trainer.fit(model)",
            "assert \"PT_XLA_DEBUG\" not in os.environ"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 5819,
        "change": [
            "class TestAugmentationSequential:",
            "data_keys=[\"input\"],",
            "random_apply=random_apply,",
            "return_transform=return_transform,",
            "+            same_on_batch=same_on_batch,",
            ")",
            "out = aug(inp)",
            "if aug.return_label:",
            "out, label = out",
            "if return_transform and isinstance(out, (tuple, list)):",
            "out = out[0]",
            "-        assert out.shape == inp.shape",
            "+        assert out.shape[-3:] == inp.shape[-3:]",
            "reproducibility_test(inp, aug)",
            "",
            "@pytest.mark.parametrize('random_apply', [1, (2, 2), (1, 2), (2,), 10, True, False])"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 5824,
        "change": [
            "def compute_q_noisy_max_torch(counts, noise_eps):",
            "",
            "if type(counts) != torch.tensor:",
            "",
            "-        counts = torch.tensor(counts, dtype=torch.float)",
            "+        counts = torch.tensor(tensors_to_literals(counts), dtype=torch.float)",
            "",
            "_, winner = counts.max(0)",
            "counts_normalized = noise_eps * ("
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 5870,
        "change": [
            "class Model(ModelDesc):",
            "isTrain = get_current_tower_context().is_training",
            "if isTrain:",
            "# beam search is too slow to run in training",
            "-            predictions = tf.to_int32(",
            "-                tf.nn.ctc_greedy_decoder(logits, seqlen)[0][0])",
            "+            predictions = tf.cast(",
            "+                tf.nn.ctc_greedy_decoder(logits, seqlen)[0][0], tf.int32)",
            "else:",
            "-            predictions = tf.to_int32(",
            "-                tf.nn.ctc_beam_search_decoder(logits, seqlen)[0][0])",
            "+            predictions = tf.cast(",
            "+                tf.nn.ctc_beam_search_decoder(logits, seqlen)[0][0], tf.int32)",
            "err = tf.edit_distance(predictions, label, normalize=True)",
            "err.set_shape([None])",
            "err = tf.reduce_mean(err, name='error')"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 5883,
        "change": [
            "class PytorchGraphTest(unittest.TestCase):",
            "class myLinear(torch.nn.Module):",
            "def __init__(self):",
            "super(myLinear, self).__init__()",
            "-                self.l = torch.nn.Linear(3, 5)",
            "+                self.linear = torch.nn.Linear(3, 5)",
            "",
            "def forward(self, x):",
            "-                return self.l(x)",
            "+                return self.linear(x)",
            "",
            "with SummaryWriter(comment='LinearModel') as w:",
            "w.add_graph(myLinear(), dummy_input, True)",
            "",
            "def test_wrong_input_size(self):",
            "print('expect error here:')",
            "-        with self.assertRaises(RuntimeError) as e_info:",
            "+        with self.assertRaises(TypeError):",
            "dummy_input = torch.rand(1, 9)",
            "model = torch.nn.Linear(3, 5)",
            "with SummaryWriter(comment='expect_error') as w:"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 5886,
        "change": [
            "class MaskRCNN():",
            "# TODO: can this be optimized to avoid duplicating the anchors?",
            "anchors = np.broadcast_to(anchors, (config.BATCH_SIZE,) + anchors.shape)",
            "# A hack to get around Keras's bad support for constants",
            "-            anchors = KL.Lambda(lambda x: tf.constant(anchors), name=\"anchors\")(input_image)",
            "+            anchors = KL.Lambda(lambda x: tf.Variable(anchors), name=\"anchors\")(input_image)",
            "else:",
            "anchors = input_anchors"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 5932,
        "change": [
            "class InvConvNear(nn.Module):",
            "return z, logdet",
            "",
            "def store_inverse(self):",
            "-        self.weight_inv = torch.inverse(",
            "+        weight_inv = torch.inverse(",
            "self.weight.float()).to(dtype=self.weight.dtype)",
            "+        self.weight_inv = nn.Parameter(weight_inv, requires_grad=False)",
            "",
            "",
            "class CouplingBlock(nn.Module):"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 6008,
        "change": [
            "class Imagen(BaseGaussianDiffusion):",
            "device = next(self.parameters()).device",
            "",
            "lowres_sample_noise_level = default(lowres_sample_noise_level, self.lowres_sample_noise_level)",
            "-        lowres_noise_times = torch.full((batch_size,), lowres_sample_noise_level, device = device, dtype = torch.long)",
            "+        lowres_noise_times = torch.full((batch_size,), int(lowres_sample_noise_level * self.num_timesteps), device = device, dtype = torch.long)",
            "",
            "for unet_number, unet, channel, image_size, learned_variance in tqdm(zip(range(1, len(self.unets) + 1), self.unets, self.sample_channels, self.image_sizes, self.learned_variance)):"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 6026,
        "change": [
            "def any(",
            "keepdims: bool = False,",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "-    x = ivy.asarray(x).type(torch.bool)",
            "+    x = torch.as_tensor(x).type(torch.bool)",
            "if axis is None:",
            "num_dims = len(x.shape)",
            "axis = list(range(num_dims))"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 6071,
        "change": [
            "def batched_forward(",
            "if st >= end:",
            "continue",
            "out_list.append(model_dev(data[st:end].to(device), **kwargs))",
            "-        out = torch.cat(out_list, dim=0)",
            "+        out = concatenate(out_list, 0)",
            "return out.to(data.device)",
            "return model(data, **kwargs)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 6080,
        "change": [
            "class EfficientFormer(nn.Module):",
            "def get_classifier(self):",
            "return self.head, self.head_dist",
            "",
            "-    def reset_classifier(self, num_classes, global_pool=None, distillation=None):",
            "+    def reset_classifier(self, num_classes, global_pool=None):",
            "self.num_classes = num_classes",
            "if global_pool is not None:",
            "self.global_pool = global_pool",
            "self.head = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()",
            "-        if self.dist:",
            "-            self.head_dist = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()",
            "+        self.head_dist = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()",
            "",
            "@torch.jit.ignore",
            "def set_distilled_training(self, enable=True):"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 6084,
        "change": [
            "class PretrainedTransformerEmbedder(TokenEmbedder):",
            "def get_output_dim(self):",
            "return self.output_dim",
            "",
            "-    def forward(self, token_ids: torch.LongTensor) -> torch.Tensor:  # type: ignore",
            "+    def forward(",
            "+        self, token_ids: torch.LongTensor, attention_mask: torch.LongTensor",
            "+    ) -> torch.Tensor:  # type: ignore",
            "",
            "-        return self.transformer_model(token_ids)[0]",
            "+        return self.transformer_model(input_ids=token_ids, attention_mask=attention_mask)[0]"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 6099,
        "change": [
            "torch_scatter = None",
            "def dev(x: torch.Tensor, as_native: bool = False) -> Union[ivy.Device, torch.device]:",
            "dv = x.device",
            "if as_native:",
            "-        return torch.device(dv.type.replace(\"gpu\", \"cuda\"))",
            "+        if isinstance(dv, torch.device):",
            "+            dv = dv.type",
            "+        return torch.device(dv.replace(\"gpu\", \"cuda\"))",
            "return as_ivy_dev(dv)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 6112,
        "change": [
            "def median(",
            "temp = input",
            "if hasattr(axis, \"__iter__\"):",
            "for dim in axis:",
            "-            temp = torch.median(",
            "+            temp = torch.quantile(",
            "temp,",
            "+                0.5,",
            "dim=dim,",
            "keepdim=keepdims,",
            ")[0]",
            "-        return input",
            "+        return temp",
            "else:",
            "-        return torch.median(",
            "+        return torch.quantile(",
            "input,",
            "+            0.5,",
            "dim=axis,",
            "keepdim=keepdims,",
            ")[0]"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 6121,
        "change": [
            "def test_welford_dense(n_samples, dim_size):",
            "samples.append(sample)",
            "w.update(sample)",
            "",
            "-    sample_cov = np.cov(torch.stack(samples).data.numpy(), bias=False, rowvar=False)",
            "-    estimates = w.get_covariance(regularize=False).data.numpy()",
            "+    sample_cov = np.cov(torch.stack(samples).data.cpu().numpy(), bias=False, rowvar=False)",
            "+    estimates = w.get_covariance(regularize=False).data.cpu().numpy()",
            "assert_equal(estimates, sample_cov)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 6133,
        "change": [
            "def mean_iou(",
            "# TODO: is it possible to vectorize this ?",
            "# iterate over classes",
            "for class_id in range(num_classes):",
            "-        tp: torch.Tensor = conf_mat[..., class_id, class_id].float()",
            "+        tp: torch.Tensor = conf_mat[..., None, class_id, class_id]",
            "total = torch.sum(conf_mat[..., class_id, :], dim=-1, keepdim=True) + \\",
            "torch.sum(conf_mat[..., :, class_id], dim=-1, keepdim=True)",
            "iou_val: torch.Tensor = tp / (total.float() - tp + 1e-6)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Algorithm Error"
    },
    {
        "number": 6219,
        "change": [
            "class BeamSearch(Search):",
            "scores_buf = top_prediction[0]",
            "indices_buf = top_prediction[1]",
            "# Project back into relative indices and beams",
            "-        beams_buf = indices_buf // vocab_size",
            "+        beams_buf = torch.div(indices_buf, vocab_size, rounding_mode='trunc')",
            "indices_buf = indices_buf.fmod(vocab_size)",
            "",
            "# At this point, beams_buf and indices_buf are single-dim and contain relative indices"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 6260,
        "change": [
            "class NanDetector:",
            "def _detect(self, tensor, name, backward):",
            "err = None",
            "if (",
            "-            tensor.numel() >= 2",
            "-        ):  # single value tensors (like the loss) will not provide much info",
            "+            torch.is_floating_point(tensor)",
            "+            # single value tensors (like the loss) will not provide much info",
            "+            and tensor.numel() >= 2",
            "+        ):",
            "with torch.no_grad():",
            "if torch.isnan(tensor).any():",
            "err = \"NaN\""
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Algorithm Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Algorithm Error"
    },
    {
        "number": 6262,
        "change": [
            "class MetaLayer(torch.nn.Module):",
            "# u: [B, F_u]",
            "# batch: [N] with max entry B - 1.",
            "row, col = edge_index",
            "-                out = torch.cat([x[col], edge_attr], dim=1)",
            "+                out = torch.cat([x[row], edge_attr], dim=1)",
            "out = self.node_mlp_1(out)",
            "-                out = scatter_mean(out, row, dim=0, dim_size=x.size(0))",
            "+                out = scatter_mean(out, col, dim=0, dim_size=x.size(0))",
            "out = torch.cat([x, out, u[batch]], dim=1)",
            "return self.node_mlp_2(out)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 6277,
        "change": [
            "def mu_law_encode(audio, quantization_channels):",
            "with tf.name_scope('encode'):",
            "mu = quantization_channels - 1",
            "# Perform mu-law companding transformation (ITU-T, 1988).",
            "-        magnitude = tf.log(1 + mu * tf.abs(audio)) / tf.log(1. + mu)",
            "+        # Minimum operation is here to deal with rare large amplitudes caused by resampling.",
            "+        magnitude = tf.log(1 + mu * tf.minimum(tf.abs(audio), 1.0)) / tf.log(1. + mu)",
            "signal = tf.sign(audio) * magnitude",
            "# Quantize signal to the specified number of levels.",
            "return tf.cast((signal + 1) / 2 * mu + 0.5, tf.int32)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 6316,
        "change": [
            "class GARPNHead(GuidedAnchorHead):",
            "if cfg.min_bbox_size > 0:",
            "w = proposals[:, 2] - proposals[:, 0]",
            "h = proposals[:, 3] - proposals[:, 1]",
            "-                valid_inds = torch.nonzero((w >= cfg.min_bbox_size) &",
            "-                                           (h >= cfg.min_bbox_size)).squeeze()",
            "+                valid_inds = torch.nonzero(",
            "+                    (w >= cfg.min_bbox_size) & (h >= cfg.min_bbox_size),",
            "+                    as_tuple=False).squeeze()",
            "proposals = proposals[valid_inds, :]",
            "scores = scores[valid_inds]",
            "proposals = torch.cat([proposals, scores.unsqueeze(-1)], dim=-1)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 6376,
        "change": [
            "class VideoSequential(ImageSequential):",
            "data_format: str = \"BTCHW\",",
            "same_on_frame: bool = True,",
            "random_apply: Union[int, bool, Tuple[int, int]] = False,",
            "+        random_apply_weights: Optional[List[float]] = None,",
            ") -> None:",
            "-        super().__init__(*args, same_on_batch=None, return_transform=None, keepdim=None, random_apply=random_apply)",
            "+        super().__init__(",
            "+            *args, same_on_batch=None, return_transform=None, keepdim=None, random_apply=random_apply,",
            "+            random_apply_weights=random_apply_weights",
            "+        )",
            "self.same_on_frame = same_on_frame",
            "self.data_format = data_format.upper()",
            "if self.data_format not in [\"BCTHW\", \"BTCHW\"]:"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 6382,
        "change": [
            "def model(X, params, mesh, labels=None, past=None, scope='model', reuse=False, t",
            "# wpe has shape [ctx, embd]",
            "# positions_for would have shape [batch, seq]",
            "# h has shape [batch, seq, embd]",
            "-        zerodim = mtf.Dimension('singleton', 0)",
            "",
            "-        h = mtf.gather(wte, X, zerodim) + mtf.gather(wpe, positions_for(X, past_length, batch_dim), zerodim)",
            "+        h = mtf.gather(wte, X, vocab_dim) + mtf.gather(wpe, positions_for(X, past_length, batch_dim), vocab_dim)",
            "",
            "# Transformer",
            "presents = []"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 6415,
        "change": [
            "def run_api_experiment(input_features, output_features, dataset, **kwargs):",
            "loaded_state = loaded_model.model.state_dict()",
            "bcast_state = hvd.broadcast_object(loaded_state)",
            "for loaded, bcast in zip(loaded_state.values(), bcast_state.values()):",
            "-            assert np.allclose(loaded, bcast)",
            "+            assert torch.allclose(loaded, bcast)",
            "finally:",
            "if output_dir:",
            "shutil.rmtree(output_dir, ignore_errors=True)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Device Management Error"
    },
    {
        "number": 6447,
        "change": [
            "import logging",
            "logger = logging.getLogger(__name__)",
            "",
            "TorchTrainer = None",
            "-TorchTrainable = None",
            "TrainingOperator = None",
            "+BaseTorchTrainable = None",
            "",
            "try:",
            "import torch  # noqa: F401",
            "",
            "-    from ray.util.sgd.torch.torch_trainer import (TorchTrainer, TorchTrainable)",
            "+    from ray.util.sgd.torch.torch_trainer import (TorchTrainer,",
            "+                                                  BaseTorchTrainable)",
            "",
            "from ray.util.sgd.torch.training_operator import TrainingOperator",
            "",
            "-    __all__ = [\"TorchTrainer\", \"TorchTrainable\", \"TrainingOperator\"]",
            "+    __all__ = [\"TorchTrainer\", \"BaseTorchTrainable\", \"TrainingOperator\"]",
            "except ImportError:",
            "logger.warning(\"PyTorch not found. TorchTrainer will not be available\")"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 6455,
        "change": [
            "def rand_segments(",
            "T = segment_size",
            "if _x_lenghts is None:",
            "_x_lenghts = T",
            "-    len_diff = _x_lenghts - segment_size + 1",
            "+    len_diff = _x_lenghts - segment_size",
            "if let_short_samples:",
            "_x_lenghts[len_diff < 0] = segment_size",
            "-        len_diff = _x_lenghts - segment_size + 1",
            "+        len_diff = _x_lenghts - segment_size",
            "else:",
            "assert all(",
            "len_diff > 0",
            "), f\" [!] At least one sample is shorter than the segment size ({segment_size}). \\n {_x_lenghts}\"",
            "-    segment_indices = (torch.rand([B]).type_as(x) * len_diff).long()",
            "-    ret = segment(x, segment_indices, segment_size)",
            "+    segment_indices = (torch.rand([B]).type_as(x) * (len_diff + 1)).long()",
            "+    ret = segment(x, segment_indices, segment_size, pad_short=pad_short)",
            "return ret, segment_indices"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 6467,
        "change": [
            "def log_tensorboard_graph(tb, model, imgsz=(640, 640)):",
            "try:",
            "p = next(model.parameters())  # for device, type",
            "imgsz = (imgsz, imgsz) if isinstance(imgsz, int) else imgsz  # expand",
            "-        im = torch.empty((1, 3, *imgsz)).to(p.device).type_as(p)  # input image",
            "+        im = torch.zeros((1, 3, *imgsz)).to(p.device).type_as(p)  # input image (WARNING: must be zeros, not empty)",
            "with warnings.catch_warnings():",
            "warnings.simplefilter('ignore')  # suppress jit trace warning",
            "tb.add_graph(torch.jit.trace(de_parallel(model), im, strict=False), [])"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 6489,
        "change": [
            "class LayerNorm2d(nn.LayerNorm):",
            "return F.layer_norm(",
            "x.permute(0, 2, 3, 1), self.normalized_shape, self.weight, self.bias, self.eps).permute(0, 3, 1, 2)",
            "else:",
            "-            s, u = torch.var_mean(x, dim=1, keepdim=True)",
            "+            s, u = torch.var_mean(x, dim=1, unbiased=False, keepdim=True)",
            "x = (x - u) * torch.rsqrt(s + self.eps)",
            "x = x * self.weight[:, None, None] + self.bias[:, None, None]",
            "return x"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 6504,
        "change": [
            "def build_lm_labels(sequence, pad_token):",
            "def build_mask(sequence, pad_token):",
            "\"\"\" Builds the mask. The attention mechanism will only attend to positions",
            "with value 1. \"\"\"",
            "-    mask = sequence.clone()",
            "-    mask[mask != pad_token] = 1",
            "-    mask[mask == pad_token] = 0",
            "+    mask = torch.ones_like(sequence)",
            "+    idx_pad_tokens = (sequence == pad_token)",
            "+    mask[idx_pad_tokens] = 0",
            "return mask"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Condition",
        "Action_Element": "Replace API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 6508,
        "change": [
            "class TFTransfoXLMainLayer(tf.keras.layers.Layer):",
            "",
            "# There are `mlen + qlen` steps that can be cached into mems",
            "new_mems = []",
            "-        end_idx = mlen + max(0, qlen)",
            "-        beg_idx = max(0, end_idx - self.mem_len)",
            "+        end_idx = mlen + tf.math.maximum(0, qlen)",
            "+        beg_idx = tf.math.maximum(0, end_idx - tf.convert_to_tensor(self.mem_len))",
            "for i in range(len(hids)):",
            "",
            "cat = tf.concat([mems[i], hids[i]], axis=0)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 6517,
        "change": [
            "def from_tfds_to_path(tfds_dataset_name: str, split: str, hub_ds_path: str, batc",
            "return from_tfds(tfds_ds=tfds_ds, ds=ds)",
            "",
            "",
            "-def from_tfds(tfds_ds: (tensorflow.data.Dataset), ds: (Dataset)):",
            "+def from_tfds(tfds_ds: tensorflow.data.Dataset, ds: Dataset):",
            "+    \"\"\"Converts a tfds dataset to hub dataset",
            "+    Args:",
            "+        tfds_ds (tensorflow.data.Dataset): A tfds_dataset object.",
            "+        ds (Dataset) : A Hub dataset object where Tensor will be created.",
            "+    Returns:",
            "+        A hub dataset",
            "+    \"\"\"",
            "tfds_numpy = tfds.as_numpy(tfds_ds)  # Convert `tf.data.Dataset` to Python generator",
            "",
            "for ex in tqdm(tfds_numpy):"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 6546,
        "change": [
            "def unpackbits_masks(masks):",
            "unpacked = tf.bitwise.bitwise_and(tf.expand_dims(masks, -1), bits) > 0",
            "unpacked = tf.reshape(",
            "unpacked,",
            "-        tf.concat([tf.shape(masks)[:-1], [-1]], axis=0))",
            "+        tf.concat([tf.shape(masks)[:-1], [8 * tf.shape(masks)[-1]]], axis=0))",
            "return unpacked"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 6551,
        "change": [
            "def _take_channels(*xs, ignore_channels=None):",
            "return xs",
            "else:",
            "channels = [channel for channel in range(xs[0].shape[1]) if channel not in ignore_channels]",
            "-        xs = [torch.index_select(x, dim=1, index=torch.tensor(channels)) for x in xs]",
            "+        xs = [torch.index_select(x, dim=1, index=torch.tensor(channels).to(x.device)) for x in xs]",
            "return xs"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 6613,
        "change": [
            "class TokenCharactersEncoder(TokenEmbedder):",
            "self._dropout = lambda x: x",
            "",
            "def get_output_dim(self) -> int:",
            "-        return self._encoder._module.get_output_dim()  # pylint: disable=protected-access",
            "+        return self._encoder._module.get_output_dim()",
            "",
            "-    def forward(self, token_characters: torch.Tensor) -> torch.Tensor:  # pylint: disable=arguments-differ",
            "+    def forward(self, token_characters: torch.Tensor) -> torch.Tensor:",
            "mask = (token_characters != 0).long()",
            "return self._dropout(self._encoder(self._embedding(token_characters), mask))",
            "",
            "# The setdefault requires a custom from_params",
            "@classmethod",
            "def from_params(cls, vocab: Vocabulary, params: Params) -> 'TokenCharactersEncoder':  # type: ignore",
            "-        # pylint: disable=arguments-differ",
            "+",
            "embedding_params: Params = params.pop(\"embedding\")",
            "# Embedding.from_params() uses \"tokens\" as the default namespace, but we need to change",
            "# that to be \"token_characters\" by default. If num_embeddings is present, set default namespace"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Null Reference Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Null Reference Error"
    },
    {
        "number": 6629,
        "change": [
            "class Normalize(Preprocessor):",
            "\"\"\"",
            "",
            "def __init__(self, scope='normalize', summary_labels=()):",
            "-        super(Normalize).__init__(scope, summary_labels)",
            "+        super(Normalize, self).__init__(scope=scope, summary_labels=summary_labels)",
            "",
            "def tf_process(self, tensor):",
            "# Min/max across every axis except batch dimension.",
            "-        min = tf.reduce_min(input_tensor=tensor, axis=np.arange(1, util.rank(tensor)))",
            "-        max = tf.reduce_max(input_tensor=tensor, axis=np.arange(1, util.rank(tensor)))",
            "+        min_value = tf.reduce_min(input_tensor=tensor, axis=np.arange(1, util.rank(tensor)))",
            "+        max_value = tf.reduce_max(input_tensor=tensor, axis=np.arange(1, util.rank(tensor)))",
            "",
            "-        return (tensor - min) / (max - min + util.epsilon)",
            "+        return (tensor - min_value) / (max_value - min_value + util.epsilon)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 6695,
        "change": [
            "class Conv(Layer):",
            "inputs = tf.pad(inputs, self._compute_causal_padding(inputs))",
            "",
            "if self.groups > 1:",
            "-            outputs = self._jit_compiled_convolution_op(inputs, self.kernel)",
            "+            outputs = self._jit_compiled_convolution_op(",
            "+                inputs, tf.convert_to_tensor(self.kernel)",
            "+            )",
            "else:",
            "outputs = self.convolution_op(inputs, self.kernel)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 6714,
        "change": [
            "def main():",
            "'op_names': ['features.6', 'features.9', 'features.13', 'features.16', 'features.20', 'classifier.2', 'classifier.5']",
            "}]",
            "",
            "-    quantizer = BNNQuantizer(model, configure_list)",
            "+    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)",
            "+    quantizer = BNNQuantizer(model, configure_list, optimizer)",
            "model = quantizer.compress()",
            "",
            "print('=' * 10 + 'train' + '=' * 10)",
            "-    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)",
            "best_top1 = 0",
            "for epoch in range(400):",
            "print('# Epoch {} #'.format(epoch))"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 6720,
        "change": [
            "class Dataset(DatasetInfoMixin, IndexableMixin):",
            "- if `dataset_path` is a path of a dataset dict directory: a :class:`DatasetDict` with each split.",
            "\"\"\"",
            "# copies file from filesystem if it is remote filesystem to local filesystem and modifies dataset_path to temp directory containing local copies",
            "+        fs = fsspec.filesystem(\"file\") if fs is None else fs",
            "+        dataset_dict_json_path = Path(dataset_path, config.DATASETDICT_JSON_FILENAME).as_posix()",
            "+        dataset_info_path = Path(dataset_path, config.DATASET_INFO_FILENAME).as_posix()",
            "+        if not fs.isfile(dataset_info_path) and fs.isfile(dataset_dict_json_path):",
            "+            raise FileNotFoundError(",
            "+                f\"No such file or directory: '{dataset_info_path}'. Expected to load a Dataset object, but got a DatasetDict. Please use datasets.load_from_disk instead.\"",
            "+            )",
            "+",
            "if is_remote_filesystem(fs):",
            "src_dataset_path = extract_path_from_uri(dataset_path)",
            "tmp_dir = tempfile.TemporaryDirectory()"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Null Reference Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Program Crash|Null Reference Error"
    },
    {
        "number": 6759,
        "change": [
            "def test_graph_store():",
            "def test_graph_store_conversion():",
            "graph_store = MyGraphStore()",
            "",
            "-    coo = (row, col) = get_edge_index(100, 100, 300)",
            "+    coo = (row, col) = get_random_edge_index(100, 100, 300)",
            "adj = SparseTensor(row=row, col=col, sparse_sizes=(100, 100))",
            "csr, csc = adj.csr()[:2], adj.csc()[:2][::-1]"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 6763,
        "change": [
            "class StableDiffusionInpaintPipelineLegacy(DiffusionPipeline):",
            "init_latents_orig = init_latents",
            "",
            "# add noise to latents using the timesteps",
            "-        noise = torch.randn(init_latents.shape, generator=generator, device=self.device, dtype=dtype)",
            "+        noise = randn_tensor(init_latents.shape, generator=generator, device=self.device, dtype=dtype)",
            "init_latents = self.scheduler.add_noise(init_latents, noise, timestep)",
            "latents = init_latents",
            "return latents, init_latents_orig, noise"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 6803,
        "change": [
            "def fully_connected_with_w(x, use_bias=True, sn=False, reuse=False, scope='linea",
            "if sn :",
            "w = tf.get_variable(\"kernel\", [channels, 1], tf.float32,",
            "initializer=weight_init, regularizer=weight_regularizer)",
            "+            w = spectral_norm(w)",
            "+",
            "if use_bias :",
            "bias = tf.get_variable(\"bias\", [1],",
            "initializer=tf.constant_initializer(0.0))",
            "",
            "-                x = tf.matmul(x, spectral_norm(w)) + bias",
            "+                x = tf.matmul(x, w) + bias",
            "else :",
            "-                x = tf.matmul(x, spectral_norm(w))",
            "+                x = tf.matmul(x, w)",
            "+",
            "else :",
            "x = tf.layers.dense(x, units=1, kernel_initializer=weight_init, kernel_regularizer=weight_regularizer, use_bias=use_bias)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 6811,
        "change": [
            "def audio_config():",
            "@pytest.mark.parametrize(\"encoder\", [\"rnn\", \"stacked_cnn\", \"parallel_cnn\", \"stacked_parallel_cnn\", \"rnn\", \"cnnrnn\"])",
            "def test_audio_input_feature(audio_config: Dict, encoder: str) -> None:",
            "audio_config.update({\"encoder\": encoder})",
            "-    audio_input_feature = AudioInputFeature(audio_config)",
            "-    audio_tensor = torch.randn([BATCH_SIZE, SEQ_SIZE, AUDIO_W_SIZE], dtype=torch.float32)",
            "+    audio_input_feature = AudioInputFeature(audio_config).to(DEVICE)",
            "+    audio_tensor = torch.randn([BATCH_SIZE, SEQ_SIZE, AUDIO_W_SIZE], dtype=torch.float32).to(DEVICE)",
            "encoder_output = audio_input_feature(audio_tensor)",
            "-    assert encoder_output[\"encoder_output\"].shape[1:] == audio_input_feature.encoder_obj.output_shape",
            "+    assert encoder_output[\"encoder_output\"].shape[1:] == audio_input_feature.output_shape"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 6839,
        "change": [
            "def trunc(",
            "elif not (\"int\" in str(x.dtype)):",
            "if not ret.get_shape().ndims == 0:",
            "ret = tf.tensor_scatter_nd_update(",
            "-                x, tf.where(tf.greater(x, 0)), tf.math.floor(x[x > 0])",
            "+                x, tf.where(tf.greater_equal(x, 0)), tf.math.floor(x[x >= 0])",
            ")",
            "ret = tf.tensor_scatter_nd_update(",
            "ret, tf.where(tf.less(x, 0)), tf.math.ceil(x[x < 0])",
            ")",
            "else:",
            "-            ret = (tf.math.floor if ret > 0 else tf.math.ceil)(ret)",
            "+            ret = (tf.math.floor if ret >= 0 else tf.math.ceil)(ret)",
            "return ret"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 6843,
        "change": [
            "class FocalLoss(nn.Module):",
            "device=input.device, dtype=input.dtype)",
            "",
            "# compute the actual focal loss",
            "-        prob = input_soft * target_one_hot",
            "+        prob = input_soft * target_one_hot + self.eps",
            "focal = -torch.log(prob) * self.alpha * (1. - prob) ** self.gamma",
            "-        loss_tmp = 1. - torch.sum(focal, dim=1)",
            "+        loss_tmp = torch.sum(focal, dim=1)",
            "",
            "loss = -1",
            "if self.reduction == 'none':"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 6895,
        "change": [
            "class InMemoryDataset(Dataset):",
            "",
            "for item, key in product(data_list, keys):",
            "data[key].append(item[key])",
            "-            s = slices[key][-1] + item[key].size(item.cat_dim(key))",
            "+            s = slices[key][-1] + item[key].size(item.cat_dim(key, item))",
            "slices[key].append(s)",
            "",
            "for key in keys:",
            "-            data[key] = torch.cat(data[key], dim=data_list[0].cat_dim(key))",
            "+            data[key] = torch.cat(",
            "+                data[key], dim=data_list[0].cat_dim(key, item))",
            "slices[key] = torch.LongTensor(slices[key])",
            "",
            "return data, slices"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 6896,
        "change": [
            "class CLIPModel(CLIPPreTrainedModel):",
            "",
            "self.visual_projection = nn.Linear(self.vision_embed_dim, self.projection_dim, bias=False)",
            "self.text_projection = nn.Linear(self.text_embed_dim, self.projection_dim, bias=False)",
            "-        self.logit_scale = nn.Parameter(torch.ones([]))",
            "+        self.logit_scale = nn.Parameter(torch.ones([]) * self.config.logit_scale_init_value)",
            "",
            "self.init_weights()"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 6898,
        "change": [
            "class BBoxHead(nn.Module):",
            "keep_inds = pos_is_gts_.new_ones(num_rois)",
            "keep_inds[:len(pos_is_gts_)] = pos_keep",
            "",
            "-            bboxes_list.append(bboxes[keep_inds])",
            "+            bboxes_list.append(bboxes[keep_inds.type(torch.bool)])",
            "",
            "return bboxes_list"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 6930,
        "change": [
            "class BloomForSequenceClassification(BloomPreTrainedModel):",
            "sequence_lengths = -1",
            "else:",
            "if input_ids is not None:",
            "-                sequence_lengths = torch.ne(input_ids, self.config.pad_token_id).sum(dim=-1) - 1",
            "+                sequence_lengths = (torch.ne(input_ids, self.config.pad_token_id).sum(-1) - 1).to(logits.device)",
            "else:",
            "sequence_lengths = -1",
            "logger.warning("
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 6965,
        "change": [
            "class RecurrentTFModelV2(TFModelV2):",
            "shape=(None, obs_space.shape[0]))",
            "state_in_h = tf.keras.layers.Input(shape=(256, ))",
            "state_in_c = tf.keras.layers.Input(shape=(256, ))",
            "-                seq_in = tf.keras.layers.Input(shape=())",
            "+                seq_in = tf.keras.layers.Input(shape=(), dtype=tf.int32)",
            "",
            "# Send to LSTM cell",
            "lstm_out, state_h, state_c = tf.keras.layers.LSTM("
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 6975,
        "change": [
            "logger = logging.getLogger(__name__)  # pylint: disable=invalid-name",
            "",
            "try:",
            "import tensorflow as tf",
            "-    assert int(tf.__version__[0]) >= 2",
            "+    assert hasattr(tf, '__version__') and int(tf.__version__[0]) >= 2",
            "_tf_available = True  # pylint: disable=invalid-name",
            "logger.info(\"TensorFlow version {} available.\".format(tf.__version__))",
            "except (ImportError, AssertionError):"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 6979,
        "change": [
            "class ModelCheckpoint(Callback):",
            "",
            "# do not save nan, replace with +/- inf",
            "if isinstance(current, torch.Tensor) and torch.isnan(current):",
            "-            current = torch.tensor(float(\"inf\" if self.mode == \"min\" else \"-inf\"))",
            "+            current = torch.tensor(float(\"inf\" if self.mode == \"min\" else \"-inf\"), device=current.device)",
            "",
            "filepath = self._get_metric_interpolated_filepath_name(monitor_candidates, trainer, del_filepath)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 6981,
        "change": [
            "class QNAFModel(QModel):",
            "l_matrix = flat_stddev",
            "l_matrix = tf.exp(l_matrix)",
            "else:",
            "-            l_matrix = tf.map_fn(fn=tf.diag, elems=flat_stddev)",
            "+            l_matrix = tf.linalg.diag(diagonal=flat_stddev)",
            "",
            "l_entries = self.l_entries[name].apply(x=embedding)",
            "l_entries = tf.exp(l_entries)"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 7035,
        "change": [
            "def bag_config():",
            "@pytest.mark.parametrize(\"encoder\", [\"embed\"])",
            "def test_bag_input_feature(bag_config: Dict, encoder: str) -> None:",
            "bag_config.update({\"encoder\": encoder})",
            "-    bag_input_feature = BagInputFeature(bag_config)",
            "-    bag_tensor = torch.randn([BATCH_SIZE, SEQ_SIZE, BAG_W_SIZE], dtype=torch.float32)",
            "+    bag_input_feature = BagInputFeature(bag_config).to(DEVICE)",
            "+    bag_tensor = torch.randn([BATCH_SIZE, SEQ_SIZE, BAG_W_SIZE], dtype=torch.float32).to(DEVICE)",
            "encoder_output = bag_input_feature(bag_tensor)",
            "-    assert encoder_output[\"encoder_output\"].shape[1:][1:] == bag_input_feature.encoder_obj.output_shape",
            "+    assert encoder_output[\"encoder_output\"].shape[1:][1:] == bag_input_feature.output_shape"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 7045,
        "change": [
            "def test_auto_scale_batch_size_set_model_attribute(tmpdir, use_hparams):",
            "",
            "trainer = Trainer(default_root_dir=tmpdir, max_epochs=1, auto_scale_batch_size=True)",
            "trainer.tune(model, datamodule_fit)",
            "-    assert trainer.datamodule == datamodule_fit",
            "after_batch_size = model.hparams.batch_size if use_hparams else model.batch_size",
            "+    assert trainer.datamodule == datamodule_fit",
            "assert before_batch_size != after_batch_size",
            "+    assert after_batch_size <= len(trainer.train_dataloader.dataset)",
            "assert datamodule_fit.batch_size == after_batch_size",
            "# should be left unchanged, since it was not passed to .tune()",
            "assert datamodule_model.batch_size == 111"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Null Reference Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Program Crash|Null Reference Error"
    },
    {
        "number": 7063,
        "change": [
            "class PytorchBackendCompiler(Compiler):",
            "input_sample = input_data.get_list(1)[0]",
            "if self.device is Device.GPU:",
            "if quantization_type is QuantizationType.HALF:",
            "-                input_sample = [t.cuda().half() for t in input_sample]",
            "+                input_sample = [",
            "+                    t.cuda().half() if torch.is_floating_point(t) else t.cuda()",
            "+                    for t in input_sample",
            "+                ]",
            "else:",
            "input_sample = [t.cuda() for t in input_sample]"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 7079,
        "change": [
            "def test_api_training_determinism(csv_filename):",
            "",
            "divergence = False",
            "for weight_1, weight_2 in zip(model_weights_1, model_weights_2):",
            "-            if not np.allclose(weight_1, weight_2):",
            "+            if not torch.allclose(weight_1, weight_2):",
            "divergence = True",
            "break",
            "assert divergence, 'model_1 and model_2 have identical weights with different seeds!'",
            "",
            "for weight_1, weight_3 in zip(model_weights_1, model_weights_3):",
            "-            assert np.allclose(weight_1, weight_3)",
            "+            assert torch.allclose(weight_1, weight_3)",
            "",
            "",
            "def run_api_commands("
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 7109,
        "change": [
            "class TFOptimizer(Optimizer):",
            "arguments: Dict of arguments for passing to fn_loss as **kwargs.",
            "fn_loss: A callable taking arguments as kwargs and returning the loss op.",
            "\"\"\"",
            "-        loss = fn_loss(**arguments)",
            "+        # Trivial operation to enforce control dependency",
            "+        previous_variables = [util.identity_operation(x=variable) for variable in variables]",
            "",
            "# Force loss value to be calculated.",
            "-        with tf.control_dependencies(control_inputs=(loss,)):",
            "-            # Trivial operation to enforce control dependency",
            "-            previous_variables = [util.identity_operation(x=variable) for variable in variables]",
            "+        with tf.control_dependencies(control_inputs=previous_variables):",
            "+            loss = fn_loss(**arguments)",
            "",
            "# The actual tensorflow minimize op.",
            "-        with tf.control_dependencies(control_inputs=previous_variables):",
            "+        with tf.control_dependencies(control_inputs=(loss,)):",
            "# colocate_gradients_with_ops=True",
            "applied = self.optimizer.minimize(loss=loss, var_list=variables)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 7132,
        "change": [
            "class Trainer(Registrable):",
            "self.optimizer.zero_grad()",
            "",
            "loss = self.batch_loss(batch, for_training=True)",
            "+            if torch.isnan(loss):",
            "+                raise ValueError(\"nan loss encountered\")",
            "+",
            "loss.backward()",
            "",
            "train_loss += loss.item()"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Program Crash|Algorithm Error"
    },
    {
        "number": 7145,
        "change": [
            "def patch_tf_keras():",
            "from tensorflow.python.keras.engine import training_arrays",
            "from tensorflow.python.keras.engine import training_generator",
            "",
            "-    training_v2 = wandb.util.import_module('tensorflow.python.keras.engine.training_v2')",
            "+    training_v2 = wandb.util.get_module('tensorflow.python.keras.engine.training_v2')",
            "old_arrays = training_arrays.fit_loop",
            "old_generator = training_generator.fit_generator",
            "if training_v2:"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Deprecation Management Error"
    },
    {
        "number": 7154,
        "change": [
            "def corr2d(X, K):  #@save",
            "Y = tf.Variable(tf.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1)))",
            "for i in range(Y.shape[0]):",
            "for j in range(Y.shape[1]):",
            "-            Y[i, j].assign(tf.reduce_sum(X[i: i + h, j: j + w] * K))",
            "+            Y[i, j].assign(tf.cast(tf.reduce_sum(",
            "+                X[i: i + h, j: j + w] * K), dtype=tf.float32))",
            "return Y"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 7185,
        "change": [
            "def get_item(",
            "x: torch.Tensor,",
            "query: torch.Tensor,",
            ") -> torch.Tensor:",
            "-    if ivy.dtype(query, as_native=True) is torch.bool:",
            "-        return x.__getitem__(query)",
            "-    return x.__getitem__(query.to(torch.int64))",
            "+    if ivy.is_array(query) and ivy.dtype(query, as_native=True) is not torch.bool:",
            "+        return x.__getitem__(query.to(torch.int64))",
            "+    return x.__getitem__(query)",
            "",
            "",
            "def to_numpy(x: torch.Tensor, /, *, copy: bool = True) -> np.ndarray:"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 7191,
        "change": [
            "class PulsarPointsRenderer(nn.Module):",
            "raster_rad = self.rasterizer.raster_settings.radius",
            "if kwargs.get(\"radius_world\", False):",
            "return raster_rad",
            "-        if isinstance(raster_rad, torch.Tensor) and raster_rad.numel() > 1:",
            "+        if (",
            "+            isinstance(raster_rad, torch.Tensor)",
            "+            and raster_rad.numel() > 1",
            "+            and raster_rad.ndim > 1",
            "+        ):",
            "# In this case it must be a batched torch tensor.",
            "raster_rad = raster_rad[cloud_idx]",
            "if orthogonal_projection:"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 7215,
        "change": [
            "class GPTNeoXForCausalLM(GPTNeoXPreTrainedModel):",
            "attention_mask = input_ids.new_ones(input_shape)",
            "",
            "# cut decoder_input_ids if past is used",
            "-        if past is not None:",
            "+        if past and past[0] is not None:",
            "input_ids = input_ids[:, -1:]",
            "",
            "return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"past_key_values\": past}"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Null Reference Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Null Reference Error"
    },
    {
        "number": 7261,
        "change": [
            "class PolicyGradientModel(Model):",
            "",
            "with tf.variable_scope('distribution'):",
            "for action, distribution in self.distribution.items():",
            "-                distribution.create_tf_operations(x=self.network.output, deterministic=self.deterministic)",
            "+                with tf.variable_scope(action):",
            "+                    distribution.create_tf_operations(x=self.network.output, deterministic=self.deterministic)",
            "self.action_taken[action] = distribution.sample()",
            "",
            "if self.baseline:"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 7271,
        "change": [
            "def generate_examples(features: dict, num_examples=100, seq_shapes=None):",
            "def generate_example_dataset(dataset_path, features, num_examples=100, seq_shapes=None):",
            "dummy_data = generate_examples(features, num_examples=num_examples, seq_shapes=seq_shapes)",
            "",
            "-    writer = datasets.ArrowWriter(features=features, path=dataset_path)",
            "-    for key, record in dummy_data:",
            "-        example = features.encode_example(record)",
            "-        writer.write(example)",
            "+    with datasets.ArrowWriter(features=features, path=dataset_path) as writer:",
            "+        for key, record in dummy_data:",
            "+            example = features.encode_example(record)",
            "+            writer.write(example)",
            "",
            "-    num_final_examples, num_bytes = writer.finalize()",
            "+        num_final_examples, num_bytes = writer.finalize()",
            "",
            "assert (",
            "num_final_examples == num_examples"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 7293,
        "change": [
            "class DistributedModel(object):",
            "",
            "grad_var_list = list(zip(self.gradients, self.global_network.get_variables()))",
            "",
            "-            global_step_inc = self.global_step.assign_add(self.batch_size)",
            "+            global_step_inc = self.global_step.assign_add(tf.shape(self.state)[0])",
            "",
            "self.assign_global_to_local = tf.group(*[v1.assign(v2) for v1, v2 in",
            "zip(self.local_network.get_variables(),"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 7298,
        "change": [
            "class Model(ModelDesc):",
            "for idx, b in enumerate([b1, b2, b3, b4, b5, final_map]):",
            "output = tf.nn.sigmoid(b, name='output{}'.format(idx+1))",
            "xentropy = class_balanced_sigmoid_cross_entropy(",
            "-                b, edgemap,",
            "+                tf.squeeze(b, [3]), edgemap,",
            "name='xentropy{}'.format(idx+1))",
            "costs.append(xentropy)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 7333,
        "change": [
            "class TensorBoard(Callback):",
            "embedding_input = tf.reshape(embedding_input,",
            "(step, int(embedding_size)))",
            "shape = (self.embeddings_data[0].shape[0], int(embedding_size))",
            "-                    embedding = tf.Variable(tf.zeros(shape),",
            "-                                            name=layer.name + '_embedding')",
            "+                    embedding = K.variable(K.zeros(shape),",
            "+                                           name=layer.name + '_embedding')",
            "embeddings_vars[layer.name] = embedding",
            "batch = tf.assign(embedding[batch_id:batch_id + step],",
            "embedding_input)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 7336,
        "change": [
            "def build_targets(p, targets, model):",
            "if use_all_anchors:",
            "na = anchor_vec.shape[0]  # number of anchors",
            "a = torch.arange(na).view(-1, 1).repeat(1, nt).view(-1)",
            "-                t = targets.repeat(na, 1)",
            "+                t = t.repeat(na, 1)",
            "else:  # use best anchor only",
            "iou, a = iou.max(0)  # best iou and anchor"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 7364,
        "change": [
            "def zca_mean(inp: torch.Tensor, dim: int = 0,",
            "else:",
            "cov = cov / float(N)",
            "",
            "-    U, S, _ = torch.svd(cov)",
            "+    U, S, _ = _torch_svd_cast(cov)",
            "",
            "S = S.reshape(-1, 1)",
            "S_inv_root: torch.Tensor = torch.rsqrt(S + eps)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 7375,
        "change": [
            "class PretrainedTransformerMismatchedEmbedder(TokenEmbedder):",
            "span_embeddings_sum = span_embeddings.sum(2)",
            "span_embeddings_len = span_mask.sum(2)",
            "# Shape: (batch_size, num_orig_tokens, embedding_size)",
            "-        orig_embeddings = span_embeddings_sum / span_embeddings_len",
            "+        orig_embeddings = span_embeddings_sum / torch.clamp_min(span_embeddings_len, 1)",
            "",
            "# All the places where the span length is zero, write in zeros.",
            "orig_embeddings[(span_embeddings_len == 0).expand(orig_embeddings.shape)] = 0"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 7386,
        "change": [
            "class PipelineTesterMixin:",
            "",
            "with tempfile.TemporaryDirectory() as tmpdir:",
            "pipe.save_pretrained(tmpdir)",
            "-            pipe_loaded = self.pipeline_class.from_pretrained(tmpdir)",
            "+            pipe_loaded = self.pipeline_class.from_pretrained(tmpdir, torch_dtype=torch.float16)",
            "pipe_loaded.to(torch_device)",
            "pipe_loaded.set_progress_bar_config(disable=None)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 7392,
        "change": [
            "def main():",
            "# train",
            "logging.info('backend = ' + args.backend)",
            "if args.backend == \"chainer\":",
            "-        from espnet.lm.chain.lm_chainer import train",
            "+        from espnet.lm.chain.lm import train",
            "train(args)",
            "elif args.backend == \"pytorch\":",
            "-        from espnet.lm.pytorch.lm_pytorch import train",
            "+        from espnet.lm.pytorch.lm import train",
            "train(args)",
            "else:",
            "raise ValueError(\"Only chainer and pytorch are supported.\")"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 7443,
        "change": [
            "class SimpleSummarizationPipelineTests(unittest.TestCase):",
            "# Bias output towards L",
            "V, C = model.lm_head.weight.shape",
            "",
            "-        bias = torch.zeros(V, requires_grad=True)",
            "+        bias = torch.zeros(V)",
            "bias[76] = 10",
            "",
            "model.lm_head.bias = torch.nn.Parameter(bias)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 7451,
        "change": [
            "def to_hetero(module: Module, metadata: Metadata, aggr: str = \"sum\",",
            "import torch",
            "from torch_geometric.nn import SAGEConv, to_hetero",
            "",
            "-        Net(torch.nn.Module):",
            "+        class GNN(torch.nn.Module):",
            "def __init__(self):",
            "-                self.conv1 = SAGEConv(-1, 16)",
            "-                self.conv2 = SAGEConv(16, 16)",
            "+                self.conv1 = SAGEConv((-1, -1), 32)",
            "+                self.conv2 = SAGEConv((32, 32), 32)",
            "",
            "def forward(self, x, edge_index):",
            "x = self.conv1(x, edge_index).relu()",
            "x = self.conv2(x, edge_index).relu()",
            "return x",
            "",
            "-        model = Net()",
            "+        model = GNN()",
            "",
            "node_types = ['paper', 'author']",
            "edge_types = ["
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 7456,
        "change": [
            "def get_batch_statistics(outputs, targets, iou_threshold):",
            "continue",
            "",
            "# Filter target_boxes by pred_label so that we only match against boxes of our own label",
            "-                filtered_target_position, filtered_targets = zip(*filter(lambda x: target_labels[x] == pred_label, enumerate(target_boxes)))",
            "-",
            "+                filtered_target_position, filtered_targets = zip(*filter(lambda x: target_labels[x[0]] == pred_label, enumerate(target_boxes)))",
            "+",
            "# Find the best matching target for our predicted box",
            "-                iou, box_filtered_index = bbox_iou(pred_box.unsqueeze(0), filtered_targets).max(0)",
            "-",
            "+                iou, box_filtered_index = bbox_iou(pred_box.unsqueeze(0), torch.stack(filtered_targets)).max(0)",
            "+",
            "# Remap the index in the list of filtered targets for that label to the index in the list with all targets.",
            "box_index = filtered_target_position[box_filtered_index]"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 7493,
        "change": [
            "class XLNetRelativeAttention(nn.Module):",
            "attn_vec = torch.einsum('bnij,jbnd->ibnd', attn_prob, v_head_h)",
            "",
            "if self.output_attentions:",
            "-            return attn_vec, attn_prob",
            "+            return attn_vec, torch.einsum('bnij->ijbn', attn_prob)",
            "",
            "return attn_vec"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 7499,
        "change": [
            "class VGG(Model):",
            "",
            "inputs = inputs * 255 - np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape([1, 1, 1, 3])",
            "",
            "-        out = self.layers(inputs)",
            "+        out = self.layers.forward(inputs)",
            "return out"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 7519,
        "change": [
            "class CapsNet(object):",
            "else:",
            "# self.masked_v = tf.matmul(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, 10, 1)), transpose_a=True)",
            "self.masked_v = tf.multiply(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, 10, 1)))",
            "-                self.v_length = tf.sqrt(tf.reduce_sum(tf.square(self.caps2), axis=2, keep_dims=True) + epsilon)",
            "+                self.v_length = tf.sqrt(reduce_sum(tf.square(self.caps2), axis=2, keepdims=True) + epsilon)",
            "",
            "# 2. Reconstructe the MNIST images with 3 FC layers",
            "# [batch_size, 1, 16, 1] => [batch_size, 16] => [batch_size, 512]"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 7528,
        "change": [
            "class Uniform(Distribution):",
            "if x.size != a.size():",
            "a = a.expand_as(x)",
            "b = b.expand_as(x)",
            "-        l = x.ge(a).type_as(a)",
            "-        u = x.le(b).type_as(b)",
            "+        lb = x.ge(a).type_as(a)",
            "+        ub = x.le(b).type_as(b)",
            "batch_log_pdf_shape = self.batch_shape(a, b) + (1,)",
            "-        return torch.sum(torch.log(l.mul(u)) - torch.log(b - a), -1).contiguous().view(batch_log_pdf_shape)",
            "+        return torch.sum(torch.log(lb.mul(ub)) - torch.log(b - a), -1).contiguous().view(batch_log_pdf_shape)",
            "",
            "def analytic_mean(self, a=None, b=None):",
            "a, b = self._sanitize_input(a, b)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 7559,
        "change": [
            "class SSIMLoss(torch.nn.Module):",
            "",
            "if ssim_loss.item() > 1.0:",
            "print(f\" > SSIM loss is out-of-range {ssim_loss.item()}, setting it 1.0\")",
            "-            ssim_loss = torch.tensor([1.0])",
            "+            ssim_loss = torch.tensor([1.0], device=ssim_loss.device)",
            "",
            "if ssim_loss.item() < 0.0:",
            "print(f\" > SSIM loss is out-of-range {ssim_loss.item()}, setting it 0.0\")",
            "-            ssim_loss = torch.tensor([0.0])",
            "+            ssim_loss = torch.tensor([0.0], device=ssim_loss.device)",
            "",
            "return ssim_loss"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 7597,
        "change": [
            "class LstmTagger(Model):",
            "",
            "def forward(self,",
            "sentence: Dict[str, torch.Tensor],",
            "-                labels: torch.Tensor = None) -> torch.Tensor:",
            "+                labels: torch.Tensor = None) -> Dict[str, torch.Tensor]:",
            "mask = get_text_field_mask(sentence)",
            "embeddings = self.word_embeddings(sentence)",
            "encoder_out = self.encoder(embeddings, mask)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 7601,
        "change": [
            "class TensorFlowEstimator(BaseEstimator):",
            "# Set up a single operator to merge all the summaries",
            "summary_op = tf.merge_all_summaries()",
            "# Set up summary writer to a tmp directory",
            "-        self._summary_writer = tf.train.SummaryWriter('/tmp/tensorflow_logs', graph_def=sess.graph_def)",
            "+        self._summary_writer = tf.train.SummaryWriter('/tmp/tensorflow_logs', graph_def=self._session.graph_def)",
            "",
            "def fit(self, X, y):",
            "\"\"\"Builds a neural network model given provided `model_fn` and training"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 7602,
        "change": [
            "def test_inputs(framework: str | None) -> list[tuple[ModuleType, FrameworkTestMo",
            ")",
            "except ModuleNotFoundError as e:",
            "logger.warning(",
            "-                f\"Failed to find test module for framework {framework_name} (tests.integration.frameworks.models.{framework_name})\"",
            "+                f\"Failed to find test module for framework {framework_name} (tests.integration.frameworks.models.{framework_name}): {e}\"",
            ")",
            "",
            "return ["
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 7619,
        "change": [
            "class Trainer(",
            ")",
            "return {}",
            "",
            "-            ckpt = torch.load(ckpt_path, map_location=lambda storage, loc: storage)",
            "+            ckpt = pl_load(ckpt_path, map_location=lambda storage, loc: storage)",
            "model.load_state_dict(ckpt['state_dict'])",
            "",
            "# attach dataloaders"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Device Management Error"
    },
    {
        "number": 7621,
        "change": [
            "def from_networkx(G):",
            "",
            "G = nx.convert_node_labels_to_integers(G)",
            "G = G.to_directed() if not nx.is_directed(G) else G",
            "-    edge_index = torch.tensor(list(G.edges)).t().contiguous()",
            "+    edge_index = torch.LongTensor(list(G.edges)).t().contiguous()",
            "",
            "data = {}"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 7643,
        "change": [
            "class AttentionDecoder(RNNDecoder):",
            "logits=self.vocab_size,",
            "predicted_ids=tf.TensorShape([]),",
            "cell_output=self.cell.output_size,",
            "-        attention_scores=tf.concat([0, self.attention_values[1:-1]], 0),",
            "+        attention_scores=tf.concat(",
            "+            [[0], tf.shape(self.attention_values)[1:-1]], 0),",
            "attention_context=self.attention_values.get_shape()[-1])",
            "",
            "@property"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 7658,
        "change": [
            "def convert_points_from_homogeneous(points: torch.Tensor,",
            "",
            "# we check for points at infinity",
            "z_vec: torch.Tensor = points[..., -1:]",
            "-    scale: torch.Tensor = 1. / torch.clamp(z_vec, eps)",
            "+    scale: torch.Tensor = torch.tensor(1.) / torch.clamp(z_vec, eps)",
            "",
            "return scale * points[..., :-1]"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 7719,
        "change": [
            "class MeanAbsoluteError(Metric):",
            "preds: Predictions from model",
            "target: Ground truth values",
            "\"\"\"",
            "-        self._check_same_shape(preds, target)",
            "-        abs_error = torch.abs(preds - target)",
            "+        sum_abs_error, n_obs = _mean_absolute_error_update(preds, target)",
            "",
            "-        self.sum_abs_error += torch.sum(abs_error)",
            "-        self.total += target.numel()",
            "+        self.sum_abs_error += sum_abs_error",
            "+        self.total += n_obs",
            "",
            "def compute(self):",
            "\"\"\"",
            "Computes mean absolute error over state.",
            "\"\"\"",
            "-        return self.sum_abs_error / self.total",
            "+        return _mean_absolute_error_compute(self.sum_abs_error, self.total)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Algorithm Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Low Efficiency|Algorithm Error"
    },
    {
        "number": 7723,
        "change": [
            "class RandomSampler(BaseSampler):",
            "else:",
            "device = 'cpu'",
            "gallery = torch.tensor(gallery, dtype=torch.long, device=device)",
            "-        perm = torch.randperm(gallery.numel(), device=gallery.device)[:num]",
            "+        # This is a temporary fix. We can revert the following code",
            "+        # when PyTorch fixes the abnormal return of torch.randperm.",
            "+        # See: https://github.com/open-mmlab/mmdetection/pull/5014",
            "+        perm = torch.randperm(gallery.numel())[:num].to(device=gallery.device)",
            "rand_inds = gallery[perm]",
            "if not is_tensor:",
            "rand_inds = rand_inds.cpu().numpy()"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 7739,
        "change": [
            "class Stft(torch.nn.Module, InversibleInterface):",
            "pad = self.n_fft // 2",
            "ilens = ilens + 2 * pad",
            "",
            "-            olens = torch.div((ilens - self.n_fft), self.hop_length) + 1",
            "+            olens = (",
            "+                torch.div((ilens - self.n_fft), self.hop_length, rounding_mode=\"floor\")",
            "+                + 1",
            "+            )",
            "output.masked_fill_(make_pad_mask(olens, output, 1), 0.0)",
            "else:",
            "olens = None"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 7781,
        "change": [
            "class ImageInputFeature(ImageFeatureMixin, InputFeature):",
            ")",
            "",
            "def forward(self, inputs: torch.Tensor) -> torch.Tensor:",
            "-        assert isinstance(inputs, torch.Tensor)",
            "-        assert inputs.dtype in [torch.float32]",
            "+        assert isinstance(inputs, torch.Tensor), f\"inputs to image feature must be a torch tensor, got {type(inputs)}\"",
            "+        assert inputs.dtype in [torch.float32], f\"inputs to image feature must be a float32 tensor, got {inputs.dtype}\"",
            "",
            "inputs_encoded = self.encoder_obj(inputs)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 7789,
        "change": [
            "def test_hetero_to_undirected():",
            "data['v', 'w'].edge_weight = edge_weight",
            "data['v', 'w'].edge_attr = edge_attr",
            "",
            "+    from torch_geometric.transforms import ToUndirected",
            "data = ToUndirected()(data)",
            "-    assert data['v', 'v'].edge_index.tolist() == [[0, 0, 1, 2, 2, 3],",
            "-                                                  [1, 2, 0, 0, 3, 2]]",
            "+    assert data['v', 'v'].edge_index.tolist() == [[0, 1, 2, 3], [1, 0, 3, 2]]",
            "assert data['v', 'v'].edge_weight.tolist() == edge_weight[perm].tolist()",
            "assert data['v', 'v'].edge_attr.tolist() == edge_attr[perm].tolist()",
            "assert data['v', 'w'].edge_index.tolist() == edge_index.tolist()",
            "assert data['v', 'w'].edge_weight.tolist() == edge_weight.tolist()",
            "assert data['v', 'w'].edge_attr.tolist() == edge_attr.tolist()",
            "-    assert data['w', 'v'].edge_index.tolist() == [[3, 1, 0], [2, 0, 2]]",
            "+    assert data['w', 'v'].edge_index.tolist() == [[3, 1], [2, 0]]",
            "assert data['w', 'v'].edge_weight.tolist() == edge_weight.tolist()",
            "assert data['w', 'v'].edge_attr.tolist() == edge_attr.tolist()"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 7809,
        "change": [
            "if __name__ == '__main__':",
            "",
            "# Load pytorch model",
            "google_utils.attempt_download(opt.weights)",
            "-    model = torch.load(opt.weights, map_location=torch.device('cpu'))['model']",
            "+    model = torch.load(opt.weights, map_location=torch.device('cpu'))['model'].float()",
            "model.eval()",
            "model.fuse()"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 7821,
        "change": [
            "def test_forward(use_token_averaged_energy):",
            ")",
            "xs = torch.randn(2, 256)",
            "if not use_token_averaged_energy:",
            "-        layer(xs, torch.LongTensor([256, 128]))",
            "+        es, elens = layer(xs, torch.LongTensor([256, 128]))",
            "+        assert es.shape[1] == max(elens)",
            "else:",
            "ds = torch.LongTensor([[3, 0, 2], [3, 0, 0]])",
            "dlens = torch.LongTensor([3, 1])"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 7866,
        "change": [
            "from .degree import DegreeAdj",
            "",
            "class DegreeTest(TestCase):",
            "def test_degree_adj(self):",
            "+        index = torch.LongTensor([[0, 0, 1, 2], [1, 2, 0, 1]])",
            "weight = torch.FloatTensor([2, 3, 4, 6])",
            "-        edge = torch.LongTensor([[0, 0, 1, 2], [1, 2, 0, 1]])",
            "-        adj = torch.sparse.FloatTensor(edge, weight, torch.Size([3, 3]))",
            "+        adj = torch.sparse.FloatTensor(index, weight, torch.Size([3, 3]))",
            "",
            "transform = DegreeAdj()",
            "",
            "-        _, adj = transform((None, adj))",
            "+        _, adj, _ = transform((None, adj, None))",
            "adj = adj.to_dense()",
            "",
            "expected_adj_out = ["
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 7912,
        "change": [
            "class Trainer:",
            "else:",
            "tr_loss_step = self.training_step(model, inputs)",
            "",
            "-                if args.logging_nan_inf_filter and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step)):",
            "-                    # if loss is nan or inf simply add the average of previous logged losses",
            "-                    tr_loss += tr_loss / (1 + self.state.global_step - self._globalstep_last_logged)",
            "+                if args.logging_nan_inf_filter and not is_torch_tpu_available():",
            "+                    if torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step):",
            "+                        # if loss is nan or inf simply add the average of previous logged losses",
            "+                        tr_loss += tr_loss / (1 + self.state.global_step - self._globalstep_last_logged)",
            "else:",
            "tr_loss += tr_loss_step"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 7948,
        "change": [
            "class SGD(base.Module):",
            "optimizer_utils.check_same_dtype(update, parameter)",
            "learning_rate = tf.cast(self.learning_rate, update.dtype.base_dtype)",
            "if isinstance(update, tf.IndexedSlices):",
            "-          parameter.scatter_nd_sub(",
            "-              update.indices, update.values * learning_rate)",
            "+          parameter.scatter_sub(",
            "+              tf.IndexedSlices(update.values * learning_rate, update.indices))",
            "else:",
            "parameter.assign_sub(update * learning_rate)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 7954,
        "change": [
            "for it in range(1000000):",
            "T_sample = T(torch.cat([X, z_sample], 1))",
            "",
            "disc = torch.mean(-T_sample)",
            "-    loglike = -nn.binary_cross_entropy(X_sample, X)",
            "+    loglike = -nn.binary_cross_entropy(X_sample, X, size_average=False) / mb_size",
            "",
            "elbo = -(disc + loglike)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 7961,
        "change": [
            "class SamplePoints(object):",
            "pos = pos / pos_max",
            "",
            "area = (pos[face[1]] - pos[face[0]]).cross(pos[face[2]] - pos[face[0]])",
            "-        area = torch.sqrt((area**2).sum(dim=-1)) / 2",
            "+        area = area.norm(p=2, dim=1) / 2",
            "",
            "prob = area / area.sum()",
            "sample = torch.multinomial(prob, self.num, replacement=True)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Algorithm Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Algorithm Error"
    },
    {
        "number": 7968,
        "change": [
            "class PaintByExamplePipeline(DiffusionPipeline):",
            "image_embeddings = image_embeddings.view(bs_embed * num_images_per_prompt, seq_len, -1)",
            "",
            "if do_classifier_free_guidance:",
            "-            uncond_embeddings = uncond_embeddings.repeat(1, image_embeddings.shape[0], 1)",
            "-            uncond_embeddings = uncond_embeddings.view(bs_embed * num_images_per_prompt, 1, -1)",
            "+            negative_prompt_embeds = negative_prompt_embeds.repeat(1, image_embeddings.shape[0], 1)",
            "+            negative_prompt_embeds = negative_prompt_embeds.view(bs_embed * num_images_per_prompt, 1, -1)",
            "",
            "# For classifier free guidance, we need to do two forward passes.",
            "# Here we concatenate the unconditional and text embeddings into a single batch",
            "# to avoid doing two forward passes",
            "-            image_embeddings = torch.cat([uncond_embeddings, image_embeddings])",
            "+            image_embeddings = torch.cat([negative_prompt_embeds, image_embeddings])",
            "",
            "return image_embeddings"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 7977,
        "change": [
            "class SequenceGenerator(nn.Module):",
            "cand_size = 2 * beam_size  # 2 x beam size in case half are EOS",
            "",
            "# offset arrays for converting between different indexing schemes",
            "-        bbsz_offsets = (torch.arange(0, bsz) * beam_size).unsqueeze(1).type_as(tokens)",
            "-        cand_offsets = torch.arange(0, cand_size).type_as(tokens)",
            "+        bbsz_offsets = (torch.arange(0, bsz) * beam_size).unsqueeze(1).type_as(tokens).to(src_tokens.device)",
            "+        cand_offsets = torch.arange(0, cand_size).type_as(tokens).to(src_tokens.device)",
            "",
            "reorder_state: Optional[Tensor] = None",
            "batch_idxs: Optional[Tensor] = None"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 8014,
        "change": [
            "class MeanSquaredError(Metric):",
            "preds: Predictions from model",
            "target: Ground truth values",
            "\"\"\"",
            "-        self._check_same_shape(preds, target)",
            "-        squared_error = torch.pow(preds - target, 2)",
            "+        sum_squared_error, n_obs = _mean_squared_error_update(preds, target)",
            "",
            "-        self.sum_squared_error += torch.sum(squared_error)",
            "-        self.total += target.numel()",
            "+        self.sum_squared_error += sum_squared_error",
            "+        self.total += n_obs",
            "",
            "def compute(self):",
            "\"\"\"",
            "Computes mean squared error over state.",
            "\"\"\"",
            "-        return self.sum_squared_error / self.total",
            "+        return _mean_squared_error_compute(self.sum_squared_error, self.total)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 8045,
        "change": [
            "def test_unnormalized_normal(kernel, jit):",
            "posterior.append(samples)",
            "",
            "posterior = torch.stack([sample[\"z\"] for sample in posterior])",
            "-    assert_equal(torch.mean(posterior), true_mean, prec=0.1)",
            "-    assert_equal(torch.std(posterior), true_std, prec=0.1)",
            "+    assert_close(torch.mean(posterior), true_mean, rtol=0.05)",
            "+    assert_close(torch.std(posterior), true_std, rtol=0.05)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Algorithm Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Algorithm Error"
    },
    {
        "number": 8166,
        "change": [
            "def bjerksund_stensland(*,",
            "volatilities=volatilities,",
            "strikes=strikes,",
            "expiries=expiries,",
            "-                forwards=forwards,",
            "+                spots=spots,",
            "discount_rates=discount_rates,",
            "cost_of_carries=cost_of_carries,",
            "is_call_options=is_call_options),",
            "# For put options, adjust inputs according to call-put transformation",
            "# function:  P(S, X, T, r, b, sigma) = C(X, S, T, r - b, -b, sigma)",
            "tf.where(is_call_options,",
            "-                bjerksund_stensland_model(forwards, strikes, expiries, discount_rates,",
            "+                bjerksund_stensland_model(spots, strikes, expiries, discount_rates,",
            "cost_of_carries, volatilities),",
            "-                bjerksund_stensland_model(strikes, forwards, expiries, discount_rates -",
            "+                bjerksund_stensland_model(strikes, spots, expiries, discount_rates -",
            "cost_of_carries, -cost_of_carries, volatilities)))",
            "",
            "return american_prices"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Null Reference Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Null Reference Error"
    },
    {
        "number": 8205,
        "change": [
            "def model(y):",
            "# Vector of variances for each of the d variables",
            "theta = pyro.sample(\"theta\", dist.HalfCauchy(torch.ones(d, **options)))",
            "# Lower cholesky factor of a correlation matrix",
            "-    eta = torch.ones(1, **options)  # Implies a uniform distribution over correlation matrices",
            "-    L_omega = pyro.sample(\"L_omega\", dist.LKJCorrCholesky(d, eta))",
            "+    concentration = torch.ones((), **options)  # Implies a uniform distribution over correlation matrices",
            "+    L_omega = pyro.sample(\"L_omega\", dist.LKJCholesky(d, concentration))",
            "# Lower cholesky factor of the covariance matrix",
            "L_Omega = torch.mm(torch.diag(theta.sqrt()), L_omega)",
            "# For inference with SVI, one might prefer to use torch.bmm(theta.sqrt().diag_embed(), L_omega)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 8242,
        "change": [
            "class DistilBertModelIntergrationTest(unittest.TestCase):",
            "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")",
            "input_ids = torch.tensor([[0, 345, 232, 328, 740, 140, 1695, 69, 6078, 1588, 2]])",
            "attention_mask = torch.tensor([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])",
            "-        output = model(input_ids, attention_mask=attention_mask)[0]",
            "+        with torch.no_grad():",
            "+            output = model(input_ids, attention_mask=attention_mask)[0]",
            "expected_shape = torch.Size((1, 11, 768))",
            "self.assertEqual(output.shape, expected_shape)",
            "expected_slice = torch.tensor("
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 8259,
        "change": [
            "class Model(object):",
            "else:",
            "assert not config.global_model and config.session is None",
            "tf.reset_default_graph()",
            "-            self.session = tf.Session()",
            "+            self.session = config.session = tf.Session()",
            "",
            "if config.distributed and not config.global_model:",
            "# Global and local model for asynchronous updates"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 8273,
        "change": [
            "def test(loader):",
            "target = batch['user', 'item'].edge_label.long().cpu()",
            "",
            "preds.append(pred)",
            "-        targets.append(pred)",
            "+        targets.append(target)",
            "",
            "pred = torch.cat(preds, dim=0).numpy()",
            "-    target = torch.cat(target, dim=0).numpy()",
            "+    target = torch.cat(targets, dim=0).numpy()",
            "",
            "+    pred = pred > 0.5",
            "acc = accuracy_score(target, pred)",
            "prec = precision_score(target, pred)",
            "rec = recall_score(target, pred)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 8283,
        "change": [
            "from ray.rllib.optimizers import SampleBatch, TFMultiGPUSupport",
            "class DQNEvaluator(TFMultiGPUSupport):",
            "\"\"\"The base DQN Evaluator that does not include the replay buffer.\"\"\"",
            "",
            "-    def __init__(self, env_creator, config, logdir):",
            "+    def __init__(self, registry, env_creator, config, logdir):",
            "env = env_creator()",
            "-        env = wrap_dqn(env, config[\"model\"])",
            "+        env = wrap_dqn(registry, env, config[\"model\"])",
            "self.env = env",
            "self.config = config",
            "",
            "tf_config = tf.ConfigProto(**config[\"tf_session_args\"])",
            "self.sess = tf.Session(config=tf_config)",
            "-        self.dqn_graph = models.DQNGraph(env, config, logdir)",
            "+        self.dqn_graph = models.DQNGraph(registry, env, config, logdir)",
            "",
            "# Create the schedule for exploration starting from 1.",
            "self.exploration = LinearSchedule("
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 8296,
        "change": [
            "def ctc_label_dense_to_sparse(labels, label_lengths):",
            "max_num_labels_tns = tf.pack([label_shape[1]])",
            "",
            "def range_less_than(previous_state, current_input):",
            "-        return tf.expand_dims(tf.range(label_shape[1]), 0) < current_input",
            "+        return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(max_num_labels_tns, current_input)",
            "",
            "-    init = tf.cast(tf.fill(max_num_labels_tns, 0), tf.bool)",
            "+    init = tf.cast(tf.fill([1, label_shape[1]], 0), tf.bool)",
            "dense_mask = functional_ops.scan(range_less_than, label_lengths,",
            "initializer=init, parallel_iterations=1)",
            "dense_mask = dense_mask[:, 0, :]"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 8304,
        "change": [
            "class PreTrainedModel(nn.Module, ModuleUtilsMixin, GenerationMixin, PushToHubMix",
            ")",
            "",
            "# Build new embeddings",
            "-        new_embeddings = nn.Embedding(new_num_tokens, old_embedding_dim).to(self.device)",
            "+        new_embeddings = nn.Embedding(new_num_tokens, old_embedding_dim).to(",
            "+            self.device, dtype=old_embeddings.weight.dtype",
            "+        )",
            "",
            "# initialize all new embeddings (in particular added tokens)",
            "self._init_weights(new_embeddings)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 8311,
        "change": [
            "def resize_images(X, height_factor, width_factor, dim_ordering):",
            "positive integers.",
            "'''",
            "if dim_ordering == 'th':",
            "+        original_shape = int_shape(X)",
            "new_shape = tf.shape(X)[2:]",
            "new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))",
            "X = permute_dimensions(X, [0, 2, 3, 1])",
            "X = tf.image.resize_nearest_neighbor(X, new_shape)",
            "-        return permute_dimensions(X, [0, 3, 1, 2])",
            "+        X = permute_dimensions(X, [0, 3, 1, 2])",
            "+        X.set_shape((None, None, original_shape[2] * height_factor, original_shape[3] * width_factor))",
            "+        return X",
            "elif dim_ordering == 'tf':",
            "+        original_shape = int_shape(X)",
            "new_shape = tf.shape(X)[1:3]",
            "new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))",
            "-        return tf.image.resize_nearest_neighbor(X, new_shape)",
            "+        X = tf.image.resize_nearest_neighbor(X, new_shape)",
            "+        X.set_shape((None, original_shape[1] * height_factor, original_shape[2] * width_factor, None))",
            "+        return X",
            "else:",
            "raise Exception('Invalid dim_ordering: ' + dim_ordering)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Device Management Error"
    },
    {
        "number": 8319,
        "change": [
            "class BaseModel():",
            "save_filename = '%s_net_%s.pth' % (which_epoch, name)",
            "save_path = os.path.join(self.save_dir, save_filename)",
            "net = getattr(self, 'net' + name)",
            "-                torch.module.save(net.cpu().state_dict(), save_path)",
            "+                torch.save(net.module.cpu().state_dict(), save_path)",
            "if len(self.gpu_ids) and torch.cuda.is_available():",
            "net.cuda(self.gpu_ids[0])"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 8358,
        "change": [
            "def clip(",
            "*,",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "+    assert tf.reduce_all(tf.less(x_min, x_max)), \"Min value must be less than max.\"",
            "if hasattr(x_min, \"dtype\") and hasattr(x_max, \"dtype\"):",
            "promoted_type = tf.experimental.numpy.promote_types(x.dtype, x_min.dtype)",
            "promoted_type = tf.experimental.numpy.promote_types(promoted_type, x_max.dtype)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Null Reference Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Program Crash|Null Reference Error"
    },
    {
        "number": 8385,
        "change": [
            "class DiceCoeff(Function):",
            "",
            "def forward(self, input, target):",
            "self.save_for_backward(input, target)",
            "-        self.inter = torch.dot(input.view(-1), target.view(-1)) + 0.0001",
            "-        self.union = torch.sum(input) + torch.sum(target) + 0.0001",
            "+        eps = 0.0001",
            "+        self.inter = torch.dot(input.view(-1), target.view(-1))",
            "+        self.union = torch.sum(input) + torch.sum(target) + eps",
            "",
            "-        t = 2 * self.inter.float() / self.union.float()",
            "+        t = (2 * self.inter.float() + eps) / self.union.float()",
            "return t",
            "",
            "# This function has only a single output, so it gets only one gradient"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 8394,
        "change": [
            "def cross_entropy_seq(logits, target_seqs):#, batch_size=1, num_steps=None):",
            "loss = sequence_loss_by_example_fn(",
            "[logits],",
            "[tf.reshape(target_seqs, [-1])],",
            "-        [tf.ones_like(tf.reshape(targets, [-1]), dtype=tf.float32)])",
            "+        [tf.ones_like(tf.reshape(target_seqs, [-1]), dtype=tf.float32)])",
            "# [tf.ones([batch_size * num_steps])])",
            "-    cost = tf.reduce_sum(loss) / batch_size",
            "+    cost = tf.reduce_sum(loss) #/ batch_size",
            "return cost"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 8440,
        "change": [
            "def stats(policy: Policy, train_batch: SampleBatch):",
            "stats_dict[\"var_IS\"] = is_stat_var",
            "",
            "if policy.config[\"use_kl_loss\"]:",
            "-        stats_dict[\"kl\"] = policy.get_tower_stats(\"mean_kl_loss\")",
            "+        stats_dict[\"kl\"] = torch.mean(",
            "+            torch.stack(policy.get_tower_stats(\"mean_kl_loss\")))",
            "stats_dict[\"KL_Coeff\"] = policy.kl_coeff",
            "",
            "return stats_dict"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 8475,
        "change": [
            "class BertModel(BertPreTrainedModel):",
            "seq_ids = torch.arange(seq_length, device=device)",
            "causal_mask = seq_ids[None, None, :].repeat(batch_size, seq_length, 1) <= seq_ids[None, :, None]",
            "causal_mask = causal_mask.to(",
            "-                    torch.long",
            "-                )  # not converting to long will cause errors with pytorch version < 1.3",
            "+                    attention_mask.dtype",
            "+                )  # causal and attention masks must have same type with pytorch version < 1.3",
            "extended_attention_mask = causal_mask[:, None, :, :] * attention_mask[:, None, None, :]",
            "else:",
            "extended_attention_mask = attention_mask[:, None, None, :]"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 8538,
        "change": [
            "class Module(object):",
            "use_while_v2=False",
            "):",
            "Module.global_scope.append('while')",
            "-        if maximum_iterations is not None and maximum_iterations.dtype not in (tf.int32, tf.int64):",
            "+        if maximum_iterations is not None and maximum_iterations.dtype is not tf.int32:",
            "maximum_iterations = tf.dtypes.cast(x=maximum_iterations, dtype=tf.int32)",
            "if use_while_v2:",
            "x = while_v2.while_loop("
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 8551,
        "change": [
            "class PartialFC(Module):",
            "logits.backward(grad)",
            "if total_features.grad is not None:",
            "total_features.grad.detach_()",
            "-        x_grad: torch.Tensor = torch.zeros_like(features)",
            "-        x_grad.mul_(self.world_size)",
            "-",
            "+        x_grad: torch.Tensor = torch.zeros_like(features, requires_grad=True)",
            "# feature gradient all-reduce",
            "dist.reduce_scatter(x_grad, list(total_features.grad.chunk(self.world_size, dim=0)))",
            "+        x_grad = x_grad * self.world_size",
            "# backward backbone",
            "return x_grad, loss_v"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 8686,
        "change": [
            "class TransfoXLModel(TransfoXLPreTrainedModel):",
            "else:",
            "mask_shift_len = qlen",
            "dec_attn_mask = (torch.triu(all_ones, 1+mlen)",
            "-                    + torch.tril(all_ones, -mask_shift_len)).byte()[:, :, None] # -1",
            "+                    + torch.tril(all_ones, -mask_shift_len)).bool()[:, :, None] # -1",
            "else:",
            "dec_attn_mask = torch.triu(",
            "-                word_emb.new_ones(qlen, klen), diagonal=1+mlen).byte()[:,:,None]",
            "+                word_emb.new_ones(qlen, klen), diagonal=1+mlen).bool()[:,:,None]",
            "",
            "hids = []",
            "attentions = []"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 8693,
        "change": [
            "class EarlyStopping(Callback):",
            "f\" {self.monitor} = {current} {self.order_dict[self.mode]} {self.divergence_threshold}.\"",
            "\" Signaling Trainer to stop.\"",
            ")",
            "-        elif self.monitor_op(current - self.min_delta, self.best_score.to(trainer.lightning_module.device)):",
            "+        elif self.monitor_op(current - self.min_delta, self.best_score.to(current.device)):",
            "should_stop = False",
            "reason = self._improvement_message(current)",
            "self.best_score = current"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Parameter",
        "Action_Element": "Redundant API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 8698,
        "change": [
            "def tensordot(",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "# find type to promote to",
            "-    dtype = tf.experimental.numpy.promote_types(x1.dtype, x2.dtype)",
            "+    dtype = ivy.as_native_dtype(ivy.promote_types(x1.dtype, x2.dtype))",
            "",
            "# type casting to float32 which is acceptable for tf.tensordot",
            "x1, x2 = tf.cast(x1, tf.float32), tf.cast(x2, tf.float32)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 8699,
        "change": [
            "def log_cosh(y_true, y_pred):",
            ">>> x = y_pred - y_true",
            ">>> assert np.allclose(",
            "...     loss.numpy(),",
            "-  ...     np.mean(x + np.log(np.exp(-2. * x) + 1.) - math_ops.log(2.), axis=-1),",
            "+  ...     np.mean(x + np.log(np.exp(-2. * x) + 1.) - tf.math.log(2.), axis=-1),",
            "...     atol=1e-5)",
            "",
            "Args:"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 8738,
        "change": [
            "class EntityLinker(flair.nn.DefaultClassifier[Sentence, Span]):",
            ")",
            "",
            "def emb_mean(self, span, embedding_names):",
            "-        return torch.mean(torch.cat([token.get_embedding(embedding_names) for token in span], 0), 0)",
            "+        return torch.mean(torch.stack([token.get_embedding(embedding_names) for token in span], 0), 0)",
            "",
            "def _get_data_points_from_sentence(self, sentence: Sentence) -> List[Span]:",
            "return sentence.get_spans(self.label_type)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 8745,
        "change": [
            "def finish_episode():",
            "rewards = torch.Tensor(rewards)",
            "rewards = (rewards - rewards.mean()) / (rewards.std() + np.finfo(np.float32).eps)",
            "for (log_prob, value), r in zip(saved_actions, rewards):",
            "-        reward = r - value.data[0, 0]",
            "+        reward = r - value.data[0]",
            "policy_losses.append(-log_prob * reward)",
            "value_losses.append(F.smooth_l1_loss(value, Variable(torch.Tensor([r]))))",
            "optimizer.zero_grad()",
            "-    loss = torch.cat(policy_losses).sum() + torch.cat(value_losses).sum()",
            "+    loss = torch.stack(policy_losses).sum() + torch.stack(value_losses).sum()",
            "loss.backward()",
            "optimizer.step()",
            "del model.rewards[:]"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 8748,
        "change": [
            "def _get_random_features_initializer(initializer, shape):",
            "random_features_initializer = initializer",
            "if isinstance(initializer, str):",
            "if initializer.lower() == 'gaussian':",
            "-      random_features_initializer = tf.compat.v1.random_normal_initializer(",
            "-          stddev=1.0)",
            "+      random_features_initializer = initializers.RandomNormal(stddev=1.0)",
            "elif initializer.lower() == 'laplacian':",
            "-      random_features_initializer = tf.compat.v1.constant_initializer(",
            "+      random_features_initializer = initializers.Constant(",
            "_get_cauchy_samples(loc=0.0, scale=1.0, shape=shape))",
            "",
            "else:"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 8765,
        "change": [
            "class SyncMultiGPUTrainer(MultiGPUTrainer,",
            "super(SyncMultiGPUTrainer, self)._setup()",
            "grad_list = MultiGPUTrainer._multi_tower_grads(",
            "self.config.tower, lambda: self._get_cost_and_grad()[1])",
            "+",
            "+        # debug tower performance:",
            "+        #ops = [k[0] for k in grad_list[1]] + [k[0] for k in grad_list[0]]",
            "+        #self.train_op = tf.group(*ops)",
            "+        #return",
            "+",
            "grads = SyncMultiGPUTrainer._average_grads(grad_list)",
            "grads = apply_grad_processors(grads, self.model.get_gradient_processor())"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 8824,
        "change": [
            "def _replace_global_by_local(kwargs):",
            "if 'collections' in kwargs:",
            "collections = kwargs['collections']",
            "if not collections:",
            "-        collections = {tf.GraphKeys.GLOBAL_VARIABLES}",
            "+        collections = {tfv1.GraphKeys.GLOBAL_VARIABLES}",
            "else:",
            "collections = set(collections.copy())",
            "-    collections.remove(tf.GraphKeys.GLOBAL_VARIABLES)",
            "-    collections.add(tf.GraphKeys.LOCAL_VARIABLES)",
            "+    collections.remove(tfv1.GraphKeys.GLOBAL_VARIABLES)",
            "+    collections.add(tfv1.GraphKeys.LOCAL_VARIABLES)",
            "kwargs['collections'] = list(collections)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 8832,
        "change": [
            "class OrthogonalRegularizer(Regularizer):",
            "size = inputs.shape[1]",
            "product_no_diagonal = product * (1. - tf.eye(size, dtype=inputs.dtype))",
            "num_pairs = size * (size - 1.) / 2.",
            "-    return self.factor * 0.5 * tf.reduce_sum(product_no_diagonal) / num_pairs",
            "+    return self.factor * 0.5 * tf.reduce_sum(tf.abs(product_no_diagonal)) / num_pairs",
            "",
            "def get_config(self):",
            "return {'factor': float(self.factor), 'mode': self.mode}"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Algorithm Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Unexpected Output|Algorithm Error"
    },
    {
        "number": 8901,
        "change": [
            "def test(data,",
            "",
            "# Load model",
            "google_utils.attempt_download(weights)",
            "-        model = torch.load(weights, map_location=device)['model'].float().fuse()  # load to FP32",
            "+        model = torch.load(weights, map_location=device)['model'].float().fuse().to(device)  # load to FP32",
            "imgsz = check_img_size(imgsz, s=model.stride.max())  # check img_size",
            "",
            "# Multi-GPU disabled, incompatible with .half() https://github.com/ultralytics/yolov5/issues/99"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 8947,
        "change": [
            "class TorchDiagGaussian(TorchDistributionWrapper):",
            "@override(ActionDistribution)",
            "def __init__(self, inputs, model):",
            "super().__init__(inputs, model)",
            "-        mean, log_std = torch.chunk(inputs, 2, dim=1)",
            "+        mean, log_std = torch.chunk(self.inputs, 2, dim=1)",
            "self.dist = torch.distributions.normal.Normal(mean, torch.exp(log_std))",
            "",
            "@override(ActionDistribution)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 8951,
        "change": [
            "def clip(",
            "*,",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "+    assert torch.all(torch.less(x_min, x_max)), \"Min value must be less than max.\"",
            "if hasattr(x_min, \"dtype\"):",
            "promoted_type = torch.promote_types(x_min.dtype, x_max.dtype)",
            "promoted_type = torch.promote_types(promoted_type, x.dtype)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Null Reference Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Program Crash|Null Reference Error"
    },
    {
        "number": 8997,
        "change": [
            "def train(args, logdir):",
            "steps_per_epoch=hp.train1.steps_per_epoch,",
            "# session_config=session_conf",
            ")",
            "-    ckpt = args.ckpt if args.ckpt else tf.train.latest_checkpoint(logdir)",
            "+    ckpt = '{}/{}'.format(logdir, args.ckpt) if args.ckpt else tf.train.latest_checkpoint(logdir)",
            "if ckpt:",
            "train_conf.session_init = SaverRestore(ckpt)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 9026,
        "change": [
            "def is_variable(x):",
            "",
            "",
            "def execute_with_gradients(func, xs, retain_grads=False):",
            "-    with _tf.GradientTape() as tape:",
            "+    with _tf.GradientTape(persistent=retain_grads, watch_accessed_variables=False) as tape:",
            "+        tape.watch(xs)",
            "func_ret = func(xs)",
            "if isinstance(func_ret, tuple):",
            "y = func_ret[0]"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Parameter",
        "Action_Element": "Missing API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 9048,
        "change": [
            "def test_sequence_tagger_param_selector(results_base_path, tasks_base_path):",
            "",
            "@pytest.mark.integration",
            "def test_text_classifier_param_selector(results_base_path, tasks_base_path):",
            "-    corpus = flair.datasets.ClassificationCorpus(tasks_base_path / \"imdb\")",
            "+    corpus = flair.datasets.ClassificationCorpus(tasks_base_path / \"imdb\", label_type=\"sentiment\")",
            "label_type = \"sentiment\"",
            "",
            "search_space = SearchSpace()",
            "",
            "# document embeddings parameter",
            "-    search_space.add(Parameter.TRANSFORMER_MODEL, hp.choice, options=[\"albert-base-v1\"])",
            "+    search_space.add(Parameter.TRANSFORMER_MODEL, hp.choice, options=[\"sshleifer/tiny-distilbert-base-cased\"])",
            "search_space.add(Parameter.LAYERS, hp.choice, options=[\"-1\", \"-2\"])",
            "",
            "# training parameter"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Unexpected Output|Data Conversion Error"
    },
    {
        "number": 9098,
        "change": [
            "\"\\n\",",
            "\"\\n\",",
            "\"\\\"\\\"\\\"fm part\\\"\\\"\\\"\\n\",",
            "-    \"fm_first_order = tf.nn.embedding_lookup(weights['feature_embeddings'],feat_index)\\n\",",
            "+    \"fm_first_order = tf.nn.embedding_lookup(weights['feature_bias'],feat_index)\\n\",",
            "\"fm_first_order = tf.reduce_sum(tf.multiply(fm_first_order,reshaped_feat_value),2)\\n\",",
            "\"\\n\",",
            "\"summed_features_emb = tf.reduce_sum(embeddings,1)\\n\","
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Unexpected Output|Deprecation Management Error"
    },
    {
        "number": 9197,
        "change": [
            "class Seq2SeqModel(ModelBase):",
            "if \"embedding\" in variable.name:",
            "tmp = tf.clip_by_norm(",
            "gradient.values, self.params[\"optimizer.clip_embed_gradients\"])",
            "-        grad = tf.IndexedSlices(tmp, gradient.indices, gradient.dense_shape)",
            "+        gradient = tf.IndexedSlices(tmp, gradient.indices, gradient.dense_shape)",
            "clipped_gradients.append(gradient)",
            "variables.append(variable)",
            "return list(zip(clipped_gradients, variables))"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 9236,
        "change": [
            "def median(",
            "keepdims: Optional[bool] = False,",
            "out: Optional[torch.tensor] = None,",
            ") -> torch.tensor:",
            "+    temp = input",
            "if hasattr(axis, \"__iter__\"):",
            "for dim in axis:",
            "-            input = torch.median(",
            "-                input,",
            "+            temp = torch.median(",
            "+                temp,",
            "dim=dim,",
            "keepdim=keepdims,",
            ")[0]"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 9246,
        "change": [
            "class Dropout(Layer):",
            "",
            "skip_dropout = tf.math.logical_not(x=Module.retrieve_tensor(name='update'))",
            "zero = tf.constant(value=0.0, dtype=util.tf_dtype(dtype='float'))",
            "-        skip_dropout = tf.math.logical_or(x=apply_dropout, y=tf.math.equal(x=rate, y=zero))",
            "+        skip_dropout = tf.math.logical_or(x=skip_dropout, y=tf.math.equal(x=rate, y=zero))",
            "return self.cond(pred=skip_dropout, true_fn=no_dropout, false_fn=apply_dropout)"
        ],
        "comments": "",
        "Symptom": "Unexpected Output",
        "Root_Cause": "Null Reference Error",
        "Action": "Redundant",
        "Element": "API Condition",
        "Action_Element": "Redundant API Condition",
        "Symptom_Root_Cause": "Unexpected Output|Null Reference Error"
    },
    {
        "number": 9260,
        "change": [
            "def test_cpu_amp_precision_context_manager(tmpdir):",
            "assert not hasattr(plugin, \"scaler\")",
            "context_manager = plugin.autocast_context_manager()",
            "assert isinstance(context_manager, torch.cpu.amp.autocast)",
            "-    assert context_manager.dtype == torch.bfloat16",
            "+    assert context_manager.fast_dtype == torch.bfloat16",
            "",
            "",
            "@pytest.mark.skipif(not _TORCH_CPU_AMP_AVAILABLE, reason=\"Torch CPU AMP is not available.\")"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 9270,
        "change": [
            "class Model(ModelDesc):",
            "zc = tf.one_hot(ids, 10, name='zc_train')",
            "zc = tf.placeholder_with_default(zc, [None, 10], name='zc')",
            "",
            "-        z = tf.random_uniform(tf.pack([tf.shape(zc)[0], 90]), -1, 1, name='z_train')",
            "+        z = tf.random_uniform(tf.stack([tf.shape(zc)[0], 90]), -1, 1, name='z_train')",
            "z = tf.placeholder_with_default(z, [None, 90], name='z')",
            "-        z = tf.concat(1, [zc, z], name='fullz')",
            "+        z = tf.concat_v2([zc, z], 1, name='fullz')",
            "",
            "with argscope([Conv2D, Deconv2D, FullyConnected],",
            "W_init=tf.truncated_normal_initializer(stddev=0.02)):"
        ],
        "comments": "",
        "Symptom": "Return Warning",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Return Warning|Deprecation Management Error"
    },
    {
        "number": 9328,
        "change": [
            "class SignatureDict(NestedDict):",
            "assert isinstance(arg, TensorDict)",
            "args.append(spec.kwargs_to_args(kwargs=arg))",
            "else:",
            "-                assert isinstance(arg, (tf.IndexedSlices, tf.Tensor, tf.Variable))",
            "+                assert isinstance(arg, (tf.IndexedSlices, tf.Tensor, tf.Variable)), (name, spec, arg)",
            "args.append(arg)",
            "return args"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Argument Error",
        "Action": "Outdated",
        "Element": "API Condition",
        "Action_Element": "Outdated API Condition",
        "Symptom_Root_Cause": "Program Crash|Argument Error"
    },
    {
        "number": 9412,
        "change": [
            "def collect_env():",
            "env_info['GCC'] = gcc",
            "",
            "env_info['PyTorch'] = torch.__version__",
            "-    env_info['PyTorch compiling details'] = torch.__config__.show()",
            "+    env_info['PyTorch compiling details'] = get_build_config()",
            "",
            "env_info['TorchVision'] = torchvision.__version__"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 9490,
        "change": [
            "class LabelSmoother:",
            "# will ignore them in any case.",
            "labels.clamp_min_(0)",
            "nll_loss = log_probs.gather(dim=-1, index=labels)",
            "-        smoothed_loss = log_probs.sum(dim=-1, keepdim=True)",
            "+        # works for fp16 input tensor too, by internally upcasting it to fp32",
            "+        smoothed_loss = log_probs.sum(dim=-1, keepdim=True, dtype=torch.float32)",
            "",
            "nll_loss.masked_fill_(padding_mask, 0.0)",
            "smoothed_loss.masked_fill_(padding_mask, 0.0)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Parameter",
        "Action_Element": "Replace API Parameter",
        "Symptom_Root_Cause": "Low Efficiency|Data Conversion Error"
    },
    {
        "number": 9535,
        "change": [
            "def prod(",
            "dtype = tf.uint64",
            "if ivy.exists(out):",
            "return ivy.inplace_update(",
            "-            out, tf.experimental.numpy.prod(x, axis=axis, keepdims=keepdims)",
            "+            out,",
            "+            tf.experimental.numpy.prod(x, axis=axis, dtype=dtype, keepdims=keepdims),",
            ")",
            "else:",
            "return tf.experimental.numpy.prod(x, axis, dtype, keepdims)"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Outdated",
        "Element": "API Parameter",
        "Action_Element": "Outdated API Parameter",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 9575,
        "change": [
            "def is_cuda_available() -> bool:",
            "Unlike :func:`torch.cuda.is_available`, this function will do its best not to create a CUDA context for fork",
            "support, if the platform allows it.",
            "\"\"\"",
            "-    if \"fork\" not in torch.multiprocessing.get_all_start_methods():",
            "+    if \"fork\" not in torch.multiprocessing.get_all_start_methods() or _is_forking_disabled():",
            "return torch.cuda.is_available()",
            "with multiprocessing.get_context(\"fork\").Pool(1) as pool:",
            "return pool.apply(torch.cuda.is_available)"
        ],
        "comments": "",
        "Symptom": "Low Efficiency",
        "Root_Cause": "Device Management Error",
        "Action": "Missing",
        "Element": "API Condition",
        "Action_Element": "Missing API Condition",
        "Symptom_Root_Cause": "Low Efficiency|Device Management Error"
    },
    {
        "number": 9631,
        "change": [
            "class ConditionalDetrModelIntegrationTests(unittest.TestCase):",
            "results = feature_extractor.post_process_object_detection(",
            "outputs, threshold=0.3, target_sizes=[image.size[::-1]]",
            ")[0]",
            "-        expected_scores = torch.tensor([0.8330, 0.8313, 0.8039, 0.6829, 0.5355])",
            "+        expected_scores = torch.tensor([0.8330, 0.8313, 0.8039, 0.6829, 0.5355]).to(torch_device)",
            "expected_labels = [75, 17, 17, 75, 63]",
            "-        expected_slice_boxes = torch.tensor([38.3089, 72.1022, 177.6293, 118.4512])",
            "+        expected_slice_boxes = torch.tensor([38.3089, 72.1022, 177.6293, 118.4512]).to(torch_device)",
            "",
            "self.assertEqual(len(results[\"scores\"]), 5)",
            "self.assertTrue(torch.allclose(results[\"scores\"], expected_scores, atol=1e-4))"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Device Management Error",
        "Action": "Outdated",
        "Element": "API Method",
        "Action_Element": "Outdated API Method",
        "Symptom_Root_Cause": "Program Crash|Device Management Error"
    },
    {
        "number": 9633,
        "change": [
            "class GraphVarParam(HyperParam):",
            "self._readable_name, self.var_name = get_op_var_name(name)",
            "",
            "def setup_graph(self):",
            "-        all_vars = tf.all_variables()",
            "+        try:",
            "+            all_vars = tf.global_variables()",
            "+        except:",
            "+            # TODO",
            "+            all_vars = tf.all_variables()",
            "+",
            "for v in all_vars:",
            "if v.name == self.var_name:",
            "self.var = v"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Deprecation Management Error",
        "Action": "Missing",
        "Element": "API Method",
        "Action_Element": "Missing API Method",
        "Symptom_Root_Cause": "Program Crash|Deprecation Management Error"
    },
    {
        "number": 9636,
        "change": [
            "class FAUST(Dataset):",
            "index = self.index[:, i]",
            "weight = torch.FloatTensor(index.size(1)).fill_(1)",
            "input = torch.FloatTensor(position.size(0)).fill_(1)",
            "-        adj = torch.sparse.FloatTensor(index, weight, torch.Size([75, 75]))",
            "+        adj = torch.sparse.FloatTensor(index, weight, torch.Size([6890, 6890]))",
            "data = (input, adj, position)",
            "",
            "if self.correspondence:"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Redundant",
        "Element": "API Method",
        "Action_Element": "Redundant API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    },
    {
        "number": 9698,
        "change": [
            "class TestElmo(AllenNlpTestCase):",
            "dataset = Dataset(instances)",
            "vocab = Vocabulary()",
            "dataset.index_instances(vocab)",
            "-        character_ids = dataset.as_array_dict()['elmo']['character_ids']",
            "+        character_ids = dataset.as_tensor_dict()['elmo']['character_ids']",
            "",
            "-        output = elmo(Variable(torch.from_numpy(character_ids)))",
            "+        output = elmo(character_ids)",
            "elmo_representations = output['elmo_representations']",
            "mask = output['mask']"
        ],
        "comments": "",
        "Symptom": "Program Crash",
        "Root_Cause": "Data Conversion Error",
        "Action": "Replace",
        "Element": "API Method",
        "Action_Element": "Replace API Method",
        "Symptom_Root_Cause": "Program Crash|Data Conversion Error"
    }
]
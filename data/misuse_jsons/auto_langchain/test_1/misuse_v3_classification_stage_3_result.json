[
    {
        "number": 3373,
        "label": "no",
        "change": [
            "def tf_function(*, num_args):",
            "results = function(self, **kwargs, **params_kwargs)",
            "return results",
            "",
            "-                function_graphs[graph_params] = tf.function(",
            "+                function_graphs[str(graph_params)] = tf.function(",
            "func=function_graph, input_signature=graph_signature.to_list(), autograph=False",
            "# experimental_implements=None, experimental_autograph_options=None,",
            "# experimental_relax_shapes=False, experimental_compile=None",
            ")",
            "",
            "# Apply function graph",
            "-            return function_graphs[graph_params](*graph_args)",
            "+            return function_graphs[str(graph_params)](*graph_args)",
            "",
            "# TensorFlow make_decorator",
            "return decorated"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3376,
        "label": "no",
        "change": [
            "Returns:",
            "\"\"\"",
            "",
            "",
            "-class Rouge(nlp.Metric):",
            "+class Rouge(datasets.Metric):",
            "def _info(self):",
            "-        return nlp.MetricInfo(",
            "+        return datasets.MetricInfo(",
            "description=_DESCRIPTION,",
            "citation=_CITATION,",
            "inputs_description=_KWARGS_DESCRIPTION,",
            "-            features=nlp.Features(",
            "+            features=datasets.Features(",
            "{",
            "-                    \"predictions\": nlp.Value(\"string\", id=\"sequence\"),",
            "-                    \"references\": nlp.Value(\"string\", id=\"sequence\"),",
            "+                    \"predictions\": datasets.Value(\"string\", id=\"sequence\"),",
            "+                    \"references\": datasets.Value(\"string\", id=\"sequence\"),",
            "}",
            "),",
            "codebase_urls=[\"https://github.com/google-research/google-research/tree/master/rouge\"],"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3378,
        "label": "no",
        "change": [
            "def benchmark_iterating():",
            "]",
            "with tempfile.TemporaryDirectory() as tmp_dir:",
            "print(\"generating dataset\")",
            "-        features = nlp.Features({\"list\": nlp.Sequence(nlp.Value(\"float32\")), \"numbers\": nlp.Value(\"float32\")})",
            "+        features = datasets.Features(",
            "+            {\"list\": datasets.Sequence(datasets.Value(\"float32\")), \"numbers\": datasets.Value(\"float32\")}",
            "+        )",
            "dataset = generate_example_dataset(",
            "os.path.join(tmp_dir, \"dataset.arrow\"),",
            "features,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3379,
        "label": "no",
        "change": [
            "def unique_all(x: Tensor) -> Tuple[Tensor, Tensor, Tensor, Tensor]:",
            "",
            "flat_tensor = tf.reshape(x, [-1])",
            "values, inverse_indices, counts = tf.unique_with_counts(flat_tensor)",
            "-    # values = tf.cast(values, 'float64') if values.dtype not in [tf.float32, tf.float64] else values",
            "tensor_list = flat_tensor.numpy().tolist()",
            "if (",
            "x.dtype.is_floating"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3380,
        "label": "no",
        "change": [
            "def test_get_rtf(ch):",
            "normalized=False,",
            "onesided=True,",
            ")",
            "+    torch.random.manual_seed(0)",
            "x = random_speech[..., :ch]",
            "n = torch.rand(2, 16, ch, dtype=torch.double)",
            "ilens = torch.LongTensor([16, 12])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3383,
        "label": "no",
        "change": [
            "class MixedInt8T5Test(unittest.TestCase):",
            "`flan-t5-small` uses `T5DenseGatedActDense` whereas `t5-small` uses `T5DenseReluDense`. We need to test",
            "both cases.",
            "\"\"\"",
            "+        import bitsandbytes as bnb",
            "+",
            "from transformers import T5ForConditionalGeneration",
            "",
            "# test with `t5-small`",
            "model = T5ForConditionalGeneration.from_pretrained(self.model_name, load_in_8bit=True, device_map=\"auto\")",
            "+",
            "+        # there was a bug with decoders - this test checks that it is fixed",
            "+        self.assertTrue(isinstance(model.decoder.block[0].layer[0].SelfAttention.q, bnb.nn.Linear8bitLt))",
            "+",
            "encoded_input = self.tokenizer(self.input_text, return_tensors=\"pt\").to(0)",
            "_ = model.generate(**encoded_input)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3384,
        "label": "yes",
        "change": [
            "sess = tf.InteractiveSession()",
            "network.print_params(False)",
            "",
            "saver = tf.train.Saver()",
            "-if not os.path.isfile(\"inception_v3.ckpt\"):",
            "+if not os.path.isfile(MODEL_PATH):",
            "raise Exception(",
            "\"Please download inception_v3 ckpt from https://github.com/tensorflow/models/tree/master/research/slim\"",
            ")",
            "",
            "try:  # TF12+",
            "-    saver.restore(sess, \"./inception_v3.ckpt\")",
            "+    saver.restore(sess, MODEL_PATH)",
            "except Exception:  # TF11",
            "-    saver.restore(sess, \"inception_v3.ckpt\")",
            "+    saver.restore(sess, MODEL_PATH)",
            "print(\"Model Restored\")",
            "",
            "y = network.outputs"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3386,
        "label": "no",
        "change": [
            "def matmul(",
            "*,",
            "transpose_a: bool = False,",
            "transpose_b: bool = False,",
            "-    out: Optional[torch.Tensor] = None,",
            "+    out: Optional[torch.Tensor] = None",
            ") -> torch.Tensor:",
            "if transpose_a is True:",
            "x1 = torch.t(x1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3388,
        "label": "no",
        "change": [
            "class Decoder(BatchScorerInterface, torch.nn.Module):",
            "logp, states = self.forward_one_step(ys, ys_mask, xs, cache=batch_state)",
            "",
            "# transpose state of [layer, batch] into [batch, layer]",
            "-        state_list = [[states[l][b] for l in range(n_layers)] for b in range(n_batch)]",
            "+        state_list = [[states[i][b] for i in range(n_layers)] for b in range(n_batch)]",
            "return logp, state_list"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3389,
        "label": "no",
        "change": [
            "def rgb_to_hsv(image: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:",
            "if len(image.shape) < 3 or image.shape[-3] != 3:",
            "raise ValueError(f\"Input size must have a shape of (*, 3, H, W). Got {image.shape}\")",
            "",
            "-    # TODO: remove if/else statement once pytorch 1.6 is deprecated and keep first branch",
            "-    max_rgb, argmax_rgb = _compute_max_argmax(image)",
            "+    max_rgb, argmax_rgb = image.max(-3)",
            "min_rgb, argmin_rgb = image.min(-3)",
            "deltac = max_rgb - min_rgb"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3392,
        "label": "yes",
        "change": [
            "class Detect(nn.Module):",
            "y = torch.cat((xy, wh, conf), 4)",
            "z.append(y.view(bs, -1, self.no))",
            "",
            "-        return x if self.training else (torch.cat(z, 1), x)",
            "+        return x if self.training else (torch.cat(z, 1),) if self.export else (torch.cat(z, 1), x)",
            "",
            "def _make_grid(self, nx=20, ny=20, i=0):",
            "d = self.anchors[i].device"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 3394,
        "label": "yes",
        "change": [
            "def benchmark_indices_mapping():",
            "functions = (select, sort, shuffle, train_test_split, shard)",
            "with tempfile.TemporaryDirectory() as tmp_dir:",
            "print(\"generating dataset\")",
            "-        features = nlp.Features({\"text\": nlp.Value(\"string\"), \"numbers\": nlp.Value(\"float32\")})",
            "+        features = datasets.Features({\"text\": datasets.Value(\"string\"), \"numbers\": datasets.Value(\"float32\")})",
            "dataset = generate_example_dataset(",
            "os.path.join(tmp_dir, \"dataset.arrow\"), features, num_examples=SPEED_TEST_N_EXAMPLES",
            ")"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3395,
        "label": "yes",
        "change": [
            "def main():",
            "# train",
            "logging.info('backend = ' + args.backend)",
            "if args.backend == \"chainer\":",
            "-        from espnet.lmchainer.asr_chainer import train",
            "+        from espnet.asr.chainer.asr_chainer import train",
            "train(args)",
            "elif args.backend == \"pytorch\":",
            "-        from espnet.lmpytorch.asr_pytorch import train",
            "+        from espnet.asr.pytorch.asr_pytorch import train",
            "train(args)",
            "else:",
            "raise ValueError(\"Only chainer and pytorch are supported.\")"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3396,
        "label": "no",
        "change": [
            "def regularize_cost_from_collection(name='regularize_cost'):",
            "\"\"\"",
            "regularization_losses = set(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))",
            "ctx = get_current_tower_context()",
            "+    if not ctx.is_training:",
            "+        # Currently cannot build the wd_cost correctly at inference,",
            "+        # because ths vs_name used in inference can be '', therefore the",
            "+        # variable filter will fail",
            "+        return None",
            "+",
            "if len(regularization_losses) > 0:",
            "# NOTE: this collection doesn't grow with towers.",
            "# It is only added with variables that are newly created."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3400,
        "label": "no",
        "change": [
            "def fbresnet_mapper(isTrain):",
            "return image",
            "",
            "def lighting(image, std, eigval, eigvec):",
            "-        v = tf.random_uniform(shape=[3]) * std * eigval",
            "+        v = tf.random_normal(shape=[3], stddev=std) * eigval",
            "inc = tf.matmul(eigvec, tf.reshape(v, [3, 1]))",
            "image = tf.cast(tf.cast(image, tf.float32) + tf.reshape(inc, [3]), image.dtype)",
            "return image"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3401,
        "label": "no",
        "change": [
            "class Average(Metric):",
            "_total_value = list(self.detach_tensors(value))[0]",
            "_count = 1",
            "if is_distributed():",
            "-            device = torch.device(\"cpu\")",
            "+            device = torch.device(\"cuda\" if dist.get_backend() == \"nccl\" else \"cpu\")",
            "count = torch.tensor(_count).to(device)",
            "total_value = torch.tensor(_total_value).to(device)",
            "dist.all_reduce(count, op=dist.ReduceOp.SUM)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3402,
        "label": "no",
        "change": [
            "torch, _ = try_import_torch()",
            "class TestDDPG(unittest.TestCase):",
            "@classmethod",
            "def setUpClass(cls) -> None:",
            "+        np.random.seed(42)",
            "+        torch.manual_seed(42)",
            "ray.init()",
            "",
            "@classmethod"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3403,
        "label": "no",
        "change": [
            "class Pipeline(_ScikitCompat):",
            "Return:",
            ":obj:`Dict[str, torch.Tensor]`: The same as :obj:`inputs` but on the proper device.",
            "\"\"\"",
            "-        return {name: tensor.to(self.device) for name, tensor in inputs.items()}",
            "+        return {",
            "+            name: tensor.to(self.device) if isinstance(tensor, torch.Tensor) else tensor",
            "+            for name, tensor in inputs.items()",
            "+        }",
            "",
            "def check_model_type(self, supported_models: Union[List[str], dict]):",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3404,
        "label": "no",
        "change": [
            "class TransformerDecoderLayerBase(nn.Module):",
            "if self.c_attn is not None:",
            "tgt_len, bsz = x.size(0), x.size(1)",
            "x = x.view(tgt_len, bsz, self.nh, self.head_dim)",
            "-            x = torch.einsum('tbhd,h->tbdh', x, self.c_attn)",
            "+            x = torch.einsum('tbhd,h->tbhd', x, self.c_attn)",
            "x = x.reshape(tgt_len, bsz, self.embed_dim)",
            "if self.attn_ln is not None:",
            "x = self.attn_ln(x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3405,
        "label": "no",
        "change": [
            "class LoadCheckpoint(session_run_hook.SessionRunHook):",
            "def after_create_session(self, session, coord):",
            "if not self._loaded:",
            "self._loaded = True",
            "-            self._saver.restore(self._checkpoint)",
            "\\ No newline at end of file",
            "+            self._saver.restore(self._checkpoint)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3406,
        "label": "yes",
        "change": [
            "def get_checkpoint_path(model_path):",
            "logger.warn(",
            "\"Checkpoint path {} is auto-corrected to {}.\".format(model_path, new_path))",
            "model_path = new_path",
            "-    assert os.path.isfile(model_path) or os.path.isfile(model_path + '.index'), model_path",
            "+    assert tf.gfile.Exists(model_path) or tf.gfile.Exists(model_path + '.index'), model_path",
            "return model_path"
        ],
        "comments": "",
        "Symptom": "return warning",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 3407,
        "label": "no",
        "change": [
            "def get_projective_transform(center: torch.Tensor, angles: torch.Tensor, scales:",
            "raise AssertionError(center.dtype, angles.dtype)",
            "",
            "# create rotation matrix",
            "-    angle_axis_rad: torch.Tensor = K.deg2rad(angles)",
            "-    rmat: torch.Tensor = K.angle_axis_to_rotation_matrix(angle_axis_rad)  # Bx3x3",
            "-    scaling_matrix: torch.Tensor = K.eye_like(3, rmat)",
            "+    angle_axis_rad: torch.Tensor = deg2rad(angles)",
            "+    rmat: torch.Tensor = angle_axis_to_rotation_matrix(angle_axis_rad)  # Bx3x3",
            "+    scaling_matrix: torch.Tensor = eye_like(3, rmat)",
            "scaling_matrix = scaling_matrix * scales.unsqueeze(dim=1)",
            "rmat = rmat @ scaling_matrix.to(rmat)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3408,
        "label": "yes",
        "change": [
            "class TextClassifier(flair.nn.Model):",
            "self.document_embeddings.embed(sentences)",
            "",
            "text_embedding_list = [sentence.get_embedding().unsqueeze(0) for sentence in sentences]",
            "-        text_embedding_tensor = torch.cat(text_embedding_list, 0)",
            "+        text_embedding_tensor = torch.cat(text_embedding_list, 0).to(flair.device)",
            "",
            "label_scores = self.decoder(text_embedding_tensor)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3410,
        "label": "no",
        "change": [
            "def reconstruct_cond_batch(c: ScheduledPromptBatch, current_step):",
            "break",
            "res[i] = cond_schedule[target_index].cond",
            "",
            "-    return res.to(shared.device)",
            "+    return res"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3415,
        "label": "yes",
        "change": [
            "def recog_v2(args):",
            "for idx, name in enumerate(js.keys(), 1):",
            "logging.info('(%d/%d) decoding ' + name, idx, len(js.keys()))",
            "batch = [(name, js[name])]",
            "-            enc = model.encode(load_inputs_and_targets(batch)[0][0])",
            "+            feat = load_inputs_and_targets(batch)[0][0]",
            "+            enc = model.encode(torch.as_tensor(feat).to(device))",
            "nbest_hyps = beam_search(",
            "x=enc,",
            "sos=model.sos,"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3418,
        "label": "no",
        "change": [
            "class TorchRNNModel(TorchRNN):",
            "name,",
            "fc_size=64,",
            "lstm_state_size=256):",
            "+        nn.Module.__init__(self)",
            "super().__init__(obs_space, action_space, num_outputs, model_config,",
            "name)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3419,
        "label": "yes",
        "change": [
            "class DecoderRNNT(torch.nn.Module):",
            "normscore = recog_args.score_norm_transducer",
            "",
            "z_list, c_list = self.zero_state(h.unsqueeze(0))",
            "-        eys = torch.zeros((1, self.embed_dim))",
            "+        eys = to_device(self, torch.zeros((1, self.embed_dim)))",
            "",
            "_, (z_list, c_list) = self.rnn_forward(eys, None)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3421,
        "label": "yes",
        "change": [
            "def parse_npz(f):",
            "",
            "adj = sp.csr_matrix((f['adj_data'], f['adj_indices'], f['adj_indptr']),",
            "f['adj_shape']).tocoo()",
            "-    edge_index = torch.tensor([adj.row, adj.col])",
            "+    edge_index = torch.tensor([adj.row, adj.col], dtype=torch.long)",
            "edge_index, _ = remove_self_loops(edge_index)",
            "edge_index = to_undirected(edge_index, x.size(0))  # Internal coalesce."
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 3423,
        "label": "no",
        "change": [
            "class Exp(MyExp):",
            "",
            "if is_distributed:",
            "batch_size = batch_size // dist.get_world_size()",
            "-            sampler = InfiniteSampler(",
            "-                len(self.dataset), seed=self.seed if self.seed else 0",
            "-            )",
            "-        else:",
            "-            sampler = torch.utils.data.RandomSampler(self.dataset)",
            "+",
            "+        sampler = InfiniteSampler(",
            "+            len(self.dataset), seed=self.seed if self.seed else 0",
            "+        )",
            "",
            "batch_sampler = YoloBatchSampler(",
            "sampler=sampler,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3425,
        "label": "no",
        "change": [
            "class LJSpeech(datasets.GeneratorBasedBuilder):",
            "example = {",
            "\"id\": uid,",
            "\"file\": os.path.join(wav_path, filename),",
            "+                    \"audio\": os.path.join(wav_path, filename),",
            "\"text\": text,",
            "\"normalized_text\": norm_text,",
            "}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3426,
        "label": "no",
        "change": [
            "def LeakyReLU(x, alpha, name=None):",
            "if name is None:",
            "name = 'output'",
            "return tf.maximum(x, alpha * x, name=name)",
            "-    #alpha = float(alpha)",
            "-    #x = ((1 + alpha) * x + (1 - alpha) * tf.abs(x))",
            "+    # alpha = float(alpha)",
            "+    # x = ((1 + alpha) * x + (1 - alpha) * tf.abs(x))",
            "# return tf.mul(x, 0.5, name=name)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3429,
        "label": "no",
        "change": [
            "class ExampleModel(BaseModel):",
            "",
            "",
            "def init_saver(self):",
            "-        # here you initalize the tensorflow saver that will be used in saving the checkpoints.",
            "+        # here you initialize the tensorflow saver that will be used in saving the checkpoints.",
            "self.saver = tf.train.Saver(max_to_keep=self.config.max_to_keep)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3430,
        "label": "no",
        "change": [
            "class Categorical(Distribution):",
            "state_value = tf.reduce_logsumexp(input_tensor=logits, axis=-1)",
            "",
            "# Softmax for corresponding probabilities",
            "-        probabilities = tf.nn.softmax(logits=logits, dim=-1)",
            "+        probabilities = tf.nn.softmax(logits=logits, axis=-1)",
            "",
            "# Min epsilon probability for numerical stability",
            "probabilities = tf.maximum(x=probabilities, y=util.epsilon)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3431,
        "label": "no",
        "change": [
            "class UNetUnconditionalModel(ModelMixin, ConfigMixin):",
            "prev_output_channel = output_channel",
            "",
            "# out",
            "-        self.conv_norm_out = nn.GroupNorm(num_channels=block_channels[0], num_groups=32, eps=1e-5)",
            "+        self.conv_norm_out = nn.GroupNorm(num_channels=block_channels[0], num_groups=32, eps=resnet_eps)",
            "self.conv_act = nn.SiLU()",
            "self.conv_out = nn.Conv2d(block_channels[0], out_channels, 3, padding=1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3435,
        "label": "no",
        "change": [
            "class Trainer(Trainable):",
            "logging.getLogger(\"ray.rllib\").setLevel(self.config[\"log_level\"])",
            "",
            "def get_scope():",
            "-            if tf and not tf.executing_eagerly():",
            "-                return tf.Graph().as_default()",
            "+            if tf1 and not tf1.executing_eagerly():",
            "+                return tf1.Graph().as_default()",
            "else:",
            "return open(os.devnull)  # fake a no-op scope"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3436,
        "label": "no",
        "change": [
            "class PassThroughEncoder(Seq2SeqEncoder):",
            "else:",
            "# We should mask out the output instead of the input.",
            "# But here, output = input, so we directly mask out the input.",
            "-            return inputs * mask.unsqueeze(dim=-1).float()",
            "+            return inputs * mask.unsqueeze(dim=-1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3437,
        "label": "no",
        "change": [
            "def zeta(",
            "*,",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "-    return torch.special.zeta(x, q)",
            "+    return torch.special.zeta(x, q, out=out)",
            "",
            "",
            "-zeta.support_native_out = False",
            "+zeta.support_native_out = True",
            "",
            "",
            "def gradient("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3441,
        "label": "yes",
        "change": [
            "class GroupViTTextTransformer(nn.Module):",
            "",
            "# text_embeds.shape = [batch_size, sequence_length, transformer.width]",
            "# take features from the eot embedding (eot_token is the highest number in each sequence)",
            "-        pooled_output = last_hidden_state[torch.arange(last_hidden_state.shape[0]), input_ids.argmax(dim=-1)]",
            "+        # casting to torch.int for onnx compatibility: argmax doesn't support int64 inputs with opset 14",
            "+        pooled_output = last_hidden_state[",
            "+            torch.arange(last_hidden_state.shape[0]), input_ids.to(torch.int).argmax(dim=-1)",
            "+        ]",
            "",
            "if not return_dict:",
            "return (last_hidden_state, pooled_output) + encoder_outputs[1:]"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3442,
        "label": "yes",
        "change": [
            "def train(args, train_dataset, model, tokenizer, labels, pad_token_label_id):",
            "if args.fp16:",
            "with amp.scale_loss(loss, optimizer) as scaled_loss:",
            "scaled_loss.backward()",
            "-                torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)",
            "else:",
            "loss.backward()",
            "-                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)",
            "",
            "tr_loss += loss.item()",
            "if (step + 1) % args.gradient_accumulation_steps == 0:",
            "+                if args.fp16:",
            "+                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)",
            "+                else:",
            "+                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)",
            "+",
            "scheduler.step()  # Update learning rate schedule",
            "optimizer.step()",
            "model.zero_grad()"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3443,
        "label": "no",
        "change": [
            "def train(args):",
            "",
            "# Save attention weight each epoch",
            "if args.num_save_attention > 0 and args.mtlalpha != 1.0:",
            "-        data = sorted(valid_json.items()[:args.num_save_attention],",
            "+        data = sorted(list(valid_json.items())[:args.num_save_attention],",
            "key=lambda x: int(x[1]['input'][0]['shape'][1]), reverse=True)",
            "data = converter_kaldi([data], device=gpu_id)",
            "trainer.extend(PlotAttentionReport(model, data, args.outdir + \"/att_ws\"), trigger=(1, 'epoch'))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3446,
        "label": "no",
        "change": [
            "def trans(args):",
            "names = [name for name in names if name]",
            "batch = [(name, js[name]) for name in names]",
            "feats = load_inputs_and_targets(batch)[0]",
            "-                nbest_hyps = model.translate_batch(",
            "-                    feats,",
            "-                    args,",
            "-                    train_args.char_list,",
            "-                )",
            "+                nbest_hyps = model.translate_batch(feats, args, train_args.char_list)",
            "",
            "for i, nbest_hyp in enumerate(nbest_hyps):",
            "name = names[i]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3452,
        "label": "yes",
        "change": [
            "class PReluLayer(Layer):",
            "",
            "# with tf.name_scope(name) as scope:",
            "with tf.variable_scope(name):",
            "-            alphas = tf.get_variable(name='alphas', shape=w_shape, initializer=a_init, dtype=D_TYPE, **a_init_args)",
            "+            alphas = tf.get_variable(name='alphas', shape=w_shape, initializer=a_init, dtype=LayersConfig.tf_dtype, **a_init_args)",
            "try:  # TF 1.0",
            "self.outputs = tf.nn.relu(self.inputs) + tf.multiply(alphas, (self.inputs - tf.abs(self.inputs))) * 0.5",
            "except Exception:  # TF 0.12"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 3456,
        "label": "no",
        "change": [
            "class TorchElasticEnvironment(ClusterEnvironment):",
            "def detect() -> bool:",
            "\"\"\"Returns ``True`` if the current process was launched using the torchelastic command.\"\"\"",
            "if _TORCH_GREATER_EQUAL_1_9_1:",
            "-            return torch.distributed.is_torchelastic_launched()",
            "+            # if not available (for example on MacOS), `is_torchelastic_launched` is not defined",
            "+            return torch.distributed.is_available() and torch.distributed.is_torchelastic_launched()",
            "required_env_vars = {\"RANK\", \"GROUP_RANK\", \"LOCAL_RANK\", \"LOCAL_WORLD_SIZE\"}",
            "return required_env_vars.issubset(os.environ.keys())"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3459,
        "label": "no",
        "change": [
            "def cast(x, dtype):",
            "# you need to assign it.",
            ">>> input = K.cast(input, dtype='float16')",
            ">>> input",
            "-        <tf.Tensor 'Cast_2:0' shape=(2, 3) dtype=float16>",
            "+        <tf.Tensor 'Cast_2:0' shape=(2, 3) dtype=float16>",
            "```",
            "\"\"\"",
            "return tf.cast(x, dtype)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3464,
        "label": "no",
        "change": [
            "class TestFeedforwardEncoder(AllenNlpTestCase):",
            ")",
            "",
            "# mask should work",
            "-        mask = torch.LongTensor([[1, 1, 1], [1, 0, 0]])",
            "+        mask = torch.BoolTensor([[True, True, True], [True, False, False]])",
            "output = encoder(tensor, mask)",
            "target = feedforward(tensor) * mask.unsqueeze(dim=-1).float()",
            "numpy.testing.assert_array_almost_equal("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3465,
        "label": "no",
        "change": [
            "class SpatialTransformer(nn.Module):",
            "self.d_head = d_head",
            "self.in_channels = in_channels",
            "inner_dim = n_heads * d_head",
            "-        self.norm = torch.nn.GroupNorm(num_groups=32, num_channels=in_channels, eps=1e-6, affine=True)",
            "+        self.norm = torch.nn.GroupNorm(num_groups=num_groups, num_channels=in_channels, eps=1e-6, affine=True)",
            "",
            "self.proj_in = nn.Conv2d(in_channels, inner_dim, kernel_size=1, stride=1, padding=0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3466,
        "label": "no",
        "change": [
            "class LSTM(Model):",
            "",
            "@override(Model)",
            "def _build_layers_v2(self, input_dict, num_outputs, options):",
            "+        import tensorflow.contrib.rnn as rnn",
            "+",
            "cell_size = options.get(\"lstm_cell_size\")",
            "if options.get(\"lstm_use_prev_action_reward\"):",
            "action_dim = int("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3468,
        "label": "no",
        "change": [
            "class WaveRNN(nn.Module):",
            "",
            "def forward(self, x, mels):",
            "bsize = x.size(0)",
            "-        h1 = torch.zeros(1, bsize, self.rnn_dims).to(x.device)",
            "+        h1 = torch.zeros(1, bsize, self.rnn_dims).to(x.device)",
            "h2 = torch.zeros(1, bsize, self.rnn_dims).to(x.device)",
            "mels, aux = self.upsample(mels)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3469,
        "label": "no",
        "change": [
            "class ResNet(nn.Module):",
            "",
            "def train(self, mode=True):",
            "super(ResNet, self).train(mode)",
            "+        self._freeze_stages()",
            "if mode and self.norm_eval:",
            "for m in self.modules():",
            "# trick: eval have effect on BatchNorm only",
            "-                if isinstance(m, nn.BatchNorm2d):",
            "+                if isinstance(m, _BatchNorm):",
            "m.eval()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3470,
        "label": "yes",
        "change": [
            "class Input(Layer):",
            "logging.info(\"Input  %s: %s\" % (self.name, str(shape)))",
            "",
            "shape_without_none = [_ if _ is not None else 1 for _ in shape]",
            "-        self.outputs = self.forward(tf.initializers.random_normal()(shape_without_none))",
            "+        self.outputs = self.forward(tf.compat.v1.initializers.random_normal()(shape_without_none))",
            "",
            "def __call__(self, prev_layer):",
            "# FIXME: better exception raising"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3471,
        "label": "no",
        "change": [
            "if TORCHVISION_VERSION < version.parse(\"0.9.1\"):",
            "\"ec29112dd5afa0611ce80d1b7f02629c\",",
            "),",
            "]",
            "-",
            "+else:",
            "+    torchvision.datasets.MNIST.mirrors.insert(0, URL)",
            "",
            "torchvision.datasets.MNIST(get_root_data_path(), train=True, download=True)",
            "torchvision.datasets.MNIST(get_root_data_path(), train=False, download=True)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3474,
        "label": "no",
        "change": [
            "def average_precision(",
            "# Return the step function integral",
            "# The following works because the last entry of precision is",
            "# guaranteed to be 1, as returned by precision_recall_curve",
            "-    return -torch.sum(recall[1:] - recall[:-1] * precision[:-1])",
            "+    return -torch.sum((recall[1:] - recall[:-1]) * precision[:-1])",
            "",
            "",
            "def dice_score("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3477,
        "label": "yes",
        "change": [
            "class Generator(datasets.GeneratorBasedBuilder):",
            "return datasets.DatasetInfo(features=self.config.features)",
            "",
            "def _split_generators(self, dl_manager):",
            "-        return [datasets.SplitGenerator(name=datasets.Split.TRAIN, gen_kwargs={})]",
            "+        return [datasets.SplitGenerator(name=datasets.Split.TRAIN, gen_kwargs=self.config.gen_kwargs)]",
            "",
            "-    def _generate_examples(self):",
            "-        for idx, ex in enumerate(self.config.generator(**self.config.gen_kwargs)):",
            "+    def _generate_examples(self, **gen_kwargs):",
            "+        for idx, ex in enumerate(self.config.generator(**gen_kwargs)):",
            "yield idx, ex"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 3479,
        "label": "no",
        "change": [
            "def one_hot(x, depth=0, on_value=1, off_value=0):",
            "x = x.astype(np.int)",
            "depth = 2",
            "",
            "+    # If depth is not given, try to infer it from the values in the array.",
            "if depth == 0:",
            "depth = np.max(x) + 1",
            "assert np.max(x) < depth, \\"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3481,
        "label": "no",
        "change": [
            "class MaskedLinear(nn.Linear):",
            "Constructor",
            "\"\"\"",
            "super(MaskedLinear, self).__init__(in_features, out_features, bias)",
            "-        self.register_buffer('mask', mask)",
            "+        self.register_buffer('mask', mask.data)",
            "",
            "def forward(self, _input):",
            "-        masked_weight = self.weight * self.mask",
            "+        masked_weight = self.weight * torch.autograd.Variable(self.mask)",
            "return F.linear(_input, masked_weight, self.bias)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3484,
        "label": "no",
        "change": [
            "def atomic_save(checkpoint, filepath: str):",
            "# Can't use the new zipfile serialization for 1.6.0 because there's a bug in",
            "# torch.hub.load_state_dict_from_url() that prevents it from loading the new files.",
            "# More details can be found here: https://github.com/pytorch/pytorch/issues/42239",
            "-    if LooseVersion(torch.__version__).version[:3] == [1, 6, 0]:",
            "+    if Version(torch.__version__).release[:3] == (1, 6, 0):",
            "torch.save(checkpoint, bytesbuffer, _use_new_zipfile_serialization=False)",
            "else:",
            "torch.save(checkpoint, bytesbuffer)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3485,
        "label": "no",
        "change": [
            "class PyTorchBenchmark(Benchmark):",
            ")",
            "torch.cuda.reset_max_memory_cached()",
            "",
            "-                        # run forward",
            "-                        _forward()",
            "+                    # run forward",
            "+                    _forward()",
            "elif not self.args.no_tpu and is_torch_tpu_available():",
            "# tpu",
            "raise NotImplementedError("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3490,
        "label": "no",
        "change": [
            "class MultiCompilerOptimizer(BaseOptimizer):",
            ")",
            "if return_all:",
            "return optimized_models",
            "-        optimized_models.sort(key=lambda x: x[1], ascending=True)",
            "+        optimized_models.sort(key=lambda x: x[1], reverse=False)",
            "return optimized_models[0][0]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3491,
        "label": "no",
        "change": [
            "def test_quantization(tmpdir, observe: str, fuse: bool, convert: bool):",
            "# todo: make it work also with strict loading",
            "qmodel2 = RegressionModel.load_from_checkpoint(model_path, strict=False)",
            "quant2_score = torch.mean(torch.tensor([mape(qmodel2(x), y) for x, y in dm.test_dataloader()]))",
            "-    assert torch.allclose(org_score, quant2_score, atol=0.45)",
            "+    assert torch.allclose(org_score, quant2_score, atol=0.47)",
            "",
            "# test without and with QAT callback",
            "trainer_args.update(max_epochs=curr_epoch + 1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3492,
        "label": "yes",
        "change": [
            "def run(",
            "seen, windows, dt = 0, [], (Profile(), Profile(), Profile())",
            "for path, im, im0s, vid_cap, s in dataset:",
            "with dt[0]:",
            "-            im = torch.from_numpy(im).to(device)",
            "+            im = torch.from_numpy(im).to(model.device)",
            "im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32",
            "im /= 255  # 0 - 255 to 0.0 - 1.0",
            "if len(im.shape) == 3:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 3493,
        "label": "no",
        "change": [
            "class Scheduler:",
            "\"\"\"",
            "Returns the state of the scheduler as a ``dict``.",
            "\"\"\"",
            "-        return {key: value for key, value in self.__dict__.items() if key != 'optimizer'}",
            "+        return {key: value for key, value in self.__dict__.items() if key != \"optimizer\"}",
            "",
            "def load_state_dict(self, state_dict: Dict[str, Any]) -> None:",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3496,
        "label": "no",
        "change": [
            "class PGModel(Model):",
            "self.dist = self.policy.get_distribution()",
            "",
            "self.baseline_value_function = LinearValueFunction()",
            "-        self.saver = tf.train.Saver()",
            "+       # self.saver = tf.train.Saver()",
            "",
            "def get_action(self, state, episode=1):",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3499,
        "label": "no",
        "change": [
            "class StatefulLayer(TemporalLayer):",
            "",
            "# def tf_apply(self, x, **internals):",
            "",
            "-    #     # optimization = tf.math.logical_not(x=Module.retrieve_tensor(name='optimization'))",
            "+    #     # optimization = tf.math.logical_not(x=Module.retrieve_tensor(name='???'))",
            "",
            "#     # def true_fn():",
            "#     batch_size = tf.shape("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3500,
        "label": "no",
        "change": [
            "class TestDotProductSimilarityFunction(AllenNlpTestCase):",
            "a_vectors = numpy.random.rand(5, 4, 3, 6, 7)",
            "b_vectors = numpy.random.rand(5, 4, 3, 6, 7)",
            "desired_result = numpy.sum(a_vectors * b_vectors, axis=-1)",
            "-        result = dot_product(Variable(torch.from_numpy(a_vectors)),",
            "-                             Variable(torch.from_numpy(b_vectors))).data.numpy()",
            "+        result = dot_product(torch.from_numpy(a_vectors),",
            "+                             torch.from_numpy(b_vectors)).data.numpy()",
            "assert result.shape == (5, 4, 3, 6)",
            "# We're cutting this down here with a random partial index, so that if this test fails the",
            "# output isn't so huge and slow."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3505,
        "label": "no",
        "change": [
            "class TFPolicy(Policy):",
            "",
            "# build output signatures",
            "output_signature = self._extra_output_signature_def()",
            "-        for i, a in enumerate(tf.nest.flatten(self._sampled_action)):",
            "+        for i, a in enumerate(tree.flatten(self._sampled_action)):",
            "output_signature[\"actions_{}\".format(i)] = \\",
            "tf.saved_model.utils.build_tensor_info(a)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3506,
        "label": "no",
        "change": [
            "class DictTrainer(BaseTrainer):",
            "",
            "def load(self, filename):",
            "try:",
            "-            checkpoint = torch.load(filename)",
            "+            checkpoint = torch.load(filename, lambda storage, loc: storage)",
            "except BaseException:",
            "print(\"Cannot load model from {}\".format(filename))",
            "exit()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3507,
        "label": "no",
        "change": [
            "class MultiStep(MetaOptimizer):",
            "deltas = [delta1 + delta2 for delta1, delta2 in zip(deltas, step_deltas)]",
            "return deltas",
            "",
            "-            deltas = tf.while_loop(",
            "+            deltas = self.while_loop(",
            "cond=util.tf_always_true, body=body, loop_vars=(deltas,),",
            "maximum_iterations=(self.num_steps - 1)",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3508,
        "label": "no",
        "change": [
            "def european_option_price(",
            "0.0, dtype=dtype, name='discount_rates')",
            "",
            "if dividend_rates is None:",
            "-      dividend_rates = tf.convert_to_tensor(",
            "-          0.0, dtype=dtype, name='dividend_rates')",
            "+      dividend_rates = 0.0",
            "+    dividend_rates = tf.convert_to_tensor(",
            "+        dividend_rates, dtype=dtype, name='dividend_rates')",
            "",
            "if discount_factors is None:",
            "discount_factors = tf.exp(-discount_rates * expiries)  # pylint: disable=invalid-unary-operand-type"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3509,
        "label": "no",
        "change": [
            "class ElmoTokenEmbedder(TokenEmbedder):",
            "The ELMo representations for the input sequence, shape",
            "``(batch_size, timesteps, embedding_dim)``",
            "\"\"\"",
            "-        elmo_output = self._elmo(inputs, word_inputs)",
            "+        elmo_output = self._elmo(tokens, word_inputs)",
            "elmo_representations = elmo_output[\"elmo_representations\"][0]",
            "if self._projection:",
            "projection = self._projection"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3511,
        "label": "no",
        "change": [
            "class TorchModel(torch.nn.Module):",
            "self.graph = graph",
            "self.layers = []",
            "for layer in graph.layer_list:",
            "-            self.layers.append(to_real_layer(layer))",
            "+            self.layers.append(layer.to_real_layer())",
            "if graph.weighted:",
            "for index, layer in enumerate(self.layers):",
            "set_stub_weight_to_torch(self.graph.layer_list[index], layer)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3512,
        "label": "no",
        "change": [
            "def psnr(input: torch.Tensor, target: torch.Tensor, max_val: float) -> torch.Ten",
            "if input.shape != target.shape:",
            "raise TypeError(f\"Expected tensors of equal shapes, but got {input.shape} and {target.shape}\")",
            "",
            "-    return 10. * torch.log10(max_val ** 2 / mse(input, target, reduction='mean'))",
            "+    return 10. * torch.log10(max_val**2 / mse(input, target, reduction='mean'))",
            "",
            "",
            "def psnr_loss(input: torch.Tensor, target: torch.Tensor, max_val: float) -> torch.Tensor:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3513,
        "label": "yes",
        "change": [
            "class OPTAttention(nn.Module):",
            "attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len) + attention_mask",
            "attn_weights = torch.max(attn_weights, torch.tensor(torch.finfo(attn_weights.dtype).min))",
            "attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)",
            "-            dtype_attn_weights = attn_weights.dtype",
            "",
            "# upcast to fp32 if the weights are in fp16. Please see https://github.com/huggingface/transformers/pull/17437",
            "-        if dtype_attn_weights == torch.float16:",
            "-            attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(dtype_attn_weights)",
            "+        if attn_weights.dtype == torch.float16:",
            "+            attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(torch.float16)",
            "else:",
            "attn_weights = nn.functional.softmax(attn_weights, dim=-1)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3514,
        "label": "no",
        "change": [
            "class SpanBasedF1Measure(Metric):",
            "possible roles associated with it).",
            "\"\"\"",
            "if mask is None:",
            "-            mask = torch.ones_like(gold_labels)",
            "+            mask = torch.ones_like(gold_labels).bool()",
            "",
            "predictions, gold_labels, mask, prediction_map = self.detach_tensors(",
            "predictions, gold_labels, mask, prediction_map"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3519,
        "label": "no",
        "change": [
            "class RNNScratch(nn.Module):",
            "(self.num_inputs, self.num_hiddens))",
            "self.W_hh = self.param('W_hh', nn.initializers.normal(self.sigma),",
            "(self.num_hiddens, self.num_hiddens))",
            "-        self.b_h = self.param('b_h', nn.initializers.zeros, (num_hiddens))",
            "+        self.b_h = self.param('b_h', nn.initializers.zeros, (self.num_hiddens))",
            "",
            "def __call__(self, inputs, state=None):",
            "\"\"\"Defined in :numref:`sec_rnn-scratch`\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3521,
        "label": "no",
        "change": [
            "eigvals.support_native_out = False",
            "",
            "",
            "def adjoint(",
            "-        x: torch.Tensor,",
            "-        /,",
            "-        *,",
            "-        out: Optional[torch.Tensor] = None,",
            "+    x: torch.Tensor,",
            "+    /,",
            "+    *,",
            "+    out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "_check_valid_dimension_size(x)",
            "return torch.adjoint(x).resolve_conj()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3523,
        "label": "no",
        "change": [
            "def vsplit(",
            "ary: torch.Tensor,",
            "indices_or_sections: Union[int, Tuple[int]],",
            "/,",
            "-    *,",
            "-    out: Optional[torch.Tensor] = None,",
            "-) -> torch.Tensor:",
            "+) -> List[torch.Tensor]:",
            "return torch.vsplit(ary, indices_or_sections)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3525,
        "label": "no",
        "change": [
            "def remove_squeezable_dimensions(",
            "Tuple of `labels` and `predictions`, possibly with last dim squeezed.",
            "\"\"\"",
            "with backend.name_scope(name or 'remove_squeezable_dimensions'):",
            "-    # tf.is_tensor returns True if predictions is a tensor or composite tensor.",
            "-    if not tf.is_tensor(predictions):",
            "+    if not tf_utils.is_tensor_or_extension_type(predictions):",
            "predictions = tf.convert_to_tensor(predictions)",
            "-    if not tf.is_tensor(labels):",
            "+    if not tf_utils.is_tensor_or_extension_type(labels):",
            "labels = tf.convert_to_tensor(labels)",
            "predictions_shape = predictions.shape",
            "predictions_rank = predictions_shape.ndims"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3531,
        "label": "yes",
        "change": [
            "class ScoreSdeVpScheduler(SchedulerMixin, ConfigMixin):",
            "self.discrete_sigmas = None",
            "self.timesteps = None",
            "",
            "-    def set_timesteps(self, num_inference_steps):",
            "-        self.timesteps = torch.linspace(1, self.config.sampling_eps, num_inference_steps)",
            "+    def set_timesteps(self, num_inference_steps, device: Union[str, torch.device] = None):",
            "+        self.timesteps = torch.linspace(1, self.config.sampling_eps, num_inference_steps, device=device)",
            "",
            "def step_pred(self, score, x, t, generator=None):",
            "if self.timesteps is None:"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 3533,
        "label": "yes",
        "change": [
            "class DeepSpeedEngine(Module):",
            "model_dtype = torch.bfloat16",
            "",
            "if self._config.grad_accum_dtype == None:",
            "-            if model_dtype == torch.bfloat16:",
            "+            if model_dtype == torch.bfloat16 and not self.zero_optimization():",
            "grad_accum_dtype = torch.float32",
            "else:",
            "grad_accum_dtype = model_dtype"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 3535,
        "label": "no",
        "change": [
            "def csoftmax_for_slice(input):",
            "p = q_list[1] * (1.0 - mass_) / tf.reduce_sum(q_list[1])",
            "p_new = tf.dynamic_stitch(condition_indices, [q_list[0], p])",
            "",
            "-        # verification of the condition and modification of masks",
            "-        less_mask = tf.cast(tf.less(u, p_new), tf.int32)  # 0 when u bigger than p, 1 when u less than p",
            "+        # condition verification and mask modification",
            "+        less_mask = tf.cast(tf.less(u, p_new), tf.int32)  # 0 when u is bigger than p, 1 when u is less than p",
            "condition_indices = tf.dynamic_partition(tf.range(tf.shape(p_new)[0]), less_mask,",
            "-                                                 2)  # 0 when u bigger",
            "-        #  than p, 1 when u less than p",
            "+                                                 2)  # 0 when u is bigger than p, 1 when u is less than p",
            "",
            "split_p_new = tf.dynamic_partition(p_new, less_mask, 2)",
            "split_u = tf.dynamic_partition(u, less_mask, 2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3536,
        "label": "no",
        "change": [
            "class ParallelDataProvider(data_provider.DataProvider):",
            "",
            "# Optionally shuffle the data",
            "if shuffle:",
            "-      shuffle_queue = data_flow_ops.RandomShuffleQueue(",
            "+      shuffle_queue = tf.RandomShuffleQueue(",
            "capacity=common_queue_capacity,",
            "min_after_dequeue=common_queue_min,",
            "dtypes=[tf.string, tf.string],",
            "seed=seed)",
            "enqueue_ops = []",
            "enqueue_ops.append(shuffle_queue.enqueue([data_source, data_target]))",
            "-      queue_runner.add_queue_runner(",
            "-          queue_runner.QueueRunner(shuffle_queue, enqueue_ops))",
            "+      tf.train.add_queue_runner(",
            "+          tf.train.QueueRunner(shuffle_queue, enqueue_ops))",
            "data_source, data_target = shuffle_queue.dequeue()",
            "",
            "# Decode source items"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3537,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "defs, block_func = cfg[DEPTH]",
            "",
            "with argscope(Conv2D, nl=tf.identity, use_bias=False,",
            "-                      W_init=tf.variance_scaling_initializer(scale=2.0, mode='FAN_OUT')), \\",
            "+                      W_init=tf.variance_scaling_initializer(scale=2.0, mode='fan_out')), \\",
            "argscope([Conv2D, MaxPooling, GlobalAvgPooling, BatchNorm], data_format='NCHW'):",
            "convmaps = (LinearWrap(image)",
            ".Conv2D('conv0', 64, 7, stride=2, nl=BNReLU)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3540,
        "label": "no",
        "change": [
            "class ProductionRuleField(Field[ProductionRuleArray]):  # type: ignore",
            "@overrides",
            "def as_tensor(self,",
            "padding_lengths: Dict[str, int],",
            "-                  cuda_device: int = -1,",
            "-                  for_training: bool = True) -> ProductionRuleArray:",
            "+                  cuda_device: int = -1) -> ProductionRuleArray:",
            "# pylint: disable=unused-argument",
            "if self.is_global_rule:",
            "-            tensor = Variable(torch.LongTensor([self._rule_id]), volatile=not for_training)",
            "+            tensor = torch.LongTensor([self._rule_id])",
            "else:",
            "tensor = None",
            "return (self.rule, self.is_global_rule, tensor)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3542,
        "label": "no",
        "change": [
            "class TexturesVertex(TexturesBase):",
            "\"\"\"",
            "if isinstance(verts_features, (tuple, list)):",
            "correct_shape = all(",
            "-                # pyre-fixme[16]: `Tensor` has no attribute `ndim`.",
            "-                (torch.is_tensor(v) and v.ndim == 2)",
            "-                for v in verts_features",
            "+                (torch.is_tensor(v) and v.ndim == 2) for v in verts_features",
            ")",
            "if not correct_shape:",
            "raise ValueError("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3544,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "if OUT_CH == 1:",
            "output = tf.image.grayscale_to_rgb(output)",
            "fake_output = tf.image.grayscale_to_rgb(fake_output)",
            "-        viz = (tf.concat(2, [input, output, fake_output]) + 1.0) * 128.0",
            "+        viz = (tf.concat_v2([input, output, fake_output], 2) + 1.0) * 128.0",
            "viz = tf.cast(tf.clip_by_value(viz, 0, 255), tf.uint8, name='viz')",
            "tf.summary.image('input,output,fake', viz, max_outputs=max(30, BATCH))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3546,
        "label": "no",
        "change": [
            "class DownloadManager(object):",
            "\"\"\"",
            "Ship the files using Beam FileSystems to the pipeline temp dir.",
            "\"\"\"",
            "-        from nlp.utils.beam_utils import upload_local_to_remote",
            "+        from datasets.utils.beam_utils import upload_local_to_remote",
            "",
            "remote_dir = pipeline._options.get_all_options().get(\"temp_location\")",
            "if remote_dir is None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3547,
        "label": "no",
        "change": [
            "class LightGCN(torch.nn.Module):",
            "self.reset_parameters()",
            "",
            "def reset_parameters(self):",
            "-        self.embedding.reset_parameters()",
            "+        torch.nn.init.xavier_uniform_(self.embedding.weight)",
            "for conv in self.convs:",
            "conv.reset_parameters()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3549,
        "label": "no",
        "change": [
            "class SACModel(TFModelV2):",
            "shift_and_log_scale_diag = tf.keras.Sequential([",
            "tf.keras.layers.Dense(",
            "units=hidden,",
            "-                activation=getattr(tf.nn, actor_hidden_activation),",
            "+                activation=getattr(tf.nn, actor_hidden_activation, None),",
            "name=\"action_hidden_{}\".format(i))",
            "for i, hidden in enumerate(actor_hiddens)",
            "] + ["
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3555,
        "label": "yes",
        "change": [
            "def _create(name, pretrained=True, channels=3, classes=80, autoshape=True, verbo",
            "cfg = list((Path(__file__).parent / 'models').rglob(f'{name}.yaml'))[0]  # model.yaml path",
            "model = Model(cfg, channels, classes)  # create model",
            "if pretrained:",
            "-                attempt_download(fname)  # download if not found locally",
            "-                ckpt = torch.load(fname, map_location=torch.device('cpu'))  # load",
            "+                ckpt = torch.load(attempt_download(fname), map_location=torch.device('cpu'))  # load",
            "msd = model.state_dict()  # model state_dict",
            "csd = ckpt['model'].float().state_dict()  # checkpoint state_dict as FP32",
            "csd = {k: v for k, v in csd.items() if msd[k].shape == v.shape}  # filter"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3556,
        "label": "no",
        "change": [
            "def convert_pandas_to_tf_tensor(",
            "# them. If the columns contain different types (for example, `float32`s",
            "# and `int32`s), then `tf.concat` raises an error.",
            "dtype: np.dtype = np.find_common_type(df.dtypes, [])",
            "-",
            "-            # if the columns are `ray.data.extensions.tensor_extension.TensorArray`,",
            "-            # the dtype will be `object`. In this case, we need to set the dtype to",
            "-            # none, and use the automatic type casting of `tf.convert_to_tensor`.",
            "-            if isinstance(dtype, object):",
            "-                dtype = None",
            "-",
            "except TypeError:",
            "# `find_common_type` fails if a series has `TensorDtype`. In this case,",
            "# don't cast any of the series and continue."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3557,
        "label": "no",
        "change": [
            "\"train_kwargs = {\\n\",",
            "\"    \\\"batch_size\\\": args[\\\"batch_size\\\"],\\n\",",
            "\"}\\n\",",
            "-    \"train_data_ptr = remote_torchvision.datasets.MNIST('../data', train=True, download=True, transform=transforms)\\n\",",
            "+    \"train_data_ptr = remote_torchvision.datasets.MNIST(str(get_root_data_path()), train=True, download=True, transform=transforms)\\n\",",
            "\"train_loader_ptr = remote_torch.utils.data.DataLoader(train_data_ptr,**train_kwargs)\"",
            "]",
            "},"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3558,
        "label": "no",
        "change": [
            "class GuidedAnchorHead(AnchorHead):",
            "bbox_deltas = bbox_anchors.new_full(bbox_anchors.size(), 0)",
            "bbox_deltas[:, 2:] += shape_pred",
            "# filter out negative samples to speed-up weighted_bounded_iou_loss",
            "-        inds = torch.nonzero(anchor_weights[:, 0] > 0).squeeze(1)",
            "+        inds = torch.nonzero(",
            "+            anchor_weights[:, 0] > 0, as_tuple=False).squeeze(1)",
            "bbox_deltas_ = bbox_deltas[inds]",
            "bbox_anchors_ = bbox_anchors[inds]",
            "bbox_gts_ = bbox_gts[inds]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3559,
        "label": "yes",
        "change": [
            "class Model(ModelDesc):",
            "# For visualization in tensorboard",
            "padded1 = tf.pad(sampled1, [[0, 0], [HALF_DIFF, HALF_DIFF], [HALF_DIFF, HALF_DIFF], [0, 0]])",
            "padded2 = tf.pad(sampled2, [[0, 0], [HALF_DIFF, HALF_DIFF], [HALF_DIFF, HALF_DIFF], [0, 0]])",
            "-        img_orig = tf.concat(1, [image[:, :, :, 0], image[:, :, :, 1]])  # b x 2h  x w",
            "-        transform1 = tf.concat(1, [padded1[:, :, :, 0], padded1[:, :, :, 1]])",
            "-        transform2 = tf.concat(1, [padded2[:, :, :, 0], padded2[:, :, :, 1]])",
            "-        stacked = tf.concat(2, [img_orig, transform1, transform2], 'viz')",
            "+        img_orig = tf.concat_v2([image[:, :, :, 0], image[:, :, :, 1]], 1)  # b x 2h  x w",
            "+        transform1 = tf.concat_v2([padded1[:, :, :, 0], padded1[:, :, :, 1]], 1)",
            "+        transform2 = tf.concat_v2([padded2[:, :, :, 0], padded2[:, :, :, 1]], 1)",
            "+        stacked = tf.concat_v2([img_orig, transform1, transform2], 2, 'viz')",
            "tf.summary.image('visualize',",
            "tf.expand_dims(stacked, -1), max_images=30)",
            "",
            "-        sampled = tf.concat(3, [sampled1, sampled2], 'sampled_concat')",
            "+        sampled = tf.concat_v2([sampled1, sampled2], 3, 'sampled_concat')",
            "logits = (LinearWrap(sampled)",
            ".apply(symbf.batch_flatten)",
            ".FullyConnected('fc1', out_dim=256, nl=tf.nn.relu)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3560,
        "label": "no",
        "change": [
            "class LengthBonus(ScorerInterface):",
            "self.n = n_vocab",
            "",
            "def score(self, y, state, x):",
            "-        return torch.tensor([1.0], device=y.device).expand(self.n), None",
            "+        return torch.tensor([1.0], device=x.device, dtype=x.dtype).expand(self.n), None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3564,
        "label": "no",
        "change": [
            "def _plot_and_save_attention(att_w, filename):",
            "",
            "",
            "def plot_multi_head_attention(data, attn_dict, outdir, suffix=\"png\"):",
            "+    \"\"\"Plot multi head attentions",
            "+",
            "+    :param dict data: utts info from json file",
            "+    :param dict[str, torch.Tensor] attn_dict: multi head attention dict.",
            "+        values should be torch.Tensor (head, input_length, output_length)",
            "+    :param str outdir: dir to save fig",
            "+    :param str suffix: filename suffix including image type (e.g., png)",
            "+    \"\"\"",
            "for name, att_ws in attn_dict.items():",
            "for idx, att_w in enumerate(att_ws):",
            "filename = \"%s/%s.%s.%s\" % ("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3565,
        "label": "no",
        "change": [
            "class AucTest(AllenNlpTestCase):",
            "",
            "predictions = torch.randn(8, device=device)",
            "labels = torch.randint(0, 2, (8,), dtype=torch.long, device=device)",
            "-        mask = torch.tensor([1, 1, 1, 1, 0, 0, 0, 0], dtype=torch.uint8, device=device)",
            "+        mask = torch.BoolTensor([True, True, True, True, False, False, False, False], device=device)",
            "",
            "auc(predictions, labels, mask)",
            "computed_auc_value = auc.get_metric(reset=True)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3567,
        "label": "yes",
        "change": [
            "def BatchNorm(x, use_local_stat=None, decay=0.9, epsilon=1e-5):",
            "",
            "n_out = shape[-1]  # channel",
            "assert n_out is not None",
            "-    beta = tf.get_variable('beta', [n_out])",
            "+    beta = tf.get_variable('beta', [n_out],",
            "+            initializer=tf.zeros_initializer)",
            "gamma = tf.get_variable('gamma', [n_out],",
            "-        initializer=tf.ones_initializer)",
            "+            initializer=tf.ones_initializer)",
            "",
            "if len(shape) == 2:",
            "batch_mean, batch_var = tf.nn.moments(x, [0], keep_dims=False)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 3568,
        "label": "no",
        "change": [
            "def recog(args):",
            "with open(args.recog_json, 'rb') as f:",
            "recog_json = json.load(f)['utts']",
            "",
            "+    if not torch_is_old:",
            "+        torch.set_grad_enabled(False)",
            "+",
            "new_json = {}",
            "for name in recog_json.keys():",
            "feat = kaldi_io_py.read_mat(recog_json[name]['input'][0]['feat'])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3569,
        "label": "yes",
        "change": [
            "def densenet_block(incoming, nb_layers, growth, bottleneck=True,",
            "\"\"\"",
            "densenet = incoming",
            "",
            "-    for i in range(nb_layers):",
            "+    with tf.variable_scope(scope, default_name=name, values=[incoming],",
            "+                           reuse=reuse) as scope:",
            "",
            "-        with tf.variable_scope(scope, default_name=name, values=[incoming],",
            "-                               reuse=reuse) as scope:",
            "+        for i in range(nb_layers):",
            "",
            "# Identity",
            "conn = densenet"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3570,
        "label": "no",
        "change": [
            "class LSTMWrapper(RecurrentNetwork, nn.Module):",
            "wrapped_out,",
            "torch.reshape(input_dict[SampleBatch.PREV_ACTIONS].float(),",
            "[-1, self.action_dim]),",
            "-                    torch.reshape(input_dict[SampleBatch.PREV_REWARDS],",
            "+                    torch.reshape(input_dict[SampleBatch.PREV_REWARDS].float(),",
            "[-1, 1]),",
            "],",
            "dim=1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3571,
        "label": "no",
        "change": [
            "class KerasTests(tf.test.TestCase):",
            "new_opt = new_model.optimizer",
            "os.remove(fname)",
            "",
            "-            self.assertEqual(type(new_opt).__module__, 'horovod.keras')",
            "+            self.assertEqual(type(new_opt).__module__, 'horovod.keras.impl')",
            "self.assertEqual(type(new_opt).__name__, 'TestOptimizer')",
            "self.assertEqual(K.get_value(opt.lr), K.get_value(new_opt.lr))",
            "self.assertEqual(len(opt.get_weights()), len(new_opt.get_weights()))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3572,
        "label": "no",
        "change": [
            "def stacked_cnn(units: tf.Tensor,",
            "padding='same',",
            "dilation_rate=dilation_rate,",
            "kernel_initializer=INITIALIZER(),",
            "-                                 kernel_regularizer=tf.nn.l2_loss)",
            "+                                 kernel_regularizer=l2_reg)",
            "if use_batch_norm:",
            "assert training_ph is not None",
            "units = tf.layers.batch_normalization(units, training=training_ph)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3573,
        "label": "yes",
        "change": [
            "class BertForQuestionAnswering(nn.Module):",
            "def compute_loss(logits, positions):",
            "max_position = positions.max().item()",
            "one_hot = torch.FloatTensor(batch_size, max(max_position, seq_length) +1, device=input_ids.device).zero_()",
            "-                one_hot = one_hot.scatter(1, positions, 1)",
            "+                one_hot = one_hot.scatter(1, positions.cpu(), 1) # Second argument need to be LongTensor and not cuda.LongTensor",
            "one_hot = one_hot[:, :seq_length]",
            "log_probs = nn.functional.log_softmax(logits, dim = -1).view(batch_size, seq_length)",
            "loss = -torch.mean(torch.sum(one_hot*log_probs), dim = -1)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 3574,
        "label": "no",
        "change": [
            "class TestChainTensor(TestCase):",
            "x.get()",
            "x.child = x.child.child",
            "",
            "-        # target = sy._PlusIsMinusTensor().on(torch.FloatTensor([1, 1]))",
            "-        target = torch.FloatTensor([1, 1])",
            "+        target = sy._PlusIsMinusTensor().on(torch.FloatTensor([1, 1]))",
            "+        # target = torch.FloatTensor([1, 1])",
            "assert torch.equal(x.grad.data, target)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3575,
        "label": "no",
        "change": [
            "class MultibandMelganGenerator(MelganGenerator):",
            "def pqmf_synthesis(self, x):",
            "return self.pqmf_layer.synthesis(x)",
            "",
            "+    @torch.no_grad()",
            "def inference(self, cond_features):",
            "cond_features = cond_features.to(self.layers[1].weight.device)",
            "cond_features = torch.nn.functional.pad(",
            "cond_features,",
            "(self.inference_padding, self.inference_padding),",
            "'replicate')",
            "-        return self.pqmf.synthesis(self.layers(cond_features))",
            "+        return self.pqmf_synthesis(self.layers(cond_features))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3576,
        "label": "no",
        "change": [
            "class PatchDominantGradientOrientation(nn.Module):",
            "self.num_ang_bins = num_angular_bins",
            "self.gradient = SpatialGradient('sobel', 1)",
            "self.eps = eps",
            "-        self.angular_smooth = nn.Conv1d(1, 1, kernel_size=3, padding=2, bias=False, padding_mode=\"circular\")",
            "+        self.angular_smooth = nn.Conv1d(1, 1, kernel_size=3, padding=1, bias=False, padding_mode=\"circular\")",
            "with torch.no_grad():",
            "self.angular_smooth.weight[:] = torch.tensor([[[0.33, 0.34, 0.33]]])",
            "sigma: float = float(self.patch_size) / math.sqrt(2.0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3577,
        "label": "no",
        "change": [
            "def build_targets(p, targets, model):",
            "# Build targets for compute_loss(), input targets(image_idx,class,x,y,w,h)",
            "nt = targets.shape[0]",
            "tcls, tbox, indices, anch = [], [], [], []",
            "-    gain = torch.ones(6, device=targets.device)  # normalized to gridspace gain",
            "+    gain = torch.ones(6, device=targets.device).long()  # normalized to gridspace gain",
            "",
            "multi_gpu = type(model) in (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel)",
            "for i, j in enumerate(model.yolo_layers):  # j: [89, 101, 113]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3578,
        "label": "no",
        "change": [
            "class LightconvLayer(nn.Module):",
            "weight = weight.view(1, H, K).expand(T*B, H, K).contiguous().view(T*B*H, K, 1)",
            "",
            "weight = F.dropout(weight, self.weight_dropout, training=self.training)",
            "-            output = torch.bmm(x_unfold, weight) # T*B*H x R x 1",
            "+            output = torch.bmm(x_unfold, weight)  # T*B*H x R x 1",
            "output = output.view(T, B, C)",
            "return output"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3585,
        "label": "yes",
        "change": [
            "class CrossViT(nn.Module):",
            "",
            "# NOTE: was before branch token section, move to here to assure all branch token are before layer norm",
            "xs = [norm(xs[i]) for i, norm in enumerate(self.norm)]",
            "-        return [xo[:, 0] for xo in xs]",
            "+        return xs",
            "",
            "def forward(self, x):",
            "xs = self.forward_features(x)",
            "-        ce_logits = [head(xs[i]) for i, head in enumerate(self.head)]",
            "+        ce_logits = [head(xs[i][:, 0]) for i, head in enumerate(self.head)]",
            "if not isinstance(self.head[0], nn.Identity):",
            "ce_logits = torch.mean(torch.stack(ce_logits, dim=0), dim=0)",
            "return ce_logits"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 3587,
        "label": "no",
        "change": [
            "def testtanh():",
            "3.3883e02,",
            "]",
            ")",
            "-",
            "-    #allclose function to compare the expected values and approximations with fixed precision",
            "-    assert torch.allclose(expected, Ptensor.tanh(x),1e-03)",
            "",
            "+    # allclose function to compare the expected values and approximations with fixed precision",
            "+    assert torch.allclose(expected, Ptensor.tanh(x), 1e-03)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3589,
        "label": "no",
        "change": [
            "class GPTNeoForCausalLM(GPTNeoPreTrainedModel):",
            "\"\"\"",
            "return tuple(",
            "tuple(past_state.index_select(0, beam_idx.to(past_state.device)) for past_state in layer_past)",
            "-            for layer_past in past",
            "+            for layer_past in past_key_values",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3593,
        "label": "no",
        "change": [
            "class ScalarMix(torch.nn.Module):",
            "variance = (",
            "torch.sum(((tensor_masked - mean) * broadcast_mask) ** 2) / num_elements_not_masked",
            ")",
            "-            return (tensor - mean) / torch.sqrt(variance + 1e-12)",
            "+            return (tensor - mean) / torch.sqrt(variance + util.tiny_value_of_dtype(variance.dtype))",
            "",
            "normed_weights = torch.nn.functional.softmax(",
            "torch.cat([parameter for parameter in self.scalar_parameters]), dim=0"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3598,
        "label": "yes",
        "change": [
            "def coalesce(edge_index, edge_attr=None, num_nodes=None):",
            "_, perm = unique(index)",
            "edge_index = edge_index[:, perm]",
            "else:",
            "-        sparse = getattr(torch.sparse, edge_attr.type().split('.')[-1])",
            "+        t = torch.cuda if edge_attr.is_cuda else torch",
            "+        sparse = getattr(t.sparse, edge_attr.type().split('.')[-1])",
            "n = num_nodes",
            "size = torch.Size([n, n] + list(edge_attr.size())[1:])",
            "adj = sparse(edge_index, edge_attr, size).coalesce()"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3599,
        "label": "no",
        "change": [
            "def fpn_classifier_graph(rois, feature_maps,",
            "name=\"mrcnn_class_conv1\")(x)",
            "x = KL.TimeDistributed(BatchNorm(axis=3), name='mrcnn_class_bn1')(x)",
            "x = KL.Activation('relu')(x)",
            "-    # x = KL.Dropout(0.5)(x)",
            "x = KL.TimeDistributed(KL.Conv2D(1024, (1, 1)),",
            "name=\"mrcnn_class_conv2\")(x)",
            "x = KL.TimeDistributed(BatchNorm(axis=3),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3600,
        "label": "no",
        "change": [
            "import torch",
            "from packaging import version",
            "",
            "if version.parse(torch.__version__) > version.parse(\"1.7.1\"):",
            "-    from torch.linalg import solve",
            "+    # TODO: remove the type: ignore once Python 3.6 is deprecated.",
            "+    # It turns out that Pytorch has no attribute `torch.linalg` for",
            "+    # Python 3.6 / PyTorch 1.7.0, 1.7.1",
            "+    from torch.linalg import solve  # type: ignore",
            "else:",
            "from torch import solve as _solve"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3603,
        "label": "no",
        "change": [
            "class ExportTokenEmbeddingTest(tf.test.TestCase):",
            "",
            "if __name__ == \"__main__\":",
            "# This test is only supported in TF 2.0+.",
            "-  if LooseVersion(tf.__version__) >= LooseVersion(\"2.0.0-beta0\"):",
            "+  if tf.executing_eagerly():",
            "logging.info(\"Using TF version: %s\", tf.__version__)",
            "tf.test.main()",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3604,
        "label": "no",
        "change": [
            "def test_load_no_dev_data_explicit(tasks_base_path):",
            "",
            "",
            "def test_multi_corpus(tasks_base_path):",
            "-    corpus_1 = flair.datasets.ColumnCorpus(tasks_base_path / \"germeval_14\", column_format={0: \"text\", 2: \"ner\"})",
            "+    corpus_1 = flair.datasets.ColumnCorpus(tasks_base_path / \"ner_german_germeval\", column_format={0: \"text\", 2: \"ner\"})",
            "",
            "corpus_2 = flair.datasets.ColumnCorpus(tasks_base_path / \"fashion\", column_format={0: \"text\", 2: \"ner\"})",
            "# get two corpora as one"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3607,
        "label": "no",
        "change": [
            "class FairSeqWav2Vec2Encoder(AbsEncoder):",
            "logging.info(\"Start fine-tuning wav2vec parameters!\")",
            "",
            "with torch.no_grad() if not ft else contextlib.nullcontext():",
            "-            enc_outputs = self.encoders(",
            "-                xs_pad,",
            "-                masks,",
            "-                features_only=True,",
            "-            )",
            "+            enc_outputs = self.encoders(xs_pad, masks, features_only=True)",
            "",
            "xs_pad = enc_outputs[\"x\"]  # (B,T,C),",
            "masks = enc_outputs[\"padding_mask\"]  # (B, T)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3609,
        "label": "no",
        "change": [
            "class BertEncoder(tf.keras.layers.Layer):",
            "position_embeddings = self._position_embedding_layer(word_embeddings)",
            "type_embeddings = self._type_embedding_layer(type_ids)",
            "",
            "-        embeddings = self._add([word_embeddings, position_embeddings, type_embeddings])",
            "+        embeddings = self._add(",
            "+            [word_embeddings, position_embeddings, type_embeddings]",
            "+        )",
            "",
            "embeddings = self._layer_norm(embeddings)",
            "embeddings = self._dropout(embeddings)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3614,
        "label": "no",
        "change": [
            "class GraphVarParam(HyperParam):",
            "",
            "def setup_graph(self):",
            "\"\"\" Will setup the assign operator for that variable. \"\"\"",
            "-        all_vars = tf.global_variables()",
            "+        all_vars = tf.all_variables()",
            "for v in all_vars:",
            "if v.name == self.var_name:",
            "self.var = v"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3615,
        "label": "no",
        "change": [
            "class GroupNorm(Layer):",
            "channels = inputs_shape[-1]",
            "self.int_shape = tf.concat(",
            "[#tf.shape(input=self.inputs)[0:3],",
            "-                inputs_shape[0:3]",
            "-                 tf.convert_to_tensor(value=[self.groups, channels // self.groups])], axis=0",
            "+                inputs_shape[0:3],",
            "+                tf.convert_to_tensor(value=[self.groups, channels // self.groups])], axis=0",
            ")",
            "elif self.data_format == 'channels_first':",
            "channels = shape[1]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3616,
        "label": "yes",
        "change": [
            "def md5sum(filename):",
            "",
            "",
            "def switch_mps_device(model_name, device):",
            "-    if model_name not in MPS_SUPPORT_MODELS and (",
            "-        device == \"mps\" or device == torch.device(\"mps\")",
            "-    ):",
            "+    if model_name not in MPS_SUPPORT_MODELS and str(device) == \"mps\":",
            "logger.info(f\"{model_name} not support mps, switch to cpu\")",
            "return torch.device(\"cpu\")",
            "return device"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 3619,
        "label": "no",
        "change": [
            "class Autotuner:",
            "return False",
            "",
            "def get_gpu_memory_info(self):",
            "-        return torch.cuda.get_device_properties(0).total_memory",
            "+        return get_accelerator().total_memory()",
            "",
            "def get_activation_memory_per_gpu(self):",
            "if self.model_info and \"activation_mem_per_gpu\" in self.model_info:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3621,
        "label": "no",
        "change": [
            "class Set(Data):",
            "target = self.target[s1[i]:s1[i + 1]]",
            "else:",
            "target = self.target[i]",
            "-            target = target.view(1, -1).squeeze(1)",
            "+",
            "+            if torch.is_tensor(target):",
            "+                target = target.view(1, -1).squeeze(1)",
            "",
            "return Data(input, pos, index, weight, target)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3623,
        "label": "yes",
        "change": [
            "class ImagePreprocessingPass(unittest.TestCase):",
            "x4 = mb.add(x=x1, y=x3)",
            "return mb.relu(x=x4)",
            "",
            "-        proto = converter._convert(prog, inputs=[ImageType(name=\"x\", shape=(10, 20, 30, 3), channel_first=False)], convert_from=\"mil\", convert_to=\"nn_proto\")",
            "-        model = models.MLModel(proto)",
            "-        assert model is not None",
            "-        assert len(model._spec.neuralNetwork.layers) == 3",
            "+        mlmodel = ct.convert(prog,",
            "+            inputs=[ImageType(name=\"x\", shape=(10, 20, 30, 3),",
            "+              channel_first=False)],",
            "+            source=\"mil\", convert_to=\"nn_proto\")",
            "+        assert mlmodel is not None",
            "+        assert len(mlmodel.get_spec().neuralNetwork.layers) == 3"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3629,
        "label": "no",
        "change": [
            "class CheckGradient(MapGradient):",
            "",
            "def _mapper(self, grad, var):",
            "# this is very slow.... see #3649",
            "-        #op = tf.Assert(tf.reduce_all(tf.is_finite(var)), [var], summarize=100)",
            "+        # op = tf.Assert(tf.reduce_all(tf.is_finite(var)), [var], summarize=100)",
            "grad = tf.check_numerics(grad, 'CheckGradient-' + var.op.name)",
            "return grad"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3631,
        "label": "no",
        "change": [
            "def test_categorical_crossentropy(",
            "native_array,",
            "fw,",
            "):",
            "-    y_true = ivy.array(y_true, dtype = ivy.float32)",
            "+    y_true = ivy.array(y_true, dtype=ivy.float32)",
            "dtype, y_pred = dtype_y_pred",
            "",
            "# Perform softmax on prediction if it's not a probability distribution."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3633,
        "label": "yes",
        "change": [
            "def add_dataset_args(parser, train=False, gen=False):",
            "return group",
            "",
            "",
            "-def add_distributed_training_args(parser):",
            "+def add_distributed_training_args(parser, default_world_size=None):",
            "group = parser.add_argument_group(\"Distributed training\")",
            "# fmt: off",
            "+    if default_world_size is None:",
            "+        default_world_size = max(1, torch.cuda.device_count())",
            "group.add_argument('--distributed-world-size', type=int, metavar='N',",
            "-                       default=max(1, torch.cuda.device_count()),",
            "+                       default=default_world_size,",
            "help='total number of GPUs across all nodes (default: all visible GPUs)')",
            "group.add_argument('--distributed-rank', default=0, type=int,",
            "help='rank of the current worker')"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 3634,
        "label": "no",
        "change": [
            "def install_openvino(with_optimization: bool = True):",
            "\"\"\"Helper function for installing the OpenVino compiler.",
            "",
            "This function just works on intel machines.",
            "+",
            "+    Args:",
            "+        with_optimization (bool): Flag for installing the full openvino engine",
            "+            or limiting the installation to the tools need for inference",
            "+            models.",
            "\"\"\"",
            "processor = cpuinfo.get_cpu_info()[\"brand_raw\"].lower()",
            "if \"intel\" not in processor:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3635,
        "label": "no",
        "change": [
            "class DocumentLSTMEmbeddings(DocumentEmbeddings):",
            "for add in range(longest_token_sequence_in_batch - len(sentence.tokens)):",
            "word_embeddings.append(",
            "torch.zeros(self.length_of_all_token_embeddings,",
            "-                                dtype=torch.float, device=flair.device).unsqueeze(0)",
            "+                                dtype=torch.float).unsqueeze(0)",
            ")",
            "",
            "-            word_embeddings_tensor = torch.cat(word_embeddings, 0)",
            "+            word_embeddings_tensor = torch.cat(word_embeddings, 0).to(flair.device)",
            "",
            "sentence_states = word_embeddings_tensor"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3638,
        "label": "no",
        "change": [
            "def compute_correspond_epilines(points: torch.Tensor, F_mat: torch.Tensor) -> to",
            "if not (len(F_mat.shape) == 3 and F_mat.shape[-2:] == (3, 3)):",
            "raise AssertionError(F_mat.shape)",
            "",
            "-    points_h: torch.Tensor = kornia.convert_points_to_homogeneous(points)",
            "+    points_h: torch.Tensor = convert_points_to_homogeneous(points)",
            "",
            "# project points and retrieve lines components",
            "a, b, c = torch.chunk(F_mat @ points_h.permute(0, 2, 1), dim=1, chunks=3)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3641,
        "label": "no",
        "change": [
            "class MultiHeadSelfAttention(nn.Module):",
            "q = q / math.sqrt(dim_per_head)  # (bs, n_heads, q_length, dim_per_head)",
            "scores = torch.matmul(q, k.transpose(2, 3))  # (bs, n_heads, q_length, k_length)",
            "mask = (mask == 0).view(mask_reshp).expand_as(scores)  # (bs, n_heads, q_length, k_length)",
            "-        scores = scores.masked_fill(mask, torch.tensor(-float(\"inf\")))  # (bs, n_heads, q_length, k_length)",
            "+        scores = scores.masked_fill(",
            "+            mask, torch.tensor(torch.finfo(scores.dtype).min)",
            "+        )  # (bs, n_heads, q_length, k_length)",
            "",
            "weights = nn.functional.softmax(scores, dim=-1)  # (bs, n_heads, q_length, k_length)",
            "weights = self.dropout(weights)  # (bs, n_heads, q_length, k_length)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3643,
        "label": "no",
        "change": [
            "class CatsVsDogs(datasets.GeneratorBasedBuilder):",
            "if b\"JFIF\" in f.peek(10):",
            "yield str(i), {",
            "\"image_file_path\": str(filepath),",
            "+                        \"image\": str(filepath),",
            "\"labels\": filepath.parent.name.lower(),",
            "}",
            "continue"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3644,
        "label": "no",
        "change": [
            "class Attention(nn.Module):",
            "",
            "def fill_with_neg_inf(t):",
            "\"\"\"FP16-compatible function that fills a input_ids with -inf.\"\"\"",
            "-    return t.float().fill_(float(\"-inf\")).type_as(t)",
            "+    return t.float().fill_(torch.finfo(t.dtype).min).type_as(t)",
            "",
            "",
            "# Public API"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3647,
        "label": "no",
        "change": [
            "def deploy(config,",
            "",
            "if total_loss is not None:",
            "# Add total_loss to summary.",
            "-      summaries.add(tf.summary.scalar('total_loss', total_loss,",
            "-                                      name='total_loss'))",
            "+      summaries.add(tf.summary.scalar('total_loss', total_loss))",
            "",
            "if summaries:",
            "# Merge all summaries together."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3649,
        "label": "no",
        "change": [
            "def _load_ply(f, *, path_manager: PathManager) -> _PlyData:",
            "if face.shape[1] < 3:",
            "raise ValueError(\"Faces must have at least 3 vertices.\")",
            "face_arrays = [face[:, [0, i + 1, i + 2]] for i in range(face.shape[1] - 2)]",
            "-        faces = torch.LongTensor(np.vstack(face_arrays))",
            "+        faces = torch.LongTensor(np.vstack(face_arrays).astype(np.int64))",
            "else:",
            "face_list = []",
            "for face_item in face:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3652,
        "label": "no",
        "change": [
            "class TFModel(NNModel, metaclass=TfModelMeta):",
            "variables_to_train.extend(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope_name))",
            "",
            "if optimizer is None:",
            "-                optimizer = tf.train.AdamOptimizer",
            "+                optimizer = tf.train.AdamOptimizer(learning_rate)",
            "",
            "# For batch norm it is necessary to update running averages",
            "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3658,
        "label": "no",
        "change": [
            "class PatchEmbed(nn.Module):",
            "",
            "def forward(self, x):",
            "B, C, H, W = x.shape",
            "-        torch._assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model {self.img_size[0]}.\")",
            "-        torch._assert(W == self.img_size[1], f\"Input image width ({W}) doesn't match model ({self.img_size[1]}.\")",
            "+        torch._assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")",
            "+        torch._assert(W == self.img_size[1], f\"Input image width ({W}) doesn't match model ({self.img_size[1]}).\")",
            "x = self.proj(x)",
            "if self.flatten:",
            "x = x.flatten(2).transpose(1, 2)  # BCHW -> BNC"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3659,
        "label": "no",
        "change": [
            "class TestJitSequenceGeneratorBase(unittest.TestCase):",
            "JIT_MSG = \"Targeting OSS scriptability for the 1.6 release\"",
            "",
            "",
            "-@unittest.skipIf(torch.__version__ < \"1.6.0\", JIT_MSG)",
            "+@unittest.skipIf(",
            "+    version_check(), \"Targeting OSS scriptability for the 1.13.0.dev20220613 release\"",
            "+)",
            "class TestJitSequenceGenerator(TestJitSequenceGeneratorBase):",
            "def test_export_transformer(self):",
            "model = self.transformer_model"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3660,
        "label": "yes",
        "change": [
            "class OpenSlr(datasets.GeneratorBasedBuilder):",
            "# set absolute path for audio file",
            "path = os.path.join(path_to_datas[i], f\"{filename}.wav\")",
            "counter += 1",
            "-                        yield counter, {\"path\": path, \"sentence\": sentence}",
            "+                        yield counter, {\"path\": path, \"audio\": path, \"sentence\": sentence}"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 3662,
        "label": "yes",
        "change": [
            "def find_homography_dlt(",
            "U, S, V = torch.svd(A)",
            "except:",
            "warnings.warn('SVD did not converge', RuntimeWarning)",
            "-        return torch.empty((points1_norm.size(0), 3, 3), device=points1.device)",
            "+        return torch.empty((points1_norm.size(0), 3, 3), device=device, dtype=dtype)",
            "",
            "H = V[..., -1].view(-1, 3, 3)",
            "H = transform2.inverse() @ (H @ transform1)"
        ],
        "comments": "",
        "Symptom": "return warning",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 3665,
        "label": "no",
        "change": [
            "def test_inputs(framework: str | None) -> list[tuple[ModuleType, FrameworkTestMo",
            ")",
            ")",
            "except ModuleNotFoundError as e:",
            "-            raise ModuleNotFoundError(",
            "-                f\"Failed to find test module for framework {framework_name} (tests.integration.frameworks.models.{framework_name})\"",
            "-            ) from e",
            "+            logger.warning(f\"Failed to find test module for framework {framework_name} (tests.integration.frameworks.models.{framework_name})\")",
            "",
            "return [",
            "(module.framework, _model)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3667,
        "label": "no",
        "change": [
            "class MixConv2d(nn.Module):",
            "a[0] = 1",
            "c_ = np.linalg.lstsq(a, b, rcond=None)[0].round()  # solve for equal weight indices, ax = b",
            "",
            "-        self.m = nn.ModuleList(",
            "-            [nn.Conv2d(c1, int(c_), k, s, k // 2, groups=math.gcd(c1, int(c_)), bias=False) for k, c_ in zip(k, c_)])",
            "+        self.m = nn.ModuleList([",
            "+            nn.Conv2d(c1, int(c_), k, s, k // 2, groups=math.gcd(c1, int(c_)), bias=False) for k, c_ in zip(k, c_)])",
            "self.bn = nn.BatchNorm2d(c2)",
            "self.act = nn.SiLU()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3668,
        "label": "no",
        "change": [
            "class YOLOXHead(BaseDenseHead, BBoxTestMixin):",
            "if self.use_l1:",
            "l1_target = self._get_l1_target(l1_target, bbox_target,",
            "priors[pos_inds])",
            "-        foreground_mask = torch.zeros_like(objectness).to(torch.uint8)",
            "+        foreground_mask = torch.zeros_like(objectness).to(torch.bool)",
            "foreground_mask[pos_inds] = 1",
            "return (foreground_mask, cls_target, obj_target, bbox_target,",
            "l1_target, num_pos_per_img)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3673,
        "label": "no",
        "change": [
            "class XSoftmax(torch.autograd.Function):",
            ">>> from transformers.models.deberta_v2.modeling_deberta_v2 import XSoftmax",
            "",
            ">>> # Make a tensor",
            "-    >>> x = torch.randn([4,20,100])",
            "+    >>> x = torch.randn([4, 20, 100])",
            "",
            ">>> # Create a mask",
            "-    >>> mask = (x>0).int()",
            "+    >>> mask = (x > 0).int()",
            "",
            ">>> # Specify the dimension to apply softmax",
            ">>> dim = -1"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3674,
        "label": "no",
        "change": [
            "class MultivariateStudentT(TorchDistribution):",
            "def __init__(self, df, loc, scale_tril, validate_args=None):",
            "dim = loc.size(-1)",
            "assert scale_tril.shape[-2:] == (dim, dim)",
            "-        df, = broadcast_all(df)",
            "+        if not isinstance(df, torch.Tensor):",
            "+            df = loc.new_tensor(df)",
            "batch_shape = broadcast_shape(df.shape, loc.shape[:-1], scale_tril.shape[:-2])",
            "event_shape = (dim,)",
            "self.df = df.expand(batch_shape)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3675,
        "label": "no",
        "change": [
            "def nanmean(",
            "dtype: Optional[torch.dtype] = None,",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "-    return torch.nanmean(a, axis=axis, keepdim=keepdims, dtype=dtype, out=out)",
            "+    return torch.nanmean(a, dim=axis, keepdim=keepdims, dtype=dtype, out=out)",
            "",
            "",
            "nanmean_support_native_out = True"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3676,
        "label": "no",
        "change": [
            "argmax = tf.argmax",
            "tensor = tf.constant",
            "arange = tf.range",
            "astype = tf.cast",
            "+int32 = tf.int32",
            "+float32 = tf.float32",
            "numpy = lambda x, *args, **kwargs: x.numpy(*args, **kwargs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3681,
        "label": "no",
        "change": [
            "def multihead_attention(queries,",
            "outputs = tf.nn.softmax(outputs) # (h*N, T_q, T_k)",
            "",
            "# Query Masking",
            "-        query_masks = tf.sign(tf.abs(tf.reduce_sum(queries, axis=-1))) # (N, T_q)",
            "+        query_masks = tf.sign(tf.reduce_sum(tf.abs(queries), axis=-1)) # (N, T_q)",
            "query_masks = tf.tile(query_masks, [num_heads, 1]) # (h*N, T_q)",
            "query_masks = tf.tile(tf.expand_dims(query_masks, -1), [1, 1, tf.shape(keys)[1]]) # (h*N, T_q, T_k)",
            "outputs *= query_masks # broadcasting. (N, T_q, C)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3684,
        "label": "no",
        "change": [
            "class TestStackedSelfAttention(AllenNlpTestCase):",
            "",
            "def test_pass_through_encoder_passes_through(self):",
            "encoder = PassThroughEncoder(input_dim=9)",
            "-        tensor = Variable(torch.randn([2, 3, 9]))",
            "+        tensor = torch.randn([2, 3, 9])",
            "output = encoder(tensor)",
            "-        numpy.testing.assert_array_almost_equal(tensor.data.cpu().numpy(),",
            "-                                                output.data.cpu().numpy())",
            "+        numpy.testing.assert_array_almost_equal(tensor.detach().cpu().numpy(),",
            "+                                                output.detach().cpu().numpy())"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3686,
        "label": "yes",
        "change": [
            "class ESPnetASRMixModel(AbsESPnetModel):",
            "ignore_label=self.ignore_id,",
            ")",
            ")",
            "-        loss_att = torch.mean(loss_att)",
            "+        loss_att = torch.stack(loss_att, dim=0).mean()",
            "acc_att = np.mean(acc_att)",
            "",
            "# Compute cer/wer using attention-decoder"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3688,
        "label": "no",
        "change": [
            "class TestTRPOAgent(unittest.TestCase):",
            "def test_trpo_agent(self):",
            "config = {",
            "'batch_size': 8,",
            "+            \"cg_iterations\": 20,",
            "+            \"cg_damping\": 0.001,",
            "+            \"line_search_steps\": 20,",
            "'max_kl_divergence': 0.01,",
            "'max_episode_length': 4,",
            "'continuous': False,",
            "'state_shape': (2,),",
            "'actions': 2}",
            "+        tf.reset_default_graph()",
            "",
            "config = create_config(config)",
            "network_builder = NeuralNetwork.layered_network(layers=[{'type': 'dense', 'num_outputs': 32}])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3690,
        "label": "no",
        "change": [
            "def itergroups(items, group_size):",
            "def batched_weighted_sum(weights, vecs, batch_size):",
            "total = 0",
            "num_items_summed = 0",
            "-    for batch_weights, batch_vecs in zip(itergroups(weights, batch_size),",
            "-                                         itergroups(vecs, batch_size)):",
            "+    for batch_weights, batch_vecs in zip(",
            "+            itergroups(weights, batch_size), itergroups(vecs, batch_size)):",
            "assert len(batch_weights) == len(batch_vecs) <= batch_size",
            "-        total += np.dot(np.asarray(batch_weights, dtype=np.float32),",
            "-                        np.asarray(batch_vecs, dtype=np.float32))",
            "+        total += np.dot(",
            "+            np.asarray(batch_weights, dtype=np.float32),",
            "+            np.asarray(batch_vecs, dtype=np.float32))",
            "num_items_summed += len(batch_weights)",
            "return total, num_items_summed"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3692,
        "label": "no",
        "change": [
            "class Layer_Recurrent_Test(unittest.TestCase):",
            "dropout=None, n_layer=2, return_seq_2d=True, name='Seq2seq'",
            ")",
            "",
            "-        net11 = tl.layers.DenseLayer(net11, n_units=10000, act=tf.identity, name='oo')",
            "+        net11 = tl.layers.DenseLayer(net11, n_units=10000, name='oo')",
            "",
            "# e_loss = tl.cost.cross_entropy_seq_with_mask(logits=net11.outputs, target_seqs=target_seqs, input_mask=target_mask, return_details=False, name='cost')",
            "# y = tf.nn.softmax(net11.outputs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3693,
        "label": "no",
        "change": [
            "class RagConfig(PretrainedConfig):",
            "decoder_config = kwargs.pop(\"generator\")",
            "decoder_model_type = decoder_config.pop(\"model_type\")",
            "",
            "-        from .configuration_auto import AutoConfig",
            "+        from ..auto.configuration_auto import AutoConfig",
            "",
            "self.question_encoder = AutoConfig.for_model(question_encoder_model_type, **question_encoder_config)",
            "self.generator = AutoConfig.for_model(decoder_model_type, **decoder_config)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3695,
        "label": "no",
        "change": [
            "class RNNLM(nn.Module):",
            "emb = self.embed(x)",
            "h[0], c[0] = self.lstm[0](self.dropout[0](emb), (state['h'][0], state['c'][0]))",
            "for n in six.moves.range(1, self.n_layers):",
            "-            h[n], c[n] = self.lstm[n](self.dropout[n](h[n-1]), (state['h'][n], state['c'][n]))",
            "+            h[n], c[n] = self.lstm[n](self.dropout[n](h[n - 1]), (state['h'][n], state['c'][n]))",
            "y = self.lo(self.dropout[-1](h[-1]))",
            "state = {'c': c, 'h': h}",
            "return state, y"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3697,
        "label": "yes",
        "change": [
            "TENSOR_CLASS_NAMES = (",
            "\"Tensor\",",
            ")",
            "",
            "-ST = TypeVar(\"ST\")",
            "+ST = t.TypeVar(\"ST\")",
            "",
            "",
            "-def _isinstance_wrapper(obj: ST, sobj: Union[str, type, Sequence]) -> bool:",
            "+def _isinstance_wrapper(obj: ST, sobj: t.Union[str, type, t.Sequence]) -> bool:",
            "\"\"\"",
            "`isinstance` wrapper to check tensor spec"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 3698,
        "label": "no",
        "change": [
            "class Newsqa(datasets.GeneratorBasedBuilder):",
            "",
            "if not os.path.exists(path_to_manual_folder):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('newsqa', data_dir=...)` that includes files from the Manual download instructions: {}\".format(",
            "-                    path_to_manual_folder, self.manual_download_instructions",
            "-                )",
            "+                f\"{path_to_manual_folder} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('newsqa', data_dir=...)` that includes files from the Manual download instructions: {self.manual_download_instructions}\"",
            ")",
            "",
            "if self.config.name == \"combined-csv\":"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3704,
        "label": "no",
        "change": [
            "def benchmark_step(first_batch):",
            "# Horovod: use DistributedGradientTape",
            "with tf.GradientTape() as tape:",
            "probs = model(data, training=True)",
            "-        loss = tf.losses.categorical_crossentropy(target, probs)",
            "+        loss = tf.losses.sparse_categorical_crossentropy(target, probs)",
            "",
            "# Horovod: add Horovod Distributed GradientTape.",
            "tape = hvd.DistributedGradientTape(tape, compression=compression)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3705,
        "label": "yes",
        "change": [
            "class WaveNet(object):",
            "The variables are all scoped to the given name.",
            "'''",
            "with tf.variable_scope(name):",
            "-            input_batch = self.encode(input_batch)",
            "+            input_batch = mu_law_encode(input_batch,",
            "+                                        self.quantization_channels)",
            "encoded = self._one_hot(input_batch)",
            "raw_output = self._create_network(encoded)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3706,
        "label": "yes",
        "change": [
            "def tensordot(",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "# find the type to promote to",
            "-    dtype = torch.promote_types(x1.dtype, x2.dtype)",
            "+    dtype = ivy.as_native_dtype(ivy.promote_types(x1.dtype, x2.dtype))",
            "# type conversion to one that torch.tensordot can work with",
            "x1, x2 = x1.type(torch.float32), x2.type(torch.float32)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3708,
        "label": "no",
        "change": [
            "class PipelineEngine(DeepSpeedEngine):",
            "Returns:",
            "A tensor from torch.zeros() allocated on self.device.",
            "\"\"\"",
            "-        if \"dtype\" not in kwargs and self.fp16_enabled():",
            "-            kwargs[\"dtype\"] = torch.half",
            "+        if \"dtype\" not in kwargs:",
            "+            if self.fp16_enabled():",
            "+                kwargs[\"dtype\"] = torch.half",
            "+            if self.bfloat16_enabled():",
            "+                kwargs[\"dtype\"] = torch.bfloat16",
            "",
            "return torch.zeros(shape, device=self.device, **kwargs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3709,
        "label": "no",
        "change": [
            "def sigmoid(x: torch.Tensor, out: Optional[torch.Tensor] = None) -> torch.Tensor",
            "return torch.sigmoid(x, out=out)",
            "",
            "",
            "-def softmax(x: torch.Tensor, axis: Optional[int] = None, out: Optional[torch.Tensor] = None) -> torch.Tensor:",
            "+def softmax(",
            "+    x: torch.Tensor, axis: Optional[int] = None, out: Optional[torch.Tensor] = None",
            "+) -> torch.Tensor:",
            "exp_x = torch.exp(x, out=out)",
            "return exp_x / torch.sum(exp_x, axis, keepdims=True)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3710,
        "label": "no",
        "change": [
            "def main_train(dir_path, max_epochs: int = 20):",
            "stopping = EarlyStopping(monitor=\"val_acc\", mode=\"max\", min_delta=0.005)",
            "trainer = pl.Trainer(",
            "default_root_dir=dir_path,",
            "-        gpus=int(torch.cuda.is_available()),",
            "+        devices=int(torch.cuda.is_available()),",
            "precision=(16 if torch.cuda.is_available() else 32),",
            "callbacks=[stopping],",
            "min_epochs=3,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3712,
        "label": "no",
        "change": [
            "class LogMelFbank(AbsFeatsExtract):",
            ")",
            "",
            "def forward(",
            "-        self, input: torch.Tensor, input_lengths: torch.Tensor",
            "+        self, input: torch.Tensor, input_lengths: torch.Tensor = None",
            ") -> Tuple[torch.Tensor, torch.Tensor]:",
            "# 1. Domain-conversion: e.g. Stft: time -> time-freq",
            "input_stft, feats_lens = self.stft(input, input_lengths)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3713,
        "label": "no",
        "change": [
            "def test_homogeneous_neighbor_loader(directed, dtype):",
            "@pytest.mark.parametrize('directed', [True])  # TODO re-enable undirected mode",
            "@pytest.mark.parametrize('dtype', [torch.int64, torch.int32])",
            "def test_heterogeneous_neighbor_loader(directed, dtype):",
            "+    if dtype != torch.int64 and not _WITH_PYG_LIB:",
            "+        return",
            "+",
            "torch.manual_seed(12345)",
            "",
            "data = HeteroData()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3716,
        "label": "no",
        "change": [
            "def coalesce(edge_index, edge_attr=None, num_nodes=None):",
            "else:",
            "sparse = getattr(torch.sparse, edge_attr.type().split('.')[-1])",
            "n = num_nodes",
            "-        size = torch.Size([n, n, *list(edge_attr.size())[1:]])",
            "+        size = torch.Size([n, n] + list(edge_attr.size())[1:])",
            "adj = sparse(edge_index, edge_attr, size).coalesce()",
            "edge_index, edge_attr = adj._indices(), adj._values()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3717,
        "label": "no",
        "change": [
            "class BaseDatasetTest(TestCase):",
            "def reduce_ex(self):",
            "raise pickle.PicklingError()",
            "",
            "-        nlp.arrow_dataset.logger.__reduce_ex__ = reduce_ex",
            "+        datasets.arrow_dataset.logger.__reduce_ex__ = reduce_ex",
            "",
            "def _create_dummy_dataset(self, in_memory: bool, tmp_dir: str, multiple_columns=False):",
            "if multiple_columns:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3718,
        "label": "no",
        "change": [
            "class BiMpmMatching(nn.Module, FromParams):",
            "",
            "# Returns",
            "",
            "-        A tuple of matching vectors for the two sentences. Each of which is a list of",
            "-        matching vectors of shape (batch, seq_len, num_perspectives or 1)",
            "+        `Tuple[List[torch.Tensor], List[torch.Tensor]]` :",
            "+            A tuple of matching vectors for the two sentences. Each of which is a list of",
            "+            matching vectors of shape (batch, seq_len, num_perspectives or 1)",
            "\"\"\"",
            "assert (not mask_2.requires_grad) and (not mask_1.requires_grad)",
            "assert context_1.size(-1) == context_2.size(-1) == self.hidden_dim"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3720,
        "label": "no",
        "change": [
            "class GravesAttention(nn.Module):",
            "",
            "def init_states(self, inputs):",
            "if self.J is None or inputs.shape[1] > self.J.shape[-1]:",
            "-            self.J = torch.arange(0, inputs.shape[1]).expand_as(torch.Tensor(inputs.shape[0], self.K, inputs.shape[1])).to(inputs.device)",
            "+            self.J = torch.arange(0, inputs.shape[1]).to(inputs.device).expand([inputs.shape[0], self.K, inputs.shape[1]])",
            "self.attention_weights = torch.zeros(inputs.shape[0], inputs.shape[1]).to(inputs.device)",
            "self.mu_prev = torch.zeros(inputs.shape[0], self.K).to(inputs.device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3722,
        "label": "no",
        "change": [
            "from torch_geometric.utils import to_dense_adj",
            "try:",
            "rowptr = torch.tensor([0, 1])",
            "col = torch.tensor([0])",
            "-    torch.ops.torch_sparse.partition(rowptr, col, None, 1)",
            "+    torch.ops.torch_sparse.partition(rowptr, col, None, 1, True)",
            "with_metis = True",
            "except RuntimeError:",
            "with_metis = False"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3723,
        "label": "no",
        "change": [
            "def solve_pnp_dlt(",
            "# Checking if world_points_norm (of any element of the batch) has rank = 3. This",
            "# function cannot be used if all world points (of any element of the batch) lie",
            "# on a line or if all world points (of any element of the batch) lie on a plane.",
            "-    s = torch.linalg.svdvals(world_points_norm)",
            "+    s = _torch_linalg_svdvals(world_points_norm)",
            "if torch.any(s[:, -1] < svd_eps):",
            "raise AssertionError(",
            "f\"The last singular value of one/more of the elements of the batch is smaller \""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3724,
        "label": "yes",
        "change": [
            "def test_train_step_epoch_end_scalar(tmpdir):",
            "train_step_out = out.training_step_output_for_epoch_end",
            "assert len(train_step_out) == 1",
            "train_step_out = train_step_out[0][0]",
            "-    assert isinstance(train_step_out, torch.Tensor)",
            "-    assert train_step_out.item() == 171",
            "+    assert isinstance(train_step_out['minimize'], torch.Tensor)",
            "+    assert train_step_out['minimize'].item() == 171",
            "",
            "# make sure the optimizer closure returns the correct things",
            "opt_closure_result = trainer.train_loop.training_step_and_backward("
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 3725,
        "label": "no",
        "change": [
            "def build_q_losses(policy, model, _, train_batch):",
            "",
            "",
            "def adam_optimizer(policy, config):",
            "-    return tf.train.AdamOptimizer(",
            "+    return tf1.train.AdamOptimizer(",
            "learning_rate=policy.cur_lr, epsilon=config[\"adam_epsilon\"])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3730,
        "label": "no",
        "change": [
            "def rgb_to_hsv(image: torch.Tensor) -> torch.Tensor:",
            "",
            "h = (h / 6.0) % 1.0",
            "",
            "-    h = 2 * pi * h",
            "+    h = 2 * pi.to(image.device) * h",
            "return torch.stack([h, s, v], dim=-3)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3731,
        "label": "no",
        "change": [
            "class DNN_Beamformer(torch.nn.Module):",
            "",
            "if isinstance(data, ComplexTensor):",
            "complex_wrapper = FC",
            "-        elif is_torch_1_8_plus and torch.is_complex(data):",
            "+        elif is_torch_1_9_plus and torch.is_complex(data):",
            "complex_wrapper = torch",
            "else:",
            "raise ValueError("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3733,
        "label": "no",
        "change": [
            "class Tester(unittest.TestCase):",
            "def test_rotation_matrix_to_angle_axis_gradcheck(self):",
            "# generate input data",
            "batch_size = 2",
            "-        rmat = torch.rand(batch_size, 4, 4)",
            "+        rmat = torch.rand(batch_size, 3, 4)",
            "rmat = utils.tensor_to_gradcheck_var(rmat)  # to var",
            "",
            "# evaluate function gradient"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3735,
        "label": "no",
        "change": [
            "def warp_perspective(src, M, dsize, flags='bilinear', border_mode=None,",
            "- Output: :math:`(B, C, H, W)`",
            "",
            ".. note::",
            "-       See a working example `here <../../../examples/warp_perspective.ipynb>`_.",
            "+       See a working example `here <https://github.com/arraiy/torchgeometry/blob/master/examples/warp_perspective.ipynb>`_.",
            "\"\"\"",
            "if not torch.is_tensor(src):",
            "raise TypeError(\"Input src type is not a torch.Tensor. Got {}\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3740,
        "label": "no",
        "change": [
            "def normc_initializer(std=1.0):",
            "return _initializer",
            "",
            "",
            "+def get_activation_fn(name):",
            "+    return getattr(tf.nn, name)",
            "+",
            "+",
            "def conv2d(x, num_filters, name, filter_size=(3, 3), stride=(1, 1), pad=\"SAME\",",
            "dtype=tf.float32, collections=None):",
            "with tf.variable_scope(name):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3741,
        "label": "no",
        "change": [
            "class Model(object):",
            "Returns:",
            "Checkpoint path where the model was saved.",
            "\"\"\"",
            "-        self.monitored_session.run(fetches=self.summarizer_flush)",
            "+        if self.flush_summarizer is not None:",
            "+            self.monitored_session.run(fetches=self.flush_summarizer)",
            "",
            "return self.saver.save(",
            "sess=self.session,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3746,
        "label": "no",
        "change": [
            "class Evolutionary(Optimizer):",
            "diffs_list.append(diffs)",
            "",
            "with tf.control_dependencies(control_inputs=diffs):",
            "-            diffs = [tf.add_n(inputs=[diffs[n] for diffs in diffs_list]) / self.samples for n in range(len(diffs_list[0]))]",
            "+            diffs = [tf.add_n(inputs=[diffs[n] for diffs in diffs_list]) /",
            "+                     self.samples for n in range(len(diffs_list[0]))]",
            "perturbation_diffs = [diff - pert for diff, pert in zip(diffs, previous_perturbations)]",
            "applied = self.apply_step(variables=variables, diffs=perturbation_diffs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3747,
        "label": "no",
        "change": [
            "class BatchNorm(base.AbstractModule):",
            "trainable=False)",
            "",
            "self._moving_variance = tf.subtract(self._moving_second_moment,",
            "-                                   tf.square(self._moving_mean),",
            "-                                   name=\"moving_variance\")",
            "+                                        tf.square(self._moving_mean),",
            "+                                        name=\"moving_variance\")",
            "",
            "def build_batch_stats():",
            "\"\"\"Builds the batch statistics calculation ops.\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3748,
        "label": "no",
        "change": [
            "class RunningStandardize(Preprocessor):",
            "",
            "def later_run():",
            "# Variance update",
            "-                variance = tf.reduce_sum(input_tensor=((tensor - mean_estimate) * mean), axis=0)",
            "+                variance = tf.reduce_sum(input_tensor=((tensor - mean_estimate) * mean), axis=0)  # reduce_mean?",
            "assignment = tf.assign_add(ref=variance_sum_estimate, value=variance)",
            "with tf.control_dependencies(control_inputs=(assignment,)):",
            "variance_estimate = variance_sum_estimate / (count - 1.0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3750,
        "label": "no",
        "change": [
            "class TFWav2Vec2ModelIntegrationTest(unittest.TestCase):",
            "",
            "input_speech = self._load_datasamples(4)",
            "",
            "-        inputs = processor(input_speech, return_tensors=\"tf\", padding=True, truncation=True)",
            "+        inputs = processor(input_speech, return_tensors=\"tf\", padding=True, sampling_rate=16000)",
            "",
            "input_values = inputs.input_values",
            "attention_mask = inputs.attention_mask",
            "",
            "logits = model(input_values, attention_mask=attention_mask).logits",
            "",
            "-        predicted_ids = tf.argmax(logits, dim=-1)",
            "+        predicted_ids = tf.argmax(logits, axis=-1)",
            "predicted_trans = processor.batch_decode(predicted_ids)",
            "",
            "EXPECTED_TRANSCRIPTIONS = ["
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3751,
        "label": "no",
        "change": [
            "class ReformerPreTrainedModel(PreTrainedModel):",
            "\"\"\"Initialize the weights\"\"\"",
            "if isinstance(module, AxialPositionEmbeddings):",
            "for weight in module.weights:",
            "-                torch.nn.init.normal_(weight, std=self.config.axial_norm_std)",
            "+                nn.init.normal_(weight, std=self.config.axial_norm_std)",
            "elif isinstance(module, nn.Embedding):",
            "module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)",
            "if module.padding_idx is not None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3752,
        "label": "no",
        "change": [
            "class SpatialTransformer2dAffineLayer(Layer):",
            "# 2.1 W",
            "n_in = int(self.theta_layer.outputs.get_shape()[-1])",
            "shape = (n_in, 6)",
            "-            W = tf.get_variable(name='W', initializer=tf.zeros(shape), dtype=D_TYPE)",
            "+            W = tf.get_variable(name='W', initializer=tf.zeros(shape), dtype=LayersConfig.tf_dtype)",
            "# 2.2 b",
            "identity = tf.constant(np.array([[1., 0, 0], [0, 1., 0]]).astype('float32').flatten())",
            "-            b = tf.get_variable(name='b', initializer=identity, dtype=D_TYPE)",
            "+            b = tf.get_variable(name='b', initializer=identity, dtype=LayersConfig.tf_dtype)",
            "# 2.3 transformation matrix",
            "self.theta = tf.nn.tanh(tf.matmul(self.theta_layer.outputs, W) + b)",
            "# 3. Spatial Transformer Sampling"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3753,
        "label": "no",
        "change": [
            "def rgb_to_hls(image: torch.Tensor) -> torch.Tensor:",
            "hi[imax == 1] = (((b - r) / deltac) + 2)[imax == 1]",
            "hi[imax == 2] = (((r - g) / deltac) + 4)[imax == 2]",
            "",
            "-    h: torch.Tensor = 2. * pi * (60. * hi) / 360.  # hue [0, 2*pi]",
            "+    h: torch.Tensor = 2. * pi.to(image.device) * (60. * hi) / 360.  # hue [0, 2*pi]",
            "",
            "image_hls: torch.Tensor = torch.stack([h, l, s], dim=-3)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3756,
        "label": "no",
        "change": [
            "class Policy(metaclass=ABCMeta):",
            "episodes = [episode]",
            "if state is not None:",
            "state_batch = [",
            "-                s.unsqueeze(0)",
            "-                if torch and isinstance(s, torch.Tensor) else [s]",
            "+                s.unsqueeze(0) if torch and isinstance(s, torch.Tensor) else",
            "+                np.expand_dims(s, 0)",
            "for s in state",
            "]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3757,
        "label": "no",
        "change": [
            "class BatchEncoding(UserDict):",
            "return self",
            "",
            "@torch_required",
            "-    def to(self, device: str) -> \"BatchEncoding\":",
            "+    def to(self, device: Union[str, \"torch.device\"]) -> \"BatchEncoding\":",
            "\"\"\"",
            "Send all values to device by calling :obj:`v.to(device)` (PyTorch only)."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3759,
        "label": "no",
        "change": [
            "class Model(base_layer.Layer, version_utils.ModelVersionSelector):",
            "Example:",
            "",
            "```python",
            "-    model.compile(optimizer=tf.keras.optimizer.Adam(learning_rate=1e-3),",
            "+    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),",
            "loss=tf.keras.losses.BinaryCrossentropy(),",
            "metrics=[tf.keras.metrics.BinaryAccuracy(),",
            "tf.keras.metrics.FalseNegatives()])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3763,
        "label": "no",
        "change": [
            "def outputVar(l, voc):",
            "max_target_len = max([len(indexes) for indexes in indexes_batch])",
            "padList = zeroPadding(indexes_batch)",
            "mask = binaryMatrix(padList)",
            "-    mask = torch.ByteTensor(mask)",
            "+    mask = torch.BoolTensor(mask)",
            "padVar = torch.LongTensor(padList)",
            "return padVar, mask, max_target_len"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3764,
        "label": "no",
        "change": [
            "class TFRagTokenForGeneration(TFRagPreTrainedModel, TFCausalLanguageModelingLoss",
            "eos_token_id=eos_token_id,",
            "forced_bos_token_id=None,",
            "forced_eos_token_id=None,",
            "+                input_ids_seq_length=tf.shape(decoder_input_ids)[-1],",
            ")",
            "model_kwargs[\"attention_mask\"] = context_attention_mask"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3767,
        "label": "no",
        "change": [
            "def main():",
            "model.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)",
            "# endregion",
            "",
            "-        # region Convert data to TF format",
            "+        # region Convert data to a tf.data.Dataset",
            "",
            "-        # Convert data to a tf.keras.utils.Sequence object for training if we're not using a TPU",
            "-        # For TPU, convert to a tf.data.Dataset",
            "tf_data = dict()",
            "max_samples = {",
            "\"train\": data_args.max_train_samples,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3768,
        "label": "no",
        "change": [
            "class RNN(Layer):",
            "else:",
            "initial_state = self.states",
            "initial_state = tf.nest.map_structure(",
            "-          lambda v: tf.cast(v, self.compute_dtype), initial_state",
            "+          # When the layer has a inferred dtype, use the dtype from the cell.",
            "+          lambda v: tf.cast(v, self.compute_dtype or self.cell.compute_dtype),",
            "+          initial_state",
            ")",
            "elif initial_state is None:",
            "initial_state = self.get_initial_state(inputs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3771,
        "label": "no",
        "change": [
            "class TestDexiNed:",
            "dtype=dtype,",
            ")",
            "",
            "-        out = model(img)",
            "-        assert_close(out[-1][:, :1], expect, atol=1e-4, rtol=1e-4)",
            "+        out = model(img)[-1]",
            "+        assert_close(out, expect, atol=3e-4, rtol=3e-4)",
            "",
            "def test_jit(self, device, dtype):",
            "op = kornia.filters.DexiNed(pretrained=False).to(device, dtype)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3774,
        "label": "no",
        "change": [
            "\"outputs\": [],",
            "\"source\": [",
            "\"!pip install torch torchvision\\n\",",
            "-    \"!pip install 'git+https://github.com/facebookresearch/pytorch3d.git'\"",
            "+    \"import sys\\n\",",
            "+    \"if torch.__version__=='1.6.0+cu101' and sys.platform.startswith('linux'):\\n\",",
            "+    \"    !pip install pytorch3d\\n\",",
            "+    \"else:\\n\",",
            "+    \"    !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\"",
            "]",
            "},",
            "{"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3775,
        "label": "no",
        "change": [
            "def laf_is_inside_image(laf: torch.Tensor, images: torch.Tensor) -> torch.Tensor",
            "raise_error_if_laf_is_not_valid(laf)",
            "n, ch, h, w = images.size()",
            "pts: torch.Tensor = laf_to_boundary_points(laf, 12)",
            "-    good_lafs_mask: torch.Tensor = (pts[..., 0] >= 0) * (pts[..., 0] <= w) * (pts[..., 1] >= 0) * (pts[..., 1] <= h)",
            "+    good_lafs_mask: torch.Tensor = (pts[..., 0] >= border) *\\",
            "+        (pts[..., 0] <= w - border) *\\",
            "+        (pts[..., 1] >= border) *\\",
            "+        (pts[..., 1] <= h - border)",
            "good_lafs_mask = good_lafs_mask.min(dim=2)[0]",
            "return good_lafs_mask"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3779,
        "label": "no",
        "change": [
            "class NaturalGradient(Optimizer):",
            "return [tf.zeros_like(tensor=delta) for delta in deltas]",
            "",
            "# Natural gradient step only works if constant > 0",
            "-        return tf.cond(pred=(constant > 0.0), true_fn=natural_gradient_step, false_fn=zero_step)",
            "+        return self.cond(pred=(constant > 0.0), true_fn=natural_gradient_step, false_fn=zero_step)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3780,
        "label": "yes",
        "change": [
            "class OneHotCategorical(Distribution):",
            "sample. The last dimension is used for the one-hot encoding.",
            ":rtype: torch.autograd.Variable.",
            "\"\"\"",
            "-        return Variable(torch.stack([t.expand_as(self.ps) for t in torch_eye(*self.event_shape())]))",
            "+        result = torch.stack([t.expand_as(self.ps) for t in torch_eye(*self.event_shape())])",
            "+        if self.ps.is_cuda:",
            "+            result = result.cuda(self.ps.get_device())",
            "+        return Variable(result)",
            "",
            "def analytic_mean(self):",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3781,
        "label": "no",
        "change": [
            "for epoch in range(num_epochs):",
            "# Format batch",
            "real_cpu = data[0].to(device)",
            "b_size = real_cpu.size(0)",
            "-        label = torch.full((b_size,), real_label, device=device)",
            "+        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)",
            "# Forward pass real batch through D",
            "output = netD(real_cpu).view(-1)",
            "# Calculate loss on all-real batch"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3785,
        "label": "no",
        "change": [
            "class TFCausalLanguageModelingLoss:",
            ")",
            "# make sure only labels that are not equal to -100",
            "# are taken into account as loss",
            "-        active_loss = tf.reshape(labels, (-1,)) != -100",
            "+        active_loss = tf.not_equal(tf.reshape(labels, (-1,)), -100)",
            "reduced_logits = tf.boolean_mask(tf.reshape(logits, (-1, shape_list(logits)[2])), active_loss)",
            "labels = tf.boolean_mask(tf.reshape(labels, (-1,)), active_loss)",
            "return loss_fn(labels, reduced_logits)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3786,
        "label": "no",
        "change": [
            "class TFHubertPreTrainedModel(TFPreTrainedModel):",
            "input_signature=[",
            "{",
            "\"input_values\": tf.TensorSpec((None, None), tf.float32, name=\"input_values\"),",
            "-                \"attention_mask\": tf.TensorSpec((None, None), tf.int64, name=\"attention_mask\"),",
            "-                \"token_type_ids\": tf.TensorSpec((None, None), tf.int64, name=\"token_type_ids\"),",
            "+                \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),",
            "+                \"token_type_ids\": tf.TensorSpec((None, None), tf.int32, name=\"token_type_ids\"),",
            "}",
            "]",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3787,
        "label": "no",
        "change": [
            "class DistMetricsCalculator(MetricsCalculator):",
            "if len(across_dim) == 0:",
            "dist_sum = torch.abs(reorder_tensor - other).sum()",
            "else:",
            "-                    dist_sum = torch.norm((reorder_tensor - other), p=self.p, dim=across_dim).sum()",
            "+                    dist_sum = torch.norm((reorder_tensor - other), p=self.p, dim=across_dim).sum()  # type: ignore",
            "# NOTE: this place need refactor when support layer level pruning.",
            "tmp_metric = metric",
            "for i in idx[:-1]:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3788,
        "label": "yes",
        "change": [
            "def bidirectional_rnn(incoming, rnncell_fw, rnncell_bw, return_seq=False,",
            "tf.add_to_collection(tf.GraphKeys.ACTIVATIONS, outputs[-1])",
            "",
            "if dynamic:",
            "-        outputs = tf.transpose(tf.pack(outputs), [1, 0, 2])",
            "-        o = advanced_indexing_op(outputs, sequence_length)",
            "+        if return_seq:",
            "+            o = outputs",
            "+        else:",
            "+            outputs = tf.transpose(tf.pack(outputs), [1, 0, 2])",
            "+            o = advanced_indexing_op(outputs, sequence_length)",
            "else:",
            "o = outputs if return_seq else outputs[-1]"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 3789,
        "label": "no",
        "change": [
            "class EpsilonDecay(Exploration):",
            "",
            "pred = tf.logical_or(x=(timestep < self.start_timestep),",
            "y=(timestep > self.start_timestep + int(self.timesteps)))",
            "-        return tf.fill(dims=shape, value=tf.cond(pred=pred, true_fn=true_fn, false_fn=false_fn))",
            "+        return tf.fill(dims=shape, value=self.cond(pred=pred, true_fn=true_fn, false_fn=false_fn))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3795,
        "label": "no",
        "change": [
            "class SignatureDict(NestedDict):",
            "elif name in kwargs:",
            "arg = kwargs[name]",
            "if isinstance(spec, self.value_type):",
            "-                    assert isinstance(arg, (tf.IndexedSlices, tf.Tensor, tf.Variable)), (name, spec, arg)",
            "+                    assert isinstance(arg, (tf.IndexedSlices, tf.Tensor, tf.Variable))",
            "if isinstance(arg, tf.IndexedSlices):",
            "# spec = tf.IndexedSlicesSpec(",
            "#     shape=spec.shape, dtype=spec.dtype, indices_dtype=arg.indices.dtype"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3796,
        "label": "no",
        "change": [
            "def init_seq2seq_weights(module):",
            "",
            "Defined in :numref:`sec_seq2seq`\"\"\"",
            "if type(module) == nn.Linear:",
            "-         nn.init.xavier_uniform_(layer.weight)",
            "+         nn.init.xavier_uniform_(module.weight)",
            "if type(module) == nn.GRU:",
            "-        for param in layer._flat_weights_names:",
            "+        for param in module._flat_weights_names:",
            "if \"weight\" in param:",
            "nn.init.xavier_uniform_(module._parameters[param])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3800,
        "label": "no",
        "change": [
            "class HEATConv(MessagePassing):",
            "alpha = softmax(alpha, index, ptr, size_i)",
            "alpha = F.dropout(alpha, p=self.dropout, training=self.training)",
            "",
            "-        out = self.lin(torch.cat([x_i, edge_attr], dim=-1)).unsqueeze(-2)",
            "-        out = out * alpha.unsqueeze(-1)",
            "-        return out",
            "+        out = self.lin(torch.cat([x_j, edge_attr], dim=-1)).unsqueeze(-2)",
            "+        return out * alpha.unsqueeze(-1)",
            "",
            "def __repr__(self) -> str:",
            "return (f'{self.__class__.__name__}({self.in_channels}, '"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3803,
        "label": "no",
        "change": [
            "class EntropyTest(AllenNlpTestCase):",
            "def test_masked_case(self):",
            "metric = Entropy()",
            "# This would have non-zero entropy without the mask.",
            "-        logits = torch.Tensor([[1, 1, 1, 1],",
            "-                               [10000, -10000, -10000, -1000]])",
            "+        logits = torch.Tensor([[1, 1, 1, 1], [10000, -10000, -10000, -1000]])",
            "mask = torch.Tensor([0, 1])",
            "metric(logits, mask)",
            "assert metric.get_metric() == 0.0"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3804,
        "label": "no",
        "change": [
            "class LongformerSelfAttention(nn.Module):",
            "]",
            "attn[extra_attention_mask_nonzeros[::-1]] = nonzero_selected_attn.view(",
            "len(selection_padding_mask_nonzeros[0]), -1",
            "-            ).type_as(hidden_states)",
            "+            )",
            "",
            "context_layer = attn.transpose(0, 1)",
            "if self.output_attentions:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3805,
        "label": "no",
        "change": [
            "class NGramRepeatBlock(nn.Module):",
            "]",
            "for bbsz_idx in range(bsz * beam_size):",
            "lprobs[bbsz_idx][",
            "-                torch.tensor(banned_tokens[bbsz_idx]).long()",
            "+                torch.tensor(banned_tokens[bbsz_idx], dtype=torch.int64)",
            "] = torch.tensor(-math.inf).to(lprobs)",
            "return lprobs"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3809,
        "label": "no",
        "change": [
            "class NLayerDiscriminator(nn.Module):",
            "]",
            "",
            "sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=1)]",
            "-        sequence += [nn.Sigmoid()]",
            "+",
            "+        if use_sigmoid:",
            "+            sequence += [nn.Sigmoid()]",
            "",
            "self.model = nn.Sequential(*sequence)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3811,
        "label": "no",
        "change": [
            "class DistributionalQModel(TFModelV2):",
            "return state_score",
            "",
            "if tf.executing_eagerly():",
            "+            from tensorflow.python.ops import variable_scope",
            "# Have to use a variable store to reuse variables in eager mode",
            "-            import tensorflow.contrib as tfc",
            "-            store = tfc.eager.EagerVariableStore()",
            "+            store = variable_scope.EagerVariableStore()",
            "",
            "# Save the scope objects, since in eager we will execute this",
            "# path repeatedly and there is no guarantee it will always be run"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3813,
        "label": "yes",
        "change": [
            "\"\\n\",",
            "\"# For evaluation we use exactly normalized rather than\\n\",",
            "\"# approximately normalized.\\n\",",
            "-        \"sts_encode1 = tf.nn.l2_normalize(embed(sts_input1))\\n\",",
            "-        \"sts_encode2 = tf.nn.l2_normalize(embed(sts_input2))\\n\",",
            "-        \"sim_scores = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)\"",
            "+        \"sts_encode1 = tf.nn.l2_normalize(embed(sts_input1), axis=1)\\n\",",
            "+        \"sts_encode2 = tf.nn.l2_normalize(embed(sts_input2), axis=1)\\n\",",
            "+        \"sim_scores = -tf.acos(tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1))\"",
            "]",
            "},",
            "{"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3817,
        "label": "no",
        "change": [
            "def nanmedian(",
            "overwrite_input: Optional[bool] = False,",
            "out: Optional[torch.tensor] = None,",
            ") -> torch.tensor:",
            "-    return torch.nanmedian(input, axis=axis, keepdims=keepdims, overwrite_input=overwrite_input, out=out)",
            "+    return torch.nanmedian(",
            "+        input, axis=axis, keepdims=keepdims, overwrite_input=overwrite_input, out=out",
            "+    )"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3819,
        "label": "no",
        "change": [
            "def cos(x: torch.Tensor)\\",
            "return torch.cos(x)",
            "",
            "",
            "-def logical_not(x: torch.Tensor) -> torch.Tensor:",
            "+def logical_not(x: torch.Tensor)\\",
            "+        -> torch.Tensor:",
            "return torch.logical_not(x.type(torch.bool))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3820,
        "label": "no",
        "change": [
            "def transform_points(trans_01: torch.Tensor,",
            ">>> trans_01 = torch.eye(4).view(1, 4, 4)  # Bx4x4",
            ">>> points_0 = kornia.transform_points(trans_01, points_1)  # BxNx3",
            "\"\"\"",
            "-    if not torch.is_tensor(trans_01) or not torch.is_tensor(points_1):",
            "-        raise TypeError(\"Input type is not a torch.Tensor\")",
            "+    check_is_tensor(trans_01)",
            "+    check_is_tensor(points_1)",
            "if not trans_01.device == points_1.device:",
            "raise TypeError(\"Tensor must be in the same device\")",
            "if not trans_01.shape[0] == points_1.shape[0] and trans_01.shape[0] != 1:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3821,
        "label": "no",
        "change": [
            "def test_metapath2vec():",
            "z = model('author', torch.arange(2))",
            "assert z.size() == (2, 16)",
            "",
            "-    pos_rw, neg_rw = model.sample(torch.arange(3))",
            "+    pos_rw, neg_rw = model._sample(torch.arange(3))",
            "",
            "loss = model.loss(pos_rw, neg_rw)",
            "assert 0 <= loss.item()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3825,
        "label": "no",
        "change": [
            "class AttentionDecoder(RNNDecoder):",
            "logits=self.vocab_size,",
            "predicted_ids=tf.TensorShape([]),",
            "cell_output=self.cell.output_size,",
            "-        attention_scores=tf.concat(",
            "-            [[0], tf.shape(self.attention_values)[1:-1]], 0),",
            "+        attention_scores=tf.shape(self.attention_values)[1:-1],",
            "attention_context=self.attention_values.get_shape()[-1])",
            "",
            "@property"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3828,
        "label": "no",
        "change": [
            "def coalesce(",
            "return edge_index",
            "",
            "dim_size = edge_index.size(1)",
            "-    idx = torch.arange(0, nnz).sub_(mask.logical_not_().cumsum(dim=0))",
            "+    idx = torch.arange(0, nnz, device=edge_index.device)",
            "+    idx.sub_(mask.logical_not_().cumsum(dim=0))",
            "",
            "if isinstance(edge_attr, Tensor):",
            "edge_attr = scatter(edge_attr, idx, 0, None, dim_size, reduce)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3830,
        "label": "no",
        "change": [
            "class SparseGPRegression(GPModel):",
            "W_Dinv = W / D",
            "K = W_Dinv.matmul(W.t()).contiguous()",
            "K.view(-1)[::M + 1] += 1  # add identity matrix to K",
            "-        L = K.cholesky()",
            "+        L = torch.linalg.cholesky(K)",
            "",
            "# get y_residual and convert it into 2D tensor for packing",
            "y_residual = self.y - self.mean_function(self.X)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3831,
        "label": "yes",
        "change": [
            "class TFFastSpeech2(TFFastSpeech):",
            "duration_outputs = self.duration_predictor(",
            "[last_encoder_hidden_states, speaker_ids, attention_mask]",
            ")  # [batch_size, length]",
            "-        duration_outputs = tf.math.exp(duration_outputs) - 1.0",
            "+        duration_outputs = tf.nn.relu(tf.math.exp(duration_outputs) - 1.0)",
            "duration_outputs = tf.cast(",
            "tf.math.round(duration_outputs * speed_ratios), tf.int32",
            ")"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3832,
        "label": "no",
        "change": [
            "class Layer(tf.Module, version_utils.LayerVersionSelector):",
            "flat_specs = [tf_utils.get_tensor_spec(x) for x in flat_kwarg]",
            "if any(s is None for s in flat_specs):",
            "continue",
            "-      kwargs[key] = args_spec.append(",
            "-          tf.nest.pack_sequence_as(kwarg, flat_specs))",
            "+      kwargs_spec[key] = tf.nest.pack_sequence_as(kwarg, flat_specs)",
            "",
            "self._saved_model_inputs_spec = inputs_spec",
            "self._saved_model_arg_spec = ([inputs_spec] + args_spec, kwargs_spec)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3833,
        "label": "no",
        "change": [
            "class TextCNN(object):",
            "# 全连接层，后面接dropout以及relu激活",
            "fc = tf.layers.dense(gmp, self.config.hidden_dim, name='fc1')",
            "fc = tf.contrib.layers.dropout(fc,",
            "-                self.config.dropout_keep_prob)",
            "+                self.keep_prob)",
            "fc = tf.nn.relu(fc)",
            "",
            "# 分类器"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3837,
        "label": "no",
        "change": [
            "def pixel_wise_softmax(x, name='pixel_wise_softmax'):",
            "References",
            "- `tf.reverse <https://www.tensorflow.org/versions/master/api_docs/python/array_ops.html#reverse>`_",
            "+",
            "\"\"\"",
            "with tf.name_scope(name):",
            "return tf.nn.softmax(x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3842,
        "label": "no",
        "change": [
            "class InverseDepthSmoothnessLoss(nn.Module):",
            "assert len(img.shape) == 4, img.shape",
            "return img[:, :, :-1, :] - img[:, :, 1:, :]",
            "",
            "-    def forward(self, idepth: torch.Tensor, image: torch.Tensor) -> torch.Tensor:",
            "+    def forward(",
            "+            self,",
            "+            idepth: torch.Tensor,",
            "+            image: torch.Tensor) -> torch.Tensor:",
            "if not torch.is_tensor(idepth):",
            "raise TypeError(\"Input idepth type is not a torch.Tensor. Got {}\"",
            ".format(type(idepth)))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3843,
        "label": "no",
        "change": [
            "class TFLayoutLMv3PreTrainedModel(TFPreTrainedModel):",
            "@tf.function(",
            "input_signature=[",
            "{",
            "-                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),",
            "-                \"bbox\": tf.TensorSpec((None, None, 4), tf.int64, name=\"bbox\"),",
            "+                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),",
            "+                \"bbox\": tf.TensorSpec((None, None, 4), tf.int32, name=\"bbox\"),",
            "\"pixel_values\": tf.TensorSpec((None, None, None, None), tf.float32, name=\"pixel_values\"),",
            "-                \"attention_mask\": tf.TensorSpec((None, None), tf.int64, name=\"attention_mask\"),",
            "+                \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),",
            "}",
            "]",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3846,
        "label": "yes",
        "change": [
            "class Tacotron(nn.Module):",
            "with open(path, \"a\") as f:",
            "print(msg, file=f)",
            "",
            "-    def load(self, path, optimizer=None):",
            "+    def load(self, path, device, optimizer=None):",
            "# Use device of model params as location for loaded state",
            "-        checkpoint = torch.load(str(path))",
            "+        checkpoint = torch.load(str(path), map_location=device)",
            "self.load_state_dict(checkpoint[\"model_state\"], strict=False)",
            "",
            "if \"optimizer_state\" in checkpoint and optimizer is not None:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 3847,
        "label": "no",
        "change": [
            "class DummyDataset(Dataset):",
            "return 12",
            "",
            "def __getitem__(self, idx):",
            "-        return np.array([0.5, 1.0, 2.0])",
            "+        return torch.tensor([0.5, 1.0, 2.0])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3849,
        "label": "yes",
        "change": [
            "floor_divide.support_native_out = True",
            "",
            "",
            "def floormod(",
            "-    x: torch.Tensor, y: torch.Tensor, *, out: Optional[torch.Tensor] = None",
            "+    x: torch.Tensor, y: torch.Tensor, /, *, out: Optional[torch.Tensor] = None",
            ") -> torch.Tensor:",
            "+    x, y = ivy.promote_types_of_inputs(x, y)",
            "return x % y"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 3856,
        "label": "no",
        "change": [
            "class TestAutoRegressiveSeqDecoder(AllenNlpTestCase):",
            ").eval()",
            "",
            "encoded_state = torch.randn(batch_size, time_steps, decoder_inout_dim)",
            "-        source_mask = torch.ones(batch_size, time_steps).long()",
            "+        source_mask = torch.ones(batch_size, time_steps).bool()",
            "target_tokens = {\"tokens\": {\"tokens\": torch.ones(batch_size, time_steps).long()}}",
            "-        source_mask[0, 1:] = 0",
            "+        source_mask[0, 1:] = False",
            "encoder_out = {\"source_mask\": source_mask, \"encoder_outputs\": encoded_state}",
            "",
            "auto_regressive_seq_decoder.forward(encoder_out, target_tokens)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3861,
        "label": "no",
        "change": [
            "class RNNModel(nn.Module):",
            "# pass input to the remote embedding table and fetch emb tensor back",
            "emb = _remote_method(EmbeddingTable.forward, self.emb_table_rref, input)",
            "output, hidden = self.rnn(emb, hidden)",
            "-        # pass output to the rremote decoder and get the decoded output back",
            "+        # pass output to the remote decoder and get the decoded output back",
            "decoded = _remote_method(Decoder.forward, self.decoder_rref, output)",
            "return decoded, hidden"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3863,
        "label": "no",
        "change": [
            "class FCNMaskHead(nn.Module):",
            "def loss(self, mask_pred, mask_targets, labels):",
            "loss = dict()",
            "if self.class_agnostic:",
            "-            loss_mask = mask_cross_entropy(mask_pred, mask_targets,",
            "-                                           torch.zeros_like(labels))",
            "+            loss_mask = self.loss_mask(mask_pred, mask_targets,",
            "+                                       torch.zeros_like(labels))",
            "else:",
            "-            loss_mask = mask_cross_entropy(mask_pred, mask_targets, labels)",
            "+            loss_mask = self.loss_mask(mask_pred, mask_targets, labels)",
            "loss['loss_mask'] = loss_mask",
            "return loss"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3864,
        "label": "no",
        "change": [
            "def build_q_losses(policy, model, _, train_batch):",
            "q_tp1_best_one_hot_selection = F.one_hot(q_tp1_best_using_online_net,",
            "policy.action_space.n)",
            "q_tp1_best = torch.sum(",
            "-            torch.where(q_tp1 > -float(\"inf\"), q_tp1, torch.tensor(0.0)) *",
            "+            torch.where(q_tp1 > -float(\"inf\"), q_tp1,",
            "+                        torch.tensor(0.0, device=policy.device)) *",
            "q_tp1_best_one_hot_selection, 1)",
            "q_probs_tp1_best = torch.sum(",
            "q_probs_tp1 * torch.unsqueeze(q_tp1_best_one_hot_selection, -1), 1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3865,
        "label": "no",
        "change": [
            "class RPNHead(AnchorHead):",
            "self.rpn_conv = nn.Conv2d(",
            "self.in_channels, self.feat_channels, 3, padding=1)",
            "self.rpn_cls = nn.Conv2d(self.feat_channels,",
            "-                                 self.num_anchors * self.cls_out_channels, 1)",
            "-        self.rpn_reg = nn.Conv2d(self.feat_channels, self.num_anchors * 4, 1)",
            "+                                 self.num_base_priors * self.cls_out_channels,",
            "+                                 1)",
            "+        self.rpn_reg = nn.Conv2d(self.feat_channels, self.num_base_priors * 4,",
            "+                                 1)",
            "",
            "def forward_single(self, x):",
            "\"\"\"Forward feature map of a single scale level.\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3867,
        "label": "no",
        "change": [
            "msort_support_native_out = True",
            "",
            "# lexsort",
            "def lexsort(",
            "-    keys: torch.Tensor,",
            "-    /,",
            "-    *,",
            "-    axis: int = -1,",
            "-    out: Optional[torch.Tensor] = None",
            "+    keys: torch.Tensor, /, *, axis: int = -1, out: Optional[torch.Tensor] = None",
            ") -> torch.Tensor:",
            "shape = keys.size()",
            "if len(shape) == 1:",
            "_, result = torch.sort(keys, dim=axis, stable=True)",
            "return result",
            "if shape[0] == 0:",
            "-        raise TypeError('need sequence of keys with len > 0 in lexsort')",
            "+        raise TypeError(\"need sequence of keys with len > 0 in lexsort\")",
            "if len(shape) == 2 and shape[1] == 1:",
            "return torch.tensor([0])",
            "_, result = torch.sort(keys[0], dim=axis, stable=True)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3868,
        "label": "no",
        "change": [
            "class Metric(nn.Module, ABC):",
            "\"\"\"",
            "for attr, default in self._defaults.items():",
            "current_val = getattr(self, attr)",
            "-            if isinstance(current_val, torch.Tensor):",
            "+            if isinstance(default, torch.Tensor):",
            "setattr(self, attr, deepcopy(default).to(current_val.device))",
            "else:",
            "setattr(self, attr, deepcopy(default))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3869,
        "label": "no",
        "change": [
            "class DistributedFusedAdam(torch.optim.Optimizer):",
            "if torch.distributed.get_rank() in ranks:",
            "self._rs_pg.append(grp)",
            "if self._compute_L2_grad_norm and torch.distributed.get_rank() in ranks:",
            "-                #self._l2_grad_norm_pg = torch.distributed.new_group(ranks=ranks)",
            "-                self._l2_grad_norm_pg = self._rs_pg[-1]",
            "+                self._l2_grad_norm_pg = torch.distributed.new_group(ranks=ranks)",
            "self._rs_st = [torch.cuda.Stream() for _ in range(self._num_rs_pg)]",
            "if self._num_ag_pg == 0:",
            "self._ag_pg = self._rs_pg"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3870,
        "label": "no",
        "change": [
            "class KernelDeepLSTMTest(tf.test.TestCase):",
            "@parameterized.expand([",
            "[\"zeros\"],",
            "[{\"w\": \"zeros\", \"b\": \"zeros\", \"bad\": \"bad\"}],",
            "-      [{\"w\": tf.zeros_initializer, \"b\": np.array([0])}],",
            "-      [{\"linear\": {\"w\": tf.zeros_initializer, \"b\": \"zeros\"}}]",
            "+      [{\"w\": tf.zeros_initializer(), \"b\": np.array([0])}],",
            "+      [{\"linear\": {\"w\": tf.zeros_initializer(), \"b\": \"zeros\"}}]",
            "])",
            "def testResults(self, initializer):",
            "\"\"\"Tests zero updates when last layer is initialized to zero.\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3874,
        "label": "no",
        "change": [
            "def negative_sampling(edge_index, num_nodes=None, num_neg_samples=None,",
            "",
            "if force_undirected:",
            "# (-sqrt((2 * N + 1)^2 - 8 * perm) + 2 * N + 1) / 2",
            "-        row = torch.floor((-torch.sqrt((2 * num_nodes + 1)**2 - 8 * perm) +",
            "+        row = torch.floor((-torch.sqrt((2. * num_nodes + 1.)**2 - 8. * perm) +",
            "2 * num_nodes + 1) / 2)",
            "col = perm - row * (2 * num_nodes - row - 1) // 2",
            "neg_edge_index = torch.stack([row, col], dim=0).long()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3877,
        "label": "no",
        "change": [
            "def _stable_1d_sort(x: torch, N: int = 2049):",
            "n = x.numel()",
            "if N - n > 0:",
            "x_max = x.max()",
            "-        x_pad = torch.cat([x, (x_max + 1) * torch.ones(2049 - n, dtype=x.dtype, device=x.device)], 0)",
            "-    x_sort = x_pad.sort()",
            "-    return x_sort.values[:n], x_sort.indices[:n]",
            "+        x = torch.cat([x, (x_max + 1) * torch.ones(N - n, dtype=x.dtype, device=x.device)], 0)",
            "+    x_sort = x.sort()",
            "+    i = min(N, n)",
            "+    return x_sort.values[:i], x_sort.indices[:i]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3880,
        "label": "yes",
        "change": [
            "def _prepare_output_docstrings(output_type, config_class):",
            "",
            "# Add the return introduction",
            "full_output_type = f\"{output_type.__module__}.{output_type.__name__}\"",
            "-    intro = RETURN_INTRODUCTION.format(full_output_type=full_output_type, config_class=config_class)",
            "+    intro = TF_RETURN_INTRODUCTION if output_type.__name__.startswith(\"TF\") else PT_RETURN_INTRODUCTION",
            "+    intro = intro.format(full_output_type=full_output_type, config_class=config_class)",
            "return intro + docstrings"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 3881,
        "label": "no",
        "change": [
            "def train(args):",
            "rho=0.95, eps=args.eps,",
            "weight_decay=args.weight_decay)",
            "elif args.opt == 'adam':",
            "-            optimizer = torch.optim.Adam(params,",
            "-                                         weight_decay=args.weight_decay)",
            "+        optimizer = torch.optim.Adam(params,",
            "+                                     weight_decay=args.weight_decay)",
            "else:",
            "raise NotImplementedError(\"unknown optimizer: \" + args.opt)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3886,
        "label": "no",
        "change": [
            "def test_copy_linear(lazy):",
            "assert torch.allclose(copied_lin.weight, lin.weight)",
            "assert id(copied_lin.bias) != id(lin.bias)",
            "assert copied_lin.bias.data_ptr() != lin.bias.data_ptr()",
            "-    assert torch.allclose(copied_lin.bias, lin.bias)",
            "+    assert torch.allclose(copied_lin.bias, lin.bias, atol=1e-6)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3887,
        "label": "no",
        "change": [
            "def test_neural_beamformer_bf_output(",
            "assert others[\"mask_spk{}\".format(n)].shape[-2] == ch",
            "assert specs[n - 1].shape == others[\"mask_spk{}\".format(n)][..., 0, :].shape",
            "assert specs[n - 1].shape == input_spectrum[..., 0, :].shape",
            "-        if is_torch_1_9_plus and torch.is_complex(specs[n - 1]):",
            "+        if is_torch_complex_tensor(specs[n - 1]):",
            "assert specs[n - 1].dtype == torch.complex64",
            "else:",
            "assert specs[n - 1].dtype == torch.float"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3889,
        "label": "no",
        "change": [
            "class SampleBatch(dict):",
            "assert torch is not None",
            "for k, v in self.items():",
            "if isinstance(v, np.ndarray) and v.dtype != object:",
            "-                    self[k] = torch.from_numpy(v).to(device)",
            "+                    self[k] = convert_to_torch_tensor(v, device)",
            "else:",
            "raise NotImplementedError",
            "return self"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3890,
        "label": "no",
        "change": [
            "def run(",
            "",
            "if npr == 0:",
            "if nl:",
            "-                    stats.append((correct, *torch.zeros((3, 0))))",
            "+                    stats.append((correct, *torch.zeros((3, 0), device=device)))",
            "continue",
            "",
            "# Predictions"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3891,
        "label": "no",
        "change": [
            "def make_model(num_layers: int = 6,",
            "# Initialize parameters with Glorot / fan_avg.",
            "for p in model.parameters():",
            "if p.dim() > 1:",
            "-            torch.nn.init.xavier_uniform(p)",
            "+            torch.nn.init.xavier_uniform_(p)",
            "return model"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3892,
        "label": "no",
        "change": [
            "class VGG2L(torch.nn.Module):",
            "if self.output is not None:",
            "sequence = self.output(sequence)",
            "",
            "-        if mask is not None:",
            "-            return sequence, self.create_new_mask(mask)",
            "-",
            "-        return sequence, mask",
            "+        return sequence, self.create_new_mask(mask)",
            "",
            "def create_new_conformer_mask(self, mask: torch.Tensor) -> torch.Tensor:",
            "\"\"\"Create a new conformer mask for output sequences."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3901,
        "label": "no",
        "change": [
            "def setup_mixins(policy, obs_space, action_space, config):",
            "ValueNetworkMixin.__init__(policy)",
            "# Set up a tf-var for the moving avg (do this here to make it work with",
            "# eager mode).",
            "-    policy._ma_adv_norm = tf.get_variable(",
            "+    policy._ma_adv_norm = tf1.get_variable(",
            "name=\"moving_average_of_advantage_norm\",",
            "dtype=tf.float32,",
            "initializer=100.0,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3902,
        "label": "no",
        "change": [
            "class CascadeRCNNHead(object):",
            "max_iou_per_box = tf.reduce_max(iou, axis=1)  # N",
            "best_iou_ind = tf.cond(tf.shape(iou)[1] > 0,",
            "lambda: tf.argmax(iou, axis=1),   # #proposal, each in 0~m-1",
            "-                                       lambda: tf.zeros([tf.shape(iou)[0]], dtype=tf.int64))",
            "+                                       lambda: tf.zeros(tf.shape(iou)[0], dtype=tf.int64))",
            "labels_per_box = tf.gather(self.gt_labels, best_iou_ind)",
            "fg_mask = max_iou_per_box >= iou_threshold",
            "fg_inds_wrt_gt = tf.boolean_mask(best_iou_ind, fg_mask)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3905,
        "label": "no",
        "change": [
            "class TFTransfoXLPreTrainedModel(TFPreTrainedModel):",
            "@tf.function(",
            "input_signature=[",
            "{",
            "-                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),",
            "+                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),",
            "}",
            "]",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3907,
        "label": "no",
        "change": [
            "class NativeMixedPrecisionPlugin(MixedPrecisionPlugin):",
            "@contextmanager",
            "def train_step_context(self) -> Generator[autocast, None, None]:",
            "\"\"\"Enable autocast context\"\"\"",
            "-        yield torch.cuda.amp.autocast()",
            "+        with torch.cuda.amp.autocast():",
            "+            yield"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3908,
        "label": "no",
        "change": [
            "class VPGModel(PGModel):",
            "self.log_probabilities = self.dist.log_prob(self.policy.get_policy_variables(), self.actions)",
            "",
            "# Concise: Get log likelihood of actions, weigh by advantages, compute gradient on that",
            "-            self.loss = -tf.reduce_mean(self.log_probabilities * self.advantage, name=\"loss_op\")",
            "+            self.loss = -tf.reduce_mean(self.log_probabilities * self.advantage, name=\"loss_op\", axis=1)",
            "",
            "self.optimize_op = self.optimizer.minimize(self.loss)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3913,
        "label": "no",
        "change": [
            "def bleu_score(",
            "assert len(translate_corpus) == len(reference_corpus)",
            "numerator = torch.zeros(n_gram)",
            "denominator = torch.zeros(n_gram)",
            "-    precision_scores = torch.zeros(n_gram)",
            "c = 0.0",
            "r = 0.0"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3915,
        "label": "yes",
        "change": [
            "class RolloutWorker(EvaluatorInterface, ParallelIteratorWorker):",
            "policy_config = policy_config or {}",
            "if (tf and policy_config.get(\"eager\")",
            "and not policy_config.get(\"no_eager_on_workers\")):",
            "-            tf.enable_eager_execution()",
            "+            # This check is necessary for certain all-framework tests that",
            "+            # use tf's eager_mode() context generator.",
            "+            if not tf.executing_eagerly():",
            "+                tf.enable_eager_execution()",
            "",
            "if log_level:",
            "logging.getLogger(\"ray.rllib\").setLevel(log_level)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 3918,
        "label": "no",
        "change": [
            "class DeepQNetwork:",
            "t_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='target_net')",
            "e_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='eval_net')",
            "",
            "-        with tf.variable_scope('soft_replacement'):",
            "+        with tf.variable_scope('hard_replacement'):",
            "self.target_replace_op = [tf.assign(t, e) for t, e in zip(t_params, e_params)]",
            "",
            "self.sess = tf.Session()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3925,
        "label": "no",
        "change": [
            "class Synthesizer(object):",
            "wav = self.pwgan.inference(vocoder_input, hop_size=self.ap.hop_length)",
            "elif self.wavernn:",
            "vocoder_input = None",
            "-                if self.tts_config.model == \"Tacotron\" :",
            "-                    vocoder_input = torch.FloatTensor(self.ap.out_linear_to_mel(linear_spec = postnet_output.T).T).T.unsqueeze(0)",
            "+                if self.tts_config.model == \"Tacotron\":",
            "+                    vocoder_input = torch.FloatTensor(self.ap.out_linear_to_mel(linear_spec=postnet_output.T).T).T.unsqueeze(0)",
            "else:",
            "vocoder_input = torch.FloatTensor(postnet_output.T).unsqueeze(0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3927,
        "label": "no",
        "change": [
            "class NUTS(HMC):",
            "else:",
            "new_tree_prob = new_tree.weight / tree_weight",
            "rand = pyro.sample(\"rand_t={}_treedepth={}\".format(self._t, tree_depth),",
            "-                                   dist.Uniform(torch.zeros(1), torch.ones(1)))",
            "+                                   dist.Uniform(new_tree_prob.new_tensor(0.),",
            "+                                                new_tree_prob.new_tensor(1.)))",
            "if rand < new_tree_prob:",
            "accepted = True",
            "z = new_tree.z_proposal"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3930,
        "label": "no",
        "change": [
            "def run(weights=ROOT / 'yolov5s.pt',  # model.pt path(s)",
            "# check_requirements(('opencv-python>=4.5.4',))",
            "net = cv2.dnn.readNetFromONNX(w)",
            "else:",
            "-            check_requirements(('onnx', 'onnxruntime'))",
            "+            check_requirements(('onnx', 'onnxruntime-gpu' if torch.has_cuda else 'onnxruntime'))",
            "import onnxruntime",
            "session = onnxruntime.InferenceSession(w, None)",
            "else:  # TensorFlow models"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3932,
        "label": "no",
        "change": [
            "class TestDrawRectangle:",
            "points_list.append([])",
            "for n in range(N):",
            "points_list[b].append([])",
            "-                points_list[b][n].append(int(torch.randint(0, w - 1, (1,))))",
            "-                points_list[b][n].append(int(torch.randint(0, h - 1, (1,))))",
            "-                points_list[b][n].append(int(torch.randint(points_list[b][n][-2] + 1, w, (1,))))",
            "-                points_list[b][n].append(int(torch.randint(points_list[b][n][-2] + 1, h, (1,))))",
            "+                points_list[b][n].append(int(torch.randint(0, w - 1, (1, ))))",
            "+                points_list[b][n].append(int(torch.randint(0, h - 1, (1, ))))",
            "+                points_list[b][n].append(int(torch.randint(points_list[b][n][-2] + 1, w, (1, ))))",
            "+                points_list[b][n].append(int(torch.randint(points_list[b][n][-2] + 1, h, (1, ))))",
            "",
            "points = torch.tensor(points_list).to(device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3934,
        "label": "no",
        "change": [
            "if __name__ == '__main__':",
            "evaluator(model)",
            "",
            "pruner._unwrap_model()",
            "-    ModelSpeedup(model, dummy_input=torch.rand(10, 3, 32, 32).to(device), masks_file='simple_masks.pth').speedup_model()",
            "+    ModelSpeedup(model, dummy_input=torch.rand(10, 3, 32, 32).to(device), masks_file=masks).speedup_model()",
            "",
            "print('\\nThe accuracy after speed up:')",
            "evaluator(model)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3938,
        "label": "no",
        "change": [
            "class DeformableDetrModel(DeformableDetrPreTrainedModel):",
            "spatial_shapes = torch.as_tensor(spatial_shapes, dtype=torch.long, device=source_flatten.device)",
            "level_start_index = torch.cat((spatial_shapes.new_zeros((1,)), spatial_shapes.prod(1).cumsum(0)[:-1]))",
            "valid_ratios = torch.stack([self.get_valid_ratio(m) for m in masks], 1)",
            "-",
            "-        # revert valid_ratios",
            "-        valid_ratios = ~valid_ratios.bool()",
            "valid_ratios = valid_ratios.float()",
            "",
            "# Fourth, sent source_flatten + mask_flatten + lvl_pos_embed_flatten (backbone + proj layer output) through encoder"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3942,
        "label": "no",
        "change": [
            "trunc.unsupported_dtypes = (\"float16\",)",
            "",
            "",
            "def abs(",
            "-    x: Union[float, torch.Tensor],",
            "-    *,",
            "-    out: Optional[torch.Tensor] = None",
            "+    x: Union[float, torch.Tensor], *, out: Optional[torch.Tensor] = None",
            ") -> torch.Tensor:",
            "x = _cast_for_unary_op(x)",
            "return torch.abs(x, out=out)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3947,
        "label": "yes",
        "change": [
            "class Model(object):",
            "",
            "elif action_spec['type'] == 'float':",
            "if 'min_value' in action_spec:",
            "-                    exploration = tf.clip_by_value(",
            "+                    exploration_value = tf.clip_by_value(",
            "t=exploration_value,",
            "clip_value_min=action_spec['min_value'],",
            "clip_value_max=action_spec['max_value']",
            ")",
            "",
            "-                action += tf.reshape(exploration, tf.shape(action))",
            "+                action += tf.reshape(exploration_value, tf.shape(action))",
            "",
            "return action"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3948,
        "label": "no",
        "change": [
            "class TFGPTJModelLanguageGenerationTest(unittest.TestCase):",
            ")  # token_type_ids should change output",
            "",
            "@slow",
            "+    @unittest.skip(reason=\"TF generate currently has no time-based stopping criteria\")",
            "def test_gptj_sample_max_time(self):",
            "tokenizer = AutoTokenizer.from_pretrained(\"anton-l/gpt-j-tiny-random\")",
            "model = TFGPTJForCausalLM.from_pretrained(\"anton-l/gpt-j-tiny-random\", from_pt=True)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3949,
        "label": "no",
        "change": [
            "class ConditionalRandomField(torch.nn.Module):",
            "tag_sequence[sequence_length + 1, end_tag] = 0.",
            "",
            "# We pass the tags and the transitions to ``viterbi_decode``.",
            "-            viterbi_path, _ = util.viterbi_decode(tag_sequence[:(sequence_length + 2)], transitions)",
            "+            viterbi_path, viterbi_score = util.viterbi_decode(tag_sequence[:(sequence_length + 2)], transitions)",
            "# Get rid of START and END sentinels and append.",
            "-            all_tags.append(viterbi_path[1:-1])",
            "+            viterbi_path = viterbi_path[1:-1]",
            "+            best_paths.append((viterbi_path, viterbi_score.item()))",
            "",
            "-        return all_tags",
            "+        return best_paths"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3951,
        "label": "no",
        "change": [
            "def zca_mean(",
            "else:",
            "cov = cov / float(N)",
            "",
            "-    U, S, _ = _torch_svd_cast(cov)",
            "+    U, S, _ = torch.linalg.svd(cov)",
            "",
            "S = S.reshape(-1, 1)",
            "S_inv_root: torch.Tensor = torch.rsqrt(S + eps)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3952,
        "label": "no",
        "change": [
            "def testLog():",
            "",
            "Ptensor = PolynomialTensor()",
            "",
            "-    x = torch.randn(50000)",
            "-",
            "+    x = torch.randn(50000)",
            "+",
            "print(x)",
            "",
            "m = torch.nn.tanh()",
            "ten = m(x)",
            "",
            "assert (EvalError(ten, Ptensor.log(x))) == True",
            "-",
            "-testExp()",
            "",
            "+",
            "+testExp()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3953,
        "label": "no",
        "change": [
            "class Bernoulli(Distribution):",
            "Reparameterized Bernoulli sampler.",
            "\"\"\"",
            "_ps = self._sanitize_input(ps)",
            "-        return torch.bernoulli(_ps)",
            "+        return torch.bernoulli(_ps).type_as(_ps)",
            "",
            "def log_pdf(self, x, ps=None, batch_size=1, *args, **kwargs):",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3955,
        "label": "no",
        "change": [
            "def normalize_min_max(x: torch.Tensor, min_val: float = 0., max_val: float = 1.,",
            "x_min: torch.Tensor = x.view(B, C, -1).min(-1)[0].view(B, C, 1)",
            "x_max: torch.Tensor = x.view(B, C, -1).max(-1)[0].view(B, C, 1)",
            "",
            "-    x_out: torch.Tensor = (",
            "-        (max_val - min_val) * (x.view(B, C, -1) - x_min) / (x_max - x_min + eps) + min_val",
            "-    )",
            "+    x_out: torch.Tensor = ((max_val - min_val) * (x.view(B, C, -1) - x_min) / (x_max - x_min + eps) + min_val)",
            "return x_out.view(shape)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3960,
        "label": "yes",
        "change": [
            "class TestRandomPerspective:",
            "assert out_perspective[0].shape == x_data.shape",
            "assert out_perspective[1].shape == (1, 3, 3)",
            "assert_allclose(out_perspective[0], x_data)",
            "-        assert_allclose(out_perspective[1], torch.eye(3, device=device))",
            "+        assert_allclose(out_perspective[1], torch.eye(3, device=device)[None])",
            "",
            "def test_transform_module_should_return_expected_transform(self, device):",
            "torch.manual_seed(0)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 3963,
        "label": "yes",
        "change": [
            "def average_grads(all_grads):",
            "for grad_and_vars in zip(*all_grads):",
            "# Ngpu * 2",
            "v = grad_and_vars[0][1]",
            "-            all_grads = [g for (g, _) in grad_and_vars]",
            "+            grads = [g for (g, _) in grad_and_vars]",
            "",
            "with tf.device(v.device):       # colocate summed grad with var",
            "grad = tf.multiply(",
            "-                    tf.add_n(all_grads), 1.0 / nr_tower)",
            "+                    tf.add_n(grads), 1.0 / nr_tower)",
            "ret.append((grad, v))",
            "return ret"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3966,
        "label": "no",
        "change": [
            "class SD(DiffusionInpaintModel):",
            "callback=self.callback,",
            "height=img_h,",
            "width=img_w,",
            "+            generator=torch.manual_seed(config.sd_seed)",
            ").images[0]",
            "",
            "output = (output * 255).round().astype(\"uint8\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3968,
        "label": "no",
        "change": [
            "class Attention(nn.Module):",
            "w = w / (v.size(-1) ** 0.5)",
            "nd, ns = w.size(-2), w.size(-1)",
            "mask = self.bias[:, :, ns - nd : ns, :ns]",
            "-        w = torch.where(mask, w, self.masked_bias)",
            "+        w = torch.where(mask, w, self.masked_bias.to(w.dtype))",
            "",
            "if attention_mask is not None:",
            "# Apply the attention mask"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3969,
        "label": "no",
        "change": [
            "def highway_convolutional_network(input_units,",
            "kernel_initializer=xavier_initializer())",
            "if use_batch_norm:",
            "units = tf.layers.batch_normalization(units, training=training_ph)",
            "-        sigmoid_gate = tf.layers.dense(input_units, activation=tf.sigmoid, kernel_initializer=xavier_initializer())",
            "+        sigmoid_gate = tf.layers.dense(input_units, 1, activation=tf.sigmoid, kernel_initializer=xavier_initializer())",
            "input_units = sigmoid_gate * input_units + (1 - sigmoid_gate) * units",
            "input_units = tf.nn.relu(input_units)",
            "return input_units"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3971,
        "label": "no",
        "change": [
            "\"        \\n\",",
            "\"        # calculate critic (value) loss using L1 smooth loss\\n\",",
            "\"        value_losses.append(remote_torch.nn.functional.smooth_l1_loss(value,\\n\",",
            "-    \"                                                                remote_torch.Tensor([R])))\\n\",",
            "+    \"                                                                R.reshape(1)))\\n\",",
            "\"    # reset gradients    \\n\",",
            "\"    optimizer.zero_grad()\\n\",",
            "\"    \\n\","
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3974,
        "label": "no",
        "change": [
            "def elastic_transform2d(image: torch.Tensor,",
            "# Warp image based on displacement matrix",
            "b, c, h, w = image.shape",
            "grid = kornia.utils.create_meshgrid(h, w, device=image.device).to(image.dtype)",
            "-    warped = F.grid_sample(",
            "-        image, (grid + disp).clamp(-1, 1), align_corners=align_corners, mode=mode)",
            "+    warped = F.grid_sample(image, (grid + disp).clamp(-1, 1), align_corners=align_corners, mode=mode)",
            "",
            "return warped"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3975,
        "label": "no",
        "change": [
            "def linspace(",
            "",
            "@with_unsupported_dtypes({\"2.9.1 and below\": (\"bool\",)}, backend_version)",
            "def meshgrid(",
            "-    *arrays: Union[tf.Tensor, tf.Variable], sparse: bool = False, indexing: str = \"xy\"",
            "+    *arrays: Union[tf.Tensor, tf.Variable],",
            "+    sparse: bool = False,",
            "+    indexing: str = \"xy\",",
            ") -> List[Union[tf.Tensor, tf.Variable]]:",
            "if not sparse:",
            "return tf.meshgrid(*arrays, indexing=indexing)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3976,
        "label": "no",
        "change": [
            "def select_device(device='', batch_size=None):",
            "p = torch.cuda.get_device_properties(i)",
            "s += f\"{'' if i == 0 else space}CUDA:{d} ({p.name}, {p.total_memory / 1024 ** 2}MB)\\n\"  # bytes to MB",
            "else:",
            "-        s += 'CPU'",
            "+        s += 'CPU\\n'",
            "",
            "-    logger.info(f'{s}\\n')  # skip a line",
            "+    logger.info(s)  # skip a line",
            "return torch.device('cuda:0' if cuda else 'cpu')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3978,
        "label": "no",
        "change": [
            "class TestCnnHighwayEncoder(AllenNlpTestCase):",
            "encoder = TimeDistributed(encoder)",
            "",
            "embedding = torch.from_numpy(np.random.randn(5, 6, 50, 4)).float()",
            "-        mask = torch.ones(5, 6, 50).long()",
            "+        mask = torch.ones(5, 6, 50).bool()",
            "token_embedding = encoder(embedding, mask)",
            "",
            "assert list(token_embedding.size()) == [5, 6, 16]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3979,
        "label": "no",
        "change": [
            "def main():",
            "log_level=trt.Logger.INFO,",
            "max_workspace_size=(1 << 32),",
            ")",
            "-    torch.save(model_trt.state_dict(), os.path.join(file_name, 'model_trt.pth'))",
            "+    torch.save(model_trt.state_dict(), os.path.join(file_name, \"model_trt.pth\"))",
            "logger.info(\"Converted TensorRT model done.\")",
            "-    engine_file = os.path.join(file_name, 'model_trt.engine')",
            "-    engine_file_demo = os.path.join('demo', 'TensorRT', 'cpp', 'model_trt.engine')",
            "-    with open(engine_file, 'wb') as f:",
            "+    engine_file = os.path.join(file_name, \"model_trt.engine\")",
            "+    engine_file_demo = os.path.join(\"demo\", \"TensorRT\", \"cpp\", \"model_trt.engine\")",
            "+    with open(engine_file, \"wb\") as f:",
            "f.write(model_trt.engine.serialize())",
            "",
            "shutil.copyfile(engine_file, engine_file_demo)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3981,
        "label": "no",
        "change": [
            "if K.backend() == 'cntk':",
            "supports_sparse = False",
            "elif K.backend() == 'theano' and not KTH.th_sparse_module:",
            "supports_sparse = False",
            "-else:",
            "-    supports_sparse = True",
            "+elif K.backend() == 'tensorflow':",
            "+    # Must wait for tf.keras to support sparse ops.",
            "+    supports_sparse = False",
            "",
            "",
            "def check_dtype(var, dtype):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3982,
        "label": "yes",
        "change": [
            "from ivy.container import Container",
            "",
            "",
            "def variable(x):",
            "-    with ivy.dev(x, as_native=True):",
            "+    with tf.device(ivy.dev(x, as_native=True)):",
            "return tf.Variable(x, trainable=True)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 3983,
        "label": "no",
        "change": [
            "class MetricInfo:",
            "for key, value in self.features.items():",
            "if not isinstance(value, Value):",
            "raise ValueError(",
            "-                        f\"When using 'numpy' format, all features should be a `nlp.Value` feature. \"",
            "+                        f\"When using 'numpy' format, all features should be a `datasets.Value` feature. \"",
            "f\"Here {key} is an instance of {value.__class__.__name__}\"",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3986,
        "label": "no",
        "change": [
            "class E2E(STInterface, torch.nn.Module):",
            "att_ws = self.dec.calculate_all_attentions(",
            "hpad, hlens, ys_pad, lang_ids=tgt_lang_ids",
            ")",
            "-",
            "+        self.train()",
            "return att_ws",
            "",
            "def subsample_frames(self, x):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3987,
        "label": "no",
        "change": [
            "from keras.testing_infra import test_utils",
            "def create_mirrored_strategy():",
            "# The test creates two virtual CPUs, and we use both of them to test with",
            "# multiple devices.",
            "+    # pylint: disable=protected-access",
            "+    tf.distribute.MirroredStrategy._collective_key_base += 1",
            "return tf.distribute.MirroredStrategy([\"cpu:0\", \"cpu:1\"])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3988,
        "label": "no",
        "change": [
            "def test_frontend_backward_multi_channel(train, use_wpe, use_beamformer):",
            "frontend.train()",
            "else:",
            "frontend.eval()",
            "-    torch.random.manual_seed(14)",
            "+    set_all_random_seed(14)",
            "x = torch.randn(2, 1000, 2, requires_grad=True)",
            "x_lengths = torch.LongTensor([1000, 980])",
            "y, y_lengths = frontend(x, x_lengths)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3989,
        "label": "no",
        "change": [
            "def attn(x, scope, n_state, *, past, params, block_offset=0, train=False):",
            "return mtf.transformer.attention.visibility_mask_to_attention_bias(vis, dtype)",
            "",
            "with tf.variable_scope(scope):",
            "-        dim_qkv = mtf.Dimension(\"qkv\", n_state * 3)",
            "+        dim_qkv = mtf.Dimension(\"qkv\", n_state.size * 3)",
            "c = conv1d(x, 'c_attn', dim_qkv, params=params)",
            "",
            "conv_output_channels = c.shape[2]  # should be equal to dim_qkv"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3991,
        "label": "no",
        "change": [
            "def build_q_losses(policy: Policy, model, _, train_batch: SampleBatch) -> Tensor",
            "q_tp1_best,",
            "q_dist_tp1_best,",
            "train_batch[PRIO_WEIGHTS],",
            "-        train_batch[SampleBatch.REWARDS],",
            "+        tf.cast(train_batch[SampleBatch.REWARDS], tf.float32),",
            "tf.cast(train_batch[SampleBatch.DONES], tf.float32),",
            "config[\"gamma\"],",
            "config[\"n_step\"],"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3992,
        "label": "yes",
        "change": [
            "class Deterministic(TFActionDistribution):",
            "return self.inputs",
            "",
            "@override(TFActionDistribution)",
            "-    def sampled_action_logp(self):",
            "-        return 0.0",
            "+    def logp(self, x):",
            "+        return tf.zeros_like(self.inputs)",
            "",
            "@override(TFActionDistribution)",
            "def _build_sample_op(self):"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 3993,
        "label": "no",
        "change": [
            "def find_fundamental(points1: torch.Tensor, points2: torch.Tensor, weights: torc",
            "",
            "# reconstruct and force the matrix to have rank2",
            "U, S, V = torch.svd(F_mat)",
            "-    rank_mask = torch.tensor([1.0, 1.0, 0.0],",
            "-                             device=F_mat.device,",
            "-                             dtype=F_mat.dtype)",
            "+    rank_mask = torch.tensor([1.0, 1.0, 0.0], device=F_mat.device, dtype=F_mat.dtype)",
            "",
            "F_projected = U @ (torch.diag_embed(S * rank_mask) @ V.transpose(-2, -1))",
            "F_est = transform2.transpose(-2, -1) @ (F_projected @ transform1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4000,
        "label": "yes",
        "change": [
            "def test_cholesky_transform(batch_shape, dim, transform):",
            "assert_close(log_det, torch.slogdet(jacobian)[1])",
            "",
            "assert log_det.shape == batch_shape",
            "-    assert_close(y, x_mat.cholesky())",
            "+    assert_close(y, torch.linalg.cholesky(x_mat))",
            "assert_close(transform.inv(y), x_mat)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 4004,
        "label": "no",
        "change": [
            "class LightningDistributed:",
            "if self.rank != 0:",
            "obj = [None] * len(obj)",
            "",
            "-        broadcast_object_list(obj, 0, group=group or _group.WORLD)",
            "+        torch.distributed.broadcast_object_list(obj, 0, group=group or _group.WORLD)",
            "",
            "return obj[0]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4006,
        "label": "no",
        "change": [
            "class SequenceTagger(flair.nn.Model):",
            "for sentence_feats, sentence_tags, sentence_length in zip(features, tags, lengths):",
            "sentence_feats = sentence_feats[:sentence_length]",
            "",
            "-                # print(sentence_tags)",
            "-                # tag_tensor = torch.LongTensor(sentence_tags)",
            "-                # tag_tensor = tag_tensor.to(flair.device)",
            "-",
            "score += torch.nn.functional.cross_entropy(sentence_feats, sentence_tags)",
            "",
            "return score"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4008,
        "label": "no",
        "change": [
            "class VersatileDiffusionImageVariationPipeline(DiffusionPipeline):",
            "`pipeline.enable_sequential_cpu_offload()` the execution device can only be inferred from Accelerate's module",
            "hooks.",
            "\"\"\"",
            "-        if self.device != torch.device(\"meta\") or not hasattr(self.image_unet, \"_hf_hook\"):",
            "+        if not hasattr(self.image_unet, \"_hf_hook\"):",
            "return self.device",
            "for module in self.image_unet.modules():",
            "if ("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4011,
        "label": "no",
        "change": [
            "def remainder(",
            "return tf.math.floormod(x1, x2)",
            "",
            "",
            "-def round(",
            "-    x: Union[tf.Tensor, tf.Variable]",
            "-) -> Union[tf.Tensor, tf.Variable]:",
            "+def round(x: Union[tf.Tensor, tf.Variable]) -> Union[tf.Tensor, tf.Variable]:",
            "if \"int\" in str(x.dtype):",
            "return x",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4016,
        "label": "no",
        "change": [
            "else:",
            "sd_model = sd_model.to(device)",
            "",
            "model_hijack = StableDiffusionModelHijack()",
            "-model_hijack.hijack(sd_model)",
            "+#model_hijack.hijack(sd_model)",
            "",
            "with open(os.path.join(script_path, \"style.css\"), \"r\", encoding=\"utf8\") as file:",
            "css = file.read()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4017,
        "label": "no",
        "change": [
            "def diff(",
            "axis: Optional[int] = -1,",
            "prepend: Optional[Union[torch.Tensor, int, float, list, tuple]] = None,",
            "append: Optional[Union[torch.Tensor, int, float, list, tuple]] = None,",
            "+    out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "x = x if type(x) == torch.Tensor else torch.Tensor(x)",
            "prepend = ("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4018,
        "label": "no",
        "change": [
            "class Normal(Distribution):",
            "def _sanitize_input(self, mu, sigma):",
            "if mu is not None:",
            "# stateless distribution",
            "-            mu = torch.unsqueeze(mu, 1)",
            "return mu, sigma",
            "elif self.mu is not None:",
            "# stateful distribution"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4019,
        "label": "no",
        "change": [
            "def random_hflip(input, p=0.5):",
            "probs: torch.Tensor = torch.empty(input.shape[0], device=device).uniform_(0, 1)",
            "else:",
            "input = input.unsqueeze(0)",
            "-        probs: torch.Tensor = torch.empty(1, device=device).uniform_(0, 1)",
            "+        probs = torch.empty(1, device=device).uniform_(0, 1)",
            "",
            "to_flip: torch.Tensor = probs < p",
            "",
            "if input[to_flip].nelement() != 0:",
            "",
            "-        flipped: torch.Tensor = flips.hflip(input[to_flip])",
            "+        flipped: torch.Tensor = hflip(input[to_flip])",
            "trans_mat: torch.Tensor = torch.zeros((3, 3))",
            "trans_mat[0][0] = -1",
            "trans_mat[1][1] = 1"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4025,
        "label": "yes",
        "change": [
            "class SimpleTaggerTest(AllenNlpTestCase):",
            "training_arrays = self.dataset.as_arrays()",
            "",
            "# TODO(Mark): clean this up once the Trainer is finalised.",
            "-        sequence = training_arrays[\"tokens\"][0]",
            "+        sequence = training_arrays[\"tokens\"][\"tokens\"]",
            "tags = training_arrays[\"tags\"]",
            "-        training_arrays = {\"tokens\": Variable(torch.from_numpy(sequence)),  # pylint: disable=no-member",
            "+        training_arrays = {\"tokens\": {\"tokens\": Variable(torch.from_numpy(sequence))},  # pylint: disable=no-member",
            "\"tags\": Variable(torch.from_numpy(tags))}  # pylint: disable=no-member",
            "_ = self.model.forward(**training_arrays)",
            "",
            "def test_tag_returns_distributions_per_token(self):",
            "-        text = TextField([\"This\", \"is\", \"a\", \"sentence\"], token_indexers=[SingleIdTokenIndexer()])",
            "+        text = TextField([\"This\", \"is\", \"a\", \"sentence\"], token_indexers={\"tokens\": SingleIdTokenIndexer()})",
            "output = self.model.tag(text)",
            "possible_tags = self.vocab.get_index_to_token_vocabulary(\"tags\").values()",
            "for tag in output[\"tags\"]:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 4029,
        "label": "no",
        "change": [
            "class LightTestStepMultipleDataloadersMixin:",
            "class LightTestFitSingleTestDataloadersMixin:",
            "\"\"\"Test fit single test dataloaders mixin.\"\"\"",
            "",
            "+    def test_dataloader(self):",
            "+        return self._dataloader(train=False)",
            "+",
            "def test_step(self, batch, batch_idx, *args, **kwargs):",
            "\"\"\"",
            "Lightning calls this inside the validation loop"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4031,
        "label": "no",
        "change": [
            "class CrossAttention(nn.Module):",
            "for i in range(hidden_states.shape[0] // slice_size):",
            "start_idx = i * slice_size",
            "end_idx = (i + 1) * slice_size",
            "-            attn_slice = (",
            "-                torch.einsum(\"b i d, b j d -> b i j\", query[start_idx:end_idx], key[start_idx:end_idx]) * self.scale",
            "-            )",
            "+            attn_slice = torch.matmul(query[start_idx:end_idx], key[start_idx:end_idx].transpose(1, 2)) * self.scale",
            "attn_slice = attn_slice.softmax(dim=-1)",
            "-            attn_slice = torch.einsum(\"b i j, b j d -> b i d\", attn_slice, value[start_idx:end_idx])",
            "+            attn_slice = torch.matmul(attn_slice, value[start_idx:end_idx])",
            "",
            "hidden_states[start_idx:end_idx] = attn_slice"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4033,
        "label": "no",
        "change": [
            "def build_vtrace_loss(policy, model, dist_class, train_batch):",
            "if isinstance(policy.action_space, gym.spaces.Discrete):",
            "is_multidiscrete = False",
            "output_hidden_shape = [policy.action_space.n]",
            "-    elif isinstance(policy.action_space,",
            "-                    gym.spaces.multi_discrete.MultiDiscrete):",
            "+    elif isinstance(policy.action_space, gym.spaces.MultiDiscrete):",
            "is_multidiscrete = True",
            "output_hidden_shape = policy.action_space.nvec.astype(np.int32)",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4034,
        "label": "no",
        "change": [
            "class TestTorchVariable(TestCase):",
            "x = Var(torch.FloatTensor([1, 2, -3, 4, 5])).send(remote)",
            "assert torch.equal(x.ceil().get(), Var(torch.FloatTensor([1, 2, -3, 4, 5])))",
            "assert torch.equal(x.ceil_().get(), Var(torch.FloatTensor([1, 2, -3, 4, 5])))",
            "-        assert torch.equal(x.cpu().get(), Var(torch.FloatTensor([1, 2, -3, 4, 5])))",
            "\\ No newline at end of file",
            "+        assert torch.equal(x.cpu().get(), Var(torch.FloatTensor([1, 2, -3, 4, 5])))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4035,
        "label": "no",
        "change": [
            "class BatchNormLayer(Layer):",
            "params_shape = x_shape[-1:]",
            "",
            "from tensorflow.python.training import moving_averages",
            "-        from tensorflow.python.ops import control_flow_ops",
            "",
            "-        with tf.variable_scope(name) as vs:",
            "+        with tf.variable_scope(name):",
            "axis = list(range(len(x_shape) - 1))",
            "",
            "# 1. beta, gamma"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4037,
        "label": "no",
        "change": [
            "class HLGD(datasets.GeneratorBasedBuilder):",
            "\"date_b\": datasets.Value(\"string\"),",
            "\"url_a\": datasets.Value(\"string\"),",
            "\"url_b\": datasets.Value(\"string\"),",
            "-                \"label\": datasets.features.ClassLabel(names=[\"different_event\", \"same_event\"]),",
            "+                \"label\": datasets.features.ClassLabel(names=[\"same_event\", \"different_event\"]),",
            "}",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4038,
        "label": "no",
        "change": [
            "class ResNestBottleneck(nn.Module):",
            "self.downsample = downsample",
            "",
            "def zero_init_last(self):",
            "-        nn.init.zeros_(self.bn3.weight)",
            "+        if getattr(self.bn3, 'weight', None) is not None:",
            "+            nn.init.zeros_(self.bn3.weight)",
            "",
            "def forward(self, x):",
            "shortcut = x"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4040,
        "label": "yes",
        "change": [
            "def main():",
            "global_step += 1",
            "",
            "# Save a trained model",
            "-        logger.info(\"** ** * Saving fine - tuned model ** ** * \")",
            "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self",
            "output_model_file = os.path.join(args.output_dir, WEIGHTS_NAME)",
            "output_config_file = os.path.join(args.output_dir, CONFIG_NAME)",
            "-        if args.do_train:",
            "+        if args.do_train and torch.distributed.get_rank() == 0:",
            "+            logger.info(\"** ** * Saving fine - tuned model ** ** * \")",
            "torch.save(model_to_save.state_dict(), output_model_file)",
            "model_to_save.config.to_json_file(output_config_file)",
            "tokenizer.save_vocabulary(args.output_dir)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 4042,
        "label": "no",
        "change": [
            "class LatentDiffusion(DiffusionPipeline):",
            "# 3. optionally sample variance",
            "variance = 0",
            "if eta > 0:",
            "-                noise = torch.randn(image.shape, generator=generator)to(image.device)",
            "+                noise = torch.randn(image.shape, generator=generator).to(image.device)",
            "variance = self.noise_scheduler.get_variance(t, num_inference_steps).sqrt() * eta * noise",
            "",
            "# 4. set current image to prev_image: x_t -> x_t-1"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4046,
        "label": "no",
        "change": [
            "def vflip(input: torch.Tensor) -> torch.Tensor:",
            "\"\"\"",
            "",
            "h = input.shape[-2]",
            "-    return input[..., torch.arange(h - 1, -1, -1), :]",
            "+    return input[..., torch.arange(h - 1, -1, -1, device=input.device), :]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4048,
        "label": "no",
        "change": [
            "def main(argv=None):",
            "facenet.plot_roc(fpr, tpr, 'NN4')",
            "",
            "if __name__ == '__main__':",
            "-  tf.app.run()",
            "+    tf.app.run()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4054,
        "label": "no",
        "change": [
            "class BLEU(Metric):",
            "",
            "None",
            "\"\"\"",
            "-        predictions, gold_targets = self.unwrap_to_tensors(predictions, gold_targets)",
            "+        predictions, gold_targets = self.detach_tensors(predictions, gold_targets)",
            "for ngram_size, _ in enumerate(self._ngram_weights, start=1):",
            "precision_matches, precision_totals = self._get_modified_precision_counts(",
            "predictions, gold_targets, ngram_size"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4056,
        "label": "no",
        "change": [
            "class TFGenerationMixin:",
            "generated, finished_sequences, cur_len, model_kwargs, next_step_cached_variables",
            "):",
            "maximum_iterations = max_length - cur_len",
            "-            generated, _, cur_len, _, _, = tf.while_loop(",
            "+            (",
            "+                generated,",
            "+                _,",
            "+                cur_len,",
            "+                _,",
            "+                _,",
            "+            ) = tf.while_loop(",
            "contrastive_search_cond_fn,",
            "contrastive_search_body_fn,",
            "(generated, finished_sequences, cur_len, model_kwargs, next_step_cached_variables),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4058,
        "label": "no",
        "change": [
            "class GANModelDesc(ModelDesc):",
            "d_pos_acc = tf.reduce_mean(tf.cast(score_real > 0.5, tf.float32), name='accuracy_real')",
            "d_neg_acc = tf.reduce_mean(tf.cast(score_fake < 0.5, tf.float32), name='accuracy_fake')",
            "",
            "-                self.d_accuracy = tf.add(.5 * d_pos_acc, .5 * d_neg_acc, name='accuracy')",
            "+                d_accuracy = tf.add(.5 * d_pos_acc, .5 * d_neg_acc, name='accuracy')",
            "self.d_loss = tf.add(.5 * d_loss_pos, .5 * d_loss_neg, name='loss')",
            "",
            "with tf.name_scope(\"gen\"):",
            "self.g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(",
            "logits=logits_fake, labels=tf.ones_like(logits_fake)), name='loss')",
            "-                self.g_accuracy = tf.reduce_mean(tf.cast(score_fake > 0.5, tf.float32), name='accuracy')",
            "+                g_accuracy = tf.reduce_mean(tf.cast(score_fake > 0.5, tf.float32), name='accuracy')",
            "",
            "-            add_moving_summary(self.g_loss, self.d_loss, self.d_accuracy, self.g_accuracy)",
            "+            add_moving_summary(self.g_loss, self.d_loss, d_accuracy, g_accuracy)",
            "",
            "",
            "class GANTrainer(FeedfreeTrainerBase):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4060,
        "label": "no",
        "change": [
            "class ReshapeLayer(Layer):",
            "",
            "",
            "class TransposeLayer(Layer):",
            "-    \"\"\"",
            "-    The :class:`TransposeLayer` class transposes the dimension of a teneor, see `tf.transpose() <https://www.tensorflow.org/api_docs/python/tf/transpose>`__ .",
            "+    \"\"\"A layer that transposes the dimension of a tensor.",
            "+",
            "+    See `tf.transpose() <https://www.tensorflow.org/api_docs/python/tf/transpose>`__ .",
            "",
            "Parameters"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4064,
        "label": "no",
        "change": [
            "class Tacotron2(TacotronAbstract):",
            "if self.num_speakers > 1:",
            "if not self.embeddings_per_sample:",
            "speaker_embeddings = self.speaker_embedding(speaker_ids)[:, None]",
            "+                speaker_embeddings = torch.unsqueeze(speaker_embeddings, 0).transpose(1, 2)",
            "encoder_outputs = self._concat_speaker_embedding(encoder_outputs, speaker_embeddings)",
            "",
            "mel_outputs, alignments, stop_tokens = self.decoder.inference_truncated(encoder_outputs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4066,
        "label": "no",
        "change": [
            "class TorchParametricActionsModel(DQNTorchModel):",
            "# Mask out invalid actions (use -inf to tag invalid).",
            "# These are then recognized by the EpsilonGreedy exploration component",
            "# as invalid actions that are not to be chosen.",
            "-        inf_mask = torch.clamp(",
            "-            torch.log(action_mask), -float(\"inf\"), float(\"inf\"))",
            "+        inf_mask = torch.clamp(torch.log(action_mask), FLOAT_MIN, FLOAT_MAX)",
            "+",
            "return action_logits + inf_mask, state",
            "",
            "def value_function(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4067,
        "label": "yes",
        "change": [
            "def triu_inverse(x):",
            "B_Dinv = B / x.bottom_diag.unsqueeze(-2)",
            "",
            "identity = torch.eye(head_size, dtype=A.dtype, device=A.device)",
            "-    top_left = torch.triangular_solve(identity, A, upper=True)[0]",
            "+    top_left = torch.linalg.solve_triangular(A, identity, upper=True)",
            "top_right = -top_left.matmul(B_Dinv)  # complexity: head_size^2 x N",
            "top = torch.cat([top_left, top_right], -1)",
            "bottom_diag = x.bottom_diag.reciprocal()"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 4068,
        "label": "no",
        "change": [
            "def train():",
            "",
            "# Compute loss",
            "loss, loss_items = compute_loss(pred, targets, model)",
            "+            if torch.isnan(loss):",
            "+                print('WARNING: nan loss detected, skipping batch ', loss_items)",
            "+                continue",
            "",
            "# Scale loss by nominal batch_size of 64",
            "loss *= batch_size / 64"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4070,
        "label": "yes",
        "change": [
            "def concat(",
            "xs = list(xs)",
            "highest_dtype = xs[0].dtype",
            "for i in xs:",
            "-        highest_dtype = tf.experimental.numpy.promote_types(highest_dtype, i.dtype)",
            "+        highest_dtype = ivy.as_native_dtype(ivy.promote_types(highest_dtype, i.dtype))",
            "",
            "for i in range(len(xs)):",
            "if is_axis_none:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 4071,
        "label": "no",
        "change": [
            "class PPOLoss:",
            "self.mean_policy_loss = reduce_mean_valid(-surrogate_loss)",
            "",
            "if use_gae:",
            "-            vf_loss1 = tf.square(value_fn - value_targets)",
            "+            vf_loss1 = tf.math.square(value_fn - value_targets)",
            "vf_clipped = vf_preds + tf.clip_by_value(",
            "value_fn - vf_preds, -vf_clip_param, vf_clip_param)",
            "-            vf_loss2 = tf.square(vf_clipped - value_targets)",
            "+            vf_loss2 = tf.math.square(vf_clipped - value_targets)",
            "vf_loss = tf.maximum(vf_loss1, vf_loss2)",
            "self.mean_vf_loss = reduce_mean_valid(vf_loss)",
            "loss = reduce_mean_valid("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4072,
        "label": "yes",
        "change": [
            "else:",
            "version_str += f'+{git_hash}'",
            "",
            "torch_version = \".\".join([TORCH_MAJOR, TORCH_MINOR])",
            "-cuda_version = \".\".join(torch.version.cuda.split('.')[:2])",
            "+# Set cuda_version to 0.0 if cpu-only",
            "+cuda_version = \"0.0\"",
            "+if torch.version.cuda is not None:",
            "+    cuda_version = \".\".join(torch.version.cuda.split('.')[:2])",
            "torch_info = {\"version\": torch_version, \"cuda_version\": cuda_version}",
            "",
            "print(f\"version={version_str}, git_hash={git_hash}, git_branch={git_branch}\")"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 4074,
        "label": "no",
        "change": [
            "def _new_trainer():",
            "train_dataset = serialize(MNIST, root='data/mnist', train=True, download=True, transform=transform)",
            "test_dataset = serialize(MNIST, root='data/mnist', train=False, download=True, transform=transform)",
            "",
            "-    multi_module = MultiModelSupervisedLearningModule(nn.CrossEntropyLoss, {'acc': pl._AccuracyWithLogits})",
            "+    multi_module = _MultiModelSupervisedLearningModule(nn.CrossEntropyLoss, {'acc': pl._AccuracyWithLogits})",
            "",
            "lightning = pl.Lightning(multi_module, cgo_trainer.Trainer(use_cgo=True,",
            "max_epochs=1,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4076,
        "label": "no",
        "change": [
            "class Decoder(torch.nn.Module):",
            "if self.labeldist is not None:",
            "if self.vlabeldist is None:",
            "self.vlabeldist = to_cuda(self, Variable(torch.from_numpy(self.labeldist)))",
            "-            loss_reg = - torch.sum((functional.log_softmax(y_all, dim=1) * self.vlabeldist).view(-1), dim=0) / len(ys_in)",
            "+            loss_reg = - torch.sum((functional.log_softmax(y_all, dim=1) *",
            "+                                    self.vlabeldist).view(-1), dim=0) / len(ys_in)",
            "self.loss = (1. - self.lsm_weight) * self.loss + self.lsm_weight * loss_reg",
            "",
            "return self.loss, acc, att_weight_all"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4078,
        "label": "no",
        "change": [
            "class PaintByExamplePipelineIntegrationTests(unittest.TestCase):",
            "image_slice = image[0, -3:, -3:, -1]",
            "",
            "assert image.shape == (1, 512, 512, 3)",
            "-        expected_slice = np.array(",
            "-            [0.47455794, 0.47086594, 0.47683704, 0.51024145, 0.5064255, 0.5123164, 0.532502, 0.5328063, 0.5428694]",
            "-        )",
            "+        expected_slice = np.array([0.4834, 0.4811, 0.4874, 0.5122, 0.5081, 0.5144, 0.5291, 0.5290, 0.5374])",
            "+",
            "assert np.abs(image_slice.flatten() - expected_slice).max() < 1e-2"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4081,
        "label": "no",
        "change": [
            "number of neurons is tunable.",
            "class SingleDenseLayerBlock(ak.Block):",
            "def build(self, hp, inputs=None):",
            "# Get the input_node from inputs.",
            "-        input_node = tf.python.util.nest.flatten(inputs)[0]",
            "+        input_node = tf.nest.flatten(inputs)[0]",
            "layer = tf.keras.layers.Dense(",
            "hp.Int(\"num_units\", min_value=32, max_value=512, step=32)",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4082,
        "label": "no",
        "change": [
            "def run(",
            "tp, fp, p, r, f1, ap, ap_class = ap_per_class(*stats, plot=plots, save_dir=save_dir, names=names)",
            "ap50, ap = ap[:, 0], ap.mean(1)  # AP@0.5, AP@0.5:0.95",
            "mp, mr, map50, map = p.mean(), r.mean(), ap50.mean(), ap.mean()",
            "-        nt = np.bincount(stats[3].astype(int), minlength=nc)  # number of targets per class",
            "-    else:",
            "-        nt = torch.zeros(1)",
            "+    nt = np.bincount(stats[3].astype(int), minlength=nc)  # number of targets per class",
            "",
            "# Print results",
            "pf = '%20s' + '%11i' * 2 + '%11.3g' * 4  # print format"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4083,
        "label": "no",
        "change": [
            "from .tokenization_utils import BatchEncoding",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "-TF_OPENAI_GPT_PRETRAINED_MODEL_ARCHIVE_MAP = {",
            "-    \"openai-gpt\": \"https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-tf_model.h5\"",
            "-}",
            "+TF_OPENAI_GPT_PRETRAINED_MODEL_ARCHIVE_MAP = {\"openai-gpt\": \"https://cdn.huggingface.co/openai-gpt-tf_model.h5\"}",
            "",
            "",
            "def gelu(x):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4084,
        "label": "yes",
        "change": [
            "class TestElmoTokenRepresentation(ElmoTestCase):",
            "for k in range(10):",
            "char_indices = indices[\"elmo\"][(k * 50):((k + 1) * 50)]",
            "sentences.append(",
            "-                    indexer.pad_token_sequence(",
            "+                    indexer.as_padded_tensor(",
            "{'key': char_indices}, desired_num_tokens={'key': 50}, padding_lengths={}",
            ")['key']",
            ")",
            "-        batch = torch.from_numpy(numpy.array(sentences))",
            "+        batch = torch.stack(sentences)",
            "",
            "elmo_token_embedder = _ElmoCharacterEncoder(self.options_file, self.weight_file)",
            "elmo_token_embedder_output = elmo_token_embedder(batch)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 4086,
        "label": "yes",
        "change": [
            "def multiclass_nms(multi_bboxes, multi_scores, score_thr, nms_cfg, max_num=-1):",
            "else:",
            "_bboxes = multi_bboxes[cls_inds, i * 4:(i + 1) * 4]",
            "_scores = multi_scores[cls_inds, i]",
            "+        if score_factors is not None:",
            "+            _scores *= score_factors[cls_inds]",
            "cls_dets = torch.cat([_bboxes, _scores[:, None]], dim=1)",
            "cls_dets, _ = nms_op(cls_dets, **nms_cfg_)",
            "-        cls_labels = multi_bboxes.new_full(",
            "-            (cls_dets.shape[0], ), i - 1, dtype=torch.long)",
            "+        cls_labels = multi_bboxes.new_full((cls_dets.shape[0], ),",
            "+                                           i - 1,",
            "+                                           dtype=torch.long)",
            "bboxes.append(cls_dets)",
            "labels.append(cls_labels)",
            "if bboxes:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 4087,
        "label": "yes",
        "change": [
            "class CommonTestCases:",
            "model = model_class(config)",
            "self.assertIsInstance(",
            "model.get_input_embeddings(),",
            "-                    torch.nn.Embedding",
            "+                    (torch.nn.Embedding, AdaptiveEmbedding)",
            ")",
            "model.set_input_embeddings(torch.nn.Embedding(10, 10))",
            "x = model.get_output_embeddings()"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 4091,
        "label": "no",
        "change": [
            "class BertForMultipleChoice(BertPreTrainedModel):",
            "super().__init__(config)",
            "",
            "self.bert = BertModel(config)",
            "-        self.dropout = nn.Dropout(config.classifier_dropout_prob)",
            "+        self.dropout = nn.Dropout(config.classifier_dropout)",
            "self.classifier = nn.Linear(config.hidden_size, 1)",
            "",
            "self.init_weights()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4092,
        "label": "no",
        "change": [
            "\"@config_enumerate\\n\",",
            "\"def model(data, num_components=3):\\n\",",
            "\"    print('Running model with {} data points'.format(len(data)))\\n\",",
            "-    \"    p = pyro.sample(\\\"p\\\", dist.Dirichlet(0.5 * torch.ones(3)))\\n\",",
            "+    \"    p = pyro.sample(\\\"p\\\", dist.Dirichlet(0.5 * torch.ones(num_components)))\\n\",",
            "\"    scale = pyro.sample(\\\"scale\\\", dist.LogNormal(0, num_components))\\n\",",
            "\"    with pyro.plate(\\\"components\\\", num_components):\\n\",",
            "\"        loc = pyro.sample(\\\"loc\\\", dist.Normal(0, 10))\\n\","
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4094,
        "label": "no",
        "change": [
            "class PGModel(Model):",
            "advantage = episode['returns'] - baseline",
            "",
            "if self.normalize_advantage:",
            "-            return zero_mean_unit_variance(advantage)",
            "+            return np.squeeze(zero_mean_unit_variance(advantage))",
            "else:",
            "-            return advantage",
            "+            return np.squeeze(advantage)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4095,
        "label": "no",
        "change": [
            "def bbox2roi(bbox_list):",
            "",
            "",
            "def roi2bbox(rois):",
            "+    \"\"\"Convert rois to bounding box format",
            "+",
            "+    Args:",
            "+        rois (torch.Tensor): RoIs with the shape (n, 5) where the first",
            "+            column indicates batch id of each RoI.",
            "+",
            "+    Returns:",
            "+        list[torch.Tensor]: Converted boxes of corresponding rois.",
            "+    \"\"\"",
            "bbox_list = []",
            "img_ids = torch.unique(rois[:, 0].cpu(), sorted=True)",
            "for img_id in img_ids:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4100,
        "label": "yes",
        "change": [
            "class DQNTorchModel(TorchModelV2, nn.Module):",
            "if self.num_atoms > 1:",
            "# Distributional Q-learning uses a discrete support z",
            "# to represent the action value distribution",
            "-            z = torch.range(0.0, self.num_atoms - 1, dtype=torch.float32)",
            "+            z = torch.range(",
            "+                0.0, self.num_atoms - 1,",
            "+                dtype=torch.float32).to(action_scores.device)",
            "z = self.v_min + \\",
            "z * (self.v_max - self.v_min) / float(self.num_atoms - 1)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "addition",
        "Element": "api call"
    },
    {
        "number": 4103,
        "label": "no",
        "change": [
            "class EntityLinker(flair.nn.DefaultClassifier[Sentence]):",
            "if len(embedding_list) > 0:",
            "embedded_entity_pairs = torch.cat(embedding_list, 0)",
            "",
            "-            return embedded_entity_pairs,",
            "+            return (embedded_entity_pairs,)",
            "else:",
            "-            return torch.zeros(0, self.word_embeddings.embedding_length, device=flair.device),",
            "+            return (torch.zeros(0, self.word_embeddings.embedding_length, device=flair.device),)",
            "",
            "def _get_state_dict(self):",
            "model_state = {"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4107,
        "label": "no",
        "change": [
            "class InternalLstm(InternalLayer, TransformationBase):",
            ")",
            "",
            "def tf_apply(self, x, state):",
            "-        state = tf.contrib.rnn.LSTMStateTuple(c=state[:, 0, :], h=state[:, 1, :])",
            "+        state = tf.nn.rnn_cell.LSTMStateTuple(c=state[:, 0, :], h=state[:, 1, :])",
            "",
            "x, state = self.cell(inputs=x, state=state)",
            "state = tf.stack(values=(state.c, state.h), axis=1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4110,
        "label": "no",
        "change": [
            "class UnCLIPPipelineIntegrationTests(unittest.TestCase):",
            ")",
            "",
            "mem_bytes = torch.cuda.max_memory_allocated()",
            "-        # make sure that less than 1.5 GB is allocated",
            "-        assert mem_bytes < 1.5 * 10**9",
            "+        # make sure that less than 7 GB is allocated",
            "+        assert mem_bytes < 7 * 10**9"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4112,
        "label": "no",
        "change": [
            "class GPTNeoXJapaneseAttention(nn.Module):",
            "batch_size, num_attention_heads, query_length, attn_head_size = query.size()",
            "key_length = key.size(-2)",
            "",
            "-        causal_mask = self._create_casual_mask(key_length, query_length)",
            "+        causal_mask = self._create_causal_mask(key_length, query_length)",
            "",
            "query = query.view(batch_size * num_attention_heads, query_length, attn_head_size)",
            "key = key.view(batch_size * num_attention_heads, key_length, attn_head_size)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4113,
        "label": "no",
        "change": [
            "class Overflow(BaseTTS):",
            "self.register_buffer(\"mean\", torch.tensor(0))",
            "self.register_buffer(\"std\", torch.tensor(1))",
            "",
            "-        # self.mean = nn.Parameter(torch.zeros(1), requires_grad=False)",
            "-        # self.std = nn.Parameter(torch.ones(1), requires_grad=False)",
            "-",
            "def update_mean_std(self, statistics_dict: Dict):",
            "self.mean.data = torch.tensor(statistics_dict[\"mean\"])",
            "self.std.data = torch.tensor(statistics_dict[\"std\"])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4114,
        "label": "no",
        "change": [
            "class LeNet(nn.Module):",
            "",
            "def __init__(self):",
            "super(LeNet, self).__init__()",
            "-        # 1 input image channel (black & white), 6 output channels, 3x3 square convolution",
            "+        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution",
            "# kernel",
            "-        self.conv1 = nn.Conv2d(1, 6, 3)",
            "-        self.conv2 = nn.Conv2d(6, 16, 3)",
            "+        self.conv1 = nn.Conv2d(1, 6, 5)",
            "+        self.conv2 = nn.Conv2d(6, 16, 5)",
            "# an affine operation: y = Wx + b",
            "-        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension",
            "+        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension",
            "self.fc2 = nn.Linear(120, 84)",
            "self.fc3 = nn.Linear(84, 10)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4117,
        "label": "no",
        "change": [
            "def quantile(",
            "",
            "temp = a.reshape((-1,) + tuple(desired_shape))",
            "",
            "-        return torch.quantile(temp, q, dim=0, keepdim=keepdims, interpolation=interpolation)",
            "+        return torch.quantile(",
            "+            temp, q, dim=0, keepdim=keepdims, interpolation=interpolation",
            "+        )",
            "",
            "return torch.quantile(a, q, dim=axis, keepdim=keepdims, interpolation=interpolation)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4119,
        "label": "yes",
        "change": [
            "class LocalMetricTest(parameterized.TestCase):",
            "@slow",
            "def test_load_real_metric(self, metric_name):",
            "doctest.ELLIPSIS_MARKER = \"[...]\"",
            "-        metric_module = importlib.import_module(datasets.load.prepare_module(os.path.join(\"metrics\", metric_name))[0])",
            "+        metric_module = importlib.import_module(",
            "+            datasets.load.metric_module_factory(os.path.join(\"metrics\", metric_name)).module_path",
            "+        )",
            "# run doctest",
            "with self.use_local_metrics():",
            "results = doctest.testmod(metric_module, verbose=True, raise_on_error=True)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 4125,
        "label": "no",
        "change": [
            "class CustomConverterMulEnc(object):",
            "self.dtype = dtype",
            "self.num_encs = len(subsamping_factors)",
            "",
            "-    def __call__(self, batch, device):",
            "+    def __call__(self, batch, device=torch.device('cpu')):",
            "\"\"\"Transform a batch and send it to a device.",
            "",
            "Args:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4128,
        "label": "no",
        "change": [
            "MOCK_MODULES = [",
            "\"tensorflow.contrib.rnn\", \"tensorflow.contrib.slim\", \"tensorflow.core\",",
            "\"tensorflow.core.util\", \"tensorflow.python\", \"tensorflow.python.client\",",
            "\"tensorflow.python.util\", \"torch\", \"torch.distributed\", \"torch.nn\",",
            "-    \"torch.nn.parallel\", \"torch.utils.data\", \"torch.utils.data.distributed\"",
            "+    \"torch.nn.parallel\", \"torch.utils.data\", \"torch.utils.data.distributed\",",
            "+    \"zoopt\"",
            "]",
            "for mod_name in MOCK_MODULES:",
            "sys.modules[mod_name] = mock.Mock()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4132,
        "label": "no",
        "change": [
            "class TFLEDModelIntegrationTest(unittest.TestCase):",
            "expected_slice = tf.convert_to_tensor(",
            "[[33.6507, 6.4572, 16.8089], [5.8739, -2.4238, 11.2902], [-3.2139, -4.3149, 4.2783]],",
            ")",
            "-        tf.debugging.assert_near(output[:, :3, :3], expected_slice, atol=TOLERANCE)",
            "+        tf.debugging.assert_near(output[:, :3, :3], expected_slice, atol=1e-3, rtol=1e-3)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4134,
        "label": "no",
        "change": [
            "def main():",
            "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args.train_batch_size)",
            "",
            "model.train()",
            "-        for epoch in args.num_train_epochs:",
            "+        for epoch in range(args.num_train_epochs):",
            "for input_ids, input_mask, segment_ids, label_ids in train_dataloader:",
            "input_ids = input_ids.to(device)",
            "input_mask = input_mask.float().to(device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4135,
        "label": "no",
        "change": [
            "class Dirichlet(Distribution):",
            "alpha = self._sanitize_input(alpha)",
            "if alpha.dim() not in (1, 2):",
            "raise ValueError('Expected alpha.dim() in (1,2), actual: {}'.format(alpha.dim()))",
            "-        alpha_np = alpha.data.numpy()",
            "+        alpha_np = alpha.data.cpu().numpy()",
            "if alpha.dim() == 1:",
            "x_np = spr.dirichlet.rvs(alpha_np)[0]",
            "else:",
            "x_np = np.empty_like(alpha_np)",
            "for i in range(alpha_np.shape[0]):",
            "x_np[i, :] = spr.dirichlet.rvs(alpha_np[i, :])[0]",
            "-        x = Variable(torch.Tensor(x_np))",
            "+        x = Variable(type(alpha.data)(x_np))",
            "return x",
            "",
            "# TODO Remove the batch_size argument."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4136,
        "label": "no",
        "change": [
            "class DQNGraph(object):",
            "with tf.variable_scope(\"q_func\", reuse=True):",
            "q_tp1_using_online_net = _build_q_network(",
            "self.obs_tp1, num_actions, config)",
            "-            q_tp1_best_using_online_net = tf.arg_max(q_tp1_using_online_net, 1)",
            "+            q_tp1_best_using_online_net = tf.argmax(q_tp1_using_online_net, 1)",
            "q_tp1_best = tf.reduce_sum(",
            "self.q_tp1 * tf.one_hot(",
            "q_tp1_best_using_online_net, num_actions), 1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4137,
        "label": "no",
        "change": [
            "class ROUGE(Metric):",
            "sequence_count = len(predictions)",
            "if is_distributed():",
            "device = predictions.device",
            "-            _sequence_count = torch.tensor(sequence_count).to(device)",
            "+            _sequence_count = torch.tensor(sequence_count, device=device)",
            "dist.all_reduce(_sequence_count, op=dist.ReduceOp.SUM)",
            "sequence_count = _sequence_count.item()",
            "self._total_sequence_count += sequence_count"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4138,
        "label": "no",
        "change": [
            "class LevitModelIntegrationTest(unittest.TestCase):",
            "expected_shape = torch.Size((1, 1000))",
            "self.assertEqual(outputs.logits.shape, expected_shape)",
            "",
            "-        expected_slice = torch.tensor([0.0096, -1.0084, -1.4318]).to(torch_device)",
            "+        expected_slice = torch.tensor([1.0448, -0.3745, -1.8317]).to(torch_device)",
            "",
            "self.assertTrue(torch.allclose(outputs.logits[0, :3], expected_slice, atol=1e-4))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4140,
        "label": "yes",
        "change": [
            "class ModelTesterMixin:",
            "model.to(torch_device)",
            "model.eval()",
            "with torch.no_grad():",
            "-                outputs = model(**inputs_dict)",
            "+                outputs = model(**self._prepare_for_class(inputs_dict, model_class))",
            "attentions = outputs[-1]",
            "self.assertEqual(model.config.output_hidden_states, False)",
            "self.assertEqual(len(attentions), self.model_tester.num_hidden_layers)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "state handling error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 4141,
        "label": "no",
        "change": [
            "def setup_model_loss_criterion(cfg, args, rank, is_cuda):",
            "loss_fn = loss_fn.cuda()",
            "",
            "optimizer = optim.sgd.SGD(args, model.parameters())",
            "-    optimizer = optim.FairseqBMUF(",
            "-        cfg=cfg.bmuf,",
            "-        optimizer=optimizer",
            "-    )",
            "+    optimizer = optim.FairseqBMUF(cfg=cfg.bmuf, optimizer=optimizer)",
            "",
            "return model, loss_fn, optimizer"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4142,
        "label": "no",
        "change": [
            "class Net(torch.nn.Module):",
            "x = global_max_pool(x, batch)",
            "x = self.lin(x).view(-1)",
            "",
            "-        attn_loss = F.kl_div(",
            "-            torch.log(score + 1e-14), data.attn[perm], reduction='none')",
            "+        attn_loss = F.kl_div(torch.log(score + 1e-14), data.attn[perm],",
            "+                             reduction='none')",
            "attn_loss = scatter_mean(attn_loss, batch)",
            "",
            "return x, attn_loss, ratio"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4143,
        "label": "no",
        "change": [
            "class Model(ForecastingModel):",
            "",
            "# Sample global parameters.",
            "noise_scale = pyro.sample(\"noise_scale\",",
            "-                                  dist.LogNormal(torch.full((dim,), -3), 1).to_event(1))",
            "+                                  dist.LogNormal(torch.full((dim,), -3.), 1.).to_event(1))",
            "assert noise_scale.shape[-1:] == (dim,)",
            "trans_timescale = pyro.sample(\"trans_timescale\",",
            "dist.LogNormal(torch.zeros(dim), 1).to_event(1))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4147,
        "label": "no",
        "change": [
            "class Pointclouds(object):",
            "self.",
            "\"\"\"",
            "if not torch.is_tensor(scale):",
            "-            scale = torch.full(len(self), scale)",
            "+            scale = torch.full((len(self),), scale, device=self.device)",
            "new_points_list = []",
            "points_list = self.points_list()",
            "for i, old_points in enumerate(points_list):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4148,
        "label": "no",
        "change": [
            "class TranslationVariableLanguages:",
            "",
            "# At construction time:",
            "",
            "-        nlp.features.Translation(languages=['en', 'fr', 'de'])",
            "+        datasets.features.Translation(languages=['en', 'fr', 'de'])",
            "",
            "# During data generation:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4153,
        "label": "no",
        "change": [
            "def stack(sequence, horizontal=True, vertical=True):",
            "# Concat all indices and values to one new large sparse matrix.",
            "indices = torch.cat(indices, dim=1)",
            "values = torch.cat([mat._values() for mat in sequence])",
            "-    size = torch.Size([y_sum, x_sum, *(sequence[0].size()[2:])])",
            "+    size = torch.Size([y_sum, x_sum, *list(sequence[0].size()[2:])])",
            "slices = torch.LongTensor(slices)",
            "",
            "return torch.sparse.FloatTensor(indices, values, size), slices"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4156,
        "label": "no",
        "change": [
            "class Sum(nn.Module):",
            "self.weight = weight  # apply weights boolean",
            "self.iter = range(n - 1)  # iter object",
            "if weight:",
            "-            self.w = nn.Parameter(-torch.arange(1., n) / 2, requires_grad=True)  # layer weights",
            "+            self.w = nn.Parameter(-torch.arange(1.0, n) / 2, requires_grad=True)  # layer weights",
            "",
            "def forward(self, x):",
            "y = x[0]  # no weight"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4159,
        "label": "no",
        "change": [
            "def EfficientNet(",
            "# original implementation.",
            "# See https://github.com/tensorflow/tensorflow/issues/49930 for more",
            "# details",
            "-        x = layers.Rescaling(1.0 / tf.math.sqrt(IMAGENET_STDDEV_RGB))(x)",
            "+        x = layers.Rescaling(",
            "+            [1.0 / math.sqrt(stddev) for stddev in IMAGENET_STDDEV_RGB]",
            "+        )(x)",
            "",
            "x = layers.ZeroPadding2D(",
            "padding=imagenet_utils.correct_pad(x, 3), name=\"stem_conv_pad\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4160,
        "label": "no",
        "change": [
            "class AdaptiveInput(nn.Module):",
            "size = self.cutoff[i] - prev",
            "dim = int(initial_dim // (factor ** i))",
            "seq = nn.Sequential(",
            "-                nn.Embedding(size, dim, padding_idx),",
            "+                nn.Embedding(size, dim, self.padding_idx),",
            "nn.Linear(dim, output_dim, bias=False)",
            ")",
            "self.embeddings.append(seq)",
            "+            self.padding_idx = None",
            "+        self.padding_idx = padding_idx",
            "",
            "def init_weights(m):",
            "if isinstance(m, nn.Embedding):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4164,
        "label": "no",
        "change": [
            "class SwinModelIntegrationTest(unittest.TestCase):",
            "expected_shape = torch.Size((1, 1000))",
            "self.assertEqual(outputs.logits.shape, expected_shape)",
            "",
            "-        expected_slice = torch.tensor([-0.2952, -0.4777, 0.2025]).to(torch_device)",
            "+        expected_slice = torch.tensor([-0.0948, -0.6454, -0.0921]).to(torch_device)",
            "",
            "self.assertTrue(torch.allclose(outputs.logits[0, :3], expected_slice, atol=1e-4))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4167,
        "label": "no",
        "change": [
            "class Model(Module):",
            "#     raise TensorForceError(\"Invalid model directory/file.\")",
            "",
            "self.saver.restore(sess=self.session, save_path=file)",
            "-        self.session.run(fetches=self.list_buffer_index_reset_op)",
            "+        self.session.run(fetches=self.reset_buffer_indices)",
            "",
            "def get_components(self):",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4169,
        "label": "no",
        "change": [
            "class CvT(nn.Module):",
            "",
            "layers.append(nn.Sequential(",
            "nn.Conv2d(dim, config['emb_dim'], kernel_size = config['emb_kernel'], padding = (config['emb_kernel'] // 2), stride = config['emb_stride']),",
            "+                LayerNorm(config['emb_dim']),",
            "Transformer(dim = config['emb_dim'], proj_kernel = config['proj_kernel'], kv_proj_stride = config['kv_proj_stride'], depth = config['depth'], heads = config['heads'], mlp_mult = config['mlp_mult'], dropout = dropout)",
            "))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4179,
        "label": "no",
        "change": [
            "class JigsawToxicityPred(datasets.GeneratorBasedBuilder):",
            "",
            "if not os.path.exists(data_dir):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('jigsaw_toxicity_pred', data_dir=...)`. Manual download instructions: {}\".format(",
            "-                    data_dir, self.manual_download_instructions",
            "-                )",
            "+                f\"{data_dir} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('jigsaw_toxicity_pred', data_dir=...)`. Manual download instructions: {self.manual_download_instructions}\"",
            ")",
            "",
            "return ["
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4180,
        "label": "no",
        "change": [
            "class LowerCholeskyAffine(Transform):",
            "",
            "Inverts y => x.",
            "\"\"\"",
            "-        return torch.triangular_solve(",
            "-            (y - self.loc).unsqueeze(-1), self.scale_tril, upper=False, transpose=False",
            "-        )[0].squeeze(-1)",
            "+        return torch.linalg.solve_triangular(",
            "+            self.scale_tril, (y - self.loc).unsqueeze(-1), upper=False",
            "+        ).squeeze(-1)",
            "",
            "def log_abs_det_jacobian(self, x, y):",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4185,
        "label": "no",
        "change": [
            "def main():",
            "",
            "",
            "# Save the trained model and the tokenizer",
            "-    if args.do_train and args.local_rank == -1 or torch.distributed.get_rank() == 0:",
            "+    if args.do_train and (args.local_rank == -1 or torch.distributed.get_rank() == 0):",
            "# Create output directory if needed",
            "if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:",
            "os.makedirs(args.output_dir)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4186,
        "label": "no",
        "change": [
            "def homography_i_H_ref(pinhole_i, pinhole_ref):",
            "- Output: :math:`(N, 4, 4)`",
            "",
            "Example:",
            "-        >>> pinhole_i = torch.rand(1, 12)    # Nx12",
            "-        >>> pinhole_ref = torch.rand(1, 12)  # Nx12",
            "-        >>> homography_i_H_ref(pinhole_i, pinhole_ref)  # Nx4x4",
            "+        pinhole_i = torch.rand(1, 12)    # Nx12",
            "+        pinhole_ref = torch.rand(1, 12)  # Nx12",
            "+        homography_i_H_ref(pinhole_i, pinhole_ref)  # Nx4x4",
            "\"\"\"",
            "+    # TODO: Add doctest once having `rtvec_to_pose`.",
            "assert len(",
            "pinhole_i.shape) == 2 and pinhole_i.shape[1] == 12, pinhole.shape",
            "assert pinhole_i.shape == pinhole_ref.shape, pinhole_ref.shape"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4189,
        "label": "yes",
        "change": [
            "class Embed(base.AbstractModule):",
            "regularizer=self._regularizers.get(self.EMBEDDINGS, None),",
            "trainable=self._trainable)",
            "",
            "+    # On the backwards pass, we want to convert the gradient from",
            "+    # indexed-slices to a regular tensor before sending it back to the",
            "+    # parameter server. This avoids excess computation on the parameter server.",
            "+",
            "+    embeddings = util.convert_gradient_to_tensor(self._embeddings)",
            "+",
            "# Lookup embeddings",
            "-    return tf.nn.embedding_lookup(",
            "-        self._embeddings, ids, name=\"embedding_lookup\")",
            "+    return tf.nn.embedding_lookup(embeddings, ids, name=\"embedding_lookup\")",
            "",
            "@property",
            "def vocab_size(self):"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 4192,
        "label": "no",
        "change": [
            "def test_hook(history):",
            "tf.summary.scalar('c1', c1)",
            "summary_op = tf.summary.merge_all()",
            "",
            "-        hook = wandb_tensorflow.WandbHook(summary_op)",
            "+        hook = wandb_tensorflow.WandbHook(summary_op, history=history)",
            "with tf.train.MonitoredTrainingSession(hooks=[hook]) as sess:",
            "summary, acc = sess.run([summary_op, c1])",
            "",
            "assert wandb_tensorflow.tf_summary_to_dict(summary) == {'c1': 42.0}",
            "+    print(history.rows)",
            "+    # TODO(adrian): there is still some kind of bug here where the history",
            "+    # is being shared with another test that manages to add rows before this one.",
            "assert history.rows[0]['c1'] == 42.0"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4196,
        "label": "no",
        "change": [
            "class TFResNetShortCut(tf.keras.layers.Layer):",
            "out_channels, kernel_size=1, strides=stride, use_bias=False, name=\"convolution\"",
            ")",
            "# Use same default momentum and epsilon as PyTorch equivalent",
            "-        self.normalization = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum=0.1, name=\"normalization\")",
            "+        self.normalization = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum=0.9, name=\"normalization\")",
            "",
            "def call(self, x: tf.Tensor, training: bool = False) -> tf.Tensor:",
            "hidden_state = x"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4197,
        "label": "no",
        "change": [
            "if dependency_check.torch_available:",
            "import torch",
            "",
            "framework_tensors.append(torch.Tensor)",
            "+    framework_tensors.append(torch.nn.Parameter)",
            "framework_shapes.append(torch.Size)",
            "",
            "framework_tensors = tuple(framework_tensors)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4205,
        "label": "no",
        "change": [
            "class OpusState:",
            "load_layers_(model.model.decoder.layers, state_dict, BART_CONVERTER, is_decoder=True)",
            "",
            "# handle tensors not associated with layers",
            "-        wemb_tensor = torch.nn.Parameter(torch.FloatTensor(self.wemb))",
            "-        bias_tensor = torch.nn.Parameter(torch.FloatTensor(self.final_bias))",
            "+        wemb_tensor = nn.Parameter(torch.FloatTensor(self.wemb))",
            "+        bias_tensor = nn.Parameter(torch.FloatTensor(self.final_bias))",
            "model.model.shared.weight = wemb_tensor",
            "model.model.encoder.embed_tokens = model.model.decoder.embed_tokens = model.model.shared"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4208,
        "label": "no",
        "change": [
            "def trace(",
            "return ret",
            "",
            "",
            "-def det(",
            "-        x: torch.Tensor,",
            "-        out: Optional[torch.Tensor] = None",
            "-) -> torch.Tensor:",
            "+def det(x: torch.Tensor, out: Optional[torch.Tensor] = None) -> torch.Tensor:",
            "return torch.linalg.det(x, out=out)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4210,
        "label": "no",
        "change": [
            "def main(args):",
            "tb_writer.add_scalar(tags[1], acc, epoch)",
            "tb_writer.add_scalar(tags[2], optimizer.param_groups[0][\"lr\"], epoch)",
            "",
            "-            torch.save(model.state_dict(), \"./weights/model-{}.pth\".format(epoch))",
            "+            torch.save(model.module.state_dict(), \"./weights/model-{}.pth\".format(epoch))",
            "",
            "# 删除临时缓存文件",
            "if rank == 0:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4212,
        "label": "no",
        "change": [
            "class EpsilonGreedy(Exploration):",
            "),",
            "false_fn=lambda: exploit_action)",
            "",
            "-        assign_op = tf.assign(self.last_timestep, timestep)",
            "-        with tf.control_dependencies([assign_op]):",
            "+        assign_op = tf1.assign(self.last_timestep, timestep)",
            "+        with tf1.control_dependencies([assign_op]):",
            "return action, tf.zeros_like(action, dtype=tf.float32)",
            "",
            "def _get_torch_exploration_action(self, q_values, explore, timestep):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4214,
        "label": "yes",
        "change": [
            "class LightweightConvolution2D(nn.Module):",
            "# convolution along frequency axis",
            "weight_f = F.softmax(self.weight_f, dim=-1)",
            "weight_f = F.dropout(weight_f, self.dropout_rate, training=self.training)",
            "-        weight_new = torch.zeros(B * T, 1, self.kernel_size, device=x.device).copy_(weight_f)",
            "+        weight_new = torch.zeros(B * T, 1, self.kernel_size, device=x.device, dtype=x.dtype).copy_(weight_f)",
            "xf = F.conv1d(x.view(1, B * T, C), weight_new, padding=self.padding_size, groups=B * T).view(B, T, C)",
            "",
            "# lightconv"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 4216,
        "label": "no",
        "change": [
            "class ECD(BaseModel):",
            "\"\"\"Loads the model from the given path.\"\"\"",
            "weights_save_path = os.path.join(save_path, MODEL_WEIGHTS_FILE_NAME)",
            "device = torch.device(get_torch_device())",
            "-        self.load_state_dict(torch.load(weights_save_path, map_location=device))",
            "+        with open_file(weights_save_path, \"rb\") as f:",
            "+            self.load_state_dict(torch.load(f, map_location=device))",
            "",
            "def get_args(self):",
            "\"\"\"Returns init arguments for constructing this model.\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4221,
        "label": "yes",
        "change": [
            "class ViltEmbeddings(nn.Module):",
            "x = x.flatten(2).transpose(1, 2)",
            "# Set `device` here, otherwise `patch_index` will always be on `CPU` and will fail near the end for torch>=1.13",
            "patch_index = torch.stack(",
            "-            torch.meshgrid(torch.arange(x_mask.shape[-2]), torch.arange(x_mask.shape[-1]), indexing=\"ij\"), dim=-1",
            "+            meshgrid(torch.arange(x_mask.shape[-2]), torch.arange(x_mask.shape[-1]), indexing=\"ij\"), dim=-1",
            ").to(device=x_mask.device)",
            "patch_index = patch_index[None, None, :, :, :]",
            "patch_index = patch_index.expand(x_mask.shape[0], x_mask.shape[1], -1, -1, -1)"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 4223,
        "label": "no",
        "change": [
            "class VisualBertForQuestionAnswering(VisualBertPreTrainedModel):",
            "",
            "loss = None",
            "if labels is not None:",
            "-            loss_fct = torch.nn.KLDivLoss(reduction=\"batchmean\")",
            "-            log_softmax = torch.nn.LogSoftmax(dim=-1)",
            "+            loss_fct = nn.KLDivLoss(reduction=\"batchmean\")",
            "+            log_softmax = nn.LogSoftmax(dim=-1)",
            "reshaped_logits = log_softmax(reshaped_logits)",
            "loss = loss_fct(reshaped_logits, labels.contiguous())",
            "if not return_dict:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4225,
        "label": "no",
        "change": [
            "from common import mpi_env_rank_and_size",
            "config = tf.ConfigProto()",
            "config.gpu_options.allow_growth = True",
            "",
            "+if _has_eager:",
            "+    # Specifies the config to use with eager execution. Does not preclude",
            "+    # tests from running in the graph mode.",
            "+    tf.enable_eager_execution(config=config)",
            "+",
            "# MLSL supports only byte, float and double data types",
            "mlsl_supported_types = set([tf.float32, tf.float64])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4227,
        "label": "no",
        "change": [
            "import ivy.functional.backends.torch as ivy_torch",
            "set(ivy_torch.valid_float_dtypes)))),",
            "as_variable=st.booleans(),",
            "with_out=st.booleans(),",
            "-    num_positional_args=helpers.num_positional_args(fn_name=\"tan\"),",
            "+    num_positional_args=helpers.num_positional_args(",
            "+        fn_name=\"functional.frontends.torch.tan\"),",
            "native_array=st.booleans(),",
            ")",
            "def test_torch_tan("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4229,
        "label": "no",
        "change": [
            "class DataCollatorForLanguageModeling(DataCollatorMixin):",
            "inputs = tf.where(indices_replaced, mask_token_id, inputs)",
            "",
            "# 10% of the time, we replace masked input tokens with random word",
            "-        indices_random = self.tf_bernoulli(input_shape, 0.5) & masked_indices & ~indices_replaced",
            "-        random_words = tf.random.uniform(input_shape, maxval=vocab_size, dtype=tf.int64)",
            "+        indices_random = self.tf_bernoulli(input_shape, 0.1) & masked_indices & ~indices_replaced",
            "+        random_words = tf.random.uniform(input_shape, maxval=vocab_size, dtype=inputs.dtype)",
            "+",
            "inputs = tf.where(indices_random, random_words, inputs)",
            "",
            "# The rest of the time (10% of the time) we keep the masked input tokens unchanged"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4235,
        "label": "no",
        "change": [
            "class Trainer(object):",
            "logger.info(\"Epoch {} (global_step {}) finished, time:{:.2f} sec.\".format(",
            "self.epoch_num, self.global_step, time.time() - start_time))",
            "",
            "-                    # trigger epoch outside the timing region.",
            "-                    self.trigger_epoch()",
            "+                    self.trigger_epoch()  # trigger epoch outside the timing region.",
            "except StopTraining:",
            "logger.info(\"Training was stopped.\")",
            "except KeyboardInterrupt:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4236,
        "label": "no",
        "change": [
            "def load_tf2_weights_in_bert(model, tf_checkpoint_path, config):",
            "pointer.data = torch.from_numpy(array)",
            "else:",
            "raise ValueError(",
            "-                f\"Shape mismatch in layer {full_name}: Model expects shape {pointer.shape} but layer contains shape: {array.shape}\"",
            "+                f\"Shape mismatch in layer {full_name}: Model expects shape {pointer.shape} but layer contains shape:\"",
            "+                f\" {array.shape}\"",
            ")",
            "logger.info(f\"Successfully set variable {full_name} to PyTorch layer {trace}\")",
            "return model"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4238,
        "label": "no",
        "change": [
            "class PretrainedTransformerMismatchedEmbedder(TokenEmbedder):",
            "segment_concat_mask: Optional[torch.BoolTensor]",
            "See `PretrainedTransformerEmbedder`.",
            "",
            "-        # Returns:",
            "+        # Returns",
            "",
            "-        Shape: [batch_size, num_orig_tokens, embedding_size].",
            "+        `torch.Tensor`",
            "+            Shape: [batch_size, num_orig_tokens, embedding_size].",
            "\"\"\"",
            "# Shape: [batch_size, num_wordpieces, embedding_size].",
            "embeddings = self._matched_embedder("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4241,
        "label": "no",
        "change": [
            "def knn(x, y, k, batch_x=None, batch_y=None, cosine=False, num_workers=1):",
            "x = torch.Tensor([[-1, -1], [-1, 1], [1, -1], [1, 1]])",
            "batch_x = torch.tensor([0, 0, 0, 0])",
            "y = torch.Tensor([[-1, 0], [1, 0]])",
            "-        batch_x = torch.tensor([0, 0])",
            "+        batch_y = torch.tensor([0, 0])",
            "assign_index = knn(x, y, 2, batch_x, batch_y)",
            "\"\"\"",
            "if torch_cluster is None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4243,
        "label": "no",
        "change": [
            "def vecdot(",
            "*,",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "-    dtype = torch.promote_types(x1.dtype, x2.dtype)",
            "x1, x2 = x1.to(torch.float32), x2.to(torch.float32)",
            "return torch.tensordot(x1, x2, dims=([axis], [axis]), out=out)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4245,
        "label": "no",
        "change": [
            "def test_tbptt_cpu_model_result_auto_reduce(tmpdir):",
            ")",
            "",
            "model = BpttTestModel(**hparams)",
            "+    model.example_input_array = torch.randn(5, truncated_bptt_steps)",
            "",
            "# fit model",
            "trainer = Trainer("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4247,
        "label": "yes",
        "change": [
            "def test_multinomial(",
            "):",
            "prob_dtype, batch_size, population_size, num_samples, replace, probs = everything",
            "# tensorflow does not support multinomial without replacement",
            "-    if backend_fw == \"tensorflow\":",
            "-        assume(replace is True)",
            "+    if backend_fw == ivy.functional.backends.tensorflow:",
            "+        assume(replace)",
            "",
            "def call():",
            "return helpers.test_function("
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 4248,
        "label": "no",
        "change": [
            "def set_test_cache_config(tmp_path_factory, monkeypatch):",
            "",
            "@pytest.fixture(autouse=True, scope=\"session\")",
            "def disable_tqdm_output():",
            "-    datasets.set_progress_bar_enabled(False)",
            "+    datasets.disable_progress_bar()",
            "",
            "",
            "@pytest.fixture(autouse=True)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4249,
        "label": "yes",
        "change": [
            "class MonotoneConvexTest(tf.test.TestCase):",
            "test_time = tf.constant([1.1, 2.7], dtype=dtype)",
            "interpolated, _ = monotone_convex.interpolate(test_time, interval_values,",
            "interval_times)",
            "-    gradient_1y = self.evaluate(tf.gradients(interpolated[0], knot_1y)[0])",
            "-    gradient_zero = self.evaluate(tf.gradients(interpolated[1], knot_1y)[0])",
            "+    gradient_1y = self.evaluate(tf.convert_to_tensor(",
            "+        tf.gradients(interpolated[0], knot_1y)[0]))",
            "+    gradient_zero = self.evaluate(tf.convert_to_tensor(",
            "+        tf.gradients(interpolated[1], knot_1y)[0]))",
            "+",
            "self.assertAlmostEqual(gradient_1y[0], 0.42)",
            "self.assertAlmostEqual(gradient_zero[0], 0.0)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 4250,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "# weight decay on all W of fc layers",
            "wd_w = tf.train.exponential_decay(0.00004, get_global_step_var(),",
            "80000, 0.7, True)",
            "-        wd_cost = tf.mul(wd_w, regularize_cost('.*/W', tf.nn.l2_loss), name='l2_regularize_loss')",
            "+        wd_cost = tf.multiply(wd_w, regularize_cost('.*/W', tf.nn.l2_loss), name='l2_regularize_loss')",
            "",
            "self.cost = tf.add_n([0.4 * loss1, loss2, wd_cost], name='cost')",
            "add_moving_summary(loss1, loss2, wd_cost, self.cost)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4256,
        "label": "no",
        "change": [
            "def mask_to_image(mask: np.ndarray, mask_values):",
            "if isinstance(mask_values[0], list):",
            "out = np.zeros((mask.shape[-2], mask.shape[-1], len(mask_values[0])), dtype=np.uint8)",
            "elif mask_values == [0, 1]:",
            "-        out = np.zeros((mask.shape[-2], mask.shape[-1]), dtype=np.bool)",
            "+        out = np.zeros((mask.shape[-2], mask.shape[-1]), dtype=bool)",
            "else:",
            "out = np.zeros((mask.shape[-2], mask.shape[-1]), dtype=np.uint8)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4258,
        "label": "yes",
        "change": [
            "def train(args):",
            "rnn = RNNLM(args.n_vocab, args.layer, args.unit, args.type, args.dropout_rate)",
            "model = ClassifierWithState(rnn)",
            "if args.ngpu > 0:",
            "-        model = torch.nn.DataParallel(model).cuda()",
            "+        model = torch.nn.DataParallel(model, device_ids=list(range(args.ngpu))).cuda()",
            "setattr(model, \"reporter\", model.module.reporter)",
            "gpu_id = 0",
            "else:"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 4267,
        "label": "no",
        "change": [
            "def train_ch8(model, train_iter, vocab, lr, num_epochs, device,",
            "animator = d2l.Animator(xlabel='epoch', ylabel='perplexity',",
            "legend=['train'], xlim=[1, num_epochs])",
            "if isinstance(model, nn.Module):",
            "-        trainer = torch.optim.SGD(model.parameters(), lr)",
            "-        updater = lambda batch_size: trainer.step()",
            "+        updater = torch.optim.SGD(model.parameters(), lr)",
            "else:",
            "updater = lambda batch_size: d2l.sgd(model.params, lr, batch_size)",
            "predict = lambda prefix: predict_ch8(prefix, 50, model, vocab, device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4269,
        "label": "yes",
        "change": [
            "class PositionalEncoding(nn.Module):",
            "pe[:, 0::2] = torch.sin(position * div_term)",
            "pe[:, 1::2] = torch.cos(position * div_term)",
            "pe = pe.unsqueeze(0).transpose(0, 1)",
            "-        self.register_buffer('pe', pe)",
            "+        self.pe = nn.Parameter(pe, requires_grad=False)",
            "",
            "def forward(self, x):",
            "x = x + self.pe[:x.size(0), :]"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 4273,
        "label": "no",
        "change": [
            "def idct(x, dim=-1):",
            "X = torch.stack([x[..., :M], xi], dim=-1)",
            "coef_real = torch.cos(torch.linspace(0, 0.5 * math.pi, N + 1, dtype=x.dtype, device=x.device))",
            "coef = torch.stack([coef_real[:M], coef_real[-M:].flip(-1)], dim=-1)",
            "-    Y = torch.view_as_complex(coef) * torch.view_as_complex(X)",
            "+    Y = as_complex(coef) * as_complex(X)",
            "# Step 2",
            "y = irfft(Y, n=N)",
            "# Step 3"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4274,
        "label": "no",
        "change": [
            "def retrieve_seq_length_op3(data, pad_val=0):  # HangSheng: return tensor for se",
            "",
            "",
            "def target_mask_op(data, pad_val=0):  # HangSheng: return tensor for mask,if input is tf.string",
            "-    \"\"\"Return tensor for mask, if input is ``tf.string``.",
            "-",
            "-    \"\"\"",
            "+    \"\"\"Return tensor for mask, if input is ``tf.string``.\"\"\"",
            "data_shape_size = data.get_shape().ndims",
            "if data_shape_size == 3:",
            "return tf.cast(tf.reduce_any(tf.not_equal(data, pad_val), axis=2), dtype=tf.int32)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4276,
        "label": "yes",
        "change": [
            "class CTC(torch.nn.Module):",
            "# expected shape of seqLength x batchSize x alphabet_size",
            "dtype = ys_hat.dtype",
            "ys_hat = ys_hat.transpose(0, 1)",
            "-        if self.ctc_type == \"warpctc\":",
            "+        if self.ctc_type == \"warpctc\" or dtype == torch.float16:",
            "# warpctc only supports float32",
            "ys_hat = ys_hat.to(dtype=torch.float32)",
            "else:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 4282,
        "label": "yes",
        "change": [
            "class ExpectedRiskMinimization(DecoderTrainer[Callable[[StateType], torch.Tensor",
            "state.score,",
            "state.action_history):",
            "if self._normalize_by_length:",
            "-                    path_length = nn_util.new_variable_with_data(model_score,",
            "-                                                                 torch.Tensor([len(history)]))",
            "+                    path_length = Variable(model_score.data.new([len(history)]))",
            "model_score = model_score / path_length",
            "batch_scores[batch_index].append(model_score)",
            "return batch_scores"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 4284,
        "label": "no",
        "change": [
            "def build_eager_tf_policy(name,",
            "dummy_batch[\"seq_lens\"] = np.array([1], dtype=np.int32)",
            "",
            "# Convert everything to tensors.",
            "-            dummy_batch = tf.nest.map_structure(",
            "-                tf1.convert_to_tensor, dummy_batch)",
            "+            dummy_batch = tf.nest.map_structure(tf1.convert_to_tensor,",
            "+                                                dummy_batch)",
            "",
            "# for IMPALA which expects a certain sample batch size.",
            "def tile_to(tensor, n):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4286,
        "label": "no",
        "change": [
            "class _TorchObject(object):",
            "def create_pointer(self, register=False):",
            "return self.child.create_pointer(parent=self, register=register)",
            "",
            "-    def footprint(self):",
            "-        return self.child.footprint()",
            "-",
            "def get(self):",
            "new_child_obj = self.child.get(parent=self)",
            "return self"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4290,
        "label": "yes",
        "change": [
            "def test_load_no_dev_data_explicit(tasks_base_path):",
            "",
            "def test_multi_corpus(tasks_base_path):",
            "",
            "-    corpus_1 = flair.datasets.NER_GERMAN_GERMEVAL(tasks_base_path)",
            "+    corpus_1 = flair.datasets.ColumnCorpus(tasks_base_path  / \"germeval_14\", column_format={0: \"text\", 2: \"ner\"})",
            "",
            "corpus_2 = flair.datasets.ColumnCorpus(tasks_base_path / \"fashion\", column_format={0: \"text\", 2: \"ner\"})",
            "# get two corpora as one"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 4291,
        "label": "no",
        "change": [
            "def full(",
            "fill_value: Union[int, float],",
            "*,",
            "dtype: tf.DType = None,",
            "-    device: str",
            "+    device: str,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "with tf.device(as_native_dev(default_device(device))):",
            "return tf.fill("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4292,
        "label": "no",
        "change": [
            "class TFGPT2ForSequenceClassification(TFGPT2PreTrainedModel, TFSequenceClassific",
            "if not tf.is_tensor(sequence_lengths):",
            "in_logits = logits[0 : logits_shape[0], sequence_lengths]",
            "",
            "-            loss = self.compute_loss(tf.reshape(inputs[\"labels\"], [-1]), tf.reshape(in_logits, [-1, self.num_labels]))",
            "+            loss = self.hf_compute_loss(",
            "+                tf.reshape(inputs[\"labels\"], [-1]), tf.reshape(in_logits, [-1, self.num_labels])",
            "+            )",
            "pooled_logits = in_logits if in_logits is not None else logits",
            "",
            "if not inputs[\"return_dict\"]:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4296,
        "label": "no",
        "change": [
            "class SummaryWriter(object):",
            "make_tsv(metadata, save_path, metadata_header=metadata_header)",
            "if label_img is not None:",
            "assert mat.shape[0] == label_img.shape[0], '#images should equal with #data points'",
            "+            assert label_img.shape[2] == label_img.shape[3], 'Image should be square, see tensorflow/tensorboard#670'",
            "make_sprite(label_img, save_path)",
            "assert mat.ndim == 2, 'mat should be 2D, where mat.size(0) is the number of data points'",
            "make_mat(mat, save_path)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4297,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "l = tf.nn.dropout(l, keep_prob)",
            "",
            "# fc will have activation summary by default. disable this for the output layer",
            "-        logits = FullyConnected('fc1', l, out_dim=10,",
            "-                             summary_activation=False, nl=tf.identity)",
            "+        logits = FullyConnected('fc1', l, out_dim=10, nl=tf.identity)",
            "prob = tf.nn.softmax(logits, name='prob')",
            "",
            "y = one_hot(label, 10)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4300,
        "label": "no",
        "change": [
            "class ElmoLstm(_EncoderBase):",
            "# the final states for all the layers.",
            "final_states.append(",
            "(",
            "-                    torch.cat([forward_state[0], backward_state[0]], -1),",
            "-                    torch.cat([forward_state[1], backward_state[1]], -1),",
            "+                    torch.cat([forward_state[0], backward_state[0]], -1),  # type: ignore",
            "+                    torch.cat([forward_state[1], backward_state[1]], -1),  # type: ignore",
            ")",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4301,
        "label": "yes",
        "change": [
            "def test_forward(use_token_averaged_energy, reduction_factor):",
            "es, elens = layer(xs, torch.LongTensor([384, 128]))",
            "assert es.shape[1] == max(elens)",
            "else:",
            "-        ds = torch.LongTensor([[3, 3, 1], [3, 0, 0]])",
            "+        ds = torch.LongTensor([[3, 3, 1], [3, 0, 0]]) // reduction_factor",
            "dlens = torch.LongTensor([3, 1])",
            "es, _ = layer(",
            "xs, torch.LongTensor([384, 128]), durations=ds, durations_lengths=dlens"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "data conversion error",
        "Action": "addition",
        "Element": "api parameter"
    },
    {
        "number": 4302,
        "label": "no",
        "change": [
            "def train_fn():",
            "transforms.Normalize((0.1307, ), (0.3081, ))])",
            "",
            "test_dataset = datasets.MNIST(",
            "-        'data-%d' % hvd.rank(), train=False, transform=transformations)",
            "+        data_dir, train=False, transform=transformations)",
            "# Horovod: use DistributedSampler to partition the test data.",
            "test_sampler = torch.utils.data.distributed.DistributedSampler(",
            "test_dataset, num_replicas=hvd.size(), rank=hvd.rank())"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4304,
        "label": "no",
        "change": [
            "class ScoreSdeVePipeline(DiffusionPipeline):",
            "# correction step",
            "for _ in range(self.scheduler.correct_steps):",
            "model_output = self.unet(sample, sigma_t)[\"sample\"]",
            "-                sample = self.scheduler.step_correct(model_output, sample)[\"prev_sample\"]",
            "+                sample = self.scheduler.step_correct(model_output, sample, generator=generator)[\"prev_sample\"]",
            "",
            "# prediction step",
            "model_output = model(sample, sigma_t)[\"sample\"]",
            "-            output = self.scheduler.step_pred(model_output, t, sample)",
            "+            output = self.scheduler.step_pred(model_output, t, sample, generator=generator)",
            "",
            "sample, sample_mean = output[\"prev_sample\"], output[\"prev_sample_mean\"]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4307,
        "label": "no",
        "change": [
            "class Laplacian(nn.Module):",
            "computed = (kernel_size - 1) // 2",
            "return computed",
            "",
            "-    def forward(self, x: torch.Tensor):",
            "+    def forward(self, x: torch.Tensor):  # type: ignore",
            "if not torch.is_tensor(x):",
            "raise TypeError(\"Input x type is not a torch.Tensor. Got {}\"",
            ".format(type(x)))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4308,
        "label": "no",
        "change": [
            "class ECD(BaseModel):",
            "weights_save_path = os.path.join(save_path, MODEL_WEIGHTS_FILE_NAME)",
            "device = torch.device(get_torch_device())",
            "with open_file(weights_save_path, \"rb\") as f:",
            "-            self.load_state_dict(torch.load(f, map_location=device))",
            "+            state_dict = torch.load(f, map_location=device)",
            "+            self.load_state_dict(update_state_dict(state_dict))",
            "",
            "def get_args(self):",
            "\"\"\"Returns init arguments for constructing this model.\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4310,
        "label": "yes",
        "change": [
            "class Loggers():",
            "if self.wandb:",
            "self.wandb.log({\"Labels\": [wandb.Image(str(x), caption=x.name) for x in paths]})",
            "",
            "-    def on_train_batch_end(self, ni, model, imgs, targets, paths, plots):",
            "+    def on_train_batch_end(self, ni, model, imgs, targets, paths, plots, sync_bn):",
            "# Callback runs on train batch end",
            "if plots:",
            "if ni == 0:",
            "-                with warnings.catch_warnings():",
            "-                    warnings.simplefilter('ignore')  # suppress jit trace warning",
            "-                    self.tb.add_graph(torch.jit.trace(de_parallel(model), imgs[0:1], strict=False), [])",
            "+                if not sync_bn:  # tb.add_graph() --sync known issue https://github.com/ultralytics/yolov5/issues/3754",
            "+                    with warnings.catch_warnings():",
            "+                        warnings.simplefilter('ignore')  # suppress jit trace warning",
            "+                        self.tb.add_graph(torch.jit.trace(de_parallel(model), imgs[0:1], strict=False), [])",
            "if ni < 3:",
            "f = self.save_dir / f'train_batch{ni}.jpg'  # filename",
            "Thread(target=plot_images, args=(imgs, targets, paths, f), daemon=True).start()"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 4311,
        "label": "yes",
        "change": [
            "class Model:",
            "enc = tf.layers.max_pooling1d(enc, 2, 1, padding=\"same\")  # (N, T, K * E / 2)",
            "",
            "### Conv1D projections",
            "-            enc = conv1d(enc, hp.hidden_units // 2, 3, scope=\"conv1d_1\")  # (N, T, E/2)",
            "-            enc = normalize(enc, type=hp.norm_type, is_training=self.is_training, activation_fn=tf.nn.relu)",
            "-            enc = conv1d(enc, hp.hidden_units // 2, 3, scope=\"conv1d_2\")  # (N, T, E/2)",
            "+            enc = conv1d(enc, hp.hidden_units // 2, 3, scope=\"conv1d_1\", activation_fn=tf.nn.relu)  # (N, T, E/2)",
            "+            enc = normalize(enc, type=hp.norm_type, is_training=self.is_training)",
            "+            enc = conv1d(enc, hp.hidden_units // 2, 3, scope=\"conv1d_2\", activation_fn=None)  # (N, T, E/2)",
            "enc += prenet_out  # (N, T, E/2) # residual connections",
            "",
            "### Highway Nets"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 4312,
        "label": "no",
        "change": [
            "def eval_on_ILSVRC12(model, model_file, dataflow):",
            "",
            "def image_preprocess(image, bgr=True):",
            "if image.dtype.base_dtype != tf.float32:",
            "-        image = tf.case(image, tf.float32)",
            "+        image = tf.cast(image, tf.float32)",
            "image = image * (1.0 / 255)",
            "",
            "mean = [0.485, 0.456, 0.406]    # rgb"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4313,
        "label": "no",
        "change": [
            "class Multinomial(Distribution):",
            "n = int(n.data.cpu()[0][0])",
            "else:",
            "n = int(n.data.cpu()[0])",
            "-        return Variable(torch.multinomial(ps.data, n, replacement=True))",
            "+        return Variable(torch_multinomial(ps.data, n, replacement=True))",
            "",
            "def batch_log_pdf(self, x, ps=None, n=None):",
            "ps, n = self._sanitize_input(ps, n)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4314,
        "label": "yes",
        "change": [
            "def build_targets(p, targets, model):",
            "tcls, tbox, indices, av = [], [], [], []",
            "reject, use_all_anchors = True, True",
            "gain = torch.ones(6, device=targets.device)  # normalized to gridspace gain",
            "+",
            "+    # m = list(model.modules())[-1]",
            "+    # for i in range(m.nl):",
            "+    #     anchor_vec = m.anchor_vec[i]",
            "multi_gpu = type(model) in (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel)",
            "for i, j in enumerate(model.yolo_layers):",
            "# get number of grid points and anchor vec for this yolo layer",
            "anchor_vec = model.module.module_list[j].anchor_vec if multi_gpu else model.module_list[j].anchor_vec",
            "",
            "# iou of targets-anchors",
            "-        gain[2:] = torch.tensor(p[i].shape)[[2, 3, 2, 3]]  # xyxy gain",
            "+        gain[2:] = torch.tensor(p[i].shape)[[3, 2, 3, 2]]  # xyxy gain",
            "t, a = targets * gain, []",
            "gwh = t[:, 4:6]",
            "if nt:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 4316,
        "label": "no",
        "change": [
            "class GaussianHJM(quasi_gaussian_hjm.QuasiGaussianHJM):",
            "",
            "self._exact_discretization_setup(dim)",
            "super(quasi_gaussian_hjm.QuasiGaussianHJM,",
            "-            self).__init__(dim, _drift_fn, _vol_fn, dtype, self._name)",
            "+            self).__init__(dim, _drift_fn, _vol_fn, self._dtype, self._name)",
            "",
            "def sample_paths(self,",
            "times,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4317,
        "label": "no",
        "change": [
            "class AcceleratorConnector:",
            "",
            "def _init_deterministic(self, deterministic: Optional[Union[bool, _LITERAL_WARN]]) -> None:",
            "self.deterministic = deterministic or False  # default to False if not set",
            "-        if _TORCH_GREATER_EQUAL_1_11 and deterministic == \"warn\":",
            "+        if deterministic == \"warn\":",
            "torch.use_deterministic_algorithms(True, warn_only=True)",
            "-        else:",
            "-            torch.use_deterministic_algorithms(self.deterministic)",
            "if self.deterministic:",
            "# https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility",
            "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4318,
        "label": "yes",
        "change": [
            "def linear_resample(x, num_samples, axis=-1):",
            "num_x_dims = len(x_shape)",
            "axis = axis % num_x_dims",
            "num_vals = x.shape[axis]",
            "-    if x.dtype not in ['float16','float32','float64']:",
            "-        x=tf.cast(x,tf.float32)",
            "+    if x.dtype not in [\"float16\", \"float32\", \"float64\"]:",
            "+        x = tf.cast(x, tf.float32)",
            "xp = tf.range(num_vals, dtype=tf.float32)",
            "x_coords = tf.range(num_samples, dtype=tf.float32) * (",
            "-                (num_vals - 1) / (num_samples - 1)",
            "+            (num_vals - 1) / (num_samples - 1)",
            ")",
            "else:",
            "xp = tf.range(num_vals, dtype=x.dtype)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 4320,
        "label": "no",
        "change": [
            "class PreTrainedModel(nn.Module, ModuleUtilsMixin, GenerationMixin, PushToHubMix",
            "resolved_archive_file = [resolved_archive_file]",
            "",
            "for archive_file in resolved_archive_file:",
            "-            state_dict = torch.load(resolved_archive_file, map_location=\"cpu\")",
            "+            state_dict = torch.load(archive_file, map_location=\"cpu\")",
            "",
            "# materialize state_dict entries one by one on CPU",
            "for k in loaded_state_dict_keys:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4323,
        "label": "no",
        "change": [
            "class DataCollatorForLanguageModeling:",
            ") -> torch.Tensor:",
            "# In order to accept both lists of lists and lists of Tensors",
            "if isinstance(examples[0], (list, tuple)):",
            "-            examples = [torch.Tensor(e) for e in examples]",
            "+            examples = [torch.tensor(e, dtype=torch.long) for e in examples]",
            "length_of_first = examples[0].size(0)",
            "are_tensors_same_length = all(x.size(0) == length_of_first for x in examples)",
            "if are_tensors_same_length:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4326,
        "label": "no",
        "change": [
            "def train_loop_per_worker(config):",
            "import horovod.torch as hvd",
            "",
            "hvd.init()",
            "-    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
            "+    device = ray.train.torch.get_device()",
            "mode = config[\"mode\"]",
            "net = Net(mode).to(device)",
            "optimizer = torch.optim.SGD("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4327,
        "label": "no",
        "change": [
            "class ExpandDims(Preprocessor):",
            "return shape[:position] + (1,) + shape[position:]",
            "",
            "def tf_process(self, tensor):",
            "-        # Flatten tensor",
            "-        return tf.expand_dims(tensor, self.axis)",
            "+        # Expand tensor.",
            "+        return tf.expand_dims(input=tensor, axis=self.axis)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4329,
        "label": "no",
        "change": [
            "def unravel_index(",
            "*,",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "-    temp = indices.to(\"int64\")",
            "+    temp = indices.detach()",
            "output = []",
            "for dim in reversed(shape):",
            "output.append(temp % dim)",
            "temp = temp // dim",
            "-    return torch.tensor(reversed(output))",
            "+    return torch.tensor(reversed(output), dtype=torch.int64)",
            "",
            "",
            "unravel_index.support_native_out = False"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4330,
        "label": "no",
        "change": [
            "class E2E(ASRInterface, torch.nn.Module):",
            "lpz = None",
            "",
            "word_eds, word_ref_lens, char_eds, char_ref_lens = [], [], [], []",
            "-            nbest_hyps = self.dec.recognize_beam_batch(hs_pad, torch.tensor(hlens), lpz,",
            "-                                                       self.recog_args, self.char_list,",
            "-                                                       self.rnnlm,",
            "-                                                       tgt_lang_ids=tgt_lang_ids.squeeze(1).tolist() if self.replace_sos else None)",
            "+            nbest_hyps = self.dec.recognize_beam_batch(",
            "+                hs_pad, torch.tensor(hlens), lpz,",
            "+                self.recog_args, self.char_list,",
            "+                self.rnnlm,",
            "+                tgt_lang_ids=tgt_lang_ids.squeeze(1).tolist() if self.replace_sos else None)",
            "# remove <sos> and <eos>",
            "y_hats = [nbest_hyp[0]['yseq'][1:-1] for nbest_hyp in nbest_hyps]",
            "for i, y_hat in enumerate(y_hats):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4331,
        "label": "no",
        "change": [
            "def _calculate_expected_result(",
            "# PyTorch does not currently support Huber loss with custom delta so we define it ourself",
            "def huber_loss(input, target, delta: float = 1.0):",
            "errors = torch.abs(input - target)  # shape (batch_size,)",
            "-    return torch.where(errors < delta, 0.5 * errors ** 2, errors * delta - (0.5 * delta ** 2))",
            "+    return torch.where(errors < delta, 0.5 * errors**2, errors * delta - (0.5 * delta**2))",
            "",
            "",
            "def _calculate_regression_loss("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4332,
        "label": "no",
        "change": [
            "def ctc_decode(y_pred, input_length, greedy=True, beam_width=100,",
            "the log probability of each decoded sequence.",
            "\"\"\"",
            "y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + epsilon())",
            "-    input_length = tf.to_int32(input_length)",
            "+    input_length = tf.cast(input_length, tf.int32)",
            "",
            "if greedy:",
            "(decoded, log_prob) = ctc.ctc_greedy_decoder("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4334,
        "label": "no",
        "change": [
            "class local(BaseOp):",
            "tf.nn.conv2d(tij, kij,",
            "padding = 'VALID',",
            "strides = [1] * 4))",
            "-                out += [tf.concat(row_i, 2)]",
            "+            out += [tf.concat(row_i, 2)]",
            "",
            "-            self.out = tf.concat(out, 1)",
            "+        self.out = tf.concat(out, 1)",
            "",
            "def speak(self):",
            "l = self.lay"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4335,
        "label": "no",
        "change": [
            "class TacotronGST(nn.Module):",
            "forward_attn, trans_agent, forward_attn_mask,",
            "location_attn, separate_stopnet)",
            "self.postnet = PostCBHG(mel_dim)",
            "-        self.last_linear = nn.Sequential(",
            "-            nn.Linear(self.postnet.cbhg.gru_features * 2, linear_dim),",
            "-            nn.Sigmoid())",
            "+        self.last_linear = nn.Linear(self.postnet.cbhg.gru_features * 2, linear_dim)",
            "+",
            "",
            "def forward(self, characters, text_lengths, mel_specs, speaker_ids=None):",
            "B = characters.size(0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4337,
        "label": "no",
        "change": [
            "def set_model_weights_in_torch(weights, torch_model, hidden_size):",
            "assert (",
            "position_embeddings.weights[emb_idx].shape == emb_weights.shape",
            "), f\"{position_embeddings[emb_idx]} emb does not match\"",
            "-            position_embeddings.weights[emb_idx] = torch.nn.Parameter(torch.tensor(emb_weights))",
            "+            position_embeddings.weights[emb_idx] = nn.Parameter(torch.tensor(emb_weights))",
            "",
            "trax_layer_weights = weights[5]",
            "assert len(torch_model_reformer.encoder.layers) * 4 == len("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4340,
        "label": "yes",
        "change": [
            "def split(data, batch):",
            "if data.x is not None:",
            "slices['x'] = node_slice",
            "else:",
            "-        data.num_nodes = torch.bincount(batch).tolist()",
            "-        slices['num_nodes'] = torch.arange(len(data.num_nodes) + 1)",
            "+        # Imitate `collate` functionality:",
            "+        data._num_nodes = torch.bincount(batch).tolist()",
            "+        data.num_nodes = batch.numel()",
            "if data.edge_attr is not None:",
            "slices['edge_attr'] = edge_slice",
            "if data.y is not None:"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 4344,
        "label": "yes",
        "change": [
            "def densenet_block(incoming, nb_layers, growth, bottleneck=True,",
            "\"\"\"",
            "densenet = incoming",
            "",
            "-    with tf.variable_scope(scope, default_name=name, values=[incoming],",
            "-                           reuse=reuse) as scope:",
            "+    for i in range(nb_layers):",
            "",
            "-        for i in range(nb_layers):",
            "+        with tf.variable_scope(scope, default_name=name, values=[incoming],",
            "+                               reuse=reuse) as scope:",
            "",
            "# Identity",
            "conn = densenet"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 4345,
        "label": "no",
        "change": [
            "def sinc(",
            "def vorbis_window(",
            "window_length: Union[tf.Tensor, tf.Variable],",
            "*,",
            "-    dtype:Optional[tf.DType] = tf.dtypes.float32,",
            "-    out: Optional[Union[tf.Tensor, tf.Variable]] = None",
            "+    dtype: Optional[tf.DType] = tf.dtypes.float32,",
            "+    out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "-    return tf.signal.vorbis_window(",
            "-    window_length,",
            "-    dtype=dtype,",
            "-    name=None",
            "-    )",
            "\\ No newline at end of file",
            "+    return tf.signal.vorbis_window(window_length, dtype=dtype, name=None)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4346,
        "label": "no",
        "change": [
            "class GPT2ModelLanguageGenerationTest(unittest.TestCase):",
            "@slow",
            "def test_lm_generate_distilgpt2(self):",
            "model = GPT2LMHeadModel.from_pretrained(\"distilgpt2\")",
            "-        input_ids = torch.tensor([[463, 1893]], dtype=torch.long, device=torch_device)  # The president",
            "+        input_ids = torch.tensor([[464, 1893]], dtype=torch.long, device=torch_device)  # The president",
            "expected_output_ids = [",
            "464,",
            "1893,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4349,
        "label": "no",
        "change": [
            "_RETURNTYPES = _descriptor.Descriptor(",
            "syntax=\"proto3\",",
            "extension_ranges=[],",
            "oneofs=[],",
            "-    serialized_start=122,",
            "-    serialized_end=197,",
            "+    serialized_start=83,",
            "+    serialized_end=158,",
            ")",
            "",
            "_RETURNTYPES.fields_by_name["
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4350,
        "label": "yes",
        "change": [
            "class CTRLModel(CTRLPreTrainedModel):",
            "inputs_embeds = self.w(input_ids)",
            "# inputs_embeds = embedded.unsqueeze(0) if len(input_ids.shape)<2 else embedded",
            "seq_len = input_ids.shape[-1]",
            "-        mask = torch.triu(torch.ones(seq_len, seq_len), 1).to(inputs_embeds.device)",
            "+        mask = torch.triu(torch.ones(seq_len + past_length, seq_len + past_length), 1).to(inputs_embeds.device)",
            "",
            "inputs_embeds *= np.sqrt(self.d_model_size)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 4351,
        "label": "no",
        "change": [
            "def main():",
            "",
            "losses = torch.cat(losses)",
            "losses = losses[: len(eval_dataset)]",
            "-        perplexity = math.exp(torch.mean(losses))",
            "+        try:",
            "+            perplexity = math.exp(torch.mean(losses))",
            "+        except OverflowError:",
            "+            perplexity = float(\"inf\")",
            "",
            "logger.info(f\"epoch {epoch}: perplexity: {perplexity}\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4353,
        "label": "no",
        "change": [
            "def test_deep_graph_infomax():",
            "loss = model.loss(pos_z, neg_z, summary)",
            "assert 0 <= loss.item()",
            "",
            "-    acc = model.test(",
            "-        torch.ones(20, 16), torch.randint(10, (20, )), torch.ones(20, 16),",
            "-        torch.randint(10, (20, )))",
            "+    acc = model.test(torch.ones(20, 16), torch.randint(10, (20, )),",
            "+                     torch.ones(20, 16), torch.randint(10, (20, )))",
            "assert 0 <= acc and acc <= 1"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4356,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            ".BatchNorm('lastbn')",
            ".apply(nonlin)",
            ".GlobalAvgPooling('gap')",
            "-                      .tf.mul(49)  # this is due to a bug in our model design",
            "+                      .tf.multiply(49)  # this is due to a bug in our model design",
            ".FullyConnected('fct', 1000)())",
            "prob = tf.nn.softmax(logits, name='output')",
            "wrong = prediction_incorrect(logits, label, 1, name='wrong-top1')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4358,
        "label": "no",
        "change": [
            "def shape(x, unknown=-1):",
            "",
            "",
            "def no_operation():",
            "+    # return tf.constant(value=False, dtype=tf_dtype(dtype='bool'))",
            "return identity_operation(x=tf.constant(value=False, dtype=tf_dtype(dtype='bool')))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4360,
        "label": "no",
        "change": [
            "class Affine(nn.Module):",
            "self.translation = translation",
            "",
            "if scale_factor is None:",
            "-            scale_factor = torch.ones(batch_size)",
            "+            scale_factor = torch.ones(batch_size, 2)",
            "self.scale_factor = scale_factor",
            "",
            "self.shear = shear"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4363,
        "label": "no",
        "change": [
            "def rmspe_loss(targets: torch.Tensor, predictions: torch.Tensor) -> torch.Tensor",
            "def mean_confidence_penalty(probabilities: torch.Tensor, num_classes: int) -> torch.Tensor:",
            "max_entropy = torch.log(torch.tensor(num_classes))",
            "# clipping needed for avoiding log(0) = -inf",
            "-    entropy_per_class = torch.maximum(-probabilities * torch.log(torch.clamp(probabilities, 1e-10, 1)), 0)",
            "+    entropy_per_class, _ = torch.max(-probabilities * torch.log(torch.clamp(probabilities, 1e-10, 1)), dim=0)",
            "entropy = torch.sum(entropy_per_class, -1)",
            "penalty = (max_entropy - entropy) / max_entropy",
            "return torch.mean(penalty)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4367,
        "label": "no",
        "change": [
            "class DistributedTrainingTest(tf.test.TestCase):",
            "strategy.cluster_resolver",
            "and strategy.cluster_resolver.task_type == \"worker\"",
            "):",
            "-            # Workaround for an issue with",
            "-            # `tf.distribute.MultiWorkerMirroredStrategy`",
            "+            # The below assertion is run by both chief and workers when using",
            "+            # `tf.distribute.MultiWorkerMirroredStrategy`, but only the chief",
            "+            # will log events.",
            "events_expected = []",
            "",
            "self.assertEqual(events_got, events_expected)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4370,
        "label": "no",
        "change": [
            "def test_is_small_dataset(",
            "dataset_size, config_max_in_memory_dataset_size, env_max_in_memory_dataset_size, monkeypatch",
            "):",
            "if config_max_in_memory_dataset_size != \"default\":",
            "-        monkeypatch.setattr(",
            "-            datasets.config, \"HF_MAX_IN_MEMORY_DATASET_SIZE_IN_BYTES\", config_max_in_memory_dataset_size",
            "-        )",
            "+        monkeypatch.setattr(datasets.config, \"IN_MEMORY_MAX_SIZE\", config_max_in_memory_dataset_size)",
            "",
            "-    max_in_memory_dataset_size = datasets.config.HF_MAX_IN_MEMORY_DATASET_SIZE_IN_BYTES",
            "+    max_in_memory_dataset_size = datasets.config.IN_MEMORY_MAX_SIZE",
            "if config_max_in_memory_dataset_size == \"default\":",
            "if env_max_in_memory_dataset_size:",
            "assert max_in_memory_dataset_size == env_max_in_memory_dataset_size"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4372,
        "label": "no",
        "change": [
            "def check_batch_state(state, max_len, pad_token):",
            "",
            "",
            "def custom_torch_load(model_path, model, training=True):",
            "-    \"\"\"Custom torch loading for transducer-models modules and parameters.",
            "+    \"\"\"Load transducer model modules and parameters with training-only ones removed.",
            "",
            "Args:",
            "-        model_path (str): Model path.",
            "-        model (torch.nn.Module): The model with pretrained modules.",
            "+        model_path (str): Model path",
            "+        model (torch.nn.Module): The model with pretrained modules",
            "",
            "\"\"\"",
            "if \"snapshot\" in os.path.basename(model_path):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4374,
        "label": "no",
        "change": [
            "class ConvBnAct(nn.Module):",
            "x = self.drop_block(x)",
            "if self.act is not None:",
            "x = self.act(x)",
            "+        if self.aa is not None:",
            "+            x = self.aa(x)",
            "return x"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4376,
        "label": "no",
        "change": [
            "class PearsonCorrelation(Metric):",
            "labels_variance = self._labels_variance.get_metric(reset=reset)",
            "if reset:",
            "self.reset()",
            "-        denominator = (math.sqrt(predictions_variance) * math.sqrt(labels_variance))",
            "+        denominator = math.sqrt(predictions_variance) * math.sqrt(labels_variance)",
            "if np.around(denominator, decimals=5) == 0:",
            "pearson_r = 0",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4377,
        "label": "no",
        "change": [
            "class ImageSegmentationPipeline(Pipeline):",
            "",
            "return super().__call__(*args, **kwargs)",
            "",
            "+    def get_inference_context(self):",
            "+        return torch.no_grad",
            "+",
            "def preprocess(self, image):",
            "image = self.load_image(image)",
            "target_size = torch.IntTensor([[image.height, image.width]])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4378,
        "label": "yes",
        "change": [
            "def _compute_equalized_tiles(interp_tiles: torch.Tensor, luts: torch.Tensor) ->",
            "tiles_equalized: torch.Tensor = torch.zeros_like(interp_tiles, dtype=torch.long)",
            "",
            "# compute the interpolation weights (shapes are 2 x TH x TW because they must be applied to 2 interp tiles)",
            "-    ih = torch.arange(2 * th - 1, -1, -1, device=interp_tiles.device).div(2. * th - 1)[None].T.expand(2 * th, tw)",
            "+    ih = torch.arange(2 * th - 1, -1, -1, device=interp_tiles.device).div(",
            "+        2. * th - 1)[None].transpose(-2, -1).expand(2 * th, tw)",
            "ih = ih.unfold(0, th, th).unfold(1, tw, tw)  # 2 x 1 x TH x TW",
            "iw = torch.arange(2 * tw - 1, -1, -1, device=interp_tiles.device).div(2. * tw - 1).expand(th, 2 * tw)",
            "iw = iw.unfold(0, th, th).unfold(1, tw, tw)  # 1 x 2 x TH x TW"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 4381,
        "label": "yes",
        "change": [
            "class DeepSpeedEngine(Module):",
            "if self.zero_optimization_partition_weights() and any(",
            "[hasattr(param,",
            "'ds_id') for param in self.module.parameters()]):",
            "-                assert all([param.dtype == torch.half for param in self.module.parameters()]), f\"Model must initialized in fp16 mode for ZeRO Stage 3.\"",
            "+                assert all([param.dtype == torch.half for param in self.module.parameters()]), \"fp16 is enabled but one or several model parameters have dtype that is not fp16\"",
            "self.module.half()",
            "else:",
            "-            assert all([param.dtype == torch.float for param in self.module.parameters()]), f\"fp16 is not enabled but one or several model parameters have dtype of fp16\"",
            "+            assert all([param.dtype == torch.float for param in self.module.parameters()]), \"fp16 is not enabled but one or several model parameters have dtype of fp16\"",
            "",
            "if not self.dont_change_device:",
            "self.module.to(self.device)"
        ],
        "comments": "",
        "Symptom": "return warning",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 4387,
        "label": "no",
        "change": [
            "class Decoder(torch.nn.Module):",
            "local_best_scores, joint_best_ids = torch.topk(local_scores, beam, dim=1)",
            "local_best_ids = local_best_ids[:, joint_best_ids[0]]",
            "else:",
            "-                    local_best_scores, local_best_ids = torch.topk(local_att_scores, beam, dim=1)",
            "+                    local_best_scores, local_best_ids = torch.topk(local_scores, beam, dim=1)",
            "",
            "for j in six.moves.range(beam):",
            "new_hyp = {}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4391,
        "label": "no",
        "change": [
            "class L1LossMasked(nn.Module):",
            "# target_flat: (batch * max_len, dim)",
            "target_flat = target.view(-1, target.shape[-1])",
            "# losses_flat: (batch * max_len, dim)",
            "-        losses_flat = functional.l1_loss(input, target, size_average=False,",
            "+        losses_flat = functional.l1_loss(input, target_flat, size_average=False,",
            "reduce=False)",
            "# losses: (batch, max_len, dim)",
            "losses = losses_flat.view(*target.size())"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4393,
        "label": "no",
        "change": [
            "def stat_scores_multiple_classes(",
            "",
            "tps = torch.zeros((num_classes + 1,), device=pred.device)",
            "fps = torch.zeros((num_classes + 1,), device=pred.device)",
            "-        tns = torch.zeros((num_classes + 1,), device=pred.device)",
            "fns = torch.zeros((num_classes + 1,), device=pred.device)",
            "sups = torch.zeros((num_classes + 1,), device=pred.device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4396,
        "label": "no",
        "change": [
            "if __name__ == '__main__':",
            "parser.add_argument(dest='output', help='output model file, can be npz or TF checkpoint')",
            "args = parser.parse_args()",
            "",
            "-    tf.train.import_meta_graph(args.meta)",
            "+    tf.train.import_meta_graph(args.meta, clear_devices=True)",
            "",
            "# loading...",
            "init = get_model_loader(args.input)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4397,
        "label": "yes",
        "change": [
            "class TrainerTrainLoopMixin(ABC):",
            "if self.reload_dataloaders_every_epoch:",
            "self.reset_train_dataloader(self.get_model())",
            "",
            "+        # track local dataloader so TPU can wrap each epoch",
            "+        train_dataloader = self.train_dataloader",
            "+",
            "# on TPU we have to wrap it under the ParallelLoader",
            "if self.use_tpu:",
            "device = xm.xla_device()",
            "-            self.train_dataloader = xla_pl.ParallelLoader(self.train_dataloader, [device])",
            "-            self.train_dataloader = self.train_dataloader.per_device_loader(device)",
            "+            train_dataloader = xla_pl.ParallelLoader(train_dataloader, [device])",
            "+            train_dataloader = train_dataloader.per_device_loader(device)",
            "",
            "# run epoch",
            "for batch_idx, batch in self.profiler.profile_iterable(",
            "-            enumerate(self.train_dataloader), \"get_train_batch\"",
            "+            enumerate(train_dataloader), \"get_train_batch\"",
            "):",
            "# stop epoch if we limited the number of training batches",
            "if batch_idx >= self.num_training_batches:"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 4398,
        "label": "no",
        "change": [
            "class TFGroupViTModel(TFGroupViTPreTrainedModel):",
            "@tf.function(",
            "input_signature=[",
            "{",
            "-                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),",
            "+                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),",
            "\"pixel_values\": tf.TensorSpec((None, None, None, None), tf.float64, name=\"pixel_values\"),",
            "-                \"attention_mask\": tf.TensorSpec((None, None), tf.int64, name=\"attention_mask\"),",
            "+                \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),",
            "}",
            "]",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4400,
        "label": "no",
        "change": [
            "class StochasticDurationPredictor(torch.nn.Module):",
            "z, logdet = flow(z, x_mask, g=x, inverse=inverse)",
            "logdet_tot = logdet_tot + logdet",
            "nll = (",
            "-                torch.sum(0.5 * (math.log(2 * math.pi) + (z ** 2)) * x_mask, [1, 2])",
            "+                torch.sum(0.5 * (math.log(2 * math.pi) + (z**2)) * x_mask, [1, 2])",
            "- logdet_tot",
            ")",
            "return nll + logq  # (B,)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4401,
        "label": "no",
        "change": [
            "class RPNHead(AnchorHead):",
            "if cfg.min_bbox_size > 0:",
            "w = proposals[:, 2] - proposals[:, 0]",
            "h = proposals[:, 3] - proposals[:, 1]",
            "-            valid_inds = torch.nonzero((w >= cfg.min_bbox_size)",
            "-                                       & (h >= cfg.min_bbox_size)).squeeze()",
            "+            valid_inds = torch.nonzero(",
            "+                (w >= cfg.min_bbox_size)",
            "+                & (h >= cfg.min_bbox_size),",
            "+                as_tuple=False).squeeze()",
            "if valid_inds.sum().item() != len(proposals):",
            "proposals = proposals[valid_inds, :]",
            "scores = scores[valid_inds]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4403,
        "label": "no",
        "change": [
            "class RandomResizedCrop(AugmentationBase):",
            "else:",
            "batch_shape = input.shape",
            "params = RandomResizedCrop.get_params(",
            "-                batch_size, batch_shape[-2:], self.size, self.scale, self.ratio)  # type: ignore",
            "+                batch_size, batch_shape[-2:], self.size, self.scale, self.ratio)",
            "return super().forward(input, params)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4404,
        "label": "no",
        "change": [
            "def resnet_group(l, name, block_func, features, count, stride):",
            "",
            "def resnet_backbone(image, num_blocks, group_func, block_func):",
            "with argscope(Conv2D, nl=tf.identity, use_bias=False,",
            "-                  W_init=tf.variance_scaling_initializer(scale=2.0, mode='FAN_OUT')):",
            "+                  W_init=tf.variance_scaling_initializer(scale=2.0, mode='fan_out')):",
            "logits = (LinearWrap(image)",
            ".Conv2D('conv0', 64, 7, stride=2, nl=BNReLU)",
            ".MaxPooling('pool0', shape=3, stride=2, padding='SAME')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4407,
        "label": "yes",
        "change": [
            "class LKJCorrCholesky(TorchDistribution):",
            "super().__init__(torch.Size(), torch.Size((d, d)), validate_args=validate_args)",
            "",
            "def sample(self, sample_shape=torch.Size()):",
            "-        y = self._gen.sample(sample_shape=self.batch_shape + sample_shape).detach()",
            "+        with torch.no_grad():",
            "+            y = self._gen.sample(sample_shape=sample_shape + self.batch_shape)",
            "z = y.mul(2).add(-1.0)",
            "return _vector_to_l_cholesky(z)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "state handling error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 4411,
        "label": "no",
        "change": [
            "def upload_to_s3_using_presigned(",
            ")  # maintain list of part no and ETag",
            "",
            "# Step 4 - Send a message to PyGrid informing about dataset upload complete!",
            "-        upload_response = client.datasets.perform_request(",
            "+        client.datasets.perform_request(",
            "syft_msg=UploadDataCompleteMessage,",
            "content={",
            "\"upload_id\": upload_response.payload.upload_id,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4416,
        "label": "no",
        "change": [
            "class ExpandDimsLayer(Layer):",
            "class TileLayer(Layer):",
            "\"\"\"",
            "The :class:`TileLayer` class constructs a tensor by tiling a given tensor,",
            "-    see `tf.tile() <https://www.tensorflow.org/api_docs/python/array_ops/slicing_and_joining#tile>`__ .",
            "+    see `tf.tile() <https://www.tensorflow.org/api_docs/python/tf/tile>`__ .",
            "",
            "Parameters"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4417,
        "label": "no",
        "change": [
            "def thresholded_relu(",
            "x: Tensor,",
            "/,",
            "*,",
            "-    threshold: Optional[Union[int, float]] = 0,",
            "+    threshold: Union[int, float] = 0,",
            "out: Optional[Tensor] = None,",
            ") -> Tensor:",
            "return tf.where(x > threshold, x, 0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4420,
        "label": "no",
        "change": [
            "class TimeDistributedLayer(Layer):",
            "",
            "self.outputs = tf.stack(x, axis=1, name=name)",
            "",
            "-        self.all_layers.append(self.outputs)",
            "-        self.all_params.extend(variables)",
            "+        self._add_layers(self.outputs)",
            "+        self._add_params(variables)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4421,
        "label": "no",
        "change": [
            "def linear_layer(x, size):",
            "",
            "",
            "def dense_layer(x, size):",
            "-    with tf.variable_scope('linear'):",
            "+    with tf.variable_scope('dense'):",
            "weights = tf.Variable(initial_value=tf.random_normal(shape=(x.get_shape()[1].value, size), stddev=sqrt(2.0 / (x.get_shape()[1].value + size))))",
            "x = tf.matmul(a=x, b=weights)",
            "x = tf.nn.relu(features=x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4424,
        "label": "no",
        "change": [
            "class DistilBertModel(DistilBertPreTrainedModel):",
            "else:",
            "raise ValueError(\"You have to specify either input_ids or inputs_embeds\")",
            "",
            "+        device = input_ids.device if input_ids is not None else inputs_embeds.device",
            "+",
            "if attention_mask is None:",
            "-            attention_mask = torch.ones(input_shape) # (bs, seq_length)",
            "+            attention_mask = torch.ones(input_shape, device=device) # (bs, seq_length)",
            "",
            "# Prepare head mask if needed",
            "# 1.0 in head_mask indicate we keep the head"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4425,
        "label": "no",
        "change": [
            "class LatentDiffusion(DiffusionPipeline):",
            "# 3. optionally sample variance",
            "variance = 0",
            "if eta > 0:",
            "-                noise = torch.randn(image.shape, generator=generator, device=image.device)",
            "+                noise = torch.randn(image.shape, generator=generator)to(image.device)",
            "variance = self.noise_scheduler.get_variance(t, num_inference_steps).sqrt() * eta * noise",
            "",
            "# 4. set current image to prev_image: x_t -> x_t-1"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4428,
        "label": "no",
        "change": [
            "class EmbedSequence(Layer):",
            "self.dropout = None",
            "",
            "def call(self, inputs, training=None, mask=None):",
            "-        embedded = self.embed(",
            "-            inputs, training=None, mask=None",
            "+        embedded = tf.nn.embedding_lookup(",
            "+            self.embeddings, inputs, name='embeddings_lookup'",
            ")",
            "",
            "# TODO use tf2 mechanism for masking"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4429,
        "label": "yes",
        "change": [
            "def fit_circle_in_2d(",
            "n_provided = points2d.shape[0]",
            "if n_provided < 3:",
            "raise ValueError(f\"{n_provided} points are not enough to determine a circle\")",
            "-    solution = lstsq(design, rhs)",
            "-    center = solution[:2] / 2",
            "-    radius = torch.sqrt(solution[2] + (center ** 2).sum())",
            "+    solution = lstsq(design, rhs[:, None])",
            "+    center = solution[:2, 0] / 2",
            "+    radius = torch.sqrt(solution[2, 0] + (center ** 2).sum())",
            "if n_points > 0:",
            "if angles is not None:",
            "warnings.warn(\"n_points ignored because angles provided\")"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 4431,
        "label": "no",
        "change": [
            "def _generate_image_and_label_batch(image, label, min_queue_examples,",
            "capacity=min_queue_examples + 3 * batch_size)",
            "",
            "# Display the training images in the visualizer.",
            "-  tf.image_summary('images', images)",
            "+  tf.summary.image('images', images)",
            "",
            "return images, tf.reshape(label_batch, [batch_size])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4434,
        "label": "no",
        "change": [
            "def distributed_init(cfg: FairseqConfig):",
            "cfg = convert_namespace_to_omegaconf(cfg)",
            "",
            "if not cfg.common.tpu:",
            "-        if torch.distributed.is_initialized():",
            "+        if torch.distributed.is_available() and torch.distributed.is_initialized():",
            "warnings.warn(",
            "\"Distributed is already initialized, cannot initialize twice!\"",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4436,
        "label": "no",
        "change": [
            "def disable_progress_bar():",
            "",
            "Usage:",
            "",
            "-    nlp.disable_progress_bar()",
            "+    datasets.disable_progress_bar()",
            "\"\"\"",
            "# Replace tqdm",
            "global _active"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4437,
        "label": "no",
        "change": [
            "class PredictConfig(object):",
            "assert_type(self.session_init, SessionInit, 'session_init')",
            "",
            "if session_creator is None:",
            "-            self.session_creator = tf.train.ChiefSessionCreator(config=get_default_sess_config())",
            "+            self.session_creator = NewSessionCreator(config=get_default_sess_config())",
            "else:",
            "self.session_creator = session_creator"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4445,
        "label": "no",
        "change": [
            "class ComplexInputNetwork(TorchModelV2, nn.Module):",
            "cnn_out, _ = self.cnns[i](SampleBatch({SampleBatch.OBS: component}))",
            "outs.append(cnn_out)",
            "elif i in self.one_hot:",
            "-                if component.dtype in [torch.int32, torch.int64, torch.uint8]:",
            "+                if component.dtype in [",
            "+                    torch.int8,",
            "+                    torch.int16,",
            "+                    torch.int32,",
            "+                    torch.int64,",
            "+                    torch.uint8,",
            "+                ]:",
            "one_hot_in = {",
            "SampleBatch.OBS: one_hot(",
            "component, self.flattened_input_space[i]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4446,
        "label": "no",
        "change": [
            "CUSTOM_FNS = {'lrelu001': lambda x: mtf.leaky_relu(x, alpha=0.01),",
            "'spike2': lambda x: mtf.exp(-x ** 2),",
            "'tanhshrink': lambda x: x - tanh(x),",
            "'softsign': lambda x: x / (mtf.abs(x) + 1),",
            "-              'softmax': lambda x: mtf.softmax(x, x.shape[-1])",
            "+              'softmax': lambda x: mtf.softmax(x, x.shape[-1]),",
            "'logsoftmax': lambda x: mtf.log_softmax(x, x.shape[-1]),",
            "'bipolarsigmoid': lambda x: mtf.sigmoid(x) * 2 - 1,",
            "'rrelu': _rrelu,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4448,
        "label": "no",
        "change": [
            "class ViTMAEEmbeddings(nn.Module):",
            "# unshuffle to get the binary mask",
            "mask = torch.gather(mask, dim=1, index=ids_restore)",
            "",
            "-        return sequence_masked, mask, ids_restore",
            "+        return sequence_unmasked, mask, ids_restore",
            "",
            "def forward(self, pixel_values, noise=None):",
            "batch_size, num_channels, height, width = pixel_values.shape"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4450,
        "label": "yes",
        "change": [
            "def generate_audio_mask_noise(audio_values, audio_mask=None, mask_ratio=0.75, ma",
            "if mask_type == \"frame-level\":",
            "num_time_patches = seq_len // freq_len",
            "noise = (",
            "-            torch.rand(batch_size, num_time_patches).unsqueeze(-1).repeat(1, 1, freq_len).view(batch_size, seq_len)",
            "+            torch.rand(batch_size, num_time_patches, device=audio_values.device)",
            "+            .unsqueeze(-1)",
            "+            .repeat(1, 1, freq_len)",
            "+            .view(batch_size, seq_len)",
            ")  # noise in [0, 1]",
            "elif mask_type == \"patch-level\":",
            "-        noise = torch.rand(batch_size, seq_len)  # noise in [0, 1]",
            "+        noise = torch.rand(batch_size, seq_len, device=audio_values.device)  # noise in [0, 1]",
            "len_keep = int(seq_len * (1 - mask_ratio))",
            "return noise, len_keep"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 4451,
        "label": "no",
        "change": [
            "class OrnsteinUhlenbeckNoise(GaussianNoise):",
            "ou_new = self.ou_theta * -self.ou_state + \\",
            "self.ou_sigma * gaussian_sample",
            "self.ou_state += ou_new",
            "-                high_low = torch.from_numpy(self.action_space.high -",
            "-                                            self.action_space.low).to(",
            "-                                                self.device)",
            "-                noise = scale * self.ou_base_scale * self.ou_state * high_low",
            "+                high_m_low = torch.from_numpy(",
            "+                    self.action_space.high - self.action_space.low). \\",
            "+                    to(self.device)",
            "+                noise = scale * self.ou_base_scale * self.ou_state * high_m_low",
            "action = torch.clamp(det_actions + noise,",
            "self.action_space.low[0],",
            "self.action_space.high[0])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4456,
        "label": "yes",
        "change": [
            "class TFCvtDropPath(tf.keras.layers.Layer):",
            "return x",
            "keep_prob = 1 - self.drop_prob",
            "shape = (tf.shape(x)[0],) + (1,) * (len(tf.shape(x)) - 1)",
            "-        random_tensor = keep_prob + tf.random.uniform(shape, 0, 1)",
            "+        random_tensor = keep_prob + tf.random.uniform(shape, 0, 1, dtype=self.compute_dtype)",
            "random_tensor = tf.floor(random_tensor)",
            "return (x / keep_prob) * random_tensor"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 4459,
        "label": "no",
        "change": [
            "class FrameScoreFeats(AbsFeatsExtract):",
            "pad = self.win_length // 2",
            "input_lengths = input_lengths + 2 * pad",
            "",
            "-            olens = (",
            "-                torch.div(",
            "-                    (input_lengths - self.win_length),",
            "-                    self.hop_length,",
            "-                    rounding_mode=\"floor\",",
            "-                )",
            "-                + 1",
            "-            )",
            "+            olens = (input_lengths - self.win_length) // self.hop_length + 1",
            "output.masked_fill_(make_pad_mask(olens, output, 1), 0.0)",
            "else:",
            "olens = None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4460,
        "label": "no",
        "change": [
            "def beta_linear_log_snr(t):",
            "",
            "@torch.jit.script",
            "def alpha_cosine_log_snr(t, s: float = 0.008):",
            "-    return -log((torch.cos((t + s) / (1 + s) * torch.pi * 0.5) ** -2) - 1)",
            "+    return -log((torch.cos((t + s) / (1 + s) * math.pi * 0.5) ** -2) - 1)",
            "",
            "def log_snr_to_alpha_sigma(log_snr):",
            "return torch.sqrt(torch.sigmoid(log_snr)), torch.sqrt(torch.sigmoid(-log_snr))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4464,
        "label": "no",
        "change": [
            "class TrainerLoggingMixin(ABC):",
            "elif isinstance(output[k], torch.Tensor) and output[k].dim() == 0:",
            "pass",
            "",
            "-            # reduce only metrics that have the same number of gpus",
            "-            elif output[k].size(0) == num_gpus:",
            "-                reduced = torch.mean(output[k])",
            "-                output[k] = reduced",
            "+            # do not reduce metrics that have batch size > num gpus",
            "+            elif output[k].size(0) <= num_gpus:",
            "+                output[k] = torch.mean(output[k])",
            "+",
            "return output"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4466,
        "label": "no",
        "change": [
            "class TestEncoderBase(AllenNlpTestCase):",
            ")",
            "",
            "# Check that error is raised if mask has wrong batch size.",
            "-        bad_mask = torch.FloatTensor([1, 1, 0])",
            "+        bad_mask = torch.BoolTensor([True, True, False])",
            "with self.assertRaises(ValueError):",
            "self.encoder_base.reset_states(bad_mask)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4467,
        "label": "yes",
        "change": [
            "class CLIPSegTextTransformer(nn.Module):",
            "# take features from the eot embedding (eot_token is the highest number in each sequence)",
            "# casting to torch.int for onnx compatibility: argmax doesn't support int64 inputs with opset 14",
            "pooled_output = last_hidden_state[",
            "-            torch.arange(last_hidden_state.shape[0], device=input_ids.device), input_ids.to(torch.int).argmax(dim=-1)",
            "+            torch.arange(last_hidden_state.shape[0], device=last_hidden_state.device),",
            "+            input_ids.to(dtype=torch.int, device=last_hidden_state.device).argmax(dim=-1),",
            "]",
            "",
            "if not return_dict:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 4474,
        "label": "no",
        "change": [
            "from horovod.common.util  import is_version_greater_equal_than",
            "",
            "if is_version_greater_equal_than(tf.__version__, \"2.6.0\"):",
            "from keras import backend as K",
            "-    if version.parse(keras.__version__) < version.parse(\"2.9.0\"):",
            "+    if version.parse(keras.__version__.replace(\"-tf\", \"+tf\")) < version.parse(\"2.9.0\"):",
            "from keras.optimizer_v2 import optimizer_v2",
            "else:",
            "from keras.optimizers.optimizer_v2 import optimizer_v2"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4476,
        "label": "yes",
        "change": [
            "def tversky_loss(input: torch.Tensor, target: torch.Tensor,",
            "# compute the actual dice score",
            "dims = (1, 2, 3)",
            "intersection = torch.sum(input_soft * target_one_hot, dims)",
            "-    fps = torch.sum(input_soft * (1. - target_one_hot), dims)",
            "-    fns = torch.sum((1. - input_soft) * target_one_hot, dims)",
            "+    fps = torch.sum(input_soft * (-target_one_hot + 1.), dims)",
            "+    fns = torch.sum((-input_soft + 1.) * target_one_hot, dims)",
            "",
            "numerator = intersection",
            "denominator = intersection + alpha * fps + beta * fns",
            "tversky_loss = numerator / (denominator + eps)",
            "-    return torch.mean(1. - tversky_loss)",
            "+    return torch.mean(-tversky_loss + 1.)",
            "",
            "",
            "class TverskyLoss(nn.Module):"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 4478,
        "label": "no",
        "change": [
            "class MetricsHolder:",
            "else:",
            "current = torch.tensor(current, device=device, dtype=torch.float)",
            "",
            "-        if use_tpu and _TPU_AVAILABLE:",
            "+        if isinstance(current, torch.Tensor) and current.device.type == \"xla\":",
            "current = current.cpu()",
            "",
            "return current"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4483,
        "label": "no",
        "change": [
            "class TFEncoderLayer(tf.keras.layers.Layer):",
            "if self.normalize_before:",
            "x = self.final_layer_norm(x)",
            "x = self.activation_fn(self.fc1(x))",
            "-        x = tf.nn.dropout(x, rate=self.self.activation_dropout if training else 0)",
            "+        x = tf.nn.dropout(x, rate=self.activation_dropout if training else 0)",
            "x = self.fc2(x)",
            "x = tf.nn.dropout(x, rate=self.dropout if training else 0)",
            "x = residual + x"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4484,
        "label": "no",
        "change": [
            "def test_mean_var(batch_shape):",
            "dim = 2",
            "loc = torch.randn(batch_shape + (dim,))",
            "A = torch.randn(batch_shape + (dim, dim + dim))",
            "-    scale_tril = A.matmul(A.transpose(-2, -1)).cholesky()",
            "+    scale_tril = torch.linalg.cholesky(A.matmul(A.transpose(-2, -1)))",
            "df = torch.randn(batch_shape).exp() + 4",
            "num_samples = 100000",
            "d = MultivariateStudentT(df, loc, scale_tril)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4485,
        "label": "no",
        "change": [
            "class DepthWarper(nn.Module):",
            "1.0 - delta_d)",
            "xy_p1 = self._compute_projection(self.width / 2, self.height / 2,",
            "1.0 + delta_d)",
            "-        dx = torch.norm((xy_p1 - xy_m1), 2, dim=2) / 2.0",
            "+        dx = torch.norm((xy_p1 - xy_m1), 2, dim=-1) / 2.0",
            "dxdd = dx / (delta_d)  # pixel*(1/meter)",
            "# half pixel sampling, we're interested in the min for all cameras",
            "return torch.min(0.5 / dxdd)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4487,
        "label": "no",
        "change": [
            "class BasicConv2d(nn.Module):",
            "",
            "def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):",
            "super(BasicConv2d, self).__init__()",
            "-        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False) # verify bias false",
            "-        self.bn = nn.BatchNorm2d(out_planes, eps=0.001, momentum=0, affine=True)",
            "+        self.conv = nn.Conv2d(in_planes, out_planes,",
            "+                              kernel_size=kernel_size, stride=stride,",
            "+                              padding=padding, bias=False) # verify bias false",
            "+        self.bn = nn.BatchNorm2d(out_planes,",
            "+                                 eps=0.001, # value found in tensorflow",
            "+                                 momentum=0.1, # default pytorch value",
            "+                                 affine=True)",
            "self.relu = nn.ReLU(inplace=True)",
            "",
            "def forward(self, x):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4490,
        "label": "no",
        "change": [
            "class TestAutoTensorParallelism(DistributedTest):",
            "",
            "# We have to load these large models on CPU with pipeline because not",
            "# enough GPU memory",
            "-        pipe = pipeline(task, model=model, device=-1, framework=\"pt\")",
            "+        pipe = pipeline(task, model=model, device=torch.device(\"cpu\"), framework=\"pt\")",
            "bs_output = pipe(query, **inf_kwargs)",
            "",
            "pipe.model = deepspeed.init_inference(pipe.model,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4492,
        "label": "no",
        "change": [
            "\"source\": [",
            "\"model.compile(optimizer='adam',\\n\",",
            "\"              loss=tf.losses.BinaryCrossentropy(from_logits=True),\\n\",",
            "-        \"              metrics=['accuracy'])\"",
            "+        \"              metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])\"",
            "]",
            "},",
            "{"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4493,
        "label": "no",
        "change": [
            "def random_intrinsics(low: Union[float, torch.Tensor], high: Union[float, torch.",
            "the random camera matrix with the shape of :math:`(1, 3, 3)`.",
            "\"\"\"",
            "sampler = torch.distributions.Uniform(low, high)",
            "-    fx, fy, cx, cy = (sampler.sample((1,)) for _ in range(4))",
            "+    fx, fy, cx, cy = (sampler.sample(torch.Size((1,))) for _ in range(4))",
            "zeros, ones = torch.zeros_like(fx), torch.ones_like(fx)",
            "camera_matrix: torch.Tensor = torch.cat([fx, zeros, cx, zeros, fy, cy, zeros, zeros, ones])",
            "return camera_matrix.view(1, 3, 3)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4494,
        "label": "no",
        "change": [
            "class AugmentationSequential(ImageSequential):",
            ") -> torch.Tensor:",
            "if isinstance(module, GeometricAugmentationBase2D):",
            "transform = module.compute_inverse_transformation(module.get_transformation_matrix(input, param))",
            "-            input = transform_boxes(torch.as_tensor(transform, device=input.device, dtype=input.dtype), input, mode)",
            "+            input = transform_bbox(torch.as_tensor(transform, device=input.device, dtype=input.dtype), input, mode)",
            "return input",
            "",
            "def inverse_keypoints("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4495,
        "label": "no",
        "change": [
            "def divide(",
            "x1, x2 = ivy.promote_types_of_inputs(x1, x2)",
            "ret = torch.div(x1, x2)",
            "if ivy.is_float_dtype(x1.dtype):",
            "-        ret = torch.tensor(ret, dtype=x1.dtype)",
            "+        ret = ret.to(x1.dtype)",
            "else:",
            "-        ret = torch.tensor(ret, dtype=ivy.default_float_dtype(as_native=True))",
            "+        ret = ret.to(ivy.default_float_dtype(as_native=True))",
            "return ret"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4498,
        "label": "yes",
        "change": [
            "class Trainer(object):",
            "last_optim_state = state.get(\"last_optimizer_state\", None)",
            "if last_optim_state == -1:",
            "master_path = re.sub(\"shard[0-9]+\", \"shard0\", filename)",
            "-                    last_optim_state = torch.load(master_path, map_location='cpu')['last_optimizer_state']",
            "+                    local_master_path = PathManager.get_local_path(master_path)",
            "+                    last_optim_state = torch.load(local_master_path, map_location='cpu')['last_optimizer_state']",
            "",
            "# If doing zero_sharding, do not broadcast global optimizer",
            "# state. Later we will broadcast sharded states to each rank"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 4499,
        "label": "no",
        "change": [
            "class ImageCaptioningInputPipeline(InputPipeline):",
            "self.params[\"caption_tokens_field\"]),",
            "\"target_len\": tfexample_decoder.ItemHandlerCallback(",
            "keys=[self.params[\"caption_tokens_field\"]],",
            "-            func=lambda dict: tf.size(dict[self.params[\"caption_tokens_field\"]]))",
            "+            func=lambda dict: tf.size(",
            "+                dict[self.params[\"caption_tokens_field\"]]))",
            "}",
            "",
            "decoder = TFSEquenceExampleDecoder("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4501,
        "label": "no",
        "change": [
            "from .base_bbox_coder import BaseBBoxCoder",
            "",
            "@BBOX_CODERS.register_module()",
            "class PseudoBBoxCoder(BaseBBoxCoder):",
            "+    \"\"\"Pseudo bounding box coder\"\"\"",
            "",
            "def __init__(self, **kwargs):",
            "super(BaseBBoxCoder, self).__init__(**kwargs)",
            "",
            "def encode(self, bboxes, gt_bboxes):",
            "+        \"\"\"torch.Tensor: return the given ``bboxes``\"\"\"",
            "return gt_bboxes",
            "",
            "def decode(self, bboxes, pred_bboxes):",
            "+        \"\"\"torch.Tensor: return the given ``pred_bboxes``\"\"\"",
            "return pred_bboxes"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4502,
        "label": "no",
        "change": [
            "class PNDMPipeline(DiffusionPipeline):",
            "# the official paper: https://arxiv.org/pdf/2202.09778.pdf",
            "",
            "# Sample gaussian noise to begin loop",
            "-        image = torch.randn(",
            "+        image = randn_tensor(",
            "(batch_size, self.unet.in_channels, self.unet.sample_size, self.unet.sample_size),",
            "generator=generator,",
            "+            device=self.device,",
            ")",
            "-        image = image.to(self.device)",
            "",
            "self.scheduler.set_timesteps(num_inference_steps)",
            "for t in self.progress_bar(self.scheduler.timesteps):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4503,
        "label": "no",
        "change": [
            "def load_data():",
            "(X_np, Y), _ = multi_mnist(inpath, max_digits=2, canvas_size=50, seed=42)",
            "X_np = X_np.astype(np.float32)",
            "X_np /= 255.0",
            "-    X = Variable(torch.from_numpy(X_np))",
            "+    X = torch.from_numpy(X_np)",
            "# Using FloatTensor to allow comparison with values sampled from",
            "# Bernoulli.",
            "counts = torch.FloatTensor([len(objs) for objs in Y])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4507,
        "label": "yes",
        "change": [
            "def finfo(type: Union[DType, str, tf.Tensor, tf.Variable]) -> Finfo:",
            "if isinstance(type, tf.Tensor):",
            "type = type.dtype",
            "if ivy.as_native_dtype(type) == tf.bfloat16:",
            "-        return Finfo(tf.experimental.numpy.finfo(tf.float32))",
            "+        return Finfo(Bfloat16Finfo())",
            "return Finfo(tf.experimental.numpy.finfo(ivy.as_native_dtype(type)))"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 4508,
        "label": "yes",
        "change": [
            "def segment_diff(x,",
            "",
            "needs_fix = tf.scatter_nd(",
            "fix_indices,",
            "-        tf.reshape(tf.ones_like(fix_indices, dtype=tf.bool), [-1]),",
            "+        # Unfortunately, scatter_nd doesn't support bool on GPUs so we need to",
            "+        # do ints here and then convert to bool.",
            "+        tf.reshape(tf.ones_like(fix_indices, dtype=tf.int32), [-1]),",
            "shape=tf.shape(x))",
            "# If exclusive is False, then needs_fix means we need to replace the values",
            "# in raw_diffs at those locations with the values in x.",
            "+    needs_fix = tf.cast(needs_fix, dtype=tf.bool)",
            "if not exclusive:",
            "return tf.where(needs_fix, x, raw_diffs)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 4510,
        "label": "no",
        "change": [
            "class BertModel(BertPreTrainedModel):",
            "device = input_ids.device if input_ids is not None else inputs_embeds.device",
            "",
            "if attention_mask is None:",
            "-            attention_mask = torch.ones(input_shape)",
            "+            attention_mask = torch.ones(input_shape, device=device)",
            "if encoder_attention_mask is None:",
            "-            encoder_attention_mask = torch.ones(input_shape)",
            "+            encoder_attention_mask = torch.ones(input_shape, device=device)",
            "if token_type_ids is None:",
            "-            token_type_ids = torch.zeros(input_shape, dtype=torch.long)",
            "+            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)",
            "",
            "# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]",
            "# ourselves in which case we just need to make it broadcastable to all heads."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4511,
        "label": "no",
        "change": [
            "class AxialRotaryEmbedding(nn.Module):",
            "def __init__(self, dim, max_freq = 10):",
            "super().__init__()",
            "self.dim = dim",
            "-        scales = torch.logspace(1., log(max_freq / 2) / log(2), self.dim // 4, base = 2)",
            "+        scales = torch.logspace(0., log(max_freq / 2) / log(2), self.dim // 4, base = 2)",
            "self.register_buffer('scales', scales)",
            "",
            "def forward(self, x):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4515,
        "label": "no",
        "change": [
            "class TFSpeech2TextPreTrainedModel(TFPreTrainedModel):",
            "input_signature=[",
            "{",
            "\"input_features\": tf.TensorSpec((None, None, None), tf.float32, name=\"input_features\"),",
            "-                \"attention_mask\": tf.TensorSpec((None, None), tf.int64, name=\"attention_mask\"),",
            "-                \"decoder_input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"decoder_input_ids\"),",
            "-                \"decoder_attention_mask\": tf.TensorSpec((None, None), tf.int64, name=\"decoder_attention_mask\"),",
            "+                \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),",
            "+                \"decoder_input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"decoder_input_ids\"),",
            "+                \"decoder_attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"decoder_attention_mask\"),",
            "}",
            "]",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4518,
        "label": "no",
        "change": [
            "class MobileBertEmbeddings(nn.Module):",
            "# dimensional output.",
            "inputs_embeds = torch.cat(",
            "[",
            "-                    nn.functional.pad(inputs_embeds[:, 1:], [0, 0, 0, 1, 0, 0], value=0),",
            "+                    nn.functional.pad(inputs_embeds[:, 1:], [0, 0, 0, 1, 0, 0], value=0.0),",
            "inputs_embeds,",
            "-                    nn.functional.pad(inputs_embeds[:, :-1], [0, 0, 1, 0, 0, 0], value=0),",
            "+                    nn.functional.pad(inputs_embeds[:, :-1], [0, 0, 1, 0, 0, 0], value=0.0),",
            "],",
            "dim=2,",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4520,
        "label": "no",
        "change": [
            "class Bernoulli(Distribution):",
            "sample.",
            ":rtype: torch.autograd.Variable.",
            "\"\"\"",
            "-        return Variable(torch.stack([torch.Tensor([t]).expand_as(self.ps) for t in [0, 1]]))",
            "+        result = torch.arange(0, 2)  # TODO Convert to LongTensor or ByteTensor.",
            "+        result = result.view((-1,) + (1,) * self.ps.dim()).expand((2,) + self.ps.size())",
            "+        if self.ps.is_cuda:",
            "+            result = result.cuda(self.ps.get_device())",
            "+        return Variable(result)",
            "",
            "def analytic_mean(self):",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4521,
        "label": "no",
        "change": [
            "class FastTextEmbeddings(TokenEmbeddings):",
            "word_embedding = np.zeros(self.embedding_length, dtype=\"float\")",
            "",
            "word_embedding = torch.tensor(",
            "-            word_embedding, device=flair.device, dtype=torch.float",
            "+            word_embedding.tolist(), device=flair.device, dtype=torch.float",
            ")",
            "return word_embedding"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4524,
        "label": "no",
        "change": [
            "class HardNet(nn.Module):",
            "# training totally unstable.",
            "return (x - mp.detach()) / (sp.detach() + eps)",
            "",
            "-    def forward(self, input: torch.Tensor) -> torch.Tensor:   # type: ignore",
            "+    def forward(self, input: torch.Tensor) -> torch.Tensor:",
            "x_norm: torch.Tensor = self._normalize_input(input)",
            "x_features: torch.Tensor = self.features(x_norm)",
            "x_out = x_features.view(x_features.size(0), -1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4528,
        "label": "yes",
        "change": [
            "def do_test_log_likelihood(run,",
            "layer_key[0])])",
            "else:",
            "expected_mean_logstd = fc(",
            "-                        fc(obs_batch,",
            "-                           vars[\"_hidden_layers.0._model.0.weight\"]),",
            "-                        vars[\"_logits._model.0.weight\"])",
            "+                        fc(",
            "+                            obs_batch,",
            "+                            np.transpose(",
            "+                                vars[\"_hidden_layers.0._model.0.weight\"])),",
            "+                        np.transpose(vars[\"_logits._model.0.weight\"]))",
            "mean, log_std = np.split(expected_mean_logstd, 2, axis=-1)",
            "if logp_func is None:",
            "expected_logp = np.log(norm.pdf(a, mean, np.exp(log_std)))"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 4530,
        "label": "no",
        "change": [
            "class TFEncoderDecoderModel(TFPreTrainedModel, TFCausalLanguageModelingLoss):",
            "`Dict[str, tf.Tensor]`: The dummy inputs.",
            "\"\"\"",
            "# Add `decoder_input_ids` because `self.decoder` requires it.",
            "-        input_ids = tf.constant(DUMMY_INPUTS)",
            "+        input_ids = tf.constant(DUMMY_INPUTS, dtype=tf.int32)",
            "dummy = {\"input_ids\": input_ids, \"decoder_input_ids\": input_ids}",
            "return dummy"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4531,
        "label": "no",
        "change": [
            "def discretized_gaussian_log_likelihood(x, *, means, log_scales, thres = 0.999):",
            "log_cdf_plus,",
            "torch.where(x > thres,",
            "log_one_minus_cdf_min,",
            "-            log(cdf_delta)))",
            "+            log(cdf_delta, eps = eps)))",
            "",
            "return log_probs"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4532,
        "label": "no",
        "change": [
            "class T5LayerNorm(nn.Module):",
            "variance = hidden_states.to(torch.float32).pow(2).mean(-1, keepdim=True)",
            "hidden_states = hidden_states * torch.rsqrt(variance + self.variance_epsilon)",
            "",
            "-        # convert into float16 if necessary",
            "-        if self.weight.dtype == torch.float16:",
            "-            hidden_states = hidden_states.to(torch.float16)",
            "+        # convert into half-precision if necessary",
            "+        if self.weight.dtype in [torch.float16, torch.bfloat16]:",
            "+            hidden_states = hidden_states.to(self.weight.dtype)",
            "+",
            "return self.weight * hidden_states"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4533,
        "label": "no",
        "change": [
            "class TestVits(unittest.TestCase):",
            "args = VitsArgs(num_speakers=num_speakers, use_speaker_embedding=True)",
            "model = Vits(args)",
            "",
            "-        ref_inp = torch.randn(1, spec_len, 513)",
            "+        ref_inp = torch.randn(1, 513, spec_len)",
            "ref_inp_len = torch.randint(1, spec_effective_len, (1,))",
            "ref_spk_id = torch.randint(1, num_speakers, (1,))",
            "tgt_spk_id = torch.randint(1, num_speakers, (1,))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4537,
        "label": "no",
        "change": [
            "def ninja_installed():",
            "def nvcc_version():",
            "import torch.utils.cpp_extension",
            "cuda_home = torch.utils.cpp_extension.CUDA_HOME",
            "+    if cuda_home is None:",
            "+        return f\"{RED} [FAIL] cannot find CUDA_HOME via torch.utils.cpp_extension.CUDA_HOME={torch.utils.cpp_extension.CUDA_HOME} {END}\"",
            "try:",
            "output = subprocess.check_output([cuda_home + \"/bin/nvcc\",",
            "\"-V\"],"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4538,
        "label": "no",
        "change": [
            "class Beta(Distribution):",
            "def log_probability(self, action):",
            "action = (action - self.min_value) / (self.max_value - self.min_value)",
            "action = tf.minimum(x=action, y=(1.0 - util.epsilon))",
            "-        return (self.alpha - 1.0) * tf.log(action) + (self.beta - 1.0) * tf.log1p(-action) - self.log_norm",
            "+        return (self.alpha - 1.0) * tf.log(action + util.epsilon) +\\",
            "+               (self.beta - 1.0) * tf.log1p(-action) - self.log_norm",
            "",
            "def kl_divergence(self, other):",
            "assert isinstance(other, Beta)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4540,
        "label": "no",
        "change": [
            "from allennlp.modules.attention.dot_product_attention import DotProductAttention",
            "",
            "",
            "class TestDotProductAttention(AllenNlpTestCase):",
            "-",
            "def test_can_init_dot(self):",
            "legacy_attention = Attention.from_params(Params({\"type\": \"dot_product\"}))",
            "isinstance(legacy_attention, DotProductAttention)",
            "",
            "def test_dot_product_similarity(self):",
            "linear = DotProductAttention(normalize=False)",
            "-        output = linear(torch.FloatTensor([[0, 0, 0], [1, 1, 1]]),",
            "-                        torch.FloatTensor([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]]))",
            "+        output = linear(",
            "+            torch.FloatTensor([[0, 0, 0], [1, 1, 1]]),",
            "+            torch.FloatTensor([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]]),",
            "+        )",
            "",
            "-        assert_almost_equal(output.numpy(),",
            "-                            numpy.array([[0.0, 0.0], [24.0, 33.0]]), decimal=2)",
            "+        assert_almost_equal(output.numpy(), numpy.array([[0.0, 0.0], [24.0, 33.0]]), decimal=2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4541,
        "label": "no",
        "change": [
            "class TokenClassificationIntegrationTest(test_combinations.TestCase):",
            "keras.layers.Conv1D(4, 5, padding='same', activation='relu'),",
            "keras.layers.Conv1D(8, 5, padding='same'),",
            "keras.layers.BatchNormalization(),",
            "-        keras.layers.Conv2D(3, 5, padding='same', activation='softmax'),",
            "+        keras.layers.Conv1D(3, 5, padding='same', activation='softmax'),",
            "]",
            "model = test_utils.get_model_from_layers(",
            "layers, input_shape=(None,))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4545,
        "label": "no",
        "change": [
            "class NeuralNetwork(nn.Module):",
            "nn.Linear(512, 512),",
            "nn.ReLU(),",
            "nn.Linear(512, 10),",
            "-            nn.ReLU()",
            ")",
            "",
            "def forward(self, x):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4555,
        "label": "yes",
        "change": [
            "class roibatchLoader(data.Dataset):",
            "# for ratio cross 1, we make it to be 1.",
            "target_ratio = 1",
            "",
            "-        self.ratio_list_batch[left_idx:(right_idx+1)] = target_ratio",
            "+        self.ratio_list_batch[left_idx:(right_idx+1)] = torch.tensor(target_ratio.astype(np.float64)) # trainset ratio list ,each batch is same number",
            "",
            "",
            "def __getitem__(self, index):"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 4559,
        "label": "no",
        "change": [
            "def random_affine_generator3d(",
            "dim=1,",
            ")",
            "else:",
            "-        scale = torch.ones(batch_size, device=device, dtype=dtype).repeat(1, 3)",
            "+        scale = torch.ones(batch_size, device=device, dtype=dtype).reshape(batch_size, 1).repeat(1, 3)",
            "",
            "if translate is not None:",
            "if translate.shape != torch.Size([3]):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4561,
        "label": "yes",
        "change": [
            "class CapsNet(object):",
            "assert self.masked_v.get_shape() == [cfg.batch_size, 1, 16, 1]",
            "# Method 2. masking with true label, default mode",
            "else:",
            "-                self.masked_v = tf.matmul(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, 10, 1)), transpose_a=True)",
            "+                # self.masked_v = tf.matmul(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, 10, 1)), transpose_a=True)",
            "+                self.masked_v = tf.multply(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, 10, 1)))",
            "self.v_length = tf.sqrt(tf.reduce_sum(tf.square(self.caps2), axis=2, keep_dims=True) + epsilon)",
            "",
            "# 2. Reconstructe the MNIST images with 3 FC layers"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 4563,
        "label": "yes",
        "change": [
            "def shift_rgb(image: torch.Tensor, r_shift: torch.Tensor, g_shift: torch.Tensor,",
            "",
            "shifts = [r_shift, g_shift, b_shift]",
            "",
            "-    shifted = (image + torch.Tensor(shifts).view(1, 3, 1, 1).to(image)).clamp_(min=0, max=1)",
            "+    shifted = (image + torch.stack(shifts).view(-1, 3, 1, 1).to(image)).clamp_(min=0, max=1)",
            "",
            "return shifted"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 4564,
        "label": "yes",
        "change": [
            "class TestImageFeatureEmbeddings(AllenNlpTestCase):",
            "super().__init__()",
            "",
            "self.image_embeddings = torch.nn.Linear(feature_size, embedding_size)",
            "-                self.image_location_embeddings = torch.nn.Linear(4, embedding_size)",
            "+                self.image_location_embeddings = torch.nn.Linear(4, embedding_size, bias=False)",
            "self.layer_norm = torch.nn.LayerNorm(embedding_size, eps=1e-12)",
            "self.dropout = torch.nn.Dropout(dropout)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 4565,
        "label": "no",
        "change": [
            "class FastRCNNHead(object):",
            "",
            "@memoized",
            "def decoded_output_boxes_class_agnostic(self):",
            "+        \"\"\" Returns: Nx4 \"\"\"",
            "assert self._bbox_class_agnostic",
            "box_logits = tf.reshape(self.box_logits, [-1, 4])",
            "decoded = decode_bbox_target("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4567,
        "label": "no",
        "change": [
            "def make_support(question, source=\"wiki40b\", method=\"dense\", n_results=10):",
            "return question_doc, support_list",
            "",
            "",
            "-@st.cache(hash_funcs={torch.Tensor: (lambda _: None), transformers.tokenization_bart.BartTokenizer: (lambda _: None)})",
            "+@st.cache(",
            "+    hash_funcs={",
            "+        torch.Tensor: (lambda _: None),",
            "+        transformers.models.bart.tokenization_bart.BartTokenizer: (lambda _: None),",
            "+    }",
            "+)",
            "def answer_question(",
            "question_doc, s2s_model, s2s_tokenizer, min_len=64, max_len=256, sampling=False, n_beams=2, top_p=0.95, temp=0.8",
            "):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4568,
        "label": "no",
        "change": [
            "class DistributionModel(MemoryModel):",
            "collapsed_size = util.prod(util.shape(entropy)[1:])",
            "entropy = tf.reshape(tensor=entropy, shape=(-1, collapsed_size))",
            "entropies.append(entropy)",
            "-",
            "entropy_per_instance = tf.reduce_mean(input_tensor=tf.concat(values=entropies, axis=1), axis=1)",
            "entropy = tf.reduce_mean(input_tensor=entropy_per_instance, axis=0)",
            "-            if 'entropy' in self.summary_labels:",
            "-                tf.contrib.summary.scalar(name='entropy', tensor=entropy)",
            "+",
            "+        if 'entropy' in self.summary_labels:",
            "+            tf.contrib.summary.scalar(name='entropy', tensor=entropy)",
            "+        if self.entropy_regularization is not None and self.entropy_regularization > 0.0:",
            "losses['entropy'] = -self.entropy_regularization * entropy",
            "",
            "return losses"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4569,
        "label": "no",
        "change": [
            "def _compute_global_attention_mask(input_ids, sep_token_id, before_sep_token=Tru",
            "# bool attention mask with True in locations of global attention",
            "attention_mask = torch.arange(input_ids.shape[1], device=input_ids.device)",
            "if before_sep_token is True:",
            "-        attention_mask = (attention_mask.expand_as(input_ids) < question_end_index).to(torch.uint8)",
            "+        attention_mask = (attention_mask.expand_as(input_ids) < question_end_index).to(torch.bool)",
            "else:",
            "# last token is separation token and should not be counted and in the middle are two separation tokens",
            "-        attention_mask = (attention_mask.expand_as(input_ids) > (question_end_index + 1)).to(torch.uint8) * (",
            "+        attention_mask = (attention_mask.expand_as(input_ids) > (question_end_index + 1)).to(torch.bool) * (",
            "attention_mask.expand_as(input_ids) < input_ids.shape[-1]",
            "-        ).to(torch.uint8)",
            "+        ).to(torch.bool)",
            "",
            "return attention_mask"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4573,
        "label": "no",
        "change": [
            "def attempt_load(weights, device=None, inplace=True, fuse=True):",
            "elif t is nn.Upsample and not hasattr(m, 'recompute_scale_factor'):",
            "m.recompute_scale_factor = None  # torch 1.11.0 compatibility",
            "",
            "+    # Return model",
            "if len(model) == 1:",
            "-        return model[-1]  # return model",
            "+        return model[-1]",
            "+",
            "+    # Return detection ensemble",
            "print(f'Ensemble created with {weights}\\n')",
            "for k in 'names', 'nc', 'yaml':",
            "setattr(model, k, getattr(model[0], k))",
            "model.stride = model[torch.argmax(torch.tensor([m.stride.max() for m in model])).int()].stride  # max stride",
            "assert all(model[0].nc == m.nc for m in model), f'Models have different class counts: {[m.nc for m in model]}'",
            "-    return model  # return ensemble",
            "+    return model"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4575,
        "label": "no",
        "change": [
            "class IndexLookupOutputTest(keras_parameterized.TestCase,",
            ")  # pyformat: disable",
            "def test_int_output(self, shape, input_array, expected_output):",
            "vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]",
            "+    if callable(input_array):",
            "+      input_array = input_array()",
            "",
            "layer = index_lookup.IndexLookup(",
            "max_tokens=None,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4580,
        "label": "no",
        "change": [
            "def perform_analysis_torch(preds, indices, noise_eps=0.1, delta=1e-5, moments=8,",
            "data_ind_eps_list = (data_ind_log_mgf - math.log(delta)) / l_list",
            "",
            "return min(eps_list_nm), min(data_ind_eps_list)",
            "+",
            "+",
            "+",
            "+"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4583,
        "label": "no",
        "change": [
            "class GroupSampler(Sampler):",
            "range(len(indices) // self.samples_per_gpu))",
            "]",
            "indices = np.concatenate(indices)",
            "-        indices = torch.from_numpy(indices).long()",
            "+        indices = indices.astype(np.int64).tolist()",
            "assert len(indices) == self.num_samples",
            "return iter(indices)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4584,
        "label": "no",
        "change": [
            "class CLIPModel(CLIPPreTrainedModel):",
            "# cosine similarity as logits",
            "logit_scale = self.logit_scale.exp()",
            "logits_per_text = torch.matmul(text_embeds, image_embeds.t()) * logit_scale",
            "-        logits_per_image = logits_per_text.T",
            "+        logits_per_image = logits_per_text.t()",
            "",
            "loss = None",
            "if return_loss:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4585,
        "label": "yes",
        "change": [
            "class BooleanAccuracy(Metric):",
            "",
            "# We want to skip predictions that are completely masked;",
            "# so we'll keep predictions that aren't.",
            "-            keep = mask.view(batch_size, -1).max(dim=1)[0].float()",
            "+            keep = mask.view(batch_size, -1).max(dim=1)[0]",
            "else:",
            "-            keep = torch.ones(batch_size, device=predictions.device).float()",
            "+            keep = torch.ones(batch_size, device=predictions.device).bool()",
            "",
            "predictions = predictions.view(batch_size, -1)",
            "gold_labels = gold_labels.view(batch_size, -1)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 4586,
        "label": "no",
        "change": [
            "class StyleChangeDetection(datasets.GeneratorBasedBuilder):",
            "",
            "if not os.path.exists(train_dir):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('style_change_detection', data_dir=...)` that includes {}. Manual download instructions: {}\".format(",
            "-                    train_dir, train_dir, self.manual_download_instructions",
            "-                )",
            "+                f\"{train_dir} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('style_change_detection', data_dir=...)` that includes {train_dir}. Manual download instructions: {self.manual_download_instructions}\"",
            ")",
            "",
            "return ["
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4588,
        "label": "no",
        "change": [
            "def cross_product_matrix(x: torch.Tensor) -> torch.Tensor:",
            "",
            "# construct the matrix, reshape to 3x3 and return",
            "zeros = torch.zeros_like(x0)",
            "-    cross_product_matrix_flat = torch.stack([",
            "-        zeros, -x2, x1,",
            "-        x2, zeros, -x0,",
            "-        -x1, x0, zeros], dim=-1)",
            "+    cross_product_matrix_flat = torch.stack([zeros, -x2, x1, x2, zeros, -x0, -x1, x0, zeros], dim=-1)",
            "return cross_product_matrix_flat.view(-1, 3, 3)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4589,
        "label": "no",
        "change": [
            "def test_load_from_disk_with_default_in_memory(",
            "current_dataset_size = 512  # arrow file size = 512, in-memory dataset size = 148",
            "if max_in_memory_dataset_size == \"default\":",
            "# default = 250 * 2 ** 20",
            "-        max_in_memory_dataset_size = datasets.config.MAX_IN_MEMORY_DATASET_SIZE_IN_BYTES",
            "+        max_in_memory_dataset_size = datasets.config.HF_MAX_IN_MEMORY_DATASET_SIZE_IN_BYTES",
            "else:",
            "-        monkeypatch.setattr(datasets.config, \"MAX_IN_MEMORY_DATASET_SIZE_IN_BYTES\", max_in_memory_dataset_size)",
            "+        monkeypatch.setattr(datasets.config, \"HF_MAX_IN_MEMORY_DATASET_SIZE_IN_BYTES\", max_in_memory_dataset_size)",
            "if max_in_memory_dataset_size:",
            "expected_in_memory = current_dataset_size < max_in_memory_dataset_size",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4591,
        "label": "no",
        "change": [
            "class STL(nn.Module):",
            "def forward(self, inputs):",
            "N = inputs.size(0)",
            "query = inputs.unsqueeze(1)  # [N, 1, E//2]",
            "-        keys = tFunctional.tanh(self.embed).unsqueeze(0).expand(N, -1, -1)  # [N, token_num, E // num_heads]",
            "+        keys = torch.tanh(self.embed).unsqueeze(0).expand(N, -1, -1)  # [N, token_num, E // num_heads]",
            "style_embed = self.attention(query, keys)",
            "",
            "return style_embed"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4593,
        "label": "no",
        "change": [
            "class DPMSolverMultistepScheduler(SchedulerMixin, ConfigMixin):",
            "self.config.sample_max_value * torch.ones_like(dynamic_max_val).to(dynamic_max_val.device),",
            ")[(...,) + (None,) * (x0_pred.ndim - 1)]",
            "x0_pred = torch.clamp(x0_pred, -dynamic_max_val, dynamic_max_val) / dynamic_max_val",
            "+                x0_pred = x0_pred.type(orig_dtype)",
            "return x0_pred",
            "# DPM-Solver needs to solve an integral of the noise prediction model.",
            "elif self.config.algorithm_type == \"dpmsolver\":"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4596,
        "label": "no",
        "change": [
            "def nms(boxes: torch.Tensor, scores: torch.Tensor, iou_threshold: float) -> torc",
            "xx2 = torch.min(x2[i], x2[order[1:]])",
            "yy2 = torch.min(y2[i], y2[order[1:]])",
            "",
            "-        w = torch.clamp(xx2 - xx1, min=0.)",
            "-        h = torch.clamp(yy2 - yy1, min=0.)",
            "+        w = torch.clamp(xx2 - xx1, min=0.0)",
            "+        h = torch.clamp(yy2 - yy1, min=0.0)",
            "inter = w * h",
            "ovr = inter / (areas[i] + areas[order[1:]] - inter)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4600,
        "label": "no",
        "change": [
            "def create_attn_mask(N, T, g=0.05):",
            "M[n, t] = val",
            "e_x = np.exp(M - np.max(M))",
            "M = e_x / e_x.sum(axis=0) # only difference",
            "-    M = Variable(torch.FloatTensor(M).t()).cuda()",
            "+    M = torch.FloatTensor(M).t().cuda()",
            "M = torch.stack([M]*32)",
            "return M"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4609,
        "label": "no",
        "change": [
            "def _fn3(x, y):",
            "",
            "",
            "# vmap",
            "-@given(",
            "+@handle_test(",
            "+    fn_tree=\"functional.ivy.vmap\",",
            "func=st.sampled_from([_fn1, _fn2, _fn3]),",
            "dtype_and_arrays_and_axes=helpers.arrays_and_axes(",
            "allow_none=False,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4611,
        "label": "no",
        "change": [
            "def transfer_lm(ch_rnnlm, th_rnnlm):",
            "",
            "def test_lm():",
            "n_vocab = 3",
            "+    n_layers = 2",
            "n_units = 2",
            "batchsize = 5",
            "-    rnnlm_ch = lm_chainer.ClassifierWithState(lm_chainer.RNNLM(n_vocab, n_units))",
            "-    rnnlm_th = lm_pytorch.ClassifierWithState(lm_pytorch.RNNLM(n_vocab, n_units))",
            "+    rnnlm_ch = lm_chainer.ClassifierWithState(lm_chainer.RNNLM(n_vocab, n_layers, n_units))",
            "+    rnnlm_th = lm_pytorch.ClassifierWithState(lm_pytorch.RNNLM(n_vocab, n_layers, n_units))",
            "transfer_lm(rnnlm_ch.predictor, rnnlm_th.predictor)",
            "import numpy",
            "# TODO(karita) implement weight transfer"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4613,
        "label": "no",
        "change": [
            "class FrozenCLIPEmbedderWithCustomWords(torch.nn.Module):",
            "image_embs_name = None",
            "if image_embs_name is not None and self.image_embs_name != image_embs_name:",
            "self.image_embs_name = image_embs_name",
            "-            self.image_embs = torch.load(aesthetic_embeddings[self.image_embs_name], map_location=device)",
            "+            self.image_embs = torch.load(shared.aesthetic_embeddings[self.image_embs_name], map_location=device)",
            "self.image_embs /= self.image_embs.norm(dim=-1, keepdim=True)",
            "self.image_embs.requires_grad_(False)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4614,
        "label": "no",
        "change": [
            "class TestCenterCrop:",
            "def test_jit_trace(self, device):",
            "@torch.jit.script",
            "def op_script(input: torch.Tensor,",
            "-                      size: Tuple[torch.Tensor, torch.Tensor]) -> torch.Tensor:",
            "+                      size: Tuple[int, int]) -> torch.Tensor:",
            "return kornia.center_crop(input, size)",
            "# 1. Trace op",
            "batch_size, channels, height, width = 1, 2, 5, 4"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4615,
        "label": "no",
        "change": [
            "class UpsampleConvLayer(torch.nn.Module):",
            "super(UpsampleConvLayer, self).__init__()",
            "self.upsample = upsample",
            "if upsample:",
            "-            self.upsample_layer = torch.nn.UpsamplingNearest2d(scale_factor=upsample)",
            "+            self.upsample_layer = torch.nn.Upsample(mode='nearest', scale_factor=upsample)",
            "reflection_padding = kernel_size // 2",
            "self.reflection_pad = torch.nn.ReflectionPad2d(reflection_padding)",
            "self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4617,
        "label": "no",
        "change": [
            "class PReluLayer(Layer):",
            "except Exception:  # TF 0.12",
            "self.outputs = tf.nn.relu(self.inputs) + tf.mul(alphas, (self.inputs - tf.abs(self.inputs))) * 0.5",
            "",
            "-        self.all_layers.append(self.outputs)",
            "-        self.all_params.extend([alphas])",
            "+        self._add_layers(self.outputs)",
            "+        self._add_params([alphas])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4620,
        "label": "no",
        "change": [
            "def scope_vars(scope, trainable_only=False):",
            "vars: [tf.Variable]",
            "list of variables in `scope`.",
            "\"\"\"",
            "-    return tf.get_collection(",
            "-        tf.GraphKeys.TRAINABLE_VARIABLES",
            "-        if trainable_only else tf.GraphKeys.VARIABLES,",
            "+    return tf1.get_collection(",
            "+        tf1.GraphKeys.TRAINABLE_VARIABLES",
            "+        if trainable_only else tf1.GraphKeys.VARIABLES,",
            "scope=scope if isinstance(scope, str) else scope.name)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4622,
        "label": "no",
        "change": [
            "class Optimizer(_BaseOptimizer):",
            ">>> opt = tf.keras.optimizers.experimental.SGD(learning_rate=1, clipvalue=1)",
            ">>> var1, var2 = tf.Variable(2.0), tf.Variable(2.0)",
            ">>> with tf.GradientTape() as tape:",
            "-    ... loss = 2 * var1 + 2 * var2",
            "+  ...   loss = 2 * var1 + 2 * var2",
            ">>> grads = tape.gradient(loss, [var1, var2])",
            ">>> print([grads[0].numpy(), grads[1].numpy()])",
            "-  [2.0., 2.0]",
            "+  [2.0, 2.0]",
            ">>> opt.apply_gradients(zip(grads, [var1, var2]))",
            ">>> # Without clipping, we should get [0, 0], but as gradients are clipped to",
            ">>> # have max value 1, we get [1.0, 1.0]."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4623,
        "label": "no",
        "change": [
            "class Mutator(BaseMutator):",
            "\"\"\"",
            "if self._connect_all:",
            "return self._all_connect_tensor_reduction(mutable.reduction,",
            "-                                                      [op(*args, **kwargs) for op in mutable.choices]), \\",
            "-                torch.ones(mutable.length)",
            "+                                                      [op(*args, **kwargs) for op in mutable]), \\",
            "+                torch.ones(len(mutable))",
            "",
            "def _map_fn(op, args, kwargs):",
            "return op(*args, **kwargs)",
            "",
            "mask = self._get_decision(mutable)",
            "-        assert len(mask) == len(mutable.choices), \\",
            "-            \"Invalid mask, expected {} to be of length {}.\".format(mask, len(mutable.choices))",
            "-        out = self._select_with_mask(_map_fn, [(choice, args, kwargs) for choice in mutable.choices], mask)",
            "+        assert len(mask) == len(mutable), \\",
            "+            \"Invalid mask, expected {} to be of length {}.\".format(mask, len(mutable))",
            "+        out = self._select_with_mask(_map_fn, [(choice, args, kwargs) for choice in mutable], mask)",
            "return self._tensor_reduction(mutable.reduction, out), mask",
            "",
            "def on_forward_input_choice(self, mutable, tensor_list):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4624,
        "label": "no",
        "change": [
            "class MultiheadAttention(nn.Module):",
            "nn.init.xavier_uniform_(self.q_proj.weight)",
            "",
            "nn.init.xavier_uniform_(self.out_proj.weight)",
            "-        nn.init.constant_(self.out_proj.bias, 0.)",
            "+        if self.out_proj.bias is not None:",
            "+            nn.init.constant_(self.out_proj.bias, 0.)",
            "if self.bias_k is not None:",
            "nn.init.xavier_normal_(self.bias_k)",
            "if self.bias_v is not None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4625,
        "label": "no",
        "change": [
            "def encode_bbox_target(boxes, anchors):",
            "",
            "# Note that here not all boxes are valid. Some may be zero",
            "txty = (xbyb - xaya) / waha",
            "-    twth = tf.log(wbhb / waha)  # may contain -inf for invalid boxes",
            "+    twth = tf.math.log(wbhb / waha)  # may contain -inf for invalid boxes",
            "encoded = tf.concat([txty, twth], axis=1)  # (-1x2x2)",
            "return tf.reshape(encoded, tf.shape(boxes))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4626,
        "label": "no",
        "change": [
            "def leaky_relu(x, alpha=0.1, name=\"LeakyReLU\"):",
            "\"\"\"",
            "",
            "with tf.name_scope(name) as scope:",
            "-        x = tf.nn.relu(x)",
            "m_x = tf.nn.relu(-x)",
            "+        x = tf.nn.relu(x)",
            "x -= alpha * m_x",
            "",
            "x.scope = scope"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4631,
        "label": "no",
        "change": [
            "class DDIMScheduler(SchedulerMixin, ConfigMixin):",
            "step_ratio = self.config.num_train_timesteps // self.num_inference_steps",
            "# creates integer timesteps by multiplying by ratio",
            "# casting to int to avoid issues when num_inference_step is power of 3",
            "-        timesteps = (np.arange(0, num_inference_steps) * step_ratio).round()[::-1].copy()",
            "+        timesteps = (np.arange(0, num_inference_steps) * step_ratio).round()[::-1].copy().astype(np.int64)",
            "self.timesteps = torch.from_numpy(timesteps).to(device)",
            "self.timesteps += offset"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4640,
        "label": "no",
        "change": [
            "class MarianTokenizationTest(TokenizerTesterMixin, unittest.TestCase):",
            "vocab = [\"</s>\", \"<unk>\", \"▁This\", \"▁is\", \"▁a\", \"▁t\", \"est\", \"\\u0120\", \"<pad>\"]",
            "vocab_tokens = dict(zip(vocab, range(len(vocab))))",
            "save_dir = Path(self.tmpdirname)",
            "-        save_json(vocab_tokens, save_dir / vocab_files_names[\"vocab\"])",
            "-        save_json(mock_tokenizer_config, save_dir / vocab_files_names[\"tokenizer_config_file\"])",
            "-        if not (save_dir / vocab_files_names[\"source_spm\"]).exists():",
            "-            copyfile(SAMPLE_SP, save_dir / vocab_files_names[\"source_spm\"])",
            "-            copyfile(SAMPLE_SP, save_dir / vocab_files_names[\"target_spm\"])",
            "+        save_json(vocab_tokens, save_dir / VOCAB_FILES_NAMES[\"vocab\"])",
            "+        save_json(mock_tokenizer_config, save_dir / VOCAB_FILES_NAMES[\"tokenizer_config_file\"])",
            "+        if not (save_dir / VOCAB_FILES_NAMES[\"source_spm\"]).exists():",
            "+            copyfile(SAMPLE_SP, save_dir / VOCAB_FILES_NAMES[\"source_spm\"])",
            "+            copyfile(SAMPLE_SP, save_dir / VOCAB_FILES_NAMES[\"target_spm\"])",
            "",
            "tokenizer = MarianTokenizer.from_pretrained(self.tmpdirname)",
            "tokenizer.save_pretrained(self.tmpdirname)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4642,
        "label": "no",
        "change": [
            "def broadcast_variables(variables, root_rank, scope=''):",
            "scope: the graph name scope",
            "\"\"\"",
            "if size() <= 1:",
            "-        return variables",
            "+        return tf.group(*variables)",
            "_assign = tf.assign if hasattr(tf, 'assign') else tf.compat.v1.assign",
            "return tf.group(*[_assign(var, broadcast(var, root_rank, scope))",
            "for var in variables])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4644,
        "label": "no",
        "change": [
            "class Queue(Memory):",
            "return lengths, successor_indices, mask",
            "",
            "lengths = tf.ones_like(input=indices, dtype=tf_util.get_dtype(type='int'))",
            "-        successor_indices = tf.expand_dims(input=indices, axis=1)",
            "+        successor_indices = tf.math.mod(x=tf.expand_dims(input=indices, axis=1), y=capacity)",
            "mask = tf.ones_like(input=successor_indices, dtype=tf_util.get_dtype(type='bool'))",
            "shape = tf.TensorShape(dims=((None, None)))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4646,
        "label": "yes",
        "change": [
            "class InvertedResidual(BaseModule):",
            "out = self.linear_conv(out)",
            "",
            "if self.with_res_shortcut:",
            "-                return x + out",
            "+                return x + self.drop_path(out)",
            "else:",
            "return out"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 4647,
        "label": "no",
        "change": [
            "def test_nn_op_forward_called():",
            "torch.__version__ = '1.4.1'",
            "",
            "for m in ['Conv2d', 'ConvTranspose2d', 'MaxPool2d']:",
            "-        with patch('torch.nn.{}.forward'.format(m)) as nn_module_forward:",
            "+        with patch(f'torch.nn.{m}.forward') as nn_module_forward:",
            "# randn input",
            "x_empty = torch.randn(0, 3, 10, 10)",
            "wrapper = eval(m)(3, 2, 1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4650,
        "label": "yes",
        "change": [
            "def compute_loss(predictions, targets, model):  # predictions, targets, model",
            "tobj[b, anchor, grid_j, grid_i] = (1.0 - model.gr) + model.gr * iou.detach().clamp(0).type(tobj.dtype)  # iou ratio",
            "",
            "# Classification",
            "-            t = torch.full_like(ps[:, 5:], cn, device=device)  # targets",
            "-            t[range(num_targets), tcls[layer_index]] = cp",
            "-            lcls += BCEcls(ps[:, 5:], t)  # BCE",
            "+            if ps.size(1) - 5 > 1:",
            "+                t = torch.full_like(ps[:, 5:], cn, device=device)  # targets",
            "+                t[range(num_targets), tcls[layer_index]] = cp",
            "+                lcls += BCEcls(ps[:, 5:], t)  # BCE",
            "",
            "lobj += BCEobj(layer_predictions[..., 4], tobj) * balance[layer_index]  # obj loss"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 4654,
        "label": "no",
        "change": [
            "class Categorical(object):",
            "class DiagGaussian(object):",
            "def __init__(self, flat):",
            "self.flat = flat",
            "-    mean, logstd = tf.split(1, 2, flat)",
            "+    mean, logstd = tf.split(flat, 2, axis=1)",
            "self.mean = mean",
            "self.logstd = logstd",
            "self.std = tf.exp(logstd)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4655,
        "label": "yes",
        "change": [
            "torch_scatter = None",
            "def dev(x: torch.Tensor, as_native: bool = False) -> Union[ivy.Device, torch.device]:",
            "dv = x.device",
            "if as_native:",
            "-        return torch.device(dv.replace(\"gpu\", \"cuda\"))",
            "+        return torch.device(dv.type.replace(\"gpu\", \"cuda\"))",
            "return as_ivy_dev(dv)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 4661,
        "label": "no",
        "change": [
            "class Shuffle(Layer):",
            "assert in_channel % self.group == 0",
            "temp = tf.reshape(inputs, [-1, h, w, in_channel // self.group, self.group])",
            "temp = tf.transpose(temp, [0, 1, 2, 4, 3])",
            "-        outputs = tf.reshape(temp, [-1, h, w, in_channel])",
            "+        outputs = tf.reshape(temp, [-1, h, w, in_channel],name=self.name)",
            "return outputs"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4662,
        "label": "no",
        "change": [
            "\"outputs\": [],",
            "\"source\": [",
            "\"!pip install torch torchvision\\n\",",
            "-    \"!pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\"",
            "+    \"import sys\\n\",",
            "+    \"if torch.__version__=='1.6.0+cu101' and sys.platform.startswith('linux'):\\n\",",
            "+    \"    !pip install pytorch3d\\n\",",
            "+    \"else:\\n\",",
            "+    \"    !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'\"",
            "]",
            "},",
            "{"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4666,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "",
            "logits = FullyConnected('linear', l, out_dim=1000, nl=tf.identity)",
            "prob = tf.nn.softmax(logits, name='output')",
            "-        loss3 = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, label)",
            "+        loss3 = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)",
            "loss3 = tf.reduce_mean(loss3, name='loss3')",
            "",
            "cost = tf.add_n([loss3, 0.3 * loss2, 0.3 * loss1], name='weighted_cost')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4667,
        "label": "no",
        "change": [
            "class BCELossMasked(nn.Module):",
            "",
            "def __init__(self, pos_weight: float = None):",
            "super().__init__()",
            "-        self.pos_weight = torch.tensor([pos_weight])",
            "+        self.pos_weight = nn.Parameter(torch.tensor([pos_weight]), requires_grad=False)",
            "",
            "def forward(self, x, target, length):",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4672,
        "label": "no",
        "change": [
            "class AttentionDecoder(DecoderBase):",
            "initial_call=False,",
            "predictions=outputs)",
            "",
            "-    next_inputs = tf.concat([next_inputs, attention_context], 1)",
            "+    next_inputs = self.transform_inputs(next_inputs, outputs)",
            "",
            "return (outputs, cell_state, next_inputs, finished)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4673,
        "label": "no",
        "change": [
            "class TestTransformBoxes:",
            "",
            "boxes = torch.tensor([[139.2640, 103.0150, 397.3120, 410.5225]], device=device, dtype=dtype)",
            "",
            "-        expected = torch.tensor([372.7360, 103.0150, 114.6880, 410.5225], device=device, dtype=dtype)",
            "+        expected = torch.tensor([[372.7360, 103.0150, 114.6880, 410.5225]], device=device, dtype=dtype)",
            "",
            "trans_mat = torch.tensor([[[-1., 0., 512.],",
            "[0., 1., 0.],"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4674,
        "label": "no",
        "change": [
            "class TestConvDistanceTransform:",
            "output1 = kornia.contrib.distance_transform(sample1, kernel_size, h)",
            "assert_close(expected_output1, output1)",
            "",
            "-    def test_gradcheck(self, device, dtype):",
            "+    def test_gradcheck(self, device):",
            "B, C, H, W = 1, 1, 32, 32",
            "-        sample1 = torch.ones(B, C, H, W, device=device, dtype=dtype, requires_grad=True)",
            "+        sample1 = torch.ones(B, C, H, W, device=device, dtype=torch.float64, requires_grad=True)",
            "assert gradcheck(kornia.contrib.distance_transform, (sample1), raise_exception=True)",
            "",
            "def test_loss_grad(self, device, dtype):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4675,
        "label": "no",
        "change": [
            "def all_reduce(py_dict, op=\"sum\", group=None):",
            "flatten_tensor /= world_size",
            "",
            "split_tensors = [",
            "-        x.reshape(shape) for x, shape in zip(",
            "-            torch.split(flatten_tensor, tensor_numels), tensor_shapes",
            "-        )",
            "+        x.reshape(shape)",
            "+        for x, shape in zip(torch.split(flatten_tensor, tensor_numels), tensor_shapes)",
            "]",
            "return OrderedDict({k: v for k, v in zip(py_key, split_tensors)})"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4676,
        "label": "no",
        "change": [
            "def sqrt(x):",
            "# is upper triangular) using some `flip` operators:",
            "#   flip(cholesky(flip(schur_complement)))",
            "try:",
            "-            top_left = torch.flip(torch.cholesky(torch.flip(schur_complement, (-2, -1))), (-2, -1))",
            "+            top_left = torch.flip(",
            "+                torch.linalg.cholesky(torch.flip(schur_complement, (-2, -1))), (-2, -1)",
            "+            )",
            "break",
            "except RuntimeError:",
            "B = B / 2"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4677,
        "label": "no",
        "change": [
            "import torch",
            "from allennlp.common import FromParams",
            "",
            "from allennlp.modules.transformer.transformer_module import TransformerModule",
            "+from allennlp.modules.transformer.layer_norm import LayerNorm",
            "",
            "",
            "class OutputLayer(TransformerModule, FromParams):",
            "",
            "-    _huggingface_mapping = {\"LayerNorm\": \"layer_norm\"}",
            "+    _pretrained_mapping = {\"LayerNorm\": \"layer_norm\"}",
            "",
            "def __init__(self, input_size: int, hidden_size: int, dropout: float):",
            "super().__init__()",
            "self.dense = torch.nn.Linear(input_size, hidden_size)",
            "-        self.layer_norm = torch.nn.LayerNorm(hidden_size, eps=1e-12)",
            "+        self.layer_norm = LayerNorm(hidden_size, eps=1e-12)",
            "self.dropout = torch.nn.Dropout(dropout)",
            "",
            "def forward(self, hidden_states, input_tensor):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4679,
        "label": "no",
        "change": [
            "class XLMForQuestionAnswering(XLMPreTrainedModel):",
            ">>> from transformers import XLMTokenizer, XLMForQuestionAnswering",
            ">>> import torch",
            "",
            "-        >>> tokenizer = XLMTokenizer.from_pretrained('xlm-mlm-en-2048')",
            "-        >>> model = XLMForQuestionAnswering.from_pretrained('xlm-mlm-en-2048')",
            "+        >>> tokenizer = XLMTokenizer.from_pretrained(\"xlm-mlm-en-2048\")",
            "+        >>> model = XLMForQuestionAnswering.from_pretrained(\"xlm-mlm-en-2048\")",
            "",
            "-        >>> input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1",
            "+        >>> input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(",
            "+        ...     0",
            "+        >>> )  # Batch size 1",
            ">>> start_positions = torch.tensor([1])",
            ">>> end_positions = torch.tensor([3])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4680,
        "label": "no",
        "change": [
            "+import pytest",
            "+import torch",
            "+",
            "+",
            "+@pytest.fixture",
            "+def data_loftr():",
            "+    url = 'https://github.com/kornia/data_test/blob/main/loftr_outdoor_and_homography_data.pt?raw=true'",
            "+    return torch.hub.load_state_dict_from_url(url)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4681,
        "label": "no",
        "change": [
            "def main(args):",
            "",
            "# Start running operations on the Graph.",
            "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)",
            "-        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))",
            "+        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))",
            "sess.run(tf.initialize_all_variables())",
            "sess.run(tf.initialize_local_variables())",
            "summary_writer = tf.train.SummaryWriter(log_dir, sess.graph)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4682,
        "label": "no",
        "change": [
            "class TFMarianMTModel(TFMarianPreTrainedModel, TFCausalLanguageModelingLoss):",
            "if inputs[\"labels\"] is not None:",
            "inputs[\"labels\"] = tf.where(",
            "inputs[\"labels\"] == self.config.pad_token_id,",
            "-                tf.fill(shape_list(inputs[\"labels\"]), -100),",
            "+                tf.fill(shape_list(inputs[\"labels\"]), tf.cast(-100, inputs[\"labels\"].dtype)),",
            "inputs[\"labels\"],",
            ")",
            "inputs[\"use_cache\"] = False"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4685,
        "label": "no",
        "change": [
            "class Cifar10Model(Trainable):",
            "x_train = self.train_data[0]",
            "model = self._build_model(x_train.shape[1:])",
            "",
            "-        opt = tf.keras.optimizers.Adadelta()",
            "+        opt = tf.keras.optimizers.Adadelta(",
            "+            lr=self.config[\"lr\"], decay=self.config[\"decay\"])",
            "model.compile(",
            "loss=\"categorical_crossentropy\",",
            "optimizer=opt,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4693,
        "label": "no",
        "change": [
            "class VQModelTests(ModelTesterMixin, unittest.TestCase):",
            "# fmt: off",
            "expected_output_slice = torch.tensor([-0.0153, -0.4044, -0.1880, -0.5161, -0.2418, -0.4072, -0.1612, -0.0633, -0.0143])",
            "# fmt: on",
            "-        self.assertTrue(torch.allclose(output_slice, expected_output_slice, rtol=1e-2))",
            "+        self.assertTrue(torch.allclose(output_slice, expected_output_slice, atol=1e-3))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4694,
        "label": "no",
        "change": [
            "def test_cluster_gcn_conv():",
            "",
            "t = '(Tensor, SparseTensor, Size) -> Tensor'",
            "jit = torch.jit.script(conv.jittable(t))",
            "-    assert torch.allclose(jit(x, adj.t()), out)",
            "+    assert torch.allclose(jit(x, adj.t()), out, atol=1e-5)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4703,
        "label": "no",
        "change": [
            "def batch_flatten(x):",
            "shape = x.get_shape().as_list()[1:]",
            "if None not in shape:",
            "return tf.reshape(x, [-1, int(np.prod(shape))])",
            "-    return tf.reshape(x, tf.pack([tf.shape(x)[0], -1]))",
            "+    return tf.reshape(x, tf.stack([tf.shape(x)[0], -1]))",
            "",
            "",
            "def class_balanced_cross_entropy(pred, label, name='cross_entropy_loss'):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4706,
        "label": "no",
        "change": [
            "class MultiLayeredConv1d(torch.nn.Module):",
            "",
            "\"\"\"",
            "x = torch.relu(self.w_1(x.transpose(-1, 1))).transpose(-1, 1)",
            "-        x = torch.relu(self.w_2(x.transpose(-1, 1))).transpose(-1, 1)",
            "-        return self.dropout(x)",
            "+        return self.w_2(self.dropout(x).transpose(-1, 1)).transpose(-1, 1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4707,
        "label": "no",
        "change": [
            "class TorchTrainer:",
            "if backend == \"auto\":",
            "backend = \"nccl\" if use_gpu else \"gloo\"",
            "",
            "+        if backend == \"nccl\":",
            "+            timeout_s = NCCL_TIMEOUT_S",
            "+",
            "logger.debug(f\"Using {backend} as backend.\")",
            "self.backend = backend",
            "self.num_cpus_per_worker = num_cpus_per_worker"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4708,
        "label": "yes",
        "change": [
            "class Bernoulli(Distribution):",
            "self.shape = shape",
            "action_size = util.prod(self.shape)",
            "",
            "-        with tf.name_scope(name=scope):",
            "-            self.logit = Linear(size=action_size, bias=log(probability), scope='logit')",
            "+        self.logit = Linear(size=action_size, bias=log(probability), scope='logit')",
            "",
            "super(Bernoulli, self).__init__(scope, summary_labels)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "null reference error",
        "Action": "removal",
        "Element": "api call"
    },
    {
        "number": 4710,
        "label": "no",
        "change": [
            "class VersatileDiffusionTextToImagePipelineIntegrationTests(unittest.TestCase):",
            "image_slice = image[0, 253:256, 253:256, -1]",
            "",
            "assert image.shape == (1, 512, 512, 3)",
            "-        expected_slice = np.array([0.0408, 0.0181, 0.0, 0.0388, 0.0046, 0.0461, 0.0411, 0.0, 0.0222])",
            "+        expected_slice = np.array([0.3493, 0.3757, 0.4093, 0.4495, 0.4233, 0.4102, 0.4507, 0.4756, 0.4787])",
            "+",
            "assert np.abs(image_slice.flatten() - expected_slice).max() < 1e-2"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4711,
        "label": "no",
        "change": [
            "class TestBasicTextFieldEmbedder(AllenNlpTestCase):",
            "token_embedder = BasicTextFieldEmbedder.from_params(vocab=self.vocab, params=params)",
            "inputs = {",
            "\"bert\": {",
            "-                \"input_ids\": (torch.rand(3, 5) * 10).long(),",
            "-                \"offsets\": (torch.rand(3, 5) * 1).long(),",
            "+                \"token_ids\": (torch.rand(3, 5) * 10).long(),",
            "+                \"mask\": (torch.rand(3, 5) * 1).long(),",
            "},",
            "\"token_characters\": {\"token_characters\": (torch.rand(3, 5, 5) * 1).long()},",
            "}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4714,
        "label": "no",
        "change": [
            "def matrix_rank(",
            ") -> torch.Tensor:",
            "# ToDo: add support for default rtol value here, for the case where None is provided",
            "ret = torch.linalg.matrix_rank(x, rtol=rtol, out=out)",
            "-    return torch.tensor(ret, dtype=ivy.default_int_dtype(as_native=True))",
            "+    return ret.to(dtype=x.dtype)",
            "",
            "",
            "matrix_rank.unsupported_dtypes = ("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4715,
        "label": "yes",
        "change": [
            "def adalam_core(",
            "final_matches, idxs, counts = torch.unique(final_matches, dim=0, return_inverse=True, return_counts=True)",
            "_, ind_sorted = torch.sort(idxs)",
            "cum_sum = counts.cumsum(0)",
            "-        cum_sum = torch.cat((torch.tensor([0]), cum_sum[:-1]))",
            "+        cum_sum = torch.cat((torch.tensor([0], dtype=cum_sum.dtype, device=cum_sum.device), cum_sum[:-1]))",
            "first_indicies = ind_sorted[cum_sum]",
            "accepted_dist = accepted_dist[first_indicies]",
            "if return_dist:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 4716,
        "label": "no",
        "change": [
            "class DataHandler:",
            "if adapter_steps is not None:",
            "return adapter_steps",
            "",
            "+        # tf.distribute's `PerWorkerDataset` does not inherit from",
            "+        # `tf.data.Dataset` and in those cases we give up on inferring steps.",
            "+        if not isinstance(dataset, tf.data.Dataset):",
            "+            return None",
            "+",
            "size = tf.data.experimental.cardinality(dataset)",
            "if size == tf.data.experimental.INFINITE_CARDINALITY and steps is None:",
            "raise ValueError("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4718,
        "label": "no",
        "change": [
            "def decode_and_evaluate(name,",
            "",
            "start_time = time.time()",
            "num_sentences = 0",
            "-    with tf.gfile.GFile(trans_file, mode=\"w\") as trans_f:",
            "+    with codecs.getwriter(\"utf-8\")(",
            "+        tf.gfile.GFile(trans_file, mode=\"w\")) as trans_f:",
            "trans_f.write(\"\")  # Write empty string to ensure file is created.",
            "",
            "while True:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4722,
        "label": "no",
        "change": [
            "class TestRandomCropSizeGen(RandomGeneratorBaseTests):",
            "",
            "def test_same_on_batch(self, device, dtype):",
            "torch.manual_seed(42)",
            "-        degrees = torch.tensor([10, 20])",
            "res = random_crop_size_generator(",
            "batch_size=8,",
            "size=(100, 100),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4725,
        "label": "no",
        "change": [
            "class TransformerEncoderBase(FairseqEncoder):",
            "# `forward` so we use a dictionary instead.",
            "# TorchScript does not support mixed values so the values are all lists.",
            "# The empty list is equivalent to None.",
            "-        src_lengths = src_tokens.ne(self.padding_idx).sum(dim=1, dtype=torch.int32).reshape(-1, 1).contiguous()",
            "+        src_lengths = (",
            "+            src_tokens.ne(self.padding_idx)",
            "+            .sum(dim=1, dtype=torch.int32)",
            "+            .reshape(-1, 1)",
            "+            .contiguous()",
            "+        )",
            "return {",
            "\"encoder_out\": [x],  # T x B x C",
            "\"encoder_padding_mask\": [encoder_padding_mask],  # B x T"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4727,
        "label": "no",
        "change": [
            "def test_fa_conv():",
            "",
            "result = conv(x, x_0, adj2.t(), return_attention_weights=True)",
            "assert torch.allclose(result[0], out)",
            "-    assert result[1].size() == torch.Size([4, 4]) and result[1]._nnz() == 10",
            "+    assert result[1][0].size() == torch.Size([4, 4])",
            "+    assert result[1][0]._nnz() == 10",
            "assert conv._alpha is None",
            "",
            "if is_full_test():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4728,
        "label": "no",
        "change": [
            "class TestEuclideanDistance(BaseTester):",
            "pt2 = torch.rand(2, 3, device=device, dtype=torch.float64, requires_grad=True)",
            "assert gradcheck(kgl.euclidean_distance, (pt1, pt2), raise_exception=True, fast_mode=True)",
            "",
            "-    def test_jit(self, device, dtype):",
            "+    def test_dynamo(self, device, dtype, torch_optimizer):",
            "pt1 = torch.rand(2, 3, device=device, dtype=dtype)",
            "pt2 = torch.rand(2, 3, device=device, dtype=dtype)",
            "op = kgl.euclidean_distance",
            "-        op_jit = torch.jit.script(op)",
            "-        self.assert_close(op(pt1, pt2), op_jit(pt1, pt2))",
            "+        op_optimized = torch_optimizer(op)",
            "+        self.assert_close(op(pt1, pt2), op_optimized(pt1, pt2))",
            "",
            "def test_module(self, device, dtype):",
            "pass"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4729,
        "label": "no",
        "change": [
            "class MNASNet(nn.Module):",
            "nn.ReLU(inplace=True),",
            "]",
            "self.layers = nn.Sequential(*layers)",
            "-        self.classifier = nn.Sequential(nn.Dropout(p=dropout, inplace=True),",
            "+        self.classifier = nn.Sequential(nn.Dropout(p=dropout),",
            "nn.Linear(1280, num_classes))",
            "self._initialize_weights()",
            "#self.for_test = 10"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4734,
        "label": "no",
        "change": [
            "def sum_grad_and_var_all_reduce(grad_and_vars,",
            "#   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))",
            "scaled_grads = [g for g, _ in grad_and_vars]",
            "if alg == 'nccl':",
            "-            summed_grads = nccl.all_sum(scaled_grads)",
            "+            from tensorflow.python.ops import nccl_ops",
            "+            summed_grads = nccl_ops.all_sum(scaled_grads)",
            "elif alg == 'simple':",
            "summed_grads = build_reduce_sum(scaled_grads)",
            "elif alg == 'trivial':"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4738,
        "label": "no",
        "change": [
            "class Lstm(Layer):",
            "",
            "# This distinction is so we can stack multiple LSTM layers",
            "if self.return_final_state:",
            "-            return tf.stack(values=(state.c, state.h), axis=1)",
            "+            return tf.concat(values=(state.c, state.h), axis=1)",
            "else:",
            "-            return x",
            "\\ No newline at end of file",
            "+            return x"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4742,
        "label": "no",
        "change": [
            "class Trainer:",
            "return loss.item()",
            "",
            "def _run_epoch(self, epoch: int, dataloader: DataLoader, train: bool = True):",
            "-        self.dataloader.sampler.set_epoch(epoch)",
            "+        dataloader.sampler.set_epoch(epoch)",
            "for iter, (source, targets) in enumerate(dataloader):",
            "step_type = \"Train\" if train else \"Eval\"",
            "source = source.to(self.local_rank)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4743,
        "label": "yes",
        "change": [
            "def execute_with_gradients(",
            "return grads",
            "",
            "if isinstance(y, ivy.NativeArray):",
            "-        grads = grad_func(torch.clone(y))",
            "+        grads = _set_duplicates(",
            "+            grad_func(torch.clone(y)), required_duplicate_index_chains",
            "+        )",
            "else:",
            "# ToDo: use functorch.jacrev if it fixes the issue with broken memory reference",
            "array_idxs = ivy.nested_argwhere(y, lambda x: ivy.is_native_array(x))"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 4750,
        "label": "no",
        "change": [
            "class TestCnnEncoder(AllenNlpTestCase):",
            "num_filters=13,",
            "ngram_filter_sizes=(1, 2, 3, 4, 5),",
            "output_dim=30)",
            "-        tensor = Variable(torch.rand(4, 8, 7))",
            "+        tensor = torch.rand(4, 8, 7)",
            "assert encoder(tensor, None).size() == (4, 30)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4755,
        "label": "no",
        "change": [
            "def as_ivy_dtype(dtype_in: Union[torch.dtype, str, bool, int, float], /) -> ivy.",
            "",
            "",
            "@with_unsupported_dtypes({\"1.11.0 and below\": (\"uint16\",)}, backend_version)",
            "-def as_native_dtype(dtype_in: Union[torch.dtype, str, bool, int, float],",
            "-                    /) -> torch.dtype:",
            "+def as_native_dtype(",
            "+    dtype_in: Union[torch.dtype, str, bool, int, float], /",
            "+) -> torch.dtype:",
            "if dtype_in is int:",
            "return ivy.default_int_dtype(as_native=True)",
            "if dtype_in is float:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4756,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "W_init=tf.truncated_normal_initializer(stddev=0.02)):",
            "with tf.variable_scope('gen'):",
            "image_gen = self.generator(z)",
            "-                tf.summary.image('gen', image_gen, max_images=30)",
            "+                tf.summary.image('gen', image_gen, max_outputs=30)",
            "with tf.variable_scope('discrim'):",
            "vecpos, _ = self.discriminator(image_pos)",
            "with tf.variable_scope('discrim', reuse=True):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4757,
        "label": "no",
        "change": [
            "def svgp_multiclass(num_steps, whiten):",
            "whiten=whiten)",
            "",
            "gpmodel.fix_param(\"Xu\")",
            "-    gpmodel.kernel.get_subkernel(\"WhiteNoise\").fix_param(\"variance\")",
            "+    gpmodel.kernel.kern1.fix_param(\"variance\")",
            "",
            "gpmodel.optimize(optim.Adam({\"lr\": 0.0001}), num_steps=num_steps)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4759,
        "label": "no",
        "change": [
            "def allclose(",
            "equal_nan: Optional[bool] = False,",
            "out: Optional[torch.Tensor] = None,",
            ") -> bool:",
            "-    return torch.allclose(x1, x2, rtol=rtol, atol=atol, equal_nan=equal_nan)",
            "+    ret = torch.allclose(x1, x2, rtol=rtol, atol=atol, equal_nan=equal_nan)",
            "+    return torch.tensor(ret)",
            "",
            "",
            "@with_unsupported_dtypes({\"1.11.0 and below\": (\"float16\",)}, backend_version)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4764,
        "label": "no",
        "change": [
            "class ResNetFPNModel(DetectionModel):",
            "maskrcnn_head_func = getattr(model_mrcnn, cfg.FPN.MRCNN_HEAD_FUNC)",
            "mask_logits = maskrcnn_head_func(",
            "'maskrcnn', roi_feature_maskrcnn, cfg.DATA.NUM_CATEGORY)   # #fg x #cat x 28 x 28",
            "-                indices = tf.stack([tf.range(tf.size(final_labels)), tf.to_int32(final_labels) - 1], axis=1)",
            "+                indices = tf.stack([tf.range(tf.size(final_labels)), tf.cast(final_labels, tf.int32) - 1], axis=1)",
            "final_mask_logits = tf.gather_nd(mask_logits, indices)   # #resultx28x28",
            "tf.sigmoid(final_mask_logits, name='output/masks')",
            "return []"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4768,
        "label": "no",
        "change": [
            "def iarange(name, size, subsample_size=0):",
            "yield Variable(torch.LongTensor(list(range(size))))",
            "return",
            "",
            "-    subsample = Variable(torch.randperm(size)[0:subsample_size])",
            "+    subsample = sample(name, Subsample(size, subsample_size))",
            "if len(_PYRO_STACK) == 0:",
            "yield subsample",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4769,
        "label": "no",
        "change": [
            "def argmin(",
            "keepdims: bool = False,",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "-    x = torch.tensor(x)",
            "return torch.argmin(x, axis=axis, keepdim=keepdims, out=out)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4770,
        "label": "no",
        "change": [
            "def SubpixelConv2d(net, scale=2, n_out_channel=None, act=tf.identity, name='subp",
            "bsize = tf.shape(X)[0] # Handling Dimension(None) type for undefined batch dim",
            "Xs=tf.split(X,r,3) #b*h*w*r*r",
            "Xr=tf.concat(Xs,2) #b*h*(r*w)*r",
            "-            X=tf.reshape(Xr,(b,r*h,r*w,c)) # b*(r*h)*(r*w)*c",
            "+            X=tf.reshape(Xr,(b,r*a,r*b,c)) # b*(r*h)*(r*w)*c",
            "else:",
            "print(_err_log)",
            "return X"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4773,
        "label": "no",
        "change": [
            "def resnet_fpn_backbone(image, num_blocks):",
            "freeze_at = cfg.BACKBONE.FREEZE_AT",
            "shape2d = tf.shape(image)[2:]",
            "mult = float(cfg.FPN.RESOLUTION_REQUIREMENT)",
            "-    new_shape2d = tf.to_int32(tf.ceil(tf.to_float(shape2d) / mult) * mult)",
            "+    new_shape2d = tf.cast(tf.ceil(tf.cast(shape2d, tf.float32) / mult) * mult, tf.int32)",
            "pad_shape2d = new_shape2d - shape2d",
            "assert len(num_blocks) == 4, num_blocks",
            "with backbone_scope(freeze=freeze_at > 0):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4774,
        "label": "no",
        "change": [
            "class ExpandedDistribution(TorchDistribution):",
            "log_prob = log_prob.expand(shape)",
            "if isinstance(score_function, torch.Tensor):",
            "score_function = score_function.expand(shape)",
            "-            if isinstance(score_function, torch.Tensor):",
            "+            if isinstance(entropy_term, torch.Tensor):",
            "entropy_term = entropy_term.expand(shape)",
            "return ScoreParts(log_prob, score_function, entropy_term)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4778,
        "label": "no",
        "change": [
            "class DatasetBuilder:",
            "Please follow the manual download instructions:",
            "{self.manual_download_instructions}",
            "Manual data can be loaded with:",
            "-                     datasets.load_dataset({self.name}, data_dir='<path/to/manual/data>')\"\"\"",
            "+                     datasets.load_dataset(\"{self.name}\", data_dir=\"<path/to/manual/data>\")\"\"\"",
            ")",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4780,
        "label": "yes",
        "change": [
            "def _load_weights(model: VisionTransformer, checkpoint_path: str, prefix: str =",
            "model.pos_embed.copy_(pos_embed_w)",
            "model.norm.weight.copy_(_n2p(w[f'{prefix}Transformer/encoder_norm/scale']))",
            "model.norm.bias.copy_(_n2p(w[f'{prefix}Transformer/encoder_norm/bias']))",
            "-    if model.head.bias.shape[0] == w[f'{prefix}head/bias'].shape[-1]:",
            "+    if isinstance(model.head, nn.Linear) and model.head.bias.shape[0] == w[f'{prefix}head/bias'].shape[-1]:",
            "model.head.weight.copy_(_n2p(w[f'{prefix}head/kernel']))",
            "model.head.bias.copy_(_n2p(w[f'{prefix}head/bias']))",
            "for i, block in enumerate(model.blocks.children()):"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 4783,
        "label": "no",
        "change": [
            "def remap_variables(fn):",
            "def freeze_variables():",
            "\"\"\"",
            "Return a context, where all variables (reused or not) returned by",
            "-    ``get_variable`` will have no gradients (they  will be followed by ``tf.stop_gradient``).",
            "+    ``get_variable`` will have no gradients (they will be wrapped by ``tf.stop_gradient``).",
            "But they will still be in ``TRAINABLE_VARIABLES`` collections so they will get",
            "saved correctly. This is useful to fix certain variables for fine-tuning.",
            "",
            "Example:",
            ".. code-block:: python",
            "",
            "-            with varreplace.freeze_get_variable():",
            "+            with varreplace.freeze_variable():",
            "x = FullyConnected('fc', x, 1000)   # fc/* will not be trained",
            "\"\"\"",
            "return remap_variables(lambda v: tf.stop_gradient(v))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4794,
        "label": "yes",
        "change": [
            "class MeanSquaredLogError(Metric):",
            "preds: Predictions from model",
            "target: Ground truth values",
            "\"\"\"",
            "-        self._check_same_shape(preds, target)",
            "-        squared_log_error = torch.pow(torch.log1p(preds) - torch.log1p(target), 2)",
            "+        sum_squared_log_error, n_obs = _mean_squared_log_error_update(preds, target)",
            "",
            "-        self.sum_squared_log_error += torch.sum(squared_log_error)",
            "-        self.total += target.numel()",
            "+        self.sum_squared_log_error += sum_squared_log_error",
            "+        self.total += n_obs",
            "",
            "def compute(self):",
            "\"\"\"",
            "Compute mean squared logarithmic error over state.",
            "\"\"\"",
            "-        return self.sum_squared_log_error / self.total",
            "+        return _mean_squared_log_error_compute(self.sum_squared_log_error, self.total)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "state handling error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 4795,
        "label": "no",
        "change": [
            "class Tacotron(nn.Module):",
            "forward_attn, trans_agent, forward_attn_mask,",
            "location_attn, separate_stopnet)",
            "self.postnet = PostCBHG(mel_dim)",
            "-        self.last_linear = nn.Sequential(",
            "-            nn.Linear(self.postnet.cbhg.gru_features * 2, linear_dim),",
            "-            nn.Sigmoid())",
            "+        self.last_linear = nn.Linear(self.postnet.cbhg.gru_features * 2, linear_dim)",
            "",
            "def forward(self, characters, text_lengths, mel_specs, speaker_ids=None):",
            "B = characters.size(0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4796,
        "label": "no",
        "change": [
            "def test_dna_conv1():",
            "assert out.size() == (num_nodes, channels)",
            "",
            "if is_full_test():",
            "-        jit = torch.jit.script(conv.jittable())",
            "+        t = '(Tensor, Tensor, OptTensor) -> Tensor'",
            "+        jit = torch.jit.script(conv.jittable(t))",
            "assert jit(x, edge_index).tolist() == out.tolist()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4797,
        "label": "no",
        "change": [
            "class InternalLstm(TransformationBase):",
            "assert False",
            "",
            "specification[self.name] = dict(",
            "-            type='float', shape=(2, self.size), initial_state=tf.identity(x=self.initial_state)",
            "+            type='float', shape=(2, self.size), initial_state=self.initial_state",
            ")",
            "",
            "return specification"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4798,
        "label": "yes",
        "change": [
            "class Wav2VecCtc(BaseFairseqModel):",
            "",
            "if net_output[\"padding_mask\"] is not None and net_output[\"padding_mask\"].any():",
            "number_of_classes = logits.size(-1)",
            "-            masking_tensor = torch.ones(number_of_classes) * float(\"-inf\")",
            "-            masking_tensor[0] = float(\"inf\")",
            "+            masking_tensor = torch.ones(",
            "+                number_of_classes, device=logits.device",
            "+            ) * float(\"-inf\")",
            "+            masking_tensor[0] = 0",
            "logits[net_output[\"padding_mask\"].T] = masking_tensor.type_as(logits)",
            "",
            "if normalize:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 4799,
        "label": "no",
        "change": [
            "class LayerScale(layers.Layer):",
            "",
            "def build(self, input_shape):",
            "self.gamma = tf.Variable(",
            "-            self.init_values * tf.ones((self.projection_dim,))",
            "+            self.init_values * tf.ones((self.projection_dim,)),",
            "+            dtype=self._compute_dtype_object",
            ")",
            "",
            "def call(self, x):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4802,
        "label": "no",
        "change": [
            "def multiclass_nms(multi_bboxes,",
            "",
            "scores = multi_scores[:, :-1]",
            "",
            "-    labels = torch.arange(num_classes, dtype=torch.long)",
            "+    labels = torch.arange(num_classes, dtype=torch.long, device=scores.device)",
            "labels = labels.view(1, -1).expand_as(scores)",
            "",
            "bboxes = bboxes.reshape(-1, 4)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4803,
        "label": "no",
        "change": [
            "def BilinearUpSample(x, shape):",
            "\"\"\"",
            "# inp_shape = tf.shape(x)",
            "# return tf.image.resize_bilinear(x,",
            "-    # tf.pack([inp_shape[1]*shape,inp_shape[2]*shape]),",
            "+    # tf.stack([inp_shape[1]*shape,inp_shape[2]*shape]),",
            "# align_corners=True)",
            "",
            "inp_shape = x.get_shape().as_list()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4821,
        "label": "no",
        "change": [
            "def run_compare_tf(",
            "graph, feed_dict, output_nodes, frontend, backend",
            ")",
            "else:",
            "-        with tf.Session(graph=graph) as sess:",
            "-            sess.run(tf.global_variables_initializer())",
            "-            tf_outputs = sess.run(output_nodes, feed_dict=feed_dict)",
            "+        if not tf_outputs:",
            "+            with tf.Session(graph=graph) as sess:",
            "+                sess.run(tf.global_variables_initializer())",
            "+                tf_outputs = sess.run(output_nodes, feed_dict=feed_dict)",
            "expected_outputs = {name: val for name, val in zip(output_names, tf_outputs)}",
            "",
            "for k,v in input_key_values.items():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4830,
        "label": "yes",
        "change": [
            "class Trainer:",
            "\"\"\"",
            "for k, v in inputs.items():",
            "if isinstance(v, torch.Tensor):",
            "-                inputs[k] = v.to(self.args.device)",
            "+                kwargs = dict(device=self.args.device)",
            "+                if self.deepspeed and inputs[k].dtype != torch.int64:",
            "+                    # NLP models inputs are int64 and those get adjusted to the right dtype of the",
            "+                    # embedding. Other models such as wav2vec2's inputs are already float and thus",
            "+                    # may need special handling to match the dtypes of the model",
            "+                    kwargs.update(dict(dtype=self.args.hf_deepspeed_config.dtype()))",
            "+",
            "+                inputs[k] = v.to(**kwargs)",
            "",
            "if self.args.past_index >= 0 and self._past is not None:",
            "inputs[\"mems\"] = self._past"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 4831,
        "label": "no",
        "change": [
            "class RNNP(torch.nn.Module):",
            "xs_pack = pack_padded_sequence(xs_pad, ilens, batch_first=True)",
            "rnn = getattr(self, (\"birnn\" if self.bidir else \"rnn\") + str(layer))",
            "rnn.flatten_parameters()",
            "-            if prev_state is not None and self.nbrnn.bidirectional:",
            "+            if prev_state is not None and rnn.bidirectional:",
            "prev_state = zero_backward_rnn_state(prev_state)",
            "ys, states = rnn(xs_pack, hx=prev_state)",
            "elayer_states.append(states)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4837,
        "label": "no",
        "change": [
            "class TestAutoRegressiveSeqDecoder(AllenNlpTestCase):",
            "",
            "encoded_state = torch.randn(batch_size, time_steps, decoder_inout_dim)",
            "source_mask = torch.ones(batch_size, time_steps).long()",
            "-        target_tokens = {\"tokens\": torch.ones(batch_size, time_steps).long()}",
            "+        target_tokens = {\"tokens\": {\"tokens\": torch.ones(batch_size, time_steps).long()}}",
            "source_mask[0, 1:] = 0",
            "encoder_out = {\"source_mask\": source_mask, \"encoder_outputs\": encoded_state}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4838,
        "label": "no",
        "change": [
            "def test_encoder_cache(normalize_before):",
            "dropout_rate=0.0,",
            "input_layer=\"embed\")",
            "elayer = encoder.encoders[0]",
            "-    memory = torch.randn(2, 5, adim)",
            "-",
            "x = torch.randn(2, 5, adim)",
            "mask = subsequent_mask(x.shape[1]).unsqueeze(0)",
            "prev_mask = mask[:, :-1, :-1]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4839,
        "label": "no",
        "change": [
            "class SequenceAccuracy(Metric):",
            "accuracy = self.correct_count / self.total_count",
            "else:",
            "accuracy = 0",
            "-",
            "if reset:",
            "self.reset()",
            "-        return accuracy",
            "+        return {\"accuracy\": accuracy}",
            "",
            "@overrides",
            "def reset(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4845,
        "label": "no",
        "change": [
            "def is_remote_filesystem(fs: fsspec.spec.AbstractFileSystem) -> bool:",
            "Validates if filesystem has remote protocol.",
            "",
            "Args:",
            "-        fs (``fsspec.spec.AbstractFileSystem``): An abstract super-class for pythonic file-systems, e.g. :code:`fsspec.filesystem(\\'file\\')` or :class:`datasets.filesystem.S3FileSystem`",
            "+        fs (``fsspec.spec.AbstractFileSystem``): An abstract super-class for pythonic file-systems, e.g. :code:`fsspec.filesystem(\\'file\\')` or :class:`datasets.filesystems.S3FileSystem`",
            "\"\"\"",
            "if fs is not None and fs.protocol != \"file\":",
            "return True"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4848,
        "label": "no",
        "change": [
            "class BartConfig(PretrainedConfig):",
            "if self.normalize_before or self.add_final_layer_norm or self.scale_embedding:",
            "logger.info(\"This configuration is a mixture of MBART and BART settings\")",
            "return False",
            "-",
            "-",
            "-class MBartConfig(BartConfig):",
            "-    model_type = \"mbart\"",
            "-    \"\"\"See real config values at https://s3.amazonaws.com/models.huggingface.co/bert/facebook/mbart-large-en-ro/config.json.\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4851,
        "label": "no",
        "change": [
            "from .tokenization_utils import BatchEncoding",
            "logger = logging.getLogger(__name__)",
            "",
            "TF_TRANSFO_XL_PRETRAINED_MODEL_ARCHIVE_MAP = {",
            "-    \"transfo-xl-wt103\": \"https://s3.amazonaws.com/models.huggingface.co/bert/transfo-xl-wt103-tf_model.h5\",",
            "+    \"transfo-xl-wt103\": \"https://cdn.huggingface.co/transfo-xl-wt103-tf_model.h5\",",
            "}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4853,
        "label": "yes",
        "change": [
            "class QLoss:",
            "# priority is robust and insensitive to `prioritized_replay_alpha`",
            "self.td_error = tf.nn.softmax_cross_entropy_with_logits(",
            "labels=m, logits=q_logits_t_selected)",
            "-            self.loss = tf.reduce_mean(self.td_error * importance_weights)",
            "+            self.loss = tf.reduce_mean(",
            "+                self.td_error * tf.cast(importance_weights, tf.float32))",
            "self.stats = {",
            "# TODO: better Q stats for dist dqn",
            "\"mean_td_error\": tf.reduce_mean(self.td_error),"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 4861,
        "label": "yes",
        "change": [
            "try:",
            "if _torch_available:",
            "import torch",
            "",
            "-        if torch.__version__ < version.Version(\"1.12\"):",
            "+        if version.Version(torch.__version__) < version.Version(\"1.12\"):",
            "raise ValueError(\"PyTorch should be >= 1.12\")",
            "logger.debug(f\"Successfully imported xformers version {_xformers_version}\")",
            "except importlib_metadata.PackageNotFoundError:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 4862,
        "label": "no",
        "change": [
            "class LocalMetricTest(parameterized.TestCase):",
            "",
            "def test_load_metric(self, metric_name):",
            "doctest.ELLIPSIS_MARKER = \"[...]\"",
            "-        metric_module = importlib.import_module(datasets.load.prepare_module(os.path.join(\"metrics\", metric_name))[0])",
            "+        metric_module = importlib.import_module(",
            "+            datasets.load.prepare_module(os.path.join(\"metrics\", metric_name), dataset=False)[0]",
            "+        )",
            "metric = datasets.load.import_main_class(metric_module.__name__, dataset=False)",
            "# check parameters",
            "parameters = inspect.signature(metric._compute).parameters"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4864,
        "label": "no",
        "change": [
            "class TestSimpleKD:",
            "def test_jit(self, device, dtype):",
            "batch_size, channels, ps = 1, 1, 19",
            "patches = torch.rand(batch_size, channels, ps, ps).to(device)",
            "-        model =  SimpleKD(patch_size=ps, kernel_type='polar', whitening='lw').to(patches.device, patches.dtype).eval()  # noqa",
            "-        model_jit = torch.jit.script( SimpleKD(patch_size=ps, kernel_type='polar', whitening='lw').to(patches.device, patches.dtype).eval())  # noqa",
            "+        model = SimpleKD(patch_size=ps, kernel_type='polar', whitening='lw').to(patches.device, patches.dtype).eval()  # noqa",
            "+        model_jit = torch.jit.script(SimpleKD(patch_size=ps, kernel_type='polar', whitening='lw').to(patches.device, patches.dtype).eval())  # noqa",
            "assert_allclose(model(patches), model_jit(patches))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4868,
        "label": "no",
        "change": [
            "class GradientAccumulator(object):",
            "self._gradients.extend(",
            "[",
            "tf.Variable(",
            "-                        tf.zeros_like(gradient), trainable=False, synchronization=tf.VariableSynchronization.ON_READ,",
            "+                        tf.zeros_like(gradient),",
            "+                        trainable=False,",
            "+                        synchronization=tf.VariableSynchronization.ON_READ,",
            "+                        aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA,",
            ")",
            "for gradient in gradients",
            "]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4871,
        "label": "yes",
        "change": [
            "def move_data_to_device(batch: Any, device: Union[str, torch.device]) -> Any:",
            "",
            "kwargs = {}",
            "# Don't issue non-blocking transfers to CPU",
            "-        if isinstance(data, Tensor) and device not in _CPU_DEVICES:",
            "+        # Same with MPS due to a race condition bug: https://github.com/pytorch/pytorch/issues/83015",
            "+        if isinstance(data, Tensor) and isinstance(device, torch.device) and device.type not in _BLOCKING_DEVICE_TYPES:",
            "kwargs[\"non_blocking\"] = True",
            "data_output = data.to(device, **kwargs)",
            "if data_output is not None:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 4874,
        "label": "yes",
        "change": [
            "def select_device(device='', batch_size=0, newline=True):",
            "if cpu:",
            "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # force torch.cuda.is_available() = False",
            "elif device:  # non-cpu device requested",
            "-        nd = torch.cuda.device_count()  # number of CUDA devices",
            "-        assert torch.cuda.is_available(), 'CUDA is not available, use `--device cpu` or do not pass a --device'",
            "+        nd = device_count()  # number of CUDA devices",
            "assert nd > int(max(device.split(','))), f'Invalid `--device {device}` request, valid devices are 0 - {nd - 1}'",
            "-        os.environ['CUDA_VISIBLE_DEVICES'] = device  # set environment variable (must be after asserts)",
            "+        os.environ['CUDA_VISIBLE_DEVICES'] = device  # set environment variable - must be before assert is_available()",
            "+        assert torch.cuda.is_available(), 'CUDA is not available, use `--device cpu` or do not pass a --device'",
            "",
            "cuda = not cpu and torch.cuda.is_available()",
            "if cuda:"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 4876,
        "label": "no",
        "change": [
            "def symmetric_linear_quantization_params(num_bits, saturation_min, saturation_ma",
            "`saturation_max`.",
            "\"\"\"",
            "# in this part, we do not need any gradient computation,",
            "-    # in order to enfore this, we put torch.no_grad()",
            "+    # in order to enforce this, we put torch.no_grad()",
            "with torch.no_grad():",
            "n = 2 ** (num_bits - 1) - 1"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4878,
        "label": "no",
        "change": [
            "def main(args):",
            "print(args)",
            "",
            "use_cuda = torch.cuda.is_available() and not args.cpu",
            "-    if hasattr(torch, 'set_grad_enabled'):",
            "-        torch.set_grad_enabled(False)",
            "",
            "# Load dataset",
            "if args.replace_unk is None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4881,
        "label": "no",
        "change": [
            "class TestTimeDistributed(AllenNlpTestCase):",
            "def test_time_distributed_works_with_multiple_inputs(self):",
            "module = lambda x, y: x + y",
            "distributed = TimeDistributed(module)",
            "-        x_input = Variable(torch.LongTensor([[[1, 2], [3, 4]]]))",
            "-        y_input = Variable(torch.LongTensor([[[4, 2], [9, 1]]]))",
            "+        x_input = torch.LongTensor([[[1, 2], [3, 4]]])",
            "+        y_input = torch.LongTensor([[[4, 2], [9, 1]]])",
            "output = distributed(x_input, y_input)",
            "assert_almost_equal(output.data.numpy(), [[[5, 4], [12, 5]]])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4882,
        "label": "no",
        "change": [
            "def test_pred_input(params, enc = None):",
            "bos = tf.constant(1, shape=[1, 1], dtype=tf.int64)",
            "src_seq = tf.random.uniform(shape=[1, length], minval=4, maxval=(params['n_vocab'] - 1), dtype=tf.int64)",
            "seq = tf.concat([bos, src_seq], axis=1)",
            "-    seq = tf.pad(seq, [[0, 0], [0, remaining]], constant_values=params['padding_id'])",
            "+    seq = tf.pad(seq, [[0, 0], [0, remaining]])",
            "dataset = tf.data.Dataset.from_tensors(seq)",
            "",
            "dataset = dataset.map(_dummy_labels)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4885,
        "label": "no",
        "change": [
            "class UNetModel(ModelMixin, ConfigMixin):",
            "hs.append(self.down[i_level].downsample(hs[-1]))",
            "",
            "# middle",
            "-        h = self.mid(hs[-1], temb)",
            "-        #        h = self.mid.block_1(h, temb)",
            "-        #        h = self.mid.attn_1(h)",
            "-        #        h = self.mid.block_2(h, temb)",
            "+        h = self.mid_new(hs[-1], temb)",
            "",
            "# upsampling",
            "for i_level in reversed(range(self.num_resolutions)):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4888,
        "label": "no",
        "change": [
            "class OPTDecoder(OPTPreTrainedModel):",
            "# with checkpoints that have been fine-tuned before transformers v4.20.1",
            "# see https://github.com/facebookresearch/metaseq/pull/164",
            "if config.do_layer_norm_before and not config._remove_final_layer_norm:",
            "-            self.final_layer_norm = nn.LayerNorm(config.hidden_size)",
            "+            self.final_layer_norm = nn.LayerNorm(",
            "+                config.hidden_size, elementwise_affine=config.layer_norm_elementwise_affine",
            "+            )",
            "else:",
            "self.final_layer_norm = None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4889,
        "label": "no",
        "change": [
            "class NormalizeRotation(object):",
            "C = torch.matmul(pos.t(), pos)",
            "e, v = torch.eig(C, eigenvectors=True)  # v[:,j] is j-th eigenvector",
            "",
            "-        data.pos = torch.matmul(pos, v)",
            "+        data.pos = torch.matmul(data.pos, v)",
            "",
            "if 'norm' in data:",
            "data.norm = F.normalize(torch.matmul(data.norm, v))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4897,
        "label": "no",
        "change": [
            "def test_deg2rad(batch_shape, device, dtype, atol, rtol):",
            "",
            "assert_close(x_deg, x_rad_to_deg, atol=atol, rtol=rtol)",
            "",
            "-    eps = torch.finfo(dtype).eps",
            "assert gradcheck(kornia.deg2rad, (tensor_to_gradcheck_var(x_deg),), raise_exception=True)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4898,
        "label": "no",
        "change": [
            "class NewDataset(datasets.GeneratorBasedBuilder):",
            "# data = datasets.load_dataset('my_dataset', 'first_domain')",
            "# data = datasets.load_dataset('my_dataset', 'second_domain')",
            "BUILDER_CONFIGS = [",
            "-        datasets.BuilderConfig(name=\"first_domain\", description=\"This part of my dataset covers a first domain\"),",
            "-        datasets.BuilderConfig(name=\"second_domain\", description=\"This part of my dataset covers a second domain\"),",
            "+        datasets.BuilderConfig(name=\"first_domain\", version=VERSION, description=\"This part of my dataset covers a first domain\"),",
            "+        datasets.BuilderConfig(name=\"second_domain\", version=VERSION, description=\"This part of my dataset covers a second domain\"),",
            "]",
            "",
            "DEFAULT_CONFIG_NAME = \"first_domain\"  # It's not mandatory to have a default configuration. Just use one if it make sense."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4899,
        "label": "no",
        "change": [
            "class HolidayCalendarTest(tf.test.TestCase, parameterized.TestCase):",
            "def test_skip_eager_reset(self):",
            "cal = dates.HolidayCalendar(start_year=2020, end_year=2021)",
            "cal.is_business_day(dates.DateTensor.from_tuples([]))  # Trigger caching.",
            "-    tf.reset_default_graph()",
            "+    tf.compat.v1.reset_default_graph()",
            "cal.reset()",
            "date_tensor = dates.DateTensor.from_tuples([(2020, 1, 3), (2020, 1, 4),",
            "(2021, 12, 24), (2021, 12, 25)])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4901,
        "label": "no",
        "change": [
            "class TestRandomRotation3D:",
            "",
            "def test_same_on_batch(self, device, dtype):",
            "f = RandomRotation3D(degrees=40, same_on_batch=True)",
            "-        input = torch.eye(6, device=device, dtype=dtype).unsqueeze(dim=0).unsqueeze(dim=0).repeat(2, 3, 1, 1, 1)",
            "+        input = torch.eye(6, device=device, dtype=dtype).unsqueeze(dim=0).unsqueeze(dim=0).repeat(2, 3, 6, 1, 1)",
            "res = f(input)",
            "assert (res[0] == res[1]).all()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4906,
        "label": "no",
        "change": [
            "class TFSegformerDecodeHead(TFSegformerPreTrainedModel):",
            "self.linear_fuse = tf.keras.layers.Conv2D(",
            "filters=config.decoder_hidden_size, kernel_size=1, use_bias=False, name=\"linear_fuse\"",
            ")",
            "-        self.batch_norm = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum=0.1, name=\"batch_norm\")",
            "+        self.batch_norm = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum=0.9, name=\"batch_norm\")",
            "self.activation = tf.keras.layers.Activation(\"relu\")",
            "",
            "self.dropout = tf.keras.layers.Dropout(config.classifier_dropout_prob)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4907,
        "label": "no",
        "change": [
            "class BartForSequenceClassification(PretrainedBartModel):",
            "",
            "loss = None",
            "if labels is not None:",
            "-            loss = F.cross_entropy(logits.view(-1, self.config.num_labels), labels.view(-1))",
            "+            loss_fct = CrossEntropyLoss()",
            "+            loss = loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))",
            "",
            "if not return_dict:",
            "output = (logits,) + outputs[1:]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4910,
        "label": "no",
        "change": [
            "def leaky_twice_relu6(x, alpha_low=0.2, alpha_high=0.2, name=\"leaky_relu6\"):",
            "",
            "\"\"\"",
            "",
            "-    if not (0 < alpha_high <= 1):",
            "+    if not isinstance(alpha_high, tf.Tensor) and not (0 < alpha_high <= 1):",
            "raise ValueError(\"`alpha_high` value must be in [0, 1]`\")",
            "",
            "-    if not (0 < alpha_low <= 1):",
            "+    if not isinstance(alpha_low, tf.Tensor) and not (0 < alpha_low <= 1):",
            "raise ValueError(\"`alpha_low` value must be in [0, 1]`\")",
            "",
            "with tf.name_scope(name, \"leaky_twice_relu6\") as name_scope:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4911,
        "label": "no",
        "change": [
            "class TfKerasModelArtifact(Artifact):",
            "def model_file_path(self, base_path):",
            "return os.path.join(base_path, self.name + self._model_extension)",
            "",
            "-    def pack(self, model):",
            "+    def pack(self, model):  # pylint:disable=arguments-differ",
            "self.model = model",
            "",
            "def get(self):",
            "return self.model",
            "",
            "-    def load(self, base_path):  # pylint:disable=arguments-differ",
            "-        from tensorflow.keras.models import load_model",
            "+    def load(self, base_path):",
            "+        try:",
            "+            from tensorflow.keras.models import load_model",
            "+        except ImportError:",
            "+            raise ImportError(\"tensorflow package is required to use TfKerasModelArtifact\")",
            "self.model = load_model(self.model_file_path(base_path))",
            "",
            "def save(self, base_path):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4913,
        "label": "no",
        "change": [
            "def test_mcmc_interface():",
            "samples.append(marginal.sample(data))",
            "sample_mean = torch.mean(torch.stack(samples), 0)",
            "sample_std = torch.std(torch.stack(samples), 0)",
            "-    assert_equal(sample_mean.data, torch.Tensor([0.0]), prec=5e-2)",
            "-    assert_equal(sample_std.data, torch.Tensor([1.0]), prec=5e-2)",
            "+    assert_equal(sample_mean.data, torch.Tensor([0.0]), prec=0.08)",
            "+    assert_equal(sample_std.data, torch.Tensor([1.0]), prec=0.08)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4917,
        "label": "no",
        "change": [
            "class Multinomial(Distribution):",
            "if var.data.dim() == 1:",
            "return var.data",
            "# nested tensor arrays because of batches\"",
            "-        return var.data.numpy()[0]",
            "+        return var.data.cpu().numpy()[0]",
            "",
            "def analytic_mean(self, ps=None, n=None):",
            "ps, n = self._sanitize_input(ps, n)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4927,
        "label": "no",
        "change": [
            "def cql_loss(policy: Policy, model: ModelV2,",
            "# CQL Loss (We are using Entropy version of CQL (the best version))",
            "rand_actions = convert_to_torch_tensor(",
            "torch.FloatTensor(actions.shape[0] * num_actions,",
            "-                          actions.shape[-1]).uniform_(action_low, action_high))",
            "+                          actions.shape[-1]).uniform_(action_low, action_high),",
            "+        policy.device)",
            "curr_actions, curr_logp = policy_actions_repeat(model, action_dist_class,",
            "obs, num_actions)",
            "next_actions, next_logp = policy_actions_repeat(model, action_dist_class,",
            "next_obs, num_actions)",
            "+",
            "curr_logp = curr_logp.view(actions.shape[0], num_actions, 1)",
            "next_logp = next_logp.view(actions.shape[0], num_actions, 1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4929,
        "label": "no",
        "change": [
            "class SimplePoutineTests(TestCase):",
            "",
            "def guide():",
            "latent = pyro.sample(\"latent\",",
            "-                                DiagNormal(Variable(torch.zeros(1)),",
            "+                                 DiagNormal(Variable(torch.zeros(1)),",
            "5 * Variable(torch.ones(1))))",
            "-            #x_dist = DiagNormal(latent, Variable(torch.ones(1)))",
            "+            # x_dist = DiagNormal(latent, Variable(torch.ones(1)))",
            "return latent",
            "",
            "self.guide = guide",
            "",
            "-",
            "def test_trace_replay(self):",
            "\"\"\"",
            "some simple invariants on a single example, but woefully incomplete"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4930,
        "label": "no",
        "change": [
            "def attempt_load(weights, device=None, inplace=True, fuse=True):",
            "# Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a",
            "model = Ensemble()",
            "for w in weights if isinstance(weights, list) else [weights]:",
            "-        ckpt = torch.load(attempt_download(w))",
            "-        ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model",
            "+        ckpt = torch.load(attempt_download(w), map_location=device)",
            "+        ckpt = (ckpt.get('ema') or ckpt['model']).float()  # FP32 model",
            "model.append(ckpt.fuse().eval() if fuse else ckpt.eval())  # fused or un-fused model in eval mode",
            "",
            "# Compatibility updates"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4931,
        "label": "no",
        "change": [
            "class Trainer(object):",
            "session_creator (tf.train.SessionCreator):",
            "session_init (sessinit.SessionInit):",
            "\"\"\"",
            "+        assert isinstance(session_creator, tf.train.SessionCreator), session_creator",
            "+        assert isinstance(session_init, SessionInit), session_init",
            "session_init._setup_graph()",
            "",
            "logger.info(\"Creating the session ...\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4936,
        "label": "no",
        "change": [
            "def count_nonzero(",
            "def _dtype_count_nonzero(a, axis, dtype):",
            "if dtype is None:",
            "return torch.count_nonzero(a, dim=axis)",
            "-        return torch.tensor(torch.count_nonzero(a, dim=axis),",
            "-                            dtype=ivy.as_native_dtype(dtype))",
            "+        return torch.tensor(",
            "+            torch.count_nonzero(a, dim=axis), dtype=ivy.as_native_dtype(dtype)",
            "+        )",
            "",
            "x = _dtype_count_nonzero(a, axis, dtype)",
            "if not keepdims:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4938,
        "label": "no",
        "change": [
            "def remainder(",
            ") -> torch.Tensor:",
            "x1, x2 = _cast_for_binary_op(x1, x2)",
            "ret = torch.remainder(x1, x2, out=out)",
            "-    ret[torch.isnan(ret)] = 0",
            "if ivy.exists(out):",
            "return ivy.inplace_update(out, ret)",
            "return ret"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4941,
        "label": "no",
        "change": [
            "def one_hot(",
            "device: torch.device,",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "-    return torch.nn.functional.one_hot(indices.type(torch.int64), depth).to(device)",
            "+    return torch.nn.functional.one_hot(indices.to(torch.int64), depth).to(",
            "+        device, indices.dtype",
            "+    )",
            "",
            "",
            "def shape(x: torch.Tensor, as_array: bool = False) -> Union[ivy.Shape, ivy.Array]:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4942,
        "label": "no",
        "change": [
            "def linear_transform(",
            "new_order: List[int] = perm.tolist()",
            "inv_order: List[int] = perm_inv.tolist()",
            "",
            "-    feature_sizes = torch.tensor(inp_size[0:dim] + inp_size[dim + 1::])",
            "+    feature_sizes = torch.tensor(inp_size[0:dim] + inp_size[dim + 1 : :])",
            "num_features: int = int(torch.prod(feature_sizes).item())",
            "",
            "inp_permute = inp.permute(new_order)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4944,
        "label": "no",
        "change": [
            "class TFDeiTForImageClassification(TFDeiTPreTrainedModel, TFSequenceClassificati",
            ">>> # model predicts one of the 1000 ImageNet classes",
            ">>> predicted_class_idx = tf.math.argmax(logits, axis=-1)[0]",
            ">>> print(\"Predicted class:\", model.config.id2label[int(predicted_class_idx)])",
            "-        Predicted class: ptarmigan",
            "+        Predicted class: little blue heron, Egretta caerulea",
            "```\"\"\"",
            "return_dict = return_dict if return_dict is not None else self.config.use_return_dict"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4946,
        "label": "no",
        "change": [
            "def init_checkpoint_callback(logger):",
            "",
            "",
            "def pl_multi_process_test(func):",
            "-    \"\"\"Wrapper for running multi-processing tests.\"\"\"",
            "+    \"\"\"Wrapper for running multi-processing tests_pytorch.\"\"\"",
            "",
            "@functools.wraps(func)",
            "def wrapper(*args, **kwargs):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4948,
        "label": "no",
        "change": [
            "net.print_layers()",
            "net.print_params(False)",
            "",
            "if len(net.all_layers) != 6:",
            "-    raise Exception(\"layers dont match\")",
            "+    raise Exception(\"layers do not match\")",
            "",
            "if len(net.all_params) != 12:",
            "-    raise Exception(\"params dont match\")",
            "+    raise Exception(\"params do not match\")",
            "",
            "if net.count_params() != 60560:",
            "-    raise Exception(\"params dont match\")",
            "+    raise Exception(\"params do not match\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4952,
        "label": "yes",
        "change": [
            "class TFMarianSinusoidalPositionalEmbedding(tf.keras.layers.Layer):",
            "position_enc = np.array(",
            "[[pos / np.power(10000, 2 * (j // 2) / dim) for j in range(dim)] for pos in range(n_pos)]",
            ")",
            "+        table = np.zeros_like(position_enc)",
            "# index 0 is all zero",
            "-        position_enc[:, 0 : dim // 2] = np.sin(position_enc[:, 0::2])",
            "-        position_enc[:, dim // 2 :] = np.cos(position_enc[:, 1::2])",
            "+        table[:, 0 : dim // 2] = np.sin(position_enc[:, 0::2])",
            "+        table[:, dim // 2 :] = np.cos(position_enc[:, 1::2])",
            "# convert to tensor",
            "-        table = tf.convert_to_tensor(position_enc)",
            "+        table = tf.convert_to_tensor(table)",
            "tf.stop_gradient(table)",
            "return table"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 4953,
        "label": "no",
        "change": [
            "class PreNorm(nn.Module):",
            "self.norm = nn.LayerNorm(dim)",
            "self.fn = fn",
            "",
            "-    def forward(self, x: torch.Tensor, **kwargs) -> nn.Module:",
            "+    def forward(self, x: torch.Tensor, **kwargs) -> torch.Tensor:",
            "return self.fn(self.norm(x), **kwargs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4957,
        "label": "no",
        "change": [
            "class SmoothGradient(SaliencyInterpreter):",
            "def forward_hook(module, inputs, output):",
            "# Random noise = N(0, stdev * (max-min))",
            "scale = output.detach().max() - output.detach().min()",
            "-            noise = torch.randn(output.shape).to(output.device) * stdev * scale",
            "+            noise = torch.randn(output.shape, device=output.device) * stdev * scale",
            "",
            "# Add the random noise",
            "output.add_(noise)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4958,
        "label": "no",
        "change": [
            "def barrier_price(*,",
            "raise ValueError('At most one of continuous_dividends and cost of carries '",
            "'may be supplied')",
            "with tf.name_scope(name or \"barrier_price\"):",
            "-    strikes = tf.convert_to_tensor(strikes, dtype=dtype, name=\"strikes\")",
            "-    dtype = strikes.dtype",
            "spots = tf.convert_to_tensor(spots, dtype=dtype, name=\"spots\")",
            "+    dtype = spots.dtype",
            "+    strikes = tf.convert_to_tensor(strikes, dtype=dtype, name=\"strikes\")",
            "volatilities = tf.convert_to_tensor(",
            "volatilities, dtype=dtype, name=\"volatilities\")",
            "expiries = tf.convert_to_tensor(expiries, dtype=dtype, name=\"expiries\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4966,
        "label": "no",
        "change": [
            "def _setup_ddp(rank, worldsize):",
            "def _ddp_test_fn(rank, worldsize):",
            "_setup_ddp(rank, worldsize)",
            "tensor = torch.tensor([1.0])",
            "-    sync = _Sync(sync_ddp_if_available, should=True, op=torch.distributed.ReduceOp.SUM)",
            "+    sync = _Sync(sync_ddp_if_available, should=True, op='SUM')",
            "actual = sync(tensor)",
            "assert actual.item() == dist.get_world_size(), \"Result-Log does not work properly with DDP and Tensors\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4969,
        "label": "no",
        "change": [
            "class Trainer:",
            "return loss.item()",
            "",
            "def _run_epoch(self, epoch: int, dataloader: DataLoader, train: bool = True):",
            "+        self.dataloader.sampler.set_epoch(epoch)",
            "for iter, (source, targets) in enumerate(dataloader):",
            "step_type = \"Train\" if train else \"Eval\"",
            "source = source.to(self.local_rank)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4971,
        "label": "no",
        "change": [
            "class QM9(InMemoryDataset):",
            "bond_idx += 2 * [self.bonds[bond.GetBondType()]]",
            "",
            "edge_index = torch.tensor([row, col], dtype=torch.long)",
            "-            edge_attr = F.one_hot(torch.tensor(bond_idx),",
            "-                                  num_classes=len(self.bonds)).to(torch.float)",
            "+            edge_attr = F.one_hot(",
            "+                torch.tensor(bond_idx),",
            "+                num_classes=len(self.bonds)).to(torch.float)",
            "edge_index, edge_attr = coalesce(edge_index, edge_attr, N, N)",
            "",
            "y = target[i].unsqueeze(0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4973,
        "label": "no",
        "change": [
            "class NlvrCoverageSemanticParserTest(ModelTestCase):",
            "('e -> 6', True, None)]",
            "# Of the actions above, those at indices 0 and 4 are on the agenda, and there are padding",
            "# indices at the end.",
            "-        test_agenda = Variable(torch.Tensor([[0], [4], [-1], [-1]]))",
            "+        test_agenda = torch.Tensor([[0], [4], [-1], [-1]])",
            "checklist_info = self.model._get_checklist_info(test_agenda, all_actions)",
            "target_checklist, terminal_actions, checklist_mask = checklist_info",
            "assert_almost_equal(target_checklist.data.numpy(), [[1], [0], [1]])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4977,
        "label": "no",
        "change": [
            "class DistributedPGModel(object):",
            "# TODO write summaries",
            "# self.summary_writer = tf.summary.FileWriter('log' + \"_%d\" % self.task_index)",
            "if not self.optimizer:",
            "-                self.optimizer = tf.train.AdamOptimizer(self.alpha)",
            "+                self.optimizer = tf.train.AdamOptimizer(self.learning_rate)",
            "",
            "else:",
            "optimizer_cls = get_function(self.optimizer)",
            "-                self.optimizer = optimizer_cls(self.alpha, *self.optimizer_args, **self.optimizer_kwargs)",
            "+                self.optimizer = optimizer_cls(self.learning_rate, *self.optimizer_args, **self.optimizer_kwargs)",
            "",
            "self.optimize_op = tf.group(self.optimizer.apply_gradients(grad_var_list),",
            "global_step_inc)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4981,
        "label": "no",
        "change": [
            "class BiaffineDependencyParser(Model):",
            "attended_arcs = attended_arcs + torch.diag(attended_arcs.new(mask.size(1)).fill_(-numpy.inf))",
            "# Mask padded tokens, because we only want to consider actual words as heads.",
            "if mask is not None:",
            "-            minus_mask = (1 - mask).byte().unsqueeze(2)",
            "+            minus_mask = (1 - mask).to(dtype=torch.bool).unsqueeze(2)",
            "attended_arcs.masked_fill_(minus_mask, -numpy.inf)",
            "",
            "# Compute the heads greedily."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4982,
        "label": "no",
        "change": [
            "class PosterizeGenerator(RandomGeneratorBase):",
            "def forward(self, batch_shape: torch.Size, same_on_batch: bool = False) -> Dict[str, torch.Tensor]:  # type:ignore",
            "batch_size = batch_shape[0]",
            "_common_param_check(batch_size, same_on_batch)",
            "-        _device, _dtype = _extract_device_dtype([self.bits if isinstance(self.bits, torch.Tensor) else None])",
            "+        _device, _ = _extract_device_dtype([self.bits if isinstance(self.bits, torch.Tensor) else None])",
            "bits_factor = _adapted_rsampling((batch_size,), self.bit_sampler, same_on_batch)",
            "return dict(bits_factor=bits_factor.to(device=_device, dtype=torch.int32))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4988,
        "label": "no",
        "change": [
            "class DstcSlotFillingNetwork(Inferable, Trainable):",
            "self._slot_vals = json.load(f)",
            "",
            "self._ner_network = ner_network",
            "-        self.load()",
            "-",
            "",
            "@overrides",
            "def load(self):",
            "# Check presence of the model files",
            "-        if tf.train.get_checkpoint_state(str(path)) is not None:",
            "+        if tf.train.get_checkpoint_state(str(self.ser_path)) is not None:",
            "print(\"\\n:: initializing `{}` from saved\"\\",
            ".format(self.__class__.__name__))",
            "self._ner_network.load()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4992,
        "label": "no",
        "change": [
            "class ProgressCallback(TrainerCallback):",
            "self.current_step = state.global_step",
            "",
            "def on_prediction_step(self, args, state, control, eval_dataloader=None, **kwargs):",
            "-        if state.is_local_process_zero and has_length(eval_dataloader.dataset):",
            "+        if state.is_local_process_zero and has_length(eval_dataloader):",
            "if self.prediction_bar is None:",
            "self.prediction_bar = tqdm(total=len(eval_dataloader), leave=self.training_bar is None)",
            "self.prediction_bar.update(1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5002,
        "label": "yes",
        "change": [
            "def get_outputs_sizes_torch(",
            "",
            "",
            "def create_model_inputs_torch(",
            "-    batch_size: int, input_infos: List[InputInfo]",
            "+    input_infos: List[InputInfo],",
            ") -> List[torch.Tensor]:",
            "input_tensors = (",
            "-        torch.randn((batch_size, *input_info.size))",
            "+        torch.randn(*input_info.size)",
            "if input_info.dtype is DataType.FLOAT32",
            "else torch.randint(",
            "-            size=(batch_size, *input_info.size),",
            "+            size=input_info.size,",
            "low=input_info.min_value or 0,",
            "high=input_info.max_value or 100,",
            ")"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "removal",
        "Element": "api parameter"
    },
    {
        "number": 5004,
        "label": "no",
        "change": [
            "class LanguageModel(nn.Module):",
            "hidden = hidden",
            "",
            "input = torch.tensor(self.dictionary.get_idx_for_item(prefix[-1])).unsqueeze(0).unsqueeze(0)",
            "-            if torch.cuda.is_available():",
            "-                input = input.cuda()",
            "",
            "for i in range(number_of_characters):",
            "+",
            "+                if torch.cuda.is_available():",
            "+                    input = input.cuda()",
            "+",
            "prediction, _, hidden = self.forward(input, hidden)",
            "prediction /= temperature",
            "word_weights = prediction.squeeze().data.div(1.0).exp().cpu()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5005,
        "label": "no",
        "change": [
            "class TestBatchSamplerBehavior(unittest.TestCase):",
            "_micro_batch_size=_micro_batch_size,",
            "_global_batch_size=global_batch_size,",
            "))",
            "-            # print(batch)",
            "-            # print(microbatches)",
            "self.assertEqual(len(microbatches), global_batch_size // _micro_batch_size)",
            "self.assertEqual(len(microbatches[0][0]), _micro_batch_size)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5006,
        "label": "no",
        "change": [
            "class TransformerEmbeddings(TransformerBaseEmbeddings):",
            "def _forward_tensors(self, tensors) -> Dict[str, torch.Tensor]:",
            "return self.forward(**tensors)",
            "",
            "-    def export_onnx(self, path: Union[str, Path], example_sentences: List[Sentence], **kwargs) -> TransformerOnnxEmbeddings:",
            "+    def export_onnx(",
            "+        self, path: Union[str, Path], example_sentences: List[Sentence], **kwargs",
            "+    ) -> TransformerOnnxEmbeddings:",
            "\"\"\"",
            "Export TransformerEmbeddings to OnnxFormat.",
            ":param example_sentences: a list of sentences that will be used for tracing. It is recommended to take 2-4"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5007,
        "label": "no",
        "change": [
            "def random_uniform(low: float = 0.0, high: float = 1.0, shape: Optional[List[int",
            "true_shape: List[int] = []",
            "else:",
            "true_shape: List[int] = shape",
            "-    return _torch.rand(true_shape, device=default_device(dev).replace('gpu', 'cuda')) * rand_range + low",
            "+    return _torch.rand(true_shape, device=default_device(dev)) * rand_range + low",
            "",
            "",
            "def random_normal(mean: float = 0.0, std: float = 1.0, shape: Optional[List[int]] = None, dev: ivy.Device = None):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5013,
        "label": "no",
        "change": [
            "class QaNet(Model):",
            "self._span_start_accuracy(span_start_logits, span_start.squeeze(-1))",
            "loss += nll_loss(util.masked_log_softmax(span_end_logits, passage_mask), span_end.squeeze(-1))",
            "self._span_end_accuracy(span_end_logits, span_end.squeeze(-1))",
            "-            self._span_accuracy(best_span, torch.stack([span_start, span_end], -1))",
            "+            self._span_accuracy(best_span, torch.cat([span_start, span_end], -1))",
            "output_dict[\"loss\"] = loss",
            "",
            "# Compute the EM and F1 on SQuAD and add the tokenized input to the output."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5014,
        "label": "no",
        "change": [
            "def chat():",
            "model = ChatBotModel(True, batch_size=1)",
            "model.build_graph()",
            "",
            "-    # saver = tf.train.import_meta_graph('checkpoints/chatbot-30.meta')",
            "-",
            "saver = tf.train.Saver()",
            "",
            "with tf.Session() as sess:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5018,
        "label": "no",
        "change": [
            "def get_dropout_mask(dropout_probability: float, tensor_for_masking: torch.Tenso",
            "This scaling ensures expected values and variances of the output of applying this mask",
            "and the original tensor are the same.",
            "\"\"\"",
            "-    binary_mask = tensor_for_masking.new_tensor(torch.rand(tensor_for_masking.size()) > dropout_probability)",
            "+    binary_mask = (torch.rand(tensor_for_masking.size()) > dropout_probability).to(tensor_for_masking.device)",
            "# Scale mask by 1/keep_prob to preserve output statistics.",
            "dropout_mask = binary_mask.float().div(1.0 - dropout_probability)",
            "return dropout_mask"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5021,
        "label": "no",
        "change": [
            "class TextCNN(object):",
            "# Final (unnormalized) scores and predictions",
            "with tf.name_scope(\"output\"):",
            "W = tf.Variable(tf.truncated_normal([num_filters_total, num_classes], stddev=0.1), name=\"W\")",
            "-            b = tf.Variable(tf.constant(0.1, shape=[num_classes]))",
            "+            b = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=\"b\")",
            "self.scores = tf.nn.xw_plus_b(self.h_drop, W, b, name=\"scores\")",
            "self.predictions = tf.argmax(self.scores, 1, name=\"predictions\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5023,
        "label": "no",
        "change": [
            "class NaiveRNNDP(AbsSVS):",
            "before_outs.transpose(1, 2)",
            ").transpose(1, 2)",
            "",
            "-        return after_outs, None, None  # outs, probs, att_ws",
            "+        return dict(",
            "+            feat_gen=after_outs[0], prob=None, att_w=None",
            "+        )  # outs, probs, att_ws",
            "",
            "def _integrate_with_spk_embed(",
            "self, hs: torch.Tensor, spembs: torch.Tensor"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5024,
        "label": "no",
        "change": [
            "class UnsharpMask(nn.Module):",
            "torch.Size([2, 4, 5, 5])",
            "\"\"\"",
            "",
            "-    def __init__(self, kernel_size: Tuple[int, int],",
            "-                 sigma: Tuple[float, float],",
            "-                 border_type: str = 'reflect') -> None:",
            "+    def __init__(self, kernel_size: Tuple[int, int], sigma: Tuple[float, float], border_type: str = 'reflect') -> None:",
            "super(UnsharpMask, self).__init__()",
            "self.kernel_size: Tuple[int, int] = kernel_size",
            "self.sigma: Tuple[float, float] = sigma"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5025,
        "label": "no",
        "change": [
            "class RegNetPreTrainedModel(PreTrainedModel):",
            "main_input_name = \"pixel_values\"",
            "supports_gradient_checkpointing = True",
            "",
            "+    # Copied from transformers.models.resnet.modeling_resnet.ResNetPreTrainedModel._init_weights",
            "def _init_weights(self, module):",
            "if isinstance(module, nn.Conv2d):",
            "nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5029,
        "label": "no",
        "change": [
            "class BBoxHead(nn.Module):",
            "",
            "bboxes_list = []",
            "for i in range(len(img_metas)):",
            "-            inds = torch.nonzero(rois[:, 0] == i).squeeze(dim=1)",
            "+            inds = torch.nonzero(",
            "+                rois[:, 0] == i, as_tuple=False).squeeze(dim=1)",
            "num_rois = inds.numel()",
            "",
            "bboxes_ = rois[inds, 1:]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5030,
        "label": "no",
        "change": [
            "class SSIMLoss(torch.nn.Module):",
            "",
            "if ssim_loss.item() < 0.0:",
            "print(f\" > SSIM loss is out-of-range {ssim_loss.item()}, setting it 0.0\")",
            "-            ssim_loss =  torch.tensor([0.0])",
            "+            ssim_loss = torch.tensor([0.0])",
            "",
            "return ssim_loss"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5036,
        "label": "yes",
        "change": [
            "def infer_inputs_from_restored_call_function(fn):",
            "if isinstance(x, tf.SparseTensorSpec):",
            "return tf.SparseTensorSpec(common_shape, x.dtype)",
            "elif isinstance(x, tf.RaggedTensorSpec):",
            "-      return tf.RaggedTensorSpec(common_shape, x.dtype)",
            "+      return tf.RaggedTensorSpec(",
            "+          common_shape,",
            "+          x.dtype,",
            "+          ragged_rank=x.ragged_rank,",
            "+          row_splits_dtype=x.row_splits_dtype,",
            "+          flat_values_spec=x.flat_values_spec)",
            "return tf.TensorSpec(common_shape, x.dtype, x.name)",
            "",
            "spec = fn.concrete_functions[0].structured_input_signature"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 5037,
        "label": "no",
        "change": [
            "def apply_mask(y_p, sw, mask):",
            "if mask is not None:",
            "mask = tf.cast(mask, y_p.dtype)",
            "if sw is not None:",
            "+            sw = tf.cast(sw, mask.dtype)",
            "mask, _, sw = squeeze_or_expand_dimensions(mask, sample_weight=sw)",
            "sw *= mask",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5039,
        "label": "no",
        "change": [
            "with tf.Graph().as_default() as graph:",
            "# vgg1.restore_params(sess)",
            "",
            "if len(vgg1.all_layers) != 21:",
            "-        raise Exception(\"layers dont match\")",
            "+        raise Exception(\"layers do not match\")",
            "",
            "if len(vgg1.all_params) != 30:",
            "-        raise Exception(\"params dont match\")",
            "+        raise Exception(\"params do not match\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5042,
        "label": "no",
        "change": [
            "from ray.tests.conftest import *  # noqa",
            "",
            "",
            "def test_huggingface(ray_start_regular_shared):",
            "-    data = datasets.load_dataset(\"emotion\")",
            "+    data = datasets.load_dataset(\"tweet_eval\", \"emotion\")",
            "",
            "assert isinstance(data, datasets.DatasetDict)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5043,
        "label": "no",
        "change": [
            "def main():",
            "np.random.seed(args.seed)",
            "",
            "if args.backend == \"pytorch\":",
            "-        from tts.pytorch.tts_pytorch import train",
            "+        fromespnet.lmpytorch.tts_pytorch import train",
            "train(args)",
            "else:",
            "raise NotImplementedError(\"Only pytorch is supported.\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5045,
        "label": "no",
        "change": [
            "class SyncMultiGPUReplicatedBuilder(DataParallelBuilder):",
            "Copy values of variables on GPU 0 to other GPUs.",
            "\"\"\"",
            "# literally all variables, because it's better to sync optimizer-internal variables as well",
            "-        all_vars = tf.global_variables() + tf.local_variables()",
            "+        all_vars = tfv1.global_variables() + tfv1.local_variables()",
            "var_by_name = {v.name: v for v in all_vars}",
            "-        trainable_names = {x.name for x in tf.trainable_variables()}",
            "+        trainable_names = {x.name for x in tfv1.trainable_variables()}",
            "post_init_ops = []",
            "",
            "def log_failure(name, reason):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5048,
        "label": "no",
        "change": [
            "import torch",
            "",
            "",
            "def cast_tensor_type(inputs, src_type, dst_type):",
            "+    \"\"\"Recursively convert Tensor in inputs from src_type to dst_type.",
            "+",
            "+    Args:",
            "+        inputs: Inputs that to be casted.",
            "+        src_type (torch.dtype): Source type..",
            "+        dst_type (torch.dtype): Destination type.",
            "+",
            "+    Returns:",
            "+        The same type with inputs, but all contained Tensors have been cast.",
            "+    \"\"\"",
            "if isinstance(inputs, torch.Tensor):",
            "return inputs.to(dst_type)",
            "elif isinstance(inputs, str):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5052,
        "label": "yes",
        "change": [
            "def _torch_solve_cast(input: torch.Tensor, A: torch.Tensor) -> Tuple[torch.Tenso",
            "if dtype not in (torch.float32, torch.float64):",
            "dtype = torch.float32",
            "",
            "-    out = solve(A.to(dtype), input.to(dtype))",
            "+    out = torch.linalg.solve(A.to(dtype), input.to(dtype))",
            "",
            "return (out.to(input.dtype), out)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 5056,
        "label": "yes",
        "change": [
            "def test_calculate_plot_attention():",
            "",
            "train_args = make_train_args(report_cer=True)",
            "",
            "-    model, x, ilens, y, data = prepare(train_args)",
            "+    model, x, ilens, y, data, uttid_list = prepare(train_args)",
            "",
            "attn_dict = model.calculate_all_attentions(x[0:1], ilens[0:1], y[0:1])",
            "-    plot.plot_multi_head_attention(data, attn_dict, \"/tmp/espnet-test\")",
            "+    plot.plot_multi_head_attention(data, uttid_list, attn_dict, \"/tmp/espnet-test\")",
            "",
            "",
            "def test_invalid_input_layer_type():"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "addition",
        "Element": "api parameter"
    },
    {
        "number": 5062,
        "label": "no",
        "change": [
            "def test_torch_permute(",
            "),",
            "native_array=st.booleans(),",
            ")",
            "-@handle_cmd_line_args",
            "def test_torch_swapdims(",
            "dtype_and_values,",
            "dim0,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5064,
        "label": "no",
        "change": [
            "class TensorflowBaseInferenceLearner(BaseInferenceLearner, ABC):",
            "return \".npy\"",
            "",
            "def free_gpu_memory(self):",
            "-        tf.keras.clear_session()",
            "+        tf.keras.backend.clear_session()",
            "self._is_gpu_ready = False",
            "",
            "def set_model_on_gpu(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5070,
        "label": "no",
        "change": [
            "def run_timeline(sess, ops, debug_name, feed_dict={}, timeline_dir=None):",
            "if timeline_dir:",
            "from tensorflow.python.client import timeline",
            "",
            "-        run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)",
            "-        run_metadata = tf.RunMetadata()",
            "+        run_options = tf1.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)",
            "+        run_metadata = tf1.RunMetadata()",
            "start = time.time()",
            "fetches = sess.run(",
            "ops,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5072,
        "label": "yes",
        "change": [
            "def test_dynamic_quantization(train_dic, recog_dic, quantize_dic):",
            "train_args = get_default_train_args(**train_dic)",
            "recog_args = get_default_recog_args(**recog_dic)",
            "",
            "+    if not is_torch_1_5_plus:",
            "+        q_dtype = torch.qint8",
            "+    else:",
            "+        q_dtype = quantize_dic[\"mod\"]",
            "+",
            "model = E2E(idim, odim, train_args)",
            "model = torch.quantization.quantize_dynamic(",
            "-        model, quantize_dic[\"mod\"], dtype=quantize_dic[\"dtype\"]",
            "+        model, q_dtype, dtype=quantize_dic[\"dtype\"]",
            ")",
            "",
            "beam_search = BeamSearchTransducer("
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 5074,
        "label": "no",
        "change": [
            "class KannadaNews(datasets.GeneratorBasedBuilder):",
            "",
            "if not os.path.exists(path_to_manual_file):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('kannada_news', data_dir=...)` that includes a file name {}. Manual download instructions: {})\".format(",
            "-                    path_to_manual_file, _TRAIN_FILENAME, self.manual_download_instructions",
            "-                )",
            "+                f\"{path_to_manual_file} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('kannada_news', data_dir=...)` that includes a file name {_TRAIN_FILENAME}. Manual download instructions: {self.manual_download_instructions})\"",
            ")",
            "return [",
            "datasets.SplitGenerator("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5077,
        "label": "no",
        "change": [
            "def is_training_name(name):",
            "This is only used to improve logging.",
            ":returns: guess whether this tensor is something only used in training.",
            "\"\"\"",
            "-    # TODO: maybe simply check against TRAINABLE_VARIABLES and EXTRA_SAVE_VARS_KEY ?",
            "+    # TODO: maybe simply check against TRAINABLE_VARIABLES and MODEL_VARIABLES?",
            "# TODO or use get_slot_names()",
            "name = get_op_tensor_name(name)[0]",
            "if name.endswith('/Adam') or name.endswith('/Adam_1'):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5078,
        "label": "no",
        "change": [
            "def optimize_ner_model(args, num_labels,  logger=None):",
            "",
            "with tf.Session() as sess:",
            "sess.run(tf.global_variables_initializer())",
            "-                saver.restore(sess, tf.train.latest_checkpoint(args.ner_model_dir))",
            "+                saver.restore(sess, tf.train.latest_checkpoint(args.model_dir))",
            "logger.info('freeze...')",
            "from tensorflow.python.framework import graph_util",
            "tmp_g = graph_util.convert_variables_to_constants(sess, graph.as_graph_def(), ['pred_ids'])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5079,
        "label": "no",
        "change": [
            "class GDC(object):",
            "kwargs['eps'] = self.__calculate_eps__(edge_weight, num_nodes,",
            "kwargs['avg_degree'])",
            "",
            "-            remaining_edge_idx = torch.nonzero(",
            "-                edge_weight >= kwargs['eps']).flatten()",
            "+            remaining_edge_idx = (edge_weight >= kwargs['eps']).nonzero(",
            "+                as_tuple=False).flatten()",
            "edge_index = edge_index[:, remaining_edge_idx]",
            "edge_weight = edge_weight[remaining_edge_idx]",
            "elif method == 'topk':"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5080,
        "label": "yes",
        "change": [
            "class GNNExplainer(torch.nn.Module):",
            "if node_idx == -1:",
            "hard_edge_mask = torch.BoolTensor([True] * edge_index.size(1),",
            "device=edge_mask.device)",
            "-            subset = torch.arange(",
            "-                edge_index.max() + 1,",
            "-                device=edge_index.device if y is None else y.device)",
            "+            subset = torch.arange(edge_index.max().item() + 1,",
            "+                                  device=edge_index.device)",
            "+            y = None",
            "+",
            "else:",
            "# Only operate on a k-hop subgraph around `node_idx`.",
            "subset, edge_index, _, hard_edge_mask = k_hop_subgraph("
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 5082,
        "label": "no",
        "change": [
            "def test_srelu():",
            "",
            "",
            "if __name__ == '__main__':",
            "-    # pytest.main([__file__])",
            "-    test_srelu()",
            "+    pytest.main([__file__])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5084,
        "label": "no",
        "change": [
            "def huber_loss(x, delta=1, name='huber_loss'):",
            "\"\"\"",
            "sqrcost = tf.square(x)",
            "abscost = tf.abs(x)",
            "-    return tf.select(abscost < delta,",
            "-                     sqrcost * 0.5,",
            "-                     abscost * delta - 0.5 * delta ** 2,",
            "-                     name=name)",
            "+    return tf.where(abscost < delta,",
            "+                    sqrcost * 0.5,",
            "+                    abscost * delta - 0.5 * delta ** 2,",
            "+                    name=name)",
            "",
            "",
            "def get_scalar_var(name, init_value, summary=False, trainable=False):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5091,
        "label": "no",
        "change": [
            "class RandomInvert(IntensityAugmentationBase2D):",
            "self.flags = dict(max_val=max_val)",
            "",
            "def apply_transform(",
            "-        self, input: Tensor, params: Dict[str, Tensor], transform: Optional[Tensor] = None",
            "+        self, input: Tensor, params: Dict[str, Tensor], flags: Dict[str, Any], transform: Optional[Tensor] = None",
            ") -> Tensor:",
            "-        return invert(input, torch.as_tensor(self.flags[\"max_val\"], device=input.device, dtype=input.dtype))",
            "+        return invert(input, torch.as_tensor(flags[\"max_val\"], device=input.device, dtype=input.dtype))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5095,
        "label": "no",
        "change": [
            "clip.support_native_out = True",
            "clip.unsupported_dtypes = (\"float16\",)",
            "",
            "",
            "-def unstack(x: torch.Tensor, axis: int, keepdims: bool = False) -> List[torch.Tensor]:",
            "+def unstack(",
            "+    x: torch.Tensor, /, *, axis: int = 0, keepdims: bool = False",
            "+) -> List[torch.Tensor]:",
            "if x.shape == ():",
            "return [x]",
            "ret = list(torch.unbind(x, axis))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5101,
        "label": "no",
        "change": [
            "class LightningModel(pl.LightningModule):",
            "super().__init__()",
            "self.model = model",
            "self.num_labels = 2",
            "-        self.qa_outputs = torch.nn.Linear(self.model.config.hidden_size, self.num_labels)",
            "+        self.qa_outputs = nn.Linear(self.model.config.hidden_size, self.num_labels)",
            "",
            "# implement only because lightning requires to do so",
            "def forward(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5102,
        "label": "yes",
        "change": [
            "class FSMTHeadTests(unittest.TestCase):",
            "config, *_ = self._get_config_and_data()",
            "input_ids = _long_tensor(([4, 4, 2]))",
            "decoder_input_ids = _long_tensor([[26388, 2, config.pad_token_id]])",
            "-        ignore = float(\"-inf\")",
            "+        causal_mask_dtype = torch.float32",
            "+        ignore = torch.finfo(causal_mask_dtype).min",
            "decoder_input_ids, decoder_attn_mask, causal_mask = _prepare_fsmt_decoder_inputs(",
            "-            config, input_ids, decoder_input_ids",
            "+            config, input_ids, decoder_input_ids, causal_mask_dtype=causal_mask_dtype",
            ")",
            "expected_causal_mask = torch.tensor(",
            "[[0, ignore, ignore], [0, 0, ignore], [0, 0, 0]]  # never attend to the final token, because its pad"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 5106,
        "label": "yes",
        "change": [
            "def main():",
            "if args.do_train:",
            "torch.save(model_to_save.state_dict(), output_model_file)",
            "",
            "-    # Load a trained model that you have fine-tuned",
            "-    model_state_dict = torch.load(output_model_file)",
            "-    model = BertForQuestionAnswering.from_pretrained(args.bert_model, state_dict=model_state_dict)",
            "+        # Load a trained model that you have fine-tuned",
            "+        model_state_dict = torch.load(output_model_file)",
            "+        model = BertForQuestionAnswering.from_pretrained(args.bert_model, state_dict=model_state_dict)",
            "+    else:",
            "+        model = BertForQuestionAnswering.from_pretrained(args.bert_model)",
            "+",
            "model.to(device)",
            "",
            "if args.do_predict and (args.local_rank == -1 or torch.distributed.get_rank() == 0):"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "state handling error",
        "Action": "removal",
        "Element": "api call"
    },
    {
        "number": 5107,
        "label": "no",
        "change": [
            "class HyperLSTMCell(tf.contrib.rnn.RNNCell):",
            "x_size = x.get_shape().as_list()[-1]",
            "embedding_size = self.hyper_embedding_size",
            "num_units = self.num_units",
            "-      batch_size = x.get_shape().as_list()[0]",
            "+      batch_size = tf.shape(x)[0]",
            "",
            "W_xh = tf.get_variable('W_xh',",
            "[x_size, 4*num_units], initializer=w_init)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5108,
        "label": "no",
        "change": [
            "class BF16_Optimizer(ZeROOptimizer):",
            "hp_frag_address.numel)",
            "for key,",
            "value in self.optimizer.state[flat_hp_partition].items()",
            "-                if torch.is_tensor(value)",
            "+                if torch.is_tensor(value) and value.dim() > 0",
            "}",
            "",
            "lp_frag_address = fragment_address(start=fragment_start - lp_start,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5111,
        "label": "no",
        "change": [
            "class TensorflowONNXTensorRTInferenceLearner(",
            "else None",
            ")",
            "out_arrays = self._predict_array(cuda_input_arrays, input_shapes)",
            "-        return tuple(tf.convert_to_tensor(array[0]) for array in out_arrays)",
            "+        return tuple(tf.convert_to_tensor(array) for array in out_arrays)",
            "",
            "",
            "class NumpyONNXTensorRTInferenceLearner("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5112,
        "label": "no",
        "change": [
            "class TFGPT2ModelTester:",
            "output_from_past_slice = output_from_past[:, :, random_slice_idx]",
            "",
            "# test that outputs are equal for slice",
            "-        tf.debugging.assert_near(output_from_past_slice, output_from_no_past_slice, rtol=1e-6)",
            "+        tf.debugging.assert_near(output_from_past_slice, output_from_no_past_slice, rtol=1e-3)",
            "",
            "def create_and_check_gpt2_lm_head(self, config, input_ids, input_mask, head_mask, token_type_ids, *args):",
            "model = TFGPT2LMHeadModel(config=config)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5118,
        "label": "no",
        "change": [
            "class TRPOModel(PolicyGradientModel):",
            "gradients = [grad for grad in gradients if grad is not None]",
            "self.policy_gradient = tf.concat(values=[tf.reshape(grad, (-1,)) for grad in gradients], axis=0)  # util.prod(util.shape(v))",
            "",
            "-            fixed_distribution = distribution.__class__([tf.stop_gradient(x) for x in distribution])",
            "+            fixed_distribution = distribution.__class__.from_tensors(parameters=[tf.stop_gradient(x) for x in distribution])",
            "fixed_kl_divergence = fixed_distribution.kl_divergence(distribution)",
            "",
            "self.tangent = tf.placeholder(tf.float32, shape=(None,))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5124,
        "label": "yes",
        "change": [
            "class TFT5ModelIntegrationTests(unittest.TestCase):",
            "labels = tokenizer(\"Hi I am\", return_tensors=\"tf\").input_ids",
            "",
            "loss = model(input_ids, labels=labels).loss",
            "-        mtf_score = -tf.math.reduce_sum(loss).numpy()",
            "+        mtf_score = -tf.math.reduce_mean(loss).numpy()",
            "",
            "-        EXPECTED_SCORE = -60.7397",
            "+        EXPECTED_SCORE = -7.594554",
            "self.assertTrue(abs(mtf_score - EXPECTED_SCORE) < 1e-4)",
            "",
            "@slow"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 5127,
        "label": "no",
        "change": [
            "def log2(",
            "x: Union[tf.Tensor, tf.Variable], *, out: Union[tf.Tensor, tf.Variable] = None",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "if ivy.is_int_dtype(x):",
            "-        x=tf.cast(x,dtype=ivy.default_float_dtype())",
            "+        x = tf.cast(x, dtype=ivy.default_float_dtype())",
            "return tf.math.log(x) / tf.math.log(tf.constant(2.0, x.dtype))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5129,
        "label": "no",
        "change": [
            "class PolicyModel(Model):",
            "is_frequency = tf.math.equal(x=tf.mod(x=episode, y=frequency), y=zero)",
            "# Only update once per episode increment",
            "false = tf.constant(value=False, dtype=util.tf_dtype(dtype='bool'))",
            "-                terminal = tf.concat(values=(false, terminal), axis=0)",
            "+                terminal = tf.concat(values=((false,), terminal), axis=0)",
            "is_terminal = terminal[-1]",
            "is_frequency = tf.math.logical_and(x=is_frequency, y=is_terminal)",
            "at_least_start = tf.math.greater_equal(x=episode, y=start)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5130,
        "label": "no",
        "change": [
            "def main(_):",
            "predict, loss = conv_model(image, label, tf.estimator.ModeKeys.TRAIN)",
            "",
            "# Horovod: adjust learning rate based on number of GPUs.",
            "-    opt = tf.train.RMSPropOptimizer(0.001 * hvd.size())",
            "+    opt = tf.train.AdamOptimizer(0.001 * hvd.size())",
            "",
            "# Horovod: add Horovod Distributed Optimizer.",
            "opt = hvd.DistributedOptimizer(opt)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5132,
        "label": "no",
        "change": [
            "class Model(ImageNetModel):",
            ".apply(nonlin)",
            ".FullyConnected('fct', 1000, use_bias=True)())",
            "add_param_summary(('.*/W', ['histogram', 'rms']))",
            "+        tf.nn.softmax(logits, name='output')  # for prediction",
            "return logits",
            "",
            "def optimizer(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5133,
        "label": "no",
        "change": [
            "def bitwise_right_shift(",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "x1, x2 = ivy.promote_types_of_inputs(x1, x2)",
            "-    x1, x2 = _clamp_bits(x1, x2)",
            "+    ivy.assertions.check_all(x2 >= 0, message=\"shifts must be non-negative\")",
            "return tf.bitwise.right_shift(x1, x2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5135,
        "label": "no",
        "change": [
            "class _OMTMVNSample(Function):",
            "loc_grad = sum_leftmost(grad_output, -1)",
            "",
            "identity = eye_like(g, dim)",
            "-        R_inv = torch.trtrs(identity, L.t(), transpose=False, upper=True)[0]",
            "+        R_inv = torch.triangular_solve(identity, L.t(), transpose=False, upper=True)[0]",
            "",
            "z_ja = z.unsqueeze(-1)",
            "g_R_inv = torch.matmul(g, R_inv).unsqueeze(-2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5141,
        "label": "no",
        "change": [
            "def info_system():",
            "",
            "def info_cuda():",
            "return {",
            "-        'GPU': set([torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]),",
            "+        'GPU': [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())],",
            "# 'nvidia_driver': get_nvidia_driver_version(run_lambda),",
            "'available': torch.cuda.is_available(),",
            "'version': torch.version.cuda,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5145,
        "label": "no",
        "change": [
            "from .tokenization_utils import BatchEncoding",
            "logger = logging.getLogger(__name__)",
            "",
            "TF_XLNET_PRETRAINED_MODEL_ARCHIVE_MAP = {",
            "-    \"xlnet-base-cased\": \"https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-tf_model.h5\",",
            "-    \"xlnet-large-cased\": \"https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-large-cased-tf_model.h5\",",
            "+    \"xlnet-base-cased\": \"https://cdn.huggingface.co/xlnet-base-cased-tf_model.h5\",",
            "+    \"xlnet-large-cased\": \"https://cdn.huggingface.co/xlnet-large-cased-tf_model.h5\",",
            "}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5147,
        "label": "no",
        "change": [
            "class OrnsteinUhlenbeckNoise(GaussianNoise):",
            "true_fn=lambda: exploration_actions,",
            "false_fn=lambda: deterministic_actions)",
            "# Logp=always zero.",
            "-        logp = tf.zeros_like(deterministic_actions, dtype=tf.float32)[:, 0]",
            "+        logp = zero_logps_from_actions(deterministic_actions)",
            "",
            "# Increment `last_timestep` by 1 (or set to `timestep`).",
            "if self.framework in [\"tf2\", \"tfe\"]:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5149,
        "label": "no",
        "change": [
            "class BaseOp(object):",
            "self.lay.w[var] = tf.get_variable(var,",
            "shape = self.lay.wshape[var],",
            "dtype = tf.float32,",
            "-                initializer = tf.contrib.layers.xavier_initializer())",
            "+                initializer = self.lay.w[var])",
            "",
            "def wrap_pholder(self, ph, feed):",
            "\"\"\"wrap layer.h into placeholders\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5150,
        "label": "no",
        "change": [
            "class Recent(Queue):",
            "# Check whether memory contains at least one valid timestep",
            "num_timesteps = tf.math.minimum(x=self.buffer_index, y=capacity)",
            "num_timesteps -= (past_horizon + future_horizon)",
            "+        num_timesteps = tf.maximum(x=num_timesteps, y=self.episode_count)",
            "",
            "# Check whether memory contains at least one timestep",
            "assertions = list()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5159,
        "label": "no",
        "change": [
            "class AutoencoderKL(ModelMixin, ConfigMixin):",
            "x = sample",
            "posterior = self.encode(x).latent_dist",
            "if sample_posterior:",
            "-            z = posterior.sample()",
            "+            z = posterior.sample(generator=generator)",
            "else:",
            "z = posterior.mode()",
            "dec = self.decode(z).sample"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5160,
        "label": "no",
        "change": [
            "class TestLAFAffineShapeEstimator:",
            "assert_allclose(new_laf, expected, atol=1e-4, rtol=1e-4)",
            "",
            "def test_gradcheck(self):",
            "-        batch_size, channels, height, width = 1, 1, 100, 100",
            "+        batch_size, channels, height, width = 1, 1, 40, 40",
            "patches = torch.rand(batch_size, channels, height, width)",
            "patches = utils.tensor_to_gradcheck_var(patches)  # to var",
            "-        laf = torch.tensor([[[[20., 0., 56.], [0., 20., 56.]]]])",
            "+        laf = torch.tensor([[[[5., 0., 26.], [0., 5., 26.]]]])",
            "laf = utils.tensor_to_gradcheck_var(laf)  # to var",
            "assert gradcheck(LAFAffineShapeEstimator(11), (laf, patches),",
            "raise_exception=True, rtol=1e-3, atol=1e-3)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5162,
        "label": "no",
        "change": [
            "train_dataset = MNISTSuperpixels(path, True, transform=transform)",
            "test_dataset = MNISTSuperpixels(path, False, transform=transform)",
            "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)",
            "test_loader = DataLoader(test_dataset, batch_size=64)",
            "+d = train_dataset",
            "",
            "",
            "class Net(torch.nn.Module):",
            "def __init__(self):",
            "super(Net, self).__init__()",
            "-        self.conv1 = SplineConv(1, 32, dim=2, kernel_size=5)",
            "+        self.conv1 = SplineConv(d.num_features, 32, dim=2, kernel_size=5)",
            "self.conv2 = SplineConv(32, 64, dim=2, kernel_size=5)",
            "self.conv3 = SplineConv(64, 64, dim=2, kernel_size=5)",
            "self.fc1 = torch.nn.Linear(4 * 64, 128)",
            "-        self.fc2 = torch.nn.Linear(128, 10)",
            "+        self.fc2 = torch.nn.Linear(128, d.num_classes)",
            "",
            "def forward(self, data):",
            "data.x = F.elu(self.conv1(data.x, data.edge_index, data.edge_attr))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5164,
        "label": "no",
        "change": [
            "with tf.Graph().as_default() as G:",
            "logger.info(\"Variables to dump:\")",
            "logger.info(\", \".join(var_dict.keys()))",
            "saver = tf.train.Saver(",
            "-                    var_list=var_dict,",
            "-                    write_version=tf.train.SaverDef.V2)",
            "+                var_list=var_dict,",
            "+                write_version=tf.train.SaverDef.V2)",
            "saver.save(sess, args.output, write_meta_graph=False)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5167,
        "label": "no",
        "change": [
            "class ViTModelIntegrationTest(unittest.TestCase):",
            "inputs = feature_extractor(images=image, return_tensors=\"pt\").to(torch_device)",
            "",
            "# forward pass",
            "-        # currently failing",
            "-        # see https://discuss.pytorch.org/t/runtimeerror-expected-object-of-scalar-type-double-but-got-scalar-type-float-for-argument-2-weight/38961/2",
            "-        outputs = model(inputs[\"pixel_values\"])",
            "-        # outputs = model(**inputs)",
            "+        outputs = model(**inputs)",
            "",
            "# verify the logits",
            "expected_shape = torch.Size((1, 1000))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5171,
        "label": "no",
        "change": [
            "class OwlViTModelIntegrationTest(unittest.TestCase):",
            "",
            "num_queries = int((model.config.vision_config.image_size / model.config.vision_config.patch_size) ** 2)",
            "self.assertEqual(outputs.pred_boxes.shape, torch.Size((1, num_queries, 4)))",
            "+",
            "expected_slice_boxes = torch.tensor(",
            "-            [[0.0948, 0.0471, 0.1915], [0.3194, 0.0583, 0.6498], [0.1441, 0.0452, 0.2197]]",
            "+            [[0.0691, 0.0445, 0.1373], [0.1592, 0.0456, 0.3192], [0.1632, 0.0423, 0.2478]]",
            ").to(torch_device)",
            "self.assertTrue(torch.allclose(outputs.pred_boxes[0, :3, :3], expected_slice_boxes, atol=1e-4))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5173,
        "label": "no",
        "change": [
            "def _scale_channel(im):",
            "# and then normalization by step.",
            "lut = (torch.cumsum(histo, 0) + (step // 2)) // step",
            "# Shift lut, prepending with 0.",
            "-        lut = torch.cat([torch.zeros(1), lut[:-1]])",
            "+        lut = torch.cat([torch.zeros(1, device=lut.device), lut[:-1]])",
            "# Clip the counts to be in range.  This is done",
            "# in the C code for image.point.",
            "return torch.clamp(lut, 0, 255)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5174,
        "label": "no",
        "change": [
            "class MetadataCaptureHook(TrainingHook):",
            "return tf.train.SessionRunArgs(self._global_step)",
            "else:",
            "tf.logging.info(\"Performing full trace on next step.\")",
            "-      run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)",
            "+      run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE) #pylint: disable=E1101",
            "return tf.train.SessionRunArgs(self._global_step, options=run_options)",
            "",
            "def after_run(self, _run_context, run_values):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5176,
        "label": "no",
        "change": [
            "def convert_features_to_dataset(features):",
            "\"Converting now to a tensor of default type long.\")",
            "",
            "# Convert all remaining python objects to torch long tensors",
            "-        cur_tensor = torch.tensor([sample[t_name] for sample in features], dtype=torch.long)",
            "+        cur_tensor = torch.as_tensor(np.array([sample[t_name] for sample in features]), dtype=torch.long)",
            "",
            "all_tensors.append(cur_tensor)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5177,
        "label": "yes",
        "change": [
            "class CLIPModelTester:",
            "",
            "def create_and_check_model(self, config, input_ids, attention_mask, pixel_values):",
            "model = CLIPModel(config).to(torch_device).eval()",
            "-        result = model(input_ids, pixel_values, attention_mask)",
            "+        with torch.no_grad():",
            "+            result = model(input_ids, pixel_values, attention_mask)",
            "self.parent.assertEqual(",
            "result.logits_per_image.shape, (self.vision_model_tester.batch_size, self.text_model_tester.batch_size)",
            ")"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "state handling error",
        "Action": "addition",
        "Element": "api call"
    },
    {
        "number": 5178,
        "label": "yes",
        "change": [
            "def inverse_pose(pose):",
            "",
            "pose_inv = pose.clone()",
            "pose_inv[..., :3, 0:3] = torch.transpose(pose[..., :3, :3], 1, 2)",
            "-    pose_inv[..., :3, 2:3] = torch.matmul(",
            "-        -1.0 * pose_inv[..., :3, :3], pose[..., :3, 2:3])",
            "+    pose_inv[..., :3, 3:4] = torch.matmul(",
            "+        -1.0 * pose_inv[..., :3, :3], pose[..., :3, 3:4])",
            "",
            "if len(pose_shape) == 2:",
            "pose_inv = torch.squeeze(pose_inv, dim=0)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 5179,
        "label": "no",
        "change": [
            "class Parameterized(nn.Module):",
            "p = pyro.sample(param_name, prior)",
            "else:  # prior != None and mode = \"guide\"",
            "MAP_param_name = param_name + \"_MAP\"",
            "-            MAP_param_0 = torch.tensor(prior.analytic_mean().data.clone(), requires_grad=True)",
            "+            MAP_param_0 = torch.tensor(prior.mean.data.clone(), requires_grad=True)",
            "MAP_param = pyro.param(MAP_param_name, MAP_param_0)",
            "p = pyro.sample(param_name, dist.Delta(MAP_param))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5180,
        "label": "no",
        "change": [
            "def test_patch_merging():",
            "assert out_size == (2, 1)",
            "assert x_out.size(1) == out_size[0] * out_size[1]",
            "",
            "-        # test different kernel_size with diffrent stride",
            "+        # test different kernel_size with different stride",
            "input_size = (6, 5)",
            "kernel_size = (6, 2)",
            "stride = (6, 2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5183,
        "label": "no",
        "change": [
            "def softmax_blend_naive(colors, fragments, blend_params):",
            "pixel_colors[n, h, w, :3] += (delta / denom) * bk_color",
            "pixel_colors[n, h, w, 3] = 1.0 - alpha",
            "",
            "-    return torch.flip(pixel_colors, [1])",
            "+    return pixel_colors",
            "",
            "",
            "class TestBlending(unittest.TestCase):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5187,
        "label": "no",
        "change": [
            "class GeneralizedChannelPermute(ConditionedGeneralizedChannelPermute, TransformM",
            "W, _ = torch.linalg.qr(torch.randn(channels, channels))",
            "",
            "# Construct the partially pivoted LU-form and the pivots",
            "-        LU, pivots = W.lu()",
            "+        LU, pivots = torch.linalg.lu_factor(W)",
            "",
            "# Convert the pivots into the permutation matrix",
            "if permutation is None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5190,
        "label": "no",
        "change": [
            "class EncoderRNN(nn.Module):",
            "return output, hidden",
            "",
            "def initHidden(self):",
            "-        return torch.zeros(1, 1, self.hidden_size), device=device)",
            "+        return torch.zeros(1, 1, self.hidden_size, device=device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5191,
        "label": "yes",
        "change": [
            "class Input(Layer):",
            "logging.info(\"Input  %s: %s\" % (self.name, str(shape)))",
            "",
            "shape_without_none = [_ if _ is not None else 1 for _ in shape]",
            "-        self.outputs = self.forward(tf.initializers.constant(value=0.0)(shape_without_none), is_train=False)",
            "+        self.outputs = self.forward(tf.initializers.random_normal()(shape_without_none), is_train=False)",
            "",
            "def __call__(self, prev_layer):",
            "# FIXME: better exception raising"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 5192,
        "label": "no",
        "change": [
            "def read_image_file(path):",
            "row = []",
            "img.append(row)",
            "for c in range(num_cols):",
            "-                    row.append(data[idx])",
            "+                    row.append(parse_byte(data[idx]))",
            "idx += 1",
            "assert len(images) == length",
            "-        out = torch.FloatTensor(images)",
            "-        return out",
            "+        return torch.FloatTensor(images)",
            "",
            "print(\"Loading training set\")",
            "training_set = ("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5194,
        "label": "yes",
        "change": [
            "class CascadeRoIHead(BaseRoIHead, BBoxTestMixin, MaskTestMixin):",
            "ms_scores.append(bbox_results['cls_score'])",
            "",
            "if i < self.num_stages - 1:",
            "-                    bbox_label = bbox_results['cls_score'].argmax(dim=1)",
            "+                    bbox_label = bbox_results['cls_score'][:, :-1].argmax(",
            "+                        dim=1)",
            "rois = self.bbox_head[i].regress_by_class(",
            "rois, bbox_label, bbox_results['bbox_pred'],",
            "img_meta[0])"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 5198,
        "label": "yes",
        "change": [
            "def test_model_saving_loading():",
            "# make prediction",
            "# assert that both predictions are the same",
            "new_pred = model_2(x)",
            "-    assert torch.eq(pred_before_saving, new_pred)",
            "+    assert torch.all(torch.eq(pred_before_saving, new_pred)).item() == 1",
            "",
            "clear_save_dir()"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 5201,
        "label": "no",
        "change": [
            "def override_to_local_variable(enable=True):",
            "ns = orig_vs.original_name_scope",
            "with tf.variable_scope(",
            "orig_vs, custom_getter=custom_getter):",
            "-                with tf.name_scope(ns + '/'):",
            "+                with tf.name_scope(ns + '/' if ns else ''):",
            "yield",
            "else:",
            "yield"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5202,
        "label": "no",
        "change": [
            "class Gaussian(Distribution):",
            "self.shape = shape",
            "action_size = util.prod(self.shape)",
            "",
            "-        with tf.name_scope(name=scope):",
            "-            self.mean = Linear(size=action_size, bias=mean, scope='mean')",
            "-            self.log_stddev = Linear(size=action_size, bias=log_stddev, scope='log-stddev')",
            "+        self.mean = Linear(size=action_size, bias=mean, scope='mean')",
            "+        self.log_stddev = Linear(size=action_size, bias=log_stddev, scope='log-stddev')",
            "",
            "super(Gaussian, self).__init__(scope, summary_labels)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5204,
        "label": "no",
        "change": [
            "def prelu(x, channel_shared=False, weights_init='zeros', restore=True, name=\"PRe",
            "i_scope = \"\"",
            "if hasattr(x, 'scope'):",
            "if x.scope: i_scope = x.scope",
            "-    with tf.name_scope(i_scope + name) as scope:",
            "+    with tf.variable_scope(i_scope + name) as scope:",
            "W_init = initializations.get(weights_init)()",
            "alphas = va.variable(shape=w_shape, initializer=W_init,",
            "-                             restore=restore, name=scope + \"alphas\")",
            "+                             restore=restore, name=\"alphas\")",
            "",
            "x = tf.nn.relu(x) + tf.mul(alphas, (x - tf.abs(x))) * 0.5"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5205,
        "label": "no",
        "change": [
            "class PathResolver(Resolver):",
            "def is_supported(self, handle):",
            "try:",
            "return tf_v1.gfile.Exists(handle)",
            "-    except tf.OpError:",
            "+    except tf.errors.OpError:",
            "return False",
            "",
            "def __call__(self, handle):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5208,
        "label": "no",
        "change": [
            "class Trainer:",
            "# main model optimizer step",
            "loss_dict[\"loss\"].backward()",
            "if grad_clip > 0:",
            "-                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip, error_if_nonfinite=False)",
            "+                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)",
            "optimizer.step()",
            "",
            "step_time = time.time() - step_start_time"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5211,
        "label": "no",
        "change": [
            "class SingleStageDetector(BaseDetector):",
            "outs = self.bbox_head(x)",
            "# get origin input shape to support onnx dynamic shape",
            "if torch.onnx.is_in_onnx_export():",
            "-            img_metas[0]['img_shape_for_onnx'] = img.shape[2:]",
            "+            # get shape as tensor",
            "+            img_shape = torch._shape_as_tensor(img)[2:]",
            "+            img_metas[0]['img_shape_for_onnx'] = img_shape",
            "bbox_list = self.bbox_head.get_bboxes(",
            "*outs, img_metas, rescale=rescale)",
            "# skip post-processing when exporting to ONNX"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5214,
        "label": "no",
        "change": [
            "class Layer_Normalization_Test(unittest.TestCase):",
            "tf.reset_default_graph()",
            "",
            "def test_all_layers(self):",
            "-        self.assertEqual(len(self.data[\"train_network\"][\"layers\"]), 7)",
            "-        self.assertEqual(len(self.data[\"eval_network\"][\"layers\"]), 7)",
            "+        self.assertEqual(len(self.data[\"train_network\"][\"layers\"]), 8)",
            "+        self.assertEqual(len(self.data[\"eval_network\"][\"layers\"]), 8)",
            "",
            "def test_all_params(self):",
            "-        self.assertEqual(len(self.data[\"train_network\"][\"params\"]), 12)",
            "+        self.assertEqual(len(self.data[\"train_network\"][\"params\"]), 16)",
            "",
            "def test_n_params(self):",
            "-        self.assertEqual(self.data[\"train_network\"][\"n_params\"], 60560)",
            "+        self.assertEqual(self.data[\"train_network\"][\"n_params\"], 60726)",
            "",
            "",
            "if __name__ == '__main__':"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5217,
        "label": "no",
        "change": [
            "def test_decoder_cache():",
            "attention_dim=adim,",
            "linear_units=3,",
            "num_blocks=2,",
            "+        normalize_before=normalize_before,",
            "dropout_rate=0.0)",
            "dlayer = decoder.decoders[0]",
            "memory = torch.randn(2, 5, adim)",
            "",
            "-    x = torch.randn(2, 5, adim)",
            "+    x = torch.randn(2, 5, adim) * 100",
            "mask = subsequent_mask(x.shape[1]).unsqueeze(0)",
            "prev_mask = mask[:, :-1, :-1]",
            "decoder.eval()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5218,
        "label": "no",
        "change": [
            "class MLPValueFunction(ValueFunction):",
            "with tf.variable_scope(\"mlp_value_function\"):",
            "self.input = tf.placeholder(tf.float32, shape=[None, self.get_features_size(state_size)], name=\"input\")",
            "",
            "-            define_network = NeuralNetwork.layered_network((",
            "+            network_builder = NeuralNetwork.layered_network((",
            "{'type': 'dense', 'num_outputs': layer_size},",
            "{'type': 'dense', 'num_outputs': 1}))",
            "-            network = NeuralNetwork(define_network=define_network, inputs=[self.input])",
            "+            network = NeuralNetwork(network_builder=network_builder, inputs=[self.input])",
            "",
            "# hidden_1 = dense(layer_input=self.input, {'num_outputs': input_shape}, scope='hidden_1')",
            "# hidden_2 = dense(hidden_1, {'num_outputs': self.layer_size}, scope='hidden_2')",
            "# out = dense(hidden_2, {'num_outputs': 1}, scope='out')",
            "-            self.mlp = tf.reshape(network.output, (-1,))",
            "+            self.mlp = tf.reshape(network.output, (-1, 1))",
            "",
            "l2 = tf.nn.l2_loss(self.mlp - self.labels)",
            "self.update = tf.train.AdamOptimizer().minimize(l2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5219,
        "label": "yes",
        "change": [
            "class TorchCustomLossModel(TorchModelV2, nn.Module):",
            "",
            "# Compute the IL loss.",
            "action_dist = TorchCategorical(logits, self.model_config)",
            "-        imitation_loss = torch.mean(",
            "-            -action_dist.logp(torch.from_numpy(batch[\"actions\"])))",
            "+        imitation_loss = torch.mean(-action_dist.logp(",
            "+            torch.from_numpy(batch[\"actions\"]).to(policy_loss[0].device)))",
            "self.imitation_loss_metric = imitation_loss.item()",
            "self.policy_loss_metric = np.mean([l.item() for l in policy_loss])"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 5220,
        "label": "no",
        "change": [
            "PT_SPEECH_SEQ_CLASS_SAMPLE = r\"\"\"",
            "",
            ">>> # audio file is decoded on the fly",
            ">>> inputs = feature_extractor(dataset[0][\"audio\"][\"array\"], return_tensors=\"pt\")",
            "-    >>> logits = model(**inputs).logits >>> predicted_class_ids = torch.argmax(logits, dim=-1)",
            "+    >>> logits = model(**inputs).logits",
            "+    >>> predicted_class_ids = torch.argmax(logits, dim=-1)",
            ">>> predicted_label = model.config.id2label[predicted_class_ids]",
            "",
            ">>> # compute loss - target_label is e.g. \"down\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5221,
        "label": "no",
        "change": [
            "class Covariance(Metric):",
            "",
            "#     # Note: this gives an approximate aggregation of the covariance.",
            "#     device = gold_labels.device",
            "-        #     delta_mean_prediction = torch.tensor(delta_mean_prediction).to(device)",
            "-        #     delta_mean_label = torch.tensor(delta_mean_label).to(device)",
            "-        #     delta_co_moment = torch.tensor(delta_co_moment).to(device)",
            "-        #     _total_count = torch.tensor(updated_count).to(device)",
            "+        #     delta_mean_prediction = torch.tensor(delta_mean_prediction, device=device)",
            "+        #     delta_mean_label = torch.tensor(delta_mean_label, device=device)",
            "+        #     delta_co_moment = torch.tensor(delta_co_moment, device=device)",
            "+        #     _total_count = torch.tensor(updated_count, device=device)",
            "#     dist.all_reduce(delta_mean_prediction, op=dist.ReduceOp.SUM)",
            "#     dist.all_reduce(delta_mean_label, op=dist.ReduceOp.SUM)",
            "#     dist.all_reduce(delta_co_moment, op=dist.ReduceOp.SUM)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5223,
        "label": "no",
        "change": [
            "def test_pytorch_np():",
            "",
            "# CUDA variable",
            "if torch.cuda.device_count()>0:",
            "-            assert isinstance(x2num.makenp(torch.autograd.variable.Variable(tensor)).cuda(), np.ndarray)",
            "+            assert isinstance(x2num.makenp(torch.autograd.variable.Variable(tensor).cuda()), np.ndarray)",
            "",
            "# python primitive type",
            "assert(isinstance(x2num.makenp(0), np.ndarray))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5225,
        "label": "no",
        "change": [
            "class LookAheadWordLM(nn.Module):",
            "elif xi == self.space:",
            "y[:, self.space] = self.zero",
            "y[:, self.eos] = self.zero",
            "-            return (wlm_state, cumsum_probs, new_node), torch.log(log_y)",
            "+            return (wlm_state, cumsum_probs, new_node), torch.log(y)",
            "else:  # if no path in the tree, transition probability is one",
            "log_y = torch.zeros(1, self.subword_dict_size)",
            "return (wlm_state, cumsum_probs, new_node), log_y"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5226,
        "label": "no",
        "change": [
            "def quantile(",
            "temp = a.detach()",
            "dimension = len(a.size())",
            "for x in axis:",
            "-            axis1 = x",
            "-            for axis2 in range(x+1,dimension):",
            "+            axis1 = x",
            "+            for axis2 in range(x + 1, dimension):",
            "temp = torch.transpose(temp, axis1, axis2)",
            "axis1 = axis2",
            "-        temp = torch.flatten(temp, start_dim=dimension-len(axis))",
            "+        temp = torch.flatten(temp, start_dim=dimension - len(axis))",
            "return torch.quantile(",
            "temp, q, dim=-1, keepdim=keepdims, interpolation=interpolation, out=out",
            ")",
            "-    return torch.quantile(a, q, dim=axis, keepdim=keepdims, interpolation=interpolation, out=out)",
            "+    return torch.quantile(",
            "+        a, q, dim=axis, keepdim=keepdims, interpolation=interpolation, out=out",
            "+    )",
            "",
            "",
            "quantile.support_native_out = True"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5227,
        "label": "no",
        "change": [
            "class Xtreme(datasets.GeneratorBasedBuilder):",
            "for line in f:",
            "if line.startswith(\"-DOCSTART-\") or line == \"\" or line == \"\\n\":",
            "if words:",
            "-                            yield guid_index, {\"words\": words, \"ner_tags\": ner_tags, \"langs\": langs}",
            "+                            yield guid_index, {\"words\": words, \"ner\": ner_tags, \"langs\": langs}",
            "guid_index += 1",
            "words = []",
            "ner_tags = []"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5230,
        "label": "no",
        "change": [
            "class TurkishMovieSentiment(datasets.GeneratorBasedBuilder):",
            "path_to_manual_file = os.path.abspath(os.path.expanduser(dl_manager.manual_dir))",
            "if not os.path.exists(path_to_manual_file):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('turkishmoviesentiment', data_dir=...)` that includes a file name {}. Manual download instructions: {})\".format(",
            "-                    path_to_manual_file, _FILENAME, self.manual_download_instructions",
            "-                )",
            "+                f\"{path_to_manual_file} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('turkishmoviesentiment', data_dir=...)` that includes a file name {_FILENAME}. Manual download instructions: {self.manual_download_instructions})\"",
            ")",
            "return [",
            "datasets.SplitGenerator("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5232,
        "label": "no",
        "change": [
            "class DDPSpawnPlugin(ParallelPlugin):",
            "self.model.to(self.root_device)",
            "",
            "def pre_backward(self, closure_loss: torch.Tensor) -> None:",
            "-        \"\"\"Run before precision plugin executes backward\"\"\"",
            "+        \"\"\"Run before precision plugin executes backward.\"\"\"",
            "if not self.lightning_module.automatic_optimization:",
            "prepare_for_backward(self.model, closure_loss)",
            "",
            "def reduce(self, tensor, group: Optional[Any] = None, reduce_op: Union[ReduceOp, str] = \"mean\") -> torch.Tensor:",
            "-        \"\"\"",
            "-        Reduces a tensor from several distributed processes to one aggregated tensor.",
            "+        \"\"\"Reduces a tensor from several distributed processes to one aggregated tensor.",
            "",
            "Args:",
            "tensor: the tensor to sync and reduce"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5234,
        "label": "no",
        "change": [
            "class SHREC2016(InMemoryDataset):",
            "'{}_{}_shape_{}'.format(self.part, self.cat, i))",
            "data = read_off('{}.off'.format(path))",
            "y = read_txt_array('{}.baryc_gt'.format(path))",
            "-            data.y_idx = y[:, 0].to(torch.long)",
            "+            data.y = y[:, 0].to(torch.long) - 1",
            "data.y_baryc = y[:, 1:]",
            "train_list.append(data)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5235,
        "label": "no",
        "change": [
            "def Deconv2D(x, out_shape, kernel_shape,",
            "if use_bias:",
            "b = tf.get_variable('b', [out_channel], initializer=b_init)",
            "",
            "-    out_shape_dyn = tf.pack([tf.shape(x)[0]] + shp3_dyn)",
            "+    out_shape_dyn = tf.stack([tf.shape(x)[0]] + shp3_dyn)",
            "conv = tf.nn.conv2d_transpose(x, W, out_shape_dyn, stride4d, padding=padding)",
            "conv.set_shape(tf.TensorShape([None] + shp3_static))",
            "return nl(tf.nn.bias_add(conv, b) if use_bias else conv, name='output')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5237,
        "label": "no",
        "change": [
            "class BigBirdForMultipleChoice(BigBirdPreTrainedModel):",
            "return_dict=return_dict,",
            ")",
            "",
            "-        sequence_output = outputs[0]",
            "+        pooled_output = outputs[1]",
            "",
            "-        pooled_output = self.sequence_summary(sequence_output)",
            "+        pooled_output = self.dropout(pooled_output)",
            "logits = self.classifier(pooled_output)",
            "reshaped_logits = logits.view(-1, num_choices)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5242,
        "label": "yes",
        "change": [
            "class TFXLNetMainLayer(tf.keras.layers.Layer):",
            "assert input_mask is None or attention_mask is None, \"You can only use one of input_mask (uses 1 for padding) \" \\",
            "\"or attention_mask (uses 0 for padding, added for compatbility with BERT). Please choose one.\"",
            "if input_mask is None and attention_mask is not None:",
            "-            input_mask = 1.0 - attention_mask",
            "+            input_mask = 1.0 - tf.cast(attention_mask, dtype=dtype_float)",
            "if input_mask is not None and perm_mask is not None:",
            "data_mask = input_mask[None] + perm_mask",
            "elif input_mask is not None and perm_mask is None:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 5243,
        "label": "no",
        "change": [
            "def roc(",
            "",
            ">>> x = torch.tensor([0, 1, 2, 3])",
            ">>> y = torch.tensor([0, 1, 2, 2])",
            "-        >>> fpr, tpr, thresholds = roc(x,y)",
            "+        >>> fpr, tpr, thresholds = roc(x, y)",
            ">>> fpr",
            "tensor([0.0000, 0.3333, 0.6667, 0.6667, 1.0000])",
            ">>> tpr"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5244,
        "label": "no",
        "change": [
            "def make_autogradtensor(**kwargs):",
            "\"simplified\": (",
            "CODE[syft.frameworks.torch.tensors.interpreters.autograd.AutogradTensor],",
            "(",
            "-                    None,  # owner",
            "agt.id,  # (int)",
            "msgpack.serde._simplify(",
            "syft.hook.local_worker, agt.child"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5245,
        "label": "no",
        "change": [
            "def rgb_to_hsv(image: torch.Tensor) -> torch.Tensor:",
            "",
            "# avoid division by zero",
            "deltac = torch.where(",
            "-        deltac == 0, torch.ones_like(deltac), deltac)",
            "+        deltac == 0, torch.ones_like(deltac, device=deltac.device, dtype=deltac.dtype), deltac)",
            "",
            "maxc_tmp = maxc.unsqueeze(-3) - image",
            "rc: torch.Tensor = maxc_tmp[..., 0, :, :]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5246,
        "label": "no",
        "change": [
            "class NormalizedAdvantageFunctions(ValueFunction):",
            ":param batch:=",
            ":return:",
            "\"\"\"",
            "-        float_terminals = tf.to_float(batch['terminals'])",
            "+        float_terminals = batch['terminals'].astype(float)",
            "+",
            "q_targets = batch['rewards'] + (1. - float_terminals) \\",
            "* self.gamma * self.get_target_value_estimate(batch['next_states'])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5247,
        "label": "yes",
        "change": [
            "from tqdm import tqdm",
            "",
            "",
            "def download_wmt_dataset(src_lang=\"ro\", tgt_lang=\"en\", dataset=\"wmt16\", save_dir=None) -> None:",
            "-    \"\"\"Download a dataset using the nlp package and save it to the format expected by finetune.py",
            "+    \"\"\"Download a dataset using the datasets package and save it to the format expected by finetune.py",
            "Format of save_dir: train.source, train.target, val.source, val.target, test.source, test.target.",
            "",
            "Args:",
            "src_lang: <str> source language",
            "tgt_lang: <str> target language",
            "-        dataset: <str> wmt16, wmt17, etc. wmt16 is a good start as it's small. To get the full list run `import nlp; print([d.id for d in nlp.list_datasets() if \"wmt\" in d.id])`",
            "+        dataset: <str> wmt16, wmt17, etc. wmt16 is a good start as it's small. To get the full list run `import datasets; print([d.id for d in datasets.list_datasets() if \"wmt\" in d.id])`",
            "save_dir: <str>, where to save the datasets, defaults to f'{dataset}-{src_lang}-{tgt_lang}'",
            "",
            "Usage:",
            ">>> download_wmt_dataset('ro', 'en', dataset='wmt16') # saves to wmt16-ro-en",
            "\"\"\"",
            "try:",
            "-        import nlp",
            "+        import datasets",
            "except (ModuleNotFoundError, ImportError):",
            "-        raise ImportError(\"run pip install nlp\")",
            "+        raise ImportError(\"run pip install datasets\")",
            "pair = f\"{src_lang}-{tgt_lang}\"",
            "print(f\"Converting {dataset}-{pair}\")",
            "-    ds = nlp.load_dataset(dataset, pair)",
            "+    ds = datasets.load_dataset(dataset, pair)",
            "if save_dir is None:",
            "save_dir = f\"{dataset}-{pair}\"",
            "save_dir = Path(save_dir)"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 5249,
        "label": "no",
        "change": [
            "class PGModel(Model):",
            "size = 1",
            "for dims in self.state_shape:",
            "size *= dims",
            "-        self.baseline_value_function = MLPValueFunction(self.session, state_size=size, layer_size=100)  # LinearValueFunction()",
            "+        self.baseline_value_function = LinearValueFunction()",
            "# self.saver = tf.train.Saver()",
            "",
            "def get_action(self, state, episode=1):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5251,
        "label": "no",
        "change": [
            "def nonzero(x: torch.Tensor) -> Tuple[torch.Tensor]:",
            "return torch.nonzero(x, as_tuple=True)",
            "",
            "",
            "-def where(condition: torch.Tensor, x1: torch.Tensor, x2: torch.Tensor, *, out: Optional[torch.Tensor] = None) -> torch.Tensor:",
            "+def where(",
            "+    condition: torch.Tensor,",
            "+    x1: torch.Tensor,",
            "+    x2: torch.Tensor,",
            "+    *,",
            "+    out: Optional[torch.Tensor] = None",
            "+) -> torch.Tensor:",
            "promoted_type = torch.promote_types(x1.dtype, x2.dtype)",
            "x1 = x1.to(promoted_type)",
            "x2 = x2.to(promoted_type)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5254,
        "label": "no",
        "change": [
            "class MSEMetric(MeanSquaredError, LudwigMetric):",
            "super().__init__()",
            "",
            "def update(self, preds: Tensor, target: Tensor) -> None:",
            "-        super().update(preds.detach(), target)",
            "+        super().update(preds, target)",
            "",
            "@classmethod",
            "def get_objective(cls):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5255,
        "label": "no",
        "change": [
            "class QLoss:",
            "r_tau = tf.clip_by_value(r_tau, v_min, v_max)",
            "b = (r_tau - v_min) / ((v_max - v_min) / float(num_atoms - 1))",
            "lb = tf.floor(b)",
            "-            ub = tf.ceil(b)",
            "+            ub = tf.math.ceil(b)",
            "# indispensable judgement which is missed in most implementations",
            "# when b happens to be an integer, lb == ub, so pr_j(s', a*) will",
            "# be discarded because (ub-b) == (b-lb) == 0",
            "-            floor_equal_ceil = tf.to_float(tf.less(ub - lb, 0.5))",
            "+            floor_equal_ceil = tf.cast(tf.less(ub - lb, 0.5), tf.float32)",
            "",
            "l_project = tf.one_hot(",
            "tf.cast(lb, dtype=tf.int32),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5257,
        "label": "no",
        "change": [
            "def test_multilabel_accuracy():",
            "assert torch.allclose(accuracy(y2, torch.logical_not(y2), class_reduction='none'), torch.tensor([0., 0.]))",
            "assert torch.allclose(accuracy(y1, torch.logical_not(y1), class_reduction='none'), torch.tensor([0., 0.]))",
            "",
            "-    with pytest.raises(RuntimeError):",
            "-        accuracy(y2, torch.zeros_like(y2), class_reduction='none')",
            "+    # num_classes does not match extracted number from input we expect a warning",
            "+    with pytest.warns(RuntimeWarning,",
            "+                      match=r'You have set .* number of classes which is'",
            "+                            r' different from predicted (.*) and'",
            "+                            r' target (.*) number of classes'):",
            "+        _ = accuracy(y2, torch.zeros_like(y2), num_classes=3)",
            "",
            "",
            "def test_accuracy():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5263,
        "label": "no",
        "change": [
            "class EagerModel(TFModelV2):",
            "",
            "def lambda_(x):",
            "eager_out = tf.py_function(self.forward_eager, [x], tf.float32)",
            "-            with tf.control_dependencies([eager_out]):",
            "+            with tf1.control_dependencies([eager_out]):",
            "eager_out.set_shape(x.shape)",
            "return eager_out"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5264,
        "label": "no",
        "change": [
            "class TestTorchVariable(TestCase):",
            "\"\"\"Linear transformation of x by w\"\"\"",
            "return x.mm(w)",
            "",
            "-        x = Var(torch.FloatTensor([[1,1],[2,2]]), requires_grad=True)",
            "-        y = Var(torch.FloatTensor([[1,1],[2,2]]), requires_grad=True)",
            "+        x = Var(torch.FloatTensor([[1, 1], [2, 2]]), requires_grad=True)",
            "+        y = Var(torch.FloatTensor([[1, 1], [2, 2]]), requires_grad=True)",
            "",
            "z = linear(x, y)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5265,
        "label": "no",
        "change": [
            "def test_base_storage():",
            "assert len(storage) == 1",
            "assert storage.x is not None",
            "",
            "-    storage = BaseStorage(key='key', parent={}, x=torch.zeros(1))",
            "-",
            "+    storage = BaseStorage(x=torch.zeros(1))",
            "copied_storage = copy.copy(storage)",
            "assert storage == copied_storage",
            "assert id(storage) != id(copied_storage)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5270,
        "label": "no",
        "change": [
            "class IndexField(Field[torch.Tensor]):",
            "@overrides",
            "def as_tensor(self,",
            "padding_lengths: Dict[str, int],",
            "-                  cuda_device: int = -1,",
            "-                  for_training: bool = True) -> torch.Tensor:",
            "+                  cuda_device: int = -1) -> torch.Tensor:",
            "# pylint: disable=unused-argument",
            "-        tensor = Variable(torch.LongTensor([self.sequence_index]), volatile=not for_training)",
            "+        tensor = torch.LongTensor([self.sequence_index])",
            "return tensor if cuda_device == -1 else tensor.cuda(cuda_device)",
            "",
            "@overrides"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5271,
        "label": "no",
        "change": [
            "def recog(args):",
            "rnnlm_args = get_model_conf(args.word_rnnlm, args.word_rnnlm_conf)",
            "word_dict = rnnlm_args.char_list_dict",
            "char_dict = {x: i for i, x in enumerate(train_args.char_list)}",
            "-        word_rnnlm = lm_pytorch.ClassifierWithState(lm_pytorch.RNNLM(",
            "-            len(word_dict), rnnlm_args.layer, rnnlm_args.unit, rnnlm_args.embed_unit))",
            "+        word_rnnlm = lm_pytorch.ClassifierWithState(",
            "+            lm_pytorch.RNNLM(",
            "+                len(word_dict), rnnlm_args.layer, rnnlm_args.unit,",
            "+                getattr(rnnlm_args, \"embed_unit\", None),  # for backward compatibility",
            "+            )",
            "+        )",
            "torch_load(args.word_rnnlm, word_rnnlm)",
            "word_rnnlm.eval()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5274,
        "label": "no",
        "change": [
            "def run_tf_model(",
            "model: tf.Module, input_tensors: Tuple[tf.Tensor]",
            ") -> Tuple[tf.Tensor]:",
            "pred = model.predict(*input_tensors)",
            "-    if isinstance(pred, tf.Module):",
            "+    if isinstance(pred, tf.Module) and pred is not None:",
            "pred = (pred,)",
            "return pred"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5276,
        "label": "no",
        "change": [
            "def patch(save=True, tensorboardX=tensorboardX_loaded):",
            "writer.EventFileWriter.add_event = add_event(",
            "writer.EventFileWriter.add_event)",
            "wandb.patched[\"tensorboard\"].append(tensorboard_py_module)",
            "-        wandb.patched[\"tensorboard\"].append(\"tensorflow.summary\")",
            "",
            "# This configures TensorFlow 2 style Tensorboard logging",
            "c_writer = wandb.util.get_module(tensorboard_c_module)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5277,
        "label": "yes",
        "change": [
            "class FaceAlignment:",
            "out += flip(self.face_alignment_net(flip(inp)).detach(), is_label=True)",
            "out = out.cpu().numpy()",
            "",
            "-            pts, pts_img = get_preds_fromhm(out, center, scale)",
            "-            pts, pts_img = pts.view(68, 2) * 4, pts_img.view(68, 2)",
            "+            pts, pts_img = get_preds_fromhm(out, center.numpy(), scale)",
            "pts, pts_img = torch.from_numpy(pts), torch.from_numpy(pts_img)",
            "+            pts, pts_img = pts.view(68, 2) * 4, pts_img.view(68, 2)",
            "",
            "if self.landmarks_type == LandmarksType._3D:",
            "heatmaps = np.zeros((68, 256, 256), dtype=np.float32)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 5285,
        "label": "no",
        "change": [
            "class _AnchorTargetLayer(nn.Module):",
            "disable_inds = bg_inds[rand_num[:bg_inds.size(0)-num_bg]]",
            "labels[i][disable_inds] = -1",
            "",
            "-        offset = torch.arange(0, batch_size)*20",
            "+        offset = torch.arange(0, batch_size)*gt_boxes.size(1)",
            "+",
            "argmax_overlaps = argmax_overlaps + offset.view(batch_size, 1).type_as(argmax_overlaps)",
            "bbox_targets = _compute_targets_batch(anchors, gt_boxes.view(-1,5)[argmax_overlaps.view(-1), :].view(batch_size, -1, 5))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5287,
        "label": "no",
        "change": [
            "from allennlp.state_machines import util",
            "",
            "class TestStateMachinesUtil(AllenNlpTestCase):",
            "def test_create_allowed_transitions(self):",
            "-        targets = torch.Tensor([[[2, 3, 4], [1, 3, 4], [1, 2, 4]], [[3, 4, 0], [2, 3, 4], [0, 0, 0]]])",
            "-        target_mask = torch.Tensor([[[1, 1, 1], [1, 1, 1], [1, 1, 1]], [[1, 1, 0], [1, 1, 1], [0, 0, 0]]])",
            "+        targets = torch.Tensor(",
            "+            [[[2, 3, 4], [1, 3, 4], [1, 2, 4]], [[3, 4, 0], [2, 3, 4], [0, 0, 0]]]",
            "+        )",
            "+        target_mask = torch.Tensor(",
            "+            [[[1, 1, 1], [1, 1, 1], [1, 1, 1]], [[1, 1, 0], [1, 1, 1], [0, 0, 0]]]",
            "+        )",
            "prefix_tree = util.construct_prefix_tree(targets, target_mask)",
            "",
            "# There were two instances in this batch."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5289,
        "label": "no",
        "change": [
            "class DeFMO(nn.Module):",
            "# use torch.hub to load pretrained model",
            "if pretrained:",
            "storage_fcn: Callable = lambda storage, loc: storage",
            "-            pretrained_dict = torch.hub.load_state_dict_from_url(",
            "-                urls['defmo_encoder'], map_location=storage_fcn",
            "-            )",
            "+            pretrained_dict = torch.hub.load_state_dict_from_url(urls['defmo_encoder'], map_location=storage_fcn)",
            "self.encoder.load_state_dict(pretrained_dict, strict=True)",
            "-            pretrained_dict_ren = torch.hub.load_state_dict_from_url(",
            "-                urls['defmo_rendering'], map_location=storage_fcn",
            "-            )",
            "+            pretrained_dict_ren = torch.hub.load_state_dict_from_url(urls['defmo_rendering'], map_location=storage_fcn)",
            "self.rendering.load_state_dict(pretrained_dict_ren, strict=True)",
            "self.eval()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5295,
        "label": "no",
        "change": [
            "def build_eager_tf_policy(",
            "dist_inputs, dist_class, _ = action_distribution_fn(",
            "self,",
            "self.model,",
            "-                    input_dict[SampleBatch.CUR_OBS],",
            "+                    input_batch,",
            "explore=False,",
            "is_training=False)",
            "# Default log-likelihood calculation.",
            "else:",
            "-                dist_inputs, _ = self.model(input_dict, state_batches,",
            "+                dist_inputs, _ = self.model(input_batch, state_batches,",
            "seq_lens)",
            "dist_class = self.dist_class"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5296,
        "label": "no",
        "change": [
            "def create_image_lists(image_dir, testing_percentage, validation_percentage):",
            "extensions = sorted(set(os.path.normcase(ext)  # Smash case on Windows.",
            "for ext in ['JPEG', 'JPG', 'jpeg', 'jpg', 'png']))",
            "file_list = []",
            "-    dir_name = os.path.basename(sub_dir)",
            "+    dir_name = os.path.basename(",
            "+        # tf.gfile.Walk() returns sub-directory with trailing '/' when it is in",
            "+        # Google Cloud Storage, which confuses os.path.basename().",
            "+        sub_dir[:-1] if sub_dir.endswith('/') else sub_dir)",
            "+",
            "if dir_name == image_dir:",
            "continue",
            "tf.logging.info(\"Looking for images in '\" + dir_name + \"'\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5298,
        "label": "no",
        "change": [
            "class GaussianNoise(Exploration):",
            "",
            "super(GaussianNoise, self).__init__(scope=scope, summary_labels=summary_labels)",
            "",
            "-    def tf_explore(self, episode, timestep, action_shape):",
            "-        return tf.random_normal(shape=action_shape[1:], mean=self.mu, stddev=self.sigma)",
            "+    def tf_explore(self, episode, timestep, action_spec):",
            "+        return tf.random_normal(shape=action_spec['shape'], mean=self.mu, stddev=self.sigma)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5299,
        "label": "no",
        "change": [
            "class TFViTMAEForPreTraining(TFViTMAEPreTrainedModel):",
            "loss = tf.reduce_mean(loss, axis=-1)  # [batch_size, num_patches], mean loss per patch",
            "",
            "loss = tf.reduce_sum(loss * mask) / tf.reduce_sum(mask)  # mean loss on removed patches",
            "+        loss = tf.reshape(loss, (1,))",
            "return loss",
            "",
            "@unpack_inputs"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5301,
        "label": "no",
        "change": [
            "class DataCollatorIntegrationTest(unittest.TestCase):",
            "total_samples = batch[\"input_ids\"].shape[0]",
            "self.assertEqual(batch[\"input_ids\"].shape, torch.Size((total_samples, 512)))",
            "self.assertEqual(batch[\"token_type_ids\"].shape, torch.Size((total_samples, 512)))",
            "-        self.assertEqual(batch[\"masked_lm_labels\"].shape, torch.Size((total_samples, 512)))",
            "+        self.assertEqual(batch[\"labels\"].shape, torch.Size((total_samples, 512)))",
            "self.assertEqual(batch[\"next_sentence_label\"].shape, torch.Size((total_samples,)))",
            "",
            "@slow"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5302,
        "label": "no",
        "change": [
            "class SingleRoIExtractor(nn.Module):",
            "target_lvls = self.map_roi_levels(rois, num_levels)",
            "roi_feats = feats[0].new_zeros(rois.size()[0], self.out_channels,",
            "out_size, out_size)",
            "+        if roi_scale_factor is not None:",
            "+            rois = self.roi_rescale(rois, roi_scale_factor)",
            "for i in range(num_levels):",
            "inds = target_lvls == i",
            "if inds.any():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5306,
        "label": "no",
        "change": [
            "class Model(training_lib.Model):",
            "if not isinstance(self.optimizer, optimizer_v2.OptimizerV2):",
            "raise ValueError(",
            "'\"optimizer\" must be an instance of '",
            "-                    \"tf.keras.optimizers.Optimizer when a dype policy \"",
            "-                    \"with a loss scale  used, but got: %s. Using policy: \"",
            "+                    \"tf.keras.optimizers.legacy.Optimizer when a dype policy \"",
            "+                    \"with a loss scale is used, but got: %s. Using policy: \"",
            "\"%s\" % (self.optimizer, self._dtype_policy)",
            ")",
            "self.optimizer = loss_scale_optimizer.LossScaleOptimizer("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5309,
        "label": "no",
        "change": [
            "class LuongAttnDecoderRNN(nn.Module):",
            "",
            "def maskNLLLoss(inp, target, mask):",
            "nTotal = mask.sum()",
            "-    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)))",
            "+    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))",
            "loss = crossEntropy.masked_select(mask).mean()",
            "loss = loss.to(device)",
            "return loss, nTotal.item()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5310,
        "label": "yes",
        "change": [
            "class CTCPrefixScorer(PartialScorerInterface):",
            "def score_partial(self, y, ids, state, x):",
            "prev_score, state = state",
            "presub_score, new_st = self.impl(y.cpu(), ids.cpu(), state)",
            "-        tscore = torch.as_tensor(presub_score - prev_score, device=y.device)",
            "+        tscore = torch.as_tensor(presub_score - prev_score, device=x.device, dtype=x.dtype)",
            "return tscore, (presub_score, new_st)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 5311,
        "label": "no",
        "change": [
            "class PointConv(MessagePassing):",
            "N, M = edge_index[0].max().item() + 1, edge_index[1].max().item() + 1",
            "return self.propagate(edge_index, size=(N, M), x=x, pos=pos)",
            "",
            "-    def message(self, x_i, pos_i, pos_j):",
            "-        msg = pos_i - pos_j",
            "-        if x_i is not None:",
            "-            msg = torch.cat([x_i, msg], dim=1)",
            "+    def message(self, x_j, pos_j, pos_i):",
            "+        msg = pos_j - pos_i",
            "+        if x_j is not None:",
            "+            msg = torch.cat([x_j, msg], dim=1)",
            "if self.local_nn is not None:",
            "msg = self.local_nn(msg)",
            "return msg"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5312,
        "label": "no",
        "change": [
            "def attempt_load(weights, map_location=None):",
            "model = Ensemble()",
            "for w in weights if isinstance(weights, list) else [weights]:",
            "attempt_download(w)",
            "-        model.append(torch.load(w, map_location=map_location)['model'].float().fuse().eval())  # load FP32 model",
            "+        ckpt = torch.load(w, map_location=map_location)  # load",
            "+        model.append(ckpt['ema' if ckpt.get('ema') else 'model'].float().fuse().eval())  # FP32 model",
            "",
            "# Compatibility updates",
            "for m in model.modules():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5313,
        "label": "no",
        "change": [
            "from ivy.core.container import Container",
            "",
            "",
            "def variable(x):",
            "-    with _tf.device('/' + ivy.dev(x).upper()):",
            "+    with _tf.device('/' + ivy.dev(x, as_str=True).upper()):",
            "return _tf.Variable(x, trainable=True)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5314,
        "label": "yes",
        "change": [
            "class Model(torch.nn.Module, Registrable):",
            "add_batch_dimension=True,",
            "cuda_device=cuda_device,",
            "for_training=False)",
            "-        outputs = self.forward(**model_input)",
            "+        outputs = self.decode(self.forward(**model_input))",
            "",
            "for name, output in list(outputs.items()):",
            "output = output[0]"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 5315,
        "label": "no",
        "change": [
            "class Reclor(datasets.GeneratorBasedBuilder):",
            "",
            "if not os.path.exists(data_dir):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('wikihow', data_dir=...)` that includes files unzipped from the reclor zip. Manual download instructions: {}\".format(",
            "-                    data_dir, self.manual_download_instructions",
            "-                )",
            "+                f\"{data_dir} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('wikihow', data_dir=...)` that includes files unzipped from the reclor zip. Manual download instructions: {self.manual_download_instructions}\"",
            ")",
            "return [",
            "datasets.SplitGenerator("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5316,
        "label": "no",
        "change": [
            "def build_GAN_losses(vecpos, vecneg):",
            "tf.histogram_summary('sigmoid-neg', sigmneg)",
            "",
            "d_loss_pos = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(",
            "-        vecpos, tf.ones_like(vecpos)), name='d_loss_pos')",
            "+        vecpos, tf.ones_like(vecpos)), name='d_CE_loss_pos')",
            "d_loss_neg = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(",
            "-        vecneg, tf.zeros_like(vecneg)), name='d_loss_neg')",
            "+        vecneg, tf.zeros_like(vecneg)), name='d_CE_loss_neg')",
            "",
            "d_pos_acc = tf.reduce_mean(tf.cast(sigmpos > 0.5, tf.float32), name='pos_acc')",
            "d_neg_acc = tf.reduce_mean(tf.cast(sigmneg < 0.5, tf.float32), name='neg_acc')",
            "",
            "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(",
            "-        vecneg, tf.ones_like(vecneg)), name='g_loss')",
            "-    d_loss = tf.add(d_loss_pos, d_loss_neg, name='d_loss')",
            "+        vecneg, tf.ones_like(vecneg)), name='g_CE_loss')",
            "+    d_loss = tf.add(d_loss_pos, d_loss_neg, name='d_CE_loss')",
            "add_moving_summary(d_loss_pos, d_loss_neg,",
            "g_loss, d_loss,",
            "d_pos_acc, d_neg_acc)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5320,
        "label": "no",
        "change": [
            "class DenseFeaturesTest(keras_parameterized.TestCase):",
            "with tf.Graph().as_default():",
            "# Dynamic rank 0 should fail",
            "features = {",
            "-          'price': tf.compat.v1.placeholder(tf.float32),",
            "+        'price': tf.compat.v1.placeholder(tf.float32),",
            "}",
            "net = df.DenseFeatures([price])(features)",
            "self.assertEqual(1, net.shape[1])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5321,
        "label": "no",
        "change": [
            "def real(",
            "",
            "",
            "def isposinf(",
            "-        x: Union[tf.Tensor, tf.Variable],",
            "-        /,",
            "-        *,",
            "-        out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            "+    x: Union[tf.Tensor, tf.Variable],",
            "+    /,",
            "+    *,",
            "+    out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "return tf.experimental.numpy.isposinf(x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5322,
        "label": "yes",
        "change": [
            "def inplace_update(",
            "elif ivy.is_ivy_array(x):",
            "x.data = val_native",
            "else:",
            "-            raise ivy.exceptions.IvyException(",
            "-                \"TensorFlow does not support inplace updates of the tf.Tensor\"",
            "-            )",
            "+            x = ivy.to_ivy(x_native)",
            "return x",
            "else:",
            "return val"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 5325,
        "label": "no",
        "change": [
            "def reshape(",
            "shape: Union[ivy.NativeShape, Sequence[int]],",
            "*,",
            "copy: Optional[bool] = None,",
            "-    out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            "order: Optional[str] = \"C\",",
            "+    out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "ivy.assertions.check_elem_in_list(order, [\"C\", \"F\"])",
            "if copy:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5327,
        "label": "no",
        "change": [
            "class Agent(object):",
            "self.common_policy = self.par_opt.get_common_loss()",
            "self.variables = ray.experimental.TensorFlowVariables(",
            "self.common_policy.loss, self.sess)",
            "-        self.observation_filter = MeanStdFilter(preprocessor.shape, clip=None)",
            "+        self.observation_filter = MeanStdFilter(",
            "+            self.preprocessor_shape, clip=None)",
            "self.reward_filter = MeanStdFilter((), clip=5.0)",
            "self.sess.run(tf.global_variables_initializer())"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5331,
        "label": "no",
        "change": [
            "img, label = read_and_decode(\"train.cifar10\")",
            "",
            "## Use shuffle_batch or batch",
            "# see https://www.tensorflow.org/versions/master/api_docs/python/io_ops.html#shuffle_batch",
            "-img_batch, label_batch = tf.train.shuffle_batch([img, label], batch_size=4, capacity=50000, min_after_dequeue=10000, num_threads=1)",
            "+img_batch, label_batch = tf.train.shuffle_batch(",
            "+    [img, label], batch_size=4, capacity=50000, min_after_dequeue=10000, num_threads=1",
            "+)",
            "",
            "print(\"img_batch   : %s\" % img_batch._shape)",
            "print(\"label_batch : %s\" % label_batch._shape)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5333,
        "label": "no",
        "change": [
            "class SummaryWriter(object):",
            "print('add_graph() only supports PyTorch v0.2.')",
            "return",
            "self.file_writer.add_graph(graph(model, input_to_model, verbose))",
            "-        except AttributeError:",
            "+        else:",
            "# Caffe2 models do not have the 'forward' method",
            "if not self.caffe2_enabled:",
            "# TODO (ml7): Remove when PyTorch 1.0 merges PyTorch and Caffe2"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5334,
        "label": "no",
        "change": [
            "class TFAlbertModel(TFAlbertPreTrainedModel):",
            "if input_ids is not None and inputs_embeds is not None:",
            "raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")",
            "elif input_ids is not None:",
            "-            input_shape = input_ids.shape",
            "+            input_shape = tf.shape(input_ids)",
            "elif inputs_embeds is not None:",
            "input_shape = inputs_embeds.shape[:-1]",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5337,
        "label": "yes",
        "change": [
            "class RelationExtractor(flair.nn.DefaultClassifier):",
            "",
            "relation_embeddings.append(embedding)",
            "",
            "-            # stack and drop out",
            "-            all_relations = torch.stack(relation_embeddings)",
            "+            # stack and drop out (squeeze and unsqueeze)",
            "+            all_relations = torch.stack(relation_embeddings).unsqueeze(1)",
            "",
            "all_relations = self.dropout(all_relations)",
            "all_relations = self.locked_dropout(all_relations)",
            "all_relations = self.word_dropout(all_relations)",
            "",
            "+            all_relations = all_relations.squeeze(1)",
            "+",
            "# send through decoder",
            "if self.non_linear_decoder:",
            "sentence_relation_scores = self.decoder_2(self.nonlinearity(self.decoder_1(all_relations)))"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 5340,
        "label": "yes",
        "change": [
            "class HullWhiteBermudanSwaptionTest(parameterized.TestCase, tf.test.TestCase):",
            "self.float_leg_end_times) - np.array(self.float_leg_start_times)",
            "self.fixed_leg_daycount_fractions = self.float_leg_daycount_fractions",
            "self.fixed_leg_coupon = 0.011 * np.ones_like(self.fixed_leg_payment_times)",
            "-    self.zero_rate_fn = lambda x: 0.01 * tf.ones_like(x)",
            "+    zero_rate_fn = lambda x: 0.01 * tf.expand_dims(tf.ones_like(x), axis=-1)",
            "+    self.zero_rate_fn = zero_rate_fn",
            "",
            "super(HullWhiteBermudanSwaptionTest, self).setUp()"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 5341,
        "label": "no",
        "change": [
            "class CenterModel(EmbeddingModel):",
            "",
            "# tag the embedding of 'input' with name 'emb', just for inference later on",
            "with tf.variable_scope(tf.get_variable_scope(), reuse=True):",
            "-            tf.identity(self.embed(inputs[0]), name=\"emb\")",
            "+            tf.identity(self.embed(x), name=\"emb\")",
            "",
            "# compute the embedding loss",
            "emb_cost = center_loss(x, label, 10, 0.01)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5344,
        "label": "no",
        "change": [
            "class HypernetworkModule(torch.nn.Module):",
            "if add_layer_norm:",
            "linears.append(torch.nn.LayerNorm(int(dim * layer_structure[i+1])))",
            "",
            "-            # Add dropout",
            "-            if use_dropout:",
            "-                p = 0.5 if 0 <= i <= len(layer_structure) - 3 else 0.2",
            "-                linears.append(torch.nn.Dropout(p=p))",
            "+            # Add dropout expect last layer",
            "+            if use_dropout and i < len(layer_structure) - 3:",
            "+                linears.append(torch.nn.Dropout(p=0.3))",
            "",
            "self.linear = torch.nn.Sequential(*linears)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5345,
        "label": "no",
        "change": [
            "class GravesAttention(nn.Module):",
            "",
            "def init_states(self, inputs):",
            "if self.J is None or inputs.shape[1]+1 > self.J.shape[-1]:",
            "-            self.J = torch.arange(0, inputs.shape[1]+2).to(inputs.device) + 0.5",
            "+            self.J = torch.arange(0, inputs.shape[1]+2.0).to(inputs.device) + 0.5",
            "self.attention_weights = torch.zeros(inputs.shape[0], inputs.shape[1]).to(inputs.device)",
            "self.mu_prev = torch.zeros(inputs.shape[0], self.K).to(inputs.device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5347,
        "label": "yes",
        "change": [
            "class TestSparseClipGrad(AllenNlpTestCase):",
            "# Now try to clip the gradients.",
            "_ = sparse_clip_norm([embedding.weight], 1.5)",
            "# Final norm should be 1.5",
            "-        grad = embedding.weight.grad.data.coalesce()",
            "-        self.assertAlmostEqual(grad._values().norm(2.0), 1.5, places=5) # pylint: disable=protected-access",
            "+        grad = embedding.weight.grad.coalesce()  # pylint: disable=no-member",
            "+        self.assertAlmostEqual(grad._values().norm(2.0).item(), 1.5, places=5) # pylint: disable=protected-access"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 5348,
        "label": "no",
        "change": [
            "class DQNTorchModel(TorchModelV2):",
            "sigma0 (float): initial value of noisy nets",
            "add_layer_norm (bool): Enable layer norm (for param noise).",
            "\"\"\"",
            "-",
            "+        nn.Module.__init__(self)",
            "super(DQNTorchModel, self).__init__(obs_space, action_space,",
            "num_outputs, model_config, name)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5349,
        "label": "no",
        "change": [
            "class TestHlsToRgb:",
            "[8., 8.]]])  # 3x2x2",
            "",
            "data = torch.tensor([[[0.0641, 0.07138],",
            "-                                  [0.07138, 0.07138]],",
            "+                                [0.07138, 0.07138]],",
            "",
            "-                                 [[0.0569, 0.0588],",
            "-                                  [0.0588, 0.0588]],",
            "+                                [[0.0569, 0.0588],",
            "+                                 [0.0588, 0.0588]],",
            "",
            "-                                 [[0.4483, 0.4667],",
            "-                                  [0.4667, 0.4667]]])  # 3x2x2",
            "+                                [[0.4483, 0.4667],",
            "+                                 [0.4667, 0.4667]]])  # 3x2x2",
            "",
            "f = kornia.color.HlsToRgb()",
            "data = data.repeat(2, 1, 1, 1)  # 2x3x2x2"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5352,
        "label": "no",
        "change": [
            "def diagonal(",
            "axis2: int = -1,",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "-    return tf.experimental.numpy.diagonal(x, offset, axis1=axis1, axis2=axis2)",
            "+    return tf.experimental.numpy.diagonal(x, offset=offset, axis1=axis1, axis2=axis2)",
            "",
            "",
            "@with_unsupported_dtypes({\"2.9.1 and below\": (\"float16\", \"bfloat16\")}, backend_version)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5353,
        "label": "no",
        "change": [
            "def _explained_variance_compute(preds: torch.Tensor,",
            "return torch.sum(denominator / denom_sum * output_scores)",
            "",
            "",
            "-def explained_variance(preds: torch.Tensor,",
            "-                       target: torch.Tensor,",
            "-                       multioutput: str = 'uniform_average',",
            "-                       ) -> Union[torch.Tensor, Sequence[torch.Tensor]]:",
            "+def explained_variance(",
            "+        preds: torch.Tensor,",
            "+        target: torch.Tensor,",
            "+        multioutput: str = 'uniform_average',",
            "+) -> Union[torch.Tensor, Sequence[torch.Tensor]]:",
            "\"\"\"",
            "Computes explained variance."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5355,
        "label": "no",
        "change": [
            "class ConcatModule(nn.Module):",
            "input_args = input_args[0]",
            "",
            "# don't concat things that are just single objects",
            "-        if torch.is_tensor(input_args) or isinstance(input_args, torch.autograd.Variable):",
            "+        if torch.is_tensor(input_args):",
            "return input_args",
            "else:",
            "return torch.cat(input_args, dim=-1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5357,
        "label": "no",
        "change": [
            "class SplineGCN(Module):",
            "self.kernel_size = kernel_size",
            "self.spline_degree = spline_degree",
            "",
            "-        self.weight = Parameter(",
            "-            torch.Tensor(*kernel_size, in_features, out_features))",
            "+        weight_size = kernel_size + (in_features, out_features)",
            "+        self.weight = Parameter(torch.Tensor(*weight_size))",
            "",
            "if bias:",
            "self.bias = Parameter(torch.Tensor(out_features))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5359,
        "label": "no",
        "change": [
            "class TorchPolicy(Policy):",
            "",
            "all_grads = []",
            "for i, opt in enumerate(self._optimizers):",
            "+            # Erase gradients in all vars of this optimizer.",
            "opt.zero_grad()",
            "# Recompute gradients of loss over all variables.",
            "loss_out[i].backward(retain_graph=(i < len(self._optimizers) - 1))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5363,
        "label": "no",
        "change": [
            "if __name__ == \"__main__\":",
            "# to bias and LayerNorm scale parameters. decay_mask_fn returns a",
            "# mask boolean with the same structure as the parameters.",
            "# The mask is True for parameters that should be decayed.",
            "+    # Note that this mask is specifically adapted for FlaxBERT-like models.",
            "+    # For other models, one should correct the layer norm parameter naming",
            "+    # accordingly.",
            "def decay_mask_fn(params):",
            "flat_params = traverse_util.flatten_dict(params)",
            "flat_mask = {path: (path[-1] != \"bias\" and path[-2:] != (\"LayerNorm\", \"scale\")) for path in flat_params}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5367,
        "label": "no",
        "change": [
            "class BertForClassification(Model):",
            "loss : torch.FloatTensor, optional",
            "A scalar loss to be optimised.",
            "\"\"\"",
            "-        input_ids = tokens[self._index]",
            "-        token_type_ids = tokens[f\"{self._index}-type-ids\"]",
            "+        inputs = tokens[self._index]",
            "+        input_ids = inputs[\"input_ids\"]",
            "+        token_type_ids = inputs[\"token_type_ids\"]",
            "input_mask = (input_ids != 0).long()",
            "",
            "_, pooled = self.bert_model("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5370,
        "label": "yes",
        "change": [
            "class CategoricalOneHotPolicy(StochasticPolicy):",
            "",
            "def __init__(self, network, session, state, random, action_count=1, scope='policy'):",
            "with tf.variable_scope(scope):",
            "-            action_layer = linear(layer_input=network.output, config={'num_outputs': action_count}, scope='outputs')",
            "-",
            "-            distribution = tf.nn.softmax(action_layer)",
            "-            sample = tf.map_fn(lambda t: tf.multinomial(logits=t, num_samples=1), elems=distribution, dtype=tf.int64)",
            "+            logits = linear(layer_input=network.output, config={'num_outputs': action_count}, scope='outputs')",
            "+            distribution = tf.nn.softmax(logits)",
            "+            sample = tf.map_fn(lambda t: tf.multinomial(logits=t, num_samples=1), elems=logits, dtype=tf.int64)",
            "",
            "super(CategoricalOneHotPolicy, self).__init__(network, [distribution, sample], session, state, random, action_count)",
            "self.dist = Categorical(random)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 5371,
        "label": "no",
        "change": [
            "def conv_quad_interp3d(",
            "raise ValueError(f\"Invalid input shape, we expect BxCxDxHxW. Got: {input.shape}\")",
            "",
            "B, CH, D, H, W = input.shape",
            "-    dev: torch.device = input.device",
            "grid_global: torch.Tensor = create_meshgrid3d(D, H, W, False, device=input.device).permute(0, 4, 1, 2, 3)",
            "grid_global = grid_global.to(input.dtype)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5377,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "b5 = branch('branch5', l, 16)",
            "",
            "final_map = Conv2D('convfcweight',",
            "-                           tf.concat(3, [b1, b2, b3, b4, b5]), 1, 1,",
            "+                           tf.concat_v2([b1, b2, b3, b4, b5], 3), 1, 1,",
            "W_init=tf.constant_initializer(0.2),",
            "use_bias=False, nl=tf.identity)",
            "costs = []"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5380,
        "label": "no",
        "change": [
            "class Decoder(torch.nn.Module):",
            "if torch_is_old:",
            "vy = Variable(h.data.new(1).zero_().long(), volatile=True)",
            "else:",
            "-            torch.set_grad_enabled(False)",
            "vy = h.new_zeros(1).long()",
            "",
            "if recog_args.maxlenratio == 0:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5384,
        "label": "no",
        "change": [
            "def start_train(config):",
            "raise",
            "finally:",
            "coord.request_stop()",
            "-            queue.close(cancel_pending_enqueues=True)",
            "+            input_queue.close(cancel_pending_enqueues=True)",
            "callbacks.after_train()",
            "sess.close()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5388,
        "label": "no",
        "change": [
            "def test_recognition_results_with_lm(etype, m_str, text_idx1):",
            "",
            "",
            "@pytest.mark.parametrize((\"etype\", \"m_str\"), [",
            "-    (\"blstmp\", \"espnet.nets.e2e_asr\"),",
            "-    (\"blstmp\", \"espnet.nets.e2e_asr_th\"),",
            "-    (\"vggblstmp\", \"espnet.nets.e2e_asr\"),",
            "-    (\"vggblstmp\", \"espnet.nets.e2e_asr_th\"),",
            "+    (\"blstmp\", \"espnet.nets.chainer.e2e_asr\"),",
            "+    (\"blstmp\", \"espnet.nets.pytorch.e2e_asr_th\"),",
            "+    (\"vggblstmp\", \"espnet.nets.chainer.e2e_asr\"),",
            "+    (\"vggblstmp\", \"espnet.nets.pytorch.e2e_asr_th\"),",
            "])",
            "def test_batch_beam_search(etype, m_str):",
            "const = 1e-4"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5390,
        "label": "no",
        "change": [
            "class TestBiMPMMatching(AllenNlpTestCase):",
            "mask1 = []",
            "for w in seq_len1:",
            "mask1.append([1] * w.item() + [0] * (len1 - w.item()))",
            "-        mask1 = torch.FloatTensor(mask1)",
            "+        mask1 = torch.BoolTensor(mask1)",
            "mask2 = []",
            "for w in seq_len2:",
            "mask2.append([1] * w.item() + [0] * (len2 - w.item()))",
            "-        mask2 = torch.FloatTensor(mask2)",
            "+        mask2 = torch.BoolTensor(mask2)",
            "",
            "d = 200  # hidden dimension",
            "n = 20  # number of perspective"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5392,
        "label": "no",
        "change": [
            "def setup(app):",
            "",
            "# @jpchen's hack to get rtd builder to install latest pytorch",
            "if 'READTHEDOCS' in os.environ:",
            "-    os.system('pip install https://download.pytorch.org/whl/cpu/torch-1.1.0-cp27-cp27mu-linux_x86_64.whl')",
            "+    os.system('pip install https://download.pytorch.org/whl/cpu/torch-1.1.0-cp36-cp36m-linux_x86_64.whl')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5394,
        "label": "no",
        "change": [
            "class Winogrande(datasets.GeneratorBasedBuilder):",
            "# TODO(winogrande): Set up version.",
            "VERSION = datasets.Version(\"1.1.0\")",
            "BUILDER_CONFIGS = [",
            "-        WinograndeConfig(name=\"winogrande_\" + size, description=\"AI2 dataset\", data_size=size) for size in _SIZES",
            "+        WinograndeConfig(name=\"winogrande_\" + data_size, description=\"AI2 dataset\", data_size=data_size)",
            "+        for data_size in _FORMATS",
            "]",
            "",
            "def _info(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5398,
        "label": "yes",
        "change": [
            "def main(args):",
            "",
            "# Get input and output tensors",
            "images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")",
            "+            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")",
            "embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")",
            "tpr, fpr, accuracy, val, val_std, far = lfw.validate(sess, paths,",
            "actual_issame, args.seed, 60,",
            "-                images_placeholder, embeddings, nrof_folds=args.lfw_nrof_folds)",
            "+                images_placeholder, phase_train_placeholder, embeddings, nrof_folds=args.lfw_nrof_folds)",
            "print('Accuracy: %1.3f+-%1.3f' % (np.mean(accuracy), np.std(accuracy)))",
            "print('Validation rate: %2.5f+-%2.5f @ FAR=%2.5f' % (val, val_std, far))"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "addition",
        "Element": "api parameter"
    },
    {
        "number": 5399,
        "label": "no",
        "change": [
            "class TestT5Examples(unittest.TestCase):",
            "output_file_name = Path(tempfile.gettempdir()) / \"utest_output_t5_sum.hypo\"",
            "score_file_name = Path(tempfile.gettempdir()) / \"utest_score_t5_sum.hypo\"",
            "",
            "-        testargs = [\"evaluate_cnn.py\", \"t5-small\", str(tmp), str(output_file_name), str(tmp), str(score_file_name)]",
            "+        testargs = [",
            "+            \"evaluate_cnn.py\",",
            "+            \"patrickvonplaten/t5-tiny-random\",",
            "+            str(tmp),",
            "+            str(output_file_name),",
            "+            str(tmp),",
            "+            str(score_file_name),",
            "+        ]",
            "",
            "with patch.object(sys, \"argv\", testargs):",
            "run_generate()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5401,
        "label": "no",
        "change": [
            "def test_local_param_in_nn_module_linear():",
            "",
            "",
            "def test_remote_param_in_nn_module_linear(workers):",
            "-    model = nn.Linear(2, 1)",
            "+    model = nn.Linear(2, 1, bias=False)",
            "tensor = torch.tensor([1.0, -1.0])",
            "model_ptr = model.send(workers[\"bob\"])",
            "tensor_ptr = tensor.send(workers[\"bob\"])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5404,
        "label": "no",
        "change": [
            "class LocalMultiGPUOptimizer(PolicyOptimizer):",
            "# all of the device copies are created.",
            "with self.local_evaluator.tf_sess.graph.as_default():",
            "with self.local_evaluator.tf_sess.as_default():",
            "-                main_scope = tf.get_variable_scope()",
            "-                with tf.variable_scope(main_scope, reuse=tf.AUTO_REUSE):",
            "+                with tf.variable_scope(\"default\", reuse=tf.AUTO_REUSE):",
            "self.par_opt = LocalSyncParallelOptimizer(",
            "tf.train.AdamOptimizer(self.sgd_stepsize),",
            "self.devices,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5405,
        "label": "no",
        "change": [
            "class SpanConstituencyParserTest(ModelTestCase):",
            "output_dict = self.model(**training_tensors)",
            "decode_output_dict = self.model.decode(output_dict)",
            "assert set(decode_output_dict.keys()) == {'spans', 'class_probabilities', 'trees',",
            "-                                                  'tokens', 'num_spans', 'loss'}",
            "+                                                  'tokens', 'pos_tags', 'num_spans', 'loss'}",
            "metrics = self.model.get_metrics(reset=True)",
            "metric_keys = set(metrics.keys())",
            "assert \"evalb_precision\" in metric_keys"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5408,
        "label": "no",
        "change": [
            "def conv1d(",
            "dilations: int = 1,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "if data_format == \"NCW\":",
            "-        x = tf.transpose(x, (0, 1, 2))",
            "+        x = tf.transpose(x, (0, 2, 1))",
            "res = tf.nn.conv1d(x, filters, strides, padding, \"NWC\", dilations)",
            "if data_format == \"NCW\":",
            "-        res = tf.transpose(res, (0, 1, 2))",
            "+        res = tf.transpose(res, (0, 2, 1))",
            "return res"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5409,
        "label": "no",
        "change": [
            "def matrix_rank(",
            ") -> torch.Tensor:",
            "# ToDo: add support for default rtol value here, for the case where None is provided",
            "ret = torch.linalg.matrix_rank(x, rtol=rtol, out=out)",
            "-    ret = torch.tensor(ret, dtype=ivy.default_float_dtype(as_native=True))",
            "+    ret = torch.tensor(ret, dtype=ivy.default_int_dtype(as_native=True))",
            "return ret"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5417,
        "label": "no",
        "change": [
            "def bbox_to_mask(boxes: torch.Tensor, width: int, height: int) -> torch.Tensor:",
            "m = m.index_fill(0, torch.arange(box[1, 1].item(), box[2, 1].item() + 1, dtype=torch.long), torch.tensor(1))",
            "m = m.unsqueeze(dim=0)",
            "m_out = (m == 1).all(dim=1) * (m == 1).all(dim=2).T",
            "+        m_out = m_out[1:-1, 1:-1]",
            "mask_out.append(m_out)",
            "",
            "return torch.stack(mask_out, dim=0).float()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5418,
        "label": "no",
        "change": [
            "class MoE(torch.nn.Module):",
            "if type(output_mlp) is tuple:",
            "output_mlp = output_mlp[0]  # Ignore the bias term for now",
            "coef = self.coefficient(hidden_states)",
            "-            coef = torch.nn.functional.softmax(coef, dim=1)",
            "+            coef = torch.nn.functional.softmax(coef, dim=-1)",
            "output = output * coef[..., 0:1] + output_mlp * coef[..., 1:]",
            "return output, self.deepspeed_moe.l_aux, self.deepspeed_moe.exp_counts"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5420,
        "label": "no",
        "change": [
            "def see_memory_usage(message, force=False):",
            "logger.info(",
            "f\"MA {round(torch.cuda.memory_allocated() / (1024 * 1024 * 1024),2 )} GB \\",
            "Max_MA {round(torch.cuda.max_memory_allocated() / (1024 * 1024 * 1024),2)} GB \\",
            "-        CA {round(torch.cuda.memory_cached() / (1024 * 1024 * 1024),2)} GB \\",
            "-        Max_CA {round(torch.cuda.max_memory_cached() / (1024 * 1024 * 1024))} GB \")",
            "+        CA {round(torch_memory_reserved() / (1024 * 1024 * 1024),2)} GB \\",
            "+        Max_CA {round(torch_max_memory_reserved() / (1024 * 1024 * 1024))} GB \")",
            "",
            "vm_stats = psutil.virtual_memory()",
            "used_GB = round(((vm_stats.total - vm_stats.available) / (1024**3)), 2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5422,
        "label": "no",
        "change": [
            "class DateTensor(tensor_wrapper.TensorWrapper):",
            "",
            "if period_type == constants.PeriodType.YEAR:",
            "y = self._years + period_tensor.quantity()",
            "-      m = tf.broadcast_to(self._months, y.shape)",
            "+      # Use tf.shape to handle the case of dynamically shaped `y`",
            "+      m = tf.broadcast_to(self._months, tf.shape(y))",
            "d = adjust_day(y, m, self._days)",
            "return from_year_month_day(y, m, d, validate=False)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5424,
        "label": "no",
        "change": [
            "class TextClassifier(nn.Module):",
            "return labels",
            "",
            "def _get_single_label(self, label_scores) -> List[Label]:",
            "-        conf, idx = torch.max(label_scores[0], 0)",
            "+        conf, idx = torch.max(label_scores, 0)",
            "label = self.label_dictionary.get_item_for_index(idx.item())",
            "",
            "return [Label(label, conf.item())]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5425,
        "label": "no",
        "change": [
            "def deprecated(help_message: Optional[str] = None):",
            "def wrapper(*args, **kwargs):",
            "func_hash = hash(deprecated_function)",
            "if func_hash not in _emitted_deprecation_warnings:",
            "-                logger.warning(warning_msg)",
            "+                warnings.warn(warning_msg, category=FutureWarning, stacklevel=2)",
            "_emitted_deprecation_warnings.add(func_hash)",
            "return deprecated_function(*args, **kwargs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5426,
        "label": "no",
        "change": [
            "def generate_rpn_proposals(boxes, scores, img_shape,",
            "(-1, 4), name='nms_input_boxes')",
            "nms_indices = tf.image.non_max_suppression(",
            "topk_valid_boxes_y1x1y2x2,",
            "-        # TODO use exp to work around a bug in TF1.9: https://github.com/tensorflow/tensorflow/issues/19578",
            "-        tf.exp(topk_valid_scores),",
            "+        topk_valid_scores,",
            "max_output_size=post_nms_topk,",
            "iou_threshold=cfg.RPN.PROPOSAL_NMS_THRESH)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5427,
        "label": "no",
        "change": [
            "class TestExpectedRiskMinimization(AllenNlpTestCase):",
            "self.initial_state = SimpleState([0], [[0]], [torch.Tensor([0.0])])",
            "self.decoder_step = SimpleTransitionFunction()",
            "# Cost is the number of odd elements in the action history.",
            "-        self.supervision = lambda state: torch.Tensor([sum([x%2 != 0 for x in",
            "+        self.supervision = lambda state: torch.Tensor([sum([x % 2 != 0 for x in",
            "state.action_history[0]])])",
            "# High beam size ensures exhaustive search.",
            "self.trainer = ExpectedRiskMinimization(beam_size=100,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5428,
        "label": "no",
        "change": [
            "class Model(object):",
            "\"It should be either Tensor or a list of Tensor.\"",
            ")",
            "for idx in range(len(check_argu)):",
            "-                        if not isinstance(check_argu[idx], [tf.Tensor, tf.SparseTensor, tf.Variable]) or not tf_ops.is_dense_tensor_like(",
            "+                        if not isinstance(check_argu[idx], (tf.Tensor, tf.SparseTensor, tf.Variable)) or not tf_ops.is_dense_tensor_like(",
            "check_argu[idx]):",
            "raise TypeError(",
            "\"The argument `%s` should be either Tensor or a list of Tensor \" % (check_order[co]) +"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5434,
        "label": "no",
        "change": [
            "def run(fn, tf_args, cluster_meta, tensorboard, log_dir, queues, background):",
            "os.environ['TF_CONFIG'] = tf_config",
            "",
            "# reserve GPU(s) again, just before launching TF process (in case situation has changed)",
            "-    if tf.test.is_built_with_cuda():",
            "+    if compat.is_gpu_available():",
            "# compute my index relative to other nodes on the same host (for GPU allocation)",
            "my_addr = cluster_spec[job_name][task_index]",
            "my_host = my_addr.split(':')[0]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5438,
        "label": "yes",
        "change": [
            "def train_cifar():",
            "optimizer = optim.Adam(get_parameters(model), lr=3e-4)",
            "else:",
            "#optimizer = optim.SGD(get_parameters(model), lr=0.001)",
            "-    optimizer = optim.SGD(get_parameters(model), lr=0.003, momentum=0.85, nesterov=True)",
            "+    optimizer = optim.SGD(get_parameters(model), lr=Tensor([0.003]).realize(), momentum=0.85, nesterov=True)",
            "",
            "# 97 steps in 2 seconds = 20ms / step",
            "# step is 1163.42 GOPS = 56 TFLOPS!!!, 41% of max 136"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 5440,
        "label": "no",
        "change": [
            "for epoch in range(opt.niter):",
            "netD.zero_grad()",
            "real_cpu = data[0].to(device)",
            "batch_size = real_cpu.size(0)",
            "-        label = torch.full((batch_size,), real_label, device=device)",
            "+        label = torch.full((batch_size,), real_label,",
            "+                           dtype=real_cpu.dtype, device=device)",
            "",
            "output = netD(real_cpu)",
            "errD_real = criterion(output, label)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5443,
        "label": "no",
        "change": [
            "class GhostNet(nn.Module):",
            "self.conv_head = nn.Conv2d(prev_chs, out_chs, 1, 1, 0, bias=True)",
            "self.act2 = nn.ReLU(inplace=True)",
            "self.flatten = nn.Flatten(1) if global_pool else nn.Identity()  # don't flatten if pooling disabled",
            "-        self.classifier = Linear(out_chs, num_classes)",
            "+        self.classifier = Linear(out_chs, num_classes) if num_classes > 0 else nn.Identity()",
            "",
            "def get_classifier(self):",
            "return self.classifier"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5445,
        "label": "no",
        "change": [
            "def DepthWarperApp():",
            "# load the data",
            "root_dir = os.path.join(root_path, 'training')",
            "img_ref, depth_ref, cam_ref = load_data(root_dir, args.sequence_name, args.frame_ref_id)",
            "-    img_i, depth_i, cam_i = load_data(root_dir, args.sequence_name, args.frame_i_id)",
            "+    img_i, _, cam_i = load_data(root_dir, args.sequence_name, args.frame_i_id)",
            "",
            "# instantiate the homography warper from `kornia`",
            "warper = dgm.DepthWarper(cam_i)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5447,
        "label": "no",
        "change": [
            "def test_lower_cholesky_transform(batch_shape, dim):",
            "x = torch.randn(batch_shape + (dim, dim))",
            "y = t(x)",
            "assert y.shape == x.shape",
            "-    actual = y.matmul(y.transpose(-1, -2)).cholesky()",
            "+    actual = torch.linalg.cholesky(y.matmul(y.transpose(-1, -2)))",
            "assert_close(actual, y)",
            "x2 = t.inv(y)",
            "assert x2.shape == x.shape"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5448,
        "label": "no",
        "change": [
            "class InitMessenger(Messenger):",
            "def _pyro_sample(self, msg):",
            "if msg[\"done\"] or msg[\"is_observed\"] or type(msg[\"fn\"]).__name__ == \"_Subsample\":",
            "return",
            "-        with torch.no_grad():",
            "+        with torch.no_grad(), helpful_support_errors(msg):",
            "value = self.init_fn(msg)",
            "if is_validation_enabled() and msg[\"value\"] is not None:",
            "if not isinstance(value, type(msg[\"value\"])):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5449,
        "label": "no",
        "change": [
            "class Encoder(torch.nn.Module):",
            "",
            "\"\"\"",
            "xs = x.unsqueeze(0)",
            "-        ilens = [x.size(0)]",
            "+        ilens = torch.tensor([x.size(0)])",
            "",
            "return self.forward(xs, ilens)[0][0]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5451,
        "label": "yes",
        "change": [
            "class NCSNpp(ModelMixin, ConfigMixin):",
            "for i_level in reversed(range(self.num_resolutions)):",
            "for i_block in range(num_res_blocks + 1):",
            "out_ch = nf * ch_mult[i_level]",
            "+                in_ch = in_ch + hs_c.pop()",
            "modules.append(",
            "ResnetBlock(",
            "-                        in_channels=in_ch + hs_c.pop(),",
            "+                        in_channels=in_ch,",
            "out_channels=out_ch,",
            "temb_channels=4 * nf,",
            "output_scale_factor=np.sqrt(2.0),"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "removal",
        "Element": "api call"
    },
    {
        "number": 5452,
        "label": "no",
        "change": [
            "class TorchHook:",
            "",
            "if torch.__version__ < \"1.0.2\":",
            "# Hard fix for PyTorch versions < 1.0.2",
            "+            # usage of torch.jit requires a torch version < torch 1.1, so we still need to support this torch version",
            "syft.torch.apply_fix16922(self.torch)",
            "",
            "torch_modules = syft.torch.torch_modules"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5453,
        "label": "no",
        "change": [
            "def TryResumeTraining():",
            "if not logger.LOG_DIR:",
            "return JustCurrentSession()",
            "path = os.path.join(logger.LOG_DIR, 'checkpoint')",
            "-    if not os.path.isfile(path):",
            "+    if not tf.gfile.Exists(path):",
            "return JustCurrentSession()",
            "return SaverRestore(path)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5455,
        "label": "no",
        "change": [
            "class DeviceAssertCallback(Callback):",
            "@pytest.mark.parametrize([\"dst_device\"], [pytest.param(torch.device(\"cpu\")), pytest.param(torch.device(\"cuda\", 0))])",
            "@RunIf(min_gpus=1)",
            "def test_submodules_device_and_dtype(dst_device, dst_dtype):",
            "-    \"\"\"",
            "-    Test that the device and dtype property updates propagate through mixed nesting of regular",
            "-    nn.Modules and the special modules of type DeviceDtypeModuleMixin (e.g. Metric or LightningModule).",
            "-    \"\"\"",
            "+    \"\"\"Test that the device and dtype property updates propagate through mixed nesting of regular nn.Modules and",
            "+    the special modules of type DeviceDtypeModuleMixin (e.g. Metric or LightningModule).\"\"\"",
            "",
            "model = TopModule()",
            "assert model.device == torch.device(\"cpu\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5456,
        "label": "no",
        "change": [
            "def l2_normalize(incoming, dim, epsilon=1e-12, name=\"l2_normalize\"):",
            "A `Tensor` with the same shape as `x`.",
            "\"\"\"",
            "with tf.name_scope(name) as name:",
            "-        x = tf.ops.convert_to_tensor(incoming, name=\"x\")",
            "+        x = tf.convert_to_tensor(incoming, name=\"x\")",
            "square_sum = tf.reduce_sum(tf.square(x), [dim], keep_dims=True)",
            "x_inv_norm = tf.rsqrt(tf.maximum(square_sum, epsilon))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5461,
        "label": "no",
        "change": [
            "class HighwayLSTM(nn.Module):",
            "self.lstm = nn.ModuleList()",
            "self.highway = nn.ModuleList()",
            "self.gate = nn.ModuleList()",
            "-        self.drop = Dropout(dropout, dims=[1] if batch_first else [0])",
            "+        self.drop = nn.Dropout(dropout)",
            "",
            "in_size = input_size",
            "for l in range(num_layers):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5462,
        "label": "no",
        "change": [
            "class PerceiverBasicDecoder(PerceiverAbstractDecoder):",
            "if self.concat_preprocessed_input:",
            "if inputs_without_pos is None:",
            "raise ValueError(\"Value is required for inputs_without_pos if concat_preprocessed_input is True\")",
            "-            pos_emb = torch.cat([inputs_without_pos, pos_emb], div=-1)",
            "+            pos_emb = torch.cat([inputs_without_pos, pos_emb], dim=-1)",
            "",
            "return pos_emb"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5464,
        "label": "no",
        "change": [
            "class MetricAverageCallbackImpl(object):",
            "self.device = device",
            "",
            "def _make_variable(self, metric, value):",
            "-        with tf.name_scope('MetricAverageCallback'):",
            "+        with tf.name_scope('MetricAverageCallback') as scope:",
            "var = tf.Variable(value, name=metric)",
            "self.backend.get_session().run(var.initializer)",
            "-            push_pull_op = bps.push_pull(var, device_dense=self.device)",
            "+            push_pull_op = bps.push_pull(var, scope, device_dense=self.device)",
            "return var, push_pull_op",
            "",
            "def _average_metrics_in_place(self, logs):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5465,
        "label": "no",
        "change": [
            "class Conv2dSubsampling(torch.nn.Module):",
            "torch.nn.ReLU()",
            ")",
            "self.out = torch.nn.Sequential(",
            "-            torch.nn.Linear(odim * ((idim - 1)// 4), odim),",
            "+            torch.nn.Linear(odim * ((idim - 1) // 4), odim),",
            "PositionalEncoding(odim, dropout_rate)",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5467,
        "label": "no",
        "change": [
            "class ParametricActionsModel(DistributionalQTFModel):",
            "action_logits = tf.reduce_sum(avail_actions * intent_vector, axis=2)",
            "",
            "# Mask out invalid actions (use tf.float32.min for stability)",
            "-        inf_mask = tf.maximum(tf.log(action_mask), tf.float32.min)",
            "+        inf_mask = tf.maximum(tf.math.log(action_mask), tf.float32.min)",
            "return action_logits + inf_mask, state",
            "",
            "def value_function(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5469,
        "label": "no",
        "change": [
            "class NormalNormalTests(TestCase):",
            "requires_grad=True))",
            "sig_q = torch.exp(log_sig_q)",
            "Normal = dist.Normal if reparameterized else fakes.NonreparameterizedNormal",
            "-            pyro.sample(\"loc_latent\", Normal(loc_q, sig_q).reshape(extra_event_dims=1))",
            "+            pyro.sample(\"loc_latent\", Normal(loc_q, sig_q).independent(1))",
            "",
            "adam = optim.Adam({\"lr\": .001})",
            "svi = SVI(model, guide, adam, loss=\"ELBO\", trace_graph=False)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5470,
        "label": "no",
        "change": [
            "class LongformerEmbeddings(nn.Module):",
            "else:",
            "position_ids = self.create_position_ids_from_inputs_embeds(inputs_embeds)",
            "",
            "-        # Copied from transformers.models.bert.modeling_bert.BertEmbeddings.forward",
            "if input_ids is not None:",
            "input_shape = input_ids.size()",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5473,
        "label": "no",
        "change": [
            "class UNet2DModel(ModelMixin, ConfigMixin):",
            "num_groups_out = norm_num_groups if norm_num_groups is not None else min(block_out_channels[0] // 4, 32)",
            "self.conv_norm_out = nn.GroupNorm(num_channels=block_out_channels[0], num_groups=num_groups_out, eps=norm_eps)",
            "self.conv_act = nn.SiLU()",
            "-        self.conv_out = nn.Conv2d(block_out_channels[0], out_channels, 3, padding=1)",
            "+        self.conv_out = nn.Conv2d(block_out_channels[0], out_channels, kernel_size=3, padding=1)",
            "",
            "def forward(",
            "self,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5474,
        "label": "no",
        "change": [
            "class TestSolveCast:",
            "error = torch.dist(B, A.matmul(X))",
            "",
            "tol_val: float = 1e-1 if dtype == torch.float16 else 1e-4",
            "-        assert_allclose(error, torch.zeros_like(error), atol=tol_val, rtol=tol_val)",
            "+        assert_close(error, torch.zeros_like(error), atol=tol_val, rtol=tol_val)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5476,
        "label": "yes",
        "change": [
            "def ga_loc_target(gt_bboxes_list,",
            "all_ignore_map.append(ignore_map)",
            "for img_id in range(img_per_gpu):",
            "gt_bboxes = gt_bboxes_list[img_id]",
            "-        scale = torch.sqrt((gt_bboxes[:, 2] - gt_bboxes[:, 0] + 1) *",
            "-                           (gt_bboxes[:, 3] - gt_bboxes[:, 1] + 1))",
            "+        scale = torch.sqrt((gt_bboxes[:, 2] - gt_bboxes[:, 0]) *",
            "+                           (gt_bboxes[:, 3] - gt_bboxes[:, 1]))",
            "min_anchor_size = scale.new_full(",
            "(1, ), float(anchor_scale * anchor_strides[0]))",
            "# assign gt bboxes to different feature levels w.r.t. their scales"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "removal",
        "Element": "api parameter"
    },
    {
        "number": 5478,
        "label": "yes",
        "change": [
            "def create_model(to_device=True, dim_in=None, dim_out=None):",
            "if 'classification' in cfg.dataset.task_type and dim_out == 2:",
            "dim_out = 1",
            "",
            "-    model = network_dict[cfg.model.type](dim_in=dim_in, dim_out=dim_out)",
            "+    model = GraphGymModule(dim_in, dim_out, cfg)",
            "if to_device:",
            "model.to(torch.device(cfg.device))",
            "return model"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 5479,
        "label": "no",
        "change": [
            "def nsc_beam_search(decoder, h, recog_args, rnnlm=None):",
            "for i, hyp in enumerate(hyps):",
            "i_topk = (",
            "torch.cat((beam_topk[0][i], beam_logp[i, 0:1])),",
            "-                    torch.cat((beam_topk[1][i], torch.LongTensor([0]))),",
            "+                    torch.cat((beam_topk[1][i], blank_tensor)),",
            ")",
            "",
            "for logp, k in zip(*i_topk):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5484,
        "label": "no",
        "change": [
            "def convert_ndarray_batch_to_tf_tensor_batch(",
            "f\"should be given, instead got: {dtypes}\"",
            ")",
            "dtypes = next(iter(dtypes.values()))",
            "-        batch = tf.convert_to_tensor(ndarrays, dtype=dtypes)",
            "+        batch = convert_ndarray_to_tf_tensor(ndarrays, dtypes)",
            "else:",
            "# Multi-tensor case.",
            "batch = {",
            "-            col_name: tf.convert_to_tensor(",
            "+            col_name: convert_ndarray_to_tf_tensor(",
            "col_ndarray,",
            "dtype=dtypes[col_name] if isinstance(dtypes, dict) else dtypes,",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5492,
        "label": "no",
        "change": [
            "class RealmScorer(RealmPreTrainedModel):",
            "# [batch_size, num_candidates, retriever_proj_size]",
            "candidate_score = candidate_score.view(-1, self.config.num_candidates, self.config.retriever_proj_size)",
            "# [batch_size, num_candidates]",
            "-        relevance_score = torch.einsum(\"BD,BND->BN\", query_score, candidate_score)",
            "+        relevance_score = torch.einsum(\"bd,bnd->bn\", query_score, candidate_score)",
            "",
            "if not return_dict:",
            "return relevance_score, query_score, candidate_score"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5496,
        "label": "no",
        "change": [
            "class HomographyWarper(nn.Module):",
            "raise TypeError(\"Patch and homography must be on the same device. \\",
            "Got patch.device: {} dst_H_src.device: {}.\"",
            ".format(patch.device, dst_homo_src.device))",
            "-        return torch.nn.functional.grid_sample(patch,",
            "-            self.warp_grid(dst_homo_src), mode='bilinear',",
            "+        return torch.nn.functional.grid_sample(",
            "+            patch, self.warp_grid(dst_homo_src), mode='bilinear',",
            "padding_mode=padding_mode)",
            "",
            "# functional api"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5507,
        "label": "no",
        "change": [
            "class KLCoeffMixin:",
            "# KL Coefficient",
            "self.kl_coeff_val = config[\"kl_coeff\"]",
            "self.kl_target = config[\"kl_target\"]",
            "-        self.kl_coeff = tf.get_variable(",
            "+        self.kl_coeff = tf1.get_variable(",
            "initializer=tf.constant_initializer(self.kl_coeff_val),",
            "name=\"kl_coeff\",",
            "shape=(),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5511,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "log_qc = tf.reduce_sum(prior_prob * zc, 1, name='logQc')",
            "Elog_qc_given_x = tf.reduce_mean(log_qc_given_x, name='ElogQc_x')",
            "Hc = tf.reduce_mean(-log_qc, name='Hc')",
            "-        MIloss = tf.mul(Hc + Elog_qc_given_x, -1.0, name='neg_MI')",
            "+        MIloss = tf.multiply(Hc + Elog_qc_given_x, -1.0, name='neg_MI')",
            "",
            "self.g_loss, self.d_loss = build_GAN_losses(vecpos, vecneg)",
            "self.g_loss = tf.add(self.g_loss, MIloss, name='total_g_loss')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5512,
        "label": "no",
        "change": [
            "def array_equal(",
            "",
            "def to_numpy(x: Union[tf.Tensor, tf.Variable], copy: bool = True) -> np.ndarray:",
            "# TensorFlow fails to convert bfloat16 tensor when it has 0 dimensions",
            "-    if get_num_dims(x) == 0 and ivy.as_native_dtype(x.dtype) is tf.bfloat16:",
            "+    if (",
            "+        ivy.is_array(x)",
            "+        and get_num_dims(x) == 0",
            "+        and ivy.as_native_dtype(x.dtype) is tf.bfloat16",
            "+    ):",
            "x = tf.expand_dims(x, 0)",
            "if copy:",
            "return np.squeeze(np.array(tf.convert_to_tensor(x)), 0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5513,
        "label": "no",
        "change": [
            "def tensordot(",
            "# type casting to float32 which is acceptable for tf.tensordot",
            "x1, x2 = tf.cast(x1, tf.float32), tf.cast(x2, tf.float32)",
            "",
            "-    ret = tf.cast(tf.tensordot(x1, x2, axes), dtype)",
            "+    ret = tf.cast(tf.tensordot(x1, x2, axes=axes), dtype)",
            "return ret"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5514,
        "label": "no",
        "change": [
            "def conv_quad_interp3d(",
            "",
            "nms_mask: torch.Tensor = kornia.feature.nms3d(input, (3, 3, 3), True)",
            "x_solved: torch.Tensor = torch.zeros_like(b)",
            "-    x_solved_masked, _ = torch.solve(b[nms_mask.view(-1)], Hes[nms_mask.view(-1)])",
            "+    x_solved_masked, _ = _torch_solve_cast(b[nms_mask.view(-1)], Hes[nms_mask.view(-1)])",
            "x_solved.masked_scatter_(nms_mask.view(-1, 1, 1), x_solved_masked)",
            "dx: torch.Tensor = -x_solved"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5516,
        "label": "no",
        "change": [
            "class MemoryEfficientMish(nn.Module):",
            "class FReLU(nn.Module):",
            "def __init__(self, c1, k=3):  # ch_in, kernel",
            "super().__init__()",
            "-        self.conv = nn.Conv2d(c1, c1, k, 1, 1, groups=c1)",
            "+        self.conv = nn.Conv2d(c1, c1, k, 1, 1, groups=c1, bias=False)",
            "self.bn = nn.BatchNorm2d(c1)",
            "",
            "def forward(self, x):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5523,
        "label": "yes",
        "change": [
            "class MapGradient(GradientProcessor):",
            "for grad, var in grads:",
            "if re.match(self.regex, var.op.name):",
            "matched = True",
            "-                with tf.device(grad.device):",
            "-                    grad = self.func(grad, var)",
            "+                grad = self.func(grad, var)",
            "if grad is not None:",
            "ret.append((grad, var))",
            "else:"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "removal",
        "Element": "api call"
    },
    {
        "number": 5525,
        "label": "no",
        "change": [
            "class Layer_Embed_Test(CustomTestCase):",
            "except AttributeError as e:",
            "print(e)",
            "self.assertEqual(embed_tensor.get_shape().as_list(), [batch_size, embedding_size])",
            "-        model = tl.models.Model(inputs=inputs, outputs=embed_tensor, name=\"word2vec_model\")",
            "+        model = tl.models.Model(inputs=inputs, outputs=embed_tensor)",
            "",
            "",
            "if __name__ == '__main__':"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5526,
        "label": "no",
        "change": [
            "sns.set_context('poster')",
            "",
            "",
            "def view_emb(emb, dir):",
            "+    '''",
            "+    Visualize a embedding matrix.",
            "+",
            "+    Args:",
            "+        emb (torch.tensor): Embedding matrix with shape (N, D). D is the",
            "+        feature dimension.",
            "+        dir (str): Output directory for the embedding figure.",
            "+",
            "+    '''",
            "if emb.shape[1] > 2:",
            "pca = PCA(n_components=2)",
            "emb = pca.fit_transform(emb)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5527,
        "label": "no",
        "change": [
            "\"# Modules in Pyro\\n\",",
            "\"\\n\",",
            "\"\\n\",",
            "-    \"This tutorial introduces [PyroModule](http://docs.pyro.ai/en/stable/nn.html#pyro.nn.module.PyroModule), Pyro's Bayesian extension of PyTorch's [nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) class. Before starting you should understand the basics of Pyro [models](http://pyro.ai/examples/intro_part_i.html) and [inference](http://pyro.ai/examples/intro_part_ii.html), understand the two primitives [pyro.sample()](http://docs.pyro.ai/en/stable/primitives.html#pyro.primitives.sample) and [pyro.param()](http://docs.pyro.ai/en/stable/primitives.html#pyro.primitives.param), and understand the basics of Pyro's [effect handlers](http://pyro.ai/examples/effect_handlers.html) (e.g. by browsing [minipyro.py](https://github.com/pyro-ppl/pyro/blob/dev/pyro/contrib/minipyro.py)).\\n\",",
            "+    \"This tutorial introduces [PyroModule](http://docs.pyro.ai/en/stable/nn.html#pyro.nn.module.PyroModule), Pyro's Bayesian extension of PyTorch's [nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) class. Before starting you should understand the basics of Pyro [models and inference](http://pyro.ai/examples/intro_long.html), understand the two primitives [pyro.sample()](http://docs.pyro.ai/en/stable/primitives.html#pyro.primitives.sample) and [pyro.param()](http://docs.pyro.ai/en/stable/primitives.html#pyro.primitives.param), and understand the basics of Pyro's [effect handlers](http://pyro.ai/examples/effect_handlers.html) (e.g. by browsing [minipyro.py](https://github.com/pyro-ppl/pyro/blob/dev/pyro/contrib/minipyro.py)).\\n\",",
            "\"\\n\",",
            "\"#### Summary:\\n\",",
            "\"\\n\","
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5530,
        "label": "no",
        "change": [
            "class TrainingArguments:",
            "device = torch.device(\"cuda\", self.local_rank)",
            "self._n_gpu = 1",
            "elif self.deepspeed:",
            "-            # deepspeed performs its own DDP internally, and requires the program to be started with:",
            "-            # deepspeed  ./program.py",
            "-            # rather than:",
            "-            # python -m torch.distributed.launch --nproc_per_node=2 ./program.py",
            "+            # deepspeed inits torch.distributed internally",
            "from .deepspeed import is_deepspeed_available",
            "",
            "if not is_deepspeed_available():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5532,
        "label": "yes",
        "change": [
            "def _compute_luts(tiles_x_im: torch.Tensor, num_bins: int = 256, clip: float = 4",
            "histos: torch.Tensor = torch.empty((tiles.shape[0], num_bins), device=tiles.device)",
            "if not diff:",
            "for i in range(tiles.shape[0]):",
            "-            histos[i] = torch.histc(tiles[i], bins=num_bins, min=0, max=1)",
            "+            histos[i] = _torch_histc_cast(tiles[i], bins=num_bins, min=0, max=1)",
            "else:",
            "bins: torch.Tensor = torch.linspace(0, 1, num_bins, device=tiles.device)",
            "histos = histogram(tiles, bins, torch.tensor(0.001)).squeeze()"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 5533,
        "label": "no",
        "change": [
            "def train_func():",
            "",
            "# __torch_distributed_begin__",
            "",
            "-from torch.nn.parallel import DistributedDataParallel",
            "+from ray import train",
            "",
            "def train_func_distributed():",
            "num_epochs = 3",
            "model = NeuralNetwork()",
            "-    model = DistributedDataParallel(model)",
            "+    model = train.torch.prepare_model(model)",
            "loss_fn = nn.MSELoss()",
            "optimizer = optim.SGD(model.parameters(), lr=0.1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5535,
        "label": "yes",
        "change": [
            "class DetrEncoderLayer(nn.Module):",
            "hidden_states = residual + hidden_states",
            "hidden_states = self.final_layer_norm(hidden_states)",
            "",
            "-        if torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any():",
            "-            clamp_value = torch.finfo(hidden_states.dtype).max - 1000",
            "-            hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)",
            "+        if self.training:",
            "+            if torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any():",
            "+                clamp_value = torch.finfo(hidden_states.dtype).max - 1000",
            "+                hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)",
            "",
            "outputs = (hidden_states,)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "state handling error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 5536,
        "label": "no",
        "change": [
            "class WSCTask(FairseqTask):",
            "prefix + leading_space + txt + trailing_space + suffix,",
            "append_eos=True,",
            ")",
            "-        mask = torch.zeros_like(toks, dtype=torch.uint8)",
            "+        mask = torch.zeros_like(toks, dtype=torch.bool)",
            "mask_start = len(self.binarize(prefix))",
            "mask_size = len(self.binarize(leading_space + txt))",
            "mask[mask_start:mask_start + mask_size] = 1"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5537,
        "label": "no",
        "change": [
            "class YOLOLayer(nn.Module):",
            "",
            "@staticmethod",
            "def _make_grid(nx=20, ny=20):",
            "-        yv, xv = torch.meshgrid([torch.arange(ny), torch.arange(nx)])",
            "+        yv, xv = torch.meshgrid([torch.arange(ny), torch.arange(nx)], indexing='ij')",
            "return torch.stack((xv, yv), 2).view((1, 1, ny, nx, 2)).float()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5541,
        "label": "no",
        "change": [
            "class RNNLM(nn.Module):",
            "self.embed = nn.Embedding(n_vocab, n_embed)",
            "if typ == \"lstm\":",
            "self.rnn = nn.ModuleList(",
            "-                [nn.LSTMCell(n_embed, n_units)] + [nn.LSTMCell(n_units, n_units) for _ in range(n_layers - 1)]",
            "-                )",
            "+                [nn.LSTMCell(n_embed, n_units)] + [nn.LSTMCell(n_units, n_units) for _ in range(n_layers - 1)])",
            "else:",
            "self.rnn = nn.ModuleList(",
            "-                [nn.GRUCell(n_embed, n_units)] + [nn.GRUCell(n_units, n_units) for _ in range(n_layers - 1)]",
            "-                )",
            "+                [nn.GRUCell(n_embed, n_units)] + [nn.GRUCell(n_units, n_units) for _ in range(n_layers - 1)])",
            "",
            "self.dropout = nn.ModuleList(",
            "[nn.Dropout(dropout_rate) for _ in range(n_layers + 1)])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5542,
        "label": "yes",
        "change": [
            "class StableDiffusionModelHijack:",
            "if len(emb.shape) == 1:",
            "emb = emb.unsqueeze(0)",
            "",
            "-            self.word_embeddings[name] = emb.detach()",
            "+            self.word_embeddings[name] = emb.detach().to(device)",
            "self.word_embeddings_checksums[name] = f'{const_hash(emb.reshape(-1)*100)&0xffff:04x}'",
            "",
            "ids = tokenizer([name], add_special_tokens=False)['input_ids'][0]"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 5545,
        "label": "no",
        "change": [
            "def ddpg_actor_critic_loss(policy, model, _, train_batch):",
            "def make_ddpg_optimizers(policy, config):",
            "# Create separate optimizers for actor & critic losses.",
            "policy._actor_optimizer = torch.optim.Adam(",
            "-        params=policy.model.policy_variables(), lr=config[\"actor_lr\"])",
            "+        params=policy.model.policy_variables(),",
            "+        lr=config[\"actor_lr\"],",
            "+        eps=1e-7)  # to match tf.keras.optimizers.Adam's epsilon default",
            "policy._critic_optimizer = torch.optim.Adam(",
            "-        params=policy.model.q_variables(), lr=config[\"critic_lr\"])",
            "+        params=policy.model.q_variables(), lr=config[\"critic_lr\"],",
            "+        eps=1e-7)  # to match tf.keras.optimizers.Adam's epsilon default",
            "return policy._actor_optimizer, policy._critic_optimizer"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5546,
        "label": "no",
        "change": [
            "class LayerBasedNetwork(Network):",
            "return network_variables + layer_variables",
            "",
            "def get_summaries(self):",
            "-        return super(LayerBasedNetwork, self).get_summaries() + \\",
            "-            [summary for layer in self.layers for summary in layer.get_summaries()]",
            "+        network_summaries = super(LayerBasedNetwork, self).get_summaries()",
            "+        layer_summaries = [summary for layer in self.layers for summary in layer.get_summaries()]",
            "+",
            "+        return network_summaries + layer_summaries",
            "",
            "",
            "class LayeredNetwork(LayerBasedNetwork):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5548,
        "label": "no",
        "change": [
            "def test_sharded_tensor_state_dict(single_process_pg):",
            "",
            "m_0 = BoringModelWithShardedTensor(spec)",
            "m_0.sharded_tensor.local_shards()[0].tensor.fill_(1)",
            "-    name_st = \".sharded_tensor\" if _TORCH_GREATER_EQUAL_1_11 and not _TORCH_GREATER_EQUAL_1_13 else \"sharded_tensor\"",
            "+    name_st = \".sharded_tensor\" if not _TORCH_GREATER_EQUAL_1_13 else \"sharded_tensor\"",
            "assert name_st in m_0.state_dict(), 'Expect \"sharded_tensor\" to appear in the state dict'",
            "",
            "m_1 = BoringModelWithShardedTensor(spec)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5549,
        "label": "no",
        "change": [
            "class CascadeRCNNHead(object):",
            "labels_per_box = tf.gather(self.gt_labels, best_iou_ind)",
            "fg_mask = max_iou_per_box >= iou_threshold",
            "fg_inds_wrt_gt = tf.boolean_mask(best_iou_ind, fg_mask)",
            "-                labels_per_box = tf.stop_gradient(labels_per_box * tf.to_int64(fg_mask))",
            "+                labels_per_box = tf.stop_gradient(labels_per_box * tf.cast(fg_mask, tf.int64))",
            "return BoxProposals(boxes, labels_per_box, fg_inds_wrt_gt)",
            "else:",
            "return BoxProposals(boxes)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5552,
        "label": "no",
        "change": [
            "class MaskedLayerNorm(torch.nn.Module):",
            "self.size = size",
            "self.eps = eps",
            "",
            "-    def forward(self, tensor: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:",
            "+    def forward(self, tensor: torch.Tensor, mask: torch.BoolTensor) -> torch.Tensor:",
            "",
            "-        broadcast_mask = mask.unsqueeze(-1).float()",
            "+        broadcast_mask = mask.unsqueeze(-1)",
            "num_elements = broadcast_mask.sum() * self.size",
            "mean = (tensor * broadcast_mask).sum() / num_elements",
            "masked_centered = (tensor - mean) * broadcast_mask"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5554,
        "label": "no",
        "change": [
            "def test_set_obj_takes_ownership(workers):",
            "",
            "me.set_obj(x)",
            "",
            "-    objs = me._objects",
            "+    objs = me.object_store._objects",
            "",
            "assert objs[x.id] == x",
            "assert objs[x.id].owner == workers[\"me\"]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5556,
        "label": "no",
        "change": [
            "class Embed(base.AbstractModule):",
            "regularizer=self._regularizers.get(self.EMBEDDINGS, None),",
            "trainable=self._trainable)",
            "",
            "-    # On the backwards pass, we want to convert the gradient from",
            "-    # indexed-slices to a regular tensor before sending it back to the",
            "-    # parameter server. This avoids excess computation on the parameter server.",
            "-",
            "-    embeddings = util.convert_gradient_to_tensor(self._embeddings)",
            "-",
            "# Lookup embeddings",
            "-    return tf.nn.embedding_lookup(embeddings, ids, name=\"embedding_lookup\")",
            "+    return tf.nn.embedding_lookup(",
            "+        self._embeddings, ids, name=\"embedding_lookup\")",
            "",
            "@property",
            "def vocab_size(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5557,
        "label": "no",
        "change": [
            "class EncdecAttnFunc(torch.autograd.Function):",
            "dropout_grads = torch._masked_scale(matmul2_dgrad1, dropout_mask, 1.0 / (1.0 - dropout_prob_t[0]))",
            "",
            "# Softmax Grad (not a publically documented op)",
            "-        softmax_grads = torch._softmax_backward_data(dropout_grads, softmax_results, -1, softmax_results)",
            "+        softmax_grads = torch._softmax_backward_data(dropout_grads, softmax_results, -1, softmax_results.dtype)",
            "",
            "# Matmul1 - DGRAD1",
            "# Input1: (data grads)  [seqs*heads, seql_q, seql_k]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5558,
        "label": "no",
        "change": [
            "class L1LossMasked(nn.Module):",
            "# target_flat: (batch * max_len, dim)",
            "target_flat = target.view(-1, target.shape[-1])",
            "# losses_flat: (batch * max_len, dim)",
            "-        losses_flat = functional.l1_loss(input, target, size_average=False,",
            "+        losses_flat = functional.l1_loss(input, target_flat, size_average=False,",
            "reduce=False)",
            "# losses: (batch, max_len, dim)",
            "losses = losses_flat.view(*target.size())",
            "+",
            "# mask: (batch, max_len, 1)",
            "mask = _sequence_mask(sequence_length=length,",
            "max_len=target.size(1)).unsqueeze(2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5564,
        "label": "no",
        "change": [
            "def compile():",
            "# https://github.com/uber/horovod/blob/10835d25eccf4b198a23a0795edddf0896f6563d/horovod/tensorflow/mpi_ops.py#L30-L40",
            "def get_ext_suffix():",
            "\"\"\"Determine library extension for various versions of Python.\"\"\"",
            "+    return '.so'    # TODO",
            "ext_suffix = sysconfig.get_config_var('EXT_SUFFIX')",
            "if ext_suffix:",
            "return ext_suffix"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5566,
        "label": "no",
        "change": [
            "for i_episode in range(num_episodes):",
            "break",
            "",
            "print('Complete')",
            "+env.render(close=True)",
            "env.close()",
            "plt.ioff()",
            "plt.show()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5568,
        "label": "no",
        "change": [
            "class SavedModelTest(test_utils.TestCase, parameterized.TestCase):",
            "if golden.deterministic:",
            "# The output from both the saved and restored model should be close.",
            "y1 = saved_model.inference(x)",
            "-      self.assertAllEqual(y1, y2)",
            "+      tf.nest.map_structure(self.assertAllEqual, y1, y2)",
            "",
            "for a, b in zip(v1, v2):",
            "self.assertEqual(a.name, b.name)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5570,
        "label": "no",
        "change": [
            "def maskrcnn_upXconv_head(feature, num_category, num_convs, norm=None):",
            "with argscope([Conv2D, Conv2DTranspose], data_format='channels_first',",
            "kernel_initializer=tf.variance_scaling_initializer(",
            "scale=2.0, mode='fan_out',",
            "-                      distribution='untruncated_normal' if get_tf_version_tuple() >= (1, 12) else 'normal')):",
            "+                      distribution='untruncated_normal')):",
            "# c2's MSRAFill is fan_out",
            "for k in range(num_convs):",
            "l = Conv2D('fcn{}'.format(k), l, cfg.MRCNN.HEAD_DIM, 3, activation=tf.nn.relu)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5572,
        "label": "no",
        "change": [
            "class DeiTForImageClassification(DeiTPreTrainedModel):",
            ">>> # model predicts one of the 1000 ImageNet classes",
            ">>> predicted_class_idx = logits.argmax(-1).item()",
            ">>> print(\"Predicted class:\", model.config.id2label[predicted_class_idx])",
            "+        Predicted class: maillot",
            "```\"\"\"",
            "return_dict = return_dict if return_dict is not None else self.config.use_return_dict"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5574,
        "label": "no",
        "change": [
            "def shift_rgb(image: torch.Tensor, r_shift: torch.Tensor, g_shift: torch.Tensor,",
            "",
            "shifts = [r_shift, g_shift, b_shift]",
            "",
            "-    shifted = (image + torch.stack(shifts).view(-1, 3, 1, 1).to(image)).clamp_(min=0, max=1)",
            "+    shifted = (image + torch.stack(shifts, dim=1).view(-1, 3, 1, 1).to(image)).clamp_(min=0, max=1)",
            "",
            "return shifted"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5579,
        "label": "yes",
        "change": [
            "class AdalamFilter:",
            "\"Please either provide orientations or set 'orientation_difference_threshold' to None to disable orientations filtering\"  # noqa: E501",
            ")",
            "k1, k2, d1, d2, o1, o2, s1, s2 = self.__to_torch(k1, k2, d1, d2, o1, o2, s1, s2)",
            "+        if len(d2) <= 1:",
            "+            return _no_match(d1)",
            "distmat = dist_matrix(d1, d2, is_normalized=False)",
            "dd12, nn12 = torch.topk(distmat, k=2, dim=1, largest=False)  # (n1, 2)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "addition",
        "Element": "api condition check"
    },
    {
        "number": 5582,
        "label": "no",
        "change": [
            "class Model(object):",
            "self.outputs, self.last_layer = self._build_layers(",
            "inputs, num_outputs, options)",
            "if options.get(\"free_log_std\", False):",
            "-            log_std = tf.get_variable(name=\"log_std\", shape=[num_outputs],",
            "-                                      initializer=tf.zeros_initializer)",
            "+            log_std = tf.get_variable(",
            "+                name=\"log_std\",",
            "+                shape=[num_outputs],",
            "+                initializer=tf.zeros_initializer)",
            "self.outputs = tf.concat(",
            "[self.outputs, 0.0 * self.outputs + log_std], 1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5583,
        "label": "no",
        "change": [
            "class LongformerSelfAttention(nn.Module):",
            "hidden_states.size(2),",
            "]",
            "",
            "-        overlapping_chunks = torch.empty(chunk_size)",
            "+        overlapping_chunks = torch.empty(chunk_size, device=hidden_states.device)",
            "for chunk in range(chunk_size[1]):",
            "overlapping_chunks[:, chunk, :, :] = hidden_states[",
            ":, chunk * window_overlap : chunk * window_overlap + 2 * window_overlap, :"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5590,
        "label": "no",
        "change": [
            "class GroupedLinearLayer(tf.keras.layers.Layer):",
            "def call(self, hidden_states):",
            "batch_size = shape_list(hidden_states)[0]",
            "x = tf.transpose(tf.reshape(hidden_states, [-1, self.num_groups, self.group_in_dim]), [1, 0, 2])",
            "-        x = tf.matmul(x, self.kernel)",
            "+        x = tf.matmul(x, tf.transpose(self.kernel, [2, 1, 0]))",
            "x = tf.transpose(x, [1, 0, 2])",
            "x = tf.reshape(x, [batch_size, -1, self.output_size])",
            "x = tf.nn.bias_add(value=x, bias=self.bias)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5593,
        "label": "no",
        "change": [
            "def vecdot(",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "dtype = torch.promote_types(x1.dtype, x2.dtype)",
            "-    x1, x2 = x1.type(torch.float32), x2.type(torch.float32)",
            "-    return torch.tensordot(x1, x2, dims=([axis], [axis]), out=out).type(dtype)",
            "+    x1, x2 = x1.to(torch.float32), x2.to(torch.float32)",
            "+    return torch.tensordot(x1, x2, dims=([axis], [axis]), out=out)",
            "",
            "",
            "vecdot.unsupported_dtypes = ("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5595,
        "label": "no",
        "change": [
            "class TestRandomCutMix:",
            "",
            "assert_allclose(out_image, expected, rtol=1e-4, atol=1e-4)",
            "assert (out_label[:, :, 0] == label).all()",
            "-        assert (out_label[:, :, 1] == torch.tensor([[1, 0], [1, 0], [1, 0], [1, 0], [0, 1]])).all()",
            "+        assert (out_label[:, :, 1] == torch.tensor([[1, 0], [1, 0], [1, 0], [1, 0], [0, 1]], device=device)).all()",
            "assert_allclose(out_label[:, :, 2], torch.tensor([[0., 0.], [0., 0.], [0., 0.0833], [0., 0.], [0.5, 0.3333]],",
            "device=device, dtype=dtype), rtol=1e-4, atol=1e-4)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5597,
        "label": "no",
        "change": [
            "class TFGPT2ModelTester:",
            "",
            "# create hypothetical next token and extent to next_input_ids",
            "next_tokens = ids_tensor((self.batch_size, 3), config.vocab_size)",
            "-        next_token_types = ids_tensor((self.batch_size, 3), self.type_vocab_size)",
            "next_attn_mask = ids_tensor((self.batch_size, 3), 2)",
            "+        next_token_types = ids_tensor((self.batch_size, 3), self.type_vocab_size)",
            "",
            "# append to next input_ids and token_type_ids",
            "next_input_ids = tf.concat([input_ids, next_tokens], axis=-1)",
            "-        next_token_type_ids = tf.concat([token_type_ids, next_token_types], axis=-1)",
            "next_attention_mask = tf.concat([input_mask, next_attn_mask], axis=-1)",
            "+        next_token_type_ids = tf.concat([token_type_ids, next_token_types], axis=-1)",
            "",
            "output_from_no_past = model(",
            "next_input_ids, token_type_ids=next_token_type_ids, attention_mask=next_attention_mask"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5598,
        "label": "yes",
        "change": [
            "class Model:",
            "return ppgs, preds_ppg, logits_ppg, pred_spec, pred_mel",
            "",
            "def loss_net2(self):",
            "-        loss_spec = tf.reduce_mean(tf.abs(self.pred_spec - self.y_spec))",
            "-        loss_mel = tf.reduce_mean(tf.abs(self.pred_mel - self.y_mel))",
            "+        loss_spec = tf.reduce_mean(tf.squared_difference(self.pred_spec, self.y_spec))",
            "+        loss_mel = tf.reduce_mean(tf.squared_difference(self.pred_mel, self.y_mel))",
            "loss = loss_spec + loss_mel",
            "return loss"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 5600,
        "label": "no",
        "change": [
            "class NormalizedAdvantageFunctions(ValueFunction):",
            "'outputs_target')",
            "self.create_training_operations()",
            "self.saver = tf.train.Saver()",
            "-        self.session.run(tf.initialize_all_variables())",
            "+        self.session.run(tf.tf.global_variables_initializer())",
            "",
            "def get_action(self, state, episode=1, total_states=0):",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5602,
        "label": "no",
        "change": [
            "class Layer_Core_Test(unittest.TestCase):",
            "",
            "if __name__ == '__main__':",
            "",
            "-    # tl.logging.set_verbosity(tl.logging.INFO)",
            "+    tf.logging.set_verbosity(tf.logging.DEBUG)",
            "tl.logging.set_verbosity(tl.logging.DEBUG)",
            "",
            "-    unittest.main()",
            "+    unittest.main()",
            "\\ No newline at end of file"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5603,
        "label": "no",
        "change": [
            "def test_polar():",
            "assert len(data) == 3",
            "assert data.pos.tolist() == pos.tolist()",
            "assert data.edge_index.tolist() == edge_index.tolist()",
            "-    assert torch.allclose(",
            "-        data.edge_attr, torch.Tensor([[1, 0], [1, PI]]), atol=1e-04)",
            "+    assert torch.allclose(data.edge_attr, torch.Tensor([[1, 0], [1, PI]]),",
            "+                          atol=1e-04)",
            "",
            "data = Data(edge_index=edge_index, pos=pos, edge_attr=edge_attr)",
            "data = Polar(norm=True)(data)",
            "assert len(data) == 3",
            "assert data.pos.tolist() == pos.tolist()",
            "assert data.edge_index.tolist() == edge_index.tolist()",
            "-    assert torch.allclose(",
            "-        data.edge_attr, torch.Tensor([[1, 1, 0], [1, 1, 0.5]]), atol=1e-04)",
            "+    assert torch.allclose(data.edge_attr,",
            "+                          torch.Tensor([[1, 1, 0], [1, 1, 0.5]]), atol=1e-04)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5614,
        "label": "no",
        "change": [
            "from __future__ import print_function",
            "import tensorflow as tf",
            "",
            "def templatemethod(name_):",
            "+  \"\"\"This decorator wraps a method with `tf.make_template`. For example,",
            "+",
            "+  @templatemethod",
            "+  def my_method():",
            "+    # Create variables",
            "+  \"\"\"",
            "def template_decorator(func):",
            "+    \"\"\"Inner decorator function\"\"\"",
            "def func_wrapper(*args, **kwargs):",
            "-      templated_func =  tf.make_template(name_, func)",
            "+      \"\"\"Inner wrapper function\"\"\"",
            "+      templated_func = tf.make_template(name_, func)",
            "return templated_func(*args, **kwargs)",
            "return func_wrapper",
            "return template_decorator"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5615,
        "label": "no",
        "change": [
            "def pow(",
            "return ret",
            "",
            "",
            "-def round(",
            "-    x: torch.Tensor,",
            "-    *,",
            "-    out: Optional[torch.Tensor] = None",
            "-) -> torch.Tensor:",
            "+def round(x: torch.Tensor, *, out: Optional[torch.Tensor] = None) -> torch.Tensor:",
            "if \"int\" in str(x.dtype):",
            "if ivy.exists(out):",
            "return ivy.inplace_update(out, x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5616,
        "label": "no",
        "change": [
            "def test_nansum(",
            "",
            "# gcd",
            "@handle_test(",
            "-    fn_tree=\"functional.experimental.nansum\",",
            "+    fn_tree=\"functional.experimental.gcd\",",
            "dtype_and_x=helpers.dtype_and_values(",
            "available_dtypes=helpers.get_dtypes(\"integer\"),",
            "num_arrays=2,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5618,
        "label": "yes",
        "change": [
            "class Trainer(object):",
            "",
            "def is_consistent(tensor):",
            "max_abs_diff = torch.max(torch.abs(tensor - tensor[0]))",
            "-                return (max_abs_diff / (tensor[0] + 1e-6) < 1e-6).all()",
            "+                return (",
            "+                    not torch.isfinite(tensor).any()",
            "+                    or (max_abs_diff / (tensor[0] + 1e-6) < 1e-6).all()",
            "+                )",
            "",
            "if not is_consistent(self._grad_norm_buf):",
            "pretty_detail = \"\\n\".join("
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 5622,
        "label": "no",
        "change": [
            "class TfKerasTests(tf.test.TestCase):",
            "initial_epoch=1)",
            "",
            "def test_sparse_as_dense(self):",
            "-        hvd.init()",
            "-",
            "-        with self.test_session() as sess:",
            "+        with self.test_session(config=self.config) as sess:",
            "K.set_session(sess)",
            "",
            "opt = keras.optimizers.RMSprop(lr=0.0001)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5626,
        "label": "no",
        "change": [
            "def sync_ddp(result: Tensor, group: Optional[Any] = None, reduce_op: Optional[Un",
            "",
            "# WA for HPU. HPU doesn't support Long types, forcefully set it to float",
            "if module_available(\"habana_frameworks.torch.utils.library_loader\"):",
            "-        from habana_frameworks.torch.utils.library_loader import is_habana_available",
            "+        from habana_frameworks.torch.utils.library_loader import is_habana_avaialble",
            "",
            "if (",
            "-            is_habana_available()",
            "+            is_habana_avaialble()",
            "and os.environ.get(\"HCCL_DISTRIBUTED_BACKEND\") == \"1\"",
            "and result.type() in (\"torch.LongTensor\", \"torch.hpu.LongTensor\")",
            "):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5627,
        "label": "no",
        "change": [
            "def mpi_discovery(distributed_port=TORCH_DISTRIBUTED_DEFAULT_PORT, verbose=True)",
            "os.environ['MASTER_PORT']))",
            "",
            "if torch.distributed.is_initialized():",
            "-        assert dist.get_rank() == rank, \"MPI rank {} does not match torch rank {}\".format(rank, dist.get_rank())",
            "-        assert dist.get_world_size() == world_size, \"MPI world size {} does not match torch world size {}\".format(",
            "-            world_size, dist.get_world_size())",
            "+        assert torch.distributed.get_rank() == rank, \"MPI rank {} does not match torch rank {}\".format(rank, dist.get_rank())",
            "+        assert torch.distributed.get_world_size() == world_size, \"MPI world size {} does not match torch world size {}\".format(",
            "+            world_size, torch.distributed.get_world_size())",
            "",
            "",
            "def in_aml():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5628,
        "label": "no",
        "change": [
            "def get_global_step_var():",
            "scope = tf.get_variable_scope()",
            "assert scope.name == '', \\",
            "\"Creating global_step_var under a variable scope would cause problems!\"",
            "-        var = tf.Variable(",
            "-            0, trainable=False, name=GLOBAL_STEP_OP_NAME)",
            "+        var = tf.get_variable(GLOBAL_STEP_OP_NAME, shape=[],",
            "+                initializer=tf.constant_initializer(), trainable=False)",
            "return var",
            "",
            "def get_global_step():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5632,
        "label": "no",
        "change": [
            "class TestStackedSelfAttentionDecoderNet(AllenNlpTestCase):",
            "batch_size = 5",
            "time_steps = 10",
            "encoded_state = torch.rand(batch_size, time_steps, decoder_inout_dim)",
            "-        source_mask = torch.ones(batch_size, time_steps)",
            "+        source_mask = torch.ones(batch_size, time_steps).bool()",
            "source_mask[0, 7:] = 0",
            "source_mask[1, 5:] = 0",
            "prev_timesteps = 3"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5637,
        "label": "yes",
        "change": [
            "def normalize_homography3d(dst_pix_trans_src_pix: torch.Tensor,",
            "# compute the transformation pixel/norm for src/dst",
            "src_norm_trans_src_pix: torch.Tensor = normal_transform_pixel3d(",
            "src_d, src_h, src_w).to(dst_pix_trans_src_pix)",
            "-    src_pix_trans_src_norm = torch.inverse(src_norm_trans_src_pix)",
            "+",
            "+    src_pix_trans_src_norm = _torch_inverse_cast(src_norm_trans_src_pix)",
            "dst_norm_trans_dst_pix: torch.Tensor = normal_transform_pixel3d(",
            "dst_d, dst_h, dst_w).to(dst_pix_trans_src_pix)",
            "# compute chain transformations"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 5643,
        "label": "no",
        "change": [
            "class NetGraph(object):",
            "self.remove_skip_layers(_KERAS_SKIP_LAYERS) # done 1 pass",
            "self.insert_1d_permute_layers()",
            "self.insert_permute_for_spatial_bn()",
            "-            self.insert_permute_for_embed_flatten()",
            "self.defuse_activation()",
            "self.remove_internal_input_layers()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5647,
        "label": "no",
        "change": [
            "class Dataset(Generic[T]):",
            "):",
            "if label_column:",
            "targets = convert_pandas_to_tf_tensor(batch[[label_column]])",
            "-                    assert targets.ndim == 2",
            "-                    targets = tf.squeeze(targets, axis=1)",
            "+                    if targets.ndim == 2 and targets.shape[1] == 1:",
            "+                        targets = tf.squeeze(targets, axis=1)",
            "batch.pop(label_column)",
            "",
            "features = None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5648,
        "label": "no",
        "change": [
            "class BidirectionalRNNEncoder(GraphModule):",
            "**kwargs)",
            "",
            "# Concatenate outputs and states of the forward and backward RNNs",
            "-    outputs_concat = tf.concat(2, outputs)",
            "+    outputs_concat = tf.concat_v2(outputs, 2)",
            "",
            "return RNNEncoderOutput(outputs=outputs_concat, final_state=states)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5650,
        "label": "no",
        "change": [
            "class Critic(object):",
            "",
            "with tf.variable_scope('Critic'):",
            "# Input (s, a), output q",
            "-            self.a = a",
            "+            self.a = tf.stop_gradient(a)    # stop critic update flows to actor",
            "self.q = self._build_net(S, self.a, 'eval_net', trainable=True)",
            "",
            "# Input (s_, a_), output q_ for q_target"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5652,
        "label": "no",
        "change": [
            "def motion_blur3d(",
            ">>> torch.allclose(out_1[0], out_1[1])",
            "True",
            ">>> # perform element-wise motion blur accross the batch",
            "-        >>> out_1 = motion_blur3d(input, 5, torch.tensor([[0., 90., 90.], [90., 180., 0.]]), torch.tensor([1, -1]))",
            "+        >>> out_1 = motion_blur3d(input, 5, torch.tensor([[0., 90., 90.], [90., 180., 0.]]), torch.tensor([1., -1.]))",
            ">>> torch.allclose(out_1[0], out_1[1])",
            "False",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5654,
        "label": "no",
        "change": [
            "def softmax_rgb_blend(",
            "z_inv = (zfar - fragments.zbuf) / (zfar - znear) * mask",
            "# pyre-fixme[16]: `Tuple` has no attribute `values`.",
            "# pyre-fixme[6]: Expected `Tensor` for 1st param but got `float`.",
            "-    z_inv_max = torch.max(z_inv, dim=-1).values[..., None]",
            "+    z_inv_max = torch.max(z_inv, dim=-1).values[..., None].clamp(min=eps)",
            "# pyre-fixme[6]: Expected `Tensor` for 1st param but got `float`.",
            "weights_num = prob_map * torch.exp((z_inv - z_inv_max) / blend_params.gamma)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5655,
        "label": "no",
        "change": [
            "def harmonic_mean(a, weights=None):",
            "return sum(weights) / sum(w/x for x, w in zip(a, weights))",
            "",
            "# torch utils",
            "-def get_optimizer(name, parameters, lr, betas=(0.9, 0.999)):",
            "+def get_optimizer(name, parameters, lr, betas=(0.9, 0.999), eps=1e-8):",
            "if name == 'sgd':",
            "return torch.optim.SGD(parameters, lr=lr)",
            "elif name == 'adagrad':",
            "return torch.optim.Adagrad(parameters, lr=lr)",
            "elif name == 'adam':",
            "-        return torch.optim.Adam(parameters, lr=lr, betas=betas) # use default lr",
            "+        return torch.optim.Adam(parameters, lr=lr, betas=betas, eps=eps)",
            "elif name == 'adamax':",
            "return torch.optim.Adamax(parameters) # use default lr",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5662,
        "label": "yes",
        "change": [
            "class FlatVarHelper(object):",
            "self.session = session",
            "shapes = map(get_shape, variables)",
            "total_size = sum(np.prod(shape) for shape in shapes)",
            "-        self.theta = theta = tf.placeholder(tf.float32, [total_size])",
            "+        self.theta = tf.placeholder(tf.float32, [total_size])",
            "start = 0",
            "assigns = []",
            "",
            "for (shape, variable) in zip(shapes, variables):",
            "size = np.prod(shape)",
            "-            assigns.append(tf.assign(variable, tf.reshape(theta[start:start + size], shape)))",
            "+            assigns.append(tf.assign(variable, tf.reshape(self.theta[start:start + size], shape)))",
            "start += size",
            "",
            "self.set_op = tf.group(*assigns)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 5663,
        "label": "no",
        "change": [
            "class FusedLAMB(torch.optim.Optimizer):",
            "continue",
            "if p.dtype == torch.float32:",
            "g_all_32.append(p.grad.data)",
            "-                elif p.dytpe == torch.float16:",
            "+                elif p.dtype == torch.float16:",
            "g_all_16.append(p.grad.data)",
            "else:",
            "raise RuntimeError('FusedLAMB only support fp16 and fp32.')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5664,
        "label": "yes",
        "change": [
            "def matmul(",
            "dtype_from = tf.as_dtype(x1.dtype)",
            "",
            "if transpose_a:",
            "-        x1 = tf.transpose(x1)",
            "+        x1 = tf.linalg.matrix_transpose(x1)",
            "if transpose_b:",
            "-        x2 = tf.transpose(x2)",
            "+        x2 = tf.linalg.matrix_transpose(x2)",
            "",
            "if adjoint_a:",
            "x1 = tf.linalg.adjoint(x1)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 5667,
        "label": "no",
        "change": [
            "def _preprocess_deconv_output_shape(x, shape, dim_ordering):",
            "",
            "if shape[0] is None:",
            "shape = (tf.shape(x)[0], ) + tuple(shape[1:])",
            "+        shape = tf.stack(list(shape))",
            "return shape"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5669,
        "label": "yes",
        "change": [
            "class LongformerOnnxConfig(OnnxConfig):",
            ")",
            "import torch",
            "",
            "+        # for some reason, replacing this code by inputs[\"global_attention_mask\"] = torch.randint(2, inputs[\"input_ids\"].shape, dtype=torch.int64)",
            "+        # makes the export fail randomly",
            "inputs[\"global_attention_mask\"] = torch.zeros_like(inputs[\"input_ids\"])",
            "# make every second token global",
            "inputs[\"global_attention_mask\"][:, ::2] = 1",
            "+",
            "return inputs"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 5671,
        "label": "no",
        "change": [
            "class TestHomographyWarper:",
            "batch_size, channels, height, width = batch_shape",
            "patch_src = torch.rand(batch_size, channels, height, width)",
            "# rotation of 90deg",
            "-        dst_homo_src = utils.create_eye_batch(batch_size, 3)",
            "+        dst_homo_src = torch.eye(3)",
            "dst_homo_src[..., 0, 0] = 0.0",
            "dst_homo_src[..., 0, 1] = 1.0",
            "dst_homo_src[..., 1, 0] = -1.0",
            "dst_homo_src[..., 1, 1] = 0.0",
            "+        dst_homo_src = dst_homo_src.expand(batch_size, -1, -1)",
            "",
            "# instantiate warper and warp from source to destination",
            "warper = kornia.HomographyWarper(height, width)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5672,
        "label": "no",
        "change": [
            "def main(args):",
            "if args.distributed_port > 0 \\",
            "or args.distributed_init_method is not None:",
            "distributed_main(args)",
            "-    elif torch.cuda.device_count() > 1:",
            "+    elif args.distributed_world_size > 1:",
            "multiprocessing_main(args)",
            "else:",
            "singleprocess_main(args)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5673,
        "label": "no",
        "change": [
            "def check_file(file, suffix=''):",
            "def check_font(font=FONT, progress=False):",
            "# Download font to CONFIG_DIR if necessary",
            "font = Path(font)",
            "-    if not font.exists() and not (CONFIG_DIR / font.name).exists():",
            "+    file = CONFIG_DIR / font.name",
            "+    if not font.exists() and not file.exists():",
            "url = \"https://ultralytics.com/assets/\" + font.name",
            "-        LOGGER.info(f'Downloading {url} to {CONFIG_DIR / font.name}...')",
            "-        torch.hub.download_url_to_file(url, str(font), progress=progress)",
            "+        LOGGER.info(f'Downloading {url} to {file}...')",
            "+        torch.hub.download_url_to_file(url, str(file), progress=progress)",
            "",
            "",
            "def check_dataset(data, autodownload=True):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5674,
        "label": "no",
        "change": [
            "class DeepQNetwork(Model):",
            "self.target_output = self.target_model.get_output()",
            "",
            "# Create training operations",
            "-        self.optimizer = tf.train.AdamOptimizer(self.alpha)",
            "+        self.optimizer = tf.train.RMSPropOptimizer(self.alpha, momentum=0.95, epsilon=0.01)",
            "self.create_training_operations()",
            "self.saver = tf.train.Saver()",
            "writer = tf.train.SummaryWriter('logs', graph=tf.get_default_graph())"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5675,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            ".FullyConnected('linear', units=10)())",
            "tf.nn.softmax(logits, name='output')",
            "",
            "-        accuracy = tf.to_float(tf.nn.in_top_k(logits, label, 1))",
            "+        accuracy = tf.cast(tf.nn.in_top_k(logits, label, 1), tf.float32)",
            "add_moving_summary(tf.reduce_mean(accuracy, name='accuracy'))",
            "",
            "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5676,
        "label": "no",
        "change": [
            "class Gaussian(Distribution):",
            "definite = mean",
            "",
            "# Non-deterministic: sample action using default normal distribution",
            "-        normal = tf.random_normal(shape=tf.shape(input=mean))",
            "-        sampled = mean + stddev * normal",
            "+        normal_distribution = tf.random_normal(shape=tf.shape(input=mean))",
            "+        sampled = mean + stddev * normal_distribution",
            "",
            "return tf.where(condition=deterministic, x=definite, y=sampled)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5678,
        "label": "no",
        "change": [
            "def test_sine_positional_encoding(num_feats=16, batch_size=2):",
            "",
            "module = SinePositionalEncoding(num_feats)",
            "h, w = 10, 6",
            "-    mask = torch.rand(batch_size, h, w) > 0.5",
            "+    mask = (torch.rand(batch_size, h, w) > 0.5).to(torch.int)",
            "assert not module.normalize",
            "out = module(mask)",
            "assert out.shape == (batch_size, num_feats * 2, h, w)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5680,
        "label": "yes",
        "change": [
            "def test_ellipsis_simplify():",
            "def test_pointer_tensor_simplify():",
            "\"\"\"Test the simplification of PointerTensor\"\"\"",
            "",
            "-    alice = syft.VirtualWorker(id=\"alice\")",
            "+    alice = syft.VirtualWorker(syft.torch.hook, id=\"alice\")",
            "input_tensor = PointerTensor(id=1000, location=alice, owner=alice)",
            "",
            "output = _simplify(input_tensor)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 5685,
        "label": "no",
        "change": [
            "class TFLogSTFTMagnitude(tf.keras.layers.Layer):",
            "Returns:",
            "Tensor: Spectral convergence loss value.",
            "\"\"\"",
            "-        return tf.math.log(tf.abs(y_mag) + 1e-9) - tf.math.log(tf.abs(x_mag) + 1e-9)",
            "+        return tf.abs(tf.math.log(y_mag + 1e-9) - tf.math.log(x_mag + 1e-9))",
            "",
            "",
            "class TFSTFT(tf.keras.layers.Layer):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5687,
        "label": "no",
        "change": [
            "class Uniform(Distribution):",
            "else:",
            "# x is 2-d",
            "if x.le(_a).data[0, 0] or x.ge(_b).data[0, 0]:",
            "-                return Variable(torch.Tensor([[-float(\"inf\")]]))",
            "+                return Variable(torch.Tensor([[-np.inf]]))",
            "return torch.sum(-torch.log(_b - _a))",
            "",
            "def batch_log_pdf(self, x, a=None, b=None, batch_size=1, *args, **kwargs):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5689,
        "label": "no",
        "change": [
            "def eye_like(n: int, input: torch.Tensor, shared_memory: bool = False) -> torch.",
            "if len(input.shape) < 1:",
            "raise AssertionError(input.shape)",
            "",
            "-    identity = torch.eye(n, device=input.device, dtype=input.dtype)",
            "+    identity = torch.eye(n, device=input.device).type(input.dtype)",
            "return identity[None].expand(input.shape[0], n, n) if shared_memory else identity[None].repeat(input.shape[0], 1, 1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5690,
        "label": "no",
        "change": [
            "class Entities(InMemoryDataset):",
            "edge = torch.tensor(edge_list, dtype=torch.long).t().contiguous()",
            "edge_index, edge_type = edge[:2], edge[2]",
            "",
            "-        oh = F.one_hot(",
            "-            edge_type, num_classes=2 * len(relations)).to(torch.float)",
            "+        oh = F.one_hot(edge_type,",
            "+                       num_classes=2 * len(relations)).to(torch.float)",
            "deg = scatter_add(oh, edge_index[0], dim=0, dim_size=len(nodes))",
            "index = edge_type + torch.arange(len(edge_list)) * 2 * len(relations)",
            "edge_norm = 1 / deg[edge_index[0]].view(-1)[index]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5700,
        "label": "no",
        "change": [
            "def test_forward_with_beamformer_net(",
            "# `mask_type` has no effect when `loss_type` is not \"mask...\"",
            "return",
            "if not is_torch_1_9_plus and use_builtin_complex:",
            "-        # builtin complex support is only available in PyTorch 1.8+",
            "+        # builtin complex support is only well supported in PyTorch 1.9+",
            "return",
            "",
            "ch = 3",
            "inputs = random_speech[..., :ch].float()",
            "ilens = torch.LongTensor([16, 12])",
            "-    speech_refs = [torch.randn(2, 16, ch).float() for spk in range(num_spk)]",
            "+    speech_refs = [torch.randn(2, 16, ch, dtype=torch.float) for spk in range(num_spk)]",
            "noise_ref1 = torch.randn(2, 16, ch, dtype=torch.float)",
            "dereverb_ref1 = torch.randn(2, 16, ch, dtype=torch.float)",
            "encoder = STFTEncoder("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5702,
        "label": "yes",
        "change": [
            "class TFFlaubertMainLayer(TFXLMMainLayer):",
            "position_ids = tf.expand_dims(tf.range(slen), axis=0)",
            "else:",
            "# assert shape_list(position_ids) == [bs, slen]  # (slen, bs)",
            "-            tf.debugging.assert_equal(shape_list(position_ids), [bs, slen])",
            "+            tf.debugging.assert_equal(",
            "+                shape_list(position_ids), [bs, slen]",
            "+            ), f\"Position id shape {shape_list(position_ids)} and input shape {[bs, slen]} mismatched\"",
            "# position_ids = position_ids.transpose(0, 1)",
            "",
            "# langs",
            "if langs is not None:",
            "# assert shape_list(langs) == [bs, slen]  # (slen, bs)",
            "-            tf.debugging.assert_equal(shape_list(langs), [bs, slen])",
            "+            tf.debugging.assert_equal(",
            "+                shape_list(langs), [bs, slen]",
            "+            ), f\"Lang shape {shape_list(langs)} and input shape {[bs, slen]} mismatched\"",
            "# langs = langs.transpose(0, 1)",
            "",
            "# Prepare head mask if needed"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 5704,
        "label": "no",
        "change": [
            "def get_detector(trained_model, device='cpu'):",
            "net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))",
            "else:",
            "net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))",
            "-        net = torch.nn.DataParallel(net)",
            "+        net = torch.nn.DataParallel(net).to(device)",
            "cudnn.benchmark = False",
            "",
            "net.eval()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5706,
        "label": "no",
        "change": [
            "class KarrasVeScheduler(SchedulerMixin, ConfigMixin):",
            "gamma = 0",
            "",
            "# sample eps ~ N(0, S_noise^2 * I)",
            "-        eps = self.config.s_noise * torch.randn(sample.shape, generator=generator).to(sample.device)",
            "+        eps = self.config.s_noise * randn_tensor(sample.shape, generator=generator).to(sample.device)",
            "sigma_hat = sigma + gamma * sigma",
            "sample_hat = sample + ((sigma_hat**2 - sigma**2) ** 0.5 * eps)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5710,
        "label": "no",
        "change": [
            "class tensorflow_extractor(base_extractor):",
            "",
            "init = tf.global_variables_initializer()",
            "with tf.Session() as sess:",
            "-            # tf.train.export_meta_graph(\"kit.meta\", as_text=True)",
            "-            # writer = tf.summary.FileWriter('./graphs', sess.graph)",
            "-            # writer.close()",
            "sess.run(init)",
            "saver = tf.train.Saver()",
            "saver.restore(sess, path + cls.architecture_map[architecture]['filename'])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5718,
        "label": "no",
        "change": [
            "class TFGPTJPreTrainedModel(TFPreTrainedModel):",
            "Returns:",
            "`Dict[str, tf.Tensor]`: The dummy inputs.",
            "\"\"\"",
            "-        dummy = {\"input_ids\": tf.constant(DUMMY_INPUTS)}",
            "+        dummy = {\"input_ids\": tf.constant(DUMMY_INPUTS, dtype=tf.int32)}",
            "return dummy",
            "",
            "@tf.function(",
            "input_signature=[",
            "{",
            "-                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),",
            "-                \"attention_mask\": tf.TensorSpec((None, None), tf.int64, name=\"attention_mask\"),",
            "+                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),",
            "+                \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),",
            "}",
            "]",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5720,
        "label": "no",
        "change": [
            "def test_layer_norm(affine):",
            "torch.jit.script(norm)",
            "out1 = norm(x)",
            "assert out1.size() == (100, 16)",
            "-    assert torch.allclose(norm(x, batch), out1)",
            "+    assert torch.allclose(norm(x, batch), out1, atol=1e-6)",
            "",
            "out2 = norm(torch.cat([x, x], dim=0), torch.cat([batch, batch + 1], dim=0))",
            "-    assert torch.allclose(out1, out2[:100])",
            "-    assert torch.allclose(out1, out2[100:])",
            "+    assert torch.allclose(out1, out2[:100], atol=1e-6)",
            "+    assert torch.allclose(out1, out2[100:], atol=1e-6)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5722,
        "label": "no",
        "change": [
            "def main_train(dir_path, max_epochs: int = 20):",
            "seed_everything(42)",
            "stopping = EarlyStopping(monitor=\"val_acc\", mode=\"max\", min_delta=0.005)",
            "trainer = pl.Trainer(",
            "+        accelerator=\"auto\",",
            "default_root_dir=dir_path,",
            "-        devices=int(torch.cuda.is_available()),",
            "precision=(16 if torch.cuda.is_available() else 32),",
            "callbacks=[stopping],",
            "min_epochs=3,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5723,
        "label": "yes",
        "change": [
            "class CheckpointMergerPipeline(DiffusionPipeline):",
            "theta_0 = theta_0()",
            "",
            "update_theta_0 = getattr(module, \"load_state_dict\")",
            "-                    theta_1 = torch.load(checkpoint_path_1)",
            "+                    theta_1 = torch.load(checkpoint_path_1, map_location=\"cpu\")",
            "",
            "-                    theta_2 = torch.load(checkpoint_path_2) if checkpoint_path_2 else None",
            "+                    theta_2 = torch.load(checkpoint_path_2, map_location=\"cpu\") if checkpoint_path_2 else None",
            "",
            "if not theta_0.keys() == theta_1.keys():",
            "print(\"SKIPPING ATTR \", attr, \" DUE TO MISMATCH\")"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 5730,
        "label": "no",
        "change": [
            "TF2_WEIGHTS_NAME = 'tf_model.h5'",
            "TF_WEIGHTS_NAME = 'model.ckpt'",
            "CONFIG_NAME = \"config.json\"",
            "",
            "-logger = logging.getLogger(__name__)  # pylint: disable=invalid-name",
            "-",
            "def is_torch_available():",
            "return _torch_available"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5734,
        "label": "no",
        "change": [
            "class LinearizedConvolution(ConvTBC):",
            "self.input_buffer[:, :-1, :] = self.input_buffer[:, 1:, :].clone()",
            "# append next input",
            "self.input_buffer[:, -1, :] = input[:, -1, :]",
            "-            input = torch.autograd.Variable(self.input_buffer, volatile=True)",
            "+            input = utils.volatile_variable(self.input_buffer)",
            "output = F.linear(input.view(bsz, -1), weight, self.bias)",
            "return output.view(bsz, 1, -1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5735,
        "label": "no",
        "change": [
            "class LanguageModelTrainer:",
            "# not really sure what this does",
            "ntokens = len(self.corpus.dictionary)",
            "",
            "-                    total_loss = torch.zeros(1)",
            "+                    total_loss = torch.zeros(1, device=flair.device)",
            "start_time = time.time()",
            "",
            "for batch, i in enumerate("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5736,
        "label": "no",
        "change": [
            "from kornia.augmentation.random_generator import DistributionWithMapper",
            "",
            "",
            "class TestDistMapper:",
            "-",
            "-    def test_mapper(self,):",
            "+    def test_mapper(self):",
            "_ = torch.manual_seed(0)",
            "-        dist = DistributionWithMapper(Normal(0., 1.,), map_fn=nn.Sigmoid())",
            "+        dist = DistributionWithMapper(Normal(0.0, 1.0), map_fn=nn.Sigmoid())",
            "out = dist.rsample((8,))",
            "-        exp = torch.tensor([",
            "-            0.8236, 0.4272, 0.1017, 0.6384, 0.2527, 0.1980, 0.5995, 0.6980",
            "-        ])",
            "+        exp = torch.tensor([0.8236, 0.4272, 0.1017, 0.6384, 0.2527, 0.1980, 0.5995, 0.6980])",
            "assert_allclose(out, exp, rtol=1e-4, atol=1e-4)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5738,
        "label": "no",
        "change": [
            "class HubertUtilsTest(unittest.TestCase):",
            "mask_prob = 0.5",
            "mask_length = 4",
            "",
            "-        mask = _compute_mask_indices((batch_size, sequence_length), mask_prob, mask_length, torch_device)",
            "+        mask = _compute_mask_indices((batch_size, sequence_length), mask_prob, mask_length)",
            "+        mask = torch.from_numpy(mask).to(torch_device)",
            "",
            "# because of overlap mask don't have to add up exactly to `mask_prob * sequence_length`, but have to be smaller or equal",
            "for batch_sum in mask.sum(axis=-1):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5744,
        "label": "yes",
        "change": [
            "class TowerContext(object):",
            "self._ctxs.append(tf.variable_scope(self._name))",
            "else:",
            "# use existing variable scope",
            "+                reuse = self.index > 0 or (not self.is_training)",
            "self._ctxs.append(tf.variable_scope(",
            "-                    tf.get_variable_scope(), reuse=self.index > 0))",
            "+                    tf.get_variable_scope(), reuse=reuse))",
            "self._ctxs.append(tf.name_scope(self._name))",
            "self._ctxs.append(tf.device(self._device))",
            "for c in self._ctxs:"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 5745,
        "label": "no",
        "change": [
            "class ModelExporter(object):",
            "\"\"\"",
            "if tags is None:",
            "tags = (tf.saved_model.SERVING if get_tf_version_tuple() >= (1, 12)",
            "-                    else tf.saved_model.tag_constants.SERVING)",
            "+                    else tf.saved_model.tag_constants.SERVING, )",
            "",
            "self.graph = self.config._maybe_create_graph()",
            "with self.graph.as_default():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5749,
        "label": "no",
        "change": [
            "class TFeat(nn.Module):",
            "# use torch.hub to load pretrained model",
            "if pretrained:",
            "storage_fcn: Callable = lambda storage, loc: storage",
            "-            pretrained_dict = torch.hub.load_state_dict_from_url(",
            "-                urls['liberty'], map_location=storage_fcn",
            "-            )",
            "+            pretrained_dict = torch.hub.load_state_dict_from_url(urls['liberty'], map_location=storage_fcn)",
            "self.load_state_dict(pretrained_dict, strict=True)",
            "self.eval()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5755,
        "label": "no",
        "change": [
            "def expand_tile(value, newdim):",
            "print(value)",
            "print('############')",
            "",
            "-    return mtf.broadcast(mtf_expand_dims(value, 'dummy_batch', 0),",
            "+    return mtf.broadcast(mtf_expand_dims(value, newdim, 0),",
            "[newdim] + value.shape.dims)  # shape.dims gets us a list which we need in order to concat"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5757,
        "label": "no",
        "change": [
            "def test_unconstrained_to_corr_cholesky_transform(y_shape):",
            "log_det = transform.log_abs_det_jacobian(y, x)",
            "assert log_det.shape == y_shape[:-1]",
            "if len(y_shape) == 1:",
            "-        triu_index = x.new_ones(x.shape).triu(diagonal=1).to(torch.uint8)",
            "+        triu_index = x.new_ones(x.shape).triu(diagonal=1).to(torch.bool)",
            "x_tril_vector = x.t()[triu_index]",
            "assert_tensors_equal(_autograd_log_det(x_tril_vector, y), log_det, prec=1e-4)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5758,
        "label": "no",
        "change": [
            "if not is_installed(\"torch\") or not is_installed(\"torchvision\"):",
            "run(f'\"{python}\" -m {torch_command}', \"Installing torch and torchvision\", \"Couldn't install torch\")",
            "",
            "if not skip_torch_cuda_test:",
            "-    run_python(\"import torch; assert torch.cuda.is_available(), 'Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDINE_ARGS variable to disable this check'\")",
            "+    run_python(\"import torch; assert torch.cuda.is_available(), 'Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check'\")",
            "",
            "if not is_installed(\"k_diffusion.sampling\"):",
            "run_pip(f\"install {k_diffusion_package}\", \"k-diffusion\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5761,
        "label": "no",
        "change": [
            "class TestDivergenceLoss:",
            "target = torch.randn((2, 4, 10, 16), dtype=dtype, device=device)",
            "args = (input, target)",
            "op = kornia.losses.js_div_loss_2d",
            "-        op_jit = torch.jit.script(op, args)",
            "+        op_jit = torch.jit.script(op)",
            "assert_close(op(*args), op_jit(*args), rtol=0, atol=1e-5)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5762,
        "label": "no",
        "change": [
            "class TrainingTest(test_combinations.TestCase):",
            "@test_combinations.run_all_keras_modes(always_skip_v1=True)",
            "def test_distribution_reduction_method_sum(self):",
            "",
            "-        strategy = tf.distribute.MirroredStrategy([\"/cpu:1\", \"/cpu:2\", \"/cpu:3\", \"/cpu:4\"])",
            "+        strategy = tf.distribute.MirroredStrategy(",
            "+            [\"/cpu:1\", \"/cpu:2\", \"/cpu:3\", \"/cpu:4\"]",
            "+        )",
            "BATCH_SIZE = 10",
            "",
            "class MyModel(training_module.Model):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5763,
        "label": "no",
        "change": [
            "class TestCenterCropGen3D(RandomGeneratorBaseTests):",
            "[0, 0, 119],",
            "[99, 0, 119],",
            "[99, 149, 119],",
            "-                 [0, 149, 119]]], device=device, dtype=torch.long),",
            "+                 [0, 149, 119]]], device=device, dtype=torch.long).repeat(2, 1, 1),",
            ")",
            "assert res.keys() == expected.keys()",
            "assert_allclose(res['src'].to(device=device), expected['src'], atol=1e-4, rtol=1e-4)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5766,
        "label": "no",
        "change": [
            "class ReloadedLayer(base_layer.Layer):",
            "",
            "",
            "def _make_tensor_spec(x):",
            "-    return tf.TensorSpec(x.shape, dtype=x.dtype)",
            "+    return tf.TensorSpec(x.shape, dtype=x.dtype, name=x.name)",
            "",
            "",
            "def _print_signature(fn, name):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5767,
        "label": "no",
        "change": [
            "def test_metrics_mod(second_operand, expected_result):",
            "final_mod = first_metric % second_operand",
            "",
            "assert isinstance(final_mod, CompositionalMetric)",
            "-",
            "-    assert torch.allclose(expected_result, final_mod.compute())",
            "+    # prevent Runtime error for PT 1.8 - Long did not match Float",
            "+    assert torch.allclose(expected_result.to(float), final_mod.compute().to(float))",
            "",
            "",
            "@pytest.mark.parametrize("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5769,
        "label": "no",
        "change": [
            "def recog(args):",
            "if args.rnnlm:",
            "rnnlm_args = get_model_conf(args.rnnlm, args.rnnlm_conf)",
            "rnnlm = lm_pytorch.ClassifierWithState(",
            "-            lm_pytorch.RNNLM(len(train_args.char_list), rnnlm_args.layer, rnnlm_args.unit))",
            "+            lm_pytorch.RNNLM(",
            "+                len(train_args.char_list), rnnlm_args.layer, rnnlm_args.unit))",
            "torch_load(args.rnnlm, rnnlm)",
            "rnnlm.eval()",
            "else:",
            "rnnlm = None",
            "",
            "if args.word_rnnlm:",
            "-        rnnlm_args = get_model_conf(args.word_rnnlm, args.rnnlm_conf)",
            "+        rnnlm_args = get_model_conf(args.word_rnnlm, args.word_rnnlm_conf)",
            "word_dict = rnnlm_args.char_list_dict",
            "char_dict = {x: i for i, x in enumerate(train_args.char_list)}",
            "word_rnnlm = lm_pytorch.ClassifierWithState(lm_pytorch.RNNLM("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5771,
        "label": "no",
        "change": [
            "class TFDebertaDisentangledSelfAttention(tf.keras.layers.Layer):",
            "if len(shape_list_pos) == 2:",
            "relative_pos = tf.expand_dims(tf.expand_dims(relative_pos, 0), 0)",
            "elif len(shape_list_pos) == 3:",
            "-            relative_pos = tf.expand_dims(relative_pos, 0)",
            "+            relative_pos = tf.expand_dims(relative_pos, 1)",
            "# bxhxqxk",
            "elif len(shape_list_pos) != 4:",
            "raise ValueError(f\"Relative position ids must be of dim 2 or 3 or 4. {len(shape_list_pos)}\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    }
]
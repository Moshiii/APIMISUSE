[
    {
        "number": 5775,
        "label": "no",
        "change": [
            "class AutoModel(object):",
            "if isinstance(input_node, input_module.StructuredDataInput):",
            "middle_nodes.append(hypermodels.StructuredDataBlock()(input_node))",
            "if isinstance(input_node, input_module.TimeseriesInput):",
            "-                middle_nodes.append(hypermodels.TimeSeriesBlock()(input_node))",
            "+                middle_nodes.append(hypermodels.TimeseriesBlock()(input_node))",
            "",
            "# Merge the middle nodes.",
            "if len(middle_nodes) > 1:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5781,
        "label": "no",
        "change": [
            "def test_gof(continuous_dist):",
            "num_samples = 50000",
            "for i in range(continuous_dist.get_num_test_data()):",
            "d = Dist(**continuous_dist.get_dist_params(i))",
            "-        samples = d.sample(torch.Size([num_samples]))",
            "+        with torch.random.fork_rng():",
            "+            samples = d.sample(torch.Size([num_samples]))",
            "with xfail_if_not_implemented():",
            "probs = d.log_prob(samples).exp()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5782,
        "label": "no",
        "change": [
            "class TestChainTensor(TestCase):",
            "x.get()",
            "x.child = x.child.child",
            "",
            "-        target = sy._PlusIsMinusTensor().on(torch.FloatTensor([1, 1]))",
            "+        # target = sy._PlusIsMinusTensor().on(torch.FloatTensor([1, 1]))",
            "+        target = torch.FloatTensor([1, 1])",
            "assert torch.equal(x.grad.data, target)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5783,
        "label": "no",
        "change": [
            "def test_torch_leaky_relu(",
            "num_positional_args,",
            "as_variable,",
            "with_out,",
            "-    native_array",
            "+    native_array,",
            "fw,",
            "alpha,",
            "):",
            "input_dtype, x = dtype_and_x",
            "-",
            "helpers.test_frontend_function(",
            "input_dtypes=input_dtype,",
            "as_variable_flags=as_variable,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5785,
        "label": "yes",
        "change": [
            "class NaturalGradient(Optimizer):",
            "#     tf.math.reduce_sum(input_tensor=(loss_grad * delta))",
            "#     for loss_grad, delta in zip(loss_gradients, estimated_deltas.values())",
            "# ])",
            "-                return estimated_deltas.fmap(function=tf_util.identity)",
            "+                return [tf_util.identity(input=delta) for delta in estimated_deltas.values()]",
            "",
            "if self.only_positive_updates:",
            "# Natural gradient step only works if constant > 0 (epsilon to avoid zero division)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 5786,
        "label": "no",
        "change": [
            "class TrackableNestedDict(NestedDict, tf.python.training.tracking.tracking.AutoT",
            "super().__setattr__(name, value)",
            "",
            "def __setitem__(self, key, value):",
            "-        value = tf.python.training.tracking.data_structures.sticky_attribute_assignment(",
            "-            trackable=self, value=value, name=key",
            "-        )",
            "+        value = sticky_attribute_assignment(trackable=self, value=value, name=key)",
            "super().__setitem__(key, value)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5787,
        "label": "no",
        "change": [
            "def nanmean(",
            "dtype: Optional[torch.dtype] = None,",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "-    return torch.nanmean(a, dim=axis, keepdim=keepdims, dtype=dtype, out=out)",
            "+    input = a.to(dtype)",
            "+    return torch.nanmean(input, dim=axis, keepdim=keepdims, out=out)",
            "",
            "",
            "nanmean.support_native_out = True"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5789,
        "label": "no",
        "change": [
            "class Beta(Distribution):",
            "self.max_value = max_value",
            "action_size = util.prod(self.shape)",
            "",
            "-        with tf.name_scope(name=scope):",
            "-            self.alpha = Linear(size=action_size, bias=alpha, scope='alpha')",
            "-            self.beta = Linear(size=action_size, bias=beta, scope='beta')",
            "+        self.alpha = Linear(size=action_size, bias=alpha, scope='alpha')",
            "+        self.beta = Linear(size=action_size, bias=beta, scope='beta')",
            "",
            "super(Beta, self).__init__(scope, summary_labels)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5795,
        "label": "no",
        "change": [
            "def get_layer(l_name, library=torch.nn):",
            "",
            "Returns:",
            "layer_handler (object): handler for the requested layer e.g. (torch.nn.ELU)",
            "+",
            "\"\"\"",
            "+",
            "all_torch_layers = [x for x in dir(torch.nn)]",
            "match = [x for x in all_torch_layers if l_name.lower() == x.lower()]",
            "if len(match) == 0:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5799,
        "label": "no",
        "change": [
            "class DecisionTransformerGPT2Attention(nn.Module):",
            "if not self.is_cross_attention:",
            "# if only \"normal\" attention layer implements causal mask",
            "query_length, key_length = query.size(-2), key.size(-2)",
            "-            causal_mask = self.bias[:, :, key_length - query_length : key_length, :key_length].bool()",
            "+            causal_mask = self.bias[:, :, key_length - query_length : key_length, :key_length].to(torch.bool)",
            "attn_weights = torch.where(causal_mask, attn_weights, self.masked_bias.to(attn_weights.dtype))",
            "",
            "if attention_mask is not None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5800,
        "label": "no",
        "change": [
            "from .modeling_tf_roberta import (",
            "logger = logging.getLogger(__name__)",
            "",
            "TF_CAMEMBERT_PRETRAINED_MODEL_ARCHIVE_MAP = {",
            "-    # \"camembert-base\": \"https://s3.amazonaws.com/models.huggingface.co/bert/camembert-base-tf_model.h5\"",
            "}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5802,
        "label": "no",
        "change": [
            "class SISNRLoss(TimeDomainLoss):",
            "# s_target = <s', s>s / ||s||^2",
            "pair_wise_dot = torch.sum(s_estimate * s_target, dim=1, keepdim=True)  # [B, 1]",
            "s_target_energy = (",
            "-            torch.sum(s_target**2, dim=1, keepdim=True) + self.eps",
            "+            torch.sum(s_target ** 2, dim=1, keepdim=True) + self.eps",
            ")  # [B, 1]",
            "pair_wise_proj = pair_wise_dot * s_target / s_target_energy  # [B, T]",
            "# e_noise = s' - s_target",
            "e_noise = s_estimate - pair_wise_proj  # [B, T]",
            "",
            "# SI-SNR = 10 * log_10(||s_target||^2 / ||e_noise||^2)",
            "-        pair_wise_si_snr = torch.sum(pair_wise_proj**2, dim=1) / (",
            "-            torch.sum(e_noise**2, dim=1) + self.eps",
            "+        pair_wise_si_snr = torch.sum(pair_wise_proj ** 2, dim=1) / (",
            "+            torch.sum(e_noise ** 2, dim=1) + self.eps",
            ")",
            "pair_wise_si_snr = 10 * torch.log10(pair_wise_si_snr + self.eps)  # [B]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5803,
        "label": "no",
        "change": [
            "class SequenceFeatureExtractionTestMixin(FeatureExtractionSavingTestMixin):",
            "input_np = feat_extract.pad(processed_features, padding=\"longest\", return_tensors=\"np\")[input_name]",
            "input_tf = feat_extract.pad(processed_features, padding=\"longest\", return_tensors=\"tf\")[input_name]",
            "",
            "-        self.assertTrue(abs(input_np.astype(np.float32).sum() - input_tf.numpy().sum()) < 1e-2)",
            "+        self.assertTrue(abs(input_np.astype(np.float32).sum() - input_tf.numpy().astype(np.float32).sum()) < 1e-2)",
            "",
            "def test_attention_mask(self):",
            "feat_dict = self.feat_extract_dict"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5805,
        "label": "no",
        "change": [
            "def finfo(type: Union[torch.dtype, str, torch.Tensor]) -> Finfo:",
            "",
            "",
            "def iinfo(type: Union[torch.dtype, str, torch.Tensor]) -> torch.iinfo:",
            "+    if isinstance(type, torch.Tensor):",
            "+        type = type.dtype",
            "return torch.iinfo(ivy.as_native_dtype(type))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5807,
        "label": "yes",
        "change": [
            "class BoringModelTPU(BoringModel):",
            "@pl_multi_process_test",
            "def test_model_tpu_one_core():",
            "\"\"\"Tests if device/debug flag is set correctely when training and after teardown for TPUSpawnPlugin.\"\"\"",
            "-    trainer = Trainer(tpu_cores=1, fast_dev_run=True, plugin=TPUSpawnPlugin(debug=True))",
            "+    trainer = Trainer(tpu_cores=1, fast_dev_run=True, strategy=TPUSpawnPlugin(debug=True))",
            "# assert training type plugin attributes for device setting",
            "assert isinstance(trainer.training_type_plugin, TPUSpawnPlugin)",
            "assert not trainer.training_type_plugin.on_gpu",
            "assert trainer.training_type_plugin.on_tpu",
            "-    assert trainer.training_type_plugin.root_device == torch.device(\"xla\")",
            "+    assert trainer.training_type_plugin.root_device == torch.device(\"xla\", index=1)",
            "model = BoringModelTPU()",
            "trainer.fit(model)",
            "assert \"PT_XLA_DEBUG\" not in os.environ"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 5812,
        "label": "no",
        "change": [
            "def test_import_pytorch_lightning_with_torch_dist_unavailable():",
            "code = dedent(",
            "\"\"\"",
            "import torch",
            "-        torch.distributed.is_available = lambda: False  # pretend torch.distributed not available",
            "+",
            "+        # pretend torch.distributed not available",
            "+        for name in list(torch.distributed.__dict__.keys()):",
            "+            if not name.startswith(\"__\"):",
            "+                delattr(torch.distributed, name)",
            "+",
            "+        torch.distributed.is_available = lambda: False",
            "+",
            "import lightning.pytorch",
            "\"\"\"",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5816,
        "label": "no",
        "change": [
            "def recog(args):",
            "",
            "if rnnlm is not None:",
            "rnnlm = lm_pytorch.ClassifierWithState(",
            "-                            extlm_pytorch.MultiLevelLM(word_rnnlm.predictor,",
            "-                                    rnnlm.predictor, word_dict, char_dict))",
            "+                extlm_pytorch.MultiLevelLM(word_rnnlm.predictor,",
            "+                                           rnnlm.predictor, word_dict, char_dict))",
            "else:",
            "rnnlm = lm_pytorch.ClassifierWithState(",
            "-                            extlm_pytorch.LookAheadWordLM(word_rnnlm.predictor,",
            "-                                    word_dict, char_dict))",
            "+                extlm_pytorch.LookAheadWordLM(word_rnnlm.predictor,",
            "+                                              word_dict, char_dict))",
            "",
            "# read json data",
            "with open(args.recog_json, 'rb') as f:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5818,
        "label": "no",
        "change": [
            "def svd(",
            "",
            "",
            "def outer(",
            "-    x1: torch.Tensor,",
            "-    x2: torch.Tensor,",
            "-    out: Optional[torch.Tensor] = None",
            "+    x1: torch.Tensor, x2: torch.Tensor, out: Optional[torch.Tensor] = None",
            ") -> torch.Tensor:",
            "ret = torch.outer(x1, x2, out=out)",
            "return ret"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5819,
        "label": "yes",
        "change": [
            "class TestAugmentationSequential:",
            "data_keys=[\"input\"],",
            "random_apply=random_apply,",
            "return_transform=return_transform,",
            "+            same_on_batch=same_on_batch,",
            ")",
            "out = aug(inp)",
            "if aug.return_label:",
            "out, label = out",
            "if return_transform and isinstance(out, (tuple, list)):",
            "out = out[0]",
            "-        assert out.shape == inp.shape",
            "+        assert out.shape[-3:] == inp.shape[-3:]",
            "reproducibility_test(inp, aug)",
            "",
            "@pytest.mark.parametrize('random_apply', [1, (2, 2), (1, 2), (2,), 10, True, False])"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 5820,
        "label": "no",
        "change": [
            "def ssim_loss(img1: torch.Tensor, img2: torch.Tensor, window_size: int,",
            "ssim_map: torch.Tensor = ssim(img1, img2, window_size, max_val, eps)",
            "",
            "# compute and reduce the loss",
            "-    loss = torch.clamp(1. - ssim_map, min=0, max=1) / 2.",
            "+    loss = torch.clamp((1. - ssim_map) / 2, min=0, max=1)",
            "",
            "if reduction == \"mean\":",
            "loss = torch.mean(loss)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5824,
        "label": "yes",
        "change": [
            "def compute_q_noisy_max_torch(counts, noise_eps):",
            "",
            "if type(counts) != torch.tensor:",
            "",
            "-        counts = torch.tensor(counts, dtype=torch.float)",
            "+        counts = torch.tensor(tensors_to_literals(counts), dtype=torch.float)",
            "",
            "_, winner = counts.max(0)",
            "counts_normalized = noise_eps * ("
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 5828,
        "label": "no",
        "change": [
            "def test_trident_resnet_backbone():",
            "TridentResNet(50, num_stages=4, **tridentresnet_config)",
            "",
            "model = TridentResNet(50, num_stages=3, **tridentresnet_config)",
            "-    model.init_weights()",
            "model.train()",
            "",
            "-    imgs = torch.randn(1, 3, 224, 224)",
            "+    imgs = torch.randn(1, 3, 32, 32)",
            "feat = model(imgs)",
            "assert len(feat) == 1",
            "-    assert feat[0].shape == torch.Size([3, 1024, 14, 14])",
            "+    assert feat[0].shape == torch.Size([3, 1024, 2, 2])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5829,
        "label": "no",
        "change": [
            "from torch_geometric.testing import is_full_test",
            "",
            "",
            "def test_graph_norm():",
            "+    torch.manual_seed(42)",
            "x = torch.randn(200, 16)",
            "batch = torch.arange(4).view(-1, 1).repeat(1, 50).view(-1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5833,
        "label": "no",
        "change": [
            "class TFHubertForCTC(TFHubertPreTrainedModel):",
            ">>> processor = Wav2Vec2Processor.from_pretrained(\"facebook/hubert-base-960h\")",
            ">>> model = TFHubertForCTC.from_pretrained(\"facebook/hubert-base-960h\")",
            "",
            "+",
            ">>> def map_to_array(batch):",
            "...     speech, _ = sf.read(batch[\"file\"])",
            "...     batch[\"speech\"] = speech",
            "...     return batch",
            "",
            "+",
            ">>> ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")",
            ">>> ds = ds.map(map_to_array)",
            "",
            "-        >>> input_values = processor(ds[\"speech\"][0], return_tensors=\"tf\").input_values # Batch size 1",
            "-        >>> logits = model(input_values).logits >>> predicted_ids = tf.argmax(logits, axis=-1)",
            "+        >>> input_values = processor(ds[\"speech\"][0], return_tensors=\"tf\").input_values  # Batch size 1",
            "+        >>> logits = model(input_values).logits",
            "+        >>> predicted_ids = tf.argmax(logits, axis=-1)",
            "",
            ">>> transcription = processor.decode(predicted_ids[0])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5837,
        "label": "no",
        "change": [
            "Minimal example",
            "",
            "def test_end(self, outputs):",
            "# OPTIONAL",
            "-            avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()",
            "-            return {'avg_test_loss': avg_loss}",
            "+            test_loss_mean = torch.stack([x['test_loss'] for x in outputs]).mean()",
            "+            return {'test_loss': test_loss_mean}",
            "",
            "def configure_optimizers(self):",
            "# REQUIRED"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5838,
        "label": "no",
        "change": [
            "def shift_tokens_right(input_ids: tf.Tensor, pad_token_id: int):",
            "if pad_token_id is None:",
            "raise ValueError(\"self.model.config.pad_token_id has to be defined.\")",
            "# replace possible -100 values in labels by `pad_token_id`",
            "-    input_ids = tf.where(input_ids == -100, tf.fill(shape_list(input_ids), pad_token_id), input_ids)",
            "+    input_ids = tf.where(",
            "+        input_ids == -100, tf.fill(shape_list(input_ids), tf.cast(pad_token_id, input_ids.dtype)), input_ids",
            "+    )",
            "language_id_index = (",
            "tf.reduce_sum(tf.cast(tf.math.not_equal(input_ids, pad_token_id), dtype=input_ids.dtype), axis=-1) - 1",
            ")",
            "-    language_id_index = tf.stack([tf.range(shape_list(input_ids)[0]), language_id_index], axis=-1)",
            "+    language_id_index = tf.stack(",
            "+        [tf.range(shape_list(input_ids)[0], dtype=input_ids.dtype), language_id_index], axis=-1",
            "+    )",
            "languages_ids = tf.gather_nd(input_ids, language_id_index)",
            "",
            "shifted_input_ids = tf.concat([tf.expand_dims(languages_ids, axis=-1), input_ids[:, :-1]], axis=-1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5840,
        "label": "no",
        "change": [
            "class IntentSlotModelDecoder(DecoderBase):",
            "dense = dense.unsqueeze(1).repeat(1, word_input_shape[1], 1)",
            "x_w = torch.cat((x_w, dense), 2)",
            "",
            "-        return [logit_d, self.word_decoder(x_w)]",
            "+        return logit_d, self.word_decoder(x_w)",
            "",
            "def get_decoder(self) -> List[nn.Module]:",
            "\"\"\"Returns the document and word decoder modules."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5842,
        "label": "no",
        "change": [
            "with tf.Graph().as_default() as G:",
            "",
            "if args.output_type == 'label':",
            "for r in res:",
            "-            print r.argsort()[-top:][::-1]",
            "+            print r[0].argsort(axis=1)[:,-args.top:][:,::-1]",
            "elif args.output_type == 'label_prob':",
            "raise NotImplementedError",
            "elif args.output_type == 'raw':"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5845,
        "label": "no",
        "change": [
            "class XLMWithLMHeadModel(XLMPreTrainedModel):",
            "mask_token_id = self.config.mask_token_id",
            "lang_id = self.config.lang_id",
            "",
            "-        mask_token = torch.full((1, 1), mask_token_id, dtype=torch.long, device=input_ids.device)",
            "+        effective_batch_size = input_ids.shape[0]",
            "+        mask_token = torch.full((effective_batch_size, 1), mask_token_id, dtype=torch.long, device=input_ids.device)",
            "input_ids = torch.cat([input_ids, mask_token], dim=1)",
            "if lang_id is not None:",
            "langs = torch.full_like(input_ids, lang_id)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5848,
        "label": "no",
        "change": [
            "def rnn(step_function, inputs, initial_states,",
            "",
            "if mask is not None:",
            "if go_backwards:",
            "-                mask = tf.reverse(mask, [True] + [False] * (ndim - 1))",
            "+                mask = tf.reverse(mask, [True] + [False] * (ndim - 2))",
            "",
            "# Transpose not supported by bool tensor types, hence round-trip to uint8.",
            "mask = tf.cast(mask, tf.uint8)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5857,
        "label": "no",
        "change": [
            "class TorchHook(FrameworkHook):",
            "if \"native_tensor\" not in dir(hook_self.torch):",
            "hook_self.torch.native_tensor = hook_self.torch.tensor",
            "",
            "-        @tracer(func_name=\"torch.tensor\")",
            "def new_tensor(*args, owner=None, id=None, register=True, **kwargs):",
            "current_tensor = hook_self.torch.native_tensor(*args, **kwargs)",
            "_apply_args(hook_self, current_tensor, owner, id)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5860,
        "label": "no",
        "change": [
            "class GraphParser(Model):",
            "\"arc representation dim\", \"arc feedforward output dim\")",
            "",
            "self._unlabelled_f1 = F1Measure(positive_label=1)",
            "-        self._arc_loss = torch.nn.BCEWithLogitsLoss(reduce=False)",
            "-        self._tag_loss = torch.nn.CrossEntropyLoss(reduce=False)",
            "+        self._arc_loss = torch.nn.BCEWithLogitsLoss(reduction='none')",
            "+        self._tag_loss = torch.nn.CrossEntropyLoss(reduction='none')",
            "initializer(self)",
            "",
            "@overrides"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5862,
        "label": "no",
        "change": [
            "class TestTransformerWordEmbeddings(BaseEmbeddingsTest):",
            "\"Berlin to Germany is like Vienna to Austria\",",
            "]",
            "",
            "-        normal_sentences = [",
            "-            Sentence(text) for text in texts",
            "-        ]",
            "-        onnx_sentences = [",
            "-            Sentence(text) for text in texts",
            "-        ]",
            "+        normal_sentences = [Sentence(text) for text in texts]",
            "+        onnx_sentences = [Sentence(text) for text in texts]",
            "",
            "embeddings = TransformerWordEmbeddings(\"distilbert-base-uncased\")",
            "results_base_path.mkdir(exist_ok=True, parents=True)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5866,
        "label": "no",
        "change": [
            "def reshape(",
            "shape: Union[ivy.NativeShape, Sequence[int]],",
            "*,",
            "copy: Optional[bool] = None,",
            "-    out: Optional[torch.Tensor] = None,",
            "order: Optional[str] = \"C\",",
            "+    out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "ivy.assertions.check_elem_in_list(order, [\"C\", \"F\"])",
            "if copy:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5867,
        "label": "no",
        "change": [
            "class MockSeq2SeqEncoder(Seq2SeqEncoder):",
            "def _make_feedforward(input_dim, output_dim):",
            "return FeedForwardEncoder(",
            "FeedForward(",
            "-            input_dim=input_dim, num_layers=1, activations=torch.relu, hidden_dims=output_dim",
            "+            input_dim=input_dim, num_layers=1, activations=torch.nn.ReLU(), hidden_dims=output_dim",
            ")",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5870,
        "label": "yes",
        "change": [
            "class Model(ModelDesc):",
            "isTrain = get_current_tower_context().is_training",
            "if isTrain:",
            "# beam search is too slow to run in training",
            "-            predictions = tf.to_int32(",
            "-                tf.nn.ctc_greedy_decoder(logits, seqlen)[0][0])",
            "+            predictions = tf.cast(",
            "+                tf.nn.ctc_greedy_decoder(logits, seqlen)[0][0], tf.int32)",
            "else:",
            "-            predictions = tf.to_int32(",
            "-                tf.nn.ctc_beam_search_decoder(logits, seqlen)[0][0])",
            "+            predictions = tf.cast(",
            "+                tf.nn.ctc_beam_search_decoder(logits, seqlen)[0][0], tf.int32)",
            "err = tf.edit_distance(predictions, label, normalize=True)",
            "err.set_shape([None])",
            "err = tf.reduce_mean(err, name='error')"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 5871,
        "label": "no",
        "change": [
            "class TorchRunner:",
            "else:",
            "self.criterion = self.loss_creator(self.config)",
            "",
            "-        if torch.cuda.is_available() and hasattr(\"cuda\", self.criterion):",
            "+        if torch.cuda.is_available() and hasattr(self.criterion, \"cuda\"):",
            "self.criterion = self.criterion.cuda()",
            "",
            "def _create_schedulers_if_available(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5873,
        "label": "no",
        "change": [
            "class SpanConstituencyParser(Model):",
            "@overrides",
            "def forward(",
            "self,  # type: ignore",
            "-        tokens: Dict[str, torch.LongTensor],",
            "+        tokens: TextFieldTensors,",
            "spans: torch.LongTensor,",
            "metadata: List[Dict[str, Any]],",
            "-        pos_tags: Dict[str, torch.LongTensor] = None,",
            "+        pos_tags: TextFieldTensors = None,",
            "span_labels: torch.LongTensor = None,",
            ") -> Dict[str, torch.Tensor]:",
            "",
            "\"\"\"",
            "# Parameters",
            "",
            "-        tokens : Dict[str, torch.LongTensor], required",
            "+        tokens : TextFieldTensors, required",
            "The output of ``TextField.as_array()``, which should typically be passed directly to a",
            "``TextFieldEmbedder``. This output is a dictionary mapping keys to ``TokenIndexer``",
            "tensors.  At its most basic, using a ``SingleIdTokenIndexer`` this is : ``{\"tokens\":"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5876,
        "label": "no",
        "change": [
            "class Conv1dLinear(torch.nn.Module):",
            "\"\"\"Calculate forward propagation.",
            "",
            "Args:",
            "-            x (torch.Tensor): Batch of input tensors (B, ..., in_chans).",
            "+            x (torch.Tensor): Batch of input tensors (B, T, in_chans).",
            "",
            "Returns:",
            "-            torch.Tensor: Batch of output tensors (B, `*`, hidden_chans).",
            "+            torch.Tensor: Batch of output tensors (B, T, hidden_chans).",
            "",
            "\"\"\"",
            "x = torch.relu(self.w_1(x.transpose(-1, 1))).transpose(-1, 1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5878,
        "label": "no",
        "change": [
            "class SamplePoints(object):",
            "sample = torch.multinomial(prob, self.num, replacement=True)",
            "face = face[:, sample]",
            "",
            "-        frac = torch.rand(self.num, 2)",
            "+        frac = torch.rand(self.num, 2, device=pos.device)",
            "mask = frac.sum(dim=-1) > 1",
            "frac[mask] = 1 - frac[mask]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5882,
        "label": "no",
        "change": [
            "class CodeGenModel(CodeGenPreTrainedModel):",
            "",
            "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for",
            "# masked positions, this operation will create a tensor which is 0.0 for",
            "-            # positions we want to attend and -10000.0 for masked positions.",
            "+            # positions we want to attend and the dtype's smallest value for masked positions.",
            "# Since we are adding it to the raw scores before the softmax, this is",
            "# effectively the same as removing these entirely.",
            "attention_mask = attention_mask.to(dtype=self.dtype)  # fp16 compatibility",
            "-            attention_mask = (1.0 - attention_mask) * -10000.0",
            "+            attention_mask = (1.0 - attention_mask) * torch.finfo(self.dtype).min",
            "",
            "# Prepare head mask if needed",
            "# 1.0 in head_mask indicate we keep the head"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5883,
        "label": "yes",
        "change": [
            "class PytorchGraphTest(unittest.TestCase):",
            "class myLinear(torch.nn.Module):",
            "def __init__(self):",
            "super(myLinear, self).__init__()",
            "-                self.l = torch.nn.Linear(3, 5)",
            "+                self.linear = torch.nn.Linear(3, 5)",
            "",
            "def forward(self, x):",
            "-                return self.l(x)",
            "+                return self.linear(x)",
            "",
            "with SummaryWriter(comment='LinearModel') as w:",
            "w.add_graph(myLinear(), dummy_input, True)",
            "",
            "def test_wrong_input_size(self):",
            "print('expect error here:')",
            "-        with self.assertRaises(RuntimeError) as e_info:",
            "+        with self.assertRaises(TypeError):",
            "dummy_input = torch.rand(1, 9)",
            "model = torch.nn.Linear(3, 5)",
            "with SummaryWriter(comment='expect_error') as w:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 5886,
        "label": "yes",
        "change": [
            "class MaskRCNN():",
            "# TODO: can this be optimized to avoid duplicating the anchors?",
            "anchors = np.broadcast_to(anchors, (config.BATCH_SIZE,) + anchors.shape)",
            "# A hack to get around Keras's bad support for constants",
            "-            anchors = KL.Lambda(lambda x: tf.constant(anchors), name=\"anchors\")(input_image)",
            "+            anchors = KL.Lambda(lambda x: tf.Variable(anchors), name=\"anchors\")(input_image)",
            "else:",
            "anchors = input_anchors"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 5893,
        "label": "no",
        "change": [
            "def convert_megatron_checkpoint(sd_megatron, config):",
            "",
            "pf = \"model.language_model.encoder.layers.\"",
            "for i in range(layers):",
            "-        causal_mask = torch.tril(torch.ones((n_positions, n_positions), dtype=torch.uint8))",
            "+        causal_mask = torch.tril(torch.ones((n_positions, n_positions), dtype=torch.bool))",
            "causal_mask = causal_mask.view(1, 1, n_positions, n_positions)",
            "sd_hf[f\"transformer.h.{i}.attn.bias\"] = causal_mask",
            "sd_hf[f\"transformer.h.{i}.attn.masked_bias\"] = torch.tensor(-1e4, dtype=torch.bfloat16)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5899,
        "label": "no",
        "change": [
            "class T5PreTrainedModel(PreTrainedModel):",
            "# replace possible -100 values in labels by `pad_token_id`",
            "shifted_input_ids.masked_fill_(shifted_input_ids == -100, pad_token_id)",
            "",
            "-        assert torch.all(shifted_input_ids >= 0).item(), \"Verify that `labels` has only positive values and -100\"",
            "+        assert torch.all(shifted_input_ids >= 0).item(), \"Verify that `shifted_input_ids` has only positive values\"",
            "",
            "return shifted_input_ids"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5900,
        "label": "no",
        "change": [
            "def invert_affine_transform(matrix: torch.Tensor) -> torch.Tensor:",
            "raise ValueError(f\"Input matrix must be a Bx2x3 tensor. Got {matrix.shape}\")",
            "",
            "matrix_tmp: torch.Tensor = convert_affinematrix_to_homography(matrix)",
            "-    matrix_inv: torch.Tensor = torch.inverse(matrix_tmp)",
            "+    matrix_inv: torch.Tensor = _torch_inverse_cast(matrix_tmp)",
            "",
            "return matrix_inv[..., :2, :3]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5907,
        "label": "no",
        "change": [
            "def test_lstm(workers):",
            "lstm = nn.LSTM(3, 3)",
            "lstm.send(bob)",
            "inputs = torch.randn(5, 1, 3).send(bob)",
            "-    hidden = (torch.randn(1, 1, 3).send(bob),",
            "-        torch.randn(1, 1, 3).send(bob), )  # clean out hidden state",
            "+    hidden = (",
            "+        torch.randn(1, 1, 3).send(bob),",
            "+        torch.randn(1, 1, 3).send(bob),",
            "+    )  # clean out hidden state",
            "out, hidden = lstm(inputs, hidden)",
            "assert out.shape == torch.Size([5, 1, 3])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5909,
        "label": "no",
        "change": [
            "def get_onnx_model_list():",
            "",
            "",
            "def check_onnx_model_list(overwrite=False):",
            "-    \"\"\"Check the model list in the serialization.rst is consistent with the state of the lib and maybe `overwrite`.\"\"\"",
            "+    \"\"\"Check the model list in the serialization.mdx is consistent with the state of the lib and maybe `overwrite`.\"\"\"",
            "current_list, start_index, end_index, lines = _find_text_in_file(",
            "filename=os.path.join(PATH_TO_DOCS, \"serialization.mdx\"),",
            "start_prompt=\"<!--This table is automatically generated by make style, do not fill manually!-->\",",
            "-        end_prompt=\"This conversion is handled with the PyTorch version of models \",",
            "+        end_prompt=\"The ONNX conversion is supported for the PyTorch versions of the models.\",",
            ")",
            "new_list = get_onnx_model_list()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5915,
        "label": "no",
        "change": [
            "def test_empty_model_error():",
            "",
            "def test_unpack_latent():",
            "def model():",
            "-        return pyro.sample('x', dist.LKJCorrCholesky(2, torch.tensor(1.)))",
            "+        return pyro.sample('x', dist.LKJCholesky(2, torch.tensor(1.)))",
            "",
            "guide = AutoDiagonalNormal(model)",
            "assert guide()['x'].shape == model().shape"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5917,
        "label": "no",
        "change": [
            "def distance_transform(",
            "",
            "offset: int = i * kernel_size // 2",
            "out += (offset + cdt) * mask",
            "-        boundary[mask == 1] = 1",
            "+        boundary = torch.where(mask == 1, signal_ones, boundary)",
            "",
            "return out"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5918,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "fg_inds_wrt_sample = tf.reshape(tf.where(rcnn_labels > 0), [-1])   # fg inds w.r.t all samples",
            "fg_sampled_boxes = tf.gather(rcnn_sampled_boxes, fg_inds_wrt_sample)",
            "",
            "-            # TODO move to models",
            "with tf.name_scope('fg_sample_patch_viz'):",
            "fg_sampled_patches = crop_and_resize(",
            "image, fg_sampled_boxes,",
            "tf.zeros_like(fg_inds_wrt_sample, dtype=tf.int32), 300)",
            "fg_sampled_patches = tf.transpose(fg_sampled_patches, [0, 2, 3, 1])",
            "+                fg_sampled_patches = tf.reverse(fg_sampled_patches, axis=-1)  # BGR->RGB",
            "tf.summary.image('viz', fg_sampled_patches, max_outputs=30)",
            "",
            "matched_gt_boxes = tf.gather(gt_boxes, fg_inds_wrt_gt)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5920,
        "label": "no",
        "change": [
            "class IntraSentenceAttentionEncoder(Seq2SeqEncoder):",
            "return False",
            "",
            "@overrides",
            "-    def forward(self, tokens: torch.Tensor, mask: torch.Tensor):  # pylint: disable=arguments-differ",
            "+    def forward(self, tokens: torch.Tensor, mask: torch.Tensor):",
            "batch_size, sequence_length, _ = tokens.size()",
            "# Shape: (batch_size, sequence_length, sequence_length)",
            "similarity_matrix = self._matrix_attention(tokens, tokens)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5923,
        "label": "no",
        "change": [
            "def recog(args):",
            "word_dict = rnnlm_args.char_list_dict",
            "char_dict = {x: i for i, x in enumerate(train_args.char_list)}",
            "word_rnnlm = lm_pytorch.ClassifierWithState(lm_pytorch.RNNLM(",
            "-            len(word_dict), rnnlm_args.unit))",
            "+            len(word_dict), rnnlm_args.layers, rnnlm_args.units))",
            "torch_load(args.word_rnnlm, word_rnnlm)",
            "word_rnnlm.eval()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5925,
        "label": "no",
        "change": [
            "class Activation(Layer):",
            "x = tf.nn.leaky_relu(features=x, alpha=0.2)  # alpha argument???",
            "",
            "elif self.nonlinearity == 'none':",
            "-            x = tf.identity(input=x)",
            "+            pass",
            "",
            "elif self.nonlinearity == 'relu':",
            "x = tf.nn.relu(features=x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5926,
        "label": "no",
        "change": [
            "class BeamSearch(Search):",
            "scores_buf = top_prediction[0]",
            "indices_buf = top_prediction[1]",
            "# Project back into relative indices and beams",
            "-        beams_buf = torch.div(indices_buf, vocab_size, rounding_mode='trunc')",
            "+        beams_buf = torch.div(indices_buf, vocab_size, rounding_mode=\"trunc\")",
            "indices_buf = indices_buf.fmod(vocab_size)",
            "",
            "# At this point, beams_buf and indices_buf are single-dim and contain relative indices"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5927,
        "label": "no",
        "change": [
            "class AdditiveAttentionTest(tf.test.TestCase, parameterized.TestCase):",
            "q = tf.cast(tf.random.uniform((2, 3, 4), seed=1), \"float16\")",
            "v = tf.cast(tf.random.uniform((2, 3, 4), seed=2), \"float16\")",
            "k = tf.cast(tf.random.uniform((2, 3, 4), seed=3), \"float16\")",
            "-            layer = keras.layers.AdditiveAttention(causal=True)",
            "-            _ = layer([q, v, k])",
            "+            layer = keras.layers.AdditiveAttention()",
            "+            _ = layer([q, v, k], use_causal_mask=True)",
            "",
            "",
            "if __name__ == \"__main__\":"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5928,
        "label": "no",
        "change": [
            "def l2_normalize(x, axis=None):",
            "# Returns",
            "A tensor.",
            "\"\"\"",
            "-    return tf.nn.l2_normalize(x, dim=axis)",
            "+    return tf.nn.l2_normalize(x, axis=axis)",
            "",
            "",
            "def in_top_k(predictions, targets, k):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5932,
        "label": "yes",
        "change": [
            "class InvConvNear(nn.Module):",
            "return z, logdet",
            "",
            "def store_inverse(self):",
            "-        self.weight_inv = torch.inverse(",
            "+        weight_inv = torch.inverse(",
            "self.weight.float()).to(dtype=self.weight.dtype)",
            "+        self.weight_inv = nn.Parameter(weight_inv, requires_grad=False)",
            "",
            "",
            "class CouplingBlock(nn.Module):"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 5935,
        "label": "no",
        "change": [
            "class ParabolicEquationStepperTest(tf.test.TestCase, parameterized.TestCase):",
            "boundary_conditions=[(None, upper_boundary_fn)])[0]",
            "",
            "true_values = tf.math.exp(final_t + grid[0])",
            "-    print('est_values: ', est_values)",
            "self.assertAllClose(",
            "est_values, true_values, atol=1e-2, rtol=1e-2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5937,
        "label": "no",
        "change": [
            "import logging",
            "logger = logging.getLogger(__name__)",
            "",
            "TF_ALBERT_PRETRAINED_MODEL_ARCHIVE_MAP = {",
            "-    'albert-base-v1': \"https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-tf_model.h5\",",
            "-    'albert-large-v1': \"https://s3.amazonaws.com/models.huggingface.co/bert/albert-large-tf_model.h5\",",
            "-    'albert-xlarge-v1': \"https://s3.amazonaws.com/models.huggingface.co/bert/albert-xlarge-tf_model.h5\",",
            "-    'albert-xxlarge-v1': \"https://s3.amazonaws.com/models.huggingface.co/bert/albert-xxlarge-tf_model.h5\",",
            "+    'albert-base-v1': \"https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v1-tf_model.h5\",",
            "+    'albert-large-v1': \"https://s3.amazonaws.com/models.huggingface.co/bert/albert-large-v1-tf_model.h5\",",
            "+    'albert-xlarge-v1': \"https://s3.amazonaws.com/models.huggingface.co/bert/albert-xlarge-v1-tf_model.h5\",",
            "+    'albert-xxlarge-v1': \"https://s3.amazonaws.com/models.huggingface.co/bert/albert-xxlarge-v1-tf_model.h5\",",
            "'albert-base-v2': \"https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-tf_model.h5\",",
            "'albert-large-v2': \"https://s3.amazonaws.com/models.huggingface.co/bert/albert-large-v2-tf_model.h5\",",
            "'albert-xlarge-v2': \"https://s3.amazonaws.com/models.huggingface.co/bert/albert-xlarge-v2-tf_model.h5\","
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5945,
        "label": "no",
        "change": [
            "def where(",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "x1, x2 = ivy.promote_types_of_inputs(x1, x2)",
            "-    return torch.where(condition, x1, x2)",
            "+    return torch.where(condition, x1, x2).to(dtype=x1.dtype)",
            "",
            "",
            "# Extra #"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5946,
        "label": "no",
        "change": [
            "class SlimPruner(BasicPruner):",
            "def patched_criterion(input_tensor: Tensor, target: Tensor):",
            "sum_l1 = 0",
            "for _, wrapper in self.get_modules_wrapper().items():",
            "-                sum_l1 += torch.norm(wrapper.module.weight.data, p=1)",
            "+                sum_l1 += torch.norm(wrapper.module.weight, p=1)",
            "return criterion(input_tensor, target) + self._scale * sum_l1",
            "return patched_criterion"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5949,
        "label": "no",
        "change": [
            "class T5ModelTest(ModelTesterMixin, unittest.TestCase):",
            "def create_t5_and_check_t5_generate_with_past_key_value_states(",
            "self, config, input_ids, decoder_input_ids, attention_mask, decoder_attention_mask, lm_labels,",
            "):",
            "-            config.num_layers = 1",
            "model = T5ForConditionalGeneration(config=config)",
            "model.to(torch_device)",
            "model.eval()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5954,
        "label": "no",
        "change": [
            "def test_add_self_loops():",
            "",
            "",
            "def test_remove_self_loops():",
            "-    row = torch.LongTensor([1, 0, 1, 0, 2, 1])",
            "-    col = torch.LongTensor([0, 1, 1, 1, 2, 0])",
            "+    row = torch.tensor([1, 0, 1, 0, 2, 1])",
            "+    col = torch.tensor([0, 1, 1, 1, 2, 0])",
            "expected_output = [[1, 0, 0, 1], [0, 1, 1, 0]]",
            "",
            "output = remove_self_loops(torch.stack([row, col], dim=0))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5963,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "if not USE_SLIM:",
            "# Use a regex to find parameters to apply weight decay.",
            "# Here we apply a weight decay on all W (weight matrix) of all fc layers",
            "-            wd_cost = tf.mul(1e-5,",
            "-                             regularize_cost('fc.*/W', tf.nn.l2_loss),",
            "-                             name='regularize_loss')",
            "+            wd_cost = tf.multiply(1e-5,",
            "+                                  regularize_cost('fc.*/W', tf.nn.l2_loss),",
            "+                                  name='regularize_loss')",
            "self.cost = tf.add_n([wd_cost, cost], name='total_cost')",
            "summary.add_moving_summary(cost, wd_cost, self.cost)",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5964,
        "label": "no",
        "change": [
            "class WarmupCosineSchedule(LRSchedule):",
            "return progress / self.warmup",
            "else:",
            "progress = (progress - self.warmup) / (1 - self.warmup)   # progress after warmup",
            "-            return 0.5 * (1. + torch.cos(math.pi * self.cycles * 2 * progress))",
            "+            return 0.5 * (1. + math.cos(math.pi * self.cycles * 2 * progress))",
            "",
            "",
            "class WarmupConstantSchedule(LRSchedule):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5968,
        "label": "no",
        "change": [
            "def matmul(",
            "ret = tf.constant(0)",
            "else:",
            "",
            "-            ret = tf.math.multiply(x1, x2)[0]",
            "+            ret = tf.reduce_sum(tf.math.multiply(x1, x2))",
            "ret = tf.cast(ret, dtype=dtype_from)  # return ret",
            "",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5969,
        "label": "no",
        "change": [
            "def test_early_stopping_patience_train(",
            "callbacks=[early_stop_callback],",
            "num_sanity_val_steps=0,",
            "max_epochs=10,",
            "+        progress_bar_refresh_rate=0,",
            ")",
            "trainer.fit(model)",
            "assert trainer.current_epoch == expected_stop_epoch"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5971,
        "label": "no",
        "change": [
            "def test_permute(",
            "native_array_flags=native_array,",
            "fw=fw,",
            "frontend=\"torch\",",
            "-        fn_name=\"permute\",",
            "+        fn_tree=\"permute\",",
            "input=np.asarray(value, dtype=dtype),",
            "dims=axis,",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5974,
        "label": "no",
        "change": [
            "\"def get_example_data(dataset, num_examples, **data_kw):\\n\",",
            "\"  \\\"\\\"\\\"Show example data\\\"\\\"\\\"\\n\",",
            "\"  with tf.Session() as sess:\\n\",",
            "-        \"    it = dataset.get_data(**data_kw).take(num_examples).map(dataset.preprocess_fn).batch(num_examples).make_one_shot_iterator().get_next()\\n\",",
            "+        \"    batched_ds = dataset.get_data(**data_kw).take(num_examples).map(dataset.preprocess_fn).batch(num_examples)\\n\",",
            "+        \"    it = tf.data.make_one_shot_iterator(batched_ds).get_next()\\n\",",
            "\"    data = sess.run(it)\\n\",",
            "\"  return data\\n\",",
            "\"\\n\","
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5981,
        "label": "no",
        "change": [
            "class TrainerDDPMixin(ABC):",
            "gpu_str = ','.join([str(x) for x in data_parallel_device_ids])",
            "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_str",
            "",
            "-        logging.info(f'VISIBLE GPUS: {os.environ[\"CUDA_VISIBLE_DEVICES\"]}')",
            "+        log.info(f'VISIBLE GPUS: {os.environ[\"CUDA_VISIBLE_DEVICES\"]}')",
            "",
            "def ddp_train(self, gpu_idx, model):",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5984,
        "label": "no",
        "change": [
            "html_static_path = [\"_static\"]",
            "# autodoc_mock_imports = ['scipy', 'tensorboardX']",
            "",
            "# Manually mocking out the libraries to prevent requiring these modules",
            "-MOCK_MODULES = [\"scipy\", \"scipy.special\", \"torch.utils.tensorboard\"]",
            "+MOCK_MODULES = [",
            "+    \"scipy\",",
            "+    \"scipy.special\",",
            "+    \"torch.utils.tensorboard\",",
            "+    \"accelerators.pytorch.lib.glow_decorator\",",
            "+    \"pytext.PreprocessingMap.ttypes\",",
            "+]",
            "for mod_name in MOCK_MODULES:",
            "sys.modules[mod_name] = mock.Mock()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5989,
        "label": "no",
        "change": [
            "import torch.nn as nn",
            "",
            "",
            "def init_weights(m):",
            "-    \"\"\"Performs weight initialization.\"\"\"",
            "+    r\"\"\"",
            "+    Performs weight initialization",
            "+",
            "+    Args:",
            "+        m (nn.Module): PyTorch module",
            "+",
            "+    \"\"\"",
            "if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):",
            "m.weight.data.fill_(1.0)",
            "m.bias.data.zero_()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5991,
        "label": "no",
        "change": [
            "def where(",
            "# ----- #",
            "",
            "",
            "-def argwhere(",
            "-        x: torch.Tensor,",
            "-        /,",
            "-        *,",
            "-        out: Optional[torch.Tensor] = None",
            "-) -> torch.Tensor:",
            "+def argwhere(x: torch.Tensor, /, *, out: Optional[torch.Tensor] = None) -> torch.Tensor:",
            "return torch.argwhere(x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5992,
        "label": "no",
        "change": [
            "def test_precision_to_scale_tril(batch_shape, event_shape):",
            "x = torch.randn(batch_shape + event_shape + event_shape)",
            "precision = x.matmul(x.transpose(-2, -1))",
            "actual = precision_to_scale_tril(precision)",
            "-    expected = precision.inverse().cholesky()",
            "+    expected = torch.linalg.cholesky(precision.inverse())",
            "assert_close(actual, expected)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5995,
        "label": "no",
        "change": [
            "class TestFindHomographyDLTIter:",
            "kornia.transform_points(dst_homo_src, points_src), points_dst, rtol=1e-3, atol=1e-4)",
            "",
            "@pytest.mark.grad",
            "+    @pytest.mark.skipif(torch.__version__ < '1.7', reason=\"pytorch bug of incopatible types: #33546 fixed in v1.7\")",
            "def test_gradcheck(self, device):",
            "",
            "# Save initial seed"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6000,
        "label": "no",
        "change": [
            "class ReconLayer(DenseLayer):",
            "# ce = cost.cross_entropy(y, x_recon)                                               # <haodong>: list , list , Error (only be used for softmax output)",
            "# ce = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, x_recon))          # <haodong>: list , list , Error (only be used for softmax output)",
            "# ce = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(y, x_recon))   # <haodong>: list , index , Error (only be used for softmax output)",
            "-        L2_w = tf.contrib.layers.l2_regularizer(lambda_l2_w)(self.train_params[0]) \\",
            "-                + tf.contrib.layers.l2_regularizer(lambda_l2_w)(self.train_params[2])           # faster than the code below",
            "+        L2_w = tf.contrib.layers.l2_regularizer(lambda_l2_w)(",
            "+            self.train_params[0]",
            "+        ) + tf.contrib.layers.l2_regularizer(lambda_l2_w)(self.train_params[2])  # faster than the code below",
            "# L2_w = lambda_l2_w * tf.reduce_mean(tf.square(self.train_params[0])) + lambda_l2_w * tf.reduce_mean( tf.square(self.train_params[2]))",
            "",
            "# DropNeuro"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6001,
        "label": "no",
        "change": [
            "class RecurrentNetwork(TorchModelV2):",
            "raise NotImplementedError(\"You must implement this for an RNN model\")",
            "",
            "",
            "-class LSTMWrapper(RecurrentNetwork):",
            "+class LSTMWrapper(RecurrentNetwork, nn.Module):",
            "\"\"\"An LSTM wrapper serving as an interface for ModelV2s that set use_lstm.",
            "\"\"\"",
            "",
            "def __init__(self, obs_space, action_space, num_outputs, model_config,",
            "name):",
            "",
            "-        super(LSTMWrapper, self).__init__(obs_space, action_space, None,",
            "-                                          model_config, name)",
            "+        nn.Module.__init__(self)",
            "+        super().__init__(obs_space, action_space, None, model_config, name)",
            "",
            "self.cell_size = model_config[\"lstm_cell_size\"]",
            "self.lstm = nn.LSTM(self.num_outputs, self.cell_size, batch_first=True)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6003,
        "label": "no",
        "change": [
            "class PPFConv(MessagePassing):",
            "for use in message passing in bipartite graphs.",
            "edge_index (LongTensor): The edge indices.",
            "\"\"\"",
            "-        if torch.is_tensor(x):",
            "+        if torch.is_tensor(pos):  # Add self-loops for symmetric adjacencies.",
            "edge_index, _ = remove_self_loops(edge_index)",
            "edge_index = add_self_loops(edge_index, num_nodes=x.size(0))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6005,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "fake_output = tf.image.grayscale_to_rgb(fake_output)",
            "viz = (tf.concat(2, [input, output, fake_output]) + 1.0) * 128.0",
            "viz = tf.cast(tf.clip_by_value(viz, 0, 255), tf.uint8, name='viz')",
            "-        tf.image_summary('gen', viz, max_images=max(30, BATCH))",
            "+        tf.image_summary('gen', viz, max_outputs=max(30, BATCH))",
            "",
            "all_vars = tf.trainable_variables()",
            "self.g_vars = [v for v in all_vars if v.name.startswith('gen/')]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6006,
        "label": "no",
        "change": [
            "class GatedCnnEncoder(Seq2SeqEncoder):",
            "",
            "self._return_all_layers = return_all_layers",
            "",
            "-    def forward(self, token_embeddings: torch.Tensor, mask: torch.Tensor):",
            "+    def forward(self, token_embeddings: torch.Tensor, mask: torch.BoolTensor):",
            "",
            "# Convolutions need transposed input",
            "transposed_embeddings = torch.transpose(token_embeddings, 1, 2)",
            "",
            "# We need to broadcast the mask to feature dimension,",
            "# and to use masked_fill_ we need the inverse of the mask.",
            "-        mask_for_fill = (1 - mask).unsqueeze(1).to(dtype=torch.bool)",
            "+        mask_for_fill = ~mask.unsqueeze(1)",
            "",
            "if self._return_all_layers:",
            "# outputs will be [[all forward layers], [all backward layers]]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6008,
        "label": "yes",
        "change": [
            "class Imagen(BaseGaussianDiffusion):",
            "device = next(self.parameters()).device",
            "",
            "lowres_sample_noise_level = default(lowres_sample_noise_level, self.lowres_sample_noise_level)",
            "-        lowres_noise_times = torch.full((batch_size,), lowres_sample_noise_level, device = device, dtype = torch.long)",
            "+        lowres_noise_times = torch.full((batch_size,), int(lowres_sample_noise_level * self.num_timesteps), device = device, dtype = torch.long)",
            "",
            "for unet_number, unet, channel, image_size, learned_variance in tqdm(zip(range(1, len(self.unets) + 1), self.unets, self.sample_channels, self.image_sizes, self.learned_variance)):"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 6009,
        "label": "no",
        "change": [
            "from ray.rllib.models.misc import (conv2d, linear, flatten,",
            "normc_initializer)",
            "from ray.rllib.models.model import Model",
            "",
            "-use_tf100_api = (distutils.version.LooseVersion(tf.VERSION) >=",
            "-                 distutils.version.LooseVersion(\"1.0.0\"))",
            "-",
            "",
            "class LSTM(Model):",
            "# TODO(rliaw): Add LSTM code for other algorithms",
            "def _init(self, inputs, num_outputs, options):",
            "+        use_tf100_api = (distutils.version.LooseVersion(tf.VERSION) >=",
            "+                         distutils.version.LooseVersion(\"1.0.0\"))",
            "+",
            "self.x = x = inputs",
            "for i in range(4):",
            "x = tf.nn.elu(conv2d(x, 32, \"l{}\".format(i + 1), [3, 3], [2, 2]))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6013,
        "label": "no",
        "change": [
            "class Categorical(Distribution):",
            "definite = tf.argmax(input=logits, axis=-1)",
            "",
            "# Non-deterministic: sample action using Gumbel distribution",
            "-        uniform = tf.random_uniform(shape=tf.shape(input=logits), minval=util.epsilon, maxval=(1.0 - util.epsilon))",
            "-        gumbel_distribution = -tf.log(x=-tf.log(x=uniform))",
            "+        uniform_distribution = tf.random_uniform(",
            "+            shape=tf.shape(input=logits),",
            "+            minval=util.epsilon,",
            "+            maxval=(1.0 - util.epsilon)",
            "+        )",
            "+        gumbel_distribution = -tf.log(x=-tf.log(x=uniform_distribution))",
            "sampled = tf.argmax(input=(logits + gumbel_distribution), axis=-1)",
            "",
            "return tf.where(condition=deterministic, x=definite, y=sampled)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6014,
        "label": "no",
        "change": [
            "else:",
            "def backend():",
            "\"\"\"Publicly accessible method",
            "for determining the current backend.",
            "+",
            "+    # Returns",
            "+        String, the name of the backend Keras is currently using.",
            "+",
            "+    # Example",
            "+    ```python",
            "+        >>> keras.backend.backend()",
            "+        'tensorflow'",
            "+    ```",
            "\"\"\"",
            "return _BACKEND"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6019,
        "label": "no",
        "change": [
            "class WaveNet(object):",
            "",
            "# We skip connections from the outputs of each layer, adding them",
            "# all up here.",
            "-            total = sum(out)",
            "+            total = sum(outputs)",
            "transformed1 = tf.nn.relu(total)",
            "conv1 = tf.nn.conv2d(transformed1, w1, [1] * 4, padding=\"SAME\")",
            "transformed2 = tf.nn.relu(conv1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6024,
        "label": "no",
        "change": [
            "class Textvqa(datasets.GeneratorBasedBuilder):",
            "citation=_CITATION,",
            ")",
            "",
            "-    def _split_generators(self, dl_manager: datasets.utils.DownloadManager):",
            "+    def _split_generators(self, dl_manager):",
            "downloaded_files = dl_manager.download_and_extract(_URLS)",
            "return [",
            "datasets.SplitGenerator("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6026,
        "label": "yes",
        "change": [
            "def any(",
            "keepdims: bool = False,",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "-    x = ivy.asarray(x).type(torch.bool)",
            "+    x = torch.as_tensor(x).type(torch.bool)",
            "if axis is None:",
            "num_dims = len(x.shape)",
            "axis = list(range(num_dims))"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 6028,
        "label": "no",
        "change": [
            "class Optimizer(tf.train.Optimizer):",
            "raise NotImplementedError",
            "",
            "def minimize(self, time, variables, **kwargs):",
            "-        diffs = self.fn_step(time=time, variables=variables, **kwargs)",
            "+        diffs = self.step(time=time, variables=variables, **kwargs)",
            "# diffs[0] = tf.Print(diffs[0], (diffs[0],))",
            "with tf.control_dependencies(control_inputs=diffs):",
            "return tf.no_op()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6029,
        "label": "no",
        "change": [
            "def test_loops_state_dict_structure():",
            "\"is_last_batch\": False,",
            "},",
            "\"_results\": {",
            "+                \"batch\": None,",
            "+                \"batch_size\": None,",
            "\"training\": False,",
            "-                \"_batch_size\": torch.tensor(1),",
            "\"device\": None,",
            "\"items\": {},",
            "},"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6032,
        "label": "no",
        "change": [
            "def load_model(model_path, weights_path=None):",
            "if weights_path:",
            "if weights_path.endswith(\".pth\"):",
            "# Load checkpoint weights",
            "-            model.load_state_dict(torch.load(weights_path))",
            "+            model.load_state_dict(torch.load(weights_path, map_location=device))",
            "else:",
            "# Load darknet weights",
            "model.load_darknet_weights(weights_path)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6033,
        "label": "no",
        "change": [
            "class YOLOXHead(nn.Module):",
            "grids = torch.cat(grids, dim=1).type(dtype)",
            "strides = torch.cat(strides, dim=1).type(dtype)",
            "",
            "-        outputs = torch.cat([(outputs[..., 0:2] + grids) * strides, torch.exp(outputs[..., 2:4]) * strides, outputs[..., 4:]], dim=-1)",
            "+        outputs = torch.cat([",
            "+            (outputs[..., 0:2] + grids) * strides,",
            "+            torch.exp(outputs[..., 2:4]) * strides,",
            "+            outputs[..., 4:]",
            "+        ], dim=-1)",
            "return outputs",
            "",
            "def get_losses("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6034,
        "label": "no",
        "change": [
            "class SimplePredictBuilder(GraphBuilder):",
            "self._ns_name, self._device))",
            "",
            "with tf.device(self._device), \\",
            "-                self._maybe_open_vs(), \\",
            "TowerContext(",
            "self._ns_name, is_training=False, vs_name=self._vs_name):",
            "inputs = input.get_input_tensors()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6035,
        "label": "no",
        "change": [
            "class AttentionBlock(nn.Module):",
            "a = torch.einsum(\"bts,bcs->bct\", weight, v)",
            "h = a.reshape(bs, -1, length)",
            "",
            "-        h = self.proj_out(h)",
            "+        h = self.proj(h)",
            "h = h.reshape(b, c, *spatial)",
            "",
            "result = x + h"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6037,
        "label": "no",
        "change": [
            "def linspace(start, stop, num, axis=None, dev=None):",
            "if axis is None:",
            "axis = -1",
            "dev = default_device(dev)",
            "-    with _tf.device('/' + dev.upper()):",
            "+    with _tf.device(ivy.dev_from_str(dev)):",
            "return _tf.linspace(start, stop, num, axis=axis)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6038,
        "label": "no",
        "change": [
            "def asarray(",
            "",
            "dtype = ivy.as_ivy_dtype(ivy.default_dtype(dtype=dtype, item=obj))",
            "return tf.convert_to_tensor(",
            "-                    ivy.nested_map(obj, lambda x: tf.cast(x, dtype)),",
            "+                    ivy.nested_map(obj, lambda x: tf.cast(x, dtype), shallow=False),",
            "dtype=dtype,",
            ")",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6039,
        "label": "no",
        "change": [
            "def camera_position_from_spherical_angles(",
            "azim = math.pi / 180.0 * azim",
            "x = dist * torch.cos(elev) * torch.sin(azim)",
            "y = dist * torch.sin(elev)",
            "-    z = -dist * torch.cos(elev) * torch.cos(azim)",
            "+    z = dist * torch.cos(elev) * torch.cos(azim)",
            "camera_position = torch.stack([x, y, z], dim=1)",
            "if camera_position.dim() == 0:",
            "camera_position = camera_position.view(1, -1)  # add batch dim."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6040,
        "label": "no",
        "change": [
            "def recursive_average(obj, weight: torch.Tensor, distributed: bool = False):",
            "obj = recursive_sum(obj, weight, distributed)",
            "weight = weight.sum()",
            "if distributed:",
            "-        torch.distributed.all_reduce(weight, op=torch.distributed.ReduceOP.SUM)",
            "+        torch.distributed.all_reduce(weight, op=torch.distributed.reduce_op.SUM)",
            "# Normalize weight to be sum-to-1",
            "obj = recursive_divide(obj, weight)",
            "return obj, weight"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6041,
        "label": "no",
        "change": [
            "def bbox_to_mask(boxes: torch.Tensor, width: int, height: int) -> torch.Tensor:",
            "\"\"\"",
            "validate_bbox(boxes)",
            "# zero padding the surroudings",
            "-    mask = torch.zeros((len(boxes), height + 2, width + 2), dtype=torch.float, device=boxes.device)",
            "+    mask = torch.zeros((len(boxes), height + 2, width + 2), dtype=boxes.dtype, device=boxes.device)",
            "# push all points one pixel off",
            "# in order to zero-out the fully filled rows or columns",
            "box_i = (boxes + 1).long()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6045,
        "label": "no",
        "change": [
            "from .tokenization_utils import BatchEncoding",
            "logger = logging.getLogger(__name__)",
            "",
            "TF_GPT2_PRETRAINED_MODEL_ARCHIVE_MAP = {",
            "-    \"gpt2\": \"https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-tf_model.h5\",",
            "-    \"gpt2-medium\": \"https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-tf_model.h5\",",
            "-    \"gpt2-large\": \"https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-large-tf_model.h5\",",
            "-    \"gpt2-xl\": \"https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-xl-tf_model.h5\",",
            "-    \"distilgpt2\": \"https://s3.amazonaws.com/models.huggingface.co/bert/distilgpt2-tf_model.h5\",",
            "+    \"gpt2\": \"https://cdn.huggingface.co/gpt2-tf_model.h5\",",
            "+    \"gpt2-medium\": \"https://cdn.huggingface.co/gpt2-medium-tf_model.h5\",",
            "+    \"gpt2-large\": \"https://cdn.huggingface.co/gpt2-large-tf_model.h5\",",
            "+    \"gpt2-xl\": \"https://cdn.huggingface.co/gpt2-xl-tf_model.h5\",",
            "+    \"distilgpt2\": \"https://cdn.huggingface.co/distilgpt2-tf_model.h5\",",
            "}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6050,
        "label": "no",
        "change": [
            "space = {",
            "hyperopt_search = HyperOptSearch(space, metric=\"mean_accuracy\", mode=\"max\")",
            "",
            "analysis = tune.run(train_mnist, num_samples=10, search_alg=hyperopt_search)",
            "+",
            "+# To enable GPUs, use this instead:",
            "+# analysis = tune.run(",
            "+#     train_mnist, config=search_space, resources_per_trial={'gpu': 1})",
            "+",
            "# __run_searchalg_end__",
            "",
            "# __run_analysis_begin__"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6054,
        "label": "no",
        "change": [
            "def test_onnxruntime(",
            "res_orig = tuple(model(*inputs_example))",
            "assert all(",
            "[",
            "-                    torch.allclose(res_tensor, res_orig_tensor, rtol=1e-03)",
            "+                    torch.allclose(res_tensor, res_orig_tensor, rtol=2e-01)",
            "for (res_tensor, res_orig_tensor) in zip(res, res_orig)",
            "]",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6055,
        "label": "no",
        "change": [
            "class LatentDiffusion(DiffusionPipeline):",
            "# 3. optionally sample variance",
            "variance = 0",
            "if eta > 0:",
            "-                noise = self.noise_scheduler.sample_noise(image.shape, device=image.device, generator=generator)",
            "+                noise = torch.randn(image.shape, generator=generator, device=image.device)",
            "variance = self.noise_scheduler.get_variance(t, num_inference_steps).sqrt() * eta * noise",
            "",
            "# 4. set current image to prev_image: x_t -> x_t-1"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6059,
        "label": "no",
        "change": [
            "class TGN(torch.nn.Module):",
            ")",
            "",
            "self.register_buffer('memory', torch.empty(num_nodes, memory_dim))",
            "-        self.register_buffer('last_update', torch.empty(num_nodes))",
            "+        self.register_buffer('last_update',",
            "+                             torch.empty(num_nodes, dtype=torch.long))",
            "self.previous_events = None",
            "",
            "self.reset_parameters()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6062,
        "label": "no",
        "change": [
            "def config_file(tmp_path: Path):",
            "",
            "",
            "@pytest.mark.execution_timeout(5)",
            "+@pytest.mark.parametrize(\"batch_size\", [1, 2])",
            "@pytest.mark.parametrize(",
            "\"input_size, segment_size, hop_size\", [(16000, None, None), (35000, 2.4, 0.8)]",
            ")",
            "-def test_SeparateSpeech(config_file, input_size, segment_size, hop_size):",
            "+def test_SeparateSpeech(config_file, batch_size, input_size, segment_size, hop_size):",
            "if not is_torch_1_2_plus:",
            "pytest.skip(\"Pytorch Version Under 1.2 is not supported for Enh task\")",
            "",
            "separate_speech = SeparateSpeech(",
            "enh_train_config=config_file, segment_size=segment_size, hop_size=hop_size",
            ")",
            "-    wav = torch.rand(1, input_size)",
            "+    wav = torch.rand(batch_size, input_size)",
            "separate_speech(wav, fs=8000)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6071,
        "label": "yes",
        "change": [
            "def batched_forward(",
            "if st >= end:",
            "continue",
            "out_list.append(model_dev(data[st:end].to(device), **kwargs))",
            "-        out = torch.cat(out_list, dim=0)",
            "+        out = concatenate(out_list, 0)",
            "return out.to(data.device)",
            "return model(data, **kwargs)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 6077,
        "label": "no",
        "change": [
            "def zca_mean(inp: torch.Tensor, dim: int = 0,",
            "",
            "T_inv: Optional[torch.Tensor] = None",
            "if return_inverse:",
            "-        T_inv = (U).mm(torch.sqrt(S) * U.t())",
            "+        T_inv = (U).mm(torch.sqrt(S + eps) * U.t())",
            "",
            "return T, mean, T_inv"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6078,
        "label": "no",
        "change": [
            "class Model(Module):",
            "# at most one terminal",
            "assertions.append(",
            "tf.debugging.assert_less_equal(",
            "-                x=tf.count_nonzero(input_tensor=terminal, dtype=util.tf_dtype(dtype='int')),",
            "+                x=tf.math.count_nonzero(input_tensor=terminal, dtype=util.tf_dtype(dtype='int')),",
            "y=tf.constant(value=1, dtype=util.tf_dtype(dtype='int'))",
            ")",
            ")",
            "# if terminal, last timestep in batch",
            "assertions.append(",
            "-            tf.debugging.assert_equal(x=tf.reduce_any(input_tensor=terminal), y=terminal[-1])",
            "+            tf.debugging.assert_equal(x=tf.math.reduce_any(input_tensor=terminal), y=terminal[-1])",
            ")",
            "",
            "# Set global tensors"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6080,
        "label": "yes",
        "change": [
            "class EfficientFormer(nn.Module):",
            "def get_classifier(self):",
            "return self.head, self.head_dist",
            "",
            "-    def reset_classifier(self, num_classes, global_pool=None, distillation=None):",
            "+    def reset_classifier(self, num_classes, global_pool=None):",
            "self.num_classes = num_classes",
            "if global_pool is not None:",
            "self.global_pool = global_pool",
            "self.head = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()",
            "-        if self.dist:",
            "-            self.head_dist = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()",
            "+        self.head_dist = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()",
            "",
            "@torch.jit.ignore",
            "def set_distilled_training(self, enable=True):"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 6081,
        "label": "no",
        "change": [
            "def grid_index(height, width, device=None):",
            "",
            "",
            "def grid_pos(height, width, dtype=None, device=None):",
            "+    dtype = torch.float if dtype is None else dtype",
            "x = torch.arange(width, dtype=dtype, device=device)",
            "y = (height - 1) - torch.arange(height, dtype=dtype, device=device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6083,
        "label": "no",
        "change": [
            "class TestEndpointSpanExtractor:",
            "# for both the forward and backward directions.",
            "extractor = EndpointSpanExtractor(8, \"x,y\", use_exclusive_start_indices=True)",
            "indices = torch.LongTensor([[[1, 3], [2, 4]], [[0, 2], [0, 1]]])",
            "-        sequence_mask = torch.LongTensor([[1, 1, 1, 1, 1], [1, 1, 1, 0, 0]])",
            "+        sequence_mask = torch.BoolTensor(",
            "+            [[True, True, True, True, True], [True, True, True, False, False]]",
            "+        )",
            "",
            "span_representations = extractor(sequence_tensor, indices, sequence_mask=sequence_mask)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6084,
        "label": "yes",
        "change": [
            "class PretrainedTransformerEmbedder(TokenEmbedder):",
            "def get_output_dim(self):",
            "return self.output_dim",
            "",
            "-    def forward(self, token_ids: torch.LongTensor) -> torch.Tensor:  # type: ignore",
            "+    def forward(",
            "+        self, token_ids: torch.LongTensor, attention_mask: torch.LongTensor",
            "+    ) -> torch.Tensor:  # type: ignore",
            "",
            "-        return self.transformer_model(token_ids)[0]",
            "+        return self.transformer_model(input_ids=token_ids, attention_mask=attention_mask)[0]"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 6085,
        "label": "no",
        "change": [
            "class AcceleratorConnector(object):",
            "return len(gpus)",
            "",
            "@property",
            "-    def parallel_devices(self) -> Union[List[torch.device], int]:",
            "+    def parallel_devices(self) -> List[Union[torch.device, int]]:",
            "if self.on_gpu:",
            "devices = [torch.device(\"cuda\", i) for i in self.parallel_device_ids]",
            "elif self.on_tpu:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6088,
        "label": "no",
        "change": [
            "def main():",
            "mel_outputs, post_mel_outputs, stop_outputs, alignment_historys = tacotron2.inference(",
            "charactor,",
            "char_length,",
            "-            speaker_ids=tf.zeros(shape=[tf.shape(charactor)[0]]),",
            "+            speaker_ids=tf.zeros(shape=[tf.shape(charactor)[0]], dtype=tf.int32),",
            ")",
            "",
            "# convert to numpy"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6089,
        "label": "no",
        "change": [
            "class TestTransformLAFs:",
            "# projected should be equal as initial",
            "assert_allclose(lafs_src, lafs_dst_to_src)",
            "",
            "-    def test_gradcheck(self):",
            "+    def test_gradcheck(self, device):",
            "# generate input data",
            "batch_size, num_points, num_dims = 2, 3, 2",
            "eye_size = 3",
            "-        points_src = torch.rand(batch_size, num_points, 2, 3)",
            "-        dst_homo_src = utils.create_random_homography(batch_size, eye_size)",
            "+        points_src = torch.rand(batch_size, num_points, 2, 3).to(device)",
            "+        dst_homo_src = utils.create_random_homography(batch_size, eye_size).to(device)",
            "# evaluate function gradient",
            "points_src = utils.tensor_to_gradcheck_var(points_src)  # to var",
            "dst_homo_src = utils.tensor_to_gradcheck_var(dst_homo_src)  # to var"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6098,
        "label": "no",
        "change": [
            "def predict_generator(model, generator,",
            "warnings.warn(",
            "UserWarning('Using a generator with `use_multiprocessing=True`'",
            "' and multiple workers may duplicate your data.'",
            "-                        ' Please consider using the`keras.utils.Sequence'",
            "+                        ' Please consider using the `keras.utils.Sequence'",
            "' class.'))",
            "if steps is None:",
            "if use_sequence_api:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6099,
        "label": "yes",
        "change": [
            "torch_scatter = None",
            "def dev(x: torch.Tensor, as_native: bool = False) -> Union[ivy.Device, torch.device]:",
            "dv = x.device",
            "if as_native:",
            "-        return torch.device(dv.type.replace(\"gpu\", \"cuda\"))",
            "+        if isinstance(dv, torch.device):",
            "+            dv = dv.type",
            "+        return torch.device(dv.replace(\"gpu\", \"cuda\"))",
            "return as_ivy_dev(dv)"
        ],
        "comments": "",
        "Symptom": "return warning",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 6101,
        "label": "no",
        "change": [
            "def _nullspace(A):",
            "",
            "Return the smallest singular value and the corresponding vector.",
            "\"\"\"",
            "-    _, s, vh = torch.svd(A)",
            "-    return s[..., -1], vh[..., -1]",
            "+    _, s, v = _torch_svd_cast(A)",
            "+    return s[..., -1], v[..., -1]",
            "",
            "",
            "def projections_from_fundamental(F_mat: torch.Tensor) -> torch.Tensor:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6103,
        "label": "no",
        "change": [
            "class JigsawUnintendedBias(datasets.GeneratorBasedBuilder):",
            "",
            "if not os.path.exists(data_dir):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('jigsaw_unintended_bias', data_dir=...)`. Manual download instructions: {}\".format(",
            "-                    data_dir, self.manual_download_instructions",
            "-                )",
            "+                f\"{data_dir} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('jigsaw_unintended_bias', data_dir=...)`. Manual download instructions: {self.manual_download_instructions}\"",
            ")",
            "",
            "return ["
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6107,
        "label": "no",
        "change": [
            "class AudioDiffusionPipeline(DiffusionPipeline):",
            "input_dims = self.get_input_dims()",
            "self.mel.set_resolution(x_res=input_dims[1], y_res=input_dims[0])",
            "if noise is None:",
            "-            noise = torch.randn(",
            "+            noise = randn_tensor(",
            "(",
            "batch_size,",
            "self.unet.in_channels,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6108,
        "label": "no",
        "change": [
            "class Tester(unittest.TestCase):",
            "# create transformation (rotation)",
            "M = torch.tensor([[",
            "[torch.cos(alpha), -torch.sin(alpha), 0.],",
            "-            [torch.sin(alpha),  torch.cos(alpha), 0.],",
            "-            [              0.,                0., 1.],",
            "+            [torch.sin(alpha), torch.cos(alpha), 0.],",
            "+            [0., 0., 1.],",
            "]])  # Bx3x3",
            "M = utils.tensor_to_gradcheck_var(M, requires_grad=False)  # to var"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6109,
        "label": "no",
        "change": [
            "def to_hetero_with_bases(module: Module, metadata: Metadata, num_bases: int,",
            "import torch",
            "from torch_geometric.nn import SAGEConv, to_hetero_with_bases",
            "",
            "-        Net(torch.nn.Module):",
            "+        class GNN(torch.nn.Module):",
            "def __init__(self):",
            "-                self.conv1 = SAGEConv(16, 16)",
            "-                self.conv2 = SAGEConv(16, 16)",
            "+                self.conv1 = SAGEConv((16, 16), 32)",
            "+                self.conv2 = SAGEConv((32, 32), 32)",
            "",
            "def forward(self, x, edge_index):",
            "x = self.conv1(x, edge_index).relu()",
            "x = self.conv2(x, edge_index).relu()",
            "return x",
            "",
            "-        model = Net()",
            "+        model = GNN()",
            "",
            "node_types = ['paper', 'author']",
            "edge_types = ["
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6112,
        "label": "yes",
        "change": [
            "def median(",
            "temp = input",
            "if hasattr(axis, \"__iter__\"):",
            "for dim in axis:",
            "-            temp = torch.median(",
            "+            temp = torch.quantile(",
            "temp,",
            "+                0.5,",
            "dim=dim,",
            "keepdim=keepdims,",
            ")[0]",
            "-        return input",
            "+        return temp",
            "else:",
            "-        return torch.median(",
            "+        return torch.quantile(",
            "input,",
            "+            0.5,",
            "dim=axis,",
            "keepdim=keepdims,",
            ")[0]"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 6119,
        "label": "no",
        "change": [
            "def in_top_k(predictions, targets, k):",
            "`output[i]` is `True` if `predictions[i, targets[i]]` is within top-`k`",
            "values of `predictions[i]`.",
            "\"\"\"",
            "-    return tf_math_ops.in_top_k(tf.cast(predictions, 'float32'),",
            "-                                tf.cast(targets, 'int32'),",
            "-                                k)",
            "+    return tf.nn.in_top_k(tf.cast(predictions, 'float32'),",
            "+                          tf.cast(targets, 'int32'),",
            "+                          k)",
            "",
            "",
            "# CONVOLUTIONS"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6120,
        "label": "no",
        "change": [
            "class AGP_Pruner(Pruner):",
            "if epoch > 0:",
            "self.now_epoch = epoch",
            "for wrapper in self.get_modules_wrapper():",
            "-                wrapper.registered_buffers['if_calculated'].copy_(torch.tensor(0)) # pylint: disable=not-callable",
            "+                wrapper.if_calculated.copy_(torch.tensor(0)) # pylint: disable=not-callable",
            "",
            "class SlimPruner(Pruner):",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6121,
        "label": "yes",
        "change": [
            "def test_welford_dense(n_samples, dim_size):",
            "samples.append(sample)",
            "w.update(sample)",
            "",
            "-    sample_cov = np.cov(torch.stack(samples).data.numpy(), bias=False, rowvar=False)",
            "-    estimates = w.get_covariance(regularize=False).data.numpy()",
            "+    sample_cov = np.cov(torch.stack(samples).data.cpu().numpy(), bias=False, rowvar=False)",
            "+    estimates = w.get_covariance(regularize=False).data.cpu().numpy()",
            "assert_equal(estimates, sample_cov)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 6133,
        "label": "yes",
        "change": [
            "def mean_iou(",
            "# TODO: is it possible to vectorize this ?",
            "# iterate over classes",
            "for class_id in range(num_classes):",
            "-        tp: torch.Tensor = conf_mat[..., class_id, class_id].float()",
            "+        tp: torch.Tensor = conf_mat[..., None, class_id, class_id]",
            "total = torch.sum(conf_mat[..., class_id, :], dim=-1, keepdim=True) + \\",
            "torch.sum(conf_mat[..., :, class_id], dim=-1, keepdim=True)",
            "iou_val: torch.Tensor = tp / (total.float() - tp + 1e-6)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 6135,
        "label": "no",
        "change": [
            "def train():",
            "torch.save(chkpt, wdir + 'backup%g.pt' % epoch)",
            "",
            "# Delete checkpoint",
            "-            del chkpt  # end epoch -------------------------------------------------------------------------------------",
            "+            del chkpt",
            "+",
            "+        # end epoch ----------------------------------------------------------------------------------------------------",
            "",
            "# Report time",
            "plot_results()  # save as results.png"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6144,
        "label": "no",
        "change": [
            "class AutoRegressiveNNTests(TestCase):",
            "# NOTE: the hidden dimension must be greater than the input_dim for the",
            "# masks to be well-defined!",
            "hidden_dim = input_dim * 5",
            "-                        permutation = torch.randperm(input_dim)",
            "+                        permutation = torch.randperm(input_dim, device='cpu')",
            "self._test_masks(",
            "input_dim,",
            "observed_dim,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6149,
        "label": "no",
        "change": [
            "def mean_iou(",
            "torch.Tensor: a tensor representing the mean intersection-over union",
            "with shape :math:`(B, K)` where K is the number of classes.",
            "\"\"\"",
            "-    if not torch.is_tensor(input) and input.dtype is not torch.uint64:",
            "+    if not torch.is_tensor(input) and input.dtype is not torch.int64:",
            "raise TypeError(\"Input input type is not a torch.Tensor with \"",
            "\"torch.int64 dtype. Got {}\".format(type(input)))",
            "-    if not torch.is_tensor(target) and target.dtype is not torch.uint64:",
            "+    if not torch.is_tensor(target) and target.dtype is not torch.int64:",
            "raise TypeError(\"Input target type is not a torch.Tensor with \"",
            "\"torch.int64 dtype. Got {}\".format(type(target)))",
            "if not input.shape == target.shape:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6151,
        "label": "no",
        "change": [
            "def test(epoch, loader, string):",
            "for data in loader:",
            "adj, slice = data['adj']['content'], data['adj']['slice'][:, 0]",
            "input, target = data['input'], data['target']",
            "-        input = torch.cat([input, input.new(input.size(0)).fill_(1)], dim=1)",
            "+        input = torch.cat([input, input.new(input.size(0), 1).fill_(1)], dim=1)",
            "num_examples += target.size(0)",
            "",
            "if torch.cuda.is_available():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6153,
        "label": "no",
        "change": [
            "class StochasticSampling(Exploration):",
            "logp = action_dist.sampled_action_logp()",
            "else:",
            "action = action_dist.deterministic_sample()",
            "-            logp = torch.zeros((action.size()[0], ), dtype=torch.float32)",
            "+            logp = torch.zeros_like(action_dist.sampled_action_logp())",
            "return action, logp"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6162,
        "label": "no",
        "change": [
            "class TranslationVariableLanguages:",
            "",
            "```python",
            ">>> # At construction time:",
            "-    >>> datasets.features.Translation(languages=['en', 'fr', 'de'])",
            "+    >>> datasets.features.TranslationVariableLanguages(languages=['en', 'fr', 'de'])",
            ">>> # During data generation:",
            ">>> yield {",
            "...         'en': 'the cat',"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6164,
        "label": "no",
        "change": [
            "if __name__ == \"__main__\":",
            "help=\"run this example in GPU\")",
            "args = parser.parse_args()",
            "",
            "+    # work around the error \"CUDA error: initialization error\" when arg.cuda is False",
            "+    # see https://github.com/pytorch/pytorch/issues/2517",
            "+    if six.PY3:",
            "+        torch.multiprocessing.set_start_method(\"spawn\")",
            "pyro.set_rng_seed(args.rng_seed)",
            "# Enable validation checks",
            "pyro.enable_validation(__debug__)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6165,
        "label": "no",
        "change": [
            "class TestIntraSentenceAttentionEncoder(AllenNlpTestCase):",
            "similarity_function=similarity,",
            "num_attention_heads=3,",
            "combination=\"1+2\")",
            "-        input_tensor = Variable(torch.from_numpy(numpy.random.rand(4, 6, 24))).float()",
            "+        input_tensor = torch.from_numpy(numpy.random.rand(4, 6, 24)).float()",
            "encoder_output = encoder(input_tensor, None)",
            "assert list(encoder_output.size()) == [4, 6, 24]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6167,
        "label": "no",
        "change": [
            "class yolov3(object):",
            "# caculate iou between true boxes and pred boxes",
            "intersect_xy1 = tf.maximum(true_box_xy - true_box_wh / 2.0,",
            "pred_box_xy - pred_box_xy / 2.0)",
            "-        intersect_xy2 = tf.maximum(true_box_xy + true_box_wh / 2.0,",
            "+        intersect_xy2 = tf.minimum(true_box_xy + true_box_wh / 2.0,",
            "pred_box_xy + pred_box_wh / 2.0)",
            "intersect_wh = tf.maximum(intersect_xy2 - intersect_xy1, 0.)",
            "intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6170,
        "label": "no",
        "change": [
            "class SEWDModelIntegrationTest(unittest.TestCase):",
            ")",
            "expected_output_sum = 54201.0469",
            "",
            "-        self.assertTrue(torch.allclose(outputs[:, :4, :4], expected_outputs_first, atol=5e-3))",
            "-        self.assertTrue(torch.allclose(outputs[:, -4:, -4:], expected_outputs_last, atol=5e-3))",
            "-        self.assertTrue(abs(outputs.sum() - expected_output_sum) < 5)",
            "+        self.assertTrue(torch.allclose(outputs[:, :4, :4], expected_outputs_first, atol=1e-3))",
            "+        self.assertTrue(torch.allclose(outputs[:, -4:, -4:], expected_outputs_last, atol=1e-3))",
            "+        self.assertTrue(abs(outputs.sum() - expected_output_sum) < 1)",
            "",
            "def test_inference_ctc_batched(self):",
            "model = SEWDForCTC.from_pretrained(\"asapp/sew-d-tiny-100k-ft-ls100h\").to(torch_device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6172,
        "label": "no",
        "change": [
            "class LSTM(Model):",
            "self.state_in = [c_in, h_in]",
            "",
            "# Setup LSTM outputs",
            "+        state_in = rnn.LSTMStateTuple(c_in, h_in)",
            "lstm_out, lstm_state = tf.nn.dynamic_rnn(",
            "lstm,",
            "last_layer,",
            "+            initial_state=state_in,",
            "sequence_length=self.seq_lens,",
            "time_major=False,",
            "dtype=tf.float32)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6174,
        "label": "no",
        "change": [
            "class BLSTM_CRF(object):",
            "b = tf.get_variable(\"b\", shape=[self.hidden_unit], dtype=tf.float32,",
            "initializer=tf.zeros_initializer())",
            "output = tf.reshape(lstm_outputs, shape=[-1, self.hidden_unit * 2])",
            "-                hidden = tf.tanh(tf.nn.xw_plus_b(output, W, b))",
            "+                hidden = tf.nn.xw_plus_b(output, W, b)",
            "",
            "# project to score of tags",
            "with tf.variable_scope(\"logits\"):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6178,
        "label": "no",
        "change": [
            "def loss(net):",
            "confs = tf.mul(best_box, _confs)",
            "",
            "# take care of the weight terms",
            "-    weight_con = snoob*(1.-best_box) + sconf*best_box",
            "+    weight_con = snoob * (1. - confs) + sconf * confs",
            "conid = tf.mul(_conid, weight_con)",
            "-    weight_coo = tf.concat(3, 4 * [tf.expand_dims(best_box, -1)])",
            "+    weight_coo = tf.concat(3, 4 * [tf.expand_dims(confs, -1)])",
            "cooid = tf.mul(_cooid, scoor * weight_coo)",
            "proid = sprob * _proid"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6181,
        "label": "no",
        "change": [
            "class StableDiffusionImg2ImgPipelineIntegrationTests(unittest.TestCase):",
            "init_image = init_image.resize((768, 512))",
            "",
            "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(",
            "-            \"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16, device_map=\"auto\"",
            "+            \"CompVis/stable-diffusion-v1-4\",",
            "+            revision=\"fp16\",",
            "+            torch_dtype=torch.float16,",
            ")",
            "pipe.to(torch_device)",
            "pipe.set_progress_bar_config(disable=None)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6183,
        "label": "no",
        "change": [
            "class Keras2Parser(Parser):",
            "# load model files into Keras graph",
            "if isinstance(model, _string_types):",
            "try:",
            "-                from _keras.applications.mobilenet import relu6",
            "-                from _keras.applications.mobilenet import DepthwiseConv2D",
            "+                from keras.applications.mobilenet import relu6",
            "+                from keras.applications.mobilenet import DepthwiseConv2D",
            "model = _keras.models.load_model(",
            "model,",
            "custom_objects={"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6184,
        "label": "no",
        "change": [
            "def nonzero(x: torch.Tensor) -> Tuple[torch.Tensor]:",
            "return torch.nonzero(x, as_tuple=True)",
            "",
            "",
            "-def where(",
            "-    condition: torch.Tensor,",
            "-    x1: torch.Tensor,",
            "-    x2: torch.Tensor",
            "-) -> torch.Tensor:",
            "+def where(condition: torch.Tensor, x1: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:",
            "promoted_type = torch.promote_types(x1.dtype, x2.dtype)",
            "x1 = x1.to(promoted_type)",
            "x2 = x2.to(promoted_type)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6186,
        "label": "no",
        "change": [
            "class Synchronization(Optimizer):",
            "",
            "last_sync = tf.get_variable(",
            "name='last-sync',",
            "-            dtype=tf.int32,",
            "-            initializer=(-self.sync_frequency),",
            "+            dtype=tf.int64,",
            "+            initializer=tf.constant_initializer(value=(-self.sync_frequency), dtype=tf.int64),",
            "trainable=False",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6187,
        "label": "no",
        "change": [
            "class SingleCostFeedfreeTrainer(FeedfreeTrainer):",
            "cost_var = self.model.get_cost()",
            "# GATE_NONE faster?",
            "grads = self.config.optimizer.compute_gradients(",
            "-                cost_var, gate_gradients=0)",
            "+                cost_var,",
            "+                gate_gradients=tf.train.Optimizer.GATE_NONE,",
            "+                colocate_gradients_with_ops=False)",
            "add_moving_summary(cost_var)",
            "return cost_var, grads"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6189,
        "label": "no",
        "change": [
            "def create_modules(module_defs):",
            ")",
            "if bn:",
            "modules.add_module(f\"batch_norm_{module_i}\",",
            "-                                   nn.BatchNorm2d(filters, momentum=0.9, eps=1e-5))",
            "+                                   nn.BatchNorm2d(filters, momentum=0.1, eps=1e-5))",
            "if module_def[\"activation\"] == \"leaky\":",
            "modules.add_module(f\"leaky_{module_i}\", nn.LeakyReLU(0.1))",
            "if module_def[\"activation\"] == \"mish\":"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6191,
        "label": "no",
        "change": [
            "def test_table_to_pandas(dtype, dummy_value):",
            "features = datasets.Features({\"foo\": datasets.Array2D(dtype=dtype, shape=(2, 2))})",
            "dataset = datasets.Dataset.from_dict({\"foo\": [[[dummy_value] * 2] * 2]}, features=features)",
            "df = dataset._data.to_pandas()",
            "-    assert type(df.foo.dtype) == datasets.features.PandasArrayExtensionDtype",
            "+    assert type(df.foo.dtype) == PandasArrayExtensionDtype",
            "arr = df.foo.to_numpy()",
            "np.testing.assert_equal(arr, np.array([[[dummy_value] * 2] * 2], dtype=np.dtype(dtype)))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6194,
        "label": "no",
        "change": [
            "def attn(x, scope, n_state, *, past, params, train=False):",
            "",
            "def split_heads(x, last_dim):",
            "with tf.variable_scope('split_heads'):",
            "-        # From [batch, sequence, features] to [batch, heads, sequence, features_per_head]",
            "-        # heads is split out of features!",
            "-        x = mtf.reshape(x, [dim_batch, dim_seq, dim_heads, last_dim], name=\"split_heads_reshape\")",
            "-        x = mtf.transpose(x, [dim_batch, dim_heads, dim_seq, last_dim], name=\"split_heads_transpose\")",
            "+            # From [batch, sequence, features] to [batch, heads, sequence, features_per_head]",
            "+            # heads is split out of features!",
            "+            x = mtf.reshape(x, [dim_batch, dim_seq, dim_heads, last_dim], name=\"split_heads_reshape\")",
            "+            x = mtf.transpose(x, [dim_batch, dim_heads, dim_seq, last_dim], name=\"split_heads_transpose\")",
            "return x",
            "",
            "def merge_heads(x):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6195,
        "label": "no",
        "change": [
            "class BatchNormLayer(Layer):",
            "gamma = None",
            "",
            "# 2.",
            "-            moving_mean_init = tf.zeros_initializer()",
            "",
            "moving_mean = tf.get_variable(",
            "'moving_mean', params_shape, initializer=moving_mean_init, dtype=LayersConfig.tf_dtype, trainable=False"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6196,
        "label": "no",
        "change": [
            "def _update_confusion_matrix_variables_optimized(",
            "y_pred)",
            "if not multi_label:",
            "label_weights = tf.reshape(label_weights, [-1])",
            "-  weights = tf.multiply(sample_weights, label_weights)",
            "+  weights = tf.cast(tf.multiply(sample_weights, label_weights), y_true.dtype)",
            "",
            "# We shouldn't need this, but in case there are predict value that is out of",
            "# the range of [0.0, 1.0]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6197,
        "label": "no",
        "change": [
            "class Attention(torch.nn.Module, Registrable):",
            "",
            "@overrides",
            "def forward(",
            "-        self, vector: torch.Tensor, matrix: torch.Tensor, matrix_mask: torch.Tensor = None",
            "+        self, vector: torch.Tensor, matrix: torch.Tensor, matrix_mask: torch.BoolTensor = None",
            ") -> torch.Tensor:",
            "similarities = self._forward_internal(vector, matrix)",
            "if self._normalize:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6200,
        "label": "no",
        "change": [
            "class MultiheadAttention(nn.Module):",
            "",
            "for key, value in items_to_add.items():",
            "state_dict[key] = value",
            "-",
            "-        return state_dict"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6201,
        "label": "no",
        "change": [
            "def matrix_rank(",
            "x = tf.expand_dims(x, 0)",
            "x, rtol = ivy.promote_types_of_inputs(x, rtol)",
            "ret = tf.linalg.matrix_rank(x, rtol)",
            "-    ret = tf.cast(ret, ivy.default_float_dtype(as_native=True))",
            "+    ret = tf.cast(ret, ivy.default_int_dtype(as_native=True))",
            "return ret"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6202,
        "label": "no",
        "change": [
            "def convert_models(model_path: str, output_path: str, opset: int):",
            "unet_path = output_path / \"unet\" / \"model.onnx\"",
            "onnx_export(",
            "pipeline.unet,",
            "-        model_args=(torch.randn(2, 4, 64, 64), torch.LongTensor([0, 1]), torch.randn(2, 77, 768), False),",
            "+        model_args=(",
            "+            torch.randn(2, pipeline.unet.in_channels, 64, 64),",
            "+            torch.LongTensor([0, 1]),",
            "+            torch.randn(2, 77, 768),",
            "+            False,",
            "+        ),",
            "output_path=unet_path,",
            "ordered_input_names=[\"sample\", \"timestep\", \"encoder_hidden_states\", \"return_dict\"],",
            "output_names=[\"out_sample\"],  # has to be different from \"sample\" for correct tracing"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6206,
        "label": "no",
        "change": [
            "from tinygrad.llops.ops_cpu import unary_op, binary_op, reduce_op, movement_op",
            "",
            "from tinygrad.ops import ProcessingOps",
            "",
            "-def processing_op(op,x,w,ret,C):",
            "+def processing_op(ctx,op,x,w,out_shape,C):",
            "assert op == ProcessingOps.CONV, f\"{op} isn't supported\"",
            "-  ret[:] = torch.conv2d(x, w, stride=(C.ys, C.xs), groups=C.groups, dilation=(C.dy, C.dx), padding=(C.py, C.px))",
            "+  return torch.conv2d(x, w, stride=(C.ys, C.xs), groups=C.groups, dilation=(C.dy, C.dx), padding=(C.py, C.px))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6207,
        "label": "no",
        "change": [
            "class Dropout(Layer):",
            "return tf.cond(",
            "pred=update,",
            "true_fn=(lambda: tf.nn.dropout(x=x, keep_prob=(1.0 - self.rate))),",
            "-            false_fn=(lambda: x)",
            "+            false_fn=(lambda: tf.identity(input=x))",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6208,
        "label": "no",
        "change": [
            "class TestKNN(unittest.TestCase):",
            "",
            "def test_knn_vs_python_cuda(self):",
            "\"\"\" Test CUDA output vs PyTorch implementation \"\"\"",
            "-        device = torch.device('cuda')",
            "+        device = torch.device(\"cuda\")",
            "Ns = [1, 4]",
            "Ds = [2, 3, 8]",
            "P1s = [1, 8, 64, 128, 1001]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6212,
        "label": "no",
        "change": [
            "def sparse_dropout(x, keep_prob, noise_shape):",
            "random_tensor += tf.random_uniform(noise_shape)",
            "dropout_mask = tf.cast(tf.floor(random_tensor), dtype=tf.bool)",
            "pre_out = tf.sparse_retain(x, dropout_mask)",
            "-    return pre_out * tf.inv(keep_prob)",
            "+    return pre_out * (1./keep_prob)",
            "",
            "",
            "def dot(x, y, sparse=False):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6216,
        "label": "no",
        "change": [
            "def do_test_log_likelihood(run,",
            "prev_reward_batch=np.array([prev_r]))",
            "check(np.exp(logp), expected_prob, atol=0.2)",
            "",
            "+        if eager_ctx:",
            "+            eager_ctx.__exit__(None, None, None)",
            "+",
            "",
            "class TestComputeLogLikelihood(unittest.TestCase):",
            "def test_dqn(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6218,
        "label": "no",
        "change": [
            "def train(args, logdir1, logdir2):",
            "# )",
            "",
            "session_inits = []",
            "-    ckpt2 = args.ckpt if args.ckpt else tf.train.latest_checkpoint(logdir2)",
            "+    ckpt2 = '{}/{}'.format(logdir2, args.ckpt) if args.ckpt else tf.train.latest_checkpoint(logdir2)",
            "if ckpt2:",
            "session_inits.append(SaverRestore(ckpt2))",
            "ckpt1 = tf.train.latest_checkpoint(logdir1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6219,
        "label": "yes",
        "change": [
            "class BeamSearch(Search):",
            "scores_buf = top_prediction[0]",
            "indices_buf = top_prediction[1]",
            "# Project back into relative indices and beams",
            "-        beams_buf = indices_buf // vocab_size",
            "+        beams_buf = torch.div(indices_buf, vocab_size, rounding_mode='trunc')",
            "indices_buf = indices_buf.fmod(vocab_size)",
            "",
            "# At this point, beams_buf and indices_buf are single-dim and contain relative indices"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 6221,
        "label": "no",
        "change": [
            "def main():",
            "global_step += 1",
            "",
            "# Save a trained model",
            "-        if args.do_train and ( n_gpu > 1 and torch.distributed.get_rank() == 0  or n_gpu <=1):",
            "+        if args.do_train and (args.local_rank == -1 or torch.distributed.get_rank() == 0):",
            "logger.info(\"** ** * Saving fine - tuned model ** ** * \")",
            "model.save_pretrained(args.output_dir)",
            "tokenizer.save_pretrained(args.output_dir)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6224,
        "label": "no",
        "change": [
            "class TestModelCloning(keras_parameterized.TestCase):",
            "run_eagerly=testing_utils.should_run_eagerly())",
            "new_model.train_on_batch([val_a, val_b], val_out)",
            "",
            "+    # New model should use provided input tensors",
            "+    self.assertListEqual(new_model.inputs, new_input_tensors)",
            "+",
            "# On top of new, non-Keras tensors",
            "if not tf.executing_eagerly():",
            "# TODO(b/121277734):Skip Eager contexts, as Input() layers raise an error"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6225,
        "label": "no",
        "change": [
            "def cart2pol(x: torch.Tensor, y: torch.Tensor, eps: float = 1.0e-8) -> Tuple[tor",
            "if not (isinstance(x, torch.Tensor) & isinstance(y, torch.Tensor)):",
            "raise TypeError(f\"Input type is not a torch.Tensor. Got {type(x)}, {type(y)}\")",
            "",
            "-    rho = torch.sqrt(x ** 2 + y ** 2 + eps)",
            "+    rho = torch.sqrt(x**2 + y**2 + eps)",
            "phi = torch.atan2(y, x)",
            "return rho, phi"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6228,
        "label": "no",
        "change": [
            "def test_train_acc():",
            "pytest.importorskip(\"torch\")",
            "import torch",
            "",
            "-    from espnet.nets.pytorch.e2e_asr_th import pad_list",
            "-    from espnet.nets.pytorch.e2e_asr_th import th_accuracy",
            "+    from espnet.nets.pytorch.e2e_asr import pad_list",
            "+    from espnet.nets.pytorch.e2e_asr import th_accuracy",
            "",
            "n_out = 7",
            "_eos = n_out - 1"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6229,
        "label": "no",
        "change": [
            "def spdz_mul(x, y, workers, mod=field):",
            "delta = delta.broadcast(workers)",
            "epsilon = epsilon.broadcast(workers)",
            "",
            "-    z = torch.fmod((c",
            "-                    + torch.fmod((delta * b), mod)",
            "-                    + torch.fmod((epsilon * a), mod)",
            "-                    ), mod)",
            "-",
            "+    z = torch.fmod(",
            "+        (c + torch.fmod((delta * b), mod) + torch.fmod((epsilon * a), mod)), mod",
            "+    )",
            "",
            "z.child.public_add_(epsilon_delta)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6230,
        "label": "no",
        "change": [
            "class TestPatchSequential:",
            "input = torch.randn(*shape, device=device, dtype=dtype)",
            "out = seq(input)",
            "if seq.return_label:",
            "-            out, label = out",
            "+            out, _ = out",
            "assert out.shape[-3:] == input.shape[-3:]",
            "",
            "reproducibility_test(input, seq)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6234,
        "label": "no",
        "change": [
            "class Categorical(Distribution):",
            "self.probabilities = tf.nn.softmax(logits=self.logits, dim=-1)",
            "",
            "# \"normalized\" logits",
            "-        self.logits = tf.log(x=self.probabilities)",
            "+        self.logits = tf.log(x=self.probabilities + util.epsilon)",
            "",
            "# General distribution values",
            "self.distribution = (self.logits,)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6235,
        "label": "no",
        "change": [
            "def _compute_mask_indices(",
            "tf.ones_like(spec_aug_mask_idxs), spec_aug_mask_idxs, spec_aug_mask.shape",
            ")",
            "",
            "-    return tf.cast(spec_aug_mask, tf.float32)",
            "+    return spec_aug_mask",
            "",
            "",
            "# Copied from transformers.models.bart.modeling_tf_bart._expand_mask"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6241,
        "label": "no",
        "change": [
            "def get_config():",
            "optimizer=tf.train.AdamOptimizer(lr, beta1=0.5, epsilon=1e-3),",
            "callbacks=Callbacks([",
            "StatPrinter(), ModelSaver(),",
            "-            ScheduledHyperParamSetter('learning_rate', [(200, 1e-4)])",
            "]),",
            "session_config=get_default_sess_config(0.5),",
            "model=Model(),",
            "step_per_epoch=300,",
            "-        max_epoch=300,",
            "+        max_epoch=200,",
            ")",
            "",
            "def sample(model_path):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6242,
        "label": "no",
        "change": [
            "class Pipeline(_ScikitCompat):",
            "elif device < 0:",
            "self.device = torch.device(\"cpu\")",
            "else:",
            "-                self.device = torch.device(\"cuda:{device}\")",
            "+                self.device = torch.device(f\"cuda:{device}\")",
            "else:",
            "self.device = device",
            "self.binary_output = binary_output"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6245,
        "label": "no",
        "change": [
            "def check_file(file, suffix=''):",
            "return files[0]  # return file",
            "",
            "",
            "-def check_font(font=FONT):",
            "+def check_font(font=FONT, progress=False):",
            "# Download font to CONFIG_DIR if necessary",
            "font = Path(font)",
            "if not font.exists() and not (CONFIG_DIR / font.name).exists():",
            "url = \"https://ultralytics.com/assets/\" + font.name",
            "LOGGER.info(f'Downloading {url} to {CONFIG_DIR / font.name}...')",
            "-        torch.hub.download_url_to_file(url, str(font), progress=False)",
            "+        torch.hub.download_url_to_file(url, str(font), progress=progress)",
            "",
            "",
            "def check_dataset(data, autodownload=True):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6247,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "# weight decay on all W of fc layers",
            "wd_w = tf.train.exponential_decay(1e-4, get_global_step_var(),",
            "200000, 0.7, True)",
            "-        wd_w = wd_w / tf.get_default_graph().get_tensor_by_name('learning_rate')",
            "wd_cost = tf.mul(wd_w, regularize_cost('.*/W', tf.nn.l2_loss), name='l2_regularize_loss')",
            "add_moving_summary(loss, wd_cost)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6248,
        "label": "no",
        "change": [
            "\"execution_count\": 127,",
            "\"metadata\": {},",
            "\"outputs\": [],",
            "-   \"source\": [",
            "-    \"c = a.add(b).get()\"",
            "-   ]",
            "+   \"source\": []",
            "},",
            "{",
            "\"cell_type\": \"code\","
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6250,
        "label": "no",
        "change": [
            "class NesT(nn.Module):",
            "Aggregate(dim_in, dim_out) if not is_last else nn.Identity()",
            "]))",
            "",
            "+",
            "self.mlp_head = nn.Sequential(",
            "-            LayerNorm(dim),",
            "+            LayerNorm(last_dim),",
            "Reduce('b c h w -> b c', 'mean'),",
            "-            nn.Linear(dim, num_classes)",
            "+            nn.Linear(last_dim, num_classes)",
            ")",
            "",
            "def forward(self, img):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6251,
        "label": "no",
        "change": [
            "class MARWILPolicy(MARWILPostprocessing, TFPolicy):",
            "self.output_actions = action_dist.sample()",
            "",
            "# Training inputs",
            "-        self.act_t = tf.placeholder(tf.int32, [None], name=\"action\")",
            "+        self.act_t = ModelCatalog.get_action_placeholder(action_space)",
            "self.cum_rew_t = tf.placeholder(tf.float32, [None], name=\"reward\")",
            "",
            "# v network evaluation"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6257,
        "label": "no",
        "change": [
            "class DummyMaskedLMTask(FairseqTask):",
            "'id': 1,",
            "'net_input': {",
            "'src_tokens': torch.stack([self.dummy_src for _ in range(bsz)]),",
            "-                    'src_lengths': torch.full((bsz, ), self.args.tokens_per_sample),",
            "+                    'src_lengths': torch.full(",
            "+                        (bsz, ), self.args.tokens_per_sample, dtype=torch.long",
            "+                    ),",
            "},",
            "'target': torch.stack([self.dummy_tgt for _ in range(bsz)]),",
            "'nsentences': bsz,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6260,
        "label": "yes",
        "change": [
            "class NanDetector:",
            "def _detect(self, tensor, name, backward):",
            "err = None",
            "if (",
            "-            tensor.numel() >= 2",
            "-        ):  # single value tensors (like the loss) will not provide much info",
            "+            torch.is_floating_point(tensor)",
            "+            # single value tensors (like the loss) will not provide much info",
            "+            and tensor.numel() >= 2",
            "+        ):",
            "with torch.no_grad():",
            "if torch.isnan(tensor).any():",
            "err = \"NaN\""
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 6262,
        "label": "yes",
        "change": [
            "class MetaLayer(torch.nn.Module):",
            "# u: [B, F_u]",
            "# batch: [N] with max entry B - 1.",
            "row, col = edge_index",
            "-                out = torch.cat([x[col], edge_attr], dim=1)",
            "+                out = torch.cat([x[row], edge_attr], dim=1)",
            "out = self.node_mlp_1(out)",
            "-                out = scatter_mean(out, row, dim=0, dim_size=x.size(0))",
            "+                out = scatter_mean(out, col, dim=0, dim_size=x.size(0))",
            "out = torch.cat([x, out, u[batch]], dim=1)",
            "return self.node_mlp_2(out)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 6269,
        "label": "no",
        "change": [
            "class TFModel(metaclass=TfModelMeta):",
            "print('\\n:: Model saved to {} \\n'.format(self._model_path.as_posix()))",
            "",
            "def get_checkpoint_state(self):",
            "-        return tf.train.get_checkpoint_state(self._model_path.as_posix())",
            "+        return tf.train.get_checkpoint_state(self._model_path.parent)",
            "",
            "def load(self):",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6270,
        "label": "no",
        "change": [
            "class GlowTTS(BaseTTS):",
            "o_mean, o_log_scale, o_dur_log, x_mask = self.encoder(x, x_lengths, g=g)",
            "# compute output durations",
            "w = (torch.exp(o_dur_log) - 1) * x_mask * self.length_scale",
            "-        w_ceil = torch.ceil(w)",
            "+        w_ceil = torch.clamp_min(torch.ceil(w), 1)",
            "y_lengths = torch.clamp_min(torch.sum(w_ceil, [1, 2]), 1).long()",
            "y_max_length = None",
            "# compute masks"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6272,
        "label": "no",
        "change": [
            "class TransfoXLModel(TransfoXLPreTrainedModel):",
            "mask_shift_len = qlen",
            "dec_attn_mask = (torch.triu(all_ones, 1 + mlen) + torch.tril(all_ones, -mask_shift_len))[:, :, None]  # -1",
            "else:",
            "-            dec_attn_mask = torch.triu(word_emb.new_ones((qlen, klen), dtype=torch.uint8), diagonal=1 + mlen)[",
            "+            dec_attn_mask = torch.triu(word_emb.new_ones((qlen, klen), dtype=torch.bool), diagonal=1 + mlen)[",
            ":, :, None",
            "]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6274,
        "label": "no",
        "change": [
            "class Categorical(Distribution):",
            "def log_prob(self, dist, actions):",
            "prob = dist['policy_output']",
            "",
            "-        return tf.log(tf.reduce_sum(tf.multiply(prob, actions), [1]) + self.epsilon)",
            "+        return tf.log(tf.reduce_sum(tf.multiply(prob, actions), [2]) + self.epsilon)",
            "",
            "def fixed_kl(self, dist):",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6277,
        "label": "yes",
        "change": [
            "def mu_law_encode(audio, quantization_channels):",
            "with tf.name_scope('encode'):",
            "mu = quantization_channels - 1",
            "# Perform mu-law companding transformation (ITU-T, 1988).",
            "-        magnitude = tf.log(1 + mu * tf.abs(audio)) / tf.log(1. + mu)",
            "+        # Minimum operation is here to deal with rare large amplitudes caused by resampling.",
            "+        magnitude = tf.log(1 + mu * tf.minimum(tf.abs(audio), 1.0)) / tf.log(1. + mu)",
            "signal = tf.sign(audio) * magnitude",
            "# Quantize signal to the specified number of levels.",
            "return tf.cast((signal + 1) / 2 * mu + 0.5, tf.int32)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 6282,
        "label": "no",
        "change": [
            "class Model():",
            "# convert inputs to tensor if it is originally not",
            "if isinstance(inputs, list):",
            "for idx in range(len(inputs)):",
            "-                if isinstance(inputs[idx], np.ndarray):",
            "-                    inputs[idx] = tf.convert_to_tensor(inputs[idx])",
            "+                inputs[idx] = tf.convert_to_tensor(inputs[idx])",
            "elif isinstance(inputs, np.ndarray):",
            "inputs = tf.convert_to_tensor(inputs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6288,
        "label": "no",
        "change": [
            "def decode(args):",
            "def _convert_att_ws_to_durations(att_ws):",
            "# get the most diagonal attention among the all of the sournce attentions for transformer",
            "if len(att_ws.shape) == 4:",
            "-            att_ws = torch.cat([att_w for att_w in att_ws], axis=0)  # (#heads * #layers, L, T)",
            "+            att_ws = torch.cat([att_w for att_w in att_ws], dim=0)  # (#heads * #layers, L, T)",
            "diagonal_scores = att_ws.max(dim=-1)[0].mean(dim=-1).mean(dim=0)  # (#heads * #layers,)",
            "diagonal_head_idx = diagonal_scores.argmax()",
            "att_ws = att_ws[diagonal_head_idx]  # (L, T)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6294,
        "label": "no",
        "change": [
            "class AMPTestModel(BoringModel):",
            "16,",
            "pytest.param(",
            "\"bf16\",",
            "-            marks=pytest.mark.skipif(not _TORCH_GREATER_EQUAL_1_10, reason=\"torch.bfloat16 not available\"),",
            "+            marks=pytest.mark.skipif(not _TORCH_BFLOAT_AVAILABLE, reason=\"torch.bfloat16 not available\"),",
            "),",
            "],",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6306,
        "label": "no",
        "change": [
            "def dropout_node(edge_index: Tensor, p: float = 0.5,",
            "num_nodes = maybe_num_nodes(edge_index, num_nodes)",
            "",
            "if not training or p == 0.0:",
            "-        node_mask = edge_index.new_zeros(num_nodes, dtype=torch.bool)",
            "-        edge_mask = edge_index.new_zeros(edge_index.size(1), dtype=torch.bool)",
            "+        node_mask = edge_index.new_ones(num_nodes, dtype=torch.bool)",
            "+        edge_mask = edge_index.new_ones(edge_index.size(1), dtype=torch.bool)",
            "return edge_index, edge_mask, node_mask",
            "",
            "prob = torch.rand(num_nodes, device=edge_index.device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6309,
        "label": "no",
        "change": [
            "class DenseFeatures(dense_features.DenseFeatures):",
            "```python",
            "price = tf.feature_column.numeric_column('price')",
            "keywords_embedded = tf.feature_column.embedding_column(",
            "-      tf.feature_column.categorical_column_with_hash_bucket(\"keywords\", 10K),",
            "+      tf.feature_column.categorical_column_with_hash_bucket(\"keywords\", 10000),",
            "dimensions=16)",
            "columns = [price, keywords_embedded, ...]",
            "feature_layer = tf.keras.layers.DenseFeatures(columns)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6310,
        "label": "no",
        "change": [
            "class ViTMSNForImageClassification(ViTMSNPreTrainedModel):",
            ">>> from PIL import Image",
            ">>> import requests",
            "",
            "-        >>> torch.manual_seed(2)",
            "+        >>> torch.manual_seed(2)  # doctest: +IGNORE_RESULT",
            "",
            ">>> url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"",
            ">>> image = Image.open(requests.get(url, stream=True).raw)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6311,
        "label": "no",
        "change": [
            "def optimize_model():",
            "expected_state_action_values = (next_state_values * GAMMA) + reward_batch",
            "",
            "# Compute Huber loss",
            "-    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))",
            "+    criterion = nn.SmoothL1Loss()",
            "+    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))",
            "",
            "# Optimize the model",
            "optimizer.zero_grad()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6315,
        "label": "no",
        "change": [
            "def MusicTaggerCRNN(weights='msd', input_tensor=None,",
            "else:",
            "# Load weights",
            "if K.image_dim_ordering() == 'tf':",
            "-            raise RuntimeError(\"Please set image_dim_ordering == 'th'.\"",
            "-                               \"You can set it at ~/.keras/keras.json\")",
            "+            raise RuntimeError('Please set `image_dim_ordering` to \"th\".'",
            "+                               'You can set it at `~/.keras/keras.json`.')",
            "",
            "if K._BACKEND == 'theano':",
            "weights_path = get_file('music_tagger_crnn_weights_theano.h5',"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6316,
        "label": "yes",
        "change": [
            "class GARPNHead(GuidedAnchorHead):",
            "if cfg.min_bbox_size > 0:",
            "w = proposals[:, 2] - proposals[:, 0]",
            "h = proposals[:, 3] - proposals[:, 1]",
            "-                valid_inds = torch.nonzero((w >= cfg.min_bbox_size) &",
            "-                                           (h >= cfg.min_bbox_size)).squeeze()",
            "+                valid_inds = torch.nonzero(",
            "+                    (w >= cfg.min_bbox_size) & (h >= cfg.min_bbox_size),",
            "+                    as_tuple=False).squeeze()",
            "proposals = proposals[valid_inds, :]",
            "scores = scores[valid_inds]",
            "proposals = torch.cat([proposals, scores.unsqueeze(-1)], dim=-1)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 6321,
        "label": "no",
        "change": [
            "def test_max_iou_assigner_with_empty_gt():",
            "[5, 5, 15, 15],",
            "[32, 32, 38, 42],",
            "])",
            "-    gt_bboxes = torch.FloatTensor([])",
            "+    gt_bboxes = torch.empty(0, 4)",
            "assign_result = self.assign(bboxes, gt_bboxes)",
            "",
            "expected_gt_inds = torch.LongTensor([0, 0, 0, 0])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6323,
        "label": "no",
        "change": [
            "def get_text_field_mask(",
            "",
            "TODO(joelgrus): can we change this?",
            "NOTE: Our functions for generating masks create torch.LongTensors, because using",
            "-    torch.ByteTensors  makes it easy to run into overflow errors",
            "+    torch.ByteTensors makes it easy to run into overflow errors",
            "when doing mask manipulation, such as summing to get the lengths of sequences - see below.",
            ">>> mask = torch.ones([260]).byte()",
            ">>> mask.sum() # equals 260."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6327,
        "label": "no",
        "change": [
            "class DownloadCommand(BaseTransformersCLICommand):",
            "self._force = force",
            "",
            "def run(self):",
            "-        from transformers import AutoModel, AutoTokenizer",
            "+        from ..models.auto import AutoModel, AutoTokenizer",
            "",
            "AutoModel.from_pretrained(self._model, cache_dir=self._cache, force_download=self._force)",
            "AutoTokenizer.from_pretrained(self._model, cache_dir=self._cache, force_download=self._force)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6328,
        "label": "no",
        "change": [
            "def train(args):",
            "elif ngpu > 1:",
            "gpu_id = range(ngpu)",
            "logging.info('gpu id: ' + str(gpu_id))",
            "-        model = torch.nn.DataParallel(model, device_ids=gpu_id)",
            "+        model = DataParallel(model, device_ids=gpu_id)",
            "model.cuda()",
            "logging.info('batch size is automatically increased (%d -> %d)' % (",
            "args.batch_size, args.batch_size * args.ngpu))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6333,
        "label": "no",
        "change": [
            "class PyTorchProfiler(BaseProfiler):",
            "# close profiler if it is already opened. might happen if 2 profilers",
            "# are created and the first one did not call `describe`",
            "try:",
            "-                torch.autograd._disable_profiler()  # noqa",
            "+                torch.autograd._disable_profiler()",
            "except (AttributeError, RuntimeError):",
            "pass"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6341,
        "label": "no",
        "change": [
            "class PadLayer(Layer):",
            "self.inputs = prev_layer.outputs",
            "",
            "if padding is None:",
            "-            raise Exception(\"padding should be a Tensor of type int32. see https://www.tensorflow.org/api_docs/python/tf/pad\")",
            "+            raise Exception(",
            "+                \"padding should be a Tensor of type int32. see https://www.tensorflow.org/api_docs/python/tf/pad\"",
            "+            )",
            "",
            "self.outputs = tf.pad(self.inputs, paddings=padding, mode=mode, name=name)",
            "self.all_layers.append(self.outputs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6347,
        "label": "no",
        "change": [
            "class TFFunnelRelMultiheadAttention(tf.keras.layers.Layer):",
            "attn_score = tf.cast(attn_score, tf.float32)",
            "# perform masking",
            "if attention_mask is not None:",
            "-            attn_score = attn_score - INF * tf.cast(attention_mask[:, None, None], tf.float32)",
            "+            attn_score = attn_score - INF * (1 - tf.cast(attention_mask[:, None, None], tf.float32))",
            "# attention probability",
            "attn_prob = tf.nn.softmax(attn_score, axis=-1)",
            "if dtype != tf.float32:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6348,
        "label": "no",
        "change": [
            "class TestRandomEqualizeAlternative(CommonTests):",
            "",
            "with pytest.raises(ValueError):",
            "self._create_augmentation_from_params(p=1.0)(",
            "-                torch.ones((1, 3, 4, 5) * 200, device=self.device, dtype=self.dtype)",
            "+                torch.ones((1, 3, 4, 5) * 3, device=self.device, dtype=self.dtype)",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6351,
        "label": "no",
        "change": [
            "class Layer_Convolution_1D_Test(CustomTestCase):",
            "cls.input_layer = Input(cls.inputs_shape, name='input_layer')",
            "",
            "cls.dense = tl.layers.Dense(",
            "-            n_units=100, act=tf.nn.relu, in_channels=200, name='dense'",
            "+            n_units=100, act=tf.nn.relu, in_channels=200",
            ")(cls.input_layer)",
            "",
            "cls.noiselayer = tl.layers.GaussianNoise("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6352,
        "label": "no",
        "change": [
            "class InstanceBalancedPosSampler(RandomSampler):",
            "num_per_gt = int(round(num_expected / float(num_gts)) + 1)",
            "sampled_inds = []",
            "for i in unique_gt_inds:",
            "-                inds = torch.nonzero(assign_result.gt_inds == i.item())",
            "+                inds = torch.nonzero(",
            "+                    assign_result.gt_inds == i.item(), as_tuple=False)",
            "if inds.numel() != 0:",
            "inds = inds.squeeze(1)",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6355,
        "label": "no",
        "change": [
            "class BagOfEmbeddingsEncoder(Seq2VecEncoder):",
            "def get_output_dim(self) -> int:",
            "return self._embedding_dim",
            "",
            "-    def forward(self, tokens: torch.Tensor, mask: torch.Tensor = None):  #pylint: disable=arguments-differ",
            "+    def forward(self, tokens: torch.Tensor, mask: torch.Tensor = None):",
            "if mask is not None:",
            "tokens = tokens * mask.unsqueeze(-1).float()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6356,
        "label": "no",
        "change": [
            "with tf.Graph().as_default() as G:",
            "init = sessinit.ParamRestore(np.load(args.model).item())",
            "else:",
            "init = sessinit.SaverRestore(args.model)",
            "-    sess = tf.Session()",
            "+    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))",
            "init.init(sess)",
            "",
            "# dump ..."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6363,
        "label": "no",
        "change": [
            "class KarrasVeScheduler(SchedulerMixin, ConfigMixin):",
            "",
            "TODO Args:",
            "\"\"\"",
            "-        if self.s_min <= sigma <= self.s_max:",
            "-            gamma = min(self.s_churn / self.num_inference_steps, 2**0.5 - 1)",
            "+        if self.config.s_min <= sigma <= self.config.s_max:",
            "+            gamma = min(self.config.s_churn / self.num_inference_steps, 2**0.5 - 1)",
            "else:",
            "gamma = 0",
            "",
            "# sample eps ~ N(0, S_noise^2 * I)",
            "-        eps = self.s_noise * torch.randn(sample.shape, generator=generator).to(sample.device)",
            "+        eps = self.config.s_noise * torch.randn(sample.shape, generator=generator).to(sample.device)",
            "sigma_hat = sigma + gamma * sigma",
            "sample_hat = sample + ((sigma_hat**2 - sigma**2) ** 0.5 * eps)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6365,
        "label": "no",
        "change": [
            "def create_model_inputs_tf(",
            "def run_tf_model(",
            "model: tf.Module, input_tensors: Tuple[tf.Tensor]",
            ") -> Tuple[tf.Tensor]:",
            "-    pred = model.predict(*input_tensors)",
            "+    pred = model.predict(input_tensors)",
            "if isinstance(pred, tf.Module) and pred is not None:",
            "pred = (pred,)",
            "return pred"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6366,
        "label": "no",
        "change": [
            "class Decoder(torch.nn.Module):",
            "self.decoder = torch.nn.ModuleList()",
            "self.dropout_dec = torch.nn.ModuleList()",
            "self.decoder += [torch.nn.LSTMCell(dunits + eprojs, dunits)]",
            "+        self.dropout_dec += [torch.nn.Dropout(p=dropout)]",
            "for _ in six.moves.range(1, self.dlayers):",
            "self.decoder += [torch.nn.LSTMCell(dunits, dunits)]",
            "self.dropout_dec += [torch.nn.Dropout(p=dropout)]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6370,
        "label": "no",
        "change": [
            "def xlogy(",
            "return torch.xlogy(x, y, out=out)",
            "",
            "",
            "-def real(x: Union[torch.Tensor],",
            "-         /,",
            "-         *,",
            "-         out: Optional[torch.Tensor] = None) -> torch.Tensor:",
            "+def real(",
            "+    x: Union[torch.Tensor], /, *, out: Optional[torch.Tensor] = None",
            "+) -> torch.Tensor:",
            "return torch.real(x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6372,
        "label": "no",
        "change": [
            "class Layer_DeformableConvolution_Test(unittest.TestCase):",
            "",
            "",
            "if __name__ == '__main__':",
            "-    # tl.logging.set_verbosity(tl.logging.INFO)",
            "+",
            "+    tf.logging.set_verbosity(tf.logging.DEBUG)",
            "tl.logging.set_verbosity(tl.logging.DEBUG)",
            "",
            "unittest.main()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6374,
        "label": "no",
        "change": [
            "def main():",
            "extension = \"text\"",
            "dataset = load_dataset(extension, data_files=data_files, cache_dir=model_args.cache_dir)",
            "",
            "-        if \"validation\" not in datasets.keys():",
            "-            datasets[\"validation\"] = load_dataset(",
            "+        if \"validation\" not in dataset.keys():",
            "+            dataset[\"validation\"] = load_dataset(",
            "extension,",
            "data_files=data_files,",
            "split=f\"train[:{data_args.validation_split_percentage}%]\",",
            "cache_dir=model_args.cache_dir,",
            ")",
            "-            datasets[\"train\"] = load_dataset(",
            "+            dataset[\"train\"] = load_dataset(",
            "extension,",
            "data_files=data_files,",
            "split=f\"train[{data_args.validation_split_percentage}%:]\","
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6376,
        "label": "yes",
        "change": [
            "class VideoSequential(ImageSequential):",
            "data_format: str = \"BTCHW\",",
            "same_on_frame: bool = True,",
            "random_apply: Union[int, bool, Tuple[int, int]] = False,",
            "+        random_apply_weights: Optional[List[float]] = None,",
            ") -> None:",
            "-        super().__init__(*args, same_on_batch=None, return_transform=None, keepdim=None, random_apply=random_apply)",
            "+        super().__init__(",
            "+            *args, same_on_batch=None, return_transform=None, keepdim=None, random_apply=random_apply,",
            "+            random_apply_weights=random_apply_weights",
            "+        )",
            "self.same_on_frame = same_on_frame",
            "self.data_format = data_format.upper()",
            "if self.data_format not in [\"BCTHW\", \"BTCHW\"]:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 6380,
        "label": "no",
        "change": [
            "class PreTrainedModel(nn.Module):",
            "model = BertModel.from_pretrained('./tf_model/my_tf_checkpoint.ckpt.index', from_tf=True, config=config)",
            "",
            "\"\"\"",
            "-        if pretrained_model_name_or_path is not None and (",
            "-                \"albert\" in pretrained_model_name_or_path and \"v2\" in pretrained_model_name_or_path):",
            "-            logger.warning(\"There is currently an upstream reproducibility issue with ALBERT v2 models. Please see \" +",
            "-                           \"https://github.com/google-research/google-research/issues/119 for more information.\")",
            "-",
            "config = kwargs.pop('config', None)",
            "state_dict = kwargs.pop('state_dict', None)",
            "cache_dir = kwargs.pop('cache_dir', None)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6382,
        "label": "yes",
        "change": [
            "def model(X, params, mesh, labels=None, past=None, scope='model', reuse=False, t",
            "# wpe has shape [ctx, embd]",
            "# positions_for would have shape [batch, seq]",
            "# h has shape [batch, seq, embd]",
            "-        zerodim = mtf.Dimension('singleton', 0)",
            "",
            "-        h = mtf.gather(wte, X, zerodim) + mtf.gather(wpe, positions_for(X, past_length, batch_dim), zerodim)",
            "+        h = mtf.gather(wte, X, vocab_dim) + mtf.gather(wpe, positions_for(X, past_length, batch_dim), vocab_dim)",
            "",
            "# Transformer",
            "presents = []"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 6384,
        "label": "no",
        "change": [
            "def _get_output_dicts(config: Dict[str, Any]) -> str:",
            "results = []",
            "for feature in config[\"output_features\"]:",
            "name = feature[NAME]",
            "-        results.append(\"{\" + f'\"{name}\": results[\"{name}\"][\"predictions\"]' + \"}\")",
            "-    return \", \".join(results)",
            "+        results.append(f'\"{name}\": results[\"{name}\"][\"predictions\"]')",
            "+    return \"{\" + \", \".join(results) + \"}\"",
            "",
            "",
            "def generate_neuropod_torchscript(model: LudwigModel):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6386,
        "label": "no",
        "change": [
            "class Detect(nn.Module):",
            "",
            "@staticmethod",
            "def _make_grid(nx=20, ny=20):",
            "-        yv, xv = torch.meshgrid([torch.arange(ny), torch.arange(nx)], indexing=\"ij\")",
            "+        # yv, xv = torch.meshgrid([torch.arange(ny), torch.arange(nx)], indexing=\"ij\") # for pytorch>=1.10",
            "+        yv, xv = torch.meshgrid([torch.arange(ny), torch.arange(nx)])",
            "return torch.stack((xv, yv), 2).view((1, 1, ny, nx, 2)).float()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6389,
        "label": "no",
        "change": [
            "class CRF(torch.nn.Module):",
            "self.transitions.detach()[:, tag_dictionary.get_idx_for_item(STOP_TAG)] = -10000",
            "self.to(flair.device)",
            "",
            "-    def forward(self, features: torch.tensor) -> torch.tensor:",
            "+    def forward(self, features: torch.Tensor) -> torch.Tensor:",
            "\"\"\"",
            "Forward propagation of Conditional Random Field.",
            ":param features: output from RNN / Linear layer in shape (batch size, seq len, hidden size)",
            ":return: CRF scores (emission scores for each token + transitions prob from previous state) in",
            "shape (batch_size, seq len, tagset size, tagset size)",
            "\"\"\"",
            "-        batch_size = features.size(0)",
            "-        seq_len = features.size(1)",
            "+        batch_size, seq_len, _, _ = features.size()",
            "",
            "emission_scores = features",
            "emission_scores = emission_scores.unsqueeze(-1).expand(batch_size, seq_len, self.tagset_size, self.tagset_size)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6394,
        "label": "no",
        "change": [
            "def flatten_and_batch_shift_indices(indices: torch.Tensor,",
            "offset_indices : ``torch.LongTensor``",
            "\"\"\"",
            "# Shape: (batch_size)",
            "+    if torch.max(indices) >= sequence_length or torch.min(indices) < 0:",
            "+        raise ConfigurationError(f\"All elements in indices should be in range (0, {sequence_length - 1})\")",
            "offsets = get_range_vector(indices.size(0), get_device_of(indices)) * sequence_length",
            "for _ in range(len(indices.size()) - 1):",
            "offsets = offsets.unsqueeze(1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6400,
        "label": "no",
        "change": [
            "class Beta(Distribution):",
            "",
            "sampled = beta_sample / tf.maximum(x=(alpha_sample + beta_sample), y=epsilon)",
            "",
            "-        sampled = tf.where(condition=(temperature < epsilon), x=definite, y=sampled)",
            "+        action = tf.where(condition=(temperature < epsilon), x=definite, y=sampled)",
            "",
            "min_value = tf_util.constant(value=self.action_spec.min_value, dtype='float')",
            "max_value = tf_util.constant(value=self.action_spec.max_value, dtype='float')",
            "",
            "with tf.control_dependencies(control_inputs=dependencies):",
            "-            return min_value + (max_value - min_value) * sampled",
            "+            return min_value + (max_value - min_value) * action",
            "",
            "@tf_function(num_args=2)",
            "def log_probability(self, *, parameters, action):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6401,
        "label": "no",
        "change": [
            "class TFT5ForConditionalGeneration(TFT5PreTrainedModel, TFCausalLanguageModeling",
            ")",
            "",
            "def serving_output(self, output):",
            "-        pkv = (tf.convert_to_tensor(output.past_key_values[1:]) if self.config.use_cache else None,)",
            "+        pkv = tf.convert_to_tensor(output.past_key_values[1:]) if self.config.use_cache else None",
            "dec_hs = tf.convert_to_tensor(output.decoder_hidden_states) if self.config.output_hidden_states else None",
            "dec_attns = tf.convert_to_tensor(output.decoder_attentions) if self.config.output_attentions else None",
            "enc_hs = tf.convert_to_tensor(output.encoder_hidden_states) if self.config.output_hidden_states else None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6402,
        "label": "no",
        "change": [
            "def diff(",
            "append: Optional[Union[torch.Tensor, int, float, list, tuple]] = None,",
            ") -> torch.Tensor:",
            "x = x if type(x) == torch.Tensor else torch.Tensor(x)",
            "-    prepend = prepend if type(prepend) == torch.Tensor else torch.Tensor(prepend)",
            "-    append = append if type(append) == torch.Tensor else torch.Tensor(append)",
            "+    prepend = prepend if type(prepend) == torch.Tensor or prepend == None else torch.Tensor(prepend)",
            "+    append = append if type(append) == torch.Tensor or append == None else torch.Tensor(append)",
            "return torch.diff(x, n=n, dim=axis, prepend=prepend, append=append)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6404,
        "label": "no",
        "change": [
            "class SetInputFeature(SetFeatureMixin, InputFeature):",
            "",
            "def forward(self, inputs):",
            "assert isinstance(inputs, torch.Tensor)",
            "-        assert inputs.dtype in [torch.bool, torch.int64]",
            "+        assert inputs.dtype in [torch.bool, torch.int64, torch.float32]",
            "",
            "encoder_output = self.encoder_obj(inputs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6405,
        "label": "no",
        "change": [
            "class ImageGPTAttention(nn.Module):",
            "if not self.is_cross_attention:",
            "# if only \"normal\" attention layer implements causal mask",
            "query_length, key_length = query.size(-2), key.size(-2)",
            "-            causal_mask = self.bias[:, :, key_length - query_length : key_length, :key_length].bool()",
            "+            causal_mask = self.bias[:, :, key_length - query_length : key_length, :key_length]",
            "mask_value = torch.finfo(attn_weights.dtype).min",
            "# Need to be a tensor, otherwise we get error: `RuntimeError: expected scalar type float but found double`.",
            "# Need to be on the same device, otherwise `RuntimeError: ..., x and y to be on the same device`"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6408,
        "label": "no",
        "change": [
            "def sum(",
            "return x.type(dtype)",
            "axis = tuple(axis) if isinstance(axis, list) else axis",
            "if axis is None:",
            "-        return torch.sum(input=x, dtype=dtype)",
            "+        return torch.sum(input=x, dim=(), dtype=dtype, keepdim=keepdims)",
            "return torch.sum(input=x, dim=axis, dtype=dtype, keepdim=keepdims)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6410,
        "label": "no",
        "change": [
            "class EntropyTest(AllenNlpTestCase):",
            "logits = torch.tensor(",
            "[[1, 1, 1, 1], [10000, -10000, -10000, -1000]], dtype=torch.float, device=device",
            ")",
            "-        mask = torch.tensor([0, 1], device=device)",
            "+        mask = torch.BoolTensor([False, True], device=device)",
            "metric(logits, mask)",
            "assert metric.get_metric() == 0.0"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6412,
        "label": "no",
        "change": [
            "class OriNet(nn.Module):",
            "# use torch.hub to load pretrained model",
            "if pretrained:",
            "storage_fcn: Callable = lambda storage, loc: storage",
            "-            pretrained_dict = torch.hub.load_state_dict_from_url(",
            "-                urls['orinet'], map_location=storage_fcn",
            "-            )",
            "+            pretrained_dict = torch.hub.load_state_dict_from_url(urls['orinet'], map_location=storage_fcn)",
            "self.load_state_dict(pretrained_dict['state_dict'], strict=False)",
            "self.eval()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6413,
        "label": "no",
        "change": [
            "class TrainerIOMixin(ABC):",
            "#     checkpoint = torch.load(checkpoint_path)",
            "# else:",
            "# load on CPU first",
            "-        checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)",
            "+        checkpoint = pl_load(checkpoint_path, map_location=lambda storage, loc: storage)",
            "",
            "# load model state",
            "model = self.get_model()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6415,
        "label": "yes",
        "change": [
            "def run_api_experiment(input_features, output_features, dataset, **kwargs):",
            "loaded_state = loaded_model.model.state_dict()",
            "bcast_state = hvd.broadcast_object(loaded_state)",
            "for loaded, bcast in zip(loaded_state.values(), bcast_state.values()):",
            "-            assert np.allclose(loaded, bcast)",
            "+            assert torch.allclose(loaded, bcast)",
            "finally:",
            "if output_dir:",
            "shutil.rmtree(output_dir, ignore_errors=True)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 6421,
        "label": "no",
        "change": [
            "class TestLaplacian(BaseTester):",
            "kernel_size = 3",
            "",
            "# evaluate function gradient",
            "-        input = torch.rand(batch_shape, device=device)",
            "-        input = tensor_to_gradcheck_var(input)",
            "-        self.gradcheck(laplacian, (input, kernel_size))",
            "+        sample = torch.rand(batch_shape, device=device)",
            "+        sample = tensor_to_gradcheck_var(sample)",
            "+        self.gradcheck(laplacian, (sample, kernel_size))",
            "",
            "def test_module(self, device, dtype):",
            "params = [3]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6423,
        "label": "no",
        "change": [
            "def interpolate(x_values,",
            "# dx = x_data[indices + 1] - x_data[indices]",
            "# dy = y_data[indices + 1] - y_data[indices]",
            "# indices is a tensor with different values per row/spline",
            "-    # Hence use a selection matrix with gather_nd",
            "def get_slice(x, encoding):",
            "if optimize_for_tpu:",
            "return tf.math.reduce_sum(tf.expand_dims(x, axis=-2) * encoding,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6428,
        "label": "no",
        "change": [
            "class TrainerDPMixin(ABC):",
            "if isinstance(device_ids, int):",
            "device_ids = list(range(device_ids))",
            "",
            "+        # set dp device",
            "+        torch.cuda.set_device(self.root_gpu)",
            "+",
            "model = LightningDataParallel(model, device_ids=device_ids)",
            "",
            "self.run_pretrain_routine(model)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6437,
        "label": "no",
        "change": [
            "bn_opt = optim.SGD(bn.parameters(), lr=1.0)",
            "for group_num in (range(args.world_size//args.group_size)):",
            "group_ids = range(group_num*args.group_size, (group_num+1)*args.group_size)",
            "cur_group = torch.distributed.new_group(ranks=group_ids)",
            "-   if (args.local_rank//args.group_size == group_num):",
            "+   if (torch.distributed.get_rank()//args.group_size == group_num):",
            "group = cur_group",
            "",
            "sbn = apex.parallel.SyncBatchNorm(feature_size, process_group=group).cuda()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6438,
        "label": "no",
        "change": [
            "ARGS = {",
            "dist.Geometric: [0.5],",
            "dist.Independent: [dist.Normal(torch.zeros(2), torch.ones(2)), 1],",
            "dist.LowRankMultivariateNormal: [torch.zeros(2), torch.ones(2, 2), torch.ones(2)],",
            "-    dist.MaskedMixture: [torch.tensor([1, 0]).byte(), dist.Normal(0, 1), dist.Normal(0, 2)],",
            "+    dist.MaskedMixture: [torch.tensor([1, 0]).bool(), dist.Normal(0, 1), dist.Normal(0, 2)],",
            "dist.MixtureOfDiagNormals: [torch.ones(2, 3), torch.ones(2, 3), torch.ones(2)],",
            "dist.MixtureOfDiagNormalsSharedCovariance: [torch.ones(2, 3), torch.ones(3), torch.ones(2)],",
            "dist.Multinomial: [2, torch.ones(2)],"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6439,
        "label": "no",
        "change": [
            "class RecipeNlg(datasets.GeneratorBasedBuilder):",
            "path_to_manual_file = os.path.abspath(os.path.expanduser(dl_manager.manual_dir))",
            "if not os.path.exists(path_to_manual_file):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('recipe_nlg', data_dir=...)` that includes file name {}. Manual download instructions: {}\".format(",
            "-                    path_to_manual_file,",
            "-                    _FILENAME,",
            "-                    self.manual_download_instructions,",
            "-                )",
            "+                f\"{path_to_manual_file} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('recipe_nlg', data_dir=...)` that includes file name {_FILENAME}. Manual download instructions: {self.manual_download_instructions}\"",
            ")",
            "return [",
            "datasets.SplitGenerator("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6446,
        "label": "no",
        "change": [
            "class Replay(Queue):",
            "random_episode_indices = tf.random_uniform(shape=(n,), maxval=(self.episode_count + 1), dtype=tf.int32)",
            "starts = tf.gather(params=self.episode_indices, indices=random_episode_indices) + 1",
            "limits = tf.gather(params=self.episode_indices, indices=(random_episode_indices + 1))",
            "-        limits += tf.where(condition=(starts < limits), x=0, y=self.capacity)",
            "+        limits += tf.where(condition=(starts < limits), x=(0,), y=self.capacity)",
            "episodes = [tf.range(start=starts[n], limit=limits[n]) for k in range(n)]",
            "indices = tf.concat(values=episodes, axis=0) % self.capacity",
            "return self.retrieve_indices(indices=indices)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6447,
        "label": "no",
        "change": [
            "import logging",
            "logger = logging.getLogger(__name__)",
            "",
            "TorchTrainer = None",
            "-TorchTrainable = None",
            "TrainingOperator = None",
            "+BaseTorchTrainable = None",
            "",
            "try:",
            "import torch  # noqa: F401",
            "",
            "-    from ray.util.sgd.torch.torch_trainer import (TorchTrainer, TorchTrainable)",
            "+    from ray.util.sgd.torch.torch_trainer import (TorchTrainer,",
            "+                                                  BaseTorchTrainable)",
            "",
            "from ray.util.sgd.torch.training_operator import TrainingOperator",
            "",
            "-    __all__ = [\"TorchTrainer\", \"TorchTrainable\", \"TrainingOperator\"]",
            "+    __all__ = [\"TorchTrainer\", \"BaseTorchTrainable\", \"TrainingOperator\"]",
            "except ImportError:",
            "logger.warning(\"PyTorch not found. TorchTrainer will not be available\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6453,
        "label": "no",
        "change": [
            "class BeamSearch(torch.nn.Module):",
            "",
            "\"\"\"",
            "if self._do_pre_beam(scores):",
            "-            return torch.topk(scores[self.pre_beam_score_key], self.pre_beam_size)[1]",
            "+            return torch.topk(scores[self.pre_beam_score_key], self.pre_beam_size, dim=-1)[1]",
            "else:",
            "return torch.arange(self.n_vocab, device=device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6455,
        "label": "yes",
        "change": [
            "def rand_segments(",
            "T = segment_size",
            "if _x_lenghts is None:",
            "_x_lenghts = T",
            "-    len_diff = _x_lenghts - segment_size + 1",
            "+    len_diff = _x_lenghts - segment_size",
            "if let_short_samples:",
            "_x_lenghts[len_diff < 0] = segment_size",
            "-        len_diff = _x_lenghts - segment_size + 1",
            "+        len_diff = _x_lenghts - segment_size",
            "else:",
            "assert all(",
            "len_diff > 0",
            "), f\" [!] At least one sample is shorter than the segment size ({segment_size}). \\n {_x_lenghts}\"",
            "-    segment_indices = (torch.rand([B]).type_as(x) * len_diff).long()",
            "-    ret = segment(x, segment_indices, segment_size)",
            "+    segment_indices = (torch.rand([B]).type_as(x) * (len_diff + 1)).long()",
            "+    ret = segment(x, segment_indices, segment_size, pad_short=pad_short)",
            "return ret, segment_indices"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 6458,
        "label": "no",
        "change": [
            "class LSTMEncoder(FairseqEncoder):",
            "x = x.transpose(0, 1)",
            "",
            "# pack embedded source tokens into a PackedSequence",
            "-        packed_x = nn.utils.rnn.pack_padded_sequence(x, src_lengths.data)",
            "+        packed_x = nn.utils.rnn.pack_padded_sequence(",
            "+            x, src_lengths.data, enforce_sorted=enforce_sorted",
            "+        )",
            "",
            "# apply LSTM",
            "if self.bidirectional:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6459,
        "label": "no",
        "change": [
            "def find_interval_index(query_xs,",
            "# cap to last_index - 1.",
            "caps = last_index - tf.cast(should_cap, dtype=tf.dtypes.int32)",
            "",
            "-    return tf.where(last_interval_is_closed, tf.minimum(indices, caps), indices)",
            "+    return tf.compat.v1.where(last_interval_is_closed,",
            "+                              tf.minimum(indices, caps), indices)",
            "",
            "",
            "def _piecewise_constant_function(x, jump_locations, values, side='left'):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6461,
        "label": "no",
        "change": [
            "def ndim(x):",
            "2",
            "```",
            "\"\"\"",
            "-    if is_sparse(x):",
            "-        return x._dims",
            "-",
            "dims = x.get_shape()._dims",
            "if dims is not None:",
            "return len(dims)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6463,
        "label": "no",
        "change": [
            "class BottleneckCSP(nn.Module):",
            "self.cv3 = nn.Conv2d(c_, c_, 1, 1, bias=False)",
            "self.cv4 = Conv(2 * c_, c2, 1, 1)",
            "self.bn = nn.BatchNorm2d(2 * c_)  # applied to cat(cv2, cv3)",
            "-        self.act = nn.LeakyReLU(0.1, inplace=True)",
            "+        self.act = nn.SiLU()",
            "self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)))",
            "",
            "def forward(self, x):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6467,
        "label": "yes",
        "change": [
            "def log_tensorboard_graph(tb, model, imgsz=(640, 640)):",
            "try:",
            "p = next(model.parameters())  # for device, type",
            "imgsz = (imgsz, imgsz) if isinstance(imgsz, int) else imgsz  # expand",
            "-        im = torch.empty((1, 3, *imgsz)).to(p.device).type_as(p)  # input image",
            "+        im = torch.zeros((1, 3, *imgsz)).to(p.device).type_as(p)  # input image (WARNING: must be zeros, not empty)",
            "with warnings.catch_warnings():",
            "warnings.simplefilter('ignore')  # suppress jit trace warning",
            "tb.add_graph(torch.jit.trace(de_parallel(model), im, strict=False), [])"
        ],
        "comments": "",
        "Symptom": "return warning",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 6468,
        "label": "no",
        "change": [
            "class TensorFlowVariables(object):",
            "def set_weights(self, new_weights):",
            "\"\"\"Sets the weights to new_weights.\"\"\"",
            "self._check_sess()",
            "-    self.sess.run(self.assignment_nodes, feed_dict={self.assignment_placeholders[name]: value for (name, value) in new_weights.items()})",
            "+    self.sess.run(self.assignment_nodes, feed_dict={self.placeholders[name]: value for (name, value) in new_weights.items()})"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6470,
        "label": "no",
        "change": [
            "def get_best_span(span_start_logits: torch.Tensor, span_end_logits: torch.Tensor",
            "span_log_probs = span_start_logits.unsqueeze(2) + span_end_logits.unsqueeze(1)",
            "# Only the upper triangle of the span matrix is valid; the lower triangle has entries where",
            "# the span ends before it starts.",
            "-    span_log_mask = torch.triu(torch.ones((passage_length, passage_length),",
            "-                                          device=device)).log()",
            "+    span_log_mask = torch.triu(torch.ones((passage_length, passage_length), device=device)).log()",
            "valid_span_log_probs = span_log_probs + span_log_mask",
            "",
            "# Here we take the span matrix and flatten it, then find the best span using argmax.  We"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6476,
        "label": "no",
        "change": [
            "class BiDynamicRNNLayer(Layer):",
            "",
            "print(\"     n_params : %d\" % (len(rnn_variables)))",
            "# Manage the outputs",
            "-            outputs = tf.concat(-1, outputs)",
            "+            outputs = tf.concat(2, outputs)",
            "if return_last:",
            "# [batch_size, 2 * n_hidden]",
            "self.outputs = advanced_indexing_op(outputs, sequence_length)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6479,
        "label": "no",
        "change": [
            "class Conv2dStaticSamePadding(nn.Conv2d):",
            "pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)",
            "pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)",
            "if pad_h > 0 or pad_w > 0:",
            "-            self.static_padding = nn.ZeroPad2d((pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2))",
            "+            self.static_padding = nn.ZeroPad2d((pad_w - pad_w // 2, pad_w - pad_w // 2,",
            "+                                                pad_h - pad_h // 2, pad_h - pad_h // 2))",
            "else:",
            "self.static_padding = Identity()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6486,
        "label": "no",
        "change": [
            "class TestSamplePoints(TestCaseMixin, unittest.TestCase):",
            "x, y, z = samples[1, :].unbind(1)",
            "radius = torch.sqrt(x ** 2 + y ** 2 + z ** 2)",
            "",
            "-        self.assertClose(radius, torch.ones((num_samples)))",
            "+        self.assertClose(radius, torch.ones(num_samples))",
            "",
            "# Pyramid: points shoudl lie on one of the faces.",
            "pyramid_verts = samples[2, :]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6489,
        "label": "yes",
        "change": [
            "class LayerNorm2d(nn.LayerNorm):",
            "return F.layer_norm(",
            "x.permute(0, 2, 3, 1), self.normalized_shape, self.weight, self.bias, self.eps).permute(0, 3, 1, 2)",
            "else:",
            "-            s, u = torch.var_mean(x, dim=1, keepdim=True)",
            "+            s, u = torch.var_mean(x, dim=1, unbiased=False, keepdim=True)",
            "x = (x - u) * torch.rsqrt(s + self.eps)",
            "x = x * self.weight[:, None, None] + self.bias[:, None, None]",
            "return x"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 6490,
        "label": "no",
        "change": [
            "def batch_normalization(incoming, beta=0.0, gamma=1.0, epsilon=1e-5,",
            "",
            "# Retrieve variable managing training mode",
            "is_training = tflearn.get_training_mode()",
            "-        mean, var = tf.python.control_flow_ops.cond(",
            "+        mean, var = tf.cond(",
            "is_training, update_mean_var, lambda: (moving_mean, moving_variance))",
            "",
            "try:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6494,
        "label": "no",
        "change": [
            "class FunnelModelIntegrationTest(unittest.TestCase):",
            "inputs = tokenizer(\"Hello! I am the Funnel Transformer model.\", return_tensors=\"pt\")",
            "output = model(**inputs)[0]",
            "",
            "-        expected_output_sum = torch.tensor(235.7827)",
            "+        expected_output_sum = torch.tensor(235.7246)",
            "expected_output_mean = torch.tensor(0.0256)",
            "self.assertTrue(torch.allclose(output.sum(), expected_output_sum, atol=1e-4))",
            "self.assertTrue(torch.allclose(output.mean(), expected_output_mean, atol=1e-4))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6495,
        "label": "no",
        "change": [
            "def create_torch_ast() -> Globals:",
            "path=method, framework_reference=torch, return_type_name=return_type",
            ")",
            "else:",
            "-            print(f\"Skipping torch.{method} not supported in {TORCH_VERSION}\")",
            "+            pass",
            "+            # TODO: Replace with logging",
            "+            # print(f\"Skipping {method} not supported in {TORCH_VERSION}\")",
            "",
            "for klass in ast.classes:",
            "klass.create_pointer_class()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6496,
        "label": "no",
        "change": [
            "class TFOptimizer(Optimizer):",
            "loss = fn_loss(**arguments)",
            "",
            "# The actual tensorflow minimize op.",
            "-        with tf.control_dependencies(control_inputs=(loss,)):",
            "-            # colocate_gradients_with_ops=True",
            "-            applied = self.optimizer.minimize(loss=loss, var_list=variables)",
            "+        applied = self.optimizer.minimize(loss=loss, var_list=variables)",
            "+        # colocate_gradients_with_ops=True",
            "",
            "# Return deltas after actually having change the variables.",
            "with tf.control_dependencies(control_inputs=(applied,)):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6500,
        "label": "no",
        "change": [
            "class TestPointMeshDistance(TestCaseMixin, unittest.TestCase):",
            "start = faces_first_idx[i]",
            "end = faces_first_idx[i + 1] if i < N - 1 else faces_packed.shape[0]",
            "",
            "-            min_idx = idx_cuda.cpu()[start:end] - points_first_idx[i]",
            "+            min_idx = idx_cuda.cpu()[start:end] - points_first_idx[i].cpu()",
            "iidx = torch.arange(tris.shape[0], device=device)",
            "min_dist = dists_temp[iidx, min_idx]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6504,
        "label": "yes",
        "change": [
            "def build_lm_labels(sequence, pad_token):",
            "def build_mask(sequence, pad_token):",
            "\"\"\" Builds the mask. The attention mechanism will only attend to positions",
            "with value 1. \"\"\"",
            "-    mask = sequence.clone()",
            "-    mask[mask != pad_token] = 1",
            "-    mask[mask == pad_token] = 0",
            "+    mask = torch.ones_like(sequence)",
            "+    idx_pad_tokens = (sequence == pad_token)",
            "+    mask[idx_pad_tokens] = 0",
            "return mask"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 6505,
        "label": "no",
        "change": [
            "class TFModelTesterMixin:",
            "for module_member_name in dir(module)",
            "if module_member_name.endswith(\"MainLayer\")",
            "for module_member in (getattr(module, module_member_name),)",
            "-            if isinstance(module_member, type) and tf.keras.layers.Layer in module_member.__bases__",
            "-            and getattr(module_member, '_keras_serializable', False)",
            "+            if isinstance(module_member, type)",
            "+            and tf.keras.layers.Layer in module_member.__bases__",
            "+            and getattr(module_member, \"_keras_serializable\", False)",
            ")",
            "for main_layer_class in tf_main_layer_classes:",
            "main_layer = main_layer_class(config)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6508,
        "label": "yes",
        "change": [
            "class TFTransfoXLMainLayer(tf.keras.layers.Layer):",
            "",
            "# There are `mlen + qlen` steps that can be cached into mems",
            "new_mems = []",
            "-        end_idx = mlen + max(0, qlen)",
            "-        beg_idx = max(0, end_idx - self.mem_len)",
            "+        end_idx = mlen + tf.math.maximum(0, qlen)",
            "+        beg_idx = tf.math.maximum(0, end_idx - tf.convert_to_tensor(self.mem_len))",
            "for i in range(len(hids)):",
            "",
            "cat = tf.concat([mems[i], hids[i]], axis=0)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 6510,
        "label": "no",
        "change": [
            "class Newsroom(datasets.GeneratorBasedBuilder):",
            "description=_DESCRIPTION,",
            "features=datasets.Features(features),",
            "supervised_keys=(_DOCUMENT, _SUMMARY),",
            "-            homepage=\"http://lil.datasets.cornell.edu/newsroom/\",",
            "+            homepage=\"https://lil.nlp.cornell.edu/newsroom/index.html\",",
            "citation=_CITATION,",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6511,
        "label": "no",
        "change": [
            "if is_torch_available():",
            ")",
            "",
            "if is_torch_higher_equal_than_1_12:",
            "-        torch_device = \"mps\" if torch.backends.mps.is_available() else torch_device",
            "+        # Some builds of torch 1.12 don't have the mps backend registered. See #892 for more details",
            "+        mps_backend_registered = hasattr(torch.backends, \"mps\")",
            "+        torch_device = \"mps\" if (mps_backend_registered and torch.backends.mps.is_available()) else torch_device",
            "",
            "",
            "def get_tests_dir(append_path=None):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6515,
        "label": "no",
        "change": [
            "\"torch.Size([5])\"",
            "]",
            "},",
            "-     \"execution_count\": 10,",
            "+     \"execution_count\": 11,",
            "\"metadata\": {},",
            "\"output_type\": \"execute_result\"",
            "}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6516,
        "label": "no",
        "change": [
            "class ConvDecoder(AbsDecoder):",
            ")",
            "",
            "def forward(self, input: torch.Tensor, ilens: torch.Tensor):",
            "-        \"\"\"",
            "+        \"\"\"Forward.",
            "+",
            "Args:",
            "-            input (torch.Tensor): spectrum [Batch, T, F]",
            "-            ilens (torch.Tensor): input lengths [Batch]",
            "+        input (torch.Tensor): spectrum [Batch, T, F]",
            "+        ilens (torch.Tensor): input lengths [Batch]",
            "\"\"\"",
            "input = input.transpose(1, 2)",
            "batch_size = input.shape[0]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6517,
        "label": "yes",
        "change": [
            "def from_tfds_to_path(tfds_dataset_name: str, split: str, hub_ds_path: str, batc",
            "return from_tfds(tfds_ds=tfds_ds, ds=ds)",
            "",
            "",
            "-def from_tfds(tfds_ds: (tensorflow.data.Dataset), ds: (Dataset)):",
            "+def from_tfds(tfds_ds: tensorflow.data.Dataset, ds: Dataset):",
            "+    \"\"\"Converts a tfds dataset to hub dataset",
            "+    Args:",
            "+        tfds_ds (tensorflow.data.Dataset): A tfds_dataset object.",
            "+        ds (Dataset) : A Hub dataset object where Tensor will be created.",
            "+    Returns:",
            "+        A hub dataset",
            "+    \"\"\"",
            "tfds_numpy = tfds.as_numpy(tfds_ds)  # Convert `tf.data.Dataset` to Python generator",
            "",
            "for ex in tqdm(tfds_numpy):"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 6518,
        "label": "no",
        "change": [
            "class PerceiverMLP(nn.Module):",
            "self.intermediate_act_fn = ACT2FN[config.hidden_act]",
            "else:",
            "self.intermediate_act_fn = config.hidden_act",
            "-        self.dense2 = nn.Linear(input_size, input_size)",
            "+        self.dense2 = nn.Linear(widening_factor * input_size, input_size)",
            "",
            "def forward(self, hidden_states):",
            "hidden_states = self.dense1(hidden_states)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6519,
        "label": "no",
        "change": [
            "def BatchNorm(x, use_local_stat=None, decay=0.9, epsilon=1e-5,",
            "return tf.identity(xn, name='output')",
            "",
            "",
            "+# TODO support NCHW",
            "@layer_register(log_shape=False)",
            "def BatchRenorm(x, rmax, dmax, decay=0.9, epsilon=1e-5,",
            "use_scale=True, use_bias=True):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6526,
        "label": "no",
        "change": [
            "class SimOTAAssigner(BaseAssigner):",
            "def dynamic_k_matching(self, cost, pairwise_ious, num_gt, valid_mask):",
            "matching_matrix = torch.zeros_like(cost)",
            "# select candidate topk ious for dynamic-k calculation",
            "-        topk_ious, _ = torch.topk(pairwise_ious, self.candidate_topk, dim=0)",
            "+        candidate_topk = min(self.candidate_topk, pairwise_ious.size(0))",
            "+        topk_ious, _ = torch.topk(pairwise_ious, candidate_topk, dim=0)",
            "# calculate dynamic k for each gt",
            "dynamic_ks = torch.clamp(topk_ious.sum(0).int(), min=1)",
            "for gt_idx in range(num_gt):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6528,
        "label": "no",
        "change": [
            "class EncdecMultiheadAttn(nn.Module):",
            "self.register_parameter('lyr_norm_beta_weights', None)",
            "self.lyr_nrm_gamma_weights = None",
            "self.lyr_nrm_beta_weights  = None",
            "-                self.lyr_nrm = torch.nn.LayerNorm(embed_dim)",
            "+                self.lyr_nrm = FusedLayerNorm(embed_dim)",
            "self.reset_parameters()",
            "-",
            "+",
            "if self.include_norm_add:",
            "if   impl == 'fast'    : self.attn_func = fast_encdec_attn_norm_add_func",
            "elif impl == 'default' : self.attn_func = encdec_attn_func"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6529,
        "label": "no",
        "change": [
            "class AutoRegressiveNN(nn.Module):",
            "",
            "if mask_encoding is None:",
            "# the dependency structure is chosen at random",
            "-            self.mask_encoding = 1 + torch.multinomial(torch.ones(input_dim - 1) / (input_dim - 1),",
            "+            self.mask_encoding = 1 + torch_multinomial(torch.ones(input_dim - 1) / (input_dim - 1),",
            "num_samples=hidden_dim, replacement=True)",
            "else:",
            "# the dependency structure is given by the user"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6534,
        "label": "no",
        "change": [
            "logger = logging.getLogger(__name__)",
            "def list(  # pylint: disable=redefined-builtin",
            "tag: t.Optional[t.Union[Tag, str]] = None,",
            "_bento_store: \"BentoStore\" = Provide[BentoMLContainer.bento_store],",
            "-) -> t.List[SysPathBento]:",
            "+) -> \"t.List[SysPathBento]\":",
            "return _bento_store.list(tag)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6535,
        "label": "no",
        "change": [
            "class NaturalGradient(Optimizer):",
            "]",
            "",
            "# delta' * grad(kldiv)",
            "-                multiply = functools.partial(tf_util.lift_indexedslices, tf.math.multiply)",
            "+                multiply = functools.partial(",
            "+                    tf_util.lift_indexedslices, tf.math.multiply,",
            "+                    with_assertions=self.config.create_tf_assertions",
            "+                )",
            "delta_kldiv_grads = tf.math.add_n(inputs=[",
            "tf.math.reduce_sum(input_tensor=multiply(delta, grad))",
            "for delta, grad in zip(deltas.values(), kldiv_grads)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6536,
        "label": "no",
        "change": [
            "def detect(net, img, device):",
            "# Creates a batch of 1",
            "img = np.expand_dims(img, 0)",
            "",
            "-    img = torch.from_numpy(img).to(device, dtype=torch.float32)",
            "+    img = torch.from_numpy(img.copy()).to(device, dtype=torch.float32)",
            "",
            "return batch_detect(net, img, device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6541,
        "label": "no",
        "change": [
            "class Simple_MNIST_Test(CustomTestCase):",
            "# the softmax is implemented internally in tl.cost.cross_entropy(y, y_) to",
            "# speed up computation, so we use identity here.",
            "# see tf.nn.sparse_softmax_cross_entropy_with_logits()",
            "-        cls.network = tl.layers.DenseLayer(network, n_units=10, act=tf.identity, name='output')",
            "+        cls.network = tl.layers.DenseLayer(network, n_units=10, name='output')",
            "",
            "# define cost function and metric.",
            "y = cls.network.outputs"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6546,
        "label": "yes",
        "change": [
            "def unpackbits_masks(masks):",
            "unpacked = tf.bitwise.bitwise_and(tf.expand_dims(masks, -1), bits) > 0",
            "unpacked = tf.reshape(",
            "unpacked,",
            "-        tf.concat([tf.shape(masks)[:-1], [-1]], axis=0))",
            "+        tf.concat([tf.shape(masks)[:-1], [8 * tf.shape(masks)[-1]]], axis=0))",
            "return unpacked"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 6549,
        "label": "no",
        "change": [
            "class ConditionalDetrForSegmentation(ConditionalDetrPreTrainedModel):",
            "...     ConditionalDetrConfig,",
            "...     ConditionalDetrForSegmentation,",
            "... )",
            "-        >>> from transformers.models.conditional_detr.feature_extraction_conditional_detr import rgb_to_id",
            "+        >>> from transformers.image_transforms import rgb_to_id",
            "",
            ">>> url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"",
            ">>> image = Image.open(requests.get(url, stream=True).raw)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6551,
        "label": "yes",
        "change": [
            "def _take_channels(*xs, ignore_channels=None):",
            "return xs",
            "else:",
            "channels = [channel for channel in range(xs[0].shape[1]) if channel not in ignore_channels]",
            "-        xs = [torch.index_select(x, dim=1, index=torch.tensor(channels)) for x in xs]",
            "+        xs = [torch.index_select(x, dim=1, index=torch.tensor(channels).to(x.device)) for x in xs]",
            "return xs"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 6553,
        "label": "no",
        "change": [
            "_MANUAL_VAR_INIT = False",
            "def clear_session():",
            "global _SESSION",
            "global _LEARNING_PHASE",
            "-    reset_default_graph()",
            "+    tf.reset_default_graph()",
            "reset_uids()",
            "_SESSION = None",
            "_LEARNING_PHASE = tf.placeholder(dtype='uint8', name='keras_learning_phase')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6559,
        "label": "no",
        "change": [
            "class Transformer(TTSInterface, torch.nn.Module):",
            "]",
            "if self.use_scaled_pos_enc:",
            "report_keys += [",
            "-                {\"encoder_alpha\": self.encoder.embed[-2].alpha.data.item()},",
            "-                {\"decoder_alpha\": self.decoder.embed[-2].alpha.data.item()},",
            "+                {\"encoder_alpha\": self.encoder.embed[-1].alpha.data.item()},",
            "+                {\"decoder_alpha\": self.decoder.embed[-1].alpha.data.item()},",
            "]",
            "self.reporter.report(report_keys)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6563,
        "label": "no",
        "change": [
            "def main():",
            "# extract",
            "logging.info('backend = ' + args.backend)",
            "if args.backend == \"pytorch\":",
            "-        from espnet.tts.pytorch.tts_pytorch import decode",
            "+        from espnet.tts.pytorch.tts import decode",
            "decode(args)",
            "else:",
            "raise NotImplementedError(\"Only pytorch is supported.\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6566,
        "label": "no",
        "change": [
            "def test_to_torch_feature_columns(ray_start_regular_shared):",
            "iterations = []",
            "",
            "for batch in iter(torchd):",
            "-        iterations.append(torch.cat((*batch[0], batch[1]), axis=1).numpy())",
            "+        iterations.append(torch.cat((batch[0], batch[1]), dim=1).numpy())",
            "combined_iterations = np.concatenate(iterations)",
            "assert np.array_equal(df.values, combined_iterations)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6570,
        "label": "no",
        "change": [
            "class DownloadManager:",
            "\"\"\"",
            "Ship the files using Beam FileSystems to the pipeline temp dir.",
            "\"\"\"",
            "-        from datasets.utils.beam_utils import upload_local_to_remote",
            "+        from .beam_utils import upload_local_to_remote",
            "",
            "remote_dir = pipeline._options.get_all_options().get(\"temp_location\")",
            "if remote_dir is None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6573,
        "label": "no",
        "change": [
            "class YOLOLayer(nn.Module):",
            "loss_conf = self.bce_loss(pred_conf[conf_mask_false], tconf[conf_mask_false]) + self.bce_loss(",
            "pred_conf[conf_mask_true], tconf[conf_mask_true]",
            ")",
            "-            loss_cls = (1 / nB) * self.ce_loss(pred_cls[mask], torch.argmax(tcls[mask], 1))",
            "+            loss_cls = self.ce_loss(pred_cls[mask], torch.argmax(tcls[mask], 1))",
            "loss = loss_x + loss_y + loss_w + loss_h + loss_conf + loss_cls",
            "",
            "return ("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6578,
        "label": "no",
        "change": [
            "class TorchElasticEnvironment(ClusterEnvironment):",
            "@staticmethod",
            "def detect() -> bool:",
            "\"\"\"Returns ``True`` if the current process was launched using the torchelastic command.\"\"\"",
            "+        if _TORCH_GREATER_EQUAL_1_9_1:",
            "+            return torch.distributed.is_torchelastic_launched()",
            "required_env_vars = {\"RANK\", \"GROUP_RANK\", \"LOCAL_RANK\", \"LOCAL_WORLD_SIZE\"}",
            "return required_env_vars.issubset(os.environ.keys())"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6580,
        "label": "no",
        "change": [
            "def cosine_beta_schedule(timesteps, s = 0.008):",
            "as proposed in https://openreview.net/forum?id=-NEXDKk8gZ",
            "\"\"\"",
            "steps = timesteps + 1",
            "-    x = torch.linspace(0, steps, steps)",
            "-    alphas_cumprod = torch.cos(((x / steps) + s) / (1 + s) * torch.pi * 0.5) ** 2",
            "+    x = torch.linspace(0, timesteps, steps)",
            "+    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * torch.pi * 0.5) ** 2",
            "alphas_cumprod = alphas_cumprod / alphas_cumprod[0]",
            "betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])",
            "return torch.clip(betas, 0, 0.999)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6585,
        "label": "no",
        "change": [
            "class Trainer:",
            "dataset.set_format(type=dataset.format[\"type\"], columns=columns)",
            "",
            "def _get_train_sampler(self) -> Optional[torch.utils.data.sampler.Sampler]:",
            "-        if not isinstance(self.train_dataset, collections.abc.Sized):",
            "+        if isinstance(self.train_dataset, torch.utils.data.IterableDataset) or not isinstance(",
            "+            self.train_dataset, collections.abc.Sized",
            "+        ):",
            "return None",
            "elif is_torch_tpu_available():",
            "return get_tpu_sampler(self.train_dataset)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6586,
        "label": "no",
        "change": [
            "def auto_scale_lr(cfg, distributed, logger):",
            "num_gpus = len(cfg.gpu_ids)",
            "",
            "# calculate the batch size",
            "-    batch_size = num_gpus * cfg.data.samples_per_gpu",
            "-    logger.info(f'You are using {num_gpus} GPU(s) '",
            "-                f'and {cfg.data.samples_per_gpu} samples per GPU. '",
            "-                f'Total batch size is {batch_size}.')",
            "+    samples_per_gpu = cfg.data.train_dataloader.samples_per_gpu",
            "+    batch_size = num_gpus * samples_per_gpu",
            "+    logger.info(f'Training with {num_gpus} GPU(s) with {samples_per_gpu} '",
            "+                f'samples per GPU. The total batch size is {batch_size}.')",
            "",
            "if batch_size != base_batch_size:",
            "# scale LR with"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6588,
        "label": "no",
        "change": [
            "\"\\n\",",
            "\"        # Checkpoint model after every epoch.\\n\",",
            "\"        state_dict = model.state_dict()\\n\",",
            "-    \"        consume_prefix_in_state_dict_if_present(state_dict, \\\"module.\\\")\\n\",",
            "\"        checkpoint = Checkpoint.from_dict(dict(model=state_dict))\\n\",",
            "\"        session.report({\\\"loss\\\": running_loss}, checkpoint=checkpoint)\"",
            "]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6589,
        "label": "no",
        "change": [
            "class Adapter(serializable.Serializable):",
            "tf.data.Dataset. The converted dataset.",
            "\"\"\"",
            "if isinstance(dataset, np.ndarray):",
            "-            dataset = tf.data.Dataset.from_tensor_slices(",
            "-                dataset.astype(np.float32))",
            "+            dataset = tf.data.Dataset.from_tensor_slices(dataset)",
            "return data_utils.batch_dataset(dataset, self.batch_size)",
            "",
            "def fit(self, dataset):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6591,
        "label": "no",
        "change": [
            "def temp_seed(seed: int, set_pytorch=False, set_tensorflow=False):",
            "if not tf.executing_eagerly():",
            "raise ValueError(\"Setting random seed for TensorFlow is only available in eager mode\")",
            "",
            "-        tf_context = tf.python.context.context()  # eager mode context",
            "+        tf_context = tfpy.context.context()  # eager mode context",
            "tf_seed = tf_context._seed",
            "tf_rng_initialized = hasattr(tf_context, \"_rng\")",
            "if tf_rng_initialized:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6594,
        "label": "no",
        "change": [
            "def convert_points_from_homogeneous(",
            "# https://github.com/opencv/opencv/pull/14411/files",
            "mask: torch.Tensor = torch.abs(z_vec) > eps",
            "scale: torch.Tensor = torch.ones_like(z_vec).masked_scatter_(",
            "-        mask, torch.tensor(1.0) / z_vec[mask])",
            "+        mask, torch.tensor(1.0).to(points.device) / z_vec[mask])",
            "",
            "return scale * points[..., :-1]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6596,
        "label": "no",
        "change": [
            "class WaveNetModel(object):",
            "",
            "# In this case, the number of global_embedding channels must be",
            "# equal to the the last dimension of the global_condition tensor.",
            "-            gc_batch_rank = len(global_condition.get_shape)",
            "+            gc_batch_rank = len(global_condition.get_shape())",
            "dims_match = (global_condition.get_shape()[gc_batch_rank - 1] ==",
            "self.global_condition_channels)",
            "if not dims_match:",
            "raise ValueError('Shape of global_condition {} does not'",
            "' match global_condition_channels {}.'.",
            "-                                 format(self.global_condition.get_shape(),",
            "+                                 format(global_condition.get_shape(),",
            "self.global_condition_channels))",
            "embedding = global_condition"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6600,
        "label": "no",
        "change": [
            "class LSTM(recurrent.DropoutRNNCellMixin, recurrent.LSTM):",
            "",
            "if self.stateful:",
            "updates = [",
            "-          tf.compat.v1.assign(self_state, state)",
            "+          tf.compat.v1.assign(self_state, tf.cast(state, self_state.dtype))",
            "for self_state, state in zip(self.states, states)",
            "]",
            "self.add_update(updates)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6604,
        "label": "no",
        "change": [
            "if 'TENSORLAYER_PACKAGE_BUILDING' not in os.environ:",
            "\" - `pip install --upgrade tensorflow-gpu`\"",
            ")",
            "",
            "-    if tensorflow.__version__ < \"1.6.0\":",
            "+    if tensorflow.__version__ < \"1.6.0\" and os.environ.get('READTHEDOCS', None) != 'True':",
            "raise RuntimeError(",
            "\"TensorLayer does not support Tensorflow version older than 1.6.0.\\n\"",
            "\"Please update Tensorflow with:\\n\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6606,
        "label": "no",
        "change": [
            "import torch.nn.functional as F",
            "def init_seeds(seed=0):",
            "torch.manual_seed(seed)",
            "",
            "-    # Reduce randomness (may be slower on Tesla GPUs) # https://pytorch.org/docs/stable/notes/randomness.html",
            "-    if seed == 0:",
            "+    # Speed-reproducibility tradeoff https://pytorch.org/docs/stable/notes/randomness.html",
            "+    if seed == 0:  # slower, more reproducible",
            "+        cudnn.deterministic = True",
            "+        cudnn.benchmark = False",
            "+    else:  # faster, less reproducible",
            "cudnn.deterministic = False",
            "cudnn.benchmark = True"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6607,
        "label": "no",
        "change": [
            "class DiffusionPriorNetwork(nn.Module):",
            "",
            "# setup self conditioning",
            "",
            "-        self_cond = None",
            "if self.self_cond:",
            "-            self_cond = default(self_cond, lambda: torch.zeros(batch, 1, self.dim, device = device, dtype = dtype))",
            "+            self_cond = default(self_cond, lambda: torch.zeros(batch, self.dim, device = device, dtype = dtype))",
            "+            self_cond = rearrange(self_cond, 'b d -> b 1 d')",
            "",
            "# in section 2.2, last paragraph",
            "# \"... consisting of encoded text, CLIP text embedding, diffusion timestep embedding, noised CLIP image embedding, final embedding for prediction\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6608,
        "label": "no",
        "change": [
            "class IntegerLookupSavingTest(keras_parameterized.TestCase,",
            "",
            "",
            "if __name__ == \"__main__\":",
            "+  # IntegerLookup is only exported as a TF2 API.",
            "+  tf.compat.v1.enable_v2_behavior()",
            "tf.test.main()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6609,
        "label": "no",
        "change": [
            "class TestRandomCutMix:",
            "expected = torch.tensor([[[[1., 0., 0., 1.],",
            "[1., 0., 0., 1.],",
            "[1., 1., 1., 1.]]],",
            "-                                 [[[1., 1., 0., 0.],",
            "-                                   [1., 1., 0., 0.],",
            "+                                 [[[0., 1., 1., 0.],",
            "+                                   [0., 1., 1., 0.],",
            "[0., 0., 0., 0.]]]], device=device, dtype=dtype)",
            "",
            "out_image, out_label = f(input, label)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6611,
        "label": "no",
        "change": [
            "class MixAugmentationBaseV2(_BasicAugmentationBase):",
            "in_tensor: Tensor = input[in_tensor_idx]",
            "in_tensor = self.transform_tensor(in_tensor)",
            "self._params = self.forward_parameters(in_tensor.shape)",
            "-            self._params.update({\"dtype\": torch.tensor(DType.get(in_tensor.dtype).value)})",
            "+            self._params.update({\"dtype\": tensor(DType.get(in_tensor.dtype).value)})",
            "else:",
            "self._params = params",
            "",
            "-        outputs = []",
            "+        outputs: List[Tensor] = []",
            "for dcate, _input in zip(keys, input):",
            "output: Tensor",
            "if dcate == DataKey.INPUT:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6613,
        "label": "no",
        "change": [
            "class TokenCharactersEncoder(TokenEmbedder):",
            "self._dropout = lambda x: x",
            "",
            "def get_output_dim(self) -> int:",
            "-        return self._encoder._module.get_output_dim()  # pylint: disable=protected-access",
            "+        return self._encoder._module.get_output_dim()",
            "",
            "-    def forward(self, token_characters: torch.Tensor) -> torch.Tensor:  # pylint: disable=arguments-differ",
            "+    def forward(self, token_characters: torch.Tensor) -> torch.Tensor:",
            "mask = (token_characters != 0).long()",
            "return self._dropout(self._encoder(self._embedding(token_characters), mask))",
            "",
            "# The setdefault requires a custom from_params",
            "@classmethod",
            "def from_params(cls, vocab: Vocabulary, params: Params) -> 'TokenCharactersEncoder':  # type: ignore",
            "-        # pylint: disable=arguments-differ",
            "+",
            "embedding_params: Params = params.pop(\"embedding\")",
            "# Embedding.from_params() uses \"tokens\" as the default namespace, but we need to change",
            "# that to be \"token_characters\" by default. If num_embeddings is present, set default namespace"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6615,
        "label": "no",
        "change": [
            "class Net(nn.Module):",
            "data, _ = voxel_max_pool(",
            "data, 14, origin=0, fake_nodes=True, transform=transform)",
            "",
            "-        x = data.input.view(-1, 4 * 64)",
            "+        x = data.input.view(-1, 4 * 128)",
            "x = F.elu(self.fc1(x))",
            "x = F.dropout(x, training=self.training)",
            "x = self.fc2(x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6617,
        "label": "no",
        "change": [
            "class MaskedConv2dFunction(Function):",
            "out_w = int(",
            "math.floor((features.size(3) + 2 * pad_w -",
            "(kernel_h - 1) - 1) / stride_w + 1))",
            "-        mask_inds = torch.nonzero(mask[0] > 0)",
            "+        mask_inds = torch.nonzero(mask[0] > 0, as_tuple=False)",
            "output = features.new_zeros(batch_size, out_channel, out_h, out_w)",
            "if mask_inds.numel() > 0:",
            "mask_h_idx = mask_inds[:, 0].contiguous()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6619,
        "label": "no",
        "change": [
            "class BertPooler(Seq2VecEncoder):",
            "def get_output_dim(self) -> int:",
            "return self._embedding_dim",
            "",
            "-    def forward(self, tokens: torch.Tensor, mask: torch.Tensor = None):  # pylint: disable=arguments-differ,unused-argument",
            "+    def forward(self, tokens: torch.Tensor, mask: torch.Tensor = None):",
            "pooled = self.pooler(tokens)",
            "pooled = self._dropout(pooled)",
            "return pooled"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6620,
        "label": "no",
        "change": [
            "class TFModel(NNModel, metaclass=TfModelMeta):",
            "variables_to_train.extend(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope_name))",
            "",
            "if optimizer is None:",
            "-                optimizer = tf.train.AdamOptimizer(learning_rate, **kwargs)",
            "+                optimizer = tf.train.AdamOptimizer",
            "",
            "# For batch norm it is necessary to update running averages",
            "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6623,
        "label": "no",
        "change": [
            "class DeformableConv2d(Layer):",
            "name='b_deformableconv2d', shape=(shape[-1]), initializer=b_init, dtype=LayersConfig.tf_dtype,",
            "**b_init_args",
            ")",
            "-                tf.reshape()",
            "+",
            "self.outputs = tf.reshape(",
            "tensor=act(tf.nn.conv3d(input_deform, W, strides=[1, 1, 1, 1, 1], padding='VALID', name=None) + b),",
            "shape=(tf.shape(self.inputs)[0], input_h, input_w, shape[-1])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6624,
        "label": "no",
        "change": [
            "class ParameterServerCustomTrainingLoopTest(tf.test.TestCase):",
            "",
            "",
            "if __name__ == \"__main__\":",
            "-  tf.__internal__.distribute.multi_process_runner.test_main()",
            "+  if tf.__internal__.tf2.enabled():",
            "+    tf.__internal__.distribute.multi_process_runner.test_main()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6628,
        "label": "no",
        "change": [
            "class TFOptimizer(Optimizer):",
            "",
            "variables.extend(self.optimizer.variables())",
            "",
            "-        # variables.extend(",
            "-        #     self.optimizer._slots[slot][key] for slot in sorted(self.optimizer._slots)",
            "-        #     for key in sorted(self.optimizer._slots[slot])",
            "-        # )",
            "-",
            "-        # if isinstance(self.optimizer, (tf.train.AdamOptimizer, tf.contrib.opt.NadamOptimizer)):",
            "-        #     variables.extend(self.optimizer._get_beta_accumulators())",
            "-",
            "return variables"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6629,
        "label": "yes",
        "change": [
            "class Normalize(Preprocessor):",
            "\"\"\"",
            "",
            "def __init__(self, scope='normalize', summary_labels=()):",
            "-        super(Normalize).__init__(scope, summary_labels)",
            "+        super(Normalize, self).__init__(scope=scope, summary_labels=summary_labels)",
            "",
            "def tf_process(self, tensor):",
            "# Min/max across every axis except batch dimension.",
            "-        min = tf.reduce_min(input_tensor=tensor, axis=np.arange(1, util.rank(tensor)))",
            "-        max = tf.reduce_max(input_tensor=tensor, axis=np.arange(1, util.rank(tensor)))",
            "+        min_value = tf.reduce_min(input_tensor=tensor, axis=np.arange(1, util.rank(tensor)))",
            "+        max_value = tf.reduce_max(input_tensor=tensor, axis=np.arange(1, util.rank(tensor)))",
            "",
            "-        return (tensor - min) / (max - min + util.epsilon)",
            "+        return (tensor - min_value) / (max_value - min_value + util.epsilon)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 6631,
        "label": "no",
        "change": [
            "def random_uniform(",
            "rand_range = high - low",
            "if shape is None:",
            "shape = []",
            "-    return torch.rand(shape, device=default_device(device), dtype=dtype) * rand_range + low",
            "+    return (",
            "+        torch.rand(shape, device=default_device(device), dtype=dtype) * rand_range + low",
            "+    )",
            "",
            "",
            "def random_normal("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6632,
        "label": "no",
        "change": [
            "class TF{{cookiecutter.camelcase_modelname}}ForMultipleChoice(TF{{cookiecutter.c",
            "Returns:",
            "tf.Tensor with dummy inputs",
            "\"\"\"",
            "-        return {\"input_ids\": tf.constant(MULTIPLE_CHOICE_DUMMY_INPUTS)}",
            "+        return {\"input_ids\": tf.constant(MULTIPLE_CHOICE_DUMMY_INPUTS, dtype=tf.int64)}",
            "",
            "@unpack_inputs",
            "@add_start_docstrings_to_model_forward({{cookiecutter.uppercase_modelname}}_INPUTS_DOCSTRING.format(\"batch_size, num_choices, sequence_length\"))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6633,
        "label": "no",
        "change": [
            "class Emotion(nlp.GeneratorBasedBuilder):",
            "valid_path = dl_manager.download_and_extract(_VALIDATION_DOWNLOAD_URL)",
            "test_path = dl_manager.download_and_extract(_TEST_DOWNLOAD_URL)",
            "return [",
            "-            nlp.SplitGenerator(name=nlp.Split.TRAIN, gen_kwargs={\"filepath\": train_path}),",
            "-            nlp.SplitGenerator(name=nlp.Split.VALIDATION, gen_kwargs={\"filepath\": valid_path}),",
            "-            nlp.SplitGenerator(name=nlp.Split.TEST, gen_kwargs={\"filepath\": test_path}),",
            "+            datasets.SplitGenerator(name=datasets.Split.TRAIN, gen_kwargs={\"filepath\": train_path}),",
            "+            datasets.SplitGenerator(name=datasets.Split.VALIDATION, gen_kwargs={\"filepath\": valid_path}),",
            "+            datasets.SplitGenerator(name=datasets.Split.TEST, gen_kwargs={\"filepath\": test_path}),",
            "]",
            "",
            "def _generate_examples(self, filepath):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6637,
        "label": "no",
        "change": [
            "def postprocess_trajectory(policy,",
            "",
            "def choose_optimizer(policy, config):",
            "if policy.config[\"opt_type\"] == \"adam\":",
            "-        return tf.train.AdamOptimizer(policy.cur_lr)",
            "+        return tf1.train.AdamOptimizer(policy.cur_lr)",
            "else:",
            "-        return tf.train.RMSPropOptimizer(policy.cur_lr, config[\"decay\"],",
            "-                                         config[\"momentum\"], config[\"epsilon\"])",
            "+        return tf1.train.RMSPropOptimizer(",
            "+            policy.cur_lr,",
            "+            config[\"decay\"], config[\"momentum\"], config[\"epsilon\"])",
            "",
            "",
            "def clip_gradients(policy, optimizer, loss):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6638,
        "label": "no",
        "change": [
            "def real(",
            "",
            "",
            "def isposinf(",
            "-        x: Union[torch.Tensor],",
            "-        /,",
            "-        *,",
            "-        out: Optional[torch.Tensor] = None,",
            "+    x: Union[torch.Tensor],",
            "+    /,",
            "+    *,",
            "+    out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "return torch.isposinf(x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6640,
        "label": "no",
        "change": [
            "class ValueFunction(object):",
            "\"\"\"",
            "",
            "self.session = tf.Session()",
            "-        # TODO fix",
            "-        #self.saver = tf.train.Saver()",
            "+        self.saver = None",
            "",
            "def get_action(self, state):",
            "raise NotImplementedError"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6641,
        "label": "no",
        "change": [
            "def unravel_index(",
            "for dim in reversed(shape):",
            "output.append(temp % dim)",
            "temp = temp // dim",
            "-    ret= tf.constant(reversed(output), dtype=tf.int32)",
            "+    ret = tf.constant(reversed(output), dtype=tf.int32)",
            "return tuple(ret)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6644,
        "label": "no",
        "change": [
            "class TurkishShrinkedNER(datasets.GeneratorBasedBuilder):",
            "path_to_manual_file = os.path.abspath(os.path.expanduser(dl_manager.manual_dir))",
            "if not os.path.exists(path_to_manual_file):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('turkish_shrinked_ner', data_dir=...)` that includes file name {}. Manual download instructions: {}\".format(",
            "-                    path_to_manual_file,",
            "-                    _FILENAME,",
            "-                    self.manual_download_instructions,",
            "-                )",
            "+                \"{path_to_manual_file} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('turkish_shrinked_ner', data_dir=...)` that includes file name {_FILENAME}. Manual download instructions: {self.manual_download_instructions}\"",
            ")",
            "return [",
            "datasets.SplitGenerator("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6648,
        "label": "no",
        "change": [
            "class DNN_WPE(torch.nn.Module):",
            "",
            "# Averaging along the channel axis: (..., C, T) -> (..., T)",
            "power = power.mean(dim=-2)",
            "+            power = torch.clamp(power, min=1e-6)",
            "",
            "# enhanced: (..., C, T) -> (..., C, T)",
            "# NOTE(kamo): Calculate in double precision"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6650,
        "label": "no",
        "change": [
            "def stack(sequence, horizontal=True, vertical=True):",
            "# Concat all indices and values to one new large sparse matrix.",
            "indices = torch.cat(indices, dim=1)",
            "values = torch.cat([mat._values() for mat in sequence])",
            "-    size = torch.Size([y_sum, x_sum, *sequence[0].size()[2:]])",
            "+    size = torch.Size([y_sum, x_sum, *(sequence[0].size()[2:])])",
            "slices = torch.LongTensor(slices)",
            "",
            "return torch.sparse.FloatTensor(indices, values, size), slices"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6651,
        "label": "no",
        "change": [
            "class Categorical(Distribution):",
            "repeat=r))",
            "",
            "if r == 1:",
            "-            return iter([Variable(torch.Tensor([[i]])) for i in range(c)])",
            "+            return (Variable(torch.Tensor([[i]])) for i in range(c))",
            "return (Variable(torch.Tensor(list(x)).unsqueeze(1))",
            "for x in itertools.product(torch.arange(0, c),",
            "repeat=r))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6653,
        "label": "no",
        "change": [
            "\"metadata\": {},",
            "\"outputs\": [],",
            "\"source\": [",
            "-    \"# equivalent to pyro.condition(scale, data={\\\"measurement\\\": Variable(torch.ones(1))})\\n\",",
            "+    \"# equivalent to pyro.condition(scale, data={\\\"measurement\\\": Variable(torch.Tensor([9.5]))})\\n\",",
            "\"def scale_obs(guess):\\n\",",
            "\"    weight = pyro.sample(\\\"weight\\\", dist.Normal(guess, Variable(torch.ones(1))))\\n\",",
            "\"     # here we attach an observation measurement == 9.5\\n\","
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6657,
        "label": "no",
        "change": [
            "def reshape_classifier_output(model, n=1000):",
            "elif nn.Conv2d in types:",
            "i = types.index(nn.Conv2d)  # nn.Conv2d index",
            "if m[i].out_channels != n:",
            "-                m[i] = nn.Conv2d(m[i].in_channels, n, m[i].kernel_size, m[i].stride, bias=m[i].bias)",
            "+                m[i] = nn.Conv2d(m[i].in_channels, n, m[i].kernel_size, m[i].stride, bias=m[i].bias is not None)",
            "",
            "",
            "@contextmanager"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6672,
        "label": "no",
        "change": [
            "class DefaultBoxes(object):",
            "self.default_boxes.append((cx, cy, w, h))",
            "",
            "# 将default_boxes转为tensor格式",
            "-        self.dboxes = torch.tensor(self.default_boxes, dtype=torch.float32)  # 这里不转类型会报错",
            "+        self.dboxes = torch.as_tensor(self.default_boxes, dtype=torch.float32)  # 这里不转类型会报错",
            "self.dboxes.clamp_(min=0, max=1)  # 将坐标（x, y, w, h）都限制在0-1之间",
            "",
            "# For IoU calculation"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6673,
        "label": "no",
        "change": [
            "def test(data,",
            "tbox = xywh2xyxy(labels[:, 1:5])",
            "scale_coords(img[si].shape[1:], tbox, shapes[si][0], shapes[si][1])  # native-space labels",
            "if plots:",
            "-                    confusion_matrix.process_batch(pred, torch.cat((labels[:, 0:1], tbox), 1))",
            "+                    confusion_matrix.process_batch(predn, torch.cat((labels[:, 0:1], tbox), 1))",
            "",
            "# Per target class",
            "for cls in torch.unique(tcls_tensor):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6681,
        "label": "no",
        "change": [
            "def arange(",
            "stop = start",
            "if dtype is None:",
            "if isinstance(start, int) and isinstance(stop, int) and isinstance(step, int):",
            "-            return torch.arange(",
            "-                start, stop, step, dtype=torch.int64, device=device",
            "-            ).to(torch.int32)",
            "+            return torch.arange(start, stop, step, dtype=torch.int64, device=device).to(",
            "+                torch.int32",
            "+            )",
            "else:",
            "return torch.arange(start, stop, step, device=device)",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6683,
        "label": "no",
        "change": [
            "class SubsamplingStep(MetaOptimizer):",
            "if some_argument:",
            "arguments_iter = iter(some_argument)",
            "some_argument = next(arguments_iter)",
            "-                elif some_argument is None or util.rank(some_argument) == 0:",
            "+                elif some_argument is None or util.rank(x=some_argument) == 0:",
            "# Non-batched argument",
            "some_argument = next(arguments_iter)",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6687,
        "label": "no",
        "change": [
            "class Testunsharp(BaseTester):",
            "",
            "def test_noncontiguous(self, device, dtype):",
            "batch_size = 3",
            "-        input = torch.rand(3, 5, 5, device=device, dtype=dtype).expand(batch_size, -1, -1, -1)",
            "+        inpt = torch.rand(3, 5, 5, device=device, dtype=dtype).expand(batch_size, -1, -1, -1)",
            "",
            "kernel_size = (3, 3)",
            "sigma = (1.5, 2.1)",
            "-        actual = unsharp_mask(input, kernel_size, sigma, \"replicate\")",
            "+        actual = unsharp_mask(inpt, kernel_size, sigma, \"replicate\")",
            "assert actual.is_contiguous()",
            "",
            "def test_gradcheck(self, device):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6688,
        "label": "no",
        "change": [
            "from ray.rllib.utils import try_import_torch",
            "_, nn = try_import_torch()",
            "",
            "",
            "-class VisionNetwork(TorchModelV2, nn.Module):",
            "+class VisionNetwork(TorchModelV2):",
            "\"\"\"Generic vision network.\"\"\"",
            "",
            "def __init__(self, obs_space, action_space, num_outputs, model_config,",
            "name):",
            "TorchModelV2.__init__(self, obs_space, action_space, num_outputs,",
            "model_config, name)",
            "-        nn.Module.__init__(self)",
            "",
            "activation = get_activation_fn(",
            "model_config.get(\"conv_activation\"), framework=\"torch\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6693,
        "label": "no",
        "change": [
            "def run(",
            "",
            "def parse_opt():",
            "parser = argparse.ArgumentParser()",
            "-    parser.add_argument('--weights', nargs='+', type=str, default=ROOT / 'yolov5s.pt', help='model path(s)')",
            "+    parser.add_argument('--weights', nargs='+', type=str, default=ROOT / 'yolov5s.pt', help='model path or triton URL')",
            "parser.add_argument('--source', type=str, default=ROOT / 'data/images', help='file/dir/URL/glob/screen/0(webcam)')",
            "parser.add_argument('--data', type=str, default=ROOT / 'data/coco128.yaml', help='(optional) dataset.yaml path')",
            "parser.add_argument('--imgsz', '--img', '--img-size', nargs='+', type=int, default=[640], help='inference size h,w')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6695,
        "label": "yes",
        "change": [
            "class Conv(Layer):",
            "inputs = tf.pad(inputs, self._compute_causal_padding(inputs))",
            "",
            "if self.groups > 1:",
            "-            outputs = self._jit_compiled_convolution_op(inputs, self.kernel)",
            "+            outputs = self._jit_compiled_convolution_op(",
            "+                inputs, tf.convert_to_tensor(self.kernel)",
            "+            )",
            "else:",
            "outputs = self.convolution_op(inputs, self.kernel)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 6696,
        "label": "no",
        "change": [
            "class TFGenerationMixin:",
            "shape=(-1,),",
            ")",
            "# expand encoder_outputs",
            "-            encoder_outputs = (tf.gather(encoder_outputs[0], expanded_batch_idxs, axis=0), *encoder_outputs[1:])",
            "-",
            "+            encoder_outputs = (tf.gather(encoder_outputs[0], expanded_batch_idxs, axis=0),)",
            "else:",
            "encoder_outputs = None",
            "cur_len = shape_list(input_ids)[-1]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6697,
        "label": "no",
        "change": [
            "import torch",
            "",
            "",
            "-def LayerNorm(normalized_shape, eps=1e-5, elementwise_affine=True):",
            "-    if torch.cuda.is_available():",
            "+def LayerNorm(normalized_shape, eps=1e-5, elementwise_affine=True, export=False):",
            "+    if not export and torch.cuda.is_available():",
            "try:",
            "from apex.normalization import FusedLayerNorm",
            "return FusedLayerNorm(normalized_shape, eps, elementwise_affine)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6700,
        "label": "no",
        "change": [
            "class GlowTTS(BaseTTS):",
            "y = y[:, :, :y_max_length]",
            "if attn is not None:",
            "attn = attn[:, :, :, :y_max_length]",
            "-        y_lengths = (y_lengths // self.num_squeeze) * self.num_squeeze",
            "+        y_lengths = torch.div(y_lengths, self.num_squeeze, rounding_mode=\"floor\") * self.num_squeeze",
            "return y, y_lengths, y_max_length, attn",
            "",
            "def store_inverse(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6706,
        "label": "no",
        "change": [
            "class QuantGrad(torch.autograd.Function):",
            "raise ValueError(\"unrecognized QuantType.\")",
            "",
            "bits = QuantGrad.get_bits_length(wrapper.config, quant_type)",
            "-        qmin, qmax = torch.Tensor([0], device=tensor.device), torch.Tensor([(1 << bits) - 1], device=tensor.device)",
            "+        qmin, qmax = torch.Tensor([0]).to(device=tensor.device), torch.Tensor([(1 << bits)-1]).to(device=tensor.device)",
            "ctx.save_for_backward(tensor, wrapper.module.scale, wrapper.module.zero_point, qmin, qmax)",
            "return output"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6709,
        "label": "no",
        "change": [
            "def rgb_to_grayscale(input: torch.Tensor) -> torch.Tensor:",
            ".format(input.shape))",
            "",
            "r, g, b = torch.chunk(input, chunks=3, dim=-3)",
            "-    gray: torch.Tensor = 0.299 * r + 0.587 * g + 0.110 * b",
            "+    gray: torch.Tensor = 0.299 * r + 0.587 * g + 0.114 * b",
            "return gray"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6710,
        "label": "no",
        "change": [
            "class AsyncInferenceTestCase(AsyncTestCase):",
            "img_path = os.path.join(root_dir, 'demo/demo.jpg')",
            "bboxes, _ = await detector.apredict(img_path)",
            "self.assertTrue(bboxes)",
            "+            # asy inference detector will hack grad_enabled,",
            "+            # so restore here to avoid it to influence other tests",
            "+            torch.set_grad_enabled(ori_grad_enabled)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6711,
        "label": "no",
        "change": [
            "def att_sum_bahdanau(v_att, keys, query):",
            "@function.Defun(tf.float32, tf.float32, func_name=\"att_sum_dot\", noinline=True)",
            "def att_sum_dot(keys, query):",
            "\"\"\"Calculates a batch- and timweise dot product\"\"\"",
            "-  return tf.reduce_sum(keys + tf.expand_dims(query, 1), [2])",
            "+  return tf.reduce_sum(keys * tf.expand_dims(query, 1), [2])",
            "",
            "",
            "class AttentionLayer(GraphModule):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6714,
        "label": "yes",
        "change": [
            "def main():",
            "'op_names': ['features.6', 'features.9', 'features.13', 'features.16', 'features.20', 'classifier.2', 'classifier.5']",
            "}]",
            "",
            "-    quantizer = BNNQuantizer(model, configure_list)",
            "+    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)",
            "+    quantizer = BNNQuantizer(model, configure_list, optimizer)",
            "model = quantizer.compress()",
            "",
            "print('=' * 10 + 'train' + '=' * 10)",
            "-    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)",
            "best_top1 = 0",
            "for epoch in range(400):",
            "print('# Epoch {} #'.format(epoch))"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "null reference error",
        "Action": "addition",
        "Element": "api parameter"
    },
    {
        "number": 6716,
        "label": "no",
        "change": [
            "class StableDiffusionImg2ImgPipeline(DiffusionPipeline):",
            "",
            "self.scheduler.set_timesteps(num_inference_steps, **extra_set_kwargs)",
            "",
            "-        if not isinstance(init_image, torch.FloatTensor):",
            "+        if isinstance(init_image, PIL.Image.Image):",
            "init_image = preprocess(init_image)",
            "",
            "# encode the init image into latents and scale the latents"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6717,
        "label": "no",
        "change": [
            "class GigaFrenConfig(datasets.BuilderConfig):",
            "",
            "",
            "class GigaFren(datasets.GeneratorBasedBuilder):",
            "-    BUILDER_CONFIGS = [GigaFrenConfig(description=f\"Translating en to fr \", version=datasets.Version(_VERSION))]",
            "+    BUILDER_CONFIGS = [GigaFrenConfig(description=\"Translating en to fr \", version=datasets.Version(_VERSION))]",
            "BUILDER_CONFIG_CLASS = GigaFrenConfig",
            "",
            "def _info(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6720,
        "label": "yes",
        "change": [
            "class Dataset(DatasetInfoMixin, IndexableMixin):",
            "- if `dataset_path` is a path of a dataset dict directory: a :class:`DatasetDict` with each split.",
            "\"\"\"",
            "# copies file from filesystem if it is remote filesystem to local filesystem and modifies dataset_path to temp directory containing local copies",
            "+        fs = fsspec.filesystem(\"file\") if fs is None else fs",
            "+        dataset_dict_json_path = Path(dataset_path, config.DATASETDICT_JSON_FILENAME).as_posix()",
            "+        dataset_info_path = Path(dataset_path, config.DATASET_INFO_FILENAME).as_posix()",
            "+        if not fs.isfile(dataset_info_path) and fs.isfile(dataset_dict_json_path):",
            "+            raise FileNotFoundError(",
            "+                f\"No such file or directory: '{dataset_info_path}'. Expected to load a Dataset object, but got a DatasetDict. Please use datasets.load_from_disk instead.\"",
            "+            )",
            "+",
            "if is_remote_filesystem(fs):",
            "src_dataset_path = extract_path_from_uri(dataset_path)",
            "tmp_dir = tempfile.TemporaryDirectory()"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "null reference error",
        "Action": "addition",
        "Element": "api condition check"
    },
    {
        "number": 6725,
        "label": "no",
        "change": [
            "class Decoder(torch.nn.Module):",
            "self.dropout_dec += [torch.nn.Dropout(p=dropout)]",
            "for _ in six.moves.range(1, self.dlayers):",
            "self.decoder += [",
            "-                torch.nn.LSTMCell(dunits, dunits) if self.dtype == \"lstm\" else torch.nn.GRUCell(dunits + eprojs,",
            "-                                                                                                dunits)]",
            "+                torch.nn.LSTMCell(dunits, dunits) if self.dtype == \"lstm\" else torch.nn.GRUCell(dunits, dunits)]",
            "self.dropout_dec += [torch.nn.Dropout(p=dropout)]",
            "# NOTE: dropout is applied only for the vertical connections",
            "# see https://arxiv.org/pdf/1409.2329.pdf"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6726,
        "label": "no",
        "change": [
            "class Lstm(TransformationBase):",
            "",
            "self.cell = tf.contrib.rnn.LSTMCell(num_units=self.lstm_size)",
            "# if self.lstm_dropout is not None:",
            "-        #     keep_prob = tf.cond(pred=update, true_fn=(lambda: 1.0 - self.lstm_dropout), false_fn=(lambda: 1.0))",
            "+        #     keep_prob = self.cond(pred=update, true_fn=(lambda: 1.0 - self.lstm_dropout), false_fn=(lambda: 1.0))",
            "#     self.lstm_cell = tf.contrib.rnn.DropoutWrapper(cell=self.lstm_cell, output_keep_prob=keep_prob)",
            "",
            "def tf_apply(self, x, sequence_length=None):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6729,
        "label": "no",
        "change": [
            "\"source\": [",
            "\"import numpy as np\\n\",",
            "\"a = np.ones(5)\\n\",",
            "-    \"b = torch.DoubleTensor(a)\\n\",",
            "+    \"b = torch.from_numpy(a)\\n\",",
            "\"np.add(a, 1, out=a)\\n\",",
            "\"print(a)\\n\",",
            "\"print(b) # see how changing the np array changed the torch Tensor automatically\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6734,
        "label": "no",
        "change": [
            "class E2E(torch.nn.Module):",
            "else:",
            "logging.warning('loss (=%f) is not correct', loss_data)",
            "",
            "-        return self.loss, loss_ctc, loss_att, acc, cer, wer",
            "+        # Note(kamo): In order to work with DataParallel, on pytorch==0.4,",
            "+        # the return value must be torch.CudaTensor, or tuple/list/dict of it.",
            "+        # Neither CPUTensor nor float/int value can be used",
            "+        # because NCCL communicates between GPU devices.",
            "+        return self.loss",
            "",
            "def recognize(self, x, recog_args, char_list, rnnlm=None):",
            "\"\"\"E2E beam search"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6737,
        "label": "no",
        "change": [
            "def KitModel(weight_file = None):",
            "IR_node.name)",
            "return code",
            "",
            "-    def emit_Maxmum(self, IR_node):",
            "-        code = \"{:<15} = tf.maxmum({}, {}, name='{}')\".format(",
            "+    def emit_Maximum(self, IR_node):",
            "+        code = \"{:<15} = tf.maximum({}, {}, name='{}')\".format(",
            "IR_node.variable_name,",
            "self.parent_variable_name(IR_node),",
            "self.parent_variable_name(IR_node, [1]),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6739,
        "label": "no",
        "change": [
            "if \"--cuda_ext\" in sys.argv:",
            "'csrc/welford.cu']))",
            "ext_modules.append(",
            "CUDAExtension(name='fused_layer_norm_cuda',",
            "-                          sources=['apex/normalization/csrc/layer_norm_cuda.cpp',",
            "-                                   'apex/normalization/csrc/layer_norm_cuda_kernel.cu'],",
            "+                          sources=['csrc/layer_norm_cuda.cpp',",
            "+                                   'csrc/layer_norm_cuda_kernel.cu'],",
            "extra_compile_args={'cxx': ['-O3'] + version_ge_1_1,",
            "'nvcc':['-maxrregcount=50',",
            "'-O3',"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6740,
        "label": "no",
        "change": [
            "else:",
            "",
            "def connect(self) -> BufferedIOBase:",
            "conn, _ = self._socket.accept()",
            "-            self.file = conn.makefile('w+b')",
            "+            self.file = conn.makefile('rwb')",
            "return self.file",
            "",
            "def close(self) -> None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6753,
        "label": "no",
        "change": [
            "class TFMBartPreTrainedModel(TFPreTrainedModel):",
            "decoder_input_ids = tf.cast(tf.convert_to_tensor(DUMMY_INPUTS), tf.int32)",
            "dummy_inputs = {",
            "\"decoder_input_ids\": decoder_input_ids,",
            "-            \"attention_mask\": tf.math.not_equal(input_ids, pad_token),",
            "+            \"attention_mask\": tf.cast(input_ids != pad_token, tf.int32),",
            "\"input_ids\": input_ids,",
            "}",
            "return dummy_inputs"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6755,
        "label": "no",
        "change": [
            "class Categorical(Distribution):",
            "self.probabilities = tf.maximum(x=self.probabilities, y=util.epsilon)",
            "",
            "# \"Normalized\" logits",
            "-        self.logits = tf.log(x=self.probabilities + util.epsilon)",
            "+        self.logits = tf.log(x=self.probabilities)",
            "",
            "def sample(self):",
            "# Deterministic: maximum likelihood action"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6757,
        "label": "no",
        "change": [
            "def lstm(x, size=None):",
            "",
            "with tf.variable_scope('lstm'):",
            "internal_input = tf.placeholder(dtype=tf.float32, shape=(None, 2, size))",
            "-        lstm = tf.contrib.rnn.LSTMCell(num_units=size)",
            "+        lstm_cell = tf.contrib.rnn.LSTMCell(num_units=size)",
            "c = internal_input[:, 0, :]",
            "h = internal_input[:, 1, :]",
            "state = tf.contrib.rnn.LSTMStateTuple(c=c, h=h)",
            "-        x, state = lstm(inputs=x, state=state)",
            "+        x, state = lstm_cell(inputs=x, state=state)",
            "",
            "internal_output = tf.stack(values=(state.c, state.h), axis=1)",
            "internal_init = np.zeros(shape=(2, size))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6759,
        "label": "yes",
        "change": [
            "def test_graph_store():",
            "def test_graph_store_conversion():",
            "graph_store = MyGraphStore()",
            "",
            "-    coo = (row, col) = get_edge_index(100, 100, 300)",
            "+    coo = (row, col) = get_random_edge_index(100, 100, 300)",
            "adj = SparseTensor(row=row, col=col, sparse_sizes=(100, 100))",
            "csr, csc = adj.csr()[:2], adj.csc()[:2][::-1]"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 6763,
        "label": "yes",
        "change": [
            "class StableDiffusionInpaintPipelineLegacy(DiffusionPipeline):",
            "init_latents_orig = init_latents",
            "",
            "# add noise to latents using the timesteps",
            "-        noise = torch.randn(init_latents.shape, generator=generator, device=self.device, dtype=dtype)",
            "+        noise = randn_tensor(init_latents.shape, generator=generator, device=self.device, dtype=dtype)",
            "init_latents = self.scheduler.add_noise(init_latents, noise, timestep)",
            "latents = init_latents",
            "return latents, init_latents_orig, noise"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 6775,
        "label": "no",
        "change": [
            "def test_load_model_from_checkpoint(tmpdir, model_template):",
            "for (old_name, old_p), (new_name, new_p) in zip(model.named_parameters(), pretrained_model.named_parameters()):",
            "assert torch.all(torch.eq(old_p, new_p)), 'loaded weights are not the same as the saved weights'",
            "",
            "+    # Check `test` on pretrained model:",
            "new_trainer = Trainer(**trainer_options)",
            "new_trainer.test(pretrained_model)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6777,
        "label": "no",
        "change": [
            "def unique_all(",
            "decimal = tf.range(tf.size(inverse_indices)) / tf.size(inverse_indices)",
            "inv_sorted = tf.argsort(tf.cast(inverse_indices, dtype=decimal.dtype) + decimal)",
            "tot_counts = tf.concat(",
            "-            [tf.zeros((1,), dtype=counts.dtype), tf.cumsum(counts, axis=0)[:-1]], 0)",
            "+            [tf.zeros((1,), dtype=counts.dtype), tf.cumsum(counts, axis=0)[:-1]], 0",
            "+        )",
            "indices = inv_sorted.numpy()[tot_counts]",
            "",
            "return Results("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6779,
        "label": "no",
        "change": [
            "def matrix_rank(",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "# ToDo: add support for default rtol value here, for the case where None is provided",
            "-    ret = torch.linalg.matrix_rank(x, atol=rtol, out=out)",
            "+    ret = torch.linalg.matrix_rank(x, rtol=rtol, out=out)",
            "return torch.tensor(ret, dtype=ivy.default_int_dtype(as_native=True))",
            "",
            "",
            "-matrix_rank.unsupported_dtypes = (\"float16\",)",
            "+matrix_rank.unsupported_dtypes = (",
            "+    \"float16\",",
            "+    \"bfloat16\",",
            "+)",
            "matrix_rank.support_native_out = True"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6780,
        "label": "no",
        "change": [
            "class NewSessionCreator(tf.train.ChiefSessionCreator):",
            "\"\"\"",
            "Args:",
            "target, graph, config: same as :meth:`Session.__init__()`.",
            "-            config: defaults to :func:`tfutils.get_default_sess_config()`",
            "+            config: a :class:`tf.ConfigProto` instance, defaults to :func:`tfutils.get_default_sess_config()`",
            "\"\"\"",
            "assert graph is None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6784,
        "label": "no",
        "change": [
            "class PipelineTest(tf.test.TestCase):",
            "tf.app.flags.FLAGS.output_dir = self.output_dir",
            "tf.app.flags.FLAGS.metrics = yaml.dump([",
            "\"log_perplexity\", \"bleu\", \"rouge_1/f_score\", \"rouge_l/f_score\"])",
            "-",
            "-    \"\"\"",
            "-      log_perplexity,bleu,rouge_1/f_score,rouge_l/f_score\"\"\"",
            "-    # tf.app.flags.FLAGS.train_source = sources_train.name",
            "-    # tf.app.flags.FLAGS.train_target = targets_train.name",
            "-    # tf.app.flags.FLAGS.vocab_source = vocab_source.name",
            "-    # tf.app.flags.FLAGS.vocab_target = vocab_target.name",
            "tf.app.flags.FLAGS.model = \"AttentionSeq2Seq\"",
            "tf.app.flags.FLAGS.model_params = \"\"\"",
            "attention.params:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6797,
        "label": "no",
        "change": [
            "def _main(args, output_file):",
            "# Fix seed for stochastic decoding",
            "if args.seed is not None and not args.no_seed_provided:",
            "np.random.seed(args.seed)",
            "-        torch.manual_seed(args.seed)",
            "+        utils.set_torch_seed(args.seed)",
            "",
            "use_cuda = torch.cuda.is_available() and not args.cpu"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6801,
        "label": "no",
        "change": [
            "def get_flattened_gradient(loss, variables):",
            "\"\"\"",
            "gradients = tf.gradients(loss, variables)",
            "",
            "-    return tf.concat(axis=0, values=[tf.reshape(grad, [get_number_of_elements(v)])",
            "-                         for (v, grad) in zip(variables, gradients)])",
            "+    return tf.concat(axis=0, values=[tf.reshape(grad, [get_number_of_elements(v)]) for (v, grad) in zip(variables, gradients)])",
            "",
            "",
            "class FlatVarHelper(object):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6803,
        "label": "yes",
        "change": [
            "def fully_connected_with_w(x, use_bias=True, sn=False, reuse=False, scope='linea",
            "if sn :",
            "w = tf.get_variable(\"kernel\", [channels, 1], tf.float32,",
            "initializer=weight_init, regularizer=weight_regularizer)",
            "+            w = spectral_norm(w)",
            "+",
            "if use_bias :",
            "bias = tf.get_variable(\"bias\", [1],",
            "initializer=tf.constant_initializer(0.0))",
            "",
            "-                x = tf.matmul(x, spectral_norm(w)) + bias",
            "+                x = tf.matmul(x, w) + bias",
            "else :",
            "-                x = tf.matmul(x, spectral_norm(w))",
            "+                x = tf.matmul(x, w)",
            "+",
            "else :",
            "x = tf.layers.dense(x, units=1, kernel_initializer=weight_init, kernel_regularizer=weight_regularizer, use_bias=use_bias)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 6804,
        "label": "no",
        "change": [
            "class BlockwiseMagnitudeSparsifier(L0_projection_sparsifier):",
            "pre_mask=(pre_mask.transpose(1, 0) if pre_mask else None),",
            ").transpose(1, 0)",
            "padded_param = self._padding_into_full_blocks(param)",
            "-        block_l1norms = padded_param.reshape(-1, 1, self.block_size).sum(dim=2)",
            "+        block_l1norms = (",
            "+            torch.abs(padded_param).reshape(-1, 1, self.block_size).sum(dim=2)",
            "+        )",
            "max_num_blocks = self._num_blocks_kept(param)",
            "",
            "topk_threshold = ("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6807,
        "label": "no",
        "change": [
            "class LJSpeech(datasets.GeneratorBasedBuilder):",
            "features=datasets.Features(",
            "{",
            "\"id\": datasets.Value(\"string\"),",
            "-                    \"audio\": datasets.features.Audio(sampling_rate=22050),",
            "+                    \"audio\": datasets.Audio(sampling_rate=22050),",
            "\"file\": datasets.Value(\"string\"),",
            "\"text\": datasets.Value(\"string\"),",
            "\"normalized_text\": datasets.Value(\"string\"),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6809,
        "label": "no",
        "change": [
            "class Batch(Data):",
            "for i, data in enumerate(data_list):",
            "num_nodes = data.num_nodes",
            "batch.batch.append(torch.full((num_nodes, ), i, dtype=torch.long))",
            "-            for key in keys:",
            "+            for key in data.keys:",
            "item = data[key]",
            "item = item + cumsum if batch.cumsum(key, item) else item",
            "batch[key].append(item)",
            "cumsum += num_nodes",
            "",
            "for key in keys:",
            "-            batch[key] = torch.cat(batch[key], dim=data_list[0].cat_dim(key))",
            "+            batch[key] = torch.cat(",
            "+                batch[key], dim=data_list[0].cat_dim(key, batch[key][0]))",
            "batch.batch = torch.cat(batch.batch, dim=-1)",
            "return batch.contiguous()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6810,
        "label": "no",
        "change": [
            "def scale_and_mask(tensor, scale=1.0, mask=None):",
            ":param scale: a positive scale",
            ":type scale: torch.Tensor or number",
            ":param mask: an optional packed tensor mask",
            "-    :type mask: torch.ByteTensor or None",
            "+    :type mask: torch.BoolTensor or None",
            "\"\"\"",
            "if isinstance(scale, torch.Tensor) and scale.dim():",
            "raise NotImplementedError('non-scalar scale is not supported')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6811,
        "label": "yes",
        "change": [
            "def audio_config():",
            "@pytest.mark.parametrize(\"encoder\", [\"rnn\", \"stacked_cnn\", \"parallel_cnn\", \"stacked_parallel_cnn\", \"rnn\", \"cnnrnn\"])",
            "def test_audio_input_feature(audio_config: Dict, encoder: str) -> None:",
            "audio_config.update({\"encoder\": encoder})",
            "-    audio_input_feature = AudioInputFeature(audio_config)",
            "-    audio_tensor = torch.randn([BATCH_SIZE, SEQ_SIZE, AUDIO_W_SIZE], dtype=torch.float32)",
            "+    audio_input_feature = AudioInputFeature(audio_config).to(DEVICE)",
            "+    audio_tensor = torch.randn([BATCH_SIZE, SEQ_SIZE, AUDIO_W_SIZE], dtype=torch.float32).to(DEVICE)",
            "encoder_output = audio_input_feature(audio_tensor)",
            "-    assert encoder_output[\"encoder_output\"].shape[1:] == audio_input_feature.encoder_obj.output_shape",
            "+    assert encoder_output[\"encoder_output\"].shape[1:] == audio_input_feature.output_shape"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 6816,
        "label": "no",
        "change": [
            "def main(args):  # pylint: disable=redefined-outer-name",
            "print(\" > Partial model initialization.\")",
            "model_dict = model.state_dict()",
            "model_dict = set_init_dict(model_dict, checkpoint['model'], c)",
            "+            # torch.save(model_dict, os.path.join(OUT_PATH, 'state_dict.pt'))",
            "+            # print(\"State Dict saved for debug in: \", os.path.join(OUT_PATH, 'state_dict.pt'))",
            "model.load_state_dict(model_dict)",
            "del model_dict"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6819,
        "label": "no",
        "change": [
            "class MaskEstimator(torch.nn.Module):",
            "",
            "# Calculate amplitude: (B, C, T, F) -> (B, C, T, F)",
            "if isinstance(xs, ComplexTensor) or (",
            "-            is_torch_1_8_plus and torch.is_complex(xs)",
            "+            is_torch_1_9_plus and torch.is_complex(xs)",
            "):",
            "xs = (xs.real ** 2 + xs.imag ** 2) ** 0.5",
            "# xs: (B, C, T, F) -> xs: (B * C, T, F)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6820,
        "label": "no",
        "change": [
            "class BatchNormalizationBase(Layer):",
            "offset += then_offset",
            "return (scale, offset)",
            "",
            "-        # Determine a boolean value for `training`: could be True, False, or",
            "-        # None.",
            "-        training_value = control_flow_util.constant_value(training)",
            "if training_value == False:  # noqa: E712",
            "mean, variance = self.moving_mean, self.moving_variance",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6823,
        "label": "no",
        "change": [
            "class Watcher(object):",
            "self._generator = directory_watcher.DirectoryWatcher(",
            "logdir,",
            "loader(save, namespace),",
            "-            io_wrapper.IsTensorFlowEventsFile)",
            "+            IsNewTensorFlowEventsFile)",
            "self._first_event_timestamp = None",
            "self._shutdown = False",
            "self._thread = threading.Thread(target=self._thread_body)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6824,
        "label": "no",
        "change": [
            "class SSIM(nn.Module):",
            "channel: int) -> torch.Tensor:",
            "return F.conv2d(input, kernel, padding=self.padding, groups=channel)",
            "",
            "-    def forward(self, img1: torch.Tensor, img2: torch.Tensor) -> torch.Tensor:  # type: ignore",
            "+    def forward(  # type: ignore",
            "+            self,",
            "+            img1: torch.Tensor,",
            "+            img2: torch.Tensor) -> torch.Tensor:",
            "if not torch.is_tensor(img1):",
            "raise TypeError(\"Input img1 type is not a torch.Tensor. Got {}\"",
            ".format(type(img1)))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6832,
        "label": "no",
        "change": [
            "def where(",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "x1, x2 = ivy.promote_types_of_inputs(x1, x2)",
            "-    return tf.experimental.numpy.where(condition, x1, x2)",
            "+    return tf.cast(tf.experimental.numpy.where(condition, x1, x2), x1.dtype)",
            "",
            "",
            "# Extra #"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6833,
        "label": "no",
        "change": [
            "class CTC(torch.nn.Module):",
            "ys_hat = ys_hat.transpose(0, 1)",
            "if self.ctc_type == \"warpctc\" or dtype == torch.float16:",
            "# warpctc only supports float32",
            "+            # torch.ctc does not support float16 (#1751)",
            "ys_hat = ys_hat.to(dtype=torch.float32)",
            "-        else:",
            "+        if self.ctc_type == \"builtin\":",
            "# use GPU when using the cuDNN implementation",
            "ys_true = to_device(self, ys_true)",
            "self.loss = to_device(self, self.loss_fn(ys_hat, ys_true, hlens, olens)).to(dtype=dtype)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6834,
        "label": "no",
        "change": [
            "print('F', F.grad)",
            "i = torch.LongTensor([[0, 1], [2, 0]])",
            "v = torch.FloatTensor([3, 4])",
            "a = torch.sparse.FloatTensor(i, v, torch.Size([3, 3]))",
            "+print(a.to_dense())",
            "f = torch.FloatTensor([[1, 2], [3, 4], [5, 6]])",
            "A = Variable(a, requires_grad=True)",
            "F = Variable(f, requires_grad=True)",
            "-",
            "out = mm()(A, F)",
            "out = out.mean()",
            "out.backward()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6835,
        "label": "no",
        "change": [
            "class Callback(object):",
            "def trigger_epoch(self):",
            "\"\"\"",
            "Triggered after every epoch.",
            "-",
            "-        In this function, ``self.epoch_num`` would be the number of epoch finished.",
            "\"\"\"",
            "self.epoch_num += 1",
            "self._trigger_epoch()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6838,
        "label": "no",
        "change": [
            "def setup(app):",
            "",
            "# @jpchen's hack to get rtd builder to install latest pytorch",
            "if 'READTHEDOCS' in os.environ:",
            "-    os.system('pip install https://download.pytorch.org/whl/cpu/torch-1.0.0-cp27-cp27mu-linux_x86_64.whl')",
            "+    os.system('pip install https://download.pytorch.org/whl/cpu/torch-1.1.0-cp27-cp27mu-linux_x86_64.whl')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6839,
        "label": "yes",
        "change": [
            "def trunc(",
            "elif not (\"int\" in str(x.dtype)):",
            "if not ret.get_shape().ndims == 0:",
            "ret = tf.tensor_scatter_nd_update(",
            "-                x, tf.where(tf.greater(x, 0)), tf.math.floor(x[x > 0])",
            "+                x, tf.where(tf.greater_equal(x, 0)), tf.math.floor(x[x >= 0])",
            ")",
            "ret = tf.tensor_scatter_nd_update(",
            "ret, tf.where(tf.less(x, 0)), tf.math.ceil(x[x < 0])",
            ")",
            "else:",
            "-            ret = (tf.math.floor if ret > 0 else tf.math.ceil)(ret)",
            "+            ret = (tf.math.floor if ret >= 0 else tf.math.ceil)(ret)",
            "return ret"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 6841,
        "label": "no",
        "change": [
            "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,",
            "if pred == tgt_vocab['<eos>']:",
            "break",
            "output_seq.append(pred.numpy())",
            "-    return ' '.join(tgt_vocab.to_tokens(tf.reshape(output_seq, shape = -1).numpy().tolist())), attention_weight_seq# Alias defined in config.ini",
            "+    return ' '.join(tgt_vocab.to_tokens(tf.reshape(output_seq, shape = -1).numpy().tolist())), attention_weight_seq",
            "+",
            "+",
            "+# Alias defined in config.ini",
            "size = lambda a: tf.size(a).numpy()",
            "",
            "reshape = tf.reshape"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6843,
        "label": "yes",
        "change": [
            "class FocalLoss(nn.Module):",
            "device=input.device, dtype=input.dtype)",
            "",
            "# compute the actual focal loss",
            "-        prob = input_soft * target_one_hot",
            "+        prob = input_soft * target_one_hot + self.eps",
            "focal = -torch.log(prob) * self.alpha * (1. - prob) ** self.gamma",
            "-        loss_tmp = 1. - torch.sum(focal, dim=1)",
            "+        loss_tmp = torch.sum(focal, dim=1)",
            "",
            "loss = -1",
            "if self.reduction == 'none':"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 6848,
        "label": "no",
        "change": [
            "def test_gaussian_mixture_model():",
            "cluster_assignments = dist.Categorical(true_mix_proportions).sample(torch.Size((N,)))",
            "data = dist.Normal(true_cluster_means[cluster_assignments], 1.0).sample()",
            "nuts_kernel = NUTS(gmm, adapt_step_size=True, max_iarange_nesting=1)",
            "-    mcmc_run = MCMC(nuts_kernel, num_samples=500, warmup_steps=200).run(data)",
            "+    mcmc_run = MCMC(nuts_kernel, num_samples=300, warmup_steps=100).run(data)",
            "posterior = EmpiricalMarginal(mcmc_run, sites=[\"phi\", \"cluster_means\"]).mean.sort()[0]",
            "assert_equal(posterior[0], true_mix_proportions, prec=0.05)",
            "assert_equal(posterior[1], true_cluster_means, prec=0.2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6850,
        "label": "no",
        "change": [
            "def tensors_to_literals(tensor_list):",
            "",
            "for tensor in tensor_list:",
            "",
            "-            if type(tensor) == torch.tensor:",
            "+            if type(tensor) == torch.Tensor:",
            "",
            "literal_list.append(tensor.item())"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6852,
        "label": "no",
        "change": [
            "class WikiBio(datasets.GeneratorBasedBuilder):",
            "",
            "def _split_generators(self, dl_manager):",
            "\"\"\"Returns SplitGenerators.\"\"\"",
            "-        my_urls = _URL",
            "-        data_dir = dl_manager.download_and_extract(my_urls)",
            "+        data_dir = dl_manager.download_and_extract(_URL)",
            "data_path = os.path.join(data_dir, \"wikipedia-biography-dataset\")",
            "return [",
            "datasets.SplitGenerator("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6857,
        "label": "no",
        "change": [
            "class TemporalConvNet(nn.Module):",
            "elif self.mask_nonlinear == \"relu\":",
            "est_mask = F.relu(score)",
            "elif self.mask_nonlinear == \"sigmoid\":",
            "-            est_mask = F.sigmoid(score)",
            "+            est_mask = torch.sigmoid(score)",
            "elif self.mask_nonlinear == \"tanh\":",
            "-            est_mask = F.tanh(score)",
            "+            est_mask = torch.tanh(score)",
            "else:",
            "raise ValueError(\"Unsupported mask non-linear function\")",
            "return est_mask"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6863,
        "label": "no",
        "change": [
            "class _QueueRunner(threading.Thread):",
            "",
            "def __init__(self, input_reader, queue, keys, dtypes):",
            "threading.Thread.__init__(self)",
            "-        self.sess = tf.get_default_session()",
            "+        self.sess = tf1.get_default_session()",
            "self.daemon = True",
            "self.input_reader = input_reader",
            "self.keys = keys",
            "self.queue = queue",
            "-        self.placeholders = [tf.placeholder(dtype) for dtype in dtypes]",
            "+        self.placeholders = [tf1.placeholder(dtype) for dtype in dtypes]",
            "self.enqueue_op = queue.enqueue(dict(zip(keys, self.placeholders)))",
            "",
            "def enqueue(self, batch):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6865,
        "label": "no",
        "change": [
            "def gpt2_model_mesh(features, labels, mode, params):",
            "",
            "output = gpt2.model(X=features, params=params, mesh=mesh,",
            "past=None, reuse=tf.AUTO_REUSE,",
            "-                                    train=mode==tf.estimator.ModeKeys.TRAIN, mesh=mesh)",
            "+                                    train=mode==tf.estimator.ModeKeys.TRAIN)",
            "",
            "",
            "# logits :: [batch, seq, vocab]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6868,
        "label": "no",
        "change": [
            "def test_enable_reproducibility(ray_start_4_cpus_2_gpus, use_gpu):",
            "torch.randn(dataset_length, 3, 32, 32),",
            "torch.randint(low=0, high=1000, size=(dataset_length,)),",
            ")",
            "-        dataloader = torch.utils.data.DataLoader(dataset, batch_size=64)",
            "+",
            "+        # num_workers > 0 tests for https://github.com/ray-project/ray/issues/30247",
            "+        dataloader = torch.utils.data.DataLoader(",
            "+            dataset, batch_size=64, num_workers=data_loader_num_workers",
            "+        )",
            "dataloader = train.torch.prepare_data_loader(dataloader)",
            "",
            "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6872,
        "label": "no",
        "change": [
            "def main():",
            "eval_datasets = [eval_dataset]",
            "if data_args.task_name == \"mnli\":",
            "mnli_mm_data_args = dataclasses.replace(data_args, task_name=\"mnli-mm\")",
            "-            eval_datasets.append(",
            "-                GlueDataset(mnli_mm_data_args, tokenizer=tokenizer, local_rank=training_args.local_rank, evaluate=True)",
            "-            )",
            "+            eval_datasets.append(GlueDataset(mnli_mm_data_args, tokenizer=tokenizer, evaluate=True))",
            "",
            "for eval_dataset in eval_datasets:",
            "result = trainer.evaluate(eval_dataset=eval_dataset)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6876,
        "label": "no",
        "change": [
            "class Resnet101(Network):",
            "self._layers['conv5_3'] = net",
            "with tf.variable_scope('resnet_v1_101', 'resnet_v1_101',",
            "regularizer=tf.contrib.layers.l2_regularizer(cfg.TRAIN.WEIGHT_DECAY)):",
            "-   # build the anchors for the image",
            "+      # build the anchors for the image",
            "self._anchor_component()",
            "",
            "# rpn"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6877,
        "label": "no",
        "change": [
            "class UnetModelTests(ModelTesterMixin, unittest.TestCase):",
            "# fmt: off",
            "expected_output_slice = torch.tensor([0.2891, -0.1899, 0.2595, -0.6214, 0.0968, -0.2622, 0.4688, 0.1311, 0.0053])",
            "# fmt: on",
            "-        self.assertTrue(torch.allclose(output_slice, expected_output_slice, rtol=1e-3))",
            "+        self.assertTrue(torch.allclose(output_slice, expected_output_slice, rtol=1e-2))",
            "",
            "",
            "class GlideSuperResUNetTests(ModelTesterMixin, unittest.TestCase):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6888,
        "label": "no",
        "change": [
            "class SingleCostTrainer(TowerTrainer):",
            "",
            "grads_no_vars = xla.compile(xla_func)",
            "if ctx.has_own_variables:",
            "-                    varlist = ctx.get_collection_in_tower(tf.GraphKeys.TRAINABLE_VARIABLES)",
            "+                    varlist = ctx.get_collection_in_tower(tfv1.GraphKeys.TRAINABLE_VARIABLES)",
            "else:",
            "-                    varlist = tf.trainable_variables()",
            "+                    varlist = tfv1.trainable_variables()",
            "return list(zip(grads_no_vars, varlist))",
            "",
            "return get_grad_fn"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6895,
        "label": "yes",
        "change": [
            "class InMemoryDataset(Dataset):",
            "",
            "for item, key in product(data_list, keys):",
            "data[key].append(item[key])",
            "-            s = slices[key][-1] + item[key].size(item.cat_dim(key))",
            "+            s = slices[key][-1] + item[key].size(item.cat_dim(key, item))",
            "slices[key].append(s)",
            "",
            "for key in keys:",
            "-            data[key] = torch.cat(data[key], dim=data_list[0].cat_dim(key))",
            "+            data[key] = torch.cat(",
            "+                data[key], dim=data_list[0].cat_dim(key, item))",
            "slices[key] = torch.LongTensor(slices[key])",
            "",
            "return data, slices"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 6896,
        "label": "yes",
        "change": [
            "class CLIPModel(CLIPPreTrainedModel):",
            "",
            "self.visual_projection = nn.Linear(self.vision_embed_dim, self.projection_dim, bias=False)",
            "self.text_projection = nn.Linear(self.text_embed_dim, self.projection_dim, bias=False)",
            "-        self.logit_scale = nn.Parameter(torch.ones([]))",
            "+        self.logit_scale = nn.Parameter(torch.ones([]) * self.config.logit_scale_init_value)",
            "",
            "self.init_weights()"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 6898,
        "label": "yes",
        "change": [
            "class BBoxHead(nn.Module):",
            "keep_inds = pos_is_gts_.new_ones(num_rois)",
            "keep_inds[:len(pos_is_gts_)] = pos_keep",
            "",
            "-            bboxes_list.append(bboxes[keep_inds])",
            "+            bboxes_list.append(bboxes[keep_inds.type(torch.bool)])",
            "",
            "return bboxes_list"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 6899,
        "label": "no",
        "change": [
            "class GatSuperNode(MessagePassing):",
            "",
            "# this is not correct it should be more hs and not x_i there based on the paper supplementary table 3!",
            "# in the paper it's h_s_ex in the pytorch it's x !",
            "-        cs_i = scatter_add( torch.mul(asv, self.mol_attend(self.dropout(h_s_ex))).transpose(0,1), \\",
            "+        cs_i = scatter_add( torch.mul(asv, self.mol_attend(self.dropout(x))).transpose(0,1), \\",
            "batch, dim_size=superatom_num).transpose(0,1)",
            "",
            "cs_i = F.elu(cs_i)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6908,
        "label": "no",
        "change": [
            "class TFAdaptiveSoftmaxMask(tf.keras.layers.Layer):",
            "cur_logprob = self._gather_logprob(cur_tail_logprob, cur_target)",
            "cur_logprob += cur_head_logprob[:, self.cutoff_ends[1] + i - 1]",
            "if target is not None:",
            "-                    loss += tf.scatter_nd(mask_idx, -cur_logprob, tf.cast(shape_list(loss), dtype=tf.int64))",
            "+                    loss += tf.scatter_nd(mask_idx, -cur_logprob, shape_list(loss))",
            "out = tf.concat(out, axis=-1)",
            "",
            "if target is not None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6912,
        "label": "no",
        "change": [
            "class SpeedyResNet:",
            "# TODO: add whitening",
            "self.net = [",
            "nn.Conv2d(3, 64, kernel_size=1),",
            "-      nn.BatchNorm2D(64, track_running_stats=False, eps=1e-12, momentum=0.8),",
            "+      nn.BatchNorm2d(64, track_running_stats=False, eps=1e-12, momentum=0.8),",
            "lambda x: x.relu(),",
            "ConvGroup(64, 128, short=False),",
            "ConvGroup(128, 256, short=True),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6913,
        "label": "no",
        "change": [
            "def binary_cross_entropy(pred,",
            "torch.Tensor: The calculated loss",
            "\"\"\"",
            "if pred.dim() != label.dim():",
            "-        label, weight = _expand_binary_labels(label, weight, pred.size(-1))",
            "+        label, weight = _expand_onehot_labels(label, weight, pred.size(-1))",
            "",
            "# weighted element-wise losses",
            "if weight is not None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6916,
        "label": "no",
        "change": [
            "class Visformer(nn.Module):",
            "self.num_features = embed_dim if self.vit_stem else embed_dim * 2",
            "self.norm = norm_layer(self.num_features)",
            "self.global_pool, self.head = create_classifier(self.num_features, self.num_classes, pool_type=global_pool)",
            "-        self.head = nn.Linear(self.num_features, num_classes)",
            "",
            "# weights init",
            "if self.pos_embed:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6921,
        "label": "no",
        "change": [
            "class GPT2ModelLanguageGenerationTest(unittest.TestCase):",
            "@slow",
            "def test_lm_generate_gpt2(self):",
            "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")",
            "-        input_ids = torch.tensor([[463, 3290]], dtype=torch.long, device=torch_device)  # The dog",
            "+        input_ids = torch.tensor([[464, 3290]], dtype=torch.long, device=torch_device)  # The dog",
            "expected_output_ids = [",
            "464,",
            "3290,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6925,
        "label": "no",
        "change": [
            "class ResNeXtBlock(tf.keras.Model):",
            "bot_channels = int(round(num_channels * bot_mul))",
            "self.conv1 = tf.keras.layers.Conv2D(bot_channels, 1, strides=1)",
            "self.conv2 = tf.keras.layers.Conv2D(bot_channels, 3, strides=strides,",
            "-                                            padding=\"same\",  groups=bot_channels//groups)",
            "+                                            padding=\"same\",",
            "+                                            groups=bot_channels//groups)",
            "self.conv3 = tf.keras.layers.Conv2D(num_channels, 1, strides=1)",
            "self.bn1 = tf.keras.layers.BatchNormalization()",
            "self.bn2 = tf.keras.layers.BatchNormalization()",
            "self.bn3 = tf.keras.layers.BatchNormalization()",
            "if use_1x1conv:",
            "-            self.conv4 = tf.keras.layers.Conv2D(num_channels, 1, strides=strides)",
            "+            self.conv4 = tf.keras.layers.Conv2D(num_channels, 1,",
            "+                                                strides=strides)",
            "self.bn4 = tf.keras.layers.BatchNormalization()",
            "else:",
            "self.conv4 = None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6930,
        "label": "yes",
        "change": [
            "class BloomForSequenceClassification(BloomPreTrainedModel):",
            "sequence_lengths = -1",
            "else:",
            "if input_ids is not None:",
            "-                sequence_lengths = torch.ne(input_ids, self.config.pad_token_id).sum(dim=-1) - 1",
            "+                sequence_lengths = (torch.ne(input_ids, self.config.pad_token_id).sum(-1) - 1).to(logits.device)",
            "else:",
            "sequence_lengths = -1",
            "logger.warning("
        ],
        "comments": "",
        "Symptom": "return warning",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 6931,
        "label": "no",
        "change": [
            "class StagingInput(FeedfreeInput):",
            "def _setup_graph(self):",
            "self.stage_op = self._input._get_stage_op()",
            "unstage_ops = self._input._get_unstage_ops()",
            "-            unstage_op = tf.group(unstage_ops, name='unstage_all')",
            "+            unstage_op = tf.group(*unstage_ops, name='unstage_all')",
            "self._check_dependency_op = unstage_ops[0]",
            "self.fetches = tf.train.SessionRunArgs(",
            "fetches=[self.stage_op, unstage_op])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6933,
        "label": "no",
        "change": [
            "class Loss(nn.Module):",
            "# positive mask will never selected",
            "# 获取负样本",
            "con_neg = con.clone()",
            "-        con_neg[mask] = torch.tensor(0.0)",
            "+        con_neg[mask] = 0.0",
            "# 按照confidence_loss降序排列 con_idx(Tensor: [N, 8732])",
            "_, con_idx = con_neg.sort(dim=1, descending=True)",
            "_, con_rank = con_idx.sort(dim=1)  # 这个步骤比较巧妙"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6940,
        "label": "no",
        "change": [
            "class LightningModule(pl.LightningModule):",
            "Lightning modules used in NNI should inherit this class.",
            "\"\"\"",
            "",
            "-    def set_model(self, model: Union[Type[nn.Module], nn.Module]) -> NoReturn:",
            "-        if isinstance(model, type):",
            "-            self.model = model()",
            "-        else:",
            "+    def set_model(self, model: Union[Type[nn.Module], nn.Module]) -> None:",
            "+        if isinstance(model, nn.Module):",
            "self.model = model",
            "+        else:",
            "+            self.model = model()",
            "",
            "",
            "Trainer = nni.trace(pl.Trainer)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6951,
        "label": "no",
        "change": [
            "class SequenceGenerator(object):",
            "# and values < cand_size indicate candidate active hypos.",
            "# After, the min values per row are the top candidate active hypos",
            "active_mask = buffer('active_mask')",
            "-            torch.add((eos_mask*cand_size).type_as(cand_offsets), cand_offsets[:eos_mask.size(1)],",
            "+            torch.add(eos_mask.type_as(cand_offsets)*cand_size, cand_offsets[:eos_mask.size(1)],",
            "out=active_mask)",
            "",
            "# get the top beam_size active hypotheses, which are just the hypos"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6954,
        "label": "no",
        "change": [
            "def sum(",
            "dtype=dtype,",
            "out=out,",
            ")",
            "-    return torch.sum(input=x, dim=axis, dtype=dtype, keepdim=keepdims, out=out)",
            "+    return torch.sum(input=x, dim=axis, dtype=dtype, keepdim=keepdims)",
            "",
            "",
            "def var("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6955,
        "label": "no",
        "change": [
            "class Synchronization(Optimizer):",
            "self.update_weight = update_weight",
            "",
            "def tf_step(self, time, variables, source_variables, **kwargs):",
            "-        last_update = tf.get_variable(name='last-update', dtype=tf.int32, initializer=(-self.update_frequency), trainable=False)",
            "+        last_update = tf.get_variable(",
            "+            name='last-update',",
            "+            dtype=tf.int32,",
            "+            initializer=(-self.update_frequency),",
            "+            trainable=False",
            "+        )",
            "",
            "def true_fn():",
            "diffs = list()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6956,
        "label": "no",
        "change": [
            "def test_train_resume_sequence_tagging_training(results_base_path, tasks_base_pa",
            "corpus_1 = flair.datasets.ColumnCorpus(",
            "data_folder=tasks_base_path / \"fashion\", column_format={0: \"text\", 2: \"ner\"}",
            ")",
            "-    corpus_2 = flair.datasets.GERMEVAL(base_path=tasks_base_path)",
            "+    corpus_2 = flair.datasets.GERMEVAL_14(base_path=tasks_base_path)",
            "",
            "corpus = MultiCorpus([corpus_1, corpus_2])",
            "tag_dictionary = corpus.make_tag_dictionary(\"ner\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6962,
        "label": "no",
        "change": [
            "class LinearStack(torch.nn.Module):",
            "self.output_dim = output_dim",
            "self.hidden_dim = hidden_dim",
            "",
            "-        self.input_layer = VerboseLinear(in_features=self.input_dim,",
            "-                                         out_features=self.hidden_dim)",
            "+        self.input_layer = torch.nn.Linear(in_features=self.input_dim,",
            "+                                           out_features=self.hidden_dim)",
            "self.layers = torch.nn.ModuleList([",
            "torch.nn.Linear(in_features=self.hidden_dim,",
            "out_features=self.hidden_dim,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6963,
        "label": "no",
        "change": [
            "def topk(x, ratio, batch, min_score=None, tol=1e-7):",
            "index = torch.arange(batch.size(0), dtype=torch.long, device=x.device)",
            "index = (index - cum_num_nodes[batch]) + (batch * max_num_nodes)",
            "",
            "-        dense_x = x.new_full((batch_size * max_num_nodes, ), -2)",
            "+        dense_x = x.new_full((batch_size * max_num_nodes, ),",
            "+                             torch.finfo(x.dtype).min)",
            "dense_x[index] = x",
            "dense_x = dense_x.view(batch_size, max_num_nodes)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6965,
        "label": "yes",
        "change": [
            "class RecurrentTFModelV2(TFModelV2):",
            "shape=(None, obs_space.shape[0]))",
            "state_in_h = tf.keras.layers.Input(shape=(256, ))",
            "state_in_c = tf.keras.layers.Input(shape=(256, ))",
            "-                seq_in = tf.keras.layers.Input(shape=())",
            "+                seq_in = tf.keras.layers.Input(shape=(), dtype=tf.int32)",
            "",
            "# Send to LSTM cell",
            "lstm_out, state_h, state_c = tf.keras.layers.LSTM("
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 6968,
        "label": "no",
        "change": [
            "class ScalarMix(torch.nn.Module):",
            "normed_weights = torch.nn.functional.softmax(",
            "torch.cat([parameter for parameter in self.scalar_parameters]), dim=0",
            ")",
            "-        normed_weights = torch.split(normed_weights, split_size_or_sections=1)",
            "+        normed_weights_split = torch.split(normed_weights, split_size_or_sections=1)",
            "",
            "pieces = []",
            "-        for weight, tensor in zip(normed_weights, tensors):",
            "+        for weight, tensor in zip(normed_weights_split, tensors):",
            "pieces.append(weight * tensor)",
            "return self.gamma * sum(pieces)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6970,
        "label": "no",
        "change": [
            "def batch_norm(",
            "variance = tf.math.reduce_variance(x, axis=dims)",
            "x = tf.transpose(x, perm=(0, *range(2, ndims), 1))",
            "ret = tf.nn.batch_normalization(x, mean, variance, offset, scale, eps)",
            "-    return tf.transpose(ret, perm=(0, ndims-1, *range(1, ndims-1)))",
            "+    return tf.transpose(ret, perm=(0, ndims - 1, *range(1, ndims - 1)))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6975,
        "label": "yes",
        "change": [
            "logger = logging.getLogger(__name__)  # pylint: disable=invalid-name",
            "",
            "try:",
            "import tensorflow as tf",
            "-    assert int(tf.__version__[0]) >= 2",
            "+    assert hasattr(tf, '__version__') and int(tf.__version__[0]) >= 2",
            "_tf_available = True  # pylint: disable=invalid-name",
            "logger.info(\"TensorFlow version {} available.\".format(tf.__version__))",
            "except (ImportError, AssertionError):"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "null reference error",
        "Action": "removal",
        "Element": "api condition check"
    },
    {
        "number": 6977,
        "label": "no",
        "change": [
            "class NcclBackend(object):",
            "recvbuf_scale = [",
            "torch.zeros(1,",
            "dtype=worker_scale.dtype,",
            "-                        device=torch.device(local_rank)) for i in range(self.size)",
            "+                        device=torch.device(get_accelerator().device_name(local_rank)))",
            "+            for i in range(self.size)",
            "]",
            "",
            "# communication phase 1"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6979,
        "label": "yes",
        "change": [
            "class ModelCheckpoint(Callback):",
            "",
            "# do not save nan, replace with +/- inf",
            "if isinstance(current, torch.Tensor) and torch.isnan(current):",
            "-            current = torch.tensor(float(\"inf\" if self.mode == \"min\" else \"-inf\"))",
            "+            current = torch.tensor(float(\"inf\" if self.mode == \"min\" else \"-inf\"), device=current.device)",
            "",
            "filepath = self._get_metric_interpolated_filepath_name(monitor_candidates, trainer, del_filepath)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 6981,
        "label": "yes",
        "change": [
            "class QNAFModel(QModel):",
            "l_matrix = flat_stddev",
            "l_matrix = tf.exp(l_matrix)",
            "else:",
            "-            l_matrix = tf.map_fn(fn=tf.diag, elems=flat_stddev)",
            "+            l_matrix = tf.linalg.diag(diagonal=flat_stddev)",
            "",
            "l_entries = self.l_entries[name].apply(x=embedding)",
            "l_entries = tf.exp(l_entries)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 6982,
        "label": "no",
        "change": [
            "class UniSpeechSatForPreTraining(UniSpeechSatPreTrainedModel):",
            "...     outputs = model(input_values, mask_time_indices=mask_time_indices)",
            "",
            ">>> # compute cosine similarity between predicted (=projected_states) and target (=projected_quantized_states)",
            "-        >>> cosine_sim = torch.cosine_similarity(",
            "-        ...     outputs.projected_states, outputs.projected_quantized_states, dim=-1",
            "-        ... )",
            "+        >>> cosine_sim = torch.cosine_similarity(outputs.projected_states, outputs.projected_quantized_states, dim=-1)",
            "",
            ">>> # show that cosine similarity is much higher than random",
            ">>> assert cosine_sim[mask_time_indices].mean() > 0.5"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6984,
        "label": "no",
        "change": [
            "class StableDiffusionInpaintLegacyPipelineIntegrationTests(unittest.TestCase):",
            ")",
            "",
            "pipe = StableDiffusionInpaintPipeline.from_pretrained(",
            "-            \"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16, device_map=\"auto\"",
            "+            \"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16",
            ")",
            "pipe.to(torch_device)",
            "pipe.set_progress_bar_config(disable=None)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6995,
        "label": "no",
        "change": [
            "class SelfAttentiveSpanExtractor(SpanExtractor):",
            "# Above we were masking the widths of spans with respect to the max",
            "# span width in the batch. Here we are masking the spans which were",
            "# originally passed in as padding.",
            "-            return attended_text_embeddings * span_indices_mask.unsqueeze(-1).float()",
            "+            return attended_text_embeddings * span_indices_mask.unsqueeze(-1)",
            "",
            "return attended_text_embeddings"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6997,
        "label": "no",
        "change": [
            "def svd(",
            "def outer(",
            "x1: Union[tf.Tensor, tf.Variable],",
            "x2: Union[tf.Tensor, tf.Variable],",
            "-    out: Optional[tf.Tensor] = None",
            "+    out: Optional[tf.Tensor] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "-    ret = tf.experimental.numpy.outer(x1, x2, out=out)",
            "+    ret = tf.experimental.numpy.outer(x1, x2)",
            "if ivy.exists(out):",
            "return ivy.inplace_update(out, ret)",
            "return ret"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6999,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "fake_output = tf.image.grayscale_to_rgb(fake_output)",
            "viz = (tf.concat(2, [input, output, fake_output]) + 1.0) * 128.0",
            "viz = tf.cast(tf.clip_by_value(viz, 0, 255), tf.uint8, name='viz')",
            "-        tf.image_summary('gen', viz, max_outputs=max(30, BATCH))",
            "+        tf.summary.image('gen', viz, max_outputs=max(30, BATCH))",
            "",
            "all_vars = tf.trainable_variables()",
            "self.g_vars = [v for v in all_vars if v.name.startswith('gen/')]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7010,
        "label": "no",
        "change": [
            "class BERTScore(datasets.Metric):",
            "batch_size=batch_size,",
            ")",
            "output_dict = {",
            "-            \"precision\": P,",
            "-            \"recall\": R,",
            "-            \"f1\": F,",
            "+            \"precision\": P.tolist(),",
            "+            \"recall\": R.tolist(),",
            "+            \"f1\": F.tolist(),",
            "\"hashcode\": hashcode,",
            "}",
            "return output_dict"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7013,
        "label": "no",
        "change": [
            "class NCSNppModelTests(ModelTesterMixin, unittest.TestCase):",
            "num_channels = 3",
            "",
            "noise = floats_tensor((batch_size, num_channels) + sizes).to(torch_device)",
            "-        time_step = torch.tensor(batch_size * [10]).to(torch_device)",
            "+        time_step = torch.tensor(batch_size * [10]).to(dtype=torch.int32, device=torch_device)",
            "",
            "return {\"sample\": noise, \"timestep\": time_step}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7018,
        "label": "no",
        "change": [
            "class CnnEncoder(Seq2VecEncoder):",
            "def get_output_dim(self) -> int:",
            "return self._output_dim",
            "",
            "-    def forward(self, tokens: torch.Tensor, mask: torch.Tensor):",
            "+    def forward(self, tokens: torch.Tensor, mask: torch.BoolTensor):",
            "if mask is not None:",
            "-            tokens = tokens * mask.unsqueeze(-1).float()",
            "+            tokens = tokens * mask.unsqueeze(-1)",
            "",
            "# Our input is expected to have shape `(batch_size, num_tokens, embedding_dim)`.  The",
            "# convolution layers expect input of shape `(batch_size, in_channels, sequence_length)`,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7024,
        "label": "no",
        "change": [
            "class Network(object):",
            "y1 = tf.slice(rois, [0, 2], [-1, 1], name=\"y1\") / height",
            "x2 = tf.slice(rois, [0, 3], [-1, 1], name=\"x2\") / width",
            "y2 = tf.slice(rois, [0, 4], [-1, 1], name=\"y2\") / height",
            "-      bboxes = tf.concat([y1, x1, y2, x2], axis=1)",
            "+      # Won't be backpropagated to rois anyway, but to save time",
            "+      bboxes = tf.stop_gradient(tf.concat([y1, x1, y2, x2], axis=1))",
            "pre_pool_size = cfg.POOLING_SIZE * 2",
            "crops = tf.image.crop_and_resize(bottom, bboxes, tf.to_int32(batch_ids), [pre_pool_size, pre_pool_size], name=\"crops\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7025,
        "label": "no",
        "change": [
            "class PretrainedBartModel(PreTrainedModel):",
            "@property",
            "def dummy_inputs(self):",
            "pad_token = self.config.pad_token_id",
            "-        input_ids = torch.tensor([[0, 6, 10, 4, 2], [0, 8, 12, 2, pad_token]])",
            "-        decoder_input_ids, decoder_attn_mask = _prepare_bart_decoder_inputs(self.config, input_ids,)",
            "+        input_ids = torch.tensor([[0, 6, 10, 4, 2], [0, 8, 12, 2, pad_token]], device=self.device)",
            "+        decoder_input_ids, decoder_attn_mask = _prepare_bart_decoder_inputs(self.config, input_ids)",
            "dummy_inputs = {",
            "\"decoder_input_ids\": decoder_input_ids,",
            "\"attention_mask\": input_ids.ne(pad_token),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7027,
        "label": "no",
        "change": [
            "class FNetBasicFourierTransform(nn.Module):",
            "\"dft_mat_hidden\", torch.tensor(linalg.dft(config.hidden_size), dtype=torch.complex64)",
            ")",
            "self.register_buffer(",
            "-                    \"dft_mat_seq\", torch.tensor(linalg.dft(config.tpu_short_sequence_length), dtype=torch.complex64)",
            "+                    \"dft_mat_seq\", torch.tensor(linalg.dft(config.tpu_short_seq_length), dtype=torch.complex64)",
            ")",
            "self.fourier_transform = partial(",
            "two_dim_matmul, matrix_dim_one=self.dft_mat_seq, matrix_dim_two=self.dft_mat_hidden"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7028,
        "label": "no",
        "change": [
            "def list_datasets(with_community_datasets=True, with_details=False):",
            "\"\"\"List all the datasets scripts available on HuggingFace AWS bucket.",
            "",
            "Args:",
            "-        with_community_datasets (Optional ``bool``): Include the community provided datasets (default: ``True``)",
            "-        with_details (Optional ``bool``): Return the full details on the datasets instead of only the short name (default: ``False``)",
            "+        with_community_datasets (``bool``, optional, default ``True``): Include the community provided datasets.",
            "+        with_details (``bool``, optional, default ``False``): Return the full details on the datasets instead of only the short name.",
            "\"\"\"",
            "api = HfApi()",
            "return api.dataset_list(with_community_datasets=with_community_datasets, id_only=bool(not with_details))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7029,
        "label": "no",
        "change": [
            "class TestVerticalFlipFn:",
            "input.to(device)",
            "",
            "expected_transform = torch.tensor([[[1., 0., 0.],",
            "-                                            [0., -1., 3.],",
            "+                                            [0., -1., 2.],",
            "[0., 0., 1.]]])  # 1 x 3 x 3",
            "",
            "identity = torch.tensor([[[1., 0., 0.],"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7030,
        "label": "no",
        "change": [
            "class FSAFHead(RetinaHead):",
            "loc_weight = torch.ones_like(reg_loss)",
            "cls_weight = torch.ones_like(cls_loss)",
            "pos_flags = assigned_gt_inds >= 0  # positive pixel flag",
            "-        pos_indices = torch.nonzero(pos_flags).flatten()",
            "+        pos_indices = torch.nonzero(pos_flags, as_tuple=False).flatten()",
            "",
            "if pos_flags.any():  # pos pixels exist",
            "pos_assigned_gt_inds = assigned_gt_inds[pos_flags]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7035,
        "label": "yes",
        "change": [
            "def bag_config():",
            "@pytest.mark.parametrize(\"encoder\", [\"embed\"])",
            "def test_bag_input_feature(bag_config: Dict, encoder: str) -> None:",
            "bag_config.update({\"encoder\": encoder})",
            "-    bag_input_feature = BagInputFeature(bag_config)",
            "-    bag_tensor = torch.randn([BATCH_SIZE, SEQ_SIZE, BAG_W_SIZE], dtype=torch.float32)",
            "+    bag_input_feature = BagInputFeature(bag_config).to(DEVICE)",
            "+    bag_tensor = torch.randn([BATCH_SIZE, SEQ_SIZE, BAG_W_SIZE], dtype=torch.float32).to(DEVICE)",
            "encoder_output = bag_input_feature(bag_tensor)",
            "-    assert encoder_output[\"encoder_output\"].shape[1:][1:] == bag_input_feature.encoder_obj.output_shape",
            "+    assert encoder_output[\"encoder_output\"].shape[1:][1:] == bag_input_feature.output_shape"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 7036,
        "label": "no",
        "change": [
            "class Callback(object):",
            "def before_train(self, trainer):",
            "self.trainer = trainer",
            "self.graph = tf.get_default_graph()",
            "-        self.sess = tf.get_default_session()",
            "self.epoch_num = 0",
            "self._before_train()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7037,
        "label": "no",
        "change": [
            "def test_tensorflow_shape(",
            "",
            "",
            "@handle_frontend_test(",
            "-fn_tree=\"tensorflow.shape_n\",",
            "-dtype_and_x=helpers.dtype_and_values(",
            "-    available_dtypes=helpers.get_dtypes(\"valid\"),",
            "-    max_num_dims=5),",
            "-output_dtype=st.sampled_from([\"int32\", \"int64\"]),",
            "+    fn_tree=\"tensorflow.shape_n\",",
            "+    dtype_and_x=helpers.dtype_and_values(",
            "+        available_dtypes=helpers.get_dtypes(\"valid\"), max_num_dims=5",
            "+    ),",
            "+    output_dtype=st.sampled_from([\"int32\", \"int64\"]),",
            ")",
            "def test_tensorflow_shape_n(",
            "*,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7038,
        "label": "no",
        "change": [
            "def convert(",
            "if convert_to == 'mil':",
            "return proto_spec # Returns the MIL program",
            "",
            "-    model = coremltools.models.MLModel(proto_spec, useCPUOnly=True)",
            "+    useCPUOnly = kwargs.get(\"useCPUOnly\", True)",
            "+    model = coremltools.models.MLModel(proto_spec, useCPUOnly=useCPUOnly)",
            "",
            "if minimum_deployment_target is not None:",
            "check_deployment_compatibility("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7045,
        "label": "yes",
        "change": [
            "def test_auto_scale_batch_size_set_model_attribute(tmpdir, use_hparams):",
            "",
            "trainer = Trainer(default_root_dir=tmpdir, max_epochs=1, auto_scale_batch_size=True)",
            "trainer.tune(model, datamodule_fit)",
            "-    assert trainer.datamodule == datamodule_fit",
            "after_batch_size = model.hparams.batch_size if use_hparams else model.batch_size",
            "+    assert trainer.datamodule == datamodule_fit",
            "assert before_batch_size != after_batch_size",
            "+    assert after_batch_size <= len(trainer.train_dataloader.dataset)",
            "assert datamodule_fit.batch_size == after_batch_size",
            "# should be left unchanged, since it was not passed to .tune()",
            "assert datamodule_model.batch_size == 111"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 7048,
        "label": "no",
        "change": [
            "class TestSolveWithMask:",
            ")",
            "def test_all_bad(self, device, dtype):",
            "A = torch.ones(10, 3, 3, device=device, dtype=dtype)",
            "-        B = torch.ones(3, 10, device=device, dtype=dtype)",
            "+        B = torch.ones(10, 3, device=device, dtype=dtype)",
            "",
            "X, _, mask = safe_solve_with_mask(B, A)",
            "assert torch.equal(mask, torch.zeros_like(mask))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7053,
        "label": "no",
        "change": [
            "def snapshot(worker):",
            "objects.append(WorkerObject(worker_id=worker.id, object=obj, id=key))",
            "",
            "db.session.add_all(objects)",
            "-    db.session.add_all(models)",
            "db.session.commit()",
            "last_snapshot_keys = current_keys"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7059,
        "label": "no",
        "change": [
            "class MLPDecoder(DecoderBase):",
            "layers.append(nn.Linear(in_dim, dim))",
            "layers.append(nn.ReLU())",
            "if config.layer_norm:",
            "-                layers.append(LayerNorm(dim))",
            "+                layers.append(nn.LayerNorm(dim))",
            "in_dim = dim",
            "if config.out_dim:",
            "out_dim = config.out_dim"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7060,
        "label": "no",
        "change": [
            "arange = tf.range",
            "astype = tf.cast",
            "int32 = tf.int32",
            "float32 = tf.float32",
            "+concat = tf.concat",
            "numpy = lambda x, *args, **kwargs: x.numpy(*args, **kwargs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7061,
        "label": "no",
        "change": [
            "class FrameScoreFeats(AbsFeatsExtract):",
            "pad = self.win_length // 2",
            "input_lengths = input_lengths + 2 * pad",
            "",
            "-            olens = torch.div((input_lengths - self.win_length), self.hop_length) + 1",
            "+            olens = (",
            "+                torch.div(",
            "+                    (input_lengths - self.win_length),",
            "+                    self.hop_length,",
            "+                    rounding_mode=\"floor\",",
            "+                )",
            "+                + 1",
            "+            )",
            "output.masked_fill_(make_pad_mask(olens, output, 1), 0.0)",
            "else:",
            "olens = None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7063,
        "label": "yes",
        "change": [
            "class PytorchBackendCompiler(Compiler):",
            "input_sample = input_data.get_list(1)[0]",
            "if self.device is Device.GPU:",
            "if quantization_type is QuantizationType.HALF:",
            "-                input_sample = [t.cuda().half() for t in input_sample]",
            "+                input_sample = [",
            "+                    t.cuda().half() if torch.is_floating_point(t) else t.cuda()",
            "+                    for t in input_sample",
            "+                ]",
            "else:",
            "input_sample = [t.cuda() for t in input_sample]"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 7067,
        "label": "no",
        "change": [
            "the corresponding GitHub repo: https://github.com/hendrycks/GELUs",
            "import math",
            "",
            "import torch",
            "+import torch.nn as nn",
            "",
            "",
            "def gelu_accurate(x):",
            "if not hasattr(gelu_accurate, \"_a\"):",
            "gelu_accurate._a = math.sqrt(2 / math.pi)",
            "-    return 0.5 * x * (1 + torch.tanh(gelu_accurate._a * (x + 0.044715 * torch.pow(x, 3))))",
            "+    return (",
            "+        0.5 * x * (1 + torch.tanh(gelu_accurate._a * (x + 0.044715 * torch.pow(x, 3))))",
            "+    )",
            "",
            "",
            "def gelu(x: torch.Tensor) -> torch.Tensor:",
            "-    if hasattr(torch.nn.functional, 'gelu'):",
            "+    if hasattr(torch.nn.functional, \"gelu\"):",
            "return torch.nn.functional.gelu(x.float()).type_as(x)",
            "else:",
            "return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7068,
        "label": "no",
        "change": [
            "class GaussianNoise(Exploration):",
            "",
            "super(GaussianNoise, self).__init__(scope=scope, summary_labels=summary_labels)",
            "",
            "-    def tf_explore(self, episode, timestep, action_spec):",
            "-        return tf.random_normal(shape=action_spec['shape'], mean=self.mu, stddev=self.sigma)",
            "+    def tf_explore(self, episode, timestep, shape):",
            "+        return tf.random_normal(shape=shape, mean=self.mu, stddev=self.sigma)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7070,
        "label": "no",
        "change": [
            "class PaintByExampleImageEncoder(CLIPPreTrainedModel):",
            "self.proj_out = nn.Linear(config.hidden_size, self.proj_size)",
            "",
            "# uncondition for scaling",
            "-        self.uncond_vector = nn.Parameter(torch.rand((1, 1, self.proj_size)))",
            "+        self.uncond_vector = nn.Parameter(torch.randn((1, 1, self.proj_size)))",
            "",
            "def forward(self, pixel_values):",
            "clip_output = self.model(pixel_values=pixel_values)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7071,
        "label": "no",
        "change": [
            "class GenerationMixin:",
            ") -> torch.LongTensor:",
            "decoder_start_token_id = self._get_decoder_start_token_id(decoder_start_token_id, bos_token_id)",
            "decoder_input_ids = (",
            "-            torch.ones((input_ids.shape[0], 1), dtype=input_ids.dtype, device=input_ids.device)",
            "-            * decoder_start_token_id",
            "+            torch.ones((input_ids.shape[0], 1), dtype=torch.long, device=input_ids.device) * decoder_start_token_id",
            ")",
            "return decoder_input_ids"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7077,
        "label": "no",
        "change": [
            "class PReluLayer(Layer):",
            "",
            "# with tf.name_scope(name) as scope:",
            "with tf.variable_scope(name):",
            "-            alphas = tf.get_variable(name='alphas', shape=w_shape, initializer=a_init, dtype=LayersConfig.tf_dtype, **a_init_args)",
            "+            alphas = tf.get_variable(",
            "+                name='alphas', shape=w_shape, initializer=a_init, dtype=LayersConfig.tf_dtype, **a_init_args",
            "+            )",
            "try:  # TF 1.0",
            "self.outputs = tf.nn.relu(self.inputs) + tf.multiply(alphas, (self.inputs - tf.abs(self.inputs))) * 0.5",
            "except Exception:  # TF 0.12"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7079,
        "label": "yes",
        "change": [
            "def test_api_training_determinism(csv_filename):",
            "",
            "divergence = False",
            "for weight_1, weight_2 in zip(model_weights_1, model_weights_2):",
            "-            if not np.allclose(weight_1, weight_2):",
            "+            if not torch.allclose(weight_1, weight_2):",
            "divergence = True",
            "break",
            "assert divergence, 'model_1 and model_2 have identical weights with different seeds!'",
            "",
            "for weight_1, weight_3 in zip(model_weights_1, model_weights_3):",
            "-            assert np.allclose(weight_1, weight_3)",
            "+            assert torch.allclose(weight_1, weight_3)",
            "",
            "",
            "def run_api_commands("
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 7080,
        "label": "no",
        "change": [
            "def predict_df(model: pl.LightningModule, df: pd.DataFrame):",
            "def test_pl_save_load():",
            "model: \"pl.LightningModule\" = AdditionModel()",
            "tag = bentoml.pytorch_lightning.save(\"pytorch_lightning_test\", model)",
            "-    info = bentoml.models.get(tag)",
            "-    assert_have_file_extension(info.path, \".pt\")",
            "+    bentoml_model = bentoml.models.get(tag)",
            "+    assert_have_file_extension(bentoml_model.path, \".pt\")",
            "+    assert bentoml_model.info.context.get(\"model_format\") == \"pytorch_lightning:v1\"",
            "",
            "pl_loaded: \"pl.LightningModule\" = bentoml.pytorch_lightning.load(tag)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7082,
        "label": "no",
        "change": [
            "class GFLHead(AnchorHead):",
            "else:",
            "loss_bbox = bbox_pred.sum() * 0",
            "loss_dfl = bbox_pred.sum() * 0",
            "-            weight_targets = torch.tensor(0).cuda()",
            "+            weight_targets = bbox_pred.new_tensor(0)",
            "",
            "# cls (qfl) loss",
            "loss_cls = self.loss_cls("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7088,
        "label": "no",
        "change": [
            "class BiaffineDependencyParser(Model):",
            "\"\"\"",
            "# Parameters",
            "",
            "-        words : Dict[str, torch.LongTensor], required",
            "+        words : TextFieldTensors, required",
            "The output of ``TextField.as_array()``, which should typically be passed directly to a",
            "``TextFieldEmbedder``. This output is a dictionary mapping keys to ``TokenIndexer``",
            "tensors.  At its most basic, using a ``SingleIdTokenIndexer`` this is : ``{\"tokens\":"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7090,
        "label": "no",
        "change": [
            "class SIFTDescriptor(nn.Module):",
            "",
            "ang_bins = []",
            "for i in range(0, self.num_ang_bins):",
            "-            out = self.pk((bo0_big == i).to(input.dtype) * wo0_big + (bo1_big == i).to(input.dtype) * wo1_big)  # noqa",
            "+            out = self.pk((bo0_big == i).to(input.dtype) * wo0_big + (bo1_big == i).to(input.dtype) * wo1_big)",
            "ang_bins.append(out)",
            "ang_bins = torch.cat(ang_bins, dim=1)",
            "ang_bins = ang_bins.view(B, -1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7092,
        "label": "no",
        "change": [
            "class data_prefetcher():",
            "torch.cuda.current_stream().wait_stream(self.stream)",
            "input = self.next_input",
            "target = self.next_target",
            "-        input.record_stream(torch.cuda.current_stream())",
            "-        target.record_stream(torch.cuda.current_stream())",
            "+        if input is not None:",
            "+            input.record_stream(torch.cuda.current_stream())",
            "+        if target is not None:",
            "+            target.record_stream(torch.cuda.current_stream())",
            "self.preload()",
            "return input, target"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7093,
        "label": "no",
        "change": [
            "class Tester(unittest.TestCase):",
            "self.assertAlmostEqual(error.item(), 0.0, places=4)",
            "",
            "# functional",
            "-        self.assertTrue(torch.allclose(points_dst,",
            "-            tgm.TransformPoints()(dst_homo_src, points_src)))",
            "+        self.assertTrue(",
            "+            torch.allclose(",
            "+                points_dst,",
            "+                tgm.TransformPoints()(",
            "+                    dst_homo_src,",
            "+                    points_src)))",
            "",
            "def test_transform_points_gradcheck(self):",
            "# generate input data"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7094,
        "label": "no",
        "change": [
            "class Net(nn.Module):",
            "x = F.elu(self.conv3(adjs[1], x))",
            "x = F.elu(self.conv4(adjs[1], x))",
            "x = self.pool(x)",
            "-        x = x.contiguous().view(-1, num_first_fc * 64)",
            "+        x = x.contiguous().view(-1, num_first_fc * 16)",
            "x = F.elu(self.fc1(x))",
            "x = F.elu(self.fc2(x))",
            "x = F.dropout(x, training=self.training)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7096,
        "label": "no",
        "change": [
            "class WarpCTC(chainer.Chain):",
            "# get ctc loss",
            "from chainer_ctc.warpctc import ctc as warp_ctc",
            "",
            "-        self.loss = warp_ctc(y_hat, ilens, [cuda.to_cpu(l.data) for l in ys])[0]",
            "+        self.loss = warp_ctc(y_hat, ilens, [cuda.to_cpu(y.data) for y in ys])[0]",
            "logging.info(\"ctc loss:\" + str(self.loss.data))",
            "",
            "return self.loss"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7102,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "",
            "log_pi_a_given_s = tf.reduce_sum(",
            "log_probs * tf.one_hot(action, NUM_ACTIONS), 1)",
            "-        advantage = tf.sub(tf.stop_gradient(self.value), futurereward, name='advantage')",
            "+        advantage = tf.subtract(tf.stop_gradient(self.value), futurereward, name='advantage')",
            "policy_loss = tf.reduce_sum(log_pi_a_given_s * advantage, name='policy_loss')",
            "xentropy_loss = tf.reduce_sum(",
            "self.logits * log_probs, name='xentropy_loss')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7106,
        "label": "no",
        "change": [
            "def parse_model(d, ch):  # model_dict, input_channels(3)",
            "LOGGER.info(f\"\\n{'':>3}{'from':>18}{'n':>3}{'params':>10}  {'module':<40}{'arguments':<30}\")",
            "anchors, nc, gd, gw, act = d['anchors'], d['nc'], d['depth_multiple'], d['width_multiple'], d.get('activation')",
            "if act:",
            "-        Conv.act = eval(act)  # redefine default activation, i.e. Conv.act = nn.SiLU()",
            "+        Conv.default_act = eval(act)  # redefine default activation, i.e. Conv.default_act = nn.SiLU()",
            "LOGGER.info(f\"{colorstr('activation:')} {act}\")  # print",
            "na = (len(anchors[0]) // 2) if isinstance(anchors, list) else anchors  # number of anchors",
            "no = na * (nc + 5)  # number of outputs = anchors * (classes + 5)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7107,
        "label": "no",
        "change": [
            "def test_unresolvable_import_paths():",
            "with mock.patch(\"sys.argv\", [\"any.py\", \"--print_config\"]), redirect_stdout(out), pytest.raises(SystemExit):",
            "LightningCLI(TestModel, run=False)",
            "",
            "-    assert \"a_func: torch.softmax\" in out.getvalue()",
            "+    assert \"a_func: torch.nn.Softmax\" in out.getvalue()",
            "",
            "",
            "def test_pytorch_profiler_init_args():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7108,
        "label": "no",
        "change": [
            "def anchor_target_single(flat_anchors,",
            "",
            "",
            "def expand_binary_labels(labels, label_weights, label_channels):",
            "-    bin_labels = labels.new_full(",
            "-        (labels.size(0), label_channels), 0, dtype=torch.float32)",
            "+    bin_labels = labels.new_full((labels.size(0), label_channels), 0)",
            "inds = torch.nonzero(labels >= 1).squeeze()",
            "if inds.numel() > 0:",
            "bin_labels[inds, labels[inds] - 1] = 1"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7109,
        "label": "yes",
        "change": [
            "class TFOptimizer(Optimizer):",
            "arguments: Dict of arguments for passing to fn_loss as **kwargs.",
            "fn_loss: A callable taking arguments as kwargs and returning the loss op.",
            "\"\"\"",
            "-        loss = fn_loss(**arguments)",
            "+        # Trivial operation to enforce control dependency",
            "+        previous_variables = [util.identity_operation(x=variable) for variable in variables]",
            "",
            "# Force loss value to be calculated.",
            "-        with tf.control_dependencies(control_inputs=(loss,)):",
            "-            # Trivial operation to enforce control dependency",
            "-            previous_variables = [util.identity_operation(x=variable) for variable in variables]",
            "+        with tf.control_dependencies(control_inputs=previous_variables):",
            "+            loss = fn_loss(**arguments)",
            "",
            "# The actual tensorflow minimize op.",
            "-        with tf.control_dependencies(control_inputs=previous_variables):",
            "+        with tf.control_dependencies(control_inputs=(loss,)):",
            "# colocate_gradients_with_ops=True",
            "applied = self.optimizer.minimize(loss=loss, var_list=variables)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 7120,
        "label": "no",
        "change": [
            "class Cropping1D(Layer):",
            "return tf.TensorShape([input_shape[0], length, input_shape[2]])",
            "",
            "def call(self, inputs):",
            "-    if sum(self.cropping) >= inputs.shape[1]:",
            "+    if tf.not_equal(tf.size(inputs), 0) and sum(self.cropping) >= inputs.shape[1]:",
            "raise ValueError(",
            "'cropping parameter of Cropping layer is too high,' +",
            "'the result of crop' + str(inputs.shape) + ' with cropping ' +"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7121,
        "label": "no",
        "change": [
            "class SessionUpdate(object):",
            "self.sess = sess",
            "self.assign_ops = defaultdict(list)",
            "for v in vars_to_update:",
            "-            #p = tf.placeholder(v.dtype, shape=v.get_shape())",
            "+            # p = tf.placeholder(v.dtype, shape=v.get_shape())",
            "with tf.device('/cpu:0'):",
            "p = tf.placeholder(v.dtype)",
            "savename = get_savename_from_varname(v.name)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7128,
        "label": "no",
        "change": [
            "def main_fun(argv, ctx):",
            "# Print the summaries to screen.",
            "for name, value in names_to_values.iteritems():",
            "summary_name = 'eval/%s' % name",
            "-      op = tf.scalar_summary(summary_name, value, collections=[])",
            "+      op = tf.summary.scalar(summary_name, value, collections=[])",
            "op = tf.Print(op, [value], summary_name)",
            "tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7129,
        "label": "no",
        "change": [
            "def get_predict_func(config):",
            "",
            "# check output_var_names against output_vars",
            "if output_var_names is not None:",
            "-        output_vars = [tf.get_default_graph().get_tensor_by_name(n) for n in output_var_names]",
            "+        output_vars = [tf.get_default_graph().get_tensor_by_name(get_op_var_name(n)[1])",
            "+                       for n in output_var_names]",
            "else:",
            "output_vars = []"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7130,
        "label": "no",
        "change": [
            "class EpsilonGreedy(Exploration):",
            "tf.random.categorical(random_valid_action_logits, 1), axis=1)",
            "",
            "chose_random = tf.random.uniform(",
            "-            tf.stack([batch_size]),",
            "-            minval=0, maxval=1, dtype=tf.float32) < epsilon",
            "+            tf.stack([batch_size]), minval=0, maxval=1,",
            "+            dtype=tf.float32) < epsilon",
            "",
            "action = tf.cond(",
            "pred=tf.constant(explore, dtype=tf.bool)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7132,
        "label": "yes",
        "change": [
            "class Trainer(Registrable):",
            "self.optimizer.zero_grad()",
            "",
            "loss = self.batch_loss(batch, for_training=True)",
            "+            if torch.isnan(loss):",
            "+                raise ValueError(\"nan loss encountered\")",
            "+",
            "loss.backward()",
            "",
            "train_loss += loss.item()"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "algorithm error",
        "Action": "addition",
        "Element": "api condition check"
    },
    {
        "number": 7137,
        "label": "no",
        "change": [
            "class BertGenerationEmbeddings(nn.Module):",
            "self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)",
            "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load",
            "# any TensorFlow checkpoint file",
            "-        self.LayerNorm = torch.nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)",
            "+        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)",
            "self.dropout = nn.Dropout(config.hidden_dropout_prob)",
            "",
            "# position_ids (1, len position emb) is contiguous in memory and exported when serialized"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7142,
        "label": "no",
        "change": [
            "class WorkerSet:",
            "def session_creator():",
            "logger.debug(\"Creating TF session {}\".format(",
            "config[\"tf_session_args\"]))",
            "-            return tf.Session(",
            "-                config=tf.ConfigProto(**config[\"tf_session_args\"]))",
            "+            return tf1.Session(",
            "+                config=tf1.ConfigProto(**config[\"tf_session_args\"]))",
            "",
            "if isinstance(config[\"input\"], FunctionType):",
            "input_creator = config[\"input\"]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7143,
        "label": "no",
        "change": [
            "def constant_propagation(nnssa):",
            "if len(constant_nodes) > 0:",
            "with tf.Graph().as_default() as graph:",
            "tf.import_graph_def(new_graph, name=\"\")",
            "-                with tf.Session(graph=graph) as sess:",
            "+                with tf.compat.v1.Session(graph=graph) as sess:",
            "query_list = []",
            "for c in constant_nodes:",
            "for j in range(constant_node_num_outputs[c]):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7145,
        "label": "yes",
        "change": [
            "def patch_tf_keras():",
            "from tensorflow.python.keras.engine import training_arrays",
            "from tensorflow.python.keras.engine import training_generator",
            "",
            "-    training_v2 = wandb.util.import_module('tensorflow.python.keras.engine.training_v2')",
            "+    training_v2 = wandb.util.get_module('tensorflow.python.keras.engine.training_v2')",
            "old_arrays = training_arrays.fit_loop",
            "old_generator = training_generator.fit_generator",
            "if training_v2:"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 7148,
        "label": "no",
        "change": [
            "class SignedGCN(torch.nn.Module):",
            "with torch.no_grad():",
            "pos_p = self.discriminate(z, pos_edge_index)[:, :2].max(dim=1)[1]",
            "neg_p = self.discriminate(z, neg_edge_index)[:, :2].max(dim=1)[1]",
            "-        pred = torch.cat([pos_p, neg_p]).cpu()",
            "+        pred = 1 - torch.cat([pos_p, neg_p]).cpu()",
            "y = torch.cat(",
            "-            [pred.new_zeros((pos_p.size(0))),",
            "-             pred.new_ones(neg_p.size(0))])",
            "+            [pred.new_ones((pos_p.size(0))),",
            "+             pred.new_zeros(neg_p.size(0))])",
            "pred, y = pred.numpy(), y.numpy()",
            "",
            "auc = roc_auc_score(y, pred)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7154,
        "label": "yes",
        "change": [
            "def corr2d(X, K):  #@save",
            "Y = tf.Variable(tf.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1)))",
            "for i in range(Y.shape[0]):",
            "for j in range(Y.shape[1]):",
            "-            Y[i, j].assign(tf.reduce_sum(X[i: i + h, j: j + w] * K))",
            "+            Y[i, j].assign(tf.cast(tf.reduce_sum(",
            "+                X[i: i + h, j: j + w] * K), dtype=tf.float32))",
            "return Y"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 7155,
        "label": "no",
        "change": [
            "def get_layer_variables_by_name(name):",
            "A list of Variables.",
            "",
            "\"\"\"",
            "-    return tf.get_collection(tf.GraphKeys.LAYER_VARIABLES + '/' + name + '/')",
            "+    return tf.get_collection(tf.GraphKeys.LAYER_VARIABLES + '/' + name)",
            "",
            "",
            "def get_value(var, session=None):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7157,
        "label": "no",
        "change": [
            "if __name__ == \"__main__\":",
            "parser = ArgumentParser(\"enas\")",
            "parser.add_argument(\"--batch-size\", default=128, type=int)",
            "parser.add_argument(\"--log-frequency\", default=10, type=int)",
            "-    # parser.add_argument(\"--search-for\", choices=[\"macro\", \"micro\"], default=\"macro\")",
            "parser.add_argument(\"--epochs\", default=None, type=int, help=\"Number of epochs (default: macro 310, micro 150)\")",
            "parser.add_argument(\"--visualization\", default=False, action=\"store_true\")",
            "args = parser.parse_args()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7159,
        "label": "no",
        "change": [
            "def count_accuracy(X, true_counts, air, batch_size):",
            "inferred_counts_m = count_vec_to_mat(inferred_counts, 3)",
            "counts += torch.mm(true_counts_m.t(), inferred_counts_m)",
            "error_ind = 1 - (true_counts_batch == inferred_counts)",
            "-        error_ix = error_ind.nonzero().squeeze()",
            "+        error_ix = error_ind.nonzero(as_tuple=False).squeeze()",
            "error_latents.append(latents_to_tensor((z_where, z_pres)).index_select(0, error_ix))",
            "error_indicators.append(error_ind)",
            "",
            "acc = counts.diag().sum().float() / X.size(0)",
            "-    error_indices = torch.cat(error_indicators).nonzero().squeeze()",
            "+    error_indices = torch.cat(error_indicators).nonzero(as_tuple=False).squeeze()",
            "if X.is_cuda:",
            "error_indices = error_indices.cuda()",
            "return acc, counts, torch.cat(error_latents), error_indices"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7160,
        "label": "no",
        "change": [
            "def main():",
            "# recog",
            "logging.info('backend = ' + args.backend)",
            "if args.backend == \"chainer\":",
            "-        from espnet.asr.chain.asr_chainer import recog",
            "+        from espnet.asr.chain.asr import recog",
            "recog(args)",
            "elif args.backend == \"pytorch\":",
            "-        from espnet.asr.pytorch.asr_pytorch import recog",
            "+        from espnet.asr.pytorch.asr import recog",
            "recog(args)",
            "else:",
            "raise ValueError(\"Only chainer and pytorch are supported.\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7167,
        "label": "no",
        "change": [
            "class EKFState(object):",
            "S = H.mm(P).mm(H.transpose(-1, -2)) + R  # innovation cov",
            "",
            "K_prefix = self._cov.mm(H.transpose(-1, -2))",
            "-        dx = K_prefix.mm(torch.gesv(dz.unsqueeze(1), S)[0]).squeeze(1)  # K*dz",
            "+        dx = K_prefix.mm(torch.solve(dz.unsqueeze(1), S)[0]).squeeze(1)  # K*dz",
            "x = self._dynamic_model.geodesic_difference(x, -dx)",
            "",
            "I = eye_like(x, self._dynamic_model.dimension)  # noqa: E741",
            "-        ImKH = I - K_prefix.mm(torch.gesv(H, S)[0])",
            "+        ImKH = I - K_prefix.mm(torch.solve(H, S)[0])",
            "# *Joseph form* of covariance update for numerical stability.",
            "P = ImKH.mm(self.cov).mm(ImKH.transpose(-1, -2)) \\",
            "-            + K_prefix.mm(torch.gesv((K_prefix.mm(torch.gesv(R, S)[0])).transpose(-1, -2),",
            "+            + K_prefix.mm(torch.solve((K_prefix.mm(torch.solve(R, S)[0])).transpose(-1, -2),",
            "S)[0])",
            "",
            "pred_mean = x"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7168,
        "label": "no",
        "change": [
            "def split_cross_attention_forward(self, x, context=None, mask=None):",
            "q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h=h), (q_in, k_in, v_in))",
            "del q_in, k_in, v_in",
            "",
            "-    r1 = torch.zeros(q.shape[0], q.shape[1], v.shape[2], device=q.device. dtype=q.dtype)",
            "+    r1 = torch.zeros(q.shape[0], q.shape[1], v.shape[2], device=q.device, dtype=q.dtype)",
            "",
            "stats = torch.cuda.memory_stats(q.device)",
            "mem_active = stats['active_bytes.all.current']"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7169,
        "label": "no",
        "change": [
            "class FeedfreeInferenceRunner(Callback):",
            "for inf in self.infs:",
            "inf.before_inference()",
            "",
            "-        sess = tf.get_default_session()",
            "sz = self._input_data.size()",
            "with get_tqdm(total=sz) as pbar:",
            "for _ in range(sz):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7171,
        "label": "no",
        "change": [
            "logger = logging.getLogger(__name__)",
            "# for the pretrained weights provided with the models",
            "####################################################",
            "TF_XXX_PRETRAINED_MODEL_ARCHIVE_MAP = {",
            "-    \"xxx-base-uncased\": \"https://s3.amazonaws.com/models.huggingface.co/bert/xxx-base-uncased-tf_model.h5\",",
            "-    \"xxx-large-uncased\": \"https://s3.amazonaws.com/models.huggingface.co/bert/xxx-large-uncased-tf_model.h5\",",
            "+    \"xxx-base-uncased\": \"https://cdn.huggingface.co/xxx-base-uncased-tf_model.h5\",",
            "+    \"xxx-large-uncased\": \"https://cdn.huggingface.co/xxx-large-uncased-tf_model.h5\",",
            "}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7172,
        "label": "no",
        "change": [
            "def autopad(k, p=None, d=1):  # kernel, padding, dilation",
            "",
            "class Conv(nn.Module):",
            "# Standard convolution with args(ch_in, ch_out, kernel, stride, padding, groups, dilation, activation)",
            "-    act = nn.SiLU()  # default activation",
            "+    default_act = nn.SiLU()  # default activation",
            "",
            "def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):",
            "super().__init__()",
            "self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)",
            "self.bn = nn.BatchNorm2d(c2)",
            "-        self.act = self.act if act is True else act if isinstance(act, nn.Module) else nn.Identity()",
            "+        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()",
            "",
            "def forward(self, x):",
            "return self.act(self.bn(self.conv(x)))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7176,
        "label": "no",
        "change": [
            "def check_img_size(img_size, s=32):",
            "",
            "def check_best_possible_recall(dataset, anchors, thr):",
            "# Check best possible recall of dataset with current anchors",
            "-    wh = torch.tensor(np.concatenate([l[:, 3:5] * s for s, l in zip(dataset.shapes, dataset.labels)]))  # width-height",
            "-    ratio = wh[:, None] / anchors.view(-1, 2)[None]  # ratio",
            "+    wh = torch.tensor(np.concatenate([l[:, 3:5] * s for s, l in zip(dataset.shapes, dataset.labels)])).float()  # wh",
            "+    ratio = wh[:, None] / anchors.view(-1, 2).cpu()[None]  # ratio",
            "m = torch.max(ratio, 1. / ratio).max(2)[0]  # max ratio",
            "bpr = (m.min(1)[0] < thr).float().mean()  # best possible recall",
            "mr = (m < thr).float().mean()  # match ratio"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7178,
        "label": "no",
        "change": [
            "def test_spinup_time(hook):",
            "spun up inside web frameworks are created quickly enough to not cause timeout errors\"\"\"",
            "data = []",
            "for i in range(10000):",
            "-        data.append(th.Tensor(5, 5).random_(100))",
            "+        data.append(torch.Tensor(5, 5).random_(100))",
            "start_time = time()",
            "dummy = sy.VirtualWorker(hook, id=\"dummy\", data=data)",
            "end_time = time()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7179,
        "label": "no",
        "change": [
            "class TestBartExamples(unittest.TestCase):",
            "def test_bart_cnn_cli(self):",
            "stream_handler = logging.StreamHandler(sys.stdout)",
            "logger.addHandler(stream_handler)",
            "-        tmp = Path(tempfile.gettempdir()) / \"utest_generations.hypo\"",
            "+        tmp = Path(tempfile.gettempdir()) / \"utest_generations_bart_sum.hypo\"",
            "with tmp.open(\"w\") as f:",
            "f.write(\"\\n\".join(articles))",
            "-        testargs = [\"evaluate_cnn.py\", str(tmp), \"output.txt\"]",
            "+        testargs = [\"evaluate_cnn.py\", str(tmp), output_file_name]",
            "with patch.object(sys, \"argv\", testargs):",
            "_run_generate()",
            "-            self.assertTrue(Path(\"output.txt\").exists())",
            "+            self.assertTrue(Path(output_file_name).exists())",
            "+            os.remove(Path(output_file_name))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7183,
        "label": "no",
        "change": [
            "def find_homography_dlt_iterated(",
            "'''Function, which finds homography via iteratively-reweighted",
            "least squares ToDo: add citation'''",
            "H: torch.Tensor = find_homography_dlt(points1, points2, weights)",
            "-    for i in range(n_iter - 1):",
            "+    for _ in range(n_iter - 1):",
            "errors: torch.Tensor = symmetric_transfer_error(points1, points2, H, False)",
            "weights_new: torch.Tensor = torch.exp(-errors / (2.0 * (soft_inl_th ** 2)))",
            "H = find_homography_dlt(points1, points2, weights_new)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7184,
        "label": "no",
        "change": [
            "class TestBilinearSimilarityFunction(AllenNlpTestCase):",
            "bilinear._bias = Parameter(torch.from_numpy(numpy.asarray([0])).float())",
            "a_vectors = numpy.random.rand(5, 4, 3, 6, 4)",
            "b_vectors = numpy.random.rand(5, 4, 3, 6, 7)",
            "-        a_variables = Variable(torch.from_numpy(a_vectors).float())",
            "-        b_variables = Variable(torch.from_numpy(b_vectors).float())",
            "+        a_variables = torch.from_numpy(a_vectors).float()",
            "+        b_variables = torch.from_numpy(b_vectors).float()",
            "result = bilinear(a_variables, b_variables).data.numpy()",
            "assert result.shape == (5, 4, 3, 6)",
            "expected_result = numpy.dot(numpy.dot(numpy.transpose(a_vectors[3, 2, 1, 3]), weights),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7185,
        "label": "yes",
        "change": [
            "def get_item(",
            "x: torch.Tensor,",
            "query: torch.Tensor,",
            ") -> torch.Tensor:",
            "-    if ivy.dtype(query, as_native=True) is torch.bool:",
            "-        return x.__getitem__(query)",
            "-    return x.__getitem__(query.to(torch.int64))",
            "+    if ivy.is_array(query) and ivy.dtype(query, as_native=True) is not torch.bool:",
            "+        return x.__getitem__(query.to(torch.int64))",
            "+    return x.__getitem__(query)",
            "",
            "",
            "def to_numpy(x: torch.Tensor, /, *, copy: bool = True) -> np.ndarray:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 7187,
        "label": "no",
        "change": [
            "class BertBlock(block_module.Block):",
            "```python",
            "# Using the Transformer Block with AutoModel.",
            "import autokeras as ak",
            "-        from autokeras import BERTBlock",
            "+        from autokeras.blocks import BertBlock",
            "from tensorflow.keras import losses",
            "",
            "input_node = ak.TextInput()",
            "-        output_node = BERTBlock(max_seq_len=128)(input_node)",
            "+        output_node = BertBlock(max_sequence_length=128)(input_node)",
            "output_node = ak.ClassificationHead()(output_node)",
            "clf = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=10)",
            "```"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7191,
        "label": "no",
        "change": [
            "class PulsarPointsRenderer(nn.Module):",
            "raster_rad = self.rasterizer.raster_settings.radius",
            "if kwargs.get(\"radius_world\", False):",
            "return raster_rad",
            "-        if isinstance(raster_rad, torch.Tensor) and raster_rad.numel() > 1:",
            "+        if (",
            "+            isinstance(raster_rad, torch.Tensor)",
            "+            and raster_rad.numel() > 1",
            "+            and raster_rad.ndim > 1",
            "+        ):",
            "# In this case it must be a batched torch tensor.",
            "raster_rad = raster_rad[cloud_idx]",
            "if orthogonal_projection:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7193,
        "label": "no",
        "change": [
            "def rotation_matrix_to_quaternion(",
            "trace: torch.Tensor = m00 + m11 + m22",
            "",
            "def trace_positive_cond():",
            "-        sq = torch.sqrt(trace + 1.0) * 2.0  # sq = 4 * qw.",
            "+        sq = torch.sqrt(trace + 1.0 + eps) * 2.0  # sq = 4 * qw.",
            "qw = 0.25 * sq",
            "qx = safe_zero_division(m21 - m12, sq)",
            "qy = safe_zero_division(m02 - m20, sq)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7194,
        "label": "no",
        "change": [
            "class Bernoulli(Distribution):",
            "# when the data is a ragged tensor. also useful for KL annealing. this entire logic",
            "# will likely be done in a better/cleaner way in the future",
            "if log_pdf_mask is not None:",
            "-            # TODO fix this to broadcasting as below, e.g. by instead:",
            "-            # logsum *= log_pdf_mask  # Then continue with broadcasting logic below.",
            "-            return torch.sum(log_pdf_mask * logsum, -1)",
            "+            logsum = logsum * log_pdf_mask",
            "batch_log_pdf_shape = self.batch_shape(ps) + (1,)",
            "return torch.sum(logsum, -1).contiguous().view(batch_log_pdf_shape)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7195,
        "label": "no",
        "change": [
            "class ModelTrainer(BaseModule):",
            "model_name = self.transaction.persistent_model_metadata.model_name",
            "",
            "ml_models = [",
            "-            ('pytorch.models.fully_connected_net', {})",
            "+            #('pytorch.models.fully_connected_net', {})",
            "#, ('pytorch.models.ensemble_conv_net', {})",
            "-            #, ('pytorch.models.ensemble_fully_connected_net', {})",
            "+            ('pytorch.models.ensemble_fully_connected_net', {})",
            "]",
            "",
            "self.train_start_time = time.time()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7201,
        "label": "no",
        "change": [
            "def gelu(",
            "",
            "",
            "@with_unsupported_dtypes({\"1.11.0 and below\": (\"float16\",)}, backend_version)",
            "-def sigmoid(",
            "-    x: torch.Tensor,",
            "-    /,",
            "-    *,",
            "-    out: Optional[torch.Tensor] = None",
            "-) -> torch.Tensor:",
            "+def sigmoid(x: torch.Tensor, /, *, out: Optional[torch.Tensor] = None) -> torch.Tensor:",
            "if not ivy.is_array(x):",
            "x = torch.tensor(x)",
            "return torch.sigmoid(x, out=out)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7202,
        "label": "no",
        "change": [
            "def vsgp_multiclass(num_steps, whiten):",
            "pyro.set_rng_seed(0)",
            "X = torch.rand(100, 1)",
            "K = (-0.5 * (X - X.t()).pow(2) / 0.01).exp() + torch.eye(100) * 1e-6",
            "-    f = K.cholesky().matmul(torch.randn(100, 3))",
            "+    f = torch.linalg.cholesky(K).matmul(torch.randn(100, 3))",
            "y = f.argmax(dim=-1)",
            "",
            "kernel = gp.kernels.Sum(gp.kernels.Matern32(1),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7204,
        "label": "no",
        "change": [
            "def train_ch8(model, train_iter, vocab, num_hiddens, lr, num_epochs,",
            "use_random_iter=False):",
            "\"\"\"Train a model (defined in Chapter 8).\"\"\"",
            "params = get_params(len(vocab), num_hiddens)",
            "-    loss = tf.keras.losses.SparseCategoricalCrossentropy()",
            "+    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)",
            "animator = d2l.Animator(xlabel='epoch', ylabel='perplexity',",
            "legend=['train'], xlim=[1, num_epochs])",
            "updater = tf.keras.optimizers.SGD(lr)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7215,
        "label": "yes",
        "change": [
            "class GPTNeoXForCausalLM(GPTNeoXPreTrainedModel):",
            "attention_mask = input_ids.new_ones(input_shape)",
            "",
            "# cut decoder_input_ids if past is used",
            "-        if past is not None:",
            "+        if past and past[0] is not None:",
            "input_ids = input_ids[:, -1:]",
            "",
            "return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"past_key_values\": past}"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 7216,
        "label": "no",
        "change": [
            "def routing(input, b_IJ):",
            "input = tf.tile(input, [1, 1, 160, 1, 1])",
            "assert input.get_shape() == [cfg.batch_size, 1152, 160, 8, 1]",
            "",
            "-    u_hat = tf.reduce_sum(W * input, axis=3, keepdims=True)",
            "+    u_hat = reduce_sum(W * input, axis=3, keepdims=True)",
            "u_hat = tf.reshape(u_hat, shape=[-1, 1152, 10, 16, 1])",
            "assert u_hat.get_shape() == [cfg.batch_size, 1152, 10, 16, 1]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7222,
        "label": "no",
        "change": [
            "class SpanningTree(TorchDistribution):",
            "import gpytorch",
            "log_det = gpytorch.lazy.NonLazyTensor(truncated).logdet()",
            "except ImportError:",
            "-            log_det = torch.cholesky(truncated).diag().log().sum() * 2",
            "+            log_det = torch.linalg.cholesky(truncated).diag().log().sum() * 2",
            "return log_det + log_diag[:-1].sum()",
            "",
            "def log_prob(self, edges):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7223,
        "label": "no",
        "change": [
            "def solve(",
            "else:",
            "x1 = tf.broadcast_to(x1, output_shape + x1.shape[-2:])",
            "x2 = tf.broadcast_to(x2, output_shape + x2.shape[-2:])",
            "-        if tf.math.reduce_any(tf.linalg.det(x1) == 0) or tf.math.reduce_any(",
            "-            tf.linalg.det(x2) == 0",
            "-        ):",
            "+        if tf.math.reduce_any(tf.linalg.det(x1) == 0) or (",
            "+            x2.shape[-1] == x2.shape[-2] and tf.math.reduce_any(",
            "+                tf.linalg.det(x2) == 0)):",
            "return x1",
            "ret = tf.linalg.solve(x1, x2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7228,
        "label": "no",
        "change": [
            "class Entropy(Metric):",
            "",
            "log_probs = torch.nn.functional.log_softmax(logits, dim=-1)",
            "probabilities = torch.exp(log_probs) * mask.unsqueeze(-1)",
            "-        weighted_negative_likelihood = - log_probs * probabilities",
            "+        weighted_negative_likelihood = -log_probs * probabilities",
            "entropy = weighted_negative_likelihood.sum(-1)",
            "",
            "self._entropy += entropy.sum() / mask.sum()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7231,
        "label": "no",
        "change": [
            "def interpolate(x,",
            "# won't go out of bounds.",
            "lower_encoding = tf.math.maximum(upper_indices - 1, 0)",
            "upper_encoding = tf.math.minimum(upper_indices, x_data_size - 1)",
            "-      # Prepare indices for `tf.gather_nd` or `tf.one_hot`",
            "+      # Prepare indices for `tf.gather` or `tf.one_hot`",
            "# TODO(b/156720909): Extract get_slice logic into a common utilities",
            "# module for cubic and linear interpolation",
            "if optimize_for_tpu:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7233,
        "label": "no",
        "change": [
            "def _make_causal_mask(input_ids_shape: tf.TensorShape, past_key_values_length: i",
            "",
            "if past_key_values_length > 0:",
            "mask = tf.concat([tf.zeros((tgt_len, past_key_values_length), dtype=tf.float32), mask], axis=-1)",
            "-    return tf.broadcast_to(mask[None, None, :, :], (bsz, 1, tgt_len, tgt_len + past_key_values_length))",
            "+",
            "+    return tf.tile(mask[None, None, :, :], (bsz, 1, 1, 1))",
            "",
            "",
            "def _expand_mask(mask: tf.Tensor, tgt_len: Optional[int] = None, past_key_values_length: int = 0):",
            "\"\"\"",
            "Expands attention_mask from `[bsz, seq_len]` to `[bsz, 1, tgt_seq_len, src_seq_len]`.",
            "\"\"\"",
            "-    bsz, src_len = shape_list(mask)",
            "+    src_len = shape_list(mask)[1]",
            "tgt_len = tgt_len if tgt_len is not None else src_len",
            "-",
            "-    expanded_mask = tf.cast(tf.broadcast_to(mask[:, None, None, :], (bsz, 1, tgt_len, src_len)), tf.float32)",
            "+    expanded_mask = tf.cast(tf.tile(mask[:, None, None, :], (1, 1, tgt_len, 1)), tf.float32)",
            "",
            "return (1.0 - expanded_mask) * LARGE_NEGATIVE"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7238,
        "label": "no",
        "change": [
            "def anchor_target_single(flat_anchors,",
            "num_valid_anchors = anchors.shape[0]",
            "bbox_targets = torch.zeros_like(anchors)",
            "bbox_weights = torch.zeros_like(anchors)",
            "-    labels = gt_labels.new_zeros(num_valid_anchors)",
            "-    label_weights = gt_labels.new_zeros(num_valid_anchors, dtype=torch.float)",
            "+    labels = anchors.new_zeros(num_valid_anchors, dtype=torch.long)",
            "+    label_weights = anchors.new_zeros(num_valid_anchors, dtype=torch.float)",
            "",
            "pos_inds = sampling_result.pos_inds",
            "neg_inds = sampling_result.neg_inds"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7246,
        "label": "no",
        "change": [
            "def _segment_reduce(values, index, segment_reduce_fn, name):",
            "dim=0,",
            ")",
            "",
            "-    output_values = segment_means.clone().view(new_shape.tolist())",
            "+    output_values = segment_means.clone().view(new_shape.tolist()).to(values.dtype)",
            "output_index = range_index_map(index.batch_shape(), index.num_segments)",
            "return output_values, output_index"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7261,
        "label": "yes",
        "change": [
            "class PolicyGradientModel(Model):",
            "",
            "with tf.variable_scope('distribution'):",
            "for action, distribution in self.distribution.items():",
            "-                distribution.create_tf_operations(x=self.network.output, deterministic=self.deterministic)",
            "+                with tf.variable_scope(action):",
            "+                    distribution.create_tf_operations(x=self.network.output, deterministic=self.deterministic)",
            "self.action_taken[action] = distribution.sample()",
            "",
            "if self.baseline:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 7263,
        "label": "no",
        "change": [
            "def stream_tfevents(path, file_api, run, step=0, namespace=\"\"):",
            "last_row = {}",
            "global_step_key = namespaced_tag(\"global_step\", namespace)",
            "try:",
            "-        for summary in tf.train.summary_iterator(path):",
            "+        for summary in summary_iterator(path):",
            "parsed = tf_summary_to_dict(summary, namespace=namespace)",
            "if last_step != parsed[global_step_key]:",
            "last_step = parsed[global_step_key]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7267,
        "label": "no",
        "change": [
            "class Experiments:",
            "if os.path.exists(self.experiment_file):",
            "try:",
            "with open(self.experiment_file, 'r') as file:",
            "-                    return json.load(file)",
            "+                    return json_tricks.load(file)",
            "except ValueError:",
            "return {}",
            "return {}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7268,
        "label": "no",
        "change": [
            "class SimpleConversationPipelineTests(unittest.TestCase):",
            "model = GPT2LMHeadModel(config)",
            "# Force model output to be L",
            "V, D = model.lm_head.weight.shape",
            "-        bias = torch.zeros(V, requires_grad=True)",
            "-        weight = torch.zeros((V, D), requires_grad=True)",
            "+        bias = torch.zeros(V)",
            "bias[76] = 1",
            "+        weight = torch.zeros((V, D), requires_grad=True)",
            "",
            "model.lm_head.bias = torch.nn.Parameter(bias)",
            "model.lm_head.weight = torch.nn.Parameter(weight)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7270,
        "label": "no",
        "change": [
            "class TransLoss(torch.nn.Module):",
            "loss (torch.Tensor): transducer loss",
            "",
            "\"\"\"",
            "-        if trans_type == \"warp-transducer\" and pred_pad.dtype != torch.float32:",
            "+        if self.trans_type == \"warp-transducer\" and pred_pad.dtype != torch.float32:",
            "# warprnnt_pytorch only supports float32",
            "pred_pad = pred_pad.to(dtype=torch.float32)",
            "if self.trans_type == \"warp-rnnt\":"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7271,
        "label": "no",
        "change": [
            "def generate_examples(features: dict, num_examples=100, seq_shapes=None):",
            "def generate_example_dataset(dataset_path, features, num_examples=100, seq_shapes=None):",
            "dummy_data = generate_examples(features, num_examples=num_examples, seq_shapes=seq_shapes)",
            "",
            "-    writer = datasets.ArrowWriter(features=features, path=dataset_path)",
            "-    for key, record in dummy_data:",
            "-        example = features.encode_example(record)",
            "-        writer.write(example)",
            "+    with datasets.ArrowWriter(features=features, path=dataset_path) as writer:",
            "+        for key, record in dummy_data:",
            "+            example = features.encode_example(record)",
            "+            writer.write(example)",
            "",
            "-    num_final_examples, num_bytes = writer.finalize()",
            "+        num_final_examples, num_bytes = writer.finalize()",
            "",
            "assert (",
            "num_final_examples == num_examples"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7274,
        "label": "no",
        "change": [
            "def make_module_spec(options, weight_file):",
            "",
            "# Input placeholders to the biLM.",
            "tokens = tf.placeholder(shape=(None, None), dtype=tf.string, name='ph2tokens')",
            "-        sequence_len = tf.placeholder(shape=(None, ), dtype=tf.int32, name='ph2sequence_len')",
            "+        sequence_len = tf.placeholder(shape=(None,), dtype=tf.int32, name='ph2sequence_len')",
            "",
            "tok_shape = tf.shape(tokens)",
            "line_tokens = tf.reshape(tokens, shape=[-1], name='reshape2line_tokens')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7276,
        "label": "no",
        "change": [
            "def resume_checkpoint(model, checkpoint_path):",
            "optimizer_state = None",
            "resume_epoch = None",
            "if os.path.isfile(checkpoint_path):",
            "-        checkpoint = torch.load(checkpoint_path)",
            "+        checkpoint = torch.load(checkpoint_path, map_location='cpu')",
            "if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:",
            "new_state_dict = OrderedDict()",
            "for k, v in checkpoint['state_dict'].items():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7279,
        "label": "no",
        "change": [
            "class TruncatedNormal(tf.compat.v1.truncated_normal_initializer):",
            ">>> a = initializer(shape=(2, 2))",
            ">>> b = initializer(shape=(2, 2))",
            ">>> tf.reduce_sum(a - b) == 0",
            "-  <tf.Tensor: shape=(), dtype=bool, numpy=True>",
            "+  <tf.Tensor: shape=(), dtype=bool, numpy=False>",
            "",
            "@end_compatibility",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7282,
        "label": "no",
        "change": [
            "class PipelineIterator(IterableDataset):",
            "elif isinstance(element[0], np.ndarray):",
            "loader_batched[k] = tuple(np.expand_dims(el[self._loader_batch_index], 0) for el in element)",
            "continue",
            "-                if isinstance(element[self._loader_batch_index], torch.Tensor):",
            "+                if element is None:",
            "+                    # This can happen for optional data that get passed around",
            "+                    loader_batched[k] = None",
            "+                elif isinstance(element[self._loader_batch_index], torch.Tensor):",
            "# Take correct batch data, but make it looked like batch_size=1",
            "# For compatibility with other methods within transformers"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7291,
        "label": "no",
        "change": [
            "class ElmoTokenEmbedder(TokenEmbedder):",
            "",
            "# Returns",
            "",
            "-        The ELMo representations for the input sequence, shape",
            "-        `(batch_size, timesteps, embedding_dim)`",
            "+        `torch.Tensor`",
            "+            The ELMo representations for the input sequence, shape",
            "+            `(batch_size, timesteps, embedding_dim)`",
            "\"\"\"",
            "elmo_output = self._elmo(tokens, word_inputs)",
            "elmo_representations = elmo_output[\"elmo_representations\"][0]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7293,
        "label": "yes",
        "change": [
            "class DistributedModel(object):",
            "",
            "grad_var_list = list(zip(self.gradients, self.global_network.get_variables()))",
            "",
            "-            global_step_inc = self.global_step.assign_add(self.batch_size)",
            "+            global_step_inc = self.global_step.assign_add(tf.shape(self.state)[0])",
            "",
            "self.assign_global_to_local = tf.group(*[v1.assign(v2) for v1, v2 in",
            "zip(self.local_network.get_variables(),"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 7296,
        "label": "no",
        "change": [
            "with tf.Session() as sess:",
            "",
            "## Note that, the rewards here with random action",
            "running_reward = rAll if running_reward is None else running_reward * 0.99 + rAll * 0.01",
            "-        print(",
            "-            \"Episode [%d/%d] sum reward:%f running reward:%f took:%.5fs %s\" %",
            "-            (i, num_episodes, rAll, running_reward, time.time() - episode_time, '' if rAll == 0 else ' !!!!!!!!')",
            "-        )",
            "+        print(\"Episode [%d/%d] sum reward:%f running reward:%f took:%.5fs %s\" % \\",
            "+            (i, num_episodes, rAll, running_reward, time.time() - episode_time, '' if rAll == 0 else ' !!!!!!!!'))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7298,
        "label": "yes",
        "change": [
            "class Model(ModelDesc):",
            "for idx, b in enumerate([b1, b2, b3, b4, b5, final_map]):",
            "output = tf.nn.sigmoid(b, name='output{}'.format(idx+1))",
            "xentropy = class_balanced_sigmoid_cross_entropy(",
            "-                b, edgemap,",
            "+                tf.squeeze(b, [3]), edgemap,",
            "name='xentropy{}'.format(idx+1))",
            "costs.append(xentropy)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 7300,
        "label": "no",
        "change": [
            "class ActorCriticLoss(object):",
            "",
            "q_t_selected = tf.squeeze(q_t, axis=len(q_t.shape) - 1)",
            "if twin_q:",
            "-            twin_q_t_selected = tf.squeeze(q_t, axis=len(q_t.shape) - 1)",
            "+            twin_q_t_selected = tf.squeeze(twin_q_t, axis=len(q_t.shape) - 1)",
            "q_tp1 = tf.minimum(q_tp1, twin_q_tp1)",
            "",
            "q_tp1_best = tf.squeeze(input=q_tp1, axis=len(q_tp1.shape) - 1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7305,
        "label": "no",
        "change": [
            "\"source\": [",
            "\"def model(xs, ys=None):\\n\",",
            "\"    # sample z from the prior \\n\",",
            "-    \"    prior_mu = Variable(torch.zeros([batch_size, z_dim]))\\n\",",
            "-    \"    prior_sigma = Variable(torch.ones([batch_size, z_dim]))\\n\",",
            "+    \"    prior_mu = torch.zeros([batch_size, z_dim])\\n\",",
            "+    \"    prior_sigma = torch.ones([batch_size, z_dim])\\n\",",
            "\"    zs = pyro.sample(\\\"z\\\", dist.Normal(prior_mu, prior_sigma))\\n\",",
            "\"\\n\",",
            "\"    # if the label y is observed, sample from the prior.\\n\",",
            "\"    # otherwise, observe the value \\n\",",
            "-    \"    alpha_prior = Variable(torch.ones([batch_size, 10]) / (10.))\\n\",",
            "+    \"    alpha_prior = torch.ones([batch_size, 10]) / (10.)\\n\",",
            "\"    if ys is None:\\n\",",
            "\"        ys = pyro.sample(\\\"y\\\", dist.OneHotCategorical(alpha_prior))\\n\",",
            "\"    else:\\n\","
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7307,
        "label": "no",
        "change": [
            "from .. import backend_version",
            "",
            "",
            "@with_unsupported_dtypes({\"1.11.0 and below\": (\"float16\",)}, backend_version)",
            "-def l2_normalize(x: torch.Tensor,",
            "-                 axis: int = None,",
            "-                 out: torch.Tensor = None",
            "-                 ) -> torch.Tensor:",
            "+def l2_normalize(",
            "+    x: torch.Tensor, axis: int = None, out: torch.Tensor = None",
            "+) -> torch.Tensor:",
            "",
            "return torch.nn.functional.normalize(x, p=2, dim=axis, out=out)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7315,
        "label": "no",
        "change": [
            "y = img_input",
            "for i in range(nlayers):",
            "y_prepool = convresblock(y, nfeats=nfeats_all[i + 1], ksize=ksize)",
            "y = MaxPooling2D(pool_size=(pool_sizes[i], pool_sizes[i]))(y_prepool)",
            "-    wheres[i] = layers.Lambda(getwhere, output_shape=lambda x: x[0])([y_prepool, y])",
            "+    wheres[i] = layers.Lambda(",
            "+        getwhere, output_shape=lambda x: x[0])([y_prepool, y])",
            "",
            "# Now build the decoder, and use the stored 'where' masks to place the features",
            "for i in range(nlayers):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7317,
        "label": "no",
        "change": [
            "class E2E(ASRInterface, chainer.Chain):",
            "xs = xs.reshape(batch, -1, self.dims)",
            "xs = [xs[i, :ilens[i], :] for i in range(len(ilens))]",
            "loss_ctc = self.ctc(xs, ys_pad_cpu)",
            "-            with chainer.no_backprop_mode():",
            "-                ys_hat = chainer.backends.cuda.to_cpu(self.ctc.argmax(xs).data)",
            "-            cer_ctc = self.error_calculator(ys_hat, ys_pad_cpu, is_ctc=True)",
            "+            if self.error_calculator is not None:",
            "+                with chainer.no_backprop_mode():",
            "+                    ys_hat = chainer.backends.cuda.to_cpu(self.ctc.argmax(xs).data)",
            "+                cer_ctc = self.error_calculator(ys_hat, ys_pad_cpu, is_ctc=True)",
            "",
            "# Compute cer/wer",
            "with chainer.no_backprop_mode():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7323,
        "label": "no",
        "change": [
            "def read_ply(path):",
            "face = None",
            "if 'face' in data:",
            "faces = data['face']['vertex_indices']",
            "-        faces = [torch.tensor(f, dtype=torch.long) for f in faces]",
            "+        faces = [torch.tensor(fa, dtype=torch.long) for fa in faces]",
            "face = torch.stack(faces, dim=-1)",
            "",
            "data = Data(pos=pos)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7328,
        "label": "no",
        "change": [
            "def kmean_anchors(dataset='./data/coco128.yaml', n=9, img_size=640, thr=4.0, gen",
            "\"\"\"",
            "from scipy.cluster.vq import kmeans",
            "",
            "-    thr = 1. / thr",
            "+    thr = 1 / thr",
            "prefix = colorstr('autoanchor: ')",
            "",
            "def metric(k, wh):  # compute metrics",
            "r = wh[:, None] / k[None]",
            "-        x = torch.min(r, 1. / r).min(2)[0]  # ratio metric",
            "+        x = torch.min(r, 1 / r).min(2)[0]  # ratio metric",
            "# x = wh_iou(wh, torch.tensor(k))  # iou metric",
            "return x, x.max(1)[0]  # x, best_x"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7333,
        "label": "yes",
        "change": [
            "class TensorBoard(Callback):",
            "embedding_input = tf.reshape(embedding_input,",
            "(step, int(embedding_size)))",
            "shape = (self.embeddings_data[0].shape[0], int(embedding_size))",
            "-                    embedding = tf.Variable(tf.zeros(shape),",
            "-                                            name=layer.name + '_embedding')",
            "+                    embedding = K.variable(K.zeros(shape),",
            "+                                           name=layer.name + '_embedding')",
            "embeddings_vars[layer.name] = embedding",
            "batch = tf.assign(embedding[batch_id:batch_id + step],",
            "embedding_input)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 7334,
        "label": "no",
        "change": [
            "class Inferencer:",
            "",
            "model = AdaptiveModel.convert_from_transformers(model_name_or_path,",
            "revision=revision,",
            "-                                                            device=devices[0],",
            "+                                                            device=devices[0],  # type: ignore",
            "task_type=task_type,",
            "**kwargs)",
            "processor = Processor.convert_from_transformers(model_name_or_path,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7336,
        "label": "yes",
        "change": [
            "def build_targets(p, targets, model):",
            "if use_all_anchors:",
            "na = anchor_vec.shape[0]  # number of anchors",
            "a = torch.arange(na).view(-1, 1).repeat(1, nt).view(-1)",
            "-                t = targets.repeat(na, 1)",
            "+                t = t.repeat(na, 1)",
            "else:  # use best anchor only",
            "iou, a = iou.max(0)  # best iou and anchor"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 7337,
        "label": "no",
        "change": [
            "class LSTM(Model):",
            "if self.state_in:",
            "c_in, h_in = self.state_in",
            "else:",
            "-            c_in = tf.placeholder(",
            "+            c_in = tf1.placeholder(",
            "tf.float32, [None, lstm.state_size.c], name=\"c\")",
            "-            h_in = tf.placeholder(",
            "+            h_in = tf1.placeholder(",
            "tf.float32, [None, lstm.state_size.h], name=\"h\")",
            "self.state_in = [c_in, h_in]",
            "",
            "# Setup LSTM outputs",
            "-        state_in = tf.nn.rnn_cell.LSTMStateTuple(c_in, h_in)",
            "-        lstm_out, lstm_state = tf.nn.dynamic_rnn(",
            "+        state_in = tf1.nn.rnn_cell.LSTMStateTuple(c_in, h_in)",
            "+        lstm_out, lstm_state = tf1.nn.dynamic_rnn(",
            "lstm,",
            "last_layer,",
            "initial_state=state_in,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7343,
        "label": "no",
        "change": [
            "class TestBlending(unittest.TestCase):",
            "# of the image with surrounding padded values.",
            "N, S, K = 1, 8, 2",
            "device = torch.device(\"cuda\")",
            "-        pix_to_face = -torch.ones((N, S, S, K), dtype=torch.int64, device=device)",
            "+        pix_to_face = torch.full(",
            "+            (N, S, S, K), fill_value=-1, dtype=torch.int64, device=device",
            "+        )",
            "h = int(S / 2)",
            "pix_to_face_full = torch.randint(",
            "size=(N, h, h, K), low=0, high=100, device=device"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7346,
        "label": "no",
        "change": [
            "class PredictionEpochLoop(Loop):",
            "self.current_batch_indices = batch_sampler.batch_indices",
            "if self.should_store_predictions:",
            "self._all_batch_indices.append(batch_sampler.batch_indices)",
            "+        else:",
            "+            warning_cache.warn(\"Lightning couldn't infer the indices fetched for your dataloader.\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7348,
        "label": "no",
        "change": [
            "class AttSplineConv(Module):",
            "is_open_spline = torch.ByteTensor(repeat_to(is_open_spline, dim))",
            "self.register_buffer('is_open_spline', is_open_spline)",
            "",
            "-        weight = torch.Tensor(kernel_size.prod(), in_channels, out_channels)",
            "-        self.weight = Parameter(weight)",
            "+        K = kernel_size.prod().item()",
            "+        self.weight = Parameter(torch.Tensor(K, in_channels, out_channels))",
            "",
            "self.root_weight = Parameter(torch.Tensor(in_channels, out_channels))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7356,
        "label": "no",
        "change": [
            "def tree_decomposition(mol):",
            "rows = [[i] * len(atom2clique[i]) for i in range(mol.GetNumAtoms())]",
            "row = torch.tensor(list(chain.from_iterable(rows)))",
            "col = torch.tensor(list(chain.from_iterable(atom2clique)))",
            "-    atom2clique = torch.stack([row, col], dim=0)",
            "+    atom2clique = torch.stack([row, col], dim=0).to(torch.long)",
            "",
            "return edge_index, atom2clique, len(cliques)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7362,
        "label": "no",
        "change": [
            "import scipy.spatial",
            "",
            "",
            "def nn_graph(pos, k=6):",
            "-    row = torch.arange(0, pos.size(0)).view(-1, 1).repeat(1, 6).view(-1).long()",
            "+    row = torch.arange(0, pos.size(0)).view(-1, 1).repeat(1, k).view(-1).long()",
            "tree = scipy.spatial.cKDTree(pos.numpy())",
            "_, col = tree.query(pos, k + 1)",
            "col = torch.LongTensor(col[:len(col)])[:, 1:].contiguous().view(-1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7363,
        "label": "no",
        "change": [
            "def contains_isolated_nodes(edge_index, num_nodes=None):",
            "\"\"\"",
            "num_nodes = maybe_num_nodes(edge_index, num_nodes)",
            "edge_index, _ = remove_self_loops(edge_index)",
            "-    return torch.unique(edge_index.view(-1)).size(0) < num_nodes",
            "+    return torch.unique(edge_index.view(-1)).numel() < num_nodes",
            "",
            "",
            "def remove_isolated_nodes(edge_index, edge_attr=None, num_nodes=None):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7364,
        "label": "yes",
        "change": [
            "def zca_mean(inp: torch.Tensor, dim: int = 0,",
            "else:",
            "cov = cov / float(N)",
            "",
            "-    U, S, _ = torch.svd(cov)",
            "+    U, S, _ = _torch_svd_cast(cov)",
            "",
            "S = S.reshape(-1, 1)",
            "S_inv_root: torch.Tensor = torch.rsqrt(S + eps)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 7367,
        "label": "no",
        "change": [
            "class Queue(Memory):",
            "updates=internal",
            "))",
            "for name, action in actions.items():",
            "-                assignments.append(tf.scatter_update(ref=self.actions_memory[name], indices=indices, updates=action))",
            "+                assignments.append(tf.scatter_update(",
            "+                    ref=self.actions_memory[name],",
            "+                    indices=indices,",
            "+                    updates=action",
            "+                ))",
            "assignments.append(tf.scatter_update(ref=self.terminal_memory, indices=indices, updates=terminal))",
            "assignments.append(tf.scatter_update(ref=self.reward_memory, indices=indices, updates=reward))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7368,
        "label": "no",
        "change": [
            "class TraceTailAdaptive_ELBO(Trace_ELBO):",
            "# rank the particles according to p/q",
            "log_pq = log_p - log_q",
            "rank = torch.argsort(log_pq, descending=False)",
            "-        rank = torch.index_select(torch.arange(self.num_particles) + 1, -1, rank).type_as(log_pq)",
            "+        rank = torch.index_select(torch.arange(self.num_particles, device=log_pq.device) + 1, -1, rank).type_as(log_pq)",
            "",
            "# compute the particle-specific weights used to construct the surrogate loss",
            "gamma = torch.pow(rank, self.tail_adaptive_beta).detach()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7371,
        "label": "no",
        "change": [
            "def test_tpu_sync_dist():",
            "\"\"\"Test tpu spawn sync dist operation.\"\"\"",
            "",
            "def test_sync_dist(_):",
            "-        sync = _Sync(TPUSpawnPlugin().reduce, should=True, op=torch.distributed.ReduceOp.SUM)",
            "+        sync = _Sync(TPUSpawnPlugin().reduce, should=True, _op=torch.distributed.ReduceOp.SUM)",
            "value = torch.tensor([1.0])",
            "value = (sync(value),)",
            "assert value.item() == 8"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7374,
        "label": "no",
        "change": [
            "def mm_diagonal(a, b, transpose=False):",
            "",
            "value = a[target] * value",
            "",
            "-    return torch.sparse.FloatTensor(index, value, b.size())",
            "+    return SparseTensor(index, value, b.size())"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7375,
        "label": "yes",
        "change": [
            "class PretrainedTransformerMismatchedEmbedder(TokenEmbedder):",
            "span_embeddings_sum = span_embeddings.sum(2)",
            "span_embeddings_len = span_mask.sum(2)",
            "# Shape: (batch_size, num_orig_tokens, embedding_size)",
            "-        orig_embeddings = span_embeddings_sum / span_embeddings_len",
            "+        orig_embeddings = span_embeddings_sum / torch.clamp_min(span_embeddings_len, 1)",
            "",
            "# All the places where the span length is zero, write in zeros.",
            "orig_embeddings[(span_embeddings_len == 0).expand(orig_embeddings.shape)] = 0"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 7378,
        "label": "no",
        "change": [
            "def pad_float_tensor(",
            "bs = shape[0]",
            "max_batch_len = pad_length(bs, batch_padding_control, -1)",
            "shape[0] = max_batch_len - bs",
            "-    pad_tensor = torch.zeros(shape, dtype=torch.float)",
            "+    pad_tensor = input_tensor.new_zeros(shape)",
            "new_tensor = torch.cat([input_tensor, pad_tensor], 0)",
            "return new_tensor"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7379,
        "label": "no",
        "change": [
            "def after_init(policy: Policy, obs_space: gym.spaces.Space,",
            "config: TrainerConfigDict) -> None:",
            "ComputeTDErrorMixin.__init__(policy)",
            "TargetNetworkMixin.__init__(policy, obs_space, action_space, config)",
            "-    # Move target net to device (this is done autoatically for the",
            "+    # Move target net to device (this is done automatically for the",
            "# policy.model, but not for any other models the policy has).",
            "policy.target_q_model = policy.target_q_model.to(policy.device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7384,
        "label": "no",
        "change": [
            "def as_ivy_dtype(dtype_in: Union[torch.dtype, str, bool, int, float], /) -> ivy.",
            "",
            "",
            "@with_unsupported_dtypes({\"1.11.0 and below\": (\"uint16\",)}, backend_version)",
            "-def as_native_dtype(",
            "-    dtype_in: Union[torch.dtype, str, bool, int, float], /",
            "-) -> torch.dtype:",
            "+def as_native_dtype(dtype_in: Union[torch.dtype, str, bool, int, float]) -> torch.dtype:",
            "if dtype_in is int:",
            "return ivy.default_int_dtype(as_native=True)",
            "if dtype_in is float:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7386,
        "label": "yes",
        "change": [
            "class PipelineTesterMixin:",
            "",
            "with tempfile.TemporaryDirectory() as tmpdir:",
            "pipe.save_pretrained(tmpdir)",
            "-            pipe_loaded = self.pipeline_class.from_pretrained(tmpdir)",
            "+            pipe_loaded = self.pipeline_class.from_pretrained(tmpdir, torch_dtype=torch.float16)",
            "pipe_loaded.to(torch_device)",
            "pipe_loaded.set_progress_bar_config(disable=None)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "addition",
        "Element": "api parameter"
    },
    {
        "number": 7391,
        "label": "no",
        "change": [
            "def repeat_op(repetitions, inputs, op, *args, **kwargs):",
            "ValueError: if the op is unknown or wrong.",
            "\"\"\"",
            "scope = kwargs.pop('scope', None)",
            "-  with tf.variable_op_scope([inputs], scope, 'RepeatOp'):",
            "+  with tf.variable_scope(scope, 'RepeatOp', [inputs]):",
            "tower = inputs",
            "for _ in range(repetitions):",
            "tower = op(tower, *args, **kwargs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7392,
        "label": "yes",
        "change": [
            "def main():",
            "# train",
            "logging.info('backend = ' + args.backend)",
            "if args.backend == \"chainer\":",
            "-        from espnet.lm.chain.lm_chainer import train",
            "+        from espnet.lm.chain.lm import train",
            "train(args)",
            "elif args.backend == \"pytorch\":",
            "-        from espnet.lm.pytorch.lm_pytorch import train",
            "+        from espnet.lm.pytorch.lm import train",
            "train(args)",
            "else:",
            "raise ValueError(\"Only chainer and pytorch are supported.\")"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 7394,
        "label": "no",
        "change": [
            "def mask_feature(x: Tensor, p: float = 0.5, mode: str = 'col',",
            "mask = torch.rand(x.size(1), device=x.device) >= p",
            "mask = mask.view(1, -1)",
            "else:",
            "-        mask = torch.randn_like(x) >= p",
            "+        mask = torch.rand_like(x) >= p",
            "",
            "x = x.masked_fill(~mask, fill_value)",
            "return x, mask"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7400,
        "label": "no",
        "change": [
            "class TorchBuffer(InterpretedBuffer):",
            "fxn_for_op : ClassVar = torch_fxn_for_op",
            "",
            "@staticmethod",
            "-  def fromCPU(data): return TorchBuffer(torch.from_numpy(data).requires_grad_(False).to(device))",
            "-  def toCPU(x): return x._buf.cpu().numpy()",
            "+  def fromCPU(x): return TorchBuffer(torch.from_numpy(x).requires_grad_(False).to(device))",
            "+  def toCPU(self): return self._buf.cpu().numpy()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7401,
        "label": "no",
        "change": [
            "class TestMedianBlur:",
            "op_module = kornia.filters.MedianBlur((3, 5))",
            "actual = op_module(img)",
            "expected = op(img, kernel_size)",
            "-        assert_allclose(actual, expected)",
            "+        assert_close(actual, expected)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7402,
        "label": "no",
        "change": [
            "def binary_focal_loss_with_logits(",
            "",
            "probs = torch.sigmoid(input)",
            "target = target.unsqueeze(dim=1)",
            "-    loss_tmp = -alpha * torch.pow((1. - probs), gamma) * target * torch.log(probs + eps) \\",
            "-               - (1 - alpha) * torch.pow(probs, gamma) * (1. - target) * torch.log(1. - probs + eps)",
            "+    loss_tmp = - alpha * torch.pow((1. - probs + eps), gamma) * target * torch.log(probs + eps) \\",
            "+               - (1 - alpha) * torch.pow(probs + eps, gamma) * (1. - target) * torch.log(1. - probs + eps)",
            "+",
            "loss_tmp = loss_tmp.squeeze(dim=1)",
            "",
            "if reduction == 'none':"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7403,
        "label": "no",
        "change": [
            "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,",
            "if pred == tgt_vocab['<eos>']:",
            "break",
            "output_seq.append(pred)",
            "-    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq# Alias defined in config.ini",
            "+    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq",
            "+",
            "+",
            "+# Alias defined in config.ini",
            "nn_Module = nn.Module",
            "",
            "ones_like = torch.ones_like"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7405,
        "label": "no",
        "change": [
            "class CascadeRCNN(BaseDetector, RPNTestMixin):",
            "scale_factor if rescale else det_bboxes)",
            "else:",
            "_bboxes = (",
            "-                        det_bboxes[:, :4] *",
            "-                        torch.from_numpy(scale_factor).to(det_bboxes.device)",
            "+                        det_bboxes[:, :4] * det_bboxes.new_tensor(scale_factor)",
            "if rescale else det_bboxes)",
            "",
            "mask_rois = bbox2roi([_bboxes])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7406,
        "label": "no",
        "change": [
            "class LocalGradientAggregationHelper:",
            "# If optimizer tracks iterations, we increment it on steps where we",
            "# are not going to call `apply_gradients()`.",
            "def increment_optimizer_iteration():",
            "-            if hasattr(optimizer, \"_iterations\") and optimizer._iterations is not None:",
            "-                return optimizer._iterations.assign_add(1).op",
            "+            # (kvignesh1420): Since all `tf.OptimizerV2` instances have the `iterations`",
            "+            # property for modifying the underlying `optimizer._iterations`, it is safe to use",
            "+            # the property instead of the private variable. For instance, the keras",
            "+            # `LossScaleOptimizer` inherits `tf.Optimizer` and exposes the cleaner `iterations`",
            "+            # property instead of the unsafe `_iterations`.",
            "+",
            "+            if hasattr(optimizer, \"iterations\") and optimizer.iterations is not None:",
            "+                return optimizer.iterations.assign_add(1).op",
            "return tf.no_op()",
            "",
            "with tf.control_dependencies([tf.group(*get_not_none_from_list(flattended_args0))]):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7407,
        "label": "no",
        "change": [
            "def bidirectional_rnn(incoming, rnncell_fw, rnncell_bw, return_seq=False,",
            "",
            "input_shape = utils.get_incoming_shape(incoming)",
            "",
            "-    with tf.variable_scope(scope, name, [incoming]) as scope:",
            "+    with tf.variable_scope(scope, name, values=[incoming]) as scope:",
            "name = scope.name",
            "",
            "# TODO: DropoutWrapper"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7411,
        "label": "no",
        "change": [
            "class BertClassifierModel(LRScheduledTFModel):",
            "self.token_types_ph = tf.placeholder(shape=(None, None), dtype=tf.int32, name='token_types_ph')",
            "",
            "if not self.one_hot_labels:",
            "-            self.y_ph = tf.placeholder(shape=(None, ), dtype=tf.int32, name='y_ph')",
            "+            self.y_ph = tf.placeholder(shape=(None,), dtype=tf.int32, name='y_ph')",
            "else:",
            "self.y_ph = tf.placeholder(shape=(None, self.n_classes), dtype=tf.float32, name='y_ph')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7415,
        "label": "no",
        "change": [
            "def FixedUnPooling(x, shape, unpool_mat=None):",
            "shape = shape2d(shape)",
            "",
            "# a faster implementation for this special case",
            "-    if shape[0] == 2 and  shape[1] == 2 and unpool_mat is None:",
            "+    if shape[0] == 2 and shape[1] == 2 and unpool_mat is None:",
            "return UnPooling2x2ZeroFilled(x)",
            "",
            "input_shape = tf.shape(x)",
            "if unpool_mat is None:",
            "mat = np.zeros(shape, dtype='float32')",
            "mat[0][0] = 1",
            "-        unpool_mat = tf.Variable(mat, trainable=False, name='unpool_mat')",
            "+        unpool_mat = tf.constant(mat, name='unpool_mat')",
            "elif isinstance(unpool_mat, np.ndarray):",
            "-        unpool_mat = tf.Variable(unpool_mat, trainable=False, name='unpool_mat')",
            "+        unpool_mat = tf.constant(unpool_mat, name='unpool_mat')",
            "assert unpool_mat.get_shape().as_list() == list(shape)",
            "",
            "# perform a tensor-matrix kronecker product"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7416,
        "label": "no",
        "change": [
            "class DeepQNetwork(ValueFunction):",
            "",
            "with tf.name_scope(\"update\"):",
            "self.q_targets = tf.placeholder(tf.float32, [None], name='q_targets')",
            "-            self.actions = tf.placeholder(tf.int32, [None, self.action_count], name='actions')",
            "+            self.actions = tf.placeholder(tf.int32, [None], name='actions')",
            "",
            "# Q values for actions taken in batch",
            "print(self.actions)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7421,
        "label": "no",
        "change": [
            "def _get_learning_rate(self):",
            "last_lr = (",
            "# backward compatibility for pytorch schedulers",
            "self.lr_scheduler.get_last_lr()[0]",
            "-            if version.parse(torch.__version__) >= version.parse(\"1.4\")",
            "+            if version.parse(version.parse(torch.__version__).base_version) >= version.parse(\"1.4\")",
            "else self.lr_scheduler.get_lr()[0]",
            ")",
            "return last_lr"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7422,
        "label": "no",
        "change": [
            "def get_outputs_sizes_tf(",
            ") -> List[Tuple[int, ...]]:",
            "outputs = tf_model(*input_tensors)",
            "if isinstance(outputs, tf.Tensor):",
            "-        return [tuple(tf.shape(outputs))]",
            "-    return [tuple(x.size()) for x in outputs]",
            "+        return [tuple(outputs.shape)]",
            "+    return [tuple(x.shape) for x in outputs]",
            "",
            "",
            "def create_model_inputs_tf("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7425,
        "label": "no",
        "change": [
            "def main():",
            "next_sample,",
            "feed_dict={samples: window})",
            "",
            "-        sample = np.random.choice(np.arange(quantization_steps), p=prediction)",
            "+        sample = np.random.choice(np.arange(quantization_channels), p=prediction)",
            "waveform.append(sample)",
            "print('Sample {:3<d}/{:3<d}: {}'",
            ".format(step + 1, args.samples, sample))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7428,
        "label": "no",
        "change": [
            "def make_preprocessing_model(file_dir):",
            "",
            "def make_training_model():",
            "\"\"\"Make a trainable model for the preprocessed inputs.\"\"\"",
            "-  float_in = tf.keras.Input(shape=(1,), dtype=\"float64\", name=\"float_col\")",
            "+  float_in = tf.keras.Input(shape=(1,), dtype=\"float32\", name=\"float_col\")",
            "# After preprocessing, both the string and int column are integer ready for",
            "# embedding.",
            "int_in = tf.keras.Input(shape=(1,), dtype=\"int64\", name=\"int_col\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7429,
        "label": "no",
        "change": [
            "-import torch",
            "-",
            "-from ludwig.encoders.binary_encoders import BinaryPassthroughEncoder",
            "-",
            "-",
            "-def test_binary_passthrough_encoder():",
            "-    binary_encoder = BinaryPassthroughEncoder()",
            "-    inputs = torch.rand(2, 1)",
            "-    outputs = binary_encoder(inputs)",
            "-    assert outputs.shape[1:] == binary_encoder.output_shape"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7430,
        "label": "no",
        "change": [
            "def triangulate_points(",
            "# 1. Solve the system Ax=0 with smallest eigenvalue",
            "# 2. Return homogeneous coordinates",
            "",
            "-    _, _, V = torch.svd(X)",
            "+    _, _, V = _torch_svd_cast(X)",
            "",
            "points3d_h = V[..., -1]",
            "points3d: torch.Tensor = convert_points_from_homogeneous(points3d_h)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7431,
        "label": "no",
        "change": [
            "def export_saved_model_to_caffe2(",
            "def export_saved_model_to_torchscript(",
            "saved_model_path: str, path: str, export_config: ExportConfig",
            ") -> None:",
            "+    cuda.CUDA_ENABLED = False",
            "+    precision.FP16_ENABLED = False",
            "task, train_config, _training_state = load(saved_model_path)",
            "task.torchscript_export(task.model, path, False, 1, export_config=export_config)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7432,
        "label": "no",
        "change": [
            "class TestDQFDAgent(unittest.TestCase):",
            "tf.reset_default_graph()",
            "",
            "# DQFD uses l2-reg",
            "-        network_builder = layered_network_builder(layers_config=[{'type': 'dense', 'size': 32,",
            "-                                                                  'weights_regularizer': 'tensorflow.contrib.layers.python.layers.regularizers.l2_regularizer',",
            "-                                                                  'weights_regularizer_kwargs': {",
            "-                                                                      'scale': 0.001",
            "-                                                                  }",
            "+        network_builder = layered_network_builder(layers_config=[{'type': 'dense',",
            "+                                                                  'size': 32,",
            "+                                                                  'l2_regularization': 0.001",
            "}])",
            "",
            "agent = DQFDAgent(config=config, network_builder=network_builder)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7433,
        "label": "no",
        "change": [
            "def interpolate(x,",
            "args[3], args[4], validate_args)",
            "",
            "with tf.control_dependencies(",
            "-        [tf.assert_equal(tf.shape(x_data), tf.shape(y_data))]):",
            "+        [tf.compat.v1.assert_equal(tf.shape(x_data), tf.shape(y_data))]):",
            "# Call 1D linear interpolation function for each batch separately.",
            "return tf.reshape(",
            "tf.map_fn("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7437,
        "label": "no",
        "change": [
            "def main(args, task=None, model_state=None):",
            "wps_meter = TimeMeter()",
            "for sample in t:",
            "sample = utils.move_to_cuda(sample) if use_cuda else sample",
            "+            if use_fp16:",
            "+                sample = utils.apply_to_sample(apply_half, sample)",
            "if \"net_input\" not in sample:",
            "continue"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7439,
        "label": "no",
        "change": [
            "class WGAN(object):",
            "D_fake, D_fake_logits, _ = self.discriminator(G, is_training=True, reuse=True)",
            "",
            "# get loss for discriminator",
            "-        d_loss_real = - tf.reduce_mean(D_real)",
            "-        d_loss_fake = tf.reduce_mean(D_fake)",
            "+        d_loss_real = - tf.reduce_mean(D_real_logits)",
            "+        d_loss_fake = tf.reduce_mean(D_fake_logits)",
            "",
            "self.d_loss = d_loss_real + d_loss_fake"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7440,
        "label": "no",
        "change": [
            "class TFTrainingArguments(TrainingArguments):",
            "def _setup_strategy(self) -> Tuple[\"tf.distribute.Strategy\", int]:",
            "logger.info(\"Tensorflow: setting up strategy\")",
            "",
            "-        if self.xla:",
            "-            tf.config.optimizer.set_jit(True)",
            "-",
            "gpus = tf.config.list_physical_devices(\"GPU\")",
            "",
            "# Set to float16 at first"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7443,
        "label": "yes",
        "change": [
            "class SimpleSummarizationPipelineTests(unittest.TestCase):",
            "# Bias output towards L",
            "V, C = model.lm_head.weight.shape",
            "",
            "-        bias = torch.zeros(V, requires_grad=True)",
            "+        bias = torch.zeros(V)",
            "bias[76] = 10",
            "",
            "model.lm_head.bias = torch.nn.Parameter(bias)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "removal",
        "Element": "api parameter"
    },
    {
        "number": 7446,
        "label": "no",
        "change": [
            "class TestRemap:",
            "grid = kornia.utils.create_meshgrid(height, width, normalized_coordinates=False, device=device).to(dtype)",
            "grid += 1.0  # apply some shift",
            "input_tuple = (img, grid[..., 0], grid[..., 1])",
            "-        op_traced = torch.jit.trace(op_script, input_tuple)",
            "+        _ = torch.jit.trace(op_script, input_tuple)",
            "",
            "# 2. Generate different input",
            "batch_size, channels, height, width = 2, 2, 2, 5"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7447,
        "label": "no",
        "change": [
            "class AttentionRNN(nn.Module):",
            "def __init__(self, out_dim, annot_dim, memory_dim,",
            "score_mask_value=-float(\"inf\")):",
            "super(AttentionRNN, self).__init__()",
            "-        self.rnn_cell = nn.GRUCell(annot_dim + memory_dim, out_dim)",
            "+        self.rnn_cell = nn.GRUCell(out_dim + memory_dim, out_dim)",
            "self.alignment_model = BahdanauAttention(annot_dim, out_dim, out_dim)",
            "self.score_mask_value = score_mask_value"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7448,
        "label": "no",
        "change": [
            "class PytorchSeq2VecWrapper(Seq2VecEncoder):",
            "# batch size is the second dimension here, because pytorch",
            "# returns RNN state as a tensor of shape (num_layers * num_directions,",
            "# batch_size, hidden_size)",
            "-            zeros = state.data.new(num_layers_times_directions,",
            "-                                   batch_size - num_valid,",
            "-                                   encoding_dim).fill_(0)",
            "-            zeros = Variable(zeros)",
            "+            zeros = state.new_zeros(num_layers_times_directions,",
            "+                                    batch_size - num_valid,",
            "+                                    encoding_dim)",
            "state = torch.cat([state, zeros], 1)",
            "",
            "# Restore the original indices and return the final state of the"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7450,
        "label": "no",
        "change": [
            "def cross(",
            "promote_type = torch.promote_types(x1.dtype, x2.dtype)",
            "x1 = x1.type(promote_type)",
            "x2 = x2.type(promote_type)",
            "+    print(torch.__version__)",
            "return torch.cross(input=x1, other=x2, dim=axis, out=out)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7451,
        "label": "no",
        "change": [
            "def to_hetero(module: Module, metadata: Metadata, aggr: str = \"sum\",",
            "import torch",
            "from torch_geometric.nn import SAGEConv, to_hetero",
            "",
            "-        Net(torch.nn.Module):",
            "+        class GNN(torch.nn.Module):",
            "def __init__(self):",
            "-                self.conv1 = SAGEConv(-1, 16)",
            "-                self.conv2 = SAGEConv(16, 16)",
            "+                self.conv1 = SAGEConv((-1, -1), 32)",
            "+                self.conv2 = SAGEConv((32, 32), 32)",
            "",
            "def forward(self, x, edge_index):",
            "x = self.conv1(x, edge_index).relu()",
            "x = self.conv2(x, edge_index).relu()",
            "return x",
            "",
            "-        model = Net()",
            "+        model = GNN()",
            "",
            "node_types = ['paper', 'author']",
            "edge_types = ["
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7456,
        "label": "yes",
        "change": [
            "def get_batch_statistics(outputs, targets, iou_threshold):",
            "continue",
            "",
            "# Filter target_boxes by pred_label so that we only match against boxes of our own label",
            "-                filtered_target_position, filtered_targets = zip(*filter(lambda x: target_labels[x] == pred_label, enumerate(target_boxes)))",
            "-",
            "+                filtered_target_position, filtered_targets = zip(*filter(lambda x: target_labels[x[0]] == pred_label, enumerate(target_boxes)))",
            "+",
            "# Find the best matching target for our predicted box",
            "-                iou, box_filtered_index = bbox_iou(pred_box.unsqueeze(0), filtered_targets).max(0)",
            "-",
            "+                iou, box_filtered_index = bbox_iou(pred_box.unsqueeze(0), torch.stack(filtered_targets)).max(0)",
            "+",
            "# Remap the index in the list of filtered targets for that label to the index in the list with all targets.",
            "box_index = filtered_target_position[box_filtered_index]"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 7457,
        "label": "no",
        "change": [
            "class NeighborSampler(BaseSampler):",
            "# TODO (matthias) Add `disjoint` option to `NeighborSampler`",
            "# TODO (matthias) `return_edge_id` if edge features present",
            "disjoint = self.node_time_dict is not None",
            "-                out = torch.ops.pyg.hetero_neighbor_sample_cpu(",
            "+                out = torch.ops.pyg.hetero_neighbor_sample(",
            "self.node_types,",
            "self.edge_types,",
            "self.colptr_dict,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7463,
        "label": "no",
        "change": [
            "def test_stop_gradient(x_raw, dtype, tensor_fn, device, call):",
            "# Tf graph mode cannot create variables as part of the computation graph",
            "assert np.array_equal(",
            "call(ivy.stop_gradient, x),",
            "-            ivy.functional.backends.numpy.array(x_raw, dtype),",
            "+            np.array(x_raw, dtype=dtype),",
            ")",
            "# compilation test",
            "if call in [helpers.torch_call]:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7465,
        "label": "no",
        "change": [
            "def run_model_torch(model, inputs, CONFIG, truncated, speaker_id=None, style_mel",
            "decoder_output, postnet_output, alignments, stop_tokens = model.inference(",
            "inputs, speaker_ids=speaker_id, speaker_embeddings=speaker_embeddings)",
            "elif 'glow' in CONFIG.model.lower():",
            "-        inputs_lengths = torch.tensor(inputs.shape[1:2]).to(inputs.device)",
            "+        inputs_lengths = torch.tensor(inputs.shape[1:2]).to(inputs.device)  # pylint: disable=not-callable",
            "postnet_output, _, _, _, alignments, _, _ = model.inference(inputs, inputs_lengths)",
            "postnet_output = postnet_output.permute(0, 2, 1)",
            "# these only belong to tacotron models."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7466,
        "label": "no",
        "change": [
            "class FrameScoreFeats(AbsFeatsExtract):",
            "pad = self.win_length // 2",
            "input_lengths = input_lengths + 2 * pad",
            "",
            "-            olens = (",
            "-                torch.div(",
            "-                    (input_lengths - self.win_length),",
            "-                    self.hop_length,",
            "-                    rounding_mode=\"floor\",",
            "-                )",
            "-                + 1",
            "-            )",
            "+            olens = torch.div((input_lengths - self.win_length), self.hop_length) + 1",
            "output.masked_fill_(make_pad_mask(olens, output, 1), 0.0)",
            "else:",
            "olens = None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7471,
        "label": "no",
        "change": [
            "def feature_visualization(x, module_type, stage, n=64, save_dir=Path('runs/detec",
            "f = f\"stage{stage}_{module_type.split('.')[-1]}_features.png\"  # filename",
            "",
            "plt.figure(tight_layout=True)",
            "-            blocks = torch.chunk(x[0], channels, dim=0)  # select batch index 0, block by channels",
            "+            blocks = torch.chunk(x[0].cpu(), channels, dim=0)  # select batch index 0, block by channels",
            "n = min(n, channels)  # number of plots",
            "ax = plt.subplots(math.ceil(n / 8), 8, tight_layout=True)[1].ravel()  # 8 rows x n/8 cols",
            "for i in range(n):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7472,
        "label": "no",
        "change": [
            "ACT2FN = {",
            "\"gelu_new\": NewGELUActivation(),",
            "\"gelu_fast\": FastGELUActivation(),",
            "\"quick_gelu\": QuickGELUActivation(),",
            "+    \"gelu_10\": ClippedGELUActivation(-10, 10),",
            "\"mish\": MishActivation(),",
            "\"linear\": LinearActivation(),",
            "\"sigmoid\": nn.Sigmoid(),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7475,
        "label": "no",
        "change": [
            "def accumulate_strings(values, name=\"strings\"):",
            "initial_value=[],",
            "dtype=tf.string,",
            "trainable=False,",
            "-      collections=[tf.GraphKeys.LOCAL_VARIABLES],",
            "+      collections=[],",
            "validate_shape=True)",
            "value_tensor = tf.identity(strings)",
            "update_op = tf.assign("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7480,
        "label": "no",
        "change": [
            "def transform_points(dst_homo_src, points_src):",
            "# to homogeneous",
            "points_src_h = convert_points_to_homogeneous(points_src)  # BxNx3",
            "# transform coordinates",
            "-    points_dst_h = torch.matmul(dst_homo_src, points_src_h.transpose(1, 2))  # Bx3xN",
            "+    points_dst_h = torch.matmul(dst_homo_src, points_src_h.transpose(1, 2))",
            "points_dst_h = points_dst_h.permute(0, 2, 1)  # BxNx3",
            "# to euclidean",
            "points_dst = convert_points_from_homogeneous(points_dst_h)  # BxNx2"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7483,
        "label": "no",
        "change": [
            "class NcclBackend(object):",
            "buffer_m = torch.cat([buffer_m, empty_tensor])",
            "",
            "buffer_m.add_(worker_error)",
            "-        worker_scale = torch.norm(buffer_m) / np.sqrt(torch.numel(buffer_m))",
            "+        worker_scale = torch.norm(buffer_m) / np.sqrt(buffer_m.numel())",
            "worker_error.set_(buffer_m - worker_scale *",
            "buffer_m.sign().add_(1).bool().float().add_(-0.5).mul_(2.0))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7493,
        "label": "yes",
        "change": [
            "class XLNetRelativeAttention(nn.Module):",
            "attn_vec = torch.einsum('bnij,jbnd->ibnd', attn_prob, v_head_h)",
            "",
            "if self.output_attentions:",
            "-            return attn_vec, attn_prob",
            "+            return attn_vec, torch.einsum('bnij->ijbn', attn_prob)",
            "",
            "return attn_vec"
        ],
        "comments": "",
        "Symptom": "return warning",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 7495,
        "label": "no",
        "change": [
            "def _load_weights(model: nn.Module, checkpoint_path: str, prefix: str = 'resnet/",
            "model.stem.conv.weight.copy_(stem_conv_w)",
            "model.norm.weight.copy_(t2p(weights[f'{prefix}group_norm/gamma']))",
            "model.norm.bias.copy_(t2p(weights[f'{prefix}group_norm/beta']))",
            "-    if isinstance(model.head.fc, nn.Conv2d) and \\",
            "+    if isinstance(getattr(model.head, 'fc', None), nn.Conv2d) and \\",
            "model.head.fc.weight.shape[0] == weights[f'{prefix}head/conv2d/kernel'].shape[-1]:",
            "model.head.fc.weight.copy_(t2p(weights[f'{prefix}head/conv2d/kernel']))",
            "model.head.fc.bias.copy_(t2p(weights[f'{prefix}head/conv2d/bias']))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7497,
        "label": "no",
        "change": [
            "class HeteroLinear(torch.nn.Module):",
            "self.is_sorted = is_sorted",
            "self.kwargs = kwargs",
            "",
            "-        self._WITH_PYG_LIB = torch.cuda.is_available() and _WITH_PYG_LIB",
            "+        self._WITH_PYG_LIB = _WITH_PYG_LIB",
            "",
            "if self._WITH_PYG_LIB:",
            "self.weight = torch.nn.Parameter("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7499,
        "label": "yes",
        "change": [
            "class VGG(Model):",
            "",
            "inputs = inputs * 255 - np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape([1, 1, 1, 3])",
            "",
            "-        out = self.layers(inputs)",
            "+        out = self.layers.forward(inputs)",
            "return out"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 7504,
        "label": "no",
        "change": [
            "class TeluguBooks(datasets.GeneratorBasedBuilder):",
            "path_to_manual_file = os.path.abspath(os.path.expanduser(dl_manager.manual_dir))",
            "if not os.path.exists(path_to_manual_file):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('telugu_books', data_dir=...)` that includes file name {}. Manual download instructions: {}\".format(",
            "-                    path_to_manual_file,",
            "-                    _FILENAME,",
            "-                    self.manual_download_instructions,",
            "-                )",
            "+                f\"{path_to_manual_file} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('telugu_books', data_dir=...)` that includes file name {_FILENAME}. Manual download instructions: {self.manual_download_instructions}\"",
            ")",
            "return [",
            "datasets.SplitGenerator("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7511,
        "label": "no",
        "change": [
            "class GammaGaussian:",
            "Integrates out all latent state (i.e. operating on event dimensions) of Gaussian component.",
            "\"\"\"",
            "n = self.dim()",
            "-        chol_P = self.precision.cholesky()",
            "+        chol_P = torch.linalg.cholesky(self.precision)",
            "chol_P_u = self.info_vec.unsqueeze(-1).triangular_solve(chol_P, upper=False).solution.squeeze(-1)",
            "u_P_u = chol_P_u.pow(2).sum(-1)",
            "# considering GammaGaussian as a Gaussian with precision = s * precision, info_vec = s * info_vec,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7513,
        "label": "no",
        "change": [
            "class MultiLabelField(Field[torch.Tensor]):",
            "def as_tensor(self, padding_lengths: Dict[str, int]) -> torch.Tensor:",
            "# pylint: disable=unused-argument",
            "",
            "-        tensor = torch.zeros(self._num_labels)  # vector of zeros",
            "+        tensor = torch.zeros(self._num_labels, dtype=torch.long)  # vector of zeros",
            "if self._label_ids:",
            "tensor.scatter_(0, torch.LongTensor(self._label_ids), 1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7514,
        "label": "no",
        "change": [
            "class RepPointsDetector(SingleStageDetector):",
            "for x, img_meta in zip(feats, img_metas):",
            "# only one image in the batch",
            "outs = self.bbox_head(x)",
            "-            bbox_inputs = outs + (img_metas, self.test_cfg, False, False)",
            "+            bbox_inputs = outs + (img_meta, self.test_cfg, False, False)",
            "det_bboxes, det_scores = self.bbox_head.get_bboxes(*bbox_inputs)[0]",
            "aug_bboxes.append(det_bboxes)",
            "aug_scores.append(det_scores)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7517,
        "label": "no",
        "change": [
            "class FBetaMeasure(Metric):",
            "",
            "if mask is None:",
            "mask = torch.ones_like(gold_labels)",
            "-        mask = mask.to(torch.uint8)",
            "+        mask = mask.to(dtype=torch.bool)",
            "gold_labels = gold_labels.float()",
            "",
            "argmax_predictions = predictions.max(dim=-1)[1].float()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7518,
        "label": "no",
        "change": [
            "class ViterbiLoss(torch.nn.Module):",
            "targets = torch.tensor(formatted_targets, dtype=torch.long).unsqueeze(2).to(flair.device)",
            "",
            "# Squeeze crf scores matrices in 1-dim shape and gather scores at targets by matrix indices",
            "-        scores_at_targets = torch.gather(features.view(batch_size, seq_len, -1), 2, targets).squeeze(0).squeeze(0)",
            "+        scores_at_targets = torch.gather(features.view(batch_size, seq_len, -1), 2, targets)",
            "scores_at_targets = pack_padded_sequence(scores_at_targets, lengths.values, batch_first=True)[0]",
            "gold_score = scores_at_targets.sum()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7519,
        "label": "no",
        "change": [
            "class CapsNet(object):",
            "else:",
            "# self.masked_v = tf.matmul(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, 10, 1)), transpose_a=True)",
            "self.masked_v = tf.multiply(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, 10, 1)))",
            "-                self.v_length = tf.sqrt(tf.reduce_sum(tf.square(self.caps2), axis=2, keep_dims=True) + epsilon)",
            "+                self.v_length = tf.sqrt(reduce_sum(tf.square(self.caps2), axis=2, keepdims=True) + epsilon)",
            "",
            "# 2. Reconstructe the MNIST images with 3 FC layers",
            "# [batch_size, 1, 16, 1] => [batch_size, 16] => [batch_size, 512]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7523,
        "label": "no",
        "change": [
            "def setup(app):",
            "",
            "",
            "# @jpchen's hack to get rtd builder to install latest pytorch",
            "+# See similar line in the install section of .travis.yml",
            "if 'READTHEDOCS' in os.environ:",
            "-    os.system('pip install torch==1.3.0+cpu -f https://download.pytorch.org/whl/torch_stable.html')",
            "+    os.system('pip install torch==1.3.0+cpu torchvision==0.4.0+cpu '",
            "+              '-f https://download.pytorch.org/whl/torch_stable.html')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7527,
        "label": "no",
        "change": [
            "class InceptionV4(nn.Module):",
            "x = self.forward_features(x)",
            "if self.drop_rate > 0:",
            "x = F.dropout(x, p=self.drop_rate, training=self.training)",
            "-        x = self.classif(x)",
            "+        x = self.last_linear(x)",
            "return x"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7528,
        "label": "yes",
        "change": [
            "class Uniform(Distribution):",
            "if x.size != a.size():",
            "a = a.expand_as(x)",
            "b = b.expand_as(x)",
            "-        l = x.ge(a).type_as(a)",
            "-        u = x.le(b).type_as(b)",
            "+        lb = x.ge(a).type_as(a)",
            "+        ub = x.le(b).type_as(b)",
            "batch_log_pdf_shape = self.batch_shape(a, b) + (1,)",
            "-        return torch.sum(torch.log(l.mul(u)) - torch.log(b - a), -1).contiguous().view(batch_log_pdf_shape)",
            "+        return torch.sum(torch.log(lb.mul(ub)) - torch.log(b - a), -1).contiguous().view(batch_log_pdf_shape)",
            "",
            "def analytic_mean(self, a=None, b=None):",
            "a, b = self._sanitize_input(a, b)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 7539,
        "label": "no",
        "change": [
            "class CosineAttention(Attention):",
            "\"\"\"",
            "Computes attention between a vector and a matrix using cosine similarity.",
            "\"\"\"",
            "-",
            "@overrides",
            "-    def _forward_internal(self,",
            "-                          vector: torch.Tensor,",
            "-                          matrix: torch.Tensor,",
            "-                          matrix_mask: torch.Tensor = None) -> torch.Tensor:",
            "+    def _forward_internal(self, vector: torch.Tensor, matrix: torch.Tensor) -> torch.Tensor:",
            "a_norm = vector / (vector.norm(p=2, dim=-1, keepdim=True) + 1e-13)",
            "b_norm = matrix / (matrix.norm(p=2, dim=-1, keepdim=True) + 1e-13)",
            "return torch.bmm(a_norm.unsqueeze(dim=1), b_norm.transpose(-1, -2)).squeeze(1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7549,
        "label": "no",
        "change": [
            "class SpatialGradient(nn.Module):",
            "self.kernel.size(2) // 2,",
            "self.kernel.size(2) // 2]",
            "out_channels: int = 3 if self.order == 2 else 2",
            "-        padded_inp: torch.Tensor = F.pad(input.view(b * c, 1, h, w), spatial_pad, 'replicate')[:, :, None]",
            "+        padded_inp: torch.Tensor = F.pad(input.reshape(b * c, 1, h, w), spatial_pad, 'replicate')[:, :, None]",
            "return F.conv3d(padded_inp, kernel_flip, padding=0).view(b, c, out_channels, h, w)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7559,
        "label": "yes",
        "change": [
            "class SSIMLoss(torch.nn.Module):",
            "",
            "if ssim_loss.item() > 1.0:",
            "print(f\" > SSIM loss is out-of-range {ssim_loss.item()}, setting it 1.0\")",
            "-            ssim_loss = torch.tensor([1.0])",
            "+            ssim_loss = torch.tensor([1.0], device=ssim_loss.device)",
            "",
            "if ssim_loss.item() < 0.0:",
            "print(f\" > SSIM loss is out-of-range {ssim_loss.item()}, setting it 0.0\")",
            "-            ssim_loss = torch.tensor([0.0])",
            "+            ssim_loss = torch.tensor([0.0], device=ssim_loss.device)",
            "",
            "return ssim_loss"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 7560,
        "label": "no",
        "change": [
            "_URLs = {",
            "class WikiLingua(datasets.GeneratorBasedBuilder):",
            "\"\"\"TODO: Short description of my dataset.\"\"\"",
            "",
            "-    VERSION = datasets.Version(\"1.1.0\")",
            "+    VERSION = datasets.Version(\"1.1.1\")",
            "",
            "# This is an example of a dataset with multiple configurations.",
            "# If you don't want/need to define several sub-sets in your dataset,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7564,
        "label": "no",
        "change": [
            "class GPBayesOptimizer(pyro.optim.multi.MultiOptimizer):",
            "x_init = self.gpmodel.X.new_empty(1).uniform_(",
            "self.constraints.lower_bound, self.constraints.upper_bound)",
            "x, y = self.find_a_candidate(differentiable, x_init)",
            "+            if torch.isnan(y):",
            "+                continue",
            "candidates.append(x)",
            "values.append(y)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7567,
        "label": "no",
        "change": [
            "def edge_tensor_type_to_adj_type(",
            "size=(src.size()[0] + dst.size()[0], ))",
            "return out.view(2, -1)",
            "",
            "-        return torch.stack(tensor_tuple, dim=0)",
            "+        return torch.stack([src, dst], dim=0)",
            "",
            "elif attr.layout == EdgeLayout.CSR:  # CSR: (rowptr, col)",
            "return SparseTensor(rowptr=src, col=dst, is_sorted=True,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7569,
        "label": "no",
        "change": [
            "def dependency_of_fetches(fetches, op):",
            "\"\"\"",
            "try:",
            "from tensorflow.python.client.session import _FetchHandler as FetchHandler",
            "-        handler = FetchHandler(tf.get_default_graph(), fetches, {})",
            "+        # use the graph of the op, so that this function can be called without being under a default graph",
            "+        handler = FetchHandler(op.graph, fetches, {})",
            "targets = tuple(handler.fetches() + handler.targets())",
            "except ImportError:",
            "if isinstance(fetches, list):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7572,
        "label": "no",
        "change": [
            "class ShardedVariableTest(tf.test.TestCase):",
            "self.assertAllClose(got, expect)",
            "self.assertGreater(len(model.variables), len(loaded_model.variables))",
            "",
            "-    with self.assertRaises(ValueError):",
            "-      with self.strategy.scope():",
            "-        keras.models.load_model(saved_dir)",
            "+    with self.strategy.scope():",
            "+      keras.models.load_model(saved_dir)",
            "",
            "def test_slot_variable_checkpointing(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7579,
        "label": "no",
        "change": [
            "class Grayscale(Preprocessor):",
            "",
            "def tf_process(self, tensor):",
            "weights = tf.reshape(tensor=self.weights, shape=(tuple(1 for _ in range(util.rank(tensor) - 1)) + (3,)))",
            "-        return tf.reduce_sum(input_tensor=(weights * tensor), axis=-1, keep_dims=True)",
            "+        return tf.reduce_sum(input_tensor=(weights * tensor), axis=-1, keepdims=True)",
            "",
            "def processed_shape(self, shape):",
            "return tuple(shape[:-1]) + (1,)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7581,
        "label": "no",
        "change": [
            "class RaoBlackwellizationTests(TestCase):",
            "mean_1_error = torch.sum(torch.pow(pyro.param(\"mean_1_%d\" % k), 2.0))",
            "mean_2_error = torch.sum(torch.pow(pyro.param(\"mean_2_%d\" % k), 2.0))",
            "superfluous_error = torch.max(torch.max(mean_0_error, mean_1_error), mean_2_error)",
            "-                    superfluous_errors.append(superfluous_error.data.numpy()[0])",
            "+                    superfluous_errors.append(superfluous_error.data.cpu().numpy()[0])",
            "",
            "if step % 500 == 0 and self.verbose:",
            "print(\"mu error, log(sigma) error:  %.4f, %.4f\" % (mu_error, log_sig_error))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7586,
        "label": "no",
        "change": [
            "if 'READTHEDOCS' in os.environ:",
            "# TODO replace with torch_stable before release",
            "# os.system('pip install torch==1.8.0+cpu torchvision==0.9.0+cpu '",
            "#           '-f https://download.pytorch.org/whl/torch_stable.html')",
            "-    # TODO replace with torch_test once torchvision binaries are released",
            "-    # os.system('pip install torch torchvision '",
            "-    #           '-f https://download.pytorch.org/whl/test/cpu/torch_test.html')",
            "-    # This is the last nightly release of 1.8.0 before splitting to 1.9.0.",
            "-    os.system('pip install --pre '",
            "-              'torch==1.8.0.dev20210210+cpu '",
            "-              'torchvision==0.9.0.dev20210210+cpu '",
            "-              '-f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html')",
            "+    os.system('pip install torch==1.8.0+cpu torchvision==0.9.0 '",
            "+              '-f https://download.pytorch.org/whl/test/cpu/torch_test.html')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7587,
        "label": "no",
        "change": [
            "class LayerNode_Test(CustomTestCase):",
            ")",
            "emb, nce = emb_net([inputs, labels])",
            "",
            "-            model = tl.models.Model(inputs=[inputs, labels], outputs=[emb, nce], name=\"word2vec_model\")",
            "+            model = tl.models.Model(inputs=[inputs, labels], outputs=[emb, nce])",
            "return model",
            "",
            "net = get_word2vec()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7588,
        "label": "no",
        "change": [
            "def test_get_hanning_kernel1d_5(device, dtype):",
            "",
            "def test_get_hanning_kernel2d_3x4(device, dtype):",
            "kernel = kornia.filters.get_hanning_kernel2d((3, 4), dtype=dtype, device=device)",
            "-    expected = torch.tensor([[0., 0.00, 0.00, 0.],",
            "-                             [0., 0.75, 0.75, 0.],",
            "-                             [0., 0.00, 0.00, 0.]], dtype=dtype, device=device)",
            "+    expected = torch.tensor(",
            "+        [[0.0, 0.00, 0.00, 0.0], [0.0, 0.75, 0.75, 0.0], [0.0, 0.00, 0.00, 0.0]], dtype=dtype, device=device",
            "+    )",
            "assert kernel.shape == (3, 4)",
            "assert_close(kernel, expected)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7590,
        "label": "no",
        "change": [
            "def hetero_data():",
            "data['paper'].x = torch.randn(8, 16)",
            "data['author'].x = torch.randn(10, 8)",
            "",
            "-    data['paper', 'paper'].edge_index = get_edge_index(8, 8, num_edges=10)",
            "+    data['paper', 'paper'].edge_index = get_random_edge_index(8, 8, 10)",
            "data['paper', 'paper'].edge_attr = torch.randn(10, 16)",
            "-    data['paper', 'author'].edge_index = get_edge_index(8, 10, num_edges=10)",
            "+    data['paper', 'author'].edge_index = get_random_edge_index(8, 10, 10)",
            "data['paper', 'author'].edge_attr = torch.randn(10, 8)",
            "-    data['author', 'paper'].edge_index = get_edge_index(10, 8, num_edges=10)",
            "+    data['author', 'paper'].edge_index = get_random_edge_index(10, 8, 10)",
            "data['author', 'paper'].edge_attr = torch.randn(10, 8)",
            "",
            "return data"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7591,
        "label": "no",
        "change": [
            "def deserialize_keras_object(",
            ")",
            ")",
            "else:",
            "-        return tf.keras.utils.deserialize_keras_object(",
            "+        return tf.keras.utils.deserialize_keras_object(  # pragma: no cover",
            "config, custom_objects, module_objects, printable_module_name",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7593,
        "label": "no",
        "change": [
            "def numpy_tensor_serializer(worker: AbstractWorker, tensor: torch.Tensor) -> bin",
            "\"Torch to Numpy serializer can only be used with tensors that do not require grad. \"",
            "\"Detaching tensor to continue\"",
            ")",
            "-        tensor = torch.detach()",
            "+        tensor = tensor.detach()",
            "",
            "np_tensor = tensor.numpy()",
            "outfile = io.BytesIO()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7594,
        "label": "no",
        "change": [
            "class ModelCatalog:",
            "",
            "dtype, shape = ModelCatalog.get_action_shape(action_space)",
            "",
            "-        return tf.placeholder(dtype, shape=shape, name=name)",
            "+        return tf1.placeholder(dtype, shape=shape, name=name)",
            "",
            "@staticmethod",
            "@DeveloperAPI"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7595,
        "label": "no",
        "change": [
            "if __name__ == '__main__':",
            "# validation_dataset = training_dataset.map(data_aug_valid, num_parallel_calls=multiprocessing.cpu_count())",
            "trainer = tl.distributed.Trainer(",
            "build_training_func=build_train, training_dataset=training_dataset, optimizer=tf.train.AdamOptimizer,",
            "-        optimizer_args={'learning_rate': 0.0001}, batch_size=128, num_epochs=50000, prefetch_buffer_size=4096",
            "+        optimizer_args={'learning_rate': 0.0001}, batch_size=128, prefetch_size=128",
            "# validation_dataset=validation_dataset, build_validation_func=build_validation",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7597,
        "label": "yes",
        "change": [
            "class LstmTagger(Model):",
            "",
            "def forward(self,",
            "sentence: Dict[str, torch.Tensor],",
            "-                labels: torch.Tensor = None) -> torch.Tensor:",
            "+                labels: torch.Tensor = None) -> Dict[str, torch.Tensor]:",
            "mask = get_text_field_mask(sentence)",
            "embeddings = self.word_embeddings(sentence)",
            "encoder_out = self.encoder(embeddings, mask)"
        ],
        "comments": "",
        "Symptom": "return warning",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 7601,
        "label": "yes",
        "change": [
            "class TensorFlowEstimator(BaseEstimator):",
            "# Set up a single operator to merge all the summaries",
            "summary_op = tf.merge_all_summaries()",
            "# Set up summary writer to a tmp directory",
            "-        self._summary_writer = tf.train.SummaryWriter('/tmp/tensorflow_logs', graph_def=sess.graph_def)",
            "+        self._summary_writer = tf.train.SummaryWriter('/tmp/tensorflow_logs', graph_def=self._session.graph_def)",
            "",
            "def fit(self, X, y):",
            "\"\"\"Builds a neural network model given provided `model_fn` and training"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 7602,
        "label": "yes",
        "change": [
            "def test_inputs(framework: str | None) -> list[tuple[ModuleType, FrameworkTestMo",
            ")",
            "except ModuleNotFoundError as e:",
            "logger.warning(",
            "-                f\"Failed to find test module for framework {framework_name} (tests.integration.frameworks.models.{framework_name})\"",
            "+                f\"Failed to find test module for framework {framework_name} (tests.integration.frameworks.models.{framework_name}): {e}\"",
            ")",
            "",
            "return ["
        ],
        "comments": "",
        "Symptom": "return warning",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 7603,
        "label": "no",
        "change": [
            "from ..builder import LOSSES",
            "",
            "def _expand_onehot_labels(labels, label_weights, label_channels):",
            "bin_labels = labels.new_full((labels.size(0), label_channels), 0)",
            "-    inds = torch.nonzero((labels >= 0) & (labels < label_channels)).squeeze()",
            "+    inds = torch.nonzero(",
            "+        (labels >= 0) & (labels < label_channels), as_tuple=False).squeeze()",
            "if inds.numel() > 0:",
            "bin_labels[inds, labels[inds]] = 1",
            "bin_label_weights = label_weights.view(-1, 1).expand("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7606,
        "label": "no",
        "change": [
            "class TFModel(Trainable, Inferable, metaclass=TfModelMeta):",
            "print('\\n:: Model saved to {} \\n'.format(self.model_path_.as_posix()))",
            "",
            "def get_checkpoint_state(self):",
            "-        if self.model_path_.is_dir():",
            "-            return tf.train.get_checkpoint_state(self.model_path_)",
            "-        return tf.train.get_checkpoint_state(self.model_path_.parent)",
            "+        if self._model_file:",
            "+            return tf.train.get_checkpoint_state(self.model_path_.parent)",
            "+        return tf.train.get_checkpoint_state(self.model_path_)",
            "",
            "@check_path_exists('dir')",
            "@overrides"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7607,
        "label": "no",
        "change": [
            "def random_normal(",
            "true_shape: List[int] = shape",
            "mean = mean.item() if isinstance(mean, torch.Tensor) else mean",
            "std = std.item() if isinstance(std, torch.Tensor) else std",
            "-    return torch.normal(",
            "-        mean, std, true_shape, device=default_device(device)",
            "-    )",
            "+    return torch.normal(mean, std, true_shape, device=default_device(device))",
            "",
            "",
            "def multinomial("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7613,
        "label": "no",
        "change": [
            "gelu.unsupported_dtypes = (\"float16\",)",
            "",
            "def sigmoid(x: torch.Tensor, /, *, out: Optional[torch.Tensor] = None) -> torch.Tensor:",
            "if not ivy.is_array(x):",
            "-        x=torch.tensor(x)",
            "+        x = torch.tensor(x)",
            "return torch.sigmoid(x, out=out)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7614,
        "label": "no",
        "change": [
            "def one_hot(indices, depth: int, device: Optional[str] = None):",
            ")",
            "",
            "",
            "-def shape(",
            "-    x: torch.Tensor, as_tensor: bool = False",
            "-) -> Union[torch.Tensor, List[int]]:",
            "+def shape(x: torch.Tensor, as_tensor: bool = False) -> Union[torch.Tensor, List[int]]:",
            "if as_tensor:",
            "return torch.tensor(x.shape)",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7616,
        "label": "no",
        "change": [
            "class TFSequenceSummary(tf.keras.layers.Layer):",
            ")  # A tensor full of shape [batch] or [batch, num choices] full of sequence length",
            "cls_shape = shape_list(cls_index)",
            "if len(cls_shape) <= len(hidden_shape) - 2:",
            "-                cls_index = cls_index[..., tf.newaxis]",
            "+                cls_index = tf.expand_dims(cls_index, axis=-1)",
            "# else:",
            "# cls_index = cls_index[..., tf.newaxis]",
            "# cls_index = cls_index.expand((-1,) * (cls_index.dim()-1) + (hidden_states.size(-1),))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7617,
        "label": "no",
        "change": [
            "class Encoder(nn.Module):",
            "# set duration predictor input",
            "if g is not None:",
            "g_exp = g.expand(-1, -1, x.size(-1))",
            "-            x_dp = torch.cat([torch.detach(x), g_exp], 1)",
            "+            x_dp = torch.cat([x.detach(), g_exp], 1)",
            "else:",
            "-            x_dp = torch.detach(x)",
            "+            x_dp = x.detach()",
            "# final projection layer",
            "x_m = self.proj_m(x) * x_mask",
            "if not self.mean_only:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7618,
        "label": "no",
        "change": [
            "class NaturalGradient(Optimizer):",
            "deltas = self.solver.solve(fn_x=fisher_matrix_product, x_init=None, b=[-grad for grad in loss_gradients], f_args=(kldiv_gradients,))",
            "",
            "# delta' * F",
            "-        delta_fisher_matrix_product = fisher_matrix_product(x=deltas)",
            "+        delta_fisher_matrix_product = fisher_matrix_product(deltas=deltas, kldiv_grads=kldiv_gradients)",
            "",
            "# c' = 0.5 * delta' * F * delta'  (= lambda * c)",
            "# TODO: Why constant and hence KL-divergence sometimes negative?"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7619,
        "label": "yes",
        "change": [
            "class Trainer(",
            ")",
            "return {}",
            "",
            "-            ckpt = torch.load(ckpt_path, map_location=lambda storage, loc: storage)",
            "+            ckpt = pl_load(ckpt_path, map_location=lambda storage, loc: storage)",
            "model.load_state_dict(ckpt['state_dict'])",
            "",
            "# attach dataloaders"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 7621,
        "label": "yes",
        "change": [
            "def from_networkx(G):",
            "",
            "G = nx.convert_node_labels_to_integers(G)",
            "G = G.to_directed() if not nx.is_directed(G) else G",
            "-    edge_index = torch.tensor(list(G.edges)).t().contiguous()",
            "+    edge_index = torch.LongTensor(list(G.edges)).t().contiguous()",
            "",
            "data = {}"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 7625,
        "label": "no",
        "change": [
            "def _map_fn_train(img, target):",
            "",
            "def _map_fn_test(img, target):",
            "# 1. Crop the central [height, width] of the image.",
            "-    img = tf.image.resize_with_pad(img, 24, 24)",
            "+    img = tf.image.resize_with_pad(img, 24, 24)",
            "# 2. Subtract off the mean and divide by the variance of the pixels.",
            "img = tf.image.per_image_standardization(img)",
            "img = tf.reshape(img, (24, 24, 3))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7627,
        "label": "no",
        "change": [
            "def input_processing(func, config, input_ids, **kwargs):",
            "signature.pop(\"kwargs\", None)",
            "parameter_names = list(signature.keys())",
            "output = {}",
            "-    allowed_types = (tf.Tensor, bool, int, ModelOutput, tuple, list, dict)",
            "+    allowed_types = (tf.Tensor, bool, int, ModelOutput, tuple, list, dict, np.ndarray)",
            "",
            "if \"inputs\" in kwargs[\"kwargs_call\"]:",
            "warnings.warn("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7630,
        "label": "no",
        "change": [
            "class Model(GANModelDesc):",
            "GaussianDistribution(\"uni_a\", 1),",
            "GaussianDistribution(\"uni_b\", 1)])",
            "# prior: the assumption how the factors are presented in the dataset",
            "-        prior = tf.constant([0.1] * 10 + [0,0], tf.float32, [12], name='prior')",
            "+        prior = tf.constant([0.1] * 10 + [0, 0], tf.float32, [12], name='prior')",
            "batch_prior = tf.tile(tf.expand_dims(prior, 0), [BATCH, 1], name='batch_prior')",
            "",
            "# sample the latent code zc:",
            "sample = self.factors.dists[0].sample(",
            "-            BATCH, tf.constant([0.1]*10, tf.float32, shape=[10]))",
            "+            BATCH, tf.constant([0.1] * 10, tf.float32, shape=[10]))",
            "z_cat = symbf.remove_shape(sample, 0, name='z_cat')",
            "# still sample the latent code from a uniform distribution.",
            "z_uni_a = symbf.remove_shape("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7631,
        "label": "no",
        "change": [
            "def closest_valid_dtype(type):",
            "",
            "",
            "def iinfo(type):",
            "-    return tf.experimental.numpy.iinfo(dtype_from_str(type))",
            "+    return tf.experimental.numpy.iinfo(dtype_to_str(type))",
            "",
            "",
            "class Finfo:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7632,
        "label": "no",
        "change": [
            "def huber_loss(x, delta=1.0):",
            "\"\"\"Reference: https://en.wikipedia.org/wiki/Huber_loss\"\"\"",
            "return tf.where(",
            "tf.abs(x) < delta,",
            "-        tf.square(x) * 0.5, delta * (tf.abs(x) - 0.5 * delta))",
            "+        tf.math.square(x) * 0.5, delta * (tf.abs(x) - 0.5 * delta))",
            "",
            "",
            "def reduce_mean_ignore_inf(x, axis):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7635,
        "label": "no",
        "change": [
            "class HfArgumentParserTest(unittest.TestCase):",
            "logger = logging.logging.getLogger()",
            "with CaptureLogger(logger) as cl:",
            "# this action activates the env var",
            "-            logging.get_logger(\"transformers.tokenization_bart\")",
            "+            logging.get_logger(\"transformers.models.bart.tokenization_bart\")",
            "self.assertIn(\"Unknown option TRANSFORMERS_VERBOSITY=super-error\", cl.out)",
            "",
            "# no need to restore as nothing was changed"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7639,
        "label": "no",
        "change": [
            "class BarkScale:",
            "def convert(f):",
            "\"\"\"Convert Hz to Bark.\"\"\"",
            "b = torch.div(f, 1000.0)",
            "-        b = torch.square(b) * 1.4",
            "+        b = torch.pow(b, 2.0) * 1.4",
            "b = torch.pow(b + 1.0, 0.69)",
            "return b * 75.0 + 25.0"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7640,
        "label": "no",
        "change": [
            "def finish_episode():",
            "for r in policy.rewards[::-1]:",
            "R = r + args.gamma * R",
            "rewards.insert(0, R)",
            "-    rewards = torch.Tensor(rewards)",
            "-    rewards = (rewards - rewards.mean()) / (rewards.std() + np.finfo(np.float32).eps)",
            "+    rewards = torch.tensor(rewards)",
            "+    rewards = (rewards - rewards.mean()) / (rewards.std() + eps)",
            "for log_prob, reward in zip(policy.saved_log_probs, rewards):",
            "policy_loss.append(-log_prob * reward)",
            "optimizer.zero_grad()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7643,
        "label": "yes",
        "change": [
            "class AttentionDecoder(RNNDecoder):",
            "logits=self.vocab_size,",
            "predicted_ids=tf.TensorShape([]),",
            "cell_output=self.cell.output_size,",
            "-        attention_scores=tf.concat([0, self.attention_values[1:-1]], 0),",
            "+        attention_scores=tf.concat(",
            "+            [[0], tf.shape(self.attention_values)[1:-1]], 0),",
            "attention_context=self.attention_values.get_shape()[-1])",
            "",
            "@property"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 7647,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)",
            "cost = tf.reduce_mean(cost, name='cross_entropy_loss')",
            "",
            "-        correct = tf.to_float(tf.nn.in_top_k(logits, label, 1), name='correct')",
            "+        correct = tf.cast(tf.nn.in_top_k(logits, label, 1), tf.float32, name='correct')",
            "# monitor training error",
            "add_moving_summary(tf.reduce_mean(correct, name='accuracy'))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7648,
        "label": "no",
        "change": [
            "class TestTorchHook(TestCase):",
            "'torch.CharTensor': torch.CharTensor,",
            "'torch.ShortTensor': torch.ShortTensor,",
            "'torch.IntTensor': torch.IntTensor,",
            "-            'torch.LongTensor': torch.LongTensor",
            "+            'torch.LongTensor': torch.LongTensor,",
            "}",
            "",
            "for k, v in tensor_types.items():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7650,
        "label": "no",
        "change": [
            "def sample_fast_rcnn_targets(boxes, gt_boxes, gt_labels):",
            "ret_labels = tf.concat(",
            "[tf.gather(gt_labels, fg_inds_wrt_gt),",
            "tf.zeros_like(bg_inds, dtype=tf.int64)], axis=0, name='sampled_labels')",
            "-    return ret_boxes, tf.stop_gradient(ret_labels), fg_inds_wrt_gt",
            "+    return tf.stop_gradient(ret_boxes), tf.stop_gradient(ret_labels), fg_inds_wrt_gt",
            "",
            "",
            "@under_name_scope()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7651,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)",
            "cost = tf.reduce_mean(cost, name='cross_entropy_loss')",
            "",
            "-        wrong = tf.to_float(tf.logical_not(tf.nn.in_top_k(logits, label, 1)), name='wrong_vector')",
            "+        wrong = tf.cast(tf.logical_not(tf.nn.in_top_k(logits, label, 1)), tf.float32, name='wrong_vector')",
            "# monitor training error",
            "add_moving_summary(tf.reduce_mean(wrong, name='train_error'))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7653,
        "label": "no",
        "change": [
            "class DistributedGroupSampler(Sampler):",
            "",
            "indices = [",
            "indices[j] for i in list(",
            "-                torch.randperm(",
            "-                    len(indices) // self.samples_per_gpu, generator=g))",
            "+                torch.randperm(len(indices) // self.samples_per_gpu,",
            "+                               generator=g))",
            "for j in range(i * self.samples_per_gpu, (i + 1) *",
            "self.samples_per_gpu)",
            "]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7654,
        "label": "no",
        "change": [
            "class BiMpmMatching(nn.Module, FromParams):",
            "len_1 = get_lengths_from_binary_sequence_mask(mask_1)",
            "len_2 = get_lengths_from_binary_sequence_mask(mask_2)",
            "",
            "-        # (batch, seq_len*)",
            "-        mask_1, mask_2 = mask_1.float(), mask_2.float()",
            "-",
            "# explicitly set masked weights to zero",
            "# (batch_size, seq_len*, hidden_dim)",
            "context_1 = context_1 * mask_1.unsqueeze(-1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7658,
        "label": "yes",
        "change": [
            "def convert_points_from_homogeneous(points: torch.Tensor,",
            "",
            "# we check for points at infinity",
            "z_vec: torch.Tensor = points[..., -1:]",
            "-    scale: torch.Tensor = 1. / torch.clamp(z_vec, eps)",
            "+    scale: torch.Tensor = torch.tensor(1.) / torch.clamp(z_vec, eps)",
            "",
            "return scale * points[..., :-1]"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 7665,
        "label": "no",
        "change": [
            "class BaseWorker(AbstractWorker):",
            "",
            "# storage object for crypto primitives",
            "self.crypto_store = PrimitiveStorage(owner=self)",
            "-        # declare the plans used for crypto computations",
            "-        sy.frameworks.torch.mpc.fss.initialize_crypto_plans(self)",
            "",
            "def register_obj(self, obj):",
            "self.object_store.register_obj(self, obj)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7666,
        "label": "no",
        "change": [
            "class ExportTest(tf.test.TestCase):",
            "",
            "if __name__ == \"__main__\":",
            "# This test is only supported in TF 2.0.",
            "-  if LooseVersion(tf.__version__) >= LooseVersion(\"2.0.0-beta0\"):",
            "+  if tf.executing_eagerly():",
            "logging.info(\"Using TF version: %s\", tf.__version__)",
            "tf.test.main()",
            "else:",
            "logging.warning(\"Skipping running tests for TF Version: %s\", tf.__version__)",
            "-"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7671,
        "label": "no",
        "change": [
            "class MultiLayeredConv1d(torch.nn.Module):",
            "",
            "\"\"\"",
            "x = torch.relu(self.w_1(x.transpose(-1, 1))).transpose(-1, 1)",
            "-        return self.w_2(self.dropout(x).transpose(-1, 1)).transpose(-1, 1)",
            "+        x = torch.relu(self.w_2(x.transpose(-1, 1))).transpose(-1, 1)",
            "+        return self.dropout(x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7672,
        "label": "no",
        "change": [
            "class TFTacotron2(tf.keras.Model):",
            "training=True,",
            ")",
            "",
            "-    @tf.function(experimental_relax_shapes=True)",
            "def call(",
            "self,",
            "input_ids,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7673,
        "label": "no",
        "change": [
            "def diff(",
            "x = x if type(x) == torch.Tensor else torch.Tensor(x)",
            "prepend = (",
            "prepend",
            "-        if type(prepend) == torch.Tensor or prepend == None",
            "+        if type(prepend) == torch.Tensor or prepend is None",
            "else torch.Tensor(prepend)",
            ")",
            "append = (",
            "append",
            "-        if type(append) == torch.Tensor or append == None",
            "+        if type(append) == torch.Tensor or append is None",
            "else torch.Tensor(append)",
            ")",
            "return torch.diff(x, n=n, dim=axis, prepend=prepend, append=append)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7676,
        "label": "no",
        "change": [
            "def argmax(",
            "keepdims: bool = False,",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "-    ret = tf.constant(x).numpy().argmax(axis=axis, keepdims=keepdims)",
            "-    ret = tf.convert_to_tensor(ret, dtype=ret.dtype)",
            "-",
            "-    return ret",
            "+    ret = x.numpy().argmax(axis=axis, keepdims=keepdims)",
            "+    return tf.convert_to_tensor(ret, dtype=ret.dtype)",
            "",
            "",
            "def argmin("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7684,
        "label": "no",
        "change": [
            "class SOSNet(nn.Module):",
            "",
            "return",
            "",
            "-    def forward(self, input: torch.Tensor, eps: float = 1e-10) -> torch.Tensor:   # type: ignore",
            "+    def forward(self, input: torch.Tensor, eps: float = 1e-10) -> torch.Tensor:",
            "descr = self.desc_norm(self.layers(input) + eps)",
            "descr = descr.view(descr.size(0), -1)",
            "return descr"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7691,
        "label": "no",
        "change": [
            "class TestCnnEncoder(AllenNlpTestCase):",
            "",
            "def test_forward_does_correct_computation(self):",
            "encoder = CnnEncoder(embedding_dim=2, num_filters=1, ngram_filter_sizes=(1, 2))",
            "-        const_init = lambda tensor: torch.nn.init.constant(tensor, 1.)",
            "-        initializer = InitializerApplicator(default_initializer=const_init)",
            "+        constant_init = lambda tensor: torch.nn.init.constant(tensor, 1.)",
            "+        initializer = InitializerApplicator(default_initializer=constant_init)",
            "initializer(encoder)",
            "input_tensor = Variable(torch.FloatTensor([[[.7, .8], [.1, 1.5]]]))",
            "encoder_output = encoder(input_tensor)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7695,
        "label": "no",
        "change": [
            "def gaussian(window_size: int, sigma: float) -> torch.Tensor:",
            "x = torch.arange(window_size, device=device, dtype=dtype) - window_size // 2",
            "if window_size % 2 == 0:",
            "x = x + 0.5",
            "-    gauss = torch.exp(-x.pow(2.0) / (2 * sigma**2))",
            "+    gauss = torch.exp(-(x**2.0) / (2 * sigma**2))",
            "return gauss / gauss.sum()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7697,
        "label": "no",
        "change": [
            "from .modeling_tf_utils import TFPreTrainedModel, get_initializer, shape_list",
            "logger = logging.getLogger(__name__)",
            "",
            "TF_ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP = {",
            "-    \"roberta-base\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-tf_model.h5\",",
            "-    \"roberta-large\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-tf_model.h5\",",
            "-    \"roberta-large-mnli\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-tf_model.h5\",",
            "-    \"distilroberta-base\": \"https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-tf_model.h5\",",
            "+    \"roberta-base\": \"https://cdn.huggingface.co/roberta-base-tf_model.h5\",",
            "+    \"roberta-large\": \"https://cdn.huggingface.co/roberta-large-tf_model.h5\",",
            "+    \"roberta-large-mnli\": \"https://cdn.huggingface.co/roberta-large-mnli-tf_model.h5\",",
            "+    \"distilroberta-base\": \"https://cdn.huggingface.co/distilroberta-base-tf_model.h5\",",
            "}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7698,
        "label": "no",
        "change": [
            "class TinyConvNet:",
            "def train(model, optim, steps, BS=128, gpu=False):",
            "losses, accuracies = [], []",
            "for i in (t := trange(steps, disable=os.getenv('CI') is not None)):",
            "+    optim.zero_grad()",
            "samp = np.random.randint(0, X_train.shape[0], size=(BS))",
            "",
            "x = Tensor(X_train[samp].reshape((-1, 28*28)).astype(np.float32), gpu=gpu)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7700,
        "label": "no",
        "change": [
            "class LSTMEncoder(FairseqEncoder):",
            "packed_outs, (final_hiddens, final_cells) = self.lstm(packed_x, (h0, c0))",
            "",
            "# unpack outputs and apply dropout",
            "-        x, _ = nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=self.padding_value)",
            "+        x, _ = nn.utils.rnn.pad_packed_sequence(packed_outs, padding_value=self.padding_idx)",
            "x = F.dropout(x, p=self.dropout_out, training=self.training)",
            "assert list(x.size()) == [seqlen, bsz, self.output_units]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7702,
        "label": "no",
        "change": [
            "class CascadeRCNN(BaseDetector, RPNTestMixin):",
            "device=device,",
            "dtype=torch.uint8))",
            "pos_inds = torch.cat(pos_inds)",
            "-                    mask_feats = bbox_feats[pos_inds]",
            "+                    mask_feats = bbox_feats[pos_inds.type(torch.bool)]",
            "mask_head = self.mask_head[i]",
            "mask_pred = mask_head(mask_feats)",
            "mask_targets = mask_head.get_target(sampling_results, gt_masks,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7704,
        "label": "no",
        "change": [
            "if os.path.exists(os.path.join(PATH, 'graph.pbtxt')):",
            "translator = skflow.TensorFlowEstimator.restore(PATH)",
            "else:",
            "translator = skflow.TensorFlowEstimator(model_fn=translate_model,",
            "-        n_classes=n_words,",
            "+        n_classes=n_fr_words,",
            "optimizer='Adam', learning_rate=0.01, batch_size=128,",
            "continue_training=True, steps=100)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7705,
        "label": "no",
        "change": [
            "class ParameterNoise(Exploration):",
            "added_noises.append(",
            "tf.assign(",
            "noise,",
            "-                    tf.random_normal(",
            "+                    tf.random.normal(",
            "shape=noise.shape,",
            "stddev=self.stddev,",
            "dtype=tf.float32)))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7712,
        "label": "no",
        "change": [
            "def vander(",
            "increasing: Optional[bool] = False,",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "-    return tf.experimental.numpy.vander(",
            "-        x, N=N, increasing=increasing",
            "-    )",
            "+    return tf.experimental.numpy.vander(x, N=N, increasing=increasing)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7714,
        "label": "no",
        "change": [
            "class LogMel(torch.nn.Module):",
            "return \", \".join(f\"{k}={v}\" for k, v in self.mel_options.items())",
            "",
            "def forward(",
            "-        self,",
            "-        feat: torch.Tensor,",
            "-        ilens: torch.Tensor = None,",
            "+        self, feat: torch.Tensor, ilens: torch.Tensor = None",
            ") -> Tuple[torch.Tensor, torch.Tensor]:",
            "# feat: (B, T, D1) x melmat: (D1, D2) -> mel_feat: (B, T, D2)",
            "mel_feat = torch.matmul(feat, self.melmat)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7717,
        "label": "no",
        "change": [
            "class Categorical(Distribution):",
            "# \"Normalized\" logits",
            "logits = tf.log(x=probabilities)",
            "",
            "-        logits = tf.Print(logits, (logits, probabilities, state_value))",
            "-",
            "return logits, probabilities, state_value",
            "",
            "def state_value(self, distr_params):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7719,
        "label": "yes",
        "change": [
            "class MeanAbsoluteError(Metric):",
            "preds: Predictions from model",
            "target: Ground truth values",
            "\"\"\"",
            "-        self._check_same_shape(preds, target)",
            "-        abs_error = torch.abs(preds - target)",
            "+        sum_abs_error, n_obs = _mean_absolute_error_update(preds, target)",
            "",
            "-        self.sum_abs_error += torch.sum(abs_error)",
            "-        self.total += target.numel()",
            "+        self.sum_abs_error += sum_abs_error",
            "+        self.total += n_obs",
            "",
            "def compute(self):",
            "\"\"\"",
            "Computes mean absolute error over state.",
            "\"\"\"",
            "-        return self.sum_abs_error / self.total",
            "+        return _mean_absolute_error_compute(self.sum_abs_error, self.total)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 7720,
        "label": "no",
        "change": [
            "def init_training_mode():",
            "# 'is_training' collection stores the training mode variable",
            "coll = tf.get_collection('is_training')",
            "if len(coll) == 0:",
            "-        tr_var = tf.get_variable(",
            "+        tr_var = variable(",
            "\"is_training\", dtype=tf.bool, shape=[],",
            "initializer=tf.constant_initializer(False),",
            "trainable=False)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7723,
        "label": "yes",
        "change": [
            "class RandomSampler(BaseSampler):",
            "else:",
            "device = 'cpu'",
            "gallery = torch.tensor(gallery, dtype=torch.long, device=device)",
            "-        perm = torch.randperm(gallery.numel(), device=gallery.device)[:num]",
            "+        # This is a temporary fix. We can revert the following code",
            "+        # when PyTorch fixes the abnormal return of torch.randperm.",
            "+        # See: https://github.com/open-mmlab/mmdetection/pull/5014",
            "+        perm = torch.randperm(gallery.numel())[:num].to(device=gallery.device)",
            "rand_inds = gallery[perm]",
            "if not is_tensor:",
            "rand_inds = rand_inds.cpu().numpy()"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 7724,
        "label": "no",
        "change": [
            "class Data(BaseData, FeatureStore, GraphStore):",
            "node_ids, index_map = {}, torch.empty_like(node_type)",
            "for i, key in enumerate(node_type_names):",
            "node_ids[i] = (node_type == i).nonzero(as_tuple=False).view(-1)",
            "-            index_map[node_ids[i]] = torch.arange(len(node_ids[i]))",
            "+            index_map[node_ids[i]] = torch.arange(len(node_ids[i]),",
            "+                                                  device=index_map.device)",
            "",
            "# We iterate over edge types to find the local edge indices:",
            "edge_ids = {}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7738,
        "label": "no",
        "change": [
            "if __name__ == '__main__':",
            "# validation_dataset = make_dataset(X_val, y_val)",
            "trainer = tl.distributed.Trainer(",
            "build_training_func=build_train, training_dataset=training_dataset, optimizer=tf.train.AdamOptimizer,",
            "-        optimizer_args={'learning_rate': 0.001}, batch_size=500, num_epochs=500, prefetch_buffer_size=4096",
            "+        optimizer_args={'learning_rate': 0.001}, batch_size=500, prefetch_size=500",
            "# validation_dataset=validation_dataset, build_validation_func=build_validation",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7739,
        "label": "yes",
        "change": [
            "class Stft(torch.nn.Module, InversibleInterface):",
            "pad = self.n_fft // 2",
            "ilens = ilens + 2 * pad",
            "",
            "-            olens = torch.div((ilens - self.n_fft), self.hop_length) + 1",
            "+            olens = (",
            "+                torch.div((ilens - self.n_fft), self.hop_length, rounding_mode=\"floor\")",
            "+                + 1",
            "+            )",
            "output.masked_fill_(make_pad_mask(olens, output, 1), 0.0)",
            "else:",
            "olens = None"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 7743,
        "label": "no",
        "change": [
            "class Categorical(Distribution):",
            "# \"Normalized\" logits",
            "logits = tf.log(x=probabilities)",
            "",
            "-        # logits = tf.Print(logits, (logits, probabilities, state_value))",
            "+        logits = tf.Print(logits, (logits, probabilities, state_value))",
            "",
            "return logits, probabilities, state_value"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7744,
        "label": "no",
        "change": [
            "class MessagePassing(torch.nn.Module):",
            "edge_mask = self._edge_mask",
            "",
            "if edge_mask is None:",
            "-            raise ValueError(f\"Could not found a pre-defined 'edge_mask' as \"",
            "-                             f\"part of {self.__class__.__name__}\")",
            "+            raise ValueError(f\"Could not find a pre-defined 'edge_mask' as \"",
            "+                             f\"part of {self.__class__.__name__}.\")",
            "",
            "if self._apply_sigmoid:",
            "edge_mask = edge_mask.sigmoid()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7751,
        "label": "no",
        "change": [
            "torch_fxn_for_op: Dict[Op, Callable] = {**base_fxn_for_op, **{",
            "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else (\"mps\" if getenv(\"MPS\", 0) else \"cpu\"))",
            "class TorchBuffer(InterpretedBuffer):",
            "fxn_for_op: ClassVar = torch_fxn_for_op",
            "-  to_tinygrad_dtype = staticmethod(lambda lbuf: {torch.float16: dtypes.float16, torch.float32: dtypes.float32}[lbuf.dtype])",
            "+  def to_tinygrad_dtype(self): return {torch.float16: dtypes.float16, torch.float32: dtypes.float32}[self._buf.dtype]",
            "",
            "@staticmethod",
            "def fromCPU(x): return TorchBuffer(torch.from_numpy(x).requires_grad_(False).to(device))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7754,
        "label": "no",
        "change": [
            "def _can_import_egl_and_pycuda():",
            "try:",
            "import pycuda.gl",
            "except (ImportError, ImportError, ModuleNotFoundError):",
            "-        warnings.warn(\"Can't import pucuda.gl, not importing MeshRasterizerOpenGL.\")",
            "+        warnings.warn(\"Can't import pycuda.gl, not importing MeshRasterizerOpenGL.\")",
            "return False",
            "",
            "return True"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7757,
        "label": "no",
        "change": [
            "class RandomErasingTorch:",
            "left = random.randint(0, img_w - w)",
            "if self.per_pixel:",
            "img[:, top:top + h, left:left + w] = torch.empty(",
            "-                            (chan, h, w), dtype=batch.dtype).cuda().normal_()",
            "+                            (chan, h, w), dtype=batch.dtype).normal_().cuda()",
            "else:",
            "img[:, top:top + h, left:left + w] = c",
            "break"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7767,
        "label": "no",
        "change": [
            "class TensorFlowEstimator(BaseEstimator):",
            "self._summaries = self._graph.get_operation_by_name('MergeSummary/MergeSummary')",
            "",
            "# Restore session.",
            "-            self._session = tf.Session(self.tf_master, config=ConfigAddon(verbose=self.verbose).config)",
            "+            self._session = tf.Session(",
            "+                self.tf_master,",
            "+                config=ConfigAddon(verbose=self.verbose).config)",
            "checkpoint_path = tf.train.latest_checkpoint(path)",
            "if checkpoint_path is None:",
            "raise ValueError(\"Missing checkpoint files in the %s. Please \""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7774,
        "label": "no",
        "change": [
            "def all_reduce_dict(data: Mapping[str, Any], device, group) -> Dict[str, Any]:",
            "return data",
            "buf = torch.cat([t.view(-1) for t in data.values()]).to(device=device)",
            "all_reduce(buf, group=group)",
            "-        split_buf = torch.split(buf, [t.numel() for t in data.values()])",
            "+        split_buf = torch.split(buf.clone(), [t.numel() for t in data.values()])",
            "reduced_data = [t.view_as(orig) for t, orig in zip(split_buf, data.values())]",
            "return OrderedDict(zip(data.keys(), reduced_data))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7776,
        "label": "no",
        "change": [
            "def generate_audio(feature):",
            "os.makedirs(destination_folder)",
            "",
            "audio_dest_path = os.path.join(destination_folder, audio_filename)",
            "-        soundfile.write(audio_dest_path, audio, sampling_rate)",
            "+        torchaudio.save(audio_dest_path, audio_tensor, sampling_rate)",
            "",
            "except OSError as e:",
            "raise OSError(\"Unable to create a folder for audio or save audio to disk.\" \"{}\".format(e))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7777,
        "label": "no",
        "change": [
            "class F1Measure(Metric):",
            "raise ConfigurationError(\"A gold label passed to F1Measure contains an id >= {}, \"",
            "\"the number of classes.\".format(num_classes))",
            "if mask is None:",
            "-            mask = torch.ones(gold_labels.size())",
            "+            mask = ones_like(gold_labels)",
            "mask = mask.float()",
            "gold_labels = gold_labels.float()",
            "positive_label_mask = gold_labels.eq(self._positive_label).float()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7778,
        "label": "no",
        "change": [
            "class ScalarMix(torch.nn.Module):",
            "in range(mixture_size)])",
            "self.gamma = Parameter(torch.FloatTensor([1.0]), requires_grad=trainable)",
            "",
            "-    def forward(self, tensors: List[torch.Tensor],  # pylint: disable=arguments-differ",
            "+    def forward(self, tensors: List[torch.Tensor],",
            "mask: torch.Tensor = None) -> torch.Tensor:",
            "\"\"\"",
            "Compute a weighted average of the ``tensors``.  The input tensors an be any shape"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7781,
        "label": "yes",
        "change": [
            "class ImageInputFeature(ImageFeatureMixin, InputFeature):",
            ")",
            "",
            "def forward(self, inputs: torch.Tensor) -> torch.Tensor:",
            "-        assert isinstance(inputs, torch.Tensor)",
            "-        assert inputs.dtype in [torch.float32]",
            "+        assert isinstance(inputs, torch.Tensor), f\"inputs to image feature must be a torch tensor, got {type(inputs)}\"",
            "+        assert inputs.dtype in [torch.float32], f\"inputs to image feature must be a float32 tensor, got {inputs.dtype}\"",
            "",
            "inputs_encoded = self.encoder_obj(inputs)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 7784,
        "label": "no",
        "change": [
            "\"  sts_encode2 = tf.nn.l2_normalize(embed(tf.constant(batch['sent_2'].tolist())), axis=1)\\n\",",
            "\"  cosine_similarities = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)\\n\",",
            "\"  clip_cosine_similarities = tf.clip_by_value(cosine_similarities, -1.0, 1.0)\\n\",",
            "-        \"  scores = 1.0 - tf.acos(clip_cosine_similarities)\\n\",",
            "+        \"  scores = 1.0 - tf.acos(clip_cosine_similarities) / math.pi\\n\",",
            "\"  \\\"\\\"\\\"Returns the similarity scores\\\"\\\"\\\"\\n\",",
            "\"  return scores\\n\",",
            "\"\\n\","
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7789,
        "label": "yes",
        "change": [
            "def test_hetero_to_undirected():",
            "data['v', 'w'].edge_weight = edge_weight",
            "data['v', 'w'].edge_attr = edge_attr",
            "",
            "+    from torch_geometric.transforms import ToUndirected",
            "data = ToUndirected()(data)",
            "-    assert data['v', 'v'].edge_index.tolist() == [[0, 0, 1, 2, 2, 3],",
            "-                                                  [1, 2, 0, 0, 3, 2]]",
            "+    assert data['v', 'v'].edge_index.tolist() == [[0, 1, 2, 3], [1, 0, 3, 2]]",
            "assert data['v', 'v'].edge_weight.tolist() == edge_weight[perm].tolist()",
            "assert data['v', 'v'].edge_attr.tolist() == edge_attr[perm].tolist()",
            "assert data['v', 'w'].edge_index.tolist() == edge_index.tolist()",
            "assert data['v', 'w'].edge_weight.tolist() == edge_weight.tolist()",
            "assert data['v', 'w'].edge_attr.tolist() == edge_attr.tolist()",
            "-    assert data['w', 'v'].edge_index.tolist() == [[3, 1, 0], [2, 0, 2]]",
            "+    assert data['w', 'v'].edge_index.tolist() == [[3, 1], [2, 0]]",
            "assert data['w', 'v'].edge_weight.tolist() == edge_weight.tolist()",
            "assert data['w', 'v'].edge_attr.tolist() == edge_attr.tolist()"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 7791,
        "label": "no",
        "change": [
            "def joint_pdf(kernel_values1: torch.Tensor, kernel_values2: torch.Tensor, epsilo",
            "\"\"\"",
            "",
            "if not isinstance(kernel_values1, torch.Tensor):",
            "-        raise TypeError(\"Input kernel_values1 type is not a torch.Tensor. Got {}\".format(type(kernel_values1)))",
            "+        raise TypeError(f\"Input kernel_values1 type is not a torch.Tensor. Got {type(kernel_values1)}\")",
            "",
            "if not isinstance(kernel_values2, torch.Tensor):",
            "-        raise TypeError(\"Input kernel_values2 type is not a torch.Tensor. Got {}\".format(type(kernel_values2)))",
            "+        raise TypeError(f\"Input kernel_values2 type is not a torch.Tensor. Got {type(kernel_values2)}\")",
            "",
            "if not kernel_values1.dim() == 3:",
            "raise ValueError(\"Input kernel_values1 must be a of the shape BxN.\" \" Got {}\".format(kernel_values1.shape))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7794,
        "label": "no",
        "change": [
            "class CategoryInputFeature(CategoryFeatureMixin, InputFeature):",
            "inputs = inputs.unsqueeze(dim=1)",
            "",
            "if inputs.dtype == torch.int8 or inputs.dtype == torch.int16:",
            "-            inputs = inputs.type(torch.IntTensor)",
            "+            inputs = inputs.type(torch.int)",
            "encoder_output = self.encoder_obj(inputs)",
            "",
            "return {\"encoder_output\": encoder_output}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7797,
        "label": "no",
        "change": [
            "def generate_rpn_proposals(boxes, scores, img_shape):",
            "topk_valid_boxes,",
            "nms_indices, name='boxes')",
            "final_scores = tf.gather(topk_valid_scores, nms_indices, name='scores')",
            "+    tf.sigmoid(final_scores, name='probs')  # for visualization",
            "return final_boxes, final_scores"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7799,
        "label": "no",
        "change": [
            "class L2FilterPruner(WeightRankFilterPruner):",
            "w_l2_norm = torch.sqrt((w ** 2).sum(dim=1))",
            "threshold = torch.topk(w_l2_norm.view(-1), num_prune, largest=False)[0].max()",
            "mask_weight = torch.gt(w_l2_norm, threshold)[:, None, None, None].expand_as(weight).type_as(weight)",
            "-        mask_bias = torch.gt(w_l2_norm, threshold).type_as(weight)",
            "+        mask_bias = torch.gt(w_l2_norm, threshold).type_as(weight).detach() if base_mask['bias_mask'] is not None else None",
            "",
            "-        return {'weight_mask': mask_weight.detach(), 'bias_mask': mask_bias.detach()}",
            "+        return {'weight_mask': mask_weight.detach(), 'bias_mask': mask_bias}",
            "",
            "",
            "class FPGMPruner(WeightRankFilterPruner):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7800,
        "label": "no",
        "change": [
            "def drop_connect(inputs, p, training):",
            "batch_size = inputs.shape[0]",
            "keep_prob = 1 - p",
            "random_tensor = keep_prob",
            "-    random_tensor += torch.rand([batch_size, 1, 1, 1], dtype=inputs.dtype)  # uniform [0,1)",
            "+    random_tensor += torch.rand([batch_size, 1, 1, 1], dtype=inputs.dtype, device=inputs.device)",
            "binary_tensor = torch.floor(random_tensor)",
            "output = inputs / keep_prob * binary_tensor",
            "return output"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7808,
        "label": "no",
        "change": [
            "def slim_block(x):",
            "x = slim.dropout(x, 0.5, is_training=is_training)",
            "x = slim.fully_connected(x, 800, activation_fn=tf.nn.relu)",
            "x = slim.dropout(x, 0.5, is_training=is_training)",
            "-        logits = slim.fully_connected(x, 10, activation_fn=tf.identity)",
            "+        logits = slim.fully_connected(x, 10, activation_fn=None)",
            "return logits, {}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7809,
        "label": "yes",
        "change": [
            "if __name__ == '__main__':",
            "",
            "# Load pytorch model",
            "google_utils.attempt_download(opt.weights)",
            "-    model = torch.load(opt.weights, map_location=torch.device('cpu'))['model']",
            "+    model = torch.load(opt.weights, map_location=torch.device('cpu'))['model'].float()",
            "model.eval()",
            "model.fuse()"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 7814,
        "label": "no",
        "change": [
            "try:",
            "class FusedLayerNorm(_FusedLayerNorm):",
            "@torch.jit.unused",
            "def forward(self, x):",
            "-            return super().forward(x)",
            "+            with torch.cuda.device(x.device):",
            "+                return super().forward(x)",
            "",
            "except ImportError:",
            "has_fused_layernorm = False"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7815,
        "label": "no",
        "change": [
            "class TestSerde(object):",
            "",
            "@pytest.mark.parametrize(\"compress\", [True, False])",
            "def test_torch_Tensor_convenience(self, compress):",
            "+        \"\"\"This test evaluates torch.Tensor.serialize()",
            "+",
            "+        As opposed to using syft.serde.serialize(), torch objects",
            "+        have a convenience function which lets you call .serialize()",
            "+        directly on the tensor itself. This tests to makes sure it",
            "+        works correctly.\"\"\"",
            "+",
            "hook = TorchHook(torch)",
            "",
            "t = Tensor(numpy.random.random((100, 100)))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7821,
        "label": "yes",
        "change": [
            "def test_forward(use_token_averaged_energy):",
            ")",
            "xs = torch.randn(2, 256)",
            "if not use_token_averaged_energy:",
            "-        layer(xs, torch.LongTensor([256, 128]))",
            "+        es, elens = layer(xs, torch.LongTensor([256, 128]))",
            "+        assert es.shape[1] == max(elens)",
            "else:",
            "ds = torch.LongTensor([[3, 0, 2], [3, 0, 0]])",
            "dlens = torch.LongTensor([3, 1])"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 7823,
        "label": "no",
        "change": [
            "class EndpointSpanExtractor(SpanExtractor):",
            "span_widths = span_ends - span_starts",
            "",
            "span_width_embeddings = self._span_width_embedding(span_widths)",
            "-            return torch.cat([combined_tensors, span_width_embeddings], -1)",
            "+            combined_tensors = torch.cat([combined_tensors, span_width_embeddings], -1)",
            "",
            "if span_indices_mask is not None:",
            "return combined_tensors * span_indices_mask.unsqueeze(-1).float()",
            "+",
            "return combined_tensors"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7824,
        "label": "no",
        "change": [
            "def _segment_reduce(values, index, segment_reduce_fn, name):",
            "",
            "segment_means = scatter(",
            "src=flat_values,",
            "-        index=flat_index.indices.type(torch.long),",
            "+        index=flat_index.indices.long(),",
            "dim=0,",
            "-        dim_size=flat_index.num_segments,",
            "+        dim_size=int(flat_index.num_segments),",
            "reduce=segment_reduce_fn,",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7825,
        "label": "no",
        "change": [
            "class LinearTest(test_utils.TestCase, parameterized.TestCase):",
            "lin_b = linear.Linear(output_size_b, name='lin_b')",
            "input_a = tf.random.uniform([batch_size, input_size])",
            "input_b = tf.random.uniform([batch_size, input_size])",
            "-    with self.assertRaisesRegexp(tf.errors.InvalidArgumentError,",
            "-                                 'Incompatible shapes'):",
            "+    with self.assertRaisesIncompatibleShapesError(",
            "+        tf.errors.InvalidArgumentError):",
            "util.apply_linear((input_a, input_b), (lin_a, lin_b))",
            "",
            "@parameterized.parameters("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7831,
        "label": "no",
        "change": [
            "class PSNRLoss(nn.Module):",
            "- output: :math:`()` a scalar",
            "",
            "Examples:",
            "-        >>> kornia.losses.psnr_loss(torch.ones(1), 1.2*torch.ones(1), 2)",
            "-        tensor(20.0000) # 10 * log(4/((1.2-1)**2)) / log(10)",
            "+        >>> psnr_loss(torch.ones(1), 1.2*torch.ones(1), 2) # 10 * log(4/((1.2-1)**2)) / log(10)",
            "+        tensor(20.0000)",
            "",
            "Reference:",
            "https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio#Definition"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7834,
        "label": "no",
        "change": [
            "class Biosses(datasets.GeneratorBasedBuilder):",
            "df = pd.read_csv(filepath, sep=\"\\t\", encoding=\"utf-8\")",
            "for idx, row in df.iterrows():",
            "yield idx, {",
            "-                \"sentence 1\": row[\"sentence1\"],",
            "-                \"sentence 2\": row[\"sentence2\"],",
            "+                \"sentence1\": row[\"sentence1\"],",
            "+                \"sentence2\": row[\"sentence2\"],",
            "\"score\": row[\"score\"],",
            "}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7843,
        "label": "no",
        "change": [
            "class BartForConditionalGeneration(PretrainedBartModel):",
            "if new_num_tokens <= old_num_tokens:",
            "new_bias = self.final_logits_bias[:, :new_num_tokens]",
            "else:",
            "-            extra_bias = torch.zeros((1, new_num_tokens - old_num_tokens))",
            "+            extra_bias = torch.zeros((1, new_num_tokens - old_num_tokens), device=self.final_logits_bias.device)",
            "new_bias = torch.cat([self.final_logits_bias, extra_bias], dim=1)",
            "self.register_buffer(\"final_logits_bias\", new_bias)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7846,
        "label": "no",
        "change": [
            "if is_tf_available():",
            "",
            "return tf.data.Dataset.from_generator(",
            "gen,",
            "-            ({k: tf.int32 for k in input_names}, tf.int64),",
            "+            ({k: tf.int32 for k in input_names}, label_type),",
            "({k: tf.TensorShape([None]) for k in input_names}, tf.TensorShape([])),",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7863,
        "label": "no",
        "change": [
            "class RandomMixUp(MixAugmentationBase):",
            "return rg.random_mixup_generator(batch_shape[0], self.p, lambda_val, same_on_batch=self.same_on_batch)",
            "",
            "def apply_transform(  # type: ignore",
            "-        self, input: torch.Tensor, label: torch.Tensor, params: Dict[str, torch.Tensor]  # type: ignore",
            "+        self, input: torch.Tensor, label: torch.Tensor, params: Dict[str, torch.Tensor]",
            ") -> Tuple[torch.Tensor, torch.Tensor]:",
            "input_permute = input.index_select(dim=0, index=params['mixup_pairs'].to(input.device))",
            "labels_permute = label.index_select(dim=0, index=params['mixup_pairs'].to(label.device))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7866,
        "label": "yes",
        "change": [
            "from .degree import DegreeAdj",
            "",
            "class DegreeTest(TestCase):",
            "def test_degree_adj(self):",
            "+        index = torch.LongTensor([[0, 0, 1, 2], [1, 2, 0, 1]])",
            "weight = torch.FloatTensor([2, 3, 4, 6])",
            "-        edge = torch.LongTensor([[0, 0, 1, 2], [1, 2, 0, 1]])",
            "-        adj = torch.sparse.FloatTensor(edge, weight, torch.Size([3, 3]))",
            "+        adj = torch.sparse.FloatTensor(index, weight, torch.Size([3, 3]))",
            "",
            "transform = DegreeAdj()",
            "",
            "-        _, adj = transform((None, adj))",
            "+        _, adj, _ = transform((None, adj, None))",
            "adj = adj.to_dense()",
            "",
            "expected_adj_out = ["
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 7870,
        "label": "no",
        "change": [
            "class StackBidirectionalRNNEncoderTest(tf.test.TestCase):",
            "[self.batch_size, cell.output_size])",
            "",
            "def test_encode_with_multi_cell(self):",
            "-    cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.LSTMCell(32)] * 4)",
            "+    cell = tf.contrib.rnn.MultiRNNCell(",
            "+        [tf.contrib.rnn.LSTMCell(32) for _ in range(4)])",
            "encoder_output_ = self._test_encode_with_cell(cell)",
            "",
            "for layer_idx in range(4):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7871,
        "label": "no",
        "change": [
            "\"Conceptually `iarange` is the same as `irange` except that it is a vectorized operation (as `torch.arange` is to `range`). As such it potentially enables large speed-ups compared to the explicit `for` loop that appears with `irange`. Let's see how this looks for our running example. First we need `data` to be in the form of a tensor:\\n\",",
            "\"\\n\",",
            "\"```python\\n\",",
            "-    \"data = Variable(torch.zeros(10, 1))\\n\",",
            "+    \"data = torch.zeros(10, 1)\\n\",",
            "\"data[0:6, 0] = torch.ones(6)  # 6 heads and 4 tails\\n\",",
            "\"```\\n\",",
            "\"\\n\","
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7874,
        "label": "no",
        "change": [
            "from syft.core.common.serde.deserialize import _deserialize",
            "from syft.lib.python import ValuesIndices",
            "",
            "",
            "-def test_torch_valuesindices_serde():",
            "-    x = torch.Tensor([1, 2, 3])",
            "-    y = x.cummax(0)",
            "+def test_torch_valuesindices_serde() -> None:",
            "+    x = torch.Tensor([[1, 2], [1, 2]])",
            "+    y = x.mode()",
            "values = y.values",
            "indices = y.indices"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7875,
        "label": "no",
        "change": [
            "class _ProposalTargetLayer(nn.Module):",
            "num_proposal = overlaps.size(1)",
            "num_boxes_per_img = overlaps.size(2)",
            "",
            "-        offset = torch.arange(0, batch_size)*20",
            "+        offset = torch.arange(0, batch_size)*gt_boxes.size(1)",
            "offset = offset.view(-1, 1).type_as(gt_assignment) + gt_assignment",
            "",
            "labels = gt_boxes[:,:,4].contiguous().view(-1).index(offset.view(-1))\\"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7878,
        "label": "no",
        "change": [
            "def start_cluster_server(ctx, num_gpus=1, rdma=False):",
            "cluster_spec = ctx.cluster_spec",
            "logging.info(\"{0}: Cluster spec: {1}\".format(ctx.worker_num, cluster_spec))",
            "",
            "-  if tf.test.is_built_with_cuda() and num_gpus > 0:",
            "+  if compat.is_gpu_available() and num_gpus > 0:",
            "# compute my index relative to other nodes placed on the same host (for GPU allocation)",
            "my_addr = cluster_spec[ctx.job_name][ctx.task_index]",
            "my_host = my_addr.split(':')[0]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7881,
        "label": "no",
        "change": [
            "class Evolutionary(Optimizer):",
            "",
            "return deltas_sum, perturbations",
            "",
            "-            deltas_sum, perturbations = tf.while_loop(",
            "+            deltas_sum, perturbations = self.while_loop(",
            "cond=util.tf_always_true, body=body, loop_vars=(deltas_sum, perturbations),",
            "maximum_iterations=(self.num_samples - 1)",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7887,
        "label": "no",
        "change": [
            "class TestRandomCutMix:",
            "",
            "assert_allclose(out_image, expected, rtol=1e-4, atol=1e-4)",
            "assert (out_label[0, :, 0] == label).all()",
            "-        assert (out_label[0, :, 1] == torch.tensor([0, 1])).all()",
            "+        assert (out_label[0, :, 1] == torch.tensor([0, 1], device=device, dtype=dtype)).all()",
            "# cut area = 4 / 12",
            "-        assert_allclose(out_label[0, :, 2], torch.tensor([0.33333, 0.33333], dtype=dtype))",
            "+        assert_allclose(out_label[0, :, 2], torch.tensor([0.33333, 0.33333], device=device, dtype=dtype))",
            "",
            "def test_random_mixup_num2(self, device, dtype):",
            "torch.manual_seed(76)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7890,
        "label": "no",
        "change": [
            "from ivy.core.device import default_device",
            "",
            "",
            "def random_uniform(low=0., high=1., shape=None, dev=None):",
            "-    dev = default_device(dev)",
            "-    with _tf.device('/' + dev.upper()):",
            "+    with _tf.device(default_device(dev)):",
            "return _tf.random.uniform(shape if shape else (), low, high)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7898,
        "label": "no",
        "change": [
            "def train(args, logdir):",
            "# dataflow",
            "df = Net1DataFlow(hp.train1.data_path, hp.train1.batch_size)",
            "",
            "-    ckpt1 = tf.train.latest_checkpoint(logdir1)",
            "-",
            "# set logger for event and model saver",
            "logger.set_logger_dir(logdir)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7904,
        "label": "no",
        "change": [
            "def Vgg19_simple_api(rgb):",
            "net = FlattenLayer(net, name='flatten')",
            "net = DenseLayer(net, n_units=4096, act=tf.nn.relu, name='fc6')",
            "net = DenseLayer(net, n_units=4096, act=tf.nn.relu, name='fc7')",
            "-    net = DenseLayer(net, n_units=1000, act=tf.identity, name='fc8')",
            "+    net = DenseLayer(net, n_units=1000, act=None, name='fc8')",
            "print(\"build model finished: %fs\" % (time.time() - start_time))",
            "return net"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7909,
        "label": "no",
        "change": [
            "class LogMel(torch.nn.Module):",
            "return ', '.join(f'{k}={v}' for k, v in self.mel_options.items())",
            "",
            "def forward(",
            "-        self, feat: torch.Tensor, ilens: torch.Tensor=None,",
            "+        self, feat: torch.Tensor, ilens: torch.Tensor = None,",
            ") -> Tuple[torch.Tensor, torch.Tensor]:",
            "# feat: (B, T, D1) x melmat: (D1, D2) -> mel_feat: (B, T, D2)",
            "mel_feat = torch.matmul(feat, self.melmat)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7912,
        "label": "yes",
        "change": [
            "class Trainer:",
            "else:",
            "tr_loss_step = self.training_step(model, inputs)",
            "",
            "-                if args.logging_nan_inf_filter and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step)):",
            "-                    # if loss is nan or inf simply add the average of previous logged losses",
            "-                    tr_loss += tr_loss / (1 + self.state.global_step - self._globalstep_last_logged)",
            "+                if args.logging_nan_inf_filter and not is_torch_tpu_available():",
            "+                    if torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step):",
            "+                        # if loss is nan or inf simply add the average of previous logged losses",
            "+                        tr_loss += tr_loss / (1 + self.state.global_step - self._globalstep_last_logged)",
            "else:",
            "tr_loss += tr_loss_step"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 7915,
        "label": "no",
        "change": [
            "def train():",
            "",
            "# Compute loss",
            "loss, loss_items = compute_loss(pred, targets, model)",
            "-            if torch.isnan(loss):",
            "-                print('WARNING: nan loss detected, skipping batch ', loss_items)",
            "+            if not torch.isfinite(loss):",
            "+                print('WARNING: non-finite loss, skipping batch ', loss_items)",
            "continue",
            "",
            "# Scale loss by nominal batch_size of 64"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7917,
        "label": "no",
        "change": [
            "class Trainer:",
            "optimizer.step()",
            "",
            "# pytorch skips the step when the norm is 0. So ignore the norm value when it is NaN",
            "-        if isinstance(grad_norm ,torch.Tensor) and (torch.isnan(grad_norm) or torch.isinf(grad_norm)):",
            "+        if isinstance(grad_norm, torch.Tensor) and (torch.isnan(grad_norm) or torch.isinf(grad_norm)):",
            "grad_norm = 0",
            "",
            "step_time = time.time() - step_start_time"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7920,
        "label": "no",
        "change": [
            "class NaturalGradient(Optimizer):",
            "kldiv_gradients = [",
            "tf.convert_to_tensor(value=grad) for grad in tf.gradients(ys=kldiv, xs=variables)",
            "]",
            "-        # if not all(isinstance(grad, tf.Tensor)):  warning!!!",
            "",
            "# Calculates the product x * F of a given vector x with the fisher matrix F.",
            "# Incorporating the product prevents having to calculate the entire matrix explicitly."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7923,
        "label": "no",
        "change": [
            "from .modeling_xlm import (",
            "logger = logging.getLogger(__name__)",
            "",
            "FLAUBERT_PRETRAINED_MODEL_ARCHIVE_MAP = {",
            "-    \"flaubert-small-cased\": \"https://s3.amazonaws.com/models.huggingface.co/bert/flaubert/flaubert_small_cased/pytorch_model.bin\",",
            "-    \"flaubert-base-uncased\": \"https://s3.amazonaws.com/models.huggingface.co/bert/flaubert/flaubert_base_uncased/pytorch_model.bin\",",
            "-    \"flaubert-base-cased\": \"https://s3.amazonaws.com/models.huggingface.co/bert/flaubert/flaubert_base_cased/pytorch_model.bin\",",
            "-    \"flaubert-large-cased\": \"https://s3.amazonaws.com/models.huggingface.co/bert/flaubert/flaubert_large_cased/pytorch_model.bin\",",
            "+    \"flaubert-small-cased\": \"https://cdn.huggingface.co/flaubert/flaubert_small_cased/pytorch_model.bin\",",
            "+    \"flaubert-base-uncased\": \"https://cdn.huggingface.co/flaubert/flaubert_base_uncased/pytorch_model.bin\",",
            "+    \"flaubert-base-cased\": \"https://cdn.huggingface.co/flaubert/flaubert_base_cased/pytorch_model.bin\",",
            "+    \"flaubert-large-cased\": \"https://cdn.huggingface.co/flaubert/flaubert_large_cased/pytorch_model.bin\",",
            "}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7924,
        "label": "no",
        "change": [
            "class SOLOV2Head(SOLOHead):",
            "if num_pos > 0:",
            "loss_mask = torch.cat(loss_mask).sum() / num_pos",
            "else:",
            "-            loss_mask = torch.cat(loss_mask).mean()",
            "+            loss_mask = mask_feats.sum() * 0",
            "",
            "# cate",
            "flatten_labels = ["
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7925,
        "label": "no",
        "change": [
            "class Decoder(nn.Module):",
            "else:",
            "stop_token = self.stopnet(stopnet_input)",
            "output = output[:, : self.r * self.memory_dim]",
            "-        return output, stop_token, self.attention_layer.attention_weights",
            "+        return output, stop_token, self.attention.attention_weights",
            "",
            "def _update_memory_input(self, new_memory):",
            "if self.use_memory_queue:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7927,
        "label": "no",
        "change": [
            "class LightningModule(",
            "return torch.tensor(value, device=self.device)",
            "",
            "@staticmethod",
            "-    def __check_numel_1(value: torch.Tensor, name: str) -> None:",
            "+    def __check_numel_1(value: Tensor, name: str) -> None:",
            "if not torch.numel(value) == 1:",
            "raise ValueError(",
            "f\"`self.log({name}, {value})` was called, but the tensor must have a single element.\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7930,
        "label": "no",
        "change": [
            "class GHMC(nn.Module):",
            "\"\"\"",
            "# the target should be binary class label",
            "if pred.dim() != target.dim():",
            "-            target, label_weight = _expand_binary_labels(",
            "+            target, label_weight = _expand_onehot_labels(",
            "target, label_weight, pred.size(-1))",
            "target, label_weight = target.float(), label_weight.float()",
            "edges = self.edges"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7935,
        "label": "no",
        "change": [
            "class Rejector(TorchDistribution):",
            "x = self.propose(sample_shape) if sample_shape else self.propose()",
            "log_prob_accept = self.log_prob_accept(x)",
            "probs = torch.exp(log_prob_accept).clamp_(0.0, 1.0)",
            "-        done = torch.bernoulli(probs).byte()",
            "+        done = torch.bernoulli(probs).bool()",
            "while not done.all():",
            "proposed_x = self.propose(sample_shape) if sample_shape else self.propose()",
            "log_prob_accept = self.log_prob_accept(proposed_x)",
            "prob_accept = torch.exp(log_prob_accept).clamp_(0.0, 1.0)",
            "-            accept = torch.bernoulli(prob_accept).byte() & ~done",
            "+            accept = torch.bernoulli(prob_accept).bool() & ~done",
            "if accept.any():",
            "x[accept] = proposed_x[accept]",
            "done |= accept"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7936,
        "label": "no",
        "change": [
            "class Plan(Serializable):",
            "# prevent circular dependency",
            "# syft relative",
            "from ...core.node.vm.vm import VirtualMachine  # noqa: F401",
            "-        if self.local_executor is not None:",
            "-            # this is necessary for syfts nn.module, because the plan contains state from the module",
            "-            # in order to use this state, we first need to send the model, and then execute te plan",
            "-            return self.local_executor(**kwargs)",
            "",
            "alice = VirtualMachine(name=\"plan_executor\")",
            "alice_client: client.Client = alice.get_client()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7938,
        "label": "no",
        "change": [
            "class KerasTests(tf.test.TestCase):",
            "new_opt = new_model.optimizer",
            "os.remove(fname)",
            "",
            "-            self.assertEqual(type(new_opt).__module__, 'horovod.keras.impl')",
            "+            self.assertEqual(type(new_opt).__module__, 'horovod._keras')",
            "self.assertEqual(type(new_opt).__name__, 'TestOptimizer')",
            "self.assertEqual(K.get_value(opt.lr), K.get_value(new_opt.lr))",
            "self.assertEqual(len(opt.get_weights()), len(new_opt.get_weights()))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7940,
        "label": "no",
        "change": [
            "def unravel_index(",
            "/,",
            "*,",
            "out: Optional[torch.Tensor] = None,",
            "-) -> torch.Tensor:",
            "-    temp = indices.detach()",
            "+) -> Tuple:",
            "+    temp = indices.to(torch.int64)",
            "output = []",
            "for dim in reversed(shape):",
            "output.append(temp % dim)",
            "temp = temp // dim",
            "-    return torch.tensor(reversed(output), dtype=torch.int64)",
            "+    return tuple(reversed(output))",
            "",
            "",
            "unravel_index.support_native_out = False"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7941,
        "label": "no",
        "change": [
            "def main():",
            "noise = torch.randn(latents.shape).to(latents.device)",
            "bsz = latents.shape[0]",
            "# Sample a random timestep for each image",
            "-                timesteps = torch.randint(0, noise_scheduler.num_train_timesteps, (bsz,), device=latents.device).long()",
            "+                timesteps = torch.randint(",
            "+                    0, noise_scheduler.config.num_train_timesteps, (bsz,), device=latents.device",
            "+                ).long()",
            "",
            "# Add noise to the latents according to the noise magnitude at each timestep",
            "# (this is the forward diffusion process)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7942,
        "label": "no",
        "change": [
            "def consecutive_cluster(src, batch=None):",
            "output = arg[src.view(-1)]",
            "output = output.view(size).long()",
            "",
            "-    return (output, None) if batch is None else (output, batch[value])",
            "+    return (output, None) if batch is None else (output, batch[perm])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7944,
        "label": "no",
        "change": [
            "def cross_entropy_seq(logits, target_seqs, batch_size=None):#, batch_size=1, num",
            ">>> see PTB tutorial for more details",
            ">>> input_data = tf.placeholder(tf.int32, [batch_size, num_steps])",
            ">>> targets = tf.placeholder(tf.int32, [batch_size, num_steps])",
            "-    >>> cost = tf.cost.cross_entropy_seq(network.outputs, targets)",
            "+    >>> cost = tl.cost.cross_entropy_seq(network.outputs, targets)",
            "\"\"\"",
            "try: # TF 1.0",
            "sequence_loss_by_example_fn = tf.contrib.legacy_seq2seq.sequence_loss_by_example"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7946,
        "label": "no",
        "change": [
            "class TriAdaptiveModel(nn.Module):",
            "",
            "# Forward pass for text passages and tables",
            "if \"passage_input_ids\" in kwargs.keys():",
            "-            table_mask = torch.flatten(kwargs[\"is_table\"]) == True",
            "+            table_mask = torch.flatten(kwargs[\"is_table\"]) == 1",
            "",
            "# Current batch consists of only tables",
            "if all(table_mask):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7948,
        "label": "yes",
        "change": [
            "class SGD(base.Module):",
            "optimizer_utils.check_same_dtype(update, parameter)",
            "learning_rate = tf.cast(self.learning_rate, update.dtype.base_dtype)",
            "if isinstance(update, tf.IndexedSlices):",
            "-          parameter.scatter_nd_sub(",
            "-              update.indices, update.values * learning_rate)",
            "+          parameter.scatter_sub(",
            "+              tf.IndexedSlices(update.values * learning_rate, update.indices))",
            "else:",
            "parameter.assign_sub(update * learning_rate)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 7954,
        "label": "yes",
        "change": [
            "for it in range(1000000):",
            "T_sample = T(torch.cat([X, z_sample], 1))",
            "",
            "disc = torch.mean(-T_sample)",
            "-    loglike = -nn.binary_cross_entropy(X_sample, X)",
            "+    loglike = -nn.binary_cross_entropy(X_sample, X, size_average=False) / mb_size",
            "",
            "elbo = -(disc + loglike)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 7958,
        "label": "no",
        "change": [
            "def diff(",
            "x: Union[tf.Tensor, tf.Variable, int, float, list, tuple],",
            "/,",
            "*,",
            "-    out: Optional[Union[tf.Tensor, tf.Variable]] = None",
            "+    out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "return tf.experimental.numpy.diff(x)",
            "",
            "-",
            "+",
            "@with_unsupported_dtypes({\"2.9.1 and below\": (\"bfloat16, float16,\")}, backend_version)",
            "def zeta(",
            "x: Union[tf.Tensor, tf.Variable],"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7961,
        "label": "yes",
        "change": [
            "class SamplePoints(object):",
            "pos = pos / pos_max",
            "",
            "area = (pos[face[1]] - pos[face[0]]).cross(pos[face[2]] - pos[face[0]])",
            "-        area = torch.sqrt((area**2).sum(dim=-1)) / 2",
            "+        area = area.norm(p=2, dim=1) / 2",
            "",
            "prob = area / area.sum()",
            "sample = torch.multinomial(prob, self.num, replacement=True)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 7962,
        "label": "no",
        "change": [
            "class ECDTrainerConfig(BaseTrainerConfig):",
            "",
            "bucketing_field: str = schema_utils.String(",
            "default=None,",
            "-        description=\"When not null, when creating batches, instead of shuffling randomly, the length along the last \"",
            "-        \"dimension of the matrix of the specified input feature is used for bucketing examples and then \"",
            "-        \"randomly shuffled examples from the same bin are sampled. Padding is trimmed to the longest \"",
            "-        \"example in the batch. The specified feature should be either a sequence or text feature and the \"",
            "-        \"encoder encoding it has to be rnn. When used, bucketing improves speed of rnn encoding up to \"",
            "-        \"1.5x, depending on the length distribution of the inputs.\",",
            "+        description=\"Feature to use for bucketing datapoints\",",
            "parameter_metadata=TRAINER_METADATA[\"bucketing_field\"],",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7963,
        "label": "no",
        "change": [
            "class OrnsteinUhlenbeckProcess(Exploration):",
            "",
            "super(OrnsteinUhlenbeckProcess, self).__init__(scope=scope, summary_labels=summary_labels)",
            "",
            "-    def tf_explore(self, episode, timestep, action_spec):",
            "-        normal_sample = tf.random_normal(shape=action_spec['shape'], mean=0.0, stddev=1.0)",
            "+    def tf_explore(self, episode, timestep, shape):",
            "+        normal_sample = tf.random_normal(shape=shape, mean=0.0, stddev=1.0)",
            "state = tf.get_variable(",
            "name='ornstein_uhlenbeck',",
            "dtype=util.tf_dtype('float'),",
            "-            shape=action_spec['shape'],",
            "-            initializer=tf.constant_initializer(self.mu)",
            "+            shape=shape,",
            "+            initializer=tf.constant_initializer(self.mu),",
            "+            trainable=False",
            ")",
            "return tf.assign_add(ref=state, value=(self.theta * (self.mu - state) + self.sigma * normal_sample))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7965,
        "label": "no",
        "change": [
            "def linear_resample(x, num_samples: int, axis: int = -1):",
            "else:",
            "x_pre_shape = x_shape[:-1]",
            "x = torch.reshape(x, ([-1, 1] + [num_vals]))",
            "-    if x.dtype not in ['float16','float32','float64']:",
            "-        x=x.type(torch.float32)",
            "+    if x.dtype not in [\"float16\", \"float32\", \"float64\"]:",
            "+        x = x.type(torch.float32)",
            "ret = torch.nn.functional.interpolate(",
            "x, num_samples, mode=\"linear\", align_corners=True",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7967,
        "label": "no",
        "change": [
            "class NestedSpacesTest(unittest.TestCase):",
            "ModelCatalog.register_custom_model(\"invalid\", InvalidModel)",
            "self.assertRaisesRegexp(",
            "ValueError,",
            "-            \"optimizer got an empty parameter list\",",
            "+            \"Subclasses of TorchModelV2 must also inherit from nn.Module\",",
            "lambda: PGTrainer(",
            "env=\"CartPole-v0\",",
            "config={"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7968,
        "label": "yes",
        "change": [
            "class PaintByExamplePipeline(DiffusionPipeline):",
            "image_embeddings = image_embeddings.view(bs_embed * num_images_per_prompt, seq_len, -1)",
            "",
            "if do_classifier_free_guidance:",
            "-            uncond_embeddings = uncond_embeddings.repeat(1, image_embeddings.shape[0], 1)",
            "-            uncond_embeddings = uncond_embeddings.view(bs_embed * num_images_per_prompt, 1, -1)",
            "+            negative_prompt_embeds = negative_prompt_embeds.repeat(1, image_embeddings.shape[0], 1)",
            "+            negative_prompt_embeds = negative_prompt_embeds.view(bs_embed * num_images_per_prompt, 1, -1)",
            "",
            "# For classifier free guidance, we need to do two forward passes.",
            "# Here we concatenate the unconditional and text embeddings into a single batch",
            "# to avoid doing two forward passes",
            "-            image_embeddings = torch.cat([uncond_embeddings, image_embeddings])",
            "+            image_embeddings = torch.cat([negative_prompt_embeds, image_embeddings])",
            "",
            "return image_embeddings"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 7975,
        "label": "no",
        "change": [
            "class NarrativeqaManual(datasets.GeneratorBasedBuilder):",
            "",
            "if not os.path.exists(manual_dir):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('narrativeqa_manual', data_dir=...)` that includes the stories downloaded from the original repository. Manual download instructions: {}\".format(",
            "-                    manual_dir, self.manual_download_instructions",
            "-                )",
            "+                f\"{manual_dir} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('narrativeqa_manual', data_dir=...)` that includes the stories downloaded from the original repository. Manual download instructions: {self.manual_download_instructions}\"",
            ")",
            "",
            "return ["
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7977,
        "label": "yes",
        "change": [
            "class SequenceGenerator(nn.Module):",
            "cand_size = 2 * beam_size  # 2 x beam size in case half are EOS",
            "",
            "# offset arrays for converting between different indexing schemes",
            "-        bbsz_offsets = (torch.arange(0, bsz) * beam_size).unsqueeze(1).type_as(tokens)",
            "-        cand_offsets = torch.arange(0, cand_size).type_as(tokens)",
            "+        bbsz_offsets = (torch.arange(0, bsz) * beam_size).unsqueeze(1).type_as(tokens).to(src_tokens.device)",
            "+        cand_offsets = torch.arange(0, cand_size).type_as(tokens).to(src_tokens.device)",
            "",
            "reorder_state: Optional[Tensor] = None",
            "batch_idxs: Optional[Tensor] = None"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 7982,
        "label": "no",
        "change": [
            "class DistributionalQTFModel(TFModelV2):",
            "return tf.nn.relu(action_activation)",
            "",
            "def _f_epsilon(self, x):",
            "-        return tf.sign(x) * tf.sqrt(tf.abs(x))",
            "+        return tf.math.sign(x) * tf.math.sqrt(tf.math.abs(x))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7985,
        "label": "no",
        "change": [
            "class STFTDecoder(AbsDecoder):",
            "ilens (torch.Tensor): input lengths [Batch]",
            "\"\"\"",
            "if not isinstance(input, ComplexTensor) and (",
            "-            is_torch_1_8_plus and not torch.is_complex(input)",
            "+            is_torch_1_9_plus and not torch.is_complex(input)",
            "):",
            "raise TypeError(\"Only support complex tensors for stft decoder\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7987,
        "label": "no",
        "change": [
            "def test_easyocr_save_load(metadata, image_array, modelstore, save_proc):",
            "_model = save_proc(LANG_LIST, RECOG_NETWORK, DETECT_MODEL, metadata)",
            "assert _model.info.metadata is not None",
            "",
            "-    easyocr_loaded = bentoml.easyocr.load(",
            "-        _model.tag,",
            "-        gpu=False,",
            "-        model_store=modelstore,",
            "-    )",
            "+    easyocr_loaded = bentoml.easyocr.load(_model.tag)",
            "",
            "raw_res = easyocr_loaded.readtext(image_array)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7992,
        "label": "no",
        "change": [
            "class TestErode:",
            "rtol=1e-4,",
            ")",
            "assert_close(",
            "-            erosion(tensor,",
            "-                    torch.ones_like(structural_element),",
            "-                    structuring_element=structural_element,",
            "-                    engine='convolution'),",
            "+            erosion(",
            "+                tensor,",
            "+                torch.ones_like(structural_element),",
            "+                structuring_element=structural_element,",
            "+                engine='convolution',",
            "+            ),",
            "expected,",
            "atol=1e-3,",
            "rtol=1e-3,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7998,
        "label": "no",
        "change": [
            "class SyncReplayOptimizer(PolicyOptimizer):",
            "self.learner_stats[policy_id] = get_learner_stats(info)",
            "replay_buffer = self.replay_buffers[policy_id]",
            "if isinstance(replay_buffer, PrioritizedReplayBuffer):",
            "-                    td_error = info[\"td_error\"]",
            "+                    # TODO(sven): This is currently structured differently for",
            "+                    #  torch/tf. Clean up these results/info dicts across",
            "+                    #  policies (note: fixing this in torch_policy.py will",
            "+                    #  break e.g. DDPPO!).",
            "+                    td_error = info.get(",
            "+                        \"td_error\", info[\"learner_stats\"].get(\"td_error\"))",
            "new_priorities = (",
            "np.abs(td_error) + self.prioritized_replay_eps)",
            "replay_buffer.update_priorities("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8002,
        "label": "no",
        "change": [
            "from .modeling_utils import Conv1D, PreTrainedModel, SequenceSummary, prune_conv",
            "",
            "logger = logging.getLogger(__name__)",
            "",
            "-OPENAI_GPT_PRETRAINED_MODEL_ARCHIVE_MAP = {",
            "-    \"openai-gpt\": \"https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-pytorch_model.bin\"",
            "-}",
            "+OPENAI_GPT_PRETRAINED_MODEL_ARCHIVE_MAP = {\"openai-gpt\": \"https://cdn.huggingface.co/openai-gpt-pytorch_model.bin\"}",
            "",
            "",
            "def load_tf_weights_in_openai_gpt(model, config, openai_checkpoint_folder_path):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8008,
        "label": "no",
        "change": [
            "class vgg16(object):",
            "y1 = tf.slice(rois, [0, 2], [-1, 1], name=\"y1\") / height",
            "x2 = tf.slice(rois, [0, 3], [-1, 1], name=\"x2\") / width",
            "y2 = tf.slice(rois, [0, 4], [-1, 1], name=\"y2\") / height",
            "-      bboxes = tf.concat([y1, x1, y2, x2], 1)",
            "+      bboxes = tf.stop_gradient(tf.concat([y1, x1, y2, x2], 1))",
            "pre_pool_size = cfg.POOLING_SIZE * 2",
            "crops = tf.image.crop_and_resize(bottom, bboxes, tf.to_int32(batch_ids), [pre_pool_size, pre_pool_size], name=\"crops\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8012,
        "label": "no",
        "change": [
            "class PolicyGradient(Objective):",
            ")",
            "return tf.math.minimum(x=(scaling * reward), y=(clipped_scaling * reward))",
            "",
            "-        skip_clipping = tf.math.equal(x=clipping_value, y=zero)",
            "+        skip_clipping = tf.math.equal(x=clipping_value, y=one)",
            "scaled = tf.cond(pred=skip_clipping, true_fn=no_clipping, false_fn=apply_clipping)",
            "",
            "loss = -scaled"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8014,
        "label": "yes",
        "change": [
            "class MeanSquaredError(Metric):",
            "preds: Predictions from model",
            "target: Ground truth values",
            "\"\"\"",
            "-        self._check_same_shape(preds, target)",
            "-        squared_error = torch.pow(preds - target, 2)",
            "+        sum_squared_error, n_obs = _mean_squared_error_update(preds, target)",
            "",
            "-        self.sum_squared_error += torch.sum(squared_error)",
            "-        self.total += target.numel()",
            "+        self.sum_squared_error += sum_squared_error",
            "+        self.total += n_obs",
            "",
            "def compute(self):",
            "\"\"\"",
            "Computes mean squared error over state.",
            "\"\"\"",
            "-        return self.sum_squared_error / self.total",
            "+        return _mean_squared_error_compute(self.sum_squared_error, self.total)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 8015,
        "label": "no",
        "change": [
            "class CaptureLogger:",
            "",
            ">>> msg = \"Testing 1, 2, 3\"",
            ">>> logging.set_verbosity_info()",
            "-        >>> logger = logging.get_logger(\"transformers.tokenization_bart\")",
            "+        >>> logger = logging.get_logger(\"transformers.models.bart.tokenization_bart\")",
            ">>> with CaptureLogger(logger) as cl:",
            "...     logger.info(msg)",
            ">>> assert cl.out, msg+\"\\n\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8016,
        "label": "no",
        "change": [
            "def test_cat(dim):",
            "assert complex_module.allclose(ret, ret2)",
            "",
            "",
            "-@pytest.mark.parametrize(\"dim\", [0, 1, 2])",
            "+@pytest.mark.parametrize(\"dim\", [None, 0, 1, 2])",
            "@pytest.mark.skipif(not is_torch_1_9_plus, reason=\"Require torch 1.9.0+\")",
            "def test_complex_norm(dim):",
            "mat = ComplexTensor(torch.rand(2, 3, 4), torch.rand(2, 3, 4))",
            "mat_th = torch.complex(mat.real, mat.imag)",
            "norm = complex_norm(mat, dim=dim, keepdim=True)",
            "norm_th = complex_norm(mat_th, dim=dim, keepdim=True)",
            "-    assert (",
            "-        torch.allclose(norm, norm_th)",
            "-        and norm.ndim == mat.ndim",
            "-        and mat.numel() == norm.numel() * mat.size(dim)",
            "-    )",
            "+    assert torch.allclose(norm, norm_th)",
            "+    if dim is not None:",
            "+        assert norm.ndim == mat.ndim and mat.numel() == norm.numel() * mat.size(dim)",
            "",
            "",
            "@pytest.mark.parametrize(\"real_vec\", [True, False])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8017,
        "label": "no",
        "change": [
            "data = dataset[0]",
            "class NeighborSampler(RawNeighborSampler):",
            "def sample(self, batch):",
            "batch = torch.tensor(batch)",
            "-        row, col, _ = self.adj.coo()",
            "+        row, col, _ = self.adj_t.coo()#change adj to adj_t",
            "",
            "# For each node in `batch`, we sample a direct neighbor (as positive",
            "# example) and a random node (as negative example):",
            "pos_batch = random_walk(row, col, batch, walk_length=1,",
            "coalesced=False)[:, 1]",
            "",
            "-        neg_batch = torch.randint(0, self.adj.size(0), (batch.numel(), ),",
            "-                                  dtype=torch.long)",
            "+        neg_batch = torch.randint(0, self.adj_t.size(0), (batch.numel(), ),",
            "+                                  dtype=torch.long)#change adj to adj_t",
            "",
            "batch = torch.cat([batch, pos_batch, neg_batch], dim=0)",
            "return super(NeighborSampler, self).sample(batch)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8018,
        "label": "no",
        "change": [
            "def test_dstack(",
            "",
            "# atleast_2d",
            "@handle_test(",
            "+    fn_tree=\"functional.experimental.atleast_2d\",",
            "dtype_and_x=helpers.dtype_and_values(",
            "available_dtypes=helpers.get_dtypes(\"valid\"),",
            "num_arrays=helpers.ints(min_value=1, max_value=5),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8019,
        "label": "no",
        "change": [
            "def center_loss(features, label, alfa, nrof_classes):",
            "centers_batch = tf.gather(centers, label)",
            "diff = (1 - alfa) * (centers_batch - features)",
            "centers = tf.scatter_sub(centers, label, diff)",
            "-    loss = tf.reduce_mean(tf.square(features - centers_batch))",
            "+    with tf.control_dependencies([centers]):",
            "+        loss = tf.reduce_mean(tf.square(features - centers_batch))",
            "return loss, centers",
            "",
            "def get_image_paths_and_labels(dataset):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8020,
        "label": "no",
        "change": [
            "class QModel(Model):",
            "",
            "# If loss clipping is used, calculate the huber loss",
            "if config.clip_loss > 0.0:",
            "-                huber_loss = tf.where(condition=(tf.abs(delta) < config.clip_gradients), x=(0.5 * self.loss_per_instance), y=(tf.abs(delta) - 0.5))",
            "+                huber_loss = tf.where(condition=(tf.abs(delta) < config.clip_loss), x=(0.5 * self.loss_per_instance), y=(tf.abs(delta) - 0.5))",
            "self.q_loss = tf.reduce_mean(input_tensor=huber_loss, axis=0)",
            "else:",
            "self.q_loss = tf.reduce_mean(input_tensor=self.loss_per_instance, axis=0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8021,
        "label": "no",
        "change": [
            "def tensor_to_image(tensor):",
            "if not torch.is_tensor(tensor):",
            "raise TypeError(\"Input type is not a torch.Tensor. Got {}\".format(",
            "type(tensor)))",
            "+    tensor = torch.squeeze(tensor)",
            "if len(tensor.shape) > 3 or len(tensor.shape) < 2:",
            "raise ValueError(",
            "\"Input size must be a two or three dimensional tensor\")",
            "-    tensor = torch.squeeze(tensor)",
            "if len(tensor.shape) == 2:",
            "tensor = torch.unsqueeze(tensor, dim=0)",
            "return tensor.permute(1, 2, 0).contiguous().cpu().detach().numpy()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8024,
        "label": "no",
        "change": [
            "class Cifar10ConvNet(base.Module):",
            "",
            "logits = self._logits_module(flat_output)",
            "",
            "-    return {'logits': logits, 'activations': activations}  # pytype: disable=bad-return-type",
            "+    return {'logits': logits, 'activations': activations}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8025,
        "label": "no",
        "change": [
            "def get_hanning_kernel1d(kernel_size: int, device=torch.device('cpu'), dtype=tor",
            "return x",
            "",
            "",
            "-def get_hanning_kernel2d(kernel_size: Tuple[int, int],",
            "-                         device=torch.device('cpu'),",
            "-                         dtype=torch.float) -> torch.Tensor:",
            "+def get_hanning_kernel2d(kernel_size: Tuple[int, int], device=torch.device('cpu'), dtype=torch.float) -> torch.Tensor:",
            "r\"\"\"Returns 2d Hanning kernel, used in signal processing and KCF tracker.",
            "",
            "Args:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8027,
        "label": "no",
        "change": [
            "def recog(args):",
            "word_dict = rnnlm_args.char_list_dict",
            "char_dict = {x: i for i, x in enumerate(train_args.char_list)}",
            "word_rnnlm = lm_pytorch.ClassifierWithState(lm_pytorch.RNNLM(",
            "-            len(word_dict), rnnlm_args.layers, rnnlm_args.units))",
            "+            len(word_dict), rnnlm_args.layer, rnnlm_args.unit))",
            "torch_load(args.word_rnnlm, word_rnnlm)",
            "word_rnnlm.eval()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8028,
        "label": "no",
        "change": [
            "class FP16_DeepSpeedZeroOptimizer(object):",
            "current_size = 0",
            "for i, tensor in enumerate(tensor_list):",
            "if tensor.grad is None:",
            "-                continue",
            "+                tensor.grad = torch.zeros_like(tensor)",
            "",
            "tensor = tensor.grad",
            "num_elements = tensor.numel()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8032,
        "label": "no",
        "change": [
            "class RaoBlackwellizationTests(TestCase):",
            "pyro.sample(\"z_%d_%d\" % (i, k),",
            "fakes.NonreparameterizedNormal(ng_zeros(4 - i), ng_ones(4 - i)))",
            "pyro.sample(\"obs_%d\" % i,",
            "-                            dist.Normal(mu_latent, torch.pow(self.lam, -0.5), extra_event_dims=1),",
            "+                            dist.Normal(mu_latent, torch.pow(self.lam, -0.5))",
            "+                                .reshape(extra_event_dims=1),",
            "obs=_x)",
            "for k in range(n_superfluous_top, n_superfluous_top + n_superfluous_bottom):",
            "pyro.sample(\"z_%d_%d\" % (i, k),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8033,
        "label": "no",
        "change": [
            "class TestErode:",
            "None, None, :, :",
            "]",
            "assert_allclose(",
            "-            erosion(tensor, torch.ones_like(structural_element), structuring_element=structural_element), expected,",
            "-            atol=1e-4, rtol=1e-4",
            "+            erosion(tensor, torch.ones_like(structural_element), structuring_element=structural_element),",
            "+            expected,",
            "+            atol=1e-4,",
            "+            rtol=1e-4,",
            ")",
            "",
            "def test_exception(self, device, dtype):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8035,
        "label": "no",
        "change": [
            "class VanLayer(nn.Module):",
            "drop_path_rate: float = 0.5,",
            "):",
            "super().__init__()",
            "-        self.drop_path = VanDropPath(drop_path) if drop_path_rate > 0.0 else nn.Identity()",
            "+        self.drop_path = VanDropPath(drop_path_rate) if drop_path_rate > 0.0 else nn.Identity()",
            "self.pre_normomalization = nn.BatchNorm2d(hidden_size)",
            "self.attention = VanSpatialAttentionLayer(hidden_size, config.hidden_act)",
            "self.attention_scaling = VanLayerScaling(hidden_size, config.layer_scale_init_value)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8038,
        "label": "no",
        "change": [
            "class DiagGaussian(TFActionDistribution):",
            "@override(ActionDistribution)",
            "def logp(self, x):",
            "return -0.5 * tf.reduce_sum(",
            "-            tf.square((x - self.mean) / self.std), axis=1) - \\",
            "+            tf.square((tf.to_float(x) - self.mean) / self.std), axis=1) - \\",
            "0.5 * np.log(2.0 * np.pi) * tf.to_float(tf.shape(x)[1]) - \\",
            "tf.reduce_sum(self.log_std, axis=1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8045,
        "label": "yes",
        "change": [
            "def test_unnormalized_normal(kernel, jit):",
            "posterior.append(samples)",
            "",
            "posterior = torch.stack([sample[\"z\"] for sample in posterior])",
            "-    assert_equal(torch.mean(posterior), true_mean, prec=0.1)",
            "-    assert_equal(torch.std(posterior), true_std, prec=0.1)",
            "+    assert_close(torch.mean(posterior), true_mean, rtol=0.05)",
            "+    assert_close(torch.std(posterior), true_std, rtol=0.05)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 8047,
        "label": "no",
        "change": [
            "class TFTapasForQuestionAnswering(TFTapasPreTrainedModel):",
            "logits_aggregation = self.aggregation_classifier(pooled_output)",
            "",
            "# Total loss calculation",
            "-        total_loss = 0.0",
            "+        total_loss = tf.zeros(shape=(1,), dtype=tf.float32)",
            "calculate_loss = False",
            "if labels is not None:",
            "calculate_loss = True"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8052,
        "label": "no",
        "change": [
            "def main_lstm_generate_text():",
            "",
            "if __name__ == '__main__':",
            "sess = tf.InteractiveSession()",
            "-    \"\"\"Restore a pretrained embedding matrix.\"\"\"",
            "+    # Restore a pretrained embedding matrix",
            "# main_restore_embedding_layer()",
            "-    \"\"\"How to generate text from a given context.\"\"\"",
            "+",
            "+    # How to generate text from a given context",
            "main_lstm_generate_text()",
            "",
            "#"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8063,
        "label": "no",
        "change": [
            "def triplet_loss(anchor, positive, negative, alpha):",
            "the triplet loss according to the FaceNet paper as a float tensor.",
            "\"\"\"",
            "with tf.variable_scope('triplet_loss'):",
            "-        pos_dist = tf.reduce_sum(tf.square(tf.sub(anchor, positive)), 1)  # Summing over distances in each batch",
            "+        pos_dist = tf.reduce_sum(tf.square(tf.sub(anchor, positive)), 1)",
            "neg_dist = tf.reduce_sum(tf.square(tf.sub(anchor, negative)), 1)",
            "",
            "basic_loss = tf.add(tf.sub(pos_dist,neg_dist), alpha)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8066,
        "label": "no",
        "change": [
            "def run(",
            "im, model = im.half(), model.half()  # to FP16",
            "model.train() if train else model.eval()  # training mode = no Detect() layer grid construction",
            "for k, m in model.named_modules():",
            "-        # if isinstance(m, Conv):  # assign export-friendly activations",
            "-        #     if isinstance(m.act, nn.SiLU):",
            "-        #         m.act = SiLU()",
            "if isinstance(m, Detect):",
            "m.inplace = inplace",
            "m.onnx_dynamic = dynamic",
            "m.export = True",
            "-            if hasattr(m, 'forward_export'):",
            "-                m.forward = m.forward_export  # assign custom forward (optional)",
            "",
            "for _ in range(2):",
            "y = model(im)  # dry runs"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8067,
        "label": "no",
        "change": [
            "def compute_weighted_loss(losses,",
            "losses = tf.convert_to_tensor(losses)",
            "input_dtype = losses.dtype",
            "",
            "-    if not isinstance(sample_weight, keras_tensor.KerasTensor):",
            "+    if not isinstance(sample_weight,",
            "+                      (keras_tensor.KerasTensor, tf.RaggedTensor)):",
            "sample_weight = tf.convert_to_tensor(sample_weight)",
            "",
            "# TODO(psv): Handle casting here in a better way, eg. if losses is float64"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8069,
        "label": "no",
        "change": [
            "class ConditionalRandomField(torch.nn.Module):",
            "\"\"\"",
            "",
            "if mask is None:",
            "-            mask = torch.ones(*tags.size(), dtype=torch.bool)",
            "+            mask = torch.ones(*tags.size(), dtype=torch.bool, device=inputs.device)",
            "else:",
            "# The code below fails in weird ways if this isn't a bool tensor, so we make sure.",
            "mask = mask.to(torch.bool)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8071,
        "label": "no",
        "change": [
            "class BlipTextModel(BlipTextPreTrainedModel):",
            "past_key_values_length = past_key_values[0][0].shape[2] if past_key_values is not None else 0",
            "",
            "if attention_mask is None:",
            "-            attention_mask = torch.ones(((batch_size, seq_length + past_key_values_length)))",
            "+            attention_mask = torch.ones(((batch_size, seq_length + past_key_values_length))).to(device)",
            "",
            "# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]",
            "# ourselves in which case we just need to make it broadcastable to all heads."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8074,
        "label": "no",
        "change": [
            "def main(args):",
            "print('Total number of examples: %d' % len(label_list))",
            "",
            "# Placeholder for the learning rate",
            "-        learning_rate_placeholder = tf.placeholder(tf.float32, name='learing_rate')",
            "+        learning_rate_placeholder = tf.placeholder(tf.float32, name='learning_rate')",
            "",
            "# Build the inference graph",
            "prelogits, _ = network.inference(image_batch, args.keep_probability,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8078,
        "label": "no",
        "change": [
            "class MaintainStepCounter(Callback):",
            "# ensure it exists",
            "gs_var = get_global_step_var()",
            "with tf.name_scope(None):",
            "-            with self.graph.colocate_with(gs_var):",
            "-                self.gs_incr_op = tf.assign_add(",
            "-                    gs_var, 1,",
            "-                    name=GLOBAL_STEP_INCR_OP_NAME).op",
            "+            self.gs_incr_op = tf.assign_add(",
            "+                gs_var, 1,",
            "+                name=GLOBAL_STEP_INCR_OP_NAME).op",
            "self._fetches = tf.train.SessionRunArgs(self.gs_incr_op)",
            "",
            "def _before_train(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8088,
        "label": "no",
        "change": [
            "class E2E(STInterface, torch.nn.Module):",
            "hs, _, _ = self.enc(hs, ilens)",
            "return hs.squeeze(0)",
            "",
            "-    def translate(self, x, trans_args, char_list, rnnlm=None):",
            "+    def translate(self, x, trans_args, char_list, rnnlm=None, ensemble_models=[]):",
            "\"\"\"E2E beam search.",
            "",
            ":param ndarray x: input acoustic feature (T, D)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8091,
        "label": "no",
        "change": [
            "class PearsonCorrelation(Metric):",
            "A tensor of the same shape as `predictions`.",
            "\"\"\"",
            "predictions, gold_labels, mask = self.detach_tensors(predictions, gold_labels, mask)",
            "-        self._device = gold_labels.device",
            "if not is_distributed():",
            "self._predictions_labels_covariance(predictions, gold_labels, mask)",
            "self._predictions_variance(predictions, predictions, mask)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8092,
        "label": "no",
        "change": [
            "class Transform(torch.nn.Module):",
            "Normalize(mean, std),",
            ")",
            "",
            "-    def forward(self, x: Image) -> torch.Tensor:",
            "+    def forward(self, x) -> torch.Tensor:",
            "+        \"\"\"`x` should be an instance of `PIL.Image.Image`\"\"\"",
            "with torch.no_grad():",
            "x = self.transforms(x)",
            "return x"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8097,
        "label": "no",
        "change": [
            "def fixed_pos_embedding(x, seq_dim=1, seq_len=None):",
            "if seq_len is None:",
            "seq_len = x.shape[seq_dim]",
            "inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2) / dim))",
            "-    sinusoid_inp = torch.einsum(\"i , j -> i j\", torch.arange(seq_len), inv_freq).to(x.device).float()",
            "+    sinusoid_inp = (",
            "+        torch.einsum(\"i , j -> i j\", torch.arange(seq_len, dtype=torch.float), inv_freq).to(x.device).float()",
            "+    )",
            "return torch.sin(sinusoid_inp), torch.cos(sinusoid_inp)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8100,
        "label": "no",
        "change": [
            "from allennlp.training import NoOpTrainer",
            "",
            "class ConstantModel(Model):",
            "def forward(self, *inputs) -> Dict[str, torch.Tensor]:",
            "-        return {\"class\": torch.tensor(98)} # pylint: disable=not-callable",
            "+        return {\"class\": torch.tensor(98)}",
            "+",
            "",
            "class TestNoOpTrainer(AllenNlpTestCase):",
            "def setUp(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8103,
        "label": "no",
        "change": [
            "class Graph(object):",
            "if relevant_nodes and in_node not in relevant_nodes:",
            "# node is not part of the current network",
            "continue",
            "-                    for in_layer in nest.flatten(in_node.inbound_layers):",
            "+                    for in_layer in nest(in_node.inbound_layers):",
            "inbound_keras_node = Node.from_keras(in_layer)",
            "",
            "if (inbound_keras_node.id not in graph.nodes_by_id):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8105,
        "label": "no",
        "change": [
            "def update_sub(x, decrement):",
            "",
            "",
            "def moving_average_update(variable, value, momentum):",
            "-    return tf.python.training.moving_averages.assign_moving_average(",
            "+    return moving_averages.assign_moving_average(",
            "variable, value, momentum)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8106,
        "label": "no",
        "change": [
            "def remainder(",
            "res_floored = tf.where(res >= 0, tf.math.floor(res), tf.math.ceil(res))",
            "diff = res - res_floored",
            "diff, x2 = ivy.promote_types_of_inputs(diff, x2)",
            "-        return tf.cast(diff * x2, x1.dtype)",
            "+        return tf.cast(tf.round(diff * x2), x1.dtype)",
            "return tf.experimental.numpy.remainder(x1, x2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8110,
        "label": "no",
        "change": [
            "import torch",
            "from pytorch_lightning import _logger as log",
            "",
            "if torch.distributed.is_available():",
            "-    from torch.distributed import ReduceOp, group",
            "+    from torch.distributed import group, ReduceOp",
            "else:",
            "class ReduceOp:",
            "SUM = None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8115,
        "label": "no",
        "change": [
            "class TestSelfAttentiveSpanExtractor:",
            "numpy.testing.assert_array_almost_equal(spans[1].data.numpy(), mean_embeddings.data.numpy())",
            "",
            "# Now test the case in which we have some masked spans in our indices.",
            "-        indices_mask = torch.LongTensor([[1, 1], [1, 0]])",
            "+        indices_mask = torch.BoolTensor([[True, True], [True, False]])",
            "span_representations = extractor(sequence_tensor, indices, span_indices_mask=indices_mask)",
            "",
            "# First element in the batch."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8116,
        "label": "no",
        "change": [
            "class CustomLossModel(Model):",
            "input_ops = reader.tf_input_ops()",
            "",
            "# define a secondary loss by building a graph copy with weight sharing",
            "+        obs = tf.cast(input_ops[\"obs\"], tf.float32)",
            "logits, _ = self._build_layers_v2({",
            "-            \"obs\": restore_original_dimensions(input_ops[\"obs\"],",
            "-                                               self.obs_space)",
            "+            \"obs\": restore_original_dimensions(obs, self.obs_space)",
            "}, self.num_outputs, self.options)",
            "",
            "# You can also add self-supervised losses easily by referencing tensors"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8117,
        "label": "no",
        "change": [
            "def detect(save_img=False):",
            "",
            "save_path = str(Path(out) / Path(p).name)",
            "s += '%gx%g ' % img.shape[2:]  # print string",
            "-            gn = torch.tensor(im0s.shape)[[1, 0, 1, 0]]  #  normalization gain whwh",
            "+            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  #  normalization gain whwh",
            "if det is not None and len(det):",
            "# Rescale boxes from imgsz to im0 size",
            "det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8118,
        "label": "no",
        "change": [
            "import tensorflow as tf",
            "",
            "def masked_softmax_cross_entropy(preds, labels, mask):",
            "\"\"\"Softmax cross-entropy loss with masking.\"\"\"",
            "-    loss = tf.nn.softmax_cross_entropy_with_logits(logits=preds, lables=labels)",
            "+    loss = tf.nn.softmax_cross_entropy_with_logits(logits=preds, labels=labels)",
            "mask = tf.cast(mask, dtype=tf.float32)",
            "mask /= tf.reduce_mean(mask)",
            "loss *= mask"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8125,
        "label": "no",
        "change": [
            "class KerasModel(Model):",
            "",
            "return model",
            "",
            "-    @catch_exceptions(",
            "-        catch_exc=ModuleNotFoundError, throw_exc=MissingDependencyException, msg=_exc",
            "-    )",
            "def save(self, path: PathType) -> None:",
            "tf.compat.v1.keras.backend.get_session()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8128,
        "label": "no",
        "change": [
            "def perform_analysis_torch(preds, indices, noise_eps=0.1, delta=1e-5, moments=8,",
            "data_ind_eps_list = (data_ind_log_mgf - math.log(delta)) / l_list",
            "",
            "return min(eps_list_nm), min(data_ind_eps_list)",
            "-",
            "-",
            "-",
            "-"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8129,
        "label": "no",
        "change": [
            "def sum(",
            "]",
            "),",
            "dtype=dtype,",
            "-                out=out,",
            ")",
            "return torch.sum(input=x, dim=axis, dtype=dtype, keepdim=keepdims)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8130,
        "label": "no",
        "change": [
            "class F1MeasureTest(AllenNlpTestCase):",
            "assert_allclose(f1, 0.8)",
            "",
            "# Test the same thing with a mask:",
            "-        mask = torch.tensor([[0, 1, 0], [1, 1, 1]], device=device)",
            "+        mask = torch.BoolTensor([[False, True, False], [True, True, True]], device=device)",
            "f1_measure(predictions, targets, mask)",
            "precision, recall, f1 = f1_measure.get_metric()",
            "assert f1_measure._true_positives == 1.0"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8138,
        "label": "no",
        "change": [
            "def test_tensorflow_l2_normalize(",
            "",
            "# trace",
            "@handle_frontend_test(",
            "+    fn_tree=\"tensorflow.linalg.trace\",",
            "dtype_and_input=_get_dtype_and_matrix(),",
            "num_positional_args=helpers.num_positional_args(",
            "fn_name=\"ivy.functional.frontends.tensorflow.linalg.trace\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8140,
        "label": "no",
        "change": [
            "class TFVisionEncoderDecoderModel(TFPreTrainedModel, TFCausalLanguageModelingLos",
            "Returns:",
            "`Dict[str, tf.Tensor]`: The dummy inputs.",
            "\"\"\"",
            "-        decoder_input_ids = tf.constant(DUMMY_INPUTS)",
            "+        decoder_input_ids = tf.constant(DUMMY_INPUTS, dtype=tf.int32)",
            "batch_size, seq_len = decoder_input_ids.shape",
            "",
            "VISION_DUMMY_INPUTS = tf.random.uniform("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8144,
        "label": "no",
        "change": [
            "def subtract(",
            "x1, x2 = ivy.promote_types_of_inputs(x1, x2)",
            "if alpha not in (1, None):",
            "x2 = x2 * alpha",
            "-    return tf.experimental.numpy.subtract(x1, x2)",
            "+    return tf.subtract(x1, x2)",
            "",
            "",
            "def tan("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8149,
        "label": "no",
        "change": [
            "class MemoryModel(Model):",
            "# e.g. F T F F F F",
            "",
            "# Store the steps until end of the episode(s) determined by the input terminal signals (True starts new count).",
            "-        lengths = tf.scan(fn=len_, elems=terminal, initializer=0)",
            "+        lengths = tf.scan(",
            "+            fn=len_, elems=terminal,",
            "+            initializer=tf.zeros_like(tensor=terminal[0], dtype=tf.int32)",
            "+        )",
            "# e.g. 1 1 2 3 4 5",
            "off_horizon = tf.greater(lengths, tf.fill(dims=tf.shape(lengths), value=horizon))",
            "# e.g. F F F F T T"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8150,
        "label": "no",
        "change": [
            "class IntraSentenceAttentionEncoder(Seq2SeqEncoder):",
            "return False",
            "",
            "@overrides",
            "-    def forward(self, tokens: torch.Tensor, mask: torch.Tensor):",
            "+    def forward(self, tokens: torch.Tensor, mask: torch.BoolTensor):",
            "batch_size, sequence_length, _ = tokens.size()",
            "# Shape: (batch_size, sequence_length, sequence_length)",
            "similarity_matrix = self._matrix_attention(tokens, tokens)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8153,
        "label": "no",
        "change": [
            "class DetrMHAttentionMap(nn.Module):",
            "weights = torch.einsum(\"bqnc,bnchw->bqnhw\", queries_per_head * self.normalize_fact, keys_per_head)",
            "",
            "if mask is not None:",
            "-            weights.masked_fill_(mask.unsqueeze(1).unsqueeze(1), float(\"-inf\"))",
            "+            weights.masked_fill_(mask.unsqueeze(1).unsqueeze(1), torch.finfo(weights.dtype).min)",
            "weights = nn.functional.softmax(weights.flatten(2), dim=-1).view(weights.size())",
            "weights = self.dropout(weights)",
            "return weights"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8155,
        "label": "no",
        "change": [
            "class Trainer(object):",
            "summary (tf.Summary or str): a summary object, or a str which will",
            "be interpreted as a serialized tf.Summary protobuf.",
            "\"\"\"",
            "-        if isinstance(summary, six.string_types):",
            "+        if isinstance(summary, six.binary_type):",
            "summary = tf.Summary.FromString(summary)",
            "+        assert isinstance(summary, tf.Summary), type(summary)",
            "for val in summary.value:",
            "if val.WhichOneof('value') == 'simple_value':",
            "val.tag = re.sub('tower[p0-9]+/', '', val.tag)   # TODO move to subclasses"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8157,
        "label": "no",
        "change": [
            "class SinusoidalPositionalEmbedding(nn.Module):",
            "if self.onnx_trace:",
            "flat_embeddings = self.weights.detach().index_select(0, positions.view(-1))",
            "embedding_shape = torch.cat(",
            "-                (bsz.view(1), seq_len.view(1), torch.tensor([-1], dtype=torch.long))",
            "+                (bsz, seq_len, torch.tensor([-1], dtype=torch.long))",
            ")",
            "embeddings = torch.onnx.operators.reshape_from_tensor_shape(",
            "flat_embeddings, embedding_shape"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8158,
        "label": "no",
        "change": [
            "class VisualBertRegionToPhraseAttention(nn.Module):",
            "def forward(self, query, key, attention_mask):",
            "attention_mask = attention_mask.to(query.dtype)",
            "attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)",
            "-        attention_mask = (1.0 - attention_mask) * -10000.0",
            "+        attention_mask = (1.0 - attention_mask) * torch.finfo(query.dtype).min",
            "",
            "mixed_query_layer = self.query(query)",
            "mixed_key_layer = self.key(key)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8162,
        "label": "no",
        "change": [
            "class ParabolicEquationStepperTest(tf.test.TestCase, parameterized.TestCase):",
            "sizes=[100],",
            "dtype=np.float64))",
            "",
            "-    initial_values = tf.math.exp(grid[0])  # Initial condtion",
            "+    initial_values = tf.math.exp(grid[0])  # Initial condition",
            "time_step = 0.001",
            "final_t = 0.1",
            "if default_bc == 'left':"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8164,
        "label": "no",
        "change": [
            "class InputFeature(BaseFeature, LudwigModule, ABC):",
            "def update_config_with_metadata(feature_config, feature_metadata, *args, **kwargs):",
            "pass",
            "",
            "+    def update_config_after_module_init(self, feature_config):",
            "+        \"\"\"Updates the config after the torch.nn.Module objects have been initialized.\"\"\"",
            "+        pass",
            "+",
            "def initialize_encoder(self, encoder_config):",
            "encoder_cls = get_encoder_cls(self.type(), encoder_config.type)",
            "encoder_schema = encoder_cls.get_schema_cls().Schema()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8166,
        "label": "yes",
        "change": [
            "def bjerksund_stensland(*,",
            "volatilities=volatilities,",
            "strikes=strikes,",
            "expiries=expiries,",
            "-                forwards=forwards,",
            "+                spots=spots,",
            "discount_rates=discount_rates,",
            "cost_of_carries=cost_of_carries,",
            "is_call_options=is_call_options),",
            "# For put options, adjust inputs according to call-put transformation",
            "# function:  P(S, X, T, r, b, sigma) = C(X, S, T, r - b, -b, sigma)",
            "tf.where(is_call_options,",
            "-                bjerksund_stensland_model(forwards, strikes, expiries, discount_rates,",
            "+                bjerksund_stensland_model(spots, strikes, expiries, discount_rates,",
            "cost_of_carries, volatilities),",
            "-                bjerksund_stensland_model(strikes, forwards, expiries, discount_rates -",
            "+                bjerksund_stensland_model(strikes, spots, expiries, discount_rates -",
            "cost_of_carries, -cost_of_carries, volatilities)))",
            "",
            "return american_prices"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 8167,
        "label": "no",
        "change": [
            "def detectMinVal(input_mat, var, threshold=1e-6, name='', debug=False):",
            "input_mat_clipped = clipoutNeg(input_mat, threshold)",
            "",
            "if debug:",
            "-        input_mat_clipped = tf.cond(tf.logical_or(tf.greater(eigen_ratio, 0.), tf.less(eigen_ratio, -500)), lambda: input_mat_clipped, lambda: tf.Print(",
            "+        input_mat_clipped = self.cond(tf.logical_or(tf.greater(eigen_ratio, 0.), tf.less(eigen_ratio, -500)), lambda: input_mat_clipped, lambda: tf.Print(",
            "input_mat_clipped, [tf.convert_to_tensor('screwed ratio ' + name + ' eigen values!!!'), tf.convert_to_tensor(var.name), eigen_min, eigen_max, eigen_ratio]))",
            "",
            "return input_mat_clipped"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8170,
        "label": "no",
        "change": [
            "def maskrcnn_loss(mask_logits, fg_labels, fg_target_masks):",
            "\"\"\"",
            "Args:",
            "mask_logits: #fg x #category xhxw",
            "-        fg_labels: #fg, in 1~#class",
            "+        fg_labels: #fg, in 1~#class, int64",
            "fg_target_masks: #fgxhxw, int",
            "\"\"\"",
            "-    num_fg = tf.size(fg_labels)",
            "-    indices = tf.stack([tf.range(num_fg), tf.to_int32(fg_labels) - 1], axis=1)  # #fgx2",
            "+    num_fg = tf.size(fg_labels, out_type=tf.int64)",
            "+    indices = tf.stack([tf.range(num_fg), fg_labels - 1], axis=1)  # #fgx2",
            "mask_logits = tf.gather_nd(mask_logits, indices)  # #fgxhxw",
            "mask_probs = tf.sigmoid(mask_logits)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8179,
        "label": "no",
        "change": [
            "class Graph(object):",
            "if relevant_nodes and in_node not in relevant_nodes:",
            "# node is not part of the current network",
            "continue",
            "-                    for in_layer in in_node.inbound_layers:",
            "+                    for in_layer in nest.flatten(in_node.inbound_layers):",
            "inbound_keras_node = Node.from_keras(in_layer)",
            "",
            "if (inbound_keras_node.id not in graph.nodes_by_id):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8185,
        "label": "no",
        "change": [
            "def main_fun(argv, ctx):",
            "saver = tf.train.Saver(tf.global_variables())",
            "",
            "# Build the summary operation from the last tower summaries.",
            "-      summary_op = tf.merge_summary(summaries)",
            "+      summary_op = tf.summary.merge(summaries)",
            "",
            "# Build an initialization operation to run below.",
            "init = tf.global_variables_initializer()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8194,
        "label": "no",
        "change": [
            "class LibrispeechLm(nlp.GeneratorBasedBuilder):",
            "\"\"\"Returns SplitGenerators.\"\"\"",
            "archive_path = dl_manager.download_and_extract(_DL_URL)",
            "return [",
            "-            nlp.SplitGenerator(name=nlp.Split.TRAIN, gen_kwargs={\"archive_path\": archive_path}),",
            "+            datasets.SplitGenerator(name=datasets.Split.TRAIN, gen_kwargs={\"archive_path\": archive_path}),",
            "]",
            "",
            "def _generate_examples(self, archive_path):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8195,
        "label": "no",
        "change": [
            "def to_list(x: Union[tf.Tensor, tf.Variable], /) -> list:",
            "def gather(",
            "params: Union[tf.Tensor, tf.Variable],",
            "indices: Union[tf.Tensor, tf.Variable],",
            "-    axis: Optional[int] = -1,",
            "+    /,",
            "*,",
            "+    axis: Optional[int] = -1,",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "axis = axis % len(indices.shape)",
            "-    return tf.gather(params, indices, axis=axis, batch_dims=axis)",
            "+    return tf.gather(params, indices, axis=axis, batch_dims=None)",
            "",
            "",
            "def gather_nd("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8199,
        "label": "no",
        "change": [
            "class Trainer:",
            "self.model = DDP(self.model, device_ids=[self.local_rank])",
            "",
            "def _load_snapshot(self, snapshot_path):",
            "-        snapshot = torch.load(snapshot_path)",
            "+        loc = f\"cuda:{self.gpu_id}\"",
            "+        snapshot = torch.load(snapshot_path, map_location=loc)",
            "self.model.load_state_dict(snapshot[\"MODEL_STATE\"])",
            "self.epochs_run = snapshot[\"EPOCHS_RUN\"]",
            "print(f\"Resuming training from snapshot at Epoch {self.epochs_run}\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8205,
        "label": "yes",
        "change": [
            "def model(y):",
            "# Vector of variances for each of the d variables",
            "theta = pyro.sample(\"theta\", dist.HalfCauchy(torch.ones(d, **options)))",
            "# Lower cholesky factor of a correlation matrix",
            "-    eta = torch.ones(1, **options)  # Implies a uniform distribution over correlation matrices",
            "-    L_omega = pyro.sample(\"L_omega\", dist.LKJCorrCholesky(d, eta))",
            "+    concentration = torch.ones((), **options)  # Implies a uniform distribution over correlation matrices",
            "+    L_omega = pyro.sample(\"L_omega\", dist.LKJCholesky(d, concentration))",
            "# Lower cholesky factor of the covariance matrix",
            "L_Omega = torch.mm(torch.diag(theta.sqrt()), L_omega)",
            "# For inference with SVI, one might prefer to use torch.bmm(theta.sqrt().diag_embed(), L_omega)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 8207,
        "label": "no",
        "change": [
            "class TestAugmentationSequential:",
            "points = torch.tensor([[[0.0, 0.0], [1.0, 1.0]]], device=device, dtype=dtype).expand(3, -1, -1)",
            "aug = K.AugmentationSequential(",
            "K.RandomCrop((3, 3), padding=1, cropping_mode='resample', fill=0),",
            "+            K.RandomAffine((360., 360.), p=1.),",
            "data_keys=[\"input\", \"mask\", \"bbox_xyxy\", \"keypoints\"],",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8208,
        "label": "no",
        "change": [
            "class MS_SSIMLoss(nn.Module):",
            "loss_l1 = F.l1_loss(img1, img2, reduction='none')",
            "",
            "# Compute average l1 loss in 3 channels",
            "-        gaussian_l1 = F.conv2d(loss_l1, g_masks[-CH:], groups=CH, padding=self.pad).mean(",
            "-            1",
            "-        )",
            "+        gaussian_l1 = F.conv2d(loss_l1, g_masks[-CH:], groups=CH, padding=self.pad).mean(1)",
            "",
            "# Compute MS-SSIM + L1 loss",
            "loss = self.alpha * loss_ms_ssim + (1 - self.alpha) * gaussian_l1 / self.DR"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8213,
        "label": "no",
        "change": [
            "def add_moving_summary(*args, **kwargs):",
            "ema_op = moving_averages.assign_moving_average(",
            "ema_var, c, decay,",
            "zero_debias=True, name=name + '_EMA_apply')",
            "-            tf.summary.scalar(name + '-summary', ema_op)    # write the EMA value as a summary",
            "ema_ops.append(ema_op)",
            "+        # cannot add it into colocate group -- will force everything to cpus",
            "+        tf.summary.scalar(name + '-summary', ema_op)    # write the EMA value as a summary",
            "if coll is not None:",
            "for op in ema_ops:",
            "# TODO a new collection to summary every step?"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8215,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)",
            "cost = tf.reduce_mean(cost, name='cross_entropy_loss')",
            "",
            "-        tf.reduce_mean(tf.to_float(tf.nn.in_top_k(logits, label, 1)), name='accuracy')",
            "+        tf.reduce_mean(tf.cast(tf.nn.in_top_k(logits, label, 1)), tf.float32, name='accuracy')",
            "",
            "wd_cost = tf.multiply(1e-5,",
            "regularize_cost('fc.*/W', tf.nn.l2_loss),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8216,
        "label": "no",
        "change": [
            "class YOLOX(SingleStageDetector):",
            "gt_bbox[..., 1::2] = gt_bbox[..., 1::2] * scale_y",
            "return img, gt_bboxes",
            "",
            "-    def _random_resize(self):",
            "-        tensor = torch.LongTensor(2).cuda()",
            "+    def _random_resize(self, device):",
            "+        tensor = torch.LongTensor(2).to(device)",
            "",
            "if self.rank == 0:",
            "size = random.randint(*self._random_size_range)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8234,
        "label": "no",
        "change": [
            "class TestPerspective:",
            "",
            "def test_smoke(self, device):",
            "x_data = torch.rand(1, 2, 3, 4).to(device)",
            "-        batch_prob = torch.rand(1) < 0.5",
            "+        batch_prob = torch.rand(1, device=device) < 0.5",
            "start_points = torch.rand(1, 4, 2).to(device)",
            "end_points = torch.rand(1, 4, 2).to(device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8238,
        "label": "no",
        "change": [
            "class Attention(BaseDenseAttention):",
            "# Reshape into [batch_size, 1, Tv, dim].",
            "k_reshaped = tf.expand_dims(key, axis=-3)",
            "if self.scale is not None:",
            "-        scores = self.attention_v * tf.reduce_sum(",
            "+        scores = self.concat_score_weight * tf.reduce_sum(",
            "tf.tanh(self.scale * (q_reshaped + k_reshaped)), axis=-1)",
            "else:",
            "-        scores = self.attention_v * tf.reduce_sum(",
            "+        scores = self.concat_score_weight * tf.reduce_sum(",
            "tf.tanh(q_reshaped + k_reshaped), axis=-1)",
            "",
            "return scores"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8240,
        "label": "no",
        "change": [
            "import pytest",
            "-",
            "-try:",
            "-    import torch",
            "-    from torch.autograd import Variable",
            "-except:",
            "-    pytest.skip(\"pytorch is not installed\")",
            "-",
            "+pytest.importorskip('torch')",
            "+import torch",
            "from e2e_asr_attctc_th import pad_list, mask_by_length"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8242,
        "label": "yes",
        "change": [
            "class DistilBertModelIntergrationTest(unittest.TestCase):",
            "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")",
            "input_ids = torch.tensor([[0, 345, 232, 328, 740, 140, 1695, 69, 6078, 1588, 2]])",
            "attention_mask = torch.tensor([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])",
            "-        output = model(input_ids, attention_mask=attention_mask)[0]",
            "+        with torch.no_grad():",
            "+            output = model(input_ids, attention_mask=attention_mask)[0]",
            "expected_shape = torch.Size((1, 11, 768))",
            "self.assertEqual(output.shape, expected_shape)",
            "expected_slice = torch.tensor("
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "state handling error",
        "Action": "addition",
        "Element": "api condition check"
    },
    {
        "number": 8243,
        "label": "no",
        "change": [
            "def model_fn(features, labels, mode, params):",
            "replica_cache_size = 300 * 1000000  # 300M per replica",
            "# Worker 0 caches all the TPU binaries.",
            "worker0_mem = replica_cache_size * ctx.num_replicas",
            "-        devices_memory_usage = [worker0_mem] + [0] * (num_hosts - 1)",
            "+        devices_memeory_usage = [worker0_mem] + [0] * (num_hosts - 1)",
            "var_placer = mtf.utils.BalancedVariablePlacer(device_list,",
            "-                                                      devices_memory_usage)",
            "+                                                      devices_memeory_usage)",
            "mesh_devices = [''] * mesh_shape.size",
            "mesh_impl = mtf.simd_mesh_impl.SimdMeshImpl(",
            "mesh_shape, layout_rules, mesh_devices, ctx.device_assignment)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8244,
        "label": "no",
        "change": [
            "def test_batch():",
            "",
            "data_list = batch.to_data_list()",
            "assert len(data_list) == 2",
            "-    assert len(data_list[0]) == 4",
            "+    assert len(data_list[0]) == 3",
            "assert data_list[0].x.tolist() == [1, 2, 3]",
            "assert data_list[0].edge_index.tolist() == [[0, 1, 1, 2], [1, 0, 2, 1]]",
            "assert data_list[0].s == '1'"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8245,
        "label": "no",
        "change": [
            "from ...proto.lib.torch.tensor_pb2 import TensorData",
            "",
            "",
            "def object2proto(obj: np.ndarray) -> TensorData:",
            "-    tensor = torch.Tensor(obj)",
            "+    tensor = torch.from_numpy(obj).clone()",
            "tensor_proto = protobuf_tensor_serializer(tensor)",
            "",
            "return tensor_proto"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8246,
        "label": "no",
        "change": [
            "class TestMeshes(TestCaseMixin, unittest.TestCase):",
            "# Multiple meshes in the batch with equal sized meshes",
            "meshes_extended = mesh.extend(3)",
            "for m in meshes_extended.verts_normals_list():",
            "-            self.assertTrue(torch.allclose(m, verts_normals_expected))",
            "+            self.assertClose(m, verts_normals_expected)",
            "for f in meshes_extended.faces_normals_list():",
            "-            self.assertTrue(torch.allclose(f, faces_normals_expected))",
            "+            self.assertClose(f, faces_normals_expected)",
            "",
            "# Multiple meshes in the batch with different sized meshes",
            "# Check padded and packed normals are the correct sizes."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8248,
        "label": "no",
        "change": [
            "def homography_i_H_ref(pinhole_i, pinhole_ref):",
            "i_pose_base = get_optical_pose_base(pinhole_i)",
            "ref_pose_base = get_optical_pose_base(pinhole_ref)",
            "i_pose_ref = torch.matmul(i_pose_base, inverse_pose(ref_pose_base))",
            "-    return torch.matmul(pinhole_matrix(pinhole_i), \\",
            "-        torch.matmul(i_pose_ref, inv_pinhole_matrix(pinhole_ref)))",
            "+    return torch.matmul(",
            "+        pinhole_matrix(pinhole_i),",
            "+        torch.matmul(",
            "+            i_pose_ref,",
            "+            inv_pinhole_matrix(pinhole_ref)))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8249,
        "label": "no",
        "change": [
            "def batch_dot(x, y, axes=None):",
            "axes = (axes, axes)",
            "x_ndim = ndim(x)",
            "y_ndim = ndim(y)",
            "+    if axes is None:",
            "+        # behaves like tf.batch_matmul as default",
            "+        axes = [x_ndim - 1, y_ndim - 2]",
            "if x_ndim > y_ndim:",
            "diff = x_ndim - y_ndim",
            "y = tf.reshape(y, tf.concat([tf.shape(y), [1] * (diff)], axis=0))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8251,
        "label": "no",
        "change": [
            "class TestSinusoidalPositionalEmbeddings(unittest.TestCase):",
            "# test that forward pass is just a lookup, there is no ignore padding logic",
            "input_ids = torch.tensor([[4, 10, pad, pad, pad]], dtype=torch.long, device=torch_device)",
            "no_cache_pad_zero = emb1(input_ids)",
            "-        self.assertTrue(torch.allclose(torch.Tensor(self.desired_weights), no_cache_pad_zero[:3, :5], atol=1e-3))",
            "+        self.assertTrue(",
            "+            torch.allclose(",
            "+                torch.tensor(self.desired_weights, device=torch_device), no_cache_pad_zero[:3, :5], atol=1e-3",
            "+            )",
            "+        )"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8255,
        "label": "no",
        "change": [
            "def linspace_helper(start, stop, num, axis=None, *, dtype=None, device):",
            "",
            "",
            "def meshgrid(",
            "-    *arrays: torch.Tensor, sparse: bool = False, indexing=\"xy\"",
            "+    *arrays: torch.Tensor,",
            "+    sparse: bool = False,",
            "+    indexing: str = \"xy\",",
            ") -> List[torch.Tensor]:",
            "if not sparse:",
            "return list(torch.meshgrid(*arrays, indexing=indexing))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8256,
        "label": "no",
        "change": [
            "def train(args):",
            "rnnlm = lm_pytorch.ClassifierWithState(",
            "lm_pytorch.RNNLM(",
            "len(args.char_list), rnnlm_args.layer, rnnlm_args.unit))",
            "-        torch.load(args.rnnlm, rnnlm)",
            "+        torch_load(args.rnnlm, rnnlm)",
            "model.rnnlm = rnnlm",
            "",
            "# write model config"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8259,
        "label": "yes",
        "change": [
            "class Model(object):",
            "else:",
            "assert not config.global_model and config.session is None",
            "tf.reset_default_graph()",
            "-            self.session = tf.Session()",
            "+            self.session = config.session = tf.Session()",
            "",
            "if config.distributed and not config.global_model:",
            "# Global and local model for asynchronous updates"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 8261,
        "label": "no",
        "change": [
            "class PipelineTesterMixin(unittest.TestCase):",
            "image_slice = image[0, -1, -3:, -3:].cpu()",
            "",
            "assert image.shape == (1, 3, 32, 32)",
            "-        expected_slice = torch.tensor([-0.7688, -0.7690, -0.7597, -0.7660, -0.7713, -0.7531, -0.7009, -0.7098, -0.7350])",
            "+        expected_slice = torch.tensor([-0.7383, -0.7385, -0.7298, -0.7364, -0.7414, -0.7239, -0.6737, -0.6813, -0.7068])",
            "assert (image_slice.flatten() - expected_slice).abs().max() < 1e-2"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8270,
        "label": "no",
        "change": [
            "def freeze_variables():",
            "with varreplace.freeze_variable():",
            "x = FullyConnected('fc', x, 1000)   # fc/* will not be trained",
            "\"\"\"",
            "-    return remap_variables(lambda v: tf.stop_gradient(v))",
            "+    def custom_getter(getter, *args, **kwargs):",
            "+        v = getter(*args, **kwargs)",
            "+        if kwargs.pop('trainable', True):",
            "+            v = tf.stop_gradient(v)",
            "+        return v",
            "+    return custom_getter_scope(custom_getter)",
            "",
            "",
            "@deprecated(\"Renamed to remap_variables\", \"2017-11-06\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8273,
        "label": "yes",
        "change": [
            "def test(loader):",
            "target = batch['user', 'item'].edge_label.long().cpu()",
            "",
            "preds.append(pred)",
            "-        targets.append(pred)",
            "+        targets.append(target)",
            "",
            "pred = torch.cat(preds, dim=0).numpy()",
            "-    target = torch.cat(target, dim=0).numpy()",
            "+    target = torch.cat(targets, dim=0).numpy()",
            "",
            "+    pred = pred > 0.5",
            "acc = accuracy_score(target, pred)",
            "prec = precision_score(target, pred)",
            "rec = recall_score(target, pred)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 8275,
        "label": "no",
        "change": [
            "class MaskedMixture(TorchDistribution):",
            "arg_constraints = {}  # nothing can be constrained",
            "",
            "def __init__(self, mask, component0, component1, validate_args=None):",
            "-        if not torch.is_tensor(mask) or mask.dtype != torch.uint8:",
            "-            raise ValueError('Expected mask to be a ByteTensor but got {}'.format(type(mask)))",
            "+        if not torch.is_tensor(mask) or mask.dtype != torch.bool:",
            "+            raise ValueError('Expected mask to be a BoolTensor but got {}'.format(type(mask)))",
            "if component0.event_shape != component1.event_shape:",
            "raise ValueError('components event_shape disagree: {} vs {}'",
            ".format(component0.event_shape, component1.event_shape))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8276,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "decoded_boxes = decode_bbox_target(",
            "fastrcnn_box_logits /",
            "tf.constant(config.FASTRCNN_BBOX_REG_WEIGHTS), anchors)",
            "-            decoded_boxes = clip_boxes(decoded_boxes, tf.shape(image)[:2], name='fastrcnn_all_boxes')",
            "+            decoded_boxes = clip_boxes(decoded_boxes, image_shape2d, name='fastrcnn_all_boxes')",
            "",
            "# indices: Nx2. Each index into (#proposal, #category)",
            "pred_indices, final_probs = fastrcnn_predictions(decoded_boxes, label_probs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8280,
        "label": "no",
        "change": [
            "class AttentionRNNCell(nn.Module):",
            "out_dim (int): context vector feature dimension.",
            "rnn_dim (int): rnn hidden state dimension.",
            "annot_dim (int): annotation vector feature dimension.",
            "-            memory_dim (int): memory vector (decoder autogression) feature dimension.",
            "+            memory_dim (int): memory vector (decoder output) feature dimension.",
            "align_model (str): 'b' for Bahdanau, 'ls' Location Sensitive alignment.",
            "\"\"\"",
            "super(AttentionRNNCell, self).__init__()",
            "self.align_model = align_model",
            "-        self.rnn_cell = nn.GRUCell(out_dim + memory_dim, rnn_dim)",
            "+        self.rnn_cell = nn.GRUCell(annot_dim + memory_dim, rnn_dim)",
            "# pick bahdanau or location sensitive attention",
            "if align_model == 'b':",
            "-            self.alignment_model = BahdanauAttention(annot_dim, out_dim, out_dim)",
            "+            self.alignment_model = BahdanauAttention(annot_dim, rnn_dim, out_dim)",
            "if align_model == 'ls':",
            "self.alignment_model = LocationSensitiveAttention(annot_dim, rnn_dim, out_dim)",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8282,
        "label": "no",
        "change": [
            "def create_random_homography(batch_size, eye_size, std_val=1e-3):",
            "return eye + std.uniform_(-std_val, std_val)",
            "",
            "",
            "-def tensor_to_gradcheck_var(tensor):",
            "+def tensor_to_gradcheck_var(tensor, dtype=torch.float64, requires_grad=True):",
            "\"\"\"Converts the input tensor to a valid variable to check the gradient.",
            "`gradcheck` needs 64-bit floating point and requires gradient.",
            "\"\"\"",
            "assert torch.is_tensor(tensor), type(tensor)",
            "-    return tensor.requires_grad_(True).type(torch.DoubleTensor)",
            "+    return tensor.requires_grad_(requires_grad).type(dtype)",
            "",
            "",
            "def compute_mse(x, y):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8283,
        "label": "yes",
        "change": [
            "from ray.rllib.optimizers import SampleBatch, TFMultiGPUSupport",
            "class DQNEvaluator(TFMultiGPUSupport):",
            "\"\"\"The base DQN Evaluator that does not include the replay buffer.\"\"\"",
            "",
            "-    def __init__(self, env_creator, config, logdir):",
            "+    def __init__(self, registry, env_creator, config, logdir):",
            "env = env_creator()",
            "-        env = wrap_dqn(env, config[\"model\"])",
            "+        env = wrap_dqn(registry, env, config[\"model\"])",
            "self.env = env",
            "self.config = config",
            "",
            "tf_config = tf.ConfigProto(**config[\"tf_session_args\"])",
            "self.sess = tf.Session(config=tf_config)",
            "-        self.dqn_graph = models.DQNGraph(env, config, logdir)",
            "+        self.dqn_graph = models.DQNGraph(registry, env, config, logdir)",
            "",
            "# Create the schedule for exploration starting from 1.",
            "self.exploration = LinearSchedule("
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 8286,
        "label": "no",
        "change": [
            "class HungarianAssigner(BaseAssigner):",
            "return AssignResult(",
            "num_gts, assigned_gt_inds, None, labels=assigned_labels)",
            "img_h, img_w, _ = img_meta['img_shape']",
            "-        factor = torch.Tensor([img_w, img_h, img_w,",
            "-                               img_h]).unsqueeze(0).to(gt_bboxes.device)",
            "+        factor = gt_bboxes.new_tensor([img_w, img_h, img_w,",
            "+                                       img_h]).unsqueeze(0)",
            "",
            "# 2. compute the weighted costs",
            "# classification and bboxcost."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8292,
        "label": "no",
        "change": [
            "def Conv2DTranspose(",
            "shape4d(strides, data_format=data_format),",
            "padding=padding.upper(),",
            "data_format=data_format)",
            "-        conv.set_shape(tf.TensorShape([None] + out_shape3_sta))",
            "+        conv.set_shape(tf.TensorShape([shape_sta[0]] + out_shape3_sta))",
            "",
            "ret = tf.nn.bias_add(conv, b, data_format=data_format) if use_bias else conv",
            "if activation is not None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8296,
        "label": "yes",
        "change": [
            "def ctc_label_dense_to_sparse(labels, label_lengths):",
            "max_num_labels_tns = tf.pack([label_shape[1]])",
            "",
            "def range_less_than(previous_state, current_input):",
            "-        return tf.expand_dims(tf.range(label_shape[1]), 0) < current_input",
            "+        return tf.expand_dims(tf.range(label_shape[1]), 0) < tf.fill(max_num_labels_tns, current_input)",
            "",
            "-    init = tf.cast(tf.fill(max_num_labels_tns, 0), tf.bool)",
            "+    init = tf.cast(tf.fill([1, label_shape[1]], 0), tf.bool)",
            "dense_mask = functional_ops.scan(range_less_than, label_lengths,",
            "initializer=init, parallel_iterations=1)",
            "dense_mask = dense_mask[:, 0, :]"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 8298,
        "label": "no",
        "change": [
            "def test_frontend_function(",
            "# strip the decorator to get an Ivy array",
            "# ToDo, fix testing for jax frontend for x32",
            "if frontend == \"jax\":",
            "-            importlib.import_module(",
            "-                'ivy.functional.frontends.jax').config.update('jax_enable_x64', True)",
            "+            importlib.import_module(\"ivy.functional.frontends.jax\").config.update(",
            "+                \"jax_enable_x64\", True",
            "+            )",
            "ret = get_frontend_ret(frontend_fn, *args_ivy, **kwargs_ivy)",
            "if with_out:",
            "if not inspect.isclass(ret):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8304,
        "label": "yes",
        "change": [
            "class PreTrainedModel(nn.Module, ModuleUtilsMixin, GenerationMixin, PushToHubMix",
            ")",
            "",
            "# Build new embeddings",
            "-        new_embeddings = nn.Embedding(new_num_tokens, old_embedding_dim).to(self.device)",
            "+        new_embeddings = nn.Embedding(new_num_tokens, old_embedding_dim).to(",
            "+            self.device, dtype=old_embeddings.weight.dtype",
            "+        )",
            "",
            "# initialize all new embeddings (in particular added tokens)",
            "self._init_weights(new_embeddings)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 8306,
        "label": "no",
        "change": [
            "class CrfTagger(Model):",
            "if tags is not None:",
            "# Add negative log-likelihood as loss",
            "log_likelihood = self.crf(logits, tags, mask)",
            "-            output[\"loss\"] = -log_likelihood",
            "+",
            "+            # It's not clear why, but pylint seems to think `log_likelihood` is tuple",
            "+            # (in fact, it's a torch.Tensor), so we need a disable.",
            "+            output[\"loss\"] = -log_likelihood  # pylint: disable=invalid-unary-operand-type",
            "",
            "# Represent viterbi tags as \"class probabilities\" that we can",
            "# feed into the metrics"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8311,
        "label": "yes",
        "change": [
            "def resize_images(X, height_factor, width_factor, dim_ordering):",
            "positive integers.",
            "'''",
            "if dim_ordering == 'th':",
            "+        original_shape = int_shape(X)",
            "new_shape = tf.shape(X)[2:]",
            "new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))",
            "X = permute_dimensions(X, [0, 2, 3, 1])",
            "X = tf.image.resize_nearest_neighbor(X, new_shape)",
            "-        return permute_dimensions(X, [0, 3, 1, 2])",
            "+        X = permute_dimensions(X, [0, 3, 1, 2])",
            "+        X.set_shape((None, None, original_shape[2] * height_factor, original_shape[3] * width_factor))",
            "+        return X",
            "elif dim_ordering == 'tf':",
            "+        original_shape = int_shape(X)",
            "new_shape = tf.shape(X)[1:3]",
            "new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))",
            "-        return tf.image.resize_nearest_neighbor(X, new_shape)",
            "+        X = tf.image.resize_nearest_neighbor(X, new_shape)",
            "+        X.set_shape((None, original_shape[1] * height_factor, original_shape[2] * width_factor, None))",
            "+        return X",
            "else:",
            "raise Exception('Invalid dim_ordering: ' + dim_ordering)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 8314,
        "label": "yes",
        "change": [
            "def _torch_solve_cast(input: torch.Tensor, A: torch.Tensor) -> Tuple[torch.Tenso",
            "if dtype not in (torch.float32, torch.float64):",
            "dtype = torch.float32",
            "",
            "-    out1, out2 = torch.solve(input.to(dtype), A.to(dtype))",
            "+    out = solve(A.to(dtype), input.to(dtype))",
            "",
            "-    return (out1.to(input.dtype), out2.to(input.dtype))",
            "+    return (out.to(input.dtype), out)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 8315,
        "label": "no",
        "change": [
            "class Mutator(BaseMutator):",
            "\"\"\"",
            "if self._connect_all:",
            "return self._all_connect_tensor_reduction(mutable.reduction, tensor_list), \\",
            "-                torch.ones(mutable.n_candidates)",
            "+                torch.ones(mutable.n_candidates).bool()",
            "mask = self._get_decision(mutable)",
            "assert len(mask) == mutable.n_candidates, \\",
            "\"Invalid mask, expected {} to be of length {}.\".format(mask, mutable.n_candidates)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8319,
        "label": "yes",
        "change": [
            "class BaseModel():",
            "save_filename = '%s_net_%s.pth' % (which_epoch, name)",
            "save_path = os.path.join(self.save_dir, save_filename)",
            "net = getattr(self, 'net' + name)",
            "-                torch.module.save(net.cpu().state_dict(), save_path)",
            "+                torch.save(net.module.cpu().state_dict(), save_path)",
            "if len(self.gpu_ids) and torch.cuda.is_available():",
            "net.cuda(self.gpu_ids[0])"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 8321,
        "label": "no",
        "change": [
            "class SimpleSeq2SeqWithoutAttentionTest(ModelTestCase):",
            "batch_size = 5",
            "num_decoding_steps = 5",
            "num_classes = 10",
            "-        sample_logits = Variable(torch.randn(batch_size, num_decoding_steps-1, num_classes))",
            "-        sample_targets = Variable(torch.from_numpy(numpy.random.randint(0, num_classes,",
            "-                                                                        (batch_size, num_decoding_steps))))",
            "+        sample_logits = torch.randn(batch_size, num_decoding_steps-1, num_classes)",
            "+        sample_targets = torch.from_numpy(numpy.random.randint(0, num_classes,",
            "+                                                               (batch_size, num_decoding_steps)))",
            "# Mask should be either 0 or 1",
            "-        sample_mask = Variable(torch.from_numpy(numpy.random.randint(0, 2,",
            "-                                                                     (batch_size, num_decoding_steps))))",
            "+        sample_mask = torch.from_numpy(numpy.random.randint(0, 2,",
            "+                                                            (batch_size, num_decoding_steps)))",
            "expected_loss = sequence_cross_entropy_with_logits(sample_logits, sample_targets[:, 1:].contiguous(),",
            "sample_mask[:, 1:].contiguous())",
            "# pylint: disable=protected-access"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8327,
        "label": "no",
        "change": [
            "def median_blur(input: torch.Tensor,",
            "b, c, h, w = input.shape",
            "",
            "# map the local window to single vector",
            "-    features: torch.Tensor = F.conv2d(",
            "-        input.reshape(b * c, 1, h, w), kernel, padding=padding, stride=1)",
            "+    features: torch.Tensor = F.conv2d(input.reshape(b * c, 1, h, w), kernel, padding=padding, stride=1)",
            "features = features.view(b, c, -1, h, w)  # BxCx(K_h * K_w)xHxW",
            "",
            "# compute the median along the feature axis"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8329,
        "label": "no",
        "change": [
            "def huber_loss(y_true, y_pred, clip_value):",
            "# Spacial case for infinity since Tensorflow does have problems",
            "# if we compare `K.abs(x) < np.inf`.",
            "return .5 * K.square(x)",
            "-",
            "+",
            "condition = K.abs(x) < clip_value",
            "squared_loss = .5 * K.square(x)",
            "linear_loss = clip_value * (K.abs(x) - .5 * clip_value)",
            "if K._BACKEND == 'tensorflow':",
            "import tensorflow as tf",
            "-        return tf.select(condition, squared_loss, linear_loss)  # condition, true, false",
            "+        return tf.where(condition, squared_loss, linear_loss)  # condition, true, false",
            "elif K._BACKEND == 'theano':",
            "from theano import tensor as T",
            "return T.switch(condition, squared_loss, linear_loss)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8332,
        "label": "no",
        "change": [
            "class TestIncrementalDecoder(FairseqIncrementalDecoder):",
            "probs[:, i, self.dictionary.eos()] = 1.0",
            "",
            "# random attention",
            "-        attn = torch.rand(bbsz, src_len, tgt_len)",
            "+        attn = torch.rand(bbsz, tgt_len, src_len)",
            "",
            "return Variable(probs), Variable(attn)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8337,
        "label": "no",
        "change": [
            "def read_file(folder, prefix, name, dtype=None):",
            "def cat(seq):",
            "seq = [item for item in seq if item is not None]",
            "seq = [item.unsqueeze(-1) if item.dim() == 1 else item for item in seq]",
            "-    return torch.cat(seq, dim=-1).squeeze() if len(seq) > 0 else None",
            "+    return torch.cat(seq, dim=-1) if len(seq) > 0 else None",
            "",
            "",
            "def split(data, batch):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8347,
        "label": "no",
        "change": [
            "class TextSimilarityHead(PredictionHead):",
            "",
            "# Check if DDP is initialized",
            "try:",
            "-            rank = torch.distributed.get_rank()",
            "+            if torch.distributed.is_available():",
            "+                rank = torch.distributed.get_rank()",
            "+            else:",
            "+                rank = -1",
            "except (AssertionError, RuntimeError):",
            "rank = -1"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8351,
        "label": "no",
        "change": [
            "class DecoderLayer(nn.Module):",
            "self.norm1 = LayerNorm(size)",
            "self.norm2 = LayerNorm(size)",
            "self.norm3 = LayerNorm(size)",
            "-        self.dropout = nn.Dropout(dropout)",
            "+        self.dropout = nn.Dropout(dropout_rate)",
            "",
            "def forward(self, tgt, tgt_mask, memory, memory_mask):",
            "\"\"\"Compute decoded features"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8355,
        "label": "no",
        "change": [
            "def train(hyp,  # path/to/hyp.yaml or hyp dictionary",
            "for v in model.modules():",
            "if hasattr(v, 'bias') and isinstance(v.bias, nn.Parameter):  # bias",
            "g2.append(v.bias)",
            "-        if isinstance(v, nn.BatchNorm2d):  # weight with decay",
            "+        if isinstance(v, nn.BatchNorm2d):  # weight (no decay)",
            "g0.append(v.weight)",
            "-        elif hasattr(v, 'weight') and isinstance(v.weight, nn.Parameter):  # weight without decay",
            "+        elif hasattr(v, 'weight') and isinstance(v.weight, nn.Parameter):  # weight (with decay)",
            "g1.append(v.weight)",
            "",
            "if opt.adam:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8358,
        "label": "yes",
        "change": [
            "def clip(",
            "*,",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "+    assert tf.reduce_all(tf.less(x_min, x_max)), \"Min value must be less than max.\"",
            "if hasattr(x_min, \"dtype\") and hasattr(x_max, \"dtype\"):",
            "promoted_type = tf.experimental.numpy.promote_types(x.dtype, x_min.dtype)",
            "promoted_type = tf.experimental.numpy.promote_types(promoted_type, x_max.dtype)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "addition",
        "Element": "api condition check"
    },
    {
        "number": 8359,
        "label": "no",
        "change": [
            "logger = logging.getLogger(__name__)",
            "LONGFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP = {",
            "\"longformer-base-4096\": \"https://s3.amazonaws.com/models.huggingface.co/bert/allenai/longformer-base-4096/config.json\",",
            "\"longformer-large-4096\": \"https://s3.amazonaws.com/models.huggingface.co/bert/allenai/longformer-large-4096/config.json\",",
            "+    \"longformer-large-4096-finetuned-triviaqa\": \"https://s3.amazonaws.com/models.huggingface.co/bert/allenai/longformer-large-4096-finetuned-triviaqa/config.json\",",
            "}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8362,
        "label": "no",
        "change": [
            "class Categorical(TFActionDistribution):",
            "",
            "@override(TFActionDistribution)",
            "def _build_sample_op(self):",
            "-        return tf.squeeze(tf.multinomial(self.inputs, 1), axis=1)",
            "+        return tf.squeeze(tf.random.categorical(self.inputs, 1), axis=1)",
            "",
            "@staticmethod",
            "@override(ActionDistribution)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8363,
        "label": "no",
        "change": [
            "def fc(x, weights, biases=None):",
            "isinstance(weights, torch.Tensor) else weights",
            "biases = biases.detach().numpy() if \\",
            "isinstance(biases, torch.Tensor) else biases",
            "-    if tf:",
            "+    if tf and tf.executing_eagerly():",
            "x = x.numpy() if isinstance(x, tf.Variable) else x",
            "weights = weights.numpy() if isinstance(weights, tf.Variable) else \\",
            "weights"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8365,
        "label": "no",
        "change": [
            "class SpeakerManager:",
            "waveform = self.speaker_encoder_ap.load_wav(wav_file, sr=self.speaker_encoder_ap.sample_rate)",
            "if not self.speaker_encoder_config.model_params.get(\"use_torch_spec\", False):",
            "m_input = self.speaker_encoder_ap.melspectrogram(waveform)",
            "-                m_input = torch.from_numpy(m_input.T)",
            "+                m_input = torch.from_numpy(m_input)",
            "else:",
            "m_input = torch.from_numpy(waveform)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8374,
        "label": "no",
        "change": [
            "class CheckpointFunction(torch.autograd.Function):",
            "tensor_inputs = checkpoint.detach_variable(tensor_inputs)",
            "if ctx.fwd_device is not None:",
            "tensor_inputs = [",
            "-                t.to(ctx.fwd_device[i], non_blocking=True) for i, t in enumerate(tensor_inputs)",
            "+                t.to(ctx.fwd_device[i], non_blocking=True)",
            "+                for i, t in enumerate(tensor_inputs)",
            "]",
            "for i, need_grad in enumerate(ctx.grad_requirements):",
            "tensor_inputs[i].requires_grad = need_grad"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8377,
        "label": "no",
        "change": [
            "def kaiser_window(",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "if periodic is False:",
            "return tf.signal.kaiser_window(",
            "-            window_length, beta, dtype=tf.dtypes.float32, name=None)",
            "-    else:",
            "-        return tf.signal.kaiser_window(",
            "-            window_length + 1, beta, dtype=dtype, name=None)[:-1]",
            "+            window_length, beta, dtype=tf.dtypes.float32, name=None",
            "+        )",
            "+    else:",
            "+        return tf.signal.kaiser_window(window_length + 1, beta, dtype=dtype, name=None)[",
            "+            :-1",
            "+        ]",
            "",
            "",
            "def moveaxis("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8382,
        "label": "no",
        "change": [
            "def main():",
            "model = create_model(num_classes=num_classes + 1, box_thresh=box_thresh)",
            "",
            "# load train weights",
            "-    assert os.path.exists(weight_path), \"{} file dose not exist.\".format(weight_path)",
            "-    model.load_state_dict(torch.load(weight_path, map_location='cpu')[\"model\"])",
            "+    assert os.path.exists(weights_path), \"{} file dose not exist.\".format(weights_path)",
            "+    model.load_state_dict(torch.load(weights_path, map_location='cpu')[\"model\"])",
            "model.to(device)",
            "",
            "# read class_indict"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8385,
        "label": "yes",
        "change": [
            "class DiceCoeff(Function):",
            "",
            "def forward(self, input, target):",
            "self.save_for_backward(input, target)",
            "-        self.inter = torch.dot(input.view(-1), target.view(-1)) + 0.0001",
            "-        self.union = torch.sum(input) + torch.sum(target) + 0.0001",
            "+        eps = 0.0001",
            "+        self.inter = torch.dot(input.view(-1), target.view(-1))",
            "+        self.union = torch.sum(input) + torch.sum(target) + eps",
            "",
            "-        t = 2 * self.inter.float() / self.union.float()",
            "+        t = (2 * self.inter.float() + eps) / self.union.float()",
            "return t",
            "",
            "# This function has only a single output, so it gets only one gradient"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 8388,
        "label": "no",
        "change": [
            "def FullyConnected(x, out_dim, W_init=None, b_init=None, nl=tf.nn.relu):",
            "",
            "W = tf.get_variable('W', [in_dim, out_dim], initializer=W_init)",
            "b = tf.get_variable('b', [out_dim], initializer=b_init)",
            "-    return nl(tf.matmul(x, W) + b)",
            "+    return nl(tf.matmul(x, W) + b, name=tf.get_variable_scope().name + '_output')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8390,
        "label": "no",
        "change": [
            "class TFWhisperPreTrainedModel(TFPreTrainedModel):",
            "self.main_input_name: tf.random.uniform(",
            "[2, self.config.num_mel_bins, self.config.max_source_positions * 2 - 1], dtype=tf.float32",
            "),",
            "-            \"decoder_input_ids\": tf.constant([[2, 3]], dtype=tf.int64),",
            "+            \"decoder_input_ids\": tf.constant([[2, 3]], dtype=tf.int32),",
            "}",
            "",
            "@tf.function(",
            "input_signature=[",
            "{",
            "\"input_features\": tf.TensorSpec((None, None, None), tf.float32, name=\"input_features\"),",
            "-                \"decoder_input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"decoder_input_ids\"),",
            "-                \"decoder_attention_mask\": tf.TensorSpec((None, None), tf.int64, name=\"decoder_attention_mask\"),",
            "+                \"decoder_input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"decoder_input_ids\"),",
            "+                \"decoder_attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"decoder_attention_mask\"),",
            "}",
            "]",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8393,
        "label": "no",
        "change": [
            "class ValTransform:",
            "# assume input is cv2 img for now",
            "def __call__(self, img, res, input_size):",
            "img, _ = preproc(img, input_size, self.means, self.std, self.swap)",
            "-        return torch.tensor_as(img), torch.zeros(1, 5)",
            "+        return torch.as_tensor(img), torch.zeros(1, 5)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8394,
        "label": "yes",
        "change": [
            "def cross_entropy_seq(logits, target_seqs):#, batch_size=1, num_steps=None):",
            "loss = sequence_loss_by_example_fn(",
            "[logits],",
            "[tf.reshape(target_seqs, [-1])],",
            "-        [tf.ones_like(tf.reshape(targets, [-1]), dtype=tf.float32)])",
            "+        [tf.ones_like(tf.reshape(target_seqs, [-1]), dtype=tf.float32)])",
            "# [tf.ones([batch_size * num_steps])])",
            "-    cost = tf.reduce_sum(loss) / batch_size",
            "+    cost = tf.reduce_sum(loss) #/ batch_size",
            "return cost"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 8395,
        "label": "no",
        "change": [
            "class ForwardTTS(BaseTTS):",
            "# init speaker embedding layer",
            "if config.use_speaker_embedding and not config.use_d_vector_file:",
            "print(\" > Init speaker_embedding layer.\")",
            "-            self.emb_g = nn.Embedding(self.args.num_speakers, self.args.hidden_channels)",
            "+            self.emb_g = nn.Embedding(self.num_speakers, self.args.hidden_channels)",
            "nn.init.uniform_(self.emb_g.weight, -0.1, 0.1)",
            "",
            "@staticmethod"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8396,
        "label": "no",
        "change": [
            "class LegacyAttention(Attention):",
            "self._similarity_function = similarity_function or DotProductSimilarity()",
            "",
            "@overrides",
            "-    def _forward_internal(self,",
            "-                          vector: torch.Tensor,",
            "-                          matrix: torch.Tensor,",
            "-                          matrix_mask: torch.Tensor = None) -> torch.Tensor:",
            "+    def _forward_internal(self, vector: torch.Tensor, matrix: torch.Tensor) -> torch.Tensor:",
            "tiled_vector = vector.unsqueeze(1).expand(vector.size()[0],",
            "matrix.size()[1],",
            "vector.size()[1])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8402,
        "label": "no",
        "change": [
            "def stylize(args):",
            "style_model.to(device)",
            "if args.export_onnx:",
            "assert args.export_onnx.endswith(\".onnx\"), \"Export model file should end with .onnx\"",
            "-                output = torch.onnx._export(style_model, content_image, args.export_onnx)",
            "+                output = torch.onnx._export(style_model, content_image, args.export_onnx).cpu()",
            "else:",
            "output = style_model(content_image).cpu()",
            "utils.save_image(args.output_image, output[0])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8407,
        "label": "no",
        "change": [
            "class abstractclassmethod(classmethod):  # pylint: disable=invalid-name",
            "super(abstractclassmethod, self).__init__(fn)",
            "",
            "",
            "-def get_nlp_path(relative_path):",
            "-    \"\"\"Returns absolute path to file given path relative to nlp root.\"\"\"",
            "-    path = os.path.join(nlp_dir(), relative_path)",
            "+def get_datasets_path(relative_path):",
            "+    \"\"\"Returns absolute path to file given path relative to datasets root.\"\"\"",
            "+    path = os.path.join(datasets_dir(), relative_path)",
            "return path"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8410,
        "label": "no",
        "change": [
            "def get_masks(slen, lengths, causal, padding_mask=None):",
            "mask = padding_mask",
            "else:",
            "# assert lengths.max().item() <= slen",
            "-        alen = tf.range(slen)",
            "-        mask = tf.math.less(alen, tf.expand_dims(lengths, axis=1))",
            "+        alen = tf.range(slen, dtype=lengths.dtype)",
            "+        mask = alen < tf.expand_dims(lengths, axis=1)",
            "",
            "# attention mask is the same as mask, or triangular inferior attention (causal)",
            "if causal:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8412,
        "label": "no",
        "change": [
            "from .modeling_roberta import (",
            "logger = logging.getLogger(__name__)",
            "",
            "CAMEMBERT_PRETRAINED_MODEL_ARCHIVE_MAP = {",
            "-    \"camembert-base\": \"https://s3.amazonaws.com/models.huggingface.co/bert/camembert-base-pytorch_model.bin\",",
            "-    \"umberto-commoncrawl-cased-v1\": \"https://s3.amazonaws.com/models.huggingface.co/bert/Musixmatch/umberto-commoncrawl-cased-v1/pytorch_model.bin\",",
            "-    \"umberto-wikipedia-uncased-v1\": \"https://s3.amazonaws.com/models.huggingface.co/bert/Musixmatch/umberto-wikipedia-uncased-v1/pytorch_model.bin\",",
            "+    \"camembert-base\": \"https://cdn.huggingface.co/camembert-base-pytorch_model.bin\",",
            "+    \"umberto-commoncrawl-cased-v1\": \"https://cdn.huggingface.co/Musixmatch/umberto-commoncrawl-cased-v1/pytorch_model.bin\",",
            "+    \"umberto-wikipedia-uncased-v1\": \"https://cdn.huggingface.co/Musixmatch/umberto-wikipedia-uncased-v1/pytorch_model.bin\",",
            "}",
            "",
            "CAMEMBERT_START_DOCSTRING = r\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8428,
        "label": "no",
        "change": [
            "class SpanBasedF1Measure(Metric):",
            "possible roles associated with it).",
            "\"\"\"",
            "if mask is None:",
            "-            mask = ones_like(gold_labels)",
            "-        # Get the data from the Variables.",
            "+            mask = torch.ones_like(gold_labels)",
            "+",
            "predictions, gold_labels, mask, prediction_map = self.unwrap_to_tensors(predictions,",
            "gold_labels,",
            "mask, prediction_map)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8429,
        "label": "no",
        "change": [
            "def interpolate_vocoder_input(scale_factor, spec):",
            "torch.tensor: interpolated spectrogram.",
            "\"\"\"",
            "print(\" > before interpolation :\", spec.shape)",
            "-    spec = torch.tensor(spec).unsqueeze(0).unsqueeze(0)",
            "+    spec = torch.tensor(spec).unsqueeze(0).unsqueeze(0)  # pylint: disable=not-callable",
            "spec = torch.nn.functional.interpolate(spec,",
            "scale_factor=scale_factor,",
            "recompute_scale_factor=True,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8431,
        "label": "no",
        "change": [
            "class ImageSegmentationPipeline(Pipeline):",
            "",
            "return super().__call__(*args, **kwargs)",
            "",
            "-    def get_inference_context(self):",
            "-        return torch.no_grad",
            "-",
            "def preprocess(self, image):",
            "image = load_image(image)",
            "target_size = torch.IntTensor([[image.height, image.width]])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8438,
        "label": "no",
        "change": [
            "class AGNN(Module):",
            "self.beta.data.uniform_(0, 1)",
            "",
            "def forward(self, x, edge_index):",
            "-        beta = self.beta if self.requires_grad else Var(self._buffers['beta'])",
            "+        beta = self.beta if self.requires_grad else self._buffers['beta']",
            "return agnn(x, edge_index, beta)",
            "",
            "def __repr__(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8440,
        "label": "yes",
        "change": [
            "def stats(policy: Policy, train_batch: SampleBatch):",
            "stats_dict[\"var_IS\"] = is_stat_var",
            "",
            "if policy.config[\"use_kl_loss\"]:",
            "-        stats_dict[\"kl\"] = policy.get_tower_stats(\"mean_kl_loss\")",
            "+        stats_dict[\"kl\"] = torch.mean(",
            "+            torch.stack(policy.get_tower_stats(\"mean_kl_loss\")))",
            "stats_dict[\"KL_Coeff\"] = policy.kl_coeff",
            "",
            "return stats_dict"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 8442,
        "label": "no",
        "change": [
            "def atomic_save(checkpoint: Dict[str, Any], filepath: Union[str, Path]) -> None:",
            "\"\"\"",
            "",
            "bytesbuffer = io.BytesIO()",
            "-    # Can't use the new zipfile serialization for 1.6.0 because there's a bug in",
            "-    # torch.hub.load_state_dict_from_url() that prevents it from loading the new files.",
            "-    # More details can be found here: https://github.com/pytorch/pytorch/issues/42239",
            "-    if Version(torch.__version__).release[:3] == (1, 6, 0):",
            "-        torch.save(checkpoint, bytesbuffer, _use_new_zipfile_serialization=False)",
            "-    else:",
            "-        torch.save(checkpoint, bytesbuffer)",
            "+    torch.save(checkpoint, bytesbuffer)",
            "with fsspec.open(filepath, \"wb\") as f:",
            "f.write(bytesbuffer.getvalue())"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8448,
        "label": "no",
        "change": [
            "def train(hyp):",
            "world_size=1,  # number of nodes",
            "rank=0)  # node rank",
            "model = torch.nn.parallel.DistributedDataParallel(model)",
            "+        # pip install torch==1.4.0+cu100 torchvision==0.5.0+cu100 -f https://download.pytorch.org/whl/torch_stable.html",
            "",
            "# Dataset",
            "dataset = LoadImagesAndLabels(train_path, imgsz, batch_size,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8451,
        "label": "no",
        "change": [
            "class Collect(object):",
            "",
            "@PIPELINES.register_module()",
            "class WrapFieldsToLists(object):",
            "-    \"\"\"",
            "-    Wrap fields of the data dictionary into lists for evaluation.",
            "+    \"\"\"Wrap fields of the data dictionary into lists for evaluation.",
            "",
            "This class can be used as a last step of a test or validation",
            "pipeline for single image evaluation or inference."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8453,
        "label": "no",
        "change": [
            "class SwinTransformerV2CR(nn.Module):",
            "for stage in self.stages:",
            "output: torch.Tensor = stage(output)",
            "# Perform average pooling",
            "-        output: torch.Tensor = self.average_pool(output)",
            "+        output: torch.Tensor = self.average_pool(output).flatten(start_dim=1)",
            "# Predict classification",
            "classification: torch.Tensor = self.head(output)",
            "return classification"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8454,
        "label": "no",
        "change": [
            "class LxmertModelTest(ModelTesterMixin, unittest.TestCase):",
            "def test_model_from_pretrained(self):",
            "for model_name in LXMERT_PRETRAINED_MODEL_ARCHIVE_LIST[:1]:",
            "model = LxmertModel.from_pretrained(model_name)",
            "+            model.to(torch_device)",
            "self.assertIsNotNone(model)",
            "",
            "def test_attention_outputs(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8455,
        "label": "no",
        "change": [
            "class SlateEpsilonGreedy(EpsilonGreedy):",
            ") -> \"tf.Tensor\":",
            "",
            "per_slate_q_values = action_distribution.inputs",
            "-        all_slates = self.model.slates",
            "+        all_slates = action_distribution.all_slates",
            "",
            "-        exploit_indices = action_distribution.deterministic_sample()",
            "-        exploit_action = tf.gather(all_slates, exploit_indices)",
            "+        exploit_action = action_distribution.deterministic_sample()",
            "",
            "batch_size = tf.shape(per_slate_q_values)[0]",
            "action_logp = tf.zeros(batch_size, dtype=tf.float32)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8457,
        "label": "no",
        "change": [
            "class AlbertForMultipleChoice(AlbertPreTrainedModel):",
            "super().__init__(config)",
            "",
            "self.albert = AlbertModel(config)",
            "-        self.dropout = nn.Dropout(config.hidden_dropout_prob)",
            "+        self.dropout = nn.Dropout(config.classifier_dropout_prob)",
            "self.classifier = nn.Linear(config.hidden_size, 1)",
            "",
            "self.init_weights()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8458,
        "label": "no",
        "change": [
            "def setup(app):",
            "",
            "# @jpchen's hack to get rtd builder to install latest pytorch",
            "if 'READTHEDOCS' in os.environ:",
            "-    os.system('pip install torch==1.2.0+cpu -f https://download.pytorch.org/whl/torch_stable.html')",
            "+    os.system('pip install torch==1.3.0+cpu -f https://download.pytorch.org/whl/torch_stable.html')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8475,
        "label": "yes",
        "change": [
            "class BertModel(BertPreTrainedModel):",
            "seq_ids = torch.arange(seq_length, device=device)",
            "causal_mask = seq_ids[None, None, :].repeat(batch_size, seq_length, 1) <= seq_ids[None, :, None]",
            "causal_mask = causal_mask.to(",
            "-                    torch.long",
            "-                )  # not converting to long will cause errors with pytorch version < 1.3",
            "+                    attention_mask.dtype",
            "+                )  # causal and attention masks must have same type with pytorch version < 1.3",
            "extended_attention_mask = causal_mask[:, None, :, :] * attention_mask[:, None, None, :]",
            "else:",
            "extended_attention_mask = attention_mask[:, None, None, :]"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 8480,
        "label": "no",
        "change": [
            "class TestDilate:",
            "None, None, :, :",
            "]",
            "assert_allclose(",
            "-            dilation(tensor, torch.ones_like(structural_element), structuring_element=structural_element), expected,",
            "-            atol=1e-4, rtol=1e-4",
            "+            dilation(tensor, torch.ones_like(structural_element), structuring_element=structural_element),",
            "+            expected,",
            "+            atol=1e-4,",
            "+            rtol=1e-4,",
            ")",
            "",
            "def test_exception(self, device, dtype):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8482,
        "label": "no",
        "change": [
            "class FastSpeech2Trainer(Seq2SeqBasedTrainer):",
            "grif_before = self.griffin_lim_tf(tf.reshape(mel_before, [-1, 80])[tf.newaxis, :], n_iter=32)",
            "grif_after = self.griffin_lim_tf(tf.reshape(mel_after, [-1, 80])[tf.newaxis, :], n_iter=32)",
            "grif_gt = self.griffin_lim_tf(tf.reshape(mel_gt, [-1, 80])[tf.newaxis, :], n_iter=32)",
            "-                self.griffin_lim_tf.save_wav(grif_before, griff_dir_name, f\"{idx}_before.wav\")",
            "-                self.griffin_lim_tf.save_wav(grif_after, griff_dir_name, f\"{idx}_after.wav\")",
            "-                self.griffin_lim_tf.save_wav(grif_gt, griff_dir_name, f\"{idx}_gt.wav\")",
            "+                self.griffin_lim_tf.save_wav(grif_before, griff_dir_name, f\"{idx}_before\")",
            "+                self.griffin_lim_tf.save_wav(grif_after, griff_dir_name, f\"{idx}_after\")",
            "+                self.griffin_lim_tf.save_wav(grif_gt, griff_dir_name, f\"{idx}_gt\")",
            "",
            "mel_gt = tf.reshape(mel_gt, (-1, 80)).numpy()  # [length, 80]",
            "mel_before = tf.reshape(mel_before, (-1, 80)).numpy()  # [length, 80]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8483,
        "label": "no",
        "change": [
            "class ESPnetFrontendModel(AbsESPnetModel):",
            "return loss.mean(), perm",
            "",
            "def collect_feats(",
            "-            self, speech_mix: torch.Tensor, speech_mix_lengths: torch.Tensor, **kwargs",
            "+        self, speech_mix: torch.Tensor, speech_mix_lengths: torch.Tensor, **kwargs",
            ") -> Dict[str, torch.Tensor]:",
            "# for data-parallel",
            "speech_mix = speech_mix[:, : speech_mix_lengths.max()]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8484,
        "label": "no",
        "change": [
            "from torch_geometric.utils import remove_self_loops",
            "from typing import Optional",
            "",
            "",
            "-def pool_edge(cluster, edge_index,",
            "-              edge_attr: Optional[torch.Tensor] = None):",
            "+def pool_edge(cluster, edge_index, edge_attr: Optional[torch.Tensor] = None):",
            "num_nodes = cluster.size(0)",
            "edge_index = cluster[edge_index.view(-1)].view(2, -1)",
            "edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8485,
        "label": "no",
        "change": [
            "class LayerNorm(torch.nn.Module):",
            "self.eps = eps",
            "",
            "if affine:",
            "-            self.weight = Parameter(torch.Tensor([in_channels]))",
            "-            self.bias = Parameter(torch.Tensor([in_channels]))",
            "+            self.weight = Parameter(torch.Tensor(in_channels))",
            "+            self.bias = Parameter(torch.Tensor(in_channels))",
            "else:",
            "self.register_parameter('weight', None)",
            "self.register_parameter('bias', None)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8486,
        "label": "no",
        "change": [
            "def summary_moving_average(cost_var):",
            "MOVING_SUMMARY_VARS_KEY, as well as the argument",
            "Return a op to maintain these average",
            "\"\"\"",
            "-    global_step_var = tf.get_default_graph().get_tensor_by_name(GLOBAL_STEP_VAR_NAME)",
            "+    global_step_var = get_global_step_var()",
            "averager = tf.train.ExponentialMovingAverage(",
            "0.99, num_updates=global_step_var, name='moving_averages')",
            "vars_to_summary = [cost_var] + \\"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8490,
        "label": "no",
        "change": [
            "def sort_batch_by_length(tensor: torch.Tensor, sequence_lengths: torch.Tensor):",
            "restoration_indices : torch.LongTensor",
            "Indices into the sorted_tensor such that",
            "``sorted_tensor.index_select(0, restoration_indices) == original_tensor``",
            "-    permuation_index : torch.LongTensor",
            "+    permutation_index : torch.LongTensor",
            "The indices used to sort the tensor. This is useful if you want to sort many",
            "tensors using the same ordering.",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8496,
        "label": "no",
        "change": [
            "class Seq2SeqModelEvalTests(unittest.TestCase):",
            "\"\"\"",
            "tensorizers = get_tensorizers()",
            "",
            "+        # Avoid numeric issues with quantization by setting a known seed.",
            "+        torch.manual_seed(42)",
            "+",
            "model = Seq2SeqModel.from_config(",
            "Seq2SeqModel.Config(",
            "source_embedding=WordEmbedding.Config(embed_dim=512),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8501,
        "label": "no",
        "change": [
            "class RNN(object):",
            "l_in_y = tf.matmul(l_in_x, Wi) + bi",
            "l_in_y = tf.reshape(l_in_y, [-1, self._time_steps, self._cell_size], name='2_3D')",
            "",
            "-            with tf.variable_scope('lstm_cell'):",
            "+            with tf.variable_scope('cell'):",
            "cell = tf.nn.rnn_cell.BasicRNNCell(self._cell_size)",
            "with tf.name_scope('initial_state'):",
            "self._cell_initial_state = cell.zero_state(self._batch_size, dtype=tf.float32)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8510,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            ".apply(fg).BatchNorm('bn6')",
            ".apply(cabs)",
            ".FullyConnected('fc1', 10, nl=tf.identity)())",
            "+        tf.get_variable = old_get_variable",
            "prob = tf.nn.softmax(logits, name='output')",
            "",
            "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, label)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8513,
        "label": "no",
        "change": [
            "def gradients(loss, variables):",
            "'''Returns the gradients of `variables` (list of tensor variables)",
            "with regard to `loss`.",
            "'''",
            "-    return tf.gradients(loss, variables)",
            "+    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)",
            "",
            "",
            "def stop_gradient(variables):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8514,
        "label": "no",
        "change": [
            "def split(data, batch):",
            "",
            "# Edge indices should start at zero for every graph.",
            "data.edge_index -= node_slice[batch[row]].unsqueeze(0)",
            "-    data.__num_nodes__ = torch.bincount(batch).tolist()",
            "",
            "slices = {'edge_index': edge_slice}",
            "if data.x is not None:",
            "slices['x'] = node_slice",
            "+    else:",
            "+        data.__num_nodes__ = torch.bincount(batch).tolist()",
            "if data.edge_attr is not None:",
            "slices['edge_attr'] = edge_slice",
            "if data.y is not None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8517,
        "label": "no",
        "change": [
            "def train(hyp,  # path/to/hyp.yaml or hyp dictionary",
            "",
            "# DP mode",
            "if cuda and RANK == -1 and torch.cuda.device_count() > 1:",
            "-        logging.warning('DP not recommended, instead use torch.distributed.run for best DDP Multi-GPU results.\\n'",
            "-                        'See Multi-GPU Tutorial at https://github.com/ultralytics/yolov5/issues/475 to get started.')",
            "+        LOGGER.warning('WARNING: DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\\n'",
            "+                       'See Multi-GPU Tutorial at https://github.com/ultralytics/yolov5/issues/475 to get started.')",
            "model = torch.nn.DataParallel(model)",
            "",
            "# SyncBatchNorm"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8522,
        "label": "no",
        "change": [
            "def add_remaining_self_loops(edge_index,",
            "loop_weight[row[inv_mask]] = edge_weight[inv_mask].view(-1)",
            "edge_weight = torch.cat([edge_weight[mask], loop_weight], dim=0)",
            "",
            "-    loop_index = torch.arange(0,",
            "-                              num_nodes,",
            "-                              dtype=torch.long,",
            "-                              device=row.device)",
            "+    loop_index = torch.arange(0, num_nodes, dtype=row.dtype, device=row.device)",
            "loop_index = loop_index.unsqueeze(0).repeat(2, 1)",
            "edge_index = torch.cat([edge_index[:, mask], loop_index], dim=1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8524,
        "label": "no",
        "change": [
            "class FoveaHead(nn.Module):",
            "pos_weights,",
            "avg_factor=num_pos)",
            "else:",
            "-            loss_bbox = torch.tensor([0],",
            "-                                     dtype=flatten_bbox_preds.dtype,",
            "-                                     device=flatten_bbox_preds.device)",
            "+            loss_bbox = torch.tensor(",
            "+                0,",
            "+                dtype=flatten_bbox_preds.dtype,",
            "+                device=flatten_bbox_preds.device)",
            "return dict(loss_cls=loss_cls, loss_bbox=loss_bbox)",
            "",
            "def fovea_target(self, gt_bbox_list, gt_label_list, featmap_sizes, points):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8531,
        "label": "no",
        "change": [
            "class Decoder(nn.Module):",
            "self.attention.init_win_idx()",
            "self.attention.init_states(inputs)",
            "outputs, stop_tokens, alignments, t = [], [], [], 0",
            "-        stop_flags = [True, False, False]",
            "while True:",
            "memory = self.prenet(self.memory_truncated)",
            "decoder_output, alignment, stop_token = self.decode(memory)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8532,
        "label": "no",
        "change": [
            "class MsrGenomicsKbcomp(datasets.GeneratorBasedBuilder):",
            "",
            "if not os.path.exists(data_dir):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('msr_genomics_kbcomp', data_dir=...)` that includes files unzipped from the reclor zip. Manual download instructions: {}\".format(",
            "-                    data_dir, self.manual_download_instructions",
            "-                )",
            "+                f\"{data_dir} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('msr_genomics_kbcomp', data_dir=...)` that includes files unzipped from the reclor zip. Manual download instructions: {self.manual_download_instructions}\"",
            ")",
            "return [",
            "datasets.SplitGenerator("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8535,
        "label": "no",
        "change": [
            "def fwd_gradient(func, x, grad_x=None, use_gradient_tape=False):",
            "op and the standard `tf.gradients`",
            "```python",
            "t = tf.range(1, 3, dtype=tf.float32)  # Shape [2]",
            "-    y = tf.stack([t, t ** 2, t ** 3], axis=0)  # Shape [3, 2]",
            "+    def fn(t):",
            "+      return tf.stack([t, t ** 2, t ** 3], axis=0)  # Shape [3, 2]",
            "# Produces shape [3, 2] with values [[1, 1], [2, 4], [3, 12]]",
            "-    fwd_grad_y = fwd_gradient(y, t)",
            "+    fwd_grad_y = fwd_gradient(fn, t)",
            "# Produces shape [2] with values [6, 17].",
            "bck_grad_y = tf.gradients(y, t)[0]",
            "```"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8538,
        "label": "yes",
        "change": [
            "class Module(object):",
            "use_while_v2=False",
            "):",
            "Module.global_scope.append('while')",
            "-        if maximum_iterations is not None and maximum_iterations.dtype not in (tf.int32, tf.int64):",
            "+        if maximum_iterations is not None and maximum_iterations.dtype is not tf.int32:",
            "maximum_iterations = tf.dtypes.cast(x=maximum_iterations, dtype=tf.int32)",
            "if use_while_v2:",
            "x = while_v2.while_loop("
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 8540,
        "label": "no",
        "change": [
            "if is_torch_available():",
            "class GenerationTesterMixin:",
            "model_tester = None",
            "all_generative_model_classes = ()",
            "+    input_name = \"input_ids\"",
            "",
            "def _get_input_ids_and_config(self):",
            "config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()",
            "",
            "-        input_ids = inputs_dict[\"input_ids\"]",
            "-        attention_mask = torch.ones_like(input_ids)",
            "+        input_ids = inputs_dict[self.input_name]",
            "+        attention_mask = torch.ones_like(input_ids, dtype=torch.long)",
            "",
            "# cut to half length & take max batch_size 3",
            "max_batch_size = 2"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8541,
        "label": "no",
        "change": [
            "class TextCNN(object):",
            "with tf.name_scope(\"score\"):",
            "# 全连接层，后面接dropout以及relu激活",
            "fc = tf.layers.dense(gmp, self.config.hidden_dim, name='fc1')",
            "-            fc = tf.contrib.layers.dropout(fc,",
            "-                self.keep_prob)",
            "+            fc = tf.contrib.layers.dropout(fc, self.keep_prob)",
            "fc = tf.nn.relu(fc)",
            "",
            "# 分类器"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8549,
        "label": "no",
        "change": [
            "class CommonTestCases:",
            "inputs = inputs_dict.copy()",
            "inputs['head_mask'] = head_mask",
            "",
            "-                with torch.no_grad():",
            "-                    outputs = model(**inputs)",
            "+                outputs = model(**inputs)",
            "",
            "# Test that we can get a gradient back for importance score computation",
            "output = sum(t.sum() for t in outputs[0])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8551,
        "label": "yes",
        "change": [
            "class PartialFC(Module):",
            "logits.backward(grad)",
            "if total_features.grad is not None:",
            "total_features.grad.detach_()",
            "-        x_grad: torch.Tensor = torch.zeros_like(features)",
            "-        x_grad.mul_(self.world_size)",
            "-",
            "+        x_grad: torch.Tensor = torch.zeros_like(features, requires_grad=True)",
            "# feature gradient all-reduce",
            "dist.reduce_scatter(x_grad, list(total_features.grad.chunk(self.world_size, dim=0)))",
            "+        x_grad = x_grad * self.world_size",
            "# backward backbone",
            "return x_grad, loss_v"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 8554,
        "label": "no",
        "change": [
            "class TL_Logger_Test(CustomTestCase):",
            "",
            "if __name__ == '__main__':",
            "",
            "-    # tl.logging.set_verbosity(tl.logging.INFO)",
            "-    # tl.logging.set_verbosity(tl.logging.INFO)",
            "-    tl.logging.set_verbosity(tl.logging.DEBUG)",
            "+    tf.logging.set_verbosity(tf.logging.DEBUG)",
            "tl.logging.set_verbosity(tl.logging.DEBUG)",
            "",
            "unittest.main()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8561,
        "label": "no",
        "change": [
            "def torch_distributed_zero_first(local_rank: int):",
            "Decorator to make all processes in distributed training wait for each local_master to do something.",
            "\"\"\"",
            "if local_rank not in [-1, 0]:",
            "-        torch.distributed.barrier()",
            "+        dist.barrier()",
            "yield",
            "if local_rank == 0:",
            "-        torch.distributed.barrier()",
            "+        dist.barrier()",
            "",
            "",
            "def init_torch_seeds(seed=0):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8562,
        "label": "no",
        "change": [
            "class Textures(object):",
            "msg = \"Expected verts_rgb to be of shape (N, V, 3); got %r\"",
            "raise ValueError(msg % verts_rgb.shape)",
            "if maps is not None:",
            "-            if torch.is_tensor(map) and map.ndim != 4:",
            "+            if torch.is_tensor(maps) and maps.ndim != 4:",
            "msg = \"Expected maps to be of shape (N, H, W, 3); got %r\"",
            "raise ValueError(msg % repr(maps.shape))",
            "elif isinstance(maps, list):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8563,
        "label": "no",
        "change": [
            "def einsum(",
            "*operands: Union[tf.Tensor, tf.Variable],",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "+    dtype = _get_promoted_type_of_operands(operands)",
            "operands = (tf.cast(operand, tf.float32) for operand in operands)",
            "-    return tf.einsum(equation, *operands)",
            "+    return tf.cast(tf.einsum(equation, *operands), dtype)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8566,
        "label": "no",
        "change": [
            "class BatchEncoding(UserDict):",
            "# This check catches things like APEX blindly calling \"to\" on all inputs to a module",
            "# Otherwise it passes the casts down and casts the LongTensor containing the token idxs",
            "# into a HalfTensor",
            "-        if isinstance(device, str) or isinstance(device, torch.device):",
            "+        if isinstance(device, str) or isinstance(device, torch.device) or isinstance(device, int):",
            "self.data = {k: v.to(device=device) for k, v in self.data.items()}",
            "else:",
            "logger.warning("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8568,
        "label": "no",
        "change": [
            "class TraceTailAdaptive_ELBO(Trace_ELBO):",
            "check_fully_reparametrized(site)",
            "",
            "# rank the particles according to p/q",
            "-        log_pq = torch.logsumexp(log_p - log_q, dim=0)",
            "+        log_pq = log_p - log_q",
            "rank = torch.argsort(log_pq, descending=False)",
            "rank = torch.index_select(torch.arange(self.num_particles) + 1, -1, rank).type_as(log_pq)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8574,
        "label": "no",
        "change": [
            "class ModelSaver(Callback):",
            "self.var_collections = var_collections",
            "if checkpoint_dir is None:",
            "checkpoint_dir = logger.LOG_DIR",
            "-        assert os.path.isdir(checkpoint_dir), checkpoint_dir",
            "+        assert tf.gfile.IsDirectory(checkpoint_dir), checkpoint_dir",
            "self.checkpoint_dir = checkpoint_dir",
            "",
            "def _setup_graph(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8578,
        "label": "no",
        "change": [
            "def train(hyp, opt, device, tb_writer=None):",
            "Thread(target=plot_images, args=(imgs, targets, paths, f), daemon=True).start()",
            "# if tb_writer:",
            "#     tb_writer.add_image(f, result, dataformats='HWC', global_step=epoch)",
            "-                    #     tb_writer.add_graph(model, imgs)  # add model to tensorboard",
            "+                    #     tb_writer.add_graph(torch.jit.trace(model, imgs, strict=False), [])  # add model graph",
            "elif plots and ni == 10 and wandb_logger.wandb:",
            "wandb_logger.log({\"Mosaics\": [wandb_logger.wandb.Image(str(x), caption=x.name) for x in",
            "save_dir.glob('train*.jpg') if x.exists()]})"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8580,
        "label": "no",
        "change": [
            "class TestMaskedLayerNorm(AllenNlpTestCase):",
            "mask_n = np.array([[1, 1, 0], [1, 1, 1]])",
            "",
            "x = torch.from_numpy(x_n).float()",
            "-        mask = torch.from_numpy(mask_n)",
            "+        mask = torch.from_numpy(mask_n).bool()",
            "",
            "layer_norm = MaskedLayerNorm(7, gamma0=0.2)",
            "normed_x = layer_norm(x, mask)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8585,
        "label": "no",
        "change": [
            "class MultiHeadSelfAttention(Seq2SeqEncoder):",
            "",
            "batch_size, timesteps, _ = inputs.size()",
            "if mask is None:",
            "-            mask = inputs.new_ones(batch_size, timesteps)",
            "+            mask = inputs.new_ones(batch_size, timesteps).bool()",
            "",
            "# Shape (batch_size, timesteps, 2 * attention_dim + values_dim)",
            "combined_projection = self._combined_projection(inputs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8591,
        "label": "no",
        "change": [
            "class AcceleratorConnector:",
            "self.deterministic = deterministic",
            "if _TORCH_GREATER_EQUAL_1_8:",
            "torch.use_deterministic_algorithms(deterministic)",
            "-        elif _TORCH_GREATER_EQUAL_1_7:",
            "+        else:",
            "torch.set_deterministic(deterministic)",
            "-        else:  # the minimum version Lightning supports is PyTorch 1.6",
            "-            torch._set_deterministic(deterministic)",
            "if deterministic:",
            "# fixing non-deterministic part of horovod",
            "# https://github.com/PyTorchLightning/pytorch-lightning/pull/1572/files#r420279383"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8598,
        "label": "no",
        "change": [
            "for i in range(split.size(0) - 1):",
            "model.conv1.reset_parameters()",
            "model.conv2.reset_parameters()",
            "model.fc1.reset_parameters()",
            "-        times = []",
            "for epoch in range(1, 301):",
            "train(epoch)",
            "-        times = torch.FloatTensor(times)",
            "acc = test(epoch, test_loader, ' Test Accuracy')",
            "accs_single.append(acc)",
            "accs.append(accs_single)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8602,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "W_init=tf.truncated_normal_initializer(stddev=0.01))",
            "logits = tf.reshape(logits, (BATCH, -1, NR_CLASS))",
            "",
            "-        loss = tf.nn.ctc_loss(logits, label, seqlen, time_major=False)",
            "+        loss = tf.nn.ctc_loss(label, logits, seqlen, time_major=False)",
            "",
            "self.cost = tf.reduce_mean(loss, name='cost')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8604,
        "label": "no",
        "change": [
            "class TestGradient:",
            "None, None, :, :",
            "]",
            "assert_allclose(",
            "-            gradient(tensor, torch.ones_like(structural_element), structuring_element=structural_element), expected,",
            "-            atol=1e-3, rtol=1e-3",
            "+            gradient(tensor, torch.ones_like(structural_element), structuring_element=structural_element),",
            "+            expected,",
            "+            atol=1e-3,",
            "+            rtol=1e-3,",
            ")",
            "",
            "def test_exception(self, device, dtype):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8608,
        "label": "no",
        "change": [
            "def _map_fn_train(img, target):",
            "",
            "def _map_fn_test(img, target):",
            "# 1. Crop the central [height, width] of the image.",
            "-    img = tf.image.resize_with_crop_or_pad(img, 24, 24)",
            "+    img = tf.image.resize_with_pad(img, 24, 24)",
            "# 2. Subtract off the mean and divide by the variance of the pixels.",
            "img = tf.image.per_image_standardization(img)",
            "img = tf.reshape(img, (24, 24, 3))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8609,
        "label": "no",
        "change": [
            "class Dropout(Layer):",
            "pass_tensors=dropout",
            ")",
            "",
            "-        skip_dropout = tf.math.logical_not(x=Module.retrieve_tensor(name='optimization'))",
            "+        skip_dropout = tf.math.logical_not(x=Module.retrieve_tensor(name='deterministic'))",
            "zero = tf.constant(value=0.0, dtype=util.tf_dtype(dtype='float'))",
            "skip_dropout = tf.math.logical_or(x=skip_dropout, y=tf.math.equal(x=rate, y=zero))",
            "return self.cond(pred=skip_dropout, true_fn=no_dropout, false_fn=apply_dropout)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8617,
        "label": "no",
        "change": [
            "sess = tf.InteractiveSession()",
            "batch_size = 128",
            "",
            "x = tf.placeholder(LayersConfig.tf_dtype, shape=[batch_size, 28, 28, 1])",
            "-y_ = tf.placeholder(",
            "-    tf.int64, shape=[",
            "-        batch_size,",
            "-    ])",
            "+y_ = tf.placeholder(tf.int64, shape=[batch_size])",
            "",
            "",
            "def model(x, is_train=True, reuse=False):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8618,
        "label": "no",
        "change": [
            "class SequenceGenerator(nn.Module):",
            "cum_unfin.append(prev)",
            "cum_fin_tensor = torch.tensor(cum_unfin, dtype=torch.int).to(bbsz_idx)",
            "",
            "-        unfin_idx = torch.div(bbsz_idx, beam_size, rounding_mode='trunc')",
            "+        unfin_idx = torch.div(bbsz_idx, beam_size, rounding_mode=\"trunc\")",
            "sent = unfin_idx + torch.index_select(cum_fin_tensor, 0, unfin_idx)",
            "",
            "# Create a set of \"{sent}{unfin_idx}\", where"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8621,
        "label": "no",
        "change": [
            "class TransformerEmbeddings(TransformerBaseEmbeddings):",
            "if self.token_embedding:",
            "assert word_ids is not None",
            "assert token_lengths is not None",
            "-            all_token_embeddings = torch.zeros(",
            "-                word_ids.shape[0], token_lengths.max(), self.embedding_length_internal, device=flair.device  # type: ignore",
            "+            all_token_embeddings = torch.zeros(  # type: ignore",
            "+                word_ids.shape[0], token_lengths.max(), self.embedding_length_internal, device=flair.device",
            ")",
            "true_tensor = torch.ones_like(word_ids[:, :1], dtype=torch.bool)",
            "if self.subtoken_pooling == \"first\":"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8622,
        "label": "no",
        "change": [
            "def crop_and_resize(image, boxes, box_ind, crop_size, pad_border=True):",
            "boxes = transform_fpcoor_for_tf(boxes, image_shape, [crop_size, crop_size])",
            "image = tf.transpose(image, [0, 2, 3, 1])   # 1hwc",
            "ret = tf.image.crop_and_resize(",
            "-        image, boxes, box_ind,",
            "+        image, boxes, tf.to_int32(box_ind),",
            "crop_size=[crop_size, crop_size])",
            "ret = tf.transpose(ret, [0, 3, 1, 2])   # ncss",
            "return ret"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8623,
        "label": "no",
        "change": [
            "var.support_native_out = True",
            "# ------#",
            "",
            "",
            "-def einsum(equation: str, *operands: torch.Tensor, out: Optional[torch.Tensor] = None) -> torch.Tensor:",
            "+def einsum(",
            "+    equation: str, *operands: torch.Tensor, out: Optional[torch.Tensor] = None",
            "+) -> torch.Tensor:",
            "return torch.einsum(equation, *operands)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8630,
        "label": "no",
        "change": [
            "def from_importance_weights(log_rhos,",
            "if clip_pg_rho_threshold is not None:",
            "clip_pg_rho_threshold.shape.assert_has_rank(0)",
            "",
            "-    with tf1.name_scope(name, values=[",
            "-        log_rhos, discounts, rewards, values, bootstrap_value",
            "-    ]):",
            "+    with tf1.name_scope(",
            "+            name,",
            "+            values=[log_rhos, discounts, rewards, values, bootstrap_value]):",
            "rhos = tf.math.exp(log_rhos)",
            "if clip_rho_threshold is not None:",
            "clipped_rhos = tf.minimum(",
            "clip_rho_threshold, rhos, name=\"clipped_rhos\")",
            "",
            "-            tf1.summary.histogram(",
            "-                    \"clipped_rhos_1000\", tf.minimum(1000.0, rhos))",
            "+            tf1.summary.histogram(\"clipped_rhos_1000\", tf.minimum(",
            "+                1000.0, rhos))",
            "tf1.summary.scalar(",
            "\"num_of_clipped_rhos\",",
            "tf.reduce_sum("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8634,
        "label": "no",
        "change": [
            "def image_to_tensor(image: Union[np.ndarray, Image.Image], keepdim: bool = True)",
            "\"Input size must be a two, three or four dimensional array\")",
            "",
            "input_shape = image.shape",
            "-    tensor: torch.Tensor = torch.from_numpy(image).to(torch.float)",
            "+    tensor: torch.Tensor = torch.from_numpy(image)",
            "",
            "if len(input_shape) == 2:",
            "# (H, W) -> (1, H, W)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8641,
        "label": "no",
        "change": [
            "class AcceleratorConnector:",
            "hvd.init()",
            "if isinstance(self.accelerator, GPUAccelerator):",
            "# Horovod assigns one local GPU per process",
            "-            self._parallel_devices = list(range(hvd.local_size()))",
            "+            self._parallel_devices = [torch.device(f\"cuda:{i}\") for i in range(hvd.local_size())]",
            "else:",
            "self._parallel_devices = [torch.device(\"cpu\")] * hvd.local_size()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8642,
        "label": "no",
        "change": [
            "class Sari(datasets.Metric):",
            "inputs_description=_KWARGS_DESCRIPTION,",
            "features=datasets.Features(",
            "{",
            "+                    \"sources\": datasets.Value(\"string\", id=\"sequence\"),",
            "\"predictions\": datasets.Value(\"string\", id=\"sequence\"),",
            "\"references\": datasets.Sequence(datasets.Value(\"string\", id=\"sequence\"), id=\"references\"),",
            "}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8647,
        "label": "no",
        "change": [
            "class RolloutWorker(ParallelIteratorWorker):",
            "# Not all Operations support this.",
            "torch.use_deterministic_algorithms(True)",
            "else:",
            "-                        torch.set_determinstic(True)",
            "+                        torch.set_deterministic(True)",
            "# This is only for Convolution no problem.",
            "torch.backends.cudnn.deterministic = True",
            "# Tf2.x."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8648,
        "label": "no",
        "change": [
            "def main():",
            "",
            "# get batch",
            "batch_data = mnist_data[batch_start:batch_end]",
            "-            epoch_loss += kl_optim.step(batch_data)",
            "+            epoch_loss += svi.step(batch_data)",
            "",
            "sample = model_sample()",
            "vis.image(batch_data[0].contiguous().view(28, 28).data.numpy())"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8651,
        "label": "no",
        "change": [
            "class DistributedFusedAdam(torch.optim.Optimizer):",
            "",
            "def _pipeline_block_step(self, block_id):",
            "if self._new_params is None:",
            "-            self._new_params = torch.zeros_like(self._flat_grads,dtype=uint8 if self._e5m2_allgather else self._flat_grads.dtype)",
            "+            self._new_params = torch.zeros_like(self._flat_grads,dtype=torch.uint8 if self._e5m2_allgather else self._flat_grads.dtype)",
            "",
            "start = block_id * self._block_size",
            "end = start + self._block_size"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8652,
        "label": "no",
        "change": [
            "class Trainer(BaseTrainer):",
            "workers : int",
            "Number of workers used in data preprocessing.",
            "device : torch.device",
            "-            Device object. Either `torch.device(\"cuda\")` or torch.device(\"cpu\")`. When `None`, trainer will",
            "+            Device object. Either ``torch.device(\"cuda\")`` or ``torch.device(\"cpu\")``. When ``None``, trainer will",
            "automatic detects GPU and selects GPU first.",
            "log_frequency : int",
            "Number of mini-batches to log metrics."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8656,
        "label": "no",
        "change": [
            "def attn(x, scope, n_state, *, past, params, block_offset=0, train=False):",
            ")",
            "else:",
            "# HOWEVER, `attention` DOES NOT implement masking so we need to pass in `bias` on our own!",
            "-            a = mtf.transformer.attention.attention(",
            "+            a = mtf_transformer.attention.attention(",
            "q, k, v,",
            "memory_length_dim=dim_seq,",
            "key_dim=dim_embd,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8657,
        "label": "no",
        "change": [
            "class Dropout(Layer):",
            ")",
            "",
            "update = Module.retrieve_tensor(name='update')",
            "-        return tf.cond(pred=update, true_fn=true_fn, false_fn=(lambda: x))",
            "+        return self.cond(pred=update, true_fn=true_fn, false_fn=(lambda: x))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8659,
        "label": "no",
        "change": [
            "def eye(",
            "elif 0 < k < n_cols:",
            "mat = torch.concat(",
            "[",
            "-                torch.zeros([n_rows, k], dtype=dtype, device=device, out=out),",
            "+                torch.zeros([n_rows, k], dtype=dtype, device=device),",
            "i[:, : n_cols - k],",
            "],",
            "1,",
            ")",
            "ret = torch.reshape(mat, reshape_dims).repeat(tile_dims)",
            "+        if out is not None:",
            "+            return ivy.inplace_update(out, ret)",
            "else:",
            "ret = torch.zeros(",
            "batch_shape + [n_rows, n_cols], dtype=dtype, device=device, out=out",
            ")",
            "-    if out is not None:",
            "-        return ivy.inplace_update(out, ret)",
            "return ret"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8660,
        "label": "no",
        "change": [
            "class GaussianPyramidTests(TestCase):",
            "def test_elbo_reparameterized(self):",
            "for N in [3, 4, 5]:",
            "self.setup_pyramid(N)",
            "-            self.do_elbo_test(True, N * 4000 - 4000)",
            "+            self.do_elbo_test(True, N * 3000 - 3000)",
            "",
            "# def test_elbo_nonreparameterized(self): XXX to add",
            "#     self.do_elbo_test(False, 5000)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8673,
        "label": "no",
        "change": [
            "class M2M100Decoder(M2M100PreTrainedModel):",
            "",
            "self.init_weights()",
            "",
            "-    # Copied from transformers.models.mbart.modeling_mbart.MBartDecoder.forward with MBart->M2M100",
            "def forward(",
            "self,",
            "input_ids=None,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8675,
        "label": "no",
        "change": [
            "class PersonalizedBase(Dataset):",
            "weight /= weight.mean()",
            "elif use_weight:",
            "#If an image does not have a alpha channel, add a ones weight map anyway so we can stack it later",
            "-                weight = torch.ones([channels] + latent_size)",
            "+                weight = torch.ones(latent_sample.shape)",
            "else:",
            "weight = None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8676,
        "label": "no",
        "change": [
            "def psnr(input: torch.Tensor, target: torch.Tensor, max_val: float) -> torch.Ten",
            "if input.shape != target.shape:",
            "raise TypeError(f\"Expected tensors of equal shapes, but got {input.shape} and {target.shape}\")",
            "",
            "-    return 10.0 * torch.log10(max_val ** 2 / mse(input, target, reduction='mean'))",
            "+    return 10.0 * torch.log10(max_val**2 / mse(input, target, reduction='mean'))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8682,
        "label": "no",
        "change": [
            "class TFFunnelForMultipleChoice(TFFunnelPreTrainedModel, TFMultipleChoiceLoss):",
            "@tf.function(",
            "input_signature=[",
            "{",
            "-                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),",
            "+                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),",
            "\"attention_mask\": tf.TensorSpec((None, None), tf.float32, name=\"attention_mask\"),",
            "-                \"token_type_ids\": tf.TensorSpec((None, None), tf.int32, name=\"token_type_ids\"),",
            "+                \"token_type_ids\": tf.TensorSpec((None, None), tf.int64, name=\"token_type_ids\"),",
            "}",
            "]",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8683,
        "label": "no",
        "change": [
            "def main():",
            "# extract",
            "logging.info('backend = ' + args.backend)",
            "if args.backend == \"pytorch\":",
            "-        from tts.pytorch.tts_pytorch import decode",
            "+        fromespnet.lmpytorch.tts_pytorch import decode",
            "decode(args)",
            "else:",
            "raise NotImplementedError(\"Only pytorch is supported.\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8684,
        "label": "no",
        "change": [
            "with tf.Graph().as_default():",
            "return x",
            "",
            "net = dnn(X)",
            "-    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(net, Y))",
            "+    loss = tf.reduce_mean(",
            "+        tf.nn.softmax_cross_entropy_with_logits(logits=net, labels=Y))",
            "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)",
            "accuracy = tf.reduce_mean(",
            "tf.cast(tf.equal(tf.argmax(net, 1), tf.argmax(Y, 1)), tf.float32),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8686,
        "label": "yes",
        "change": [
            "class TransfoXLModel(TransfoXLPreTrainedModel):",
            "else:",
            "mask_shift_len = qlen",
            "dec_attn_mask = (torch.triu(all_ones, 1+mlen)",
            "-                    + torch.tril(all_ones, -mask_shift_len)).byte()[:, :, None] # -1",
            "+                    + torch.tril(all_ones, -mask_shift_len)).bool()[:, :, None] # -1",
            "else:",
            "dec_attn_mask = torch.triu(",
            "-                word_emb.new_ones(qlen, klen), diagonal=1+mlen).byte()[:,:,None]",
            "+                word_emb.new_ones(qlen, klen), diagonal=1+mlen).bool()[:,:,None]",
            "",
            "hids = []",
            "attentions = []"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 8688,
        "label": "no",
        "change": [
            "class DetrModelIntegrationTests(unittest.TestCase):",
            "expected_slice_masks = torch.tensor(",
            "[[-7.7558, -10.8788, -11.9797], [-11.8881, -16.4329, -17.7451], [-14.7316, -19.7383, -20.3004]]",
            ").to(torch_device)",
            "-        self.assertTrue(torch.allclose(outputs.pred_masks[0, 0, :3, :3], expected_slice_masks, atol=1e-4))",
            "+        self.assertTrue(torch.allclose(outputs.pred_masks[0, 0, :3, :3], expected_slice_masks, atol=1e-3))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8693,
        "label": "yes",
        "change": [
            "class EarlyStopping(Callback):",
            "f\" {self.monitor} = {current} {self.order_dict[self.mode]} {self.divergence_threshold}.\"",
            "\" Signaling Trainer to stop.\"",
            ")",
            "-        elif self.monitor_op(current - self.min_delta, self.best_score.to(trainer.lightning_module.device)):",
            "+        elif self.monitor_op(current - self.min_delta, self.best_score.to(current.device)):",
            "should_stop = False",
            "reason = self._improvement_message(current)",
            "self.best_score = current"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 8698,
        "label": "yes",
        "change": [
            "def tensordot(",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "# find type to promote to",
            "-    dtype = tf.experimental.numpy.promote_types(x1.dtype, x2.dtype)",
            "+    dtype = ivy.as_native_dtype(ivy.promote_types(x1.dtype, x2.dtype))",
            "",
            "# type casting to float32 which is acceptable for tf.tensordot",
            "x1, x2 = tf.cast(x1, tf.float32), tf.cast(x2, tf.float32)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 8699,
        "label": "yes",
        "change": [
            "def log_cosh(y_true, y_pred):",
            ">>> x = y_pred - y_true",
            ">>> assert np.allclose(",
            "...     loss.numpy(),",
            "-  ...     np.mean(x + np.log(np.exp(-2. * x) + 1.) - math_ops.log(2.), axis=-1),",
            "+  ...     np.mean(x + np.log(np.exp(-2. * x) + 1.) - tf.math.log(2.), axis=-1),",
            "...     atol=1e-5)",
            "",
            "Args:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 8705,
        "label": "no",
        "change": [
            "class CustomConverterMulEnc(object):",
            "ys = batch[0][-1]",
            "",
            "# perform subsampling",
            "-        if np.sum(self.subsamping_factors) > self.num_encs:",
            "+        if np.sum(self.subsampling_factors) > self.num_encs:",
            "xs_list = [",
            "[x[:: self.subsampling_factors[i], :] for x in xs_list[i]]",
            "for i in range(self.num_encs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8706,
        "label": "no",
        "change": [
            "class DeformableDetrTransformer(Transformer):",
            "nn.init.xavier_uniform_(p)",
            "for m in self.modules():",
            "if isinstance(m, MultiScaleDeformableAttention):",
            "-                m.init_weight()",
            "+                m.init_weights()",
            "if not self.as_two_stage:",
            "xavier_init(self.reference_points, distribution='uniform', bias=0.)",
            "normal_(self.level_embeds)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8707,
        "label": "no",
        "change": [
            "def filter_logits(logits, top_k=0, top_p=0.0, filter_value=-float(\"Inf\")):",
            "sorted_indices_to_remove[..., 0] = 0",
            "",
            "# indices_to_remove = sorted_indices[sorted_indices_to_remove]",
            "-        indices_to_remove = torch.zeros_like(logits, dtype=torch.uint8).scatter_(",
            "+        indices_to_remove = torch.zeros_like(logits, dtype=torch.bool).scatter_(",
            "dim=-1, index=sorted_indices, src=sorted_indices_to_remove",
            ")",
            "logits[indices_to_remove] = filter_value"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8709,
        "label": "no",
        "change": [
            "if __name__ == '__main__':",
            "torch.save({'step': step, 'model_state': model.state_dict()}, model_fpath)",
            "print('<saved>')",
            "",
            "-    optimiser = optim.Adam(model.parameters())",
            "-    train(model, optimiser, epochs=60, batch_size=128, classes=2**bits,",
            "+    optimizer = optim.Adam(model.parameters())",
            "+    train(model, optimizer, epochs=60, batch_size=64, classes=2 ** bits,",
            "seq_len=seq_len, step=step, lr=1e-4)",
            "",
            "\\ No newline at end of file"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8711,
        "label": "no",
        "change": [
            "class ROIPoolingLayer(Layer):",
            "",
            "logging.info(\"ROIPoolingLayer %s: (%d, %d)\" % (name, pool_height, pool_width))",
            "",
            "-        self.inputs = prev_layer.outputs",
            "-",
            "self.outputs = roi_pooling(self.inputs, rois, pool_height, pool_width)",
            "",
            "-        self.all_layers.append(self.outputs)",
            "+        self._add_layers(self.outputs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8713,
        "label": "no",
        "change": [
            "class Optimizer(object):",
            "The optimization operation.",
            "\"\"\"",
            "deltas = self.step(time=time, variables=variables, **kwargs)",
            "-        # deltas[0] = tf.Print(deltas[0], (deltas[0],))",
            "with tf.control_dependencies(control_inputs=deltas):",
            "return tf.no_op()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8717,
        "label": "no",
        "change": [
            "class DegreeScalerAggregation(Aggregation):",
            "elif scaler == 'amplification':",
            "out_scaler = out * (torch.log(deg + 1) / self.avg_deg_log)",
            "elif scaler == 'attenuation':",
            "-                out_scaler = out * (self.avg_deg_log / torch.log(deg + 1))",
            "+                # Clamp minimum degree to one to avoid dividing by zero:",
            "+                out_scaler = out * (self.avg_deg_log /",
            "+                                    torch.log(deg.clamp(min=1) + 1))",
            "elif scaler == 'linear':",
            "out_scaler = out * (deg / self.avg_deg_lin)",
            "elif scaler == 'inverse_linear':",
            "-                # Clamps minimum degree into one to avoid dividing by zero",
            "-                out_scaler = out * (self.avg_deg_lin / deg.clamp(1))",
            "+                # Clamp minimum degree to one to avoid dividing by zero:",
            "+                out_scaler = out * (self.avg_deg_lin / deg.clamp(min=1))",
            "else:",
            "raise ValueError(f\"Unknown scaler '{scaler}'\")",
            "outs.append(out_scaler)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8718,
        "label": "no",
        "change": [
            "def broadcast(backend, value, root_rank, name):",
            "return _eval(backend, hvd.broadcast(tf.constant(value, name=name), root_rank))",
            "",
            "",
            "-def load_model(keras, wrap_optimizer, filepath, custom_optimizers, custom_objects):",
            "+def load_model(keras, wrap_optimizer, optimizer_modules, filepath, custom_optimizers, custom_objects):",
            "horovod_objects = {",
            "subclass.__name__.lower(): wrap_optimizer(subclass)",
            "for subclass in keras.optimizers.Optimizer.__subclasses__()",
            "-        if subclass.__module__ == keras.optimizers.Optimizer.__module__",
            "+        if subclass.__module__ in optimizer_modules",
            "}",
            "",
            "if custom_optimizers is not None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8719,
        "label": "no",
        "change": [
            "from ivy.container import Container",
            "",
            "",
            "def variable(x):",
            "-    with tf.device(\"/\" + ivy.dev(x, as_str=True).upper()):",
            "+    with ivy.dev(x, as_native=True):",
            "return tf.Variable(x, trainable=True)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8726,
        "label": "no",
        "change": [
            "def expand_tile(value, newdim):",
            "print(value)",
            "print('############')",
            "",
            "-    return mtf.broadcast(mtf_expand_dims(value, newdim, 0),",
            "+    return mtf.broadcast(mtf_expand_dims(value, 'dummy_batch', 0),",
            "[newdim] + value.shape.dims)  # shape.dims gets us a list which we need in order to concat"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8727,
        "label": "no",
        "change": [
            "def test_metric_are_properly_reduced(tmpdir):",
            "trainer.fit(model)",
            "",
            "assert trainer.callback_metrics[\"val_acc\"] == 8 / 32.",
            "-    assert \"train_acc\" in trainer.callback_metrics",
            "+    assert \"train_loss\" in trainer.callback_metrics"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8729,
        "label": "no",
        "change": [
            "class ObjectInfo:",
            "",
            "def __repr__(self):",
            "single_line_description = self.description.replace(\"\\n\", \"\") if self.description is not None else \"\"",
            "-        return f\"nlp.ObjectInfo(\\n\\tid='{self.id}',\\n\\tdescription='{single_line_description}',\\n\\tfiles={self.siblings}\\n)\"",
            "+        return f\"datasets.ObjectInfo(\\n\\tid='{self.id}',\\n\\tdescription='{single_line_description}',\\n\\tfiles={self.siblings}\\n)\"",
            "",
            "",
            "class HfApi:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8738,
        "label": "yes",
        "change": [
            "class EntityLinker(flair.nn.DefaultClassifier[Sentence, Span]):",
            ")",
            "",
            "def emb_mean(self, span, embedding_names):",
            "-        return torch.mean(torch.cat([token.get_embedding(embedding_names) for token in span], 0), 0)",
            "+        return torch.mean(torch.stack([token.get_embedding(embedding_names) for token in span], 0), 0)",
            "",
            "def _get_data_points_from_sentence(self, sentence: Sentence) -> List[Span]:",
            "return sentence.get_spans(self.label_type)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 8743,
        "label": "no",
        "change": [
            "class TFAdaptiveSoftmaxMask(tf.keras.layers.Layer):",
            "@staticmethod",
            "def _gather_logprob(logprob, target):",
            "lp_size = shape_list(logprob)",
            "-        r = tf.range(lp_size[0])",
            "+        r = tf.range(lp_size[0], dtype=target.dtype)",
            "idx = tf.stack([r, target], 1)",
            "return tf.gather_nd(logprob, idx)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8744,
        "label": "no",
        "change": [
            "def european_option_price(*,",
            "sigmas = tf.convert_to_tensor(sigmas, dtype=dtype, name='sigmas')",
            "rhos = tf.convert_to_tensor(rhos, dtype=dtype, name='rhos')",
            "variances = tf.convert_to_tensor(variances, dtype=dtype, name='variances')",
            "-    forwards = tf.convert_to_tensor(forwards, dtype=dtype, name='forwards')",
            "",
            "if discount_factors is not None:",
            "discount_factors = tf.convert_to_tensor("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8745,
        "label": "yes",
        "change": [
            "def finish_episode():",
            "rewards = torch.Tensor(rewards)",
            "rewards = (rewards - rewards.mean()) / (rewards.std() + np.finfo(np.float32).eps)",
            "for (log_prob, value), r in zip(saved_actions, rewards):",
            "-        reward = r - value.data[0, 0]",
            "+        reward = r - value.data[0]",
            "policy_losses.append(-log_prob * reward)",
            "value_losses.append(F.smooth_l1_loss(value, Variable(torch.Tensor([r]))))",
            "optimizer.zero_grad()",
            "-    loss = torch.cat(policy_losses).sum() + torch.cat(value_losses).sum()",
            "+    loss = torch.stack(policy_losses).sum() + torch.stack(value_losses).sum()",
            "loss.backward()",
            "optimizer.step()",
            "del model.rewards[:]"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 8746,
        "label": "no",
        "change": [
            "class Detect(nn.Module):",
            "t = self.anchors[i].dtype",
            "shape = 1, self.na, ny, nx, 2  # grid shape",
            "y, x = torch.arange(ny, device=d, dtype=t), torch.arange(nx, device=d, dtype=t)",
            "-        if torch_1_10:  # torch>=1.10.0 meshgrid workaround for torch>=0.7 compatibility",
            "-            yv, xv = torch.meshgrid(y, x, indexing='ij')",
            "-        else:",
            "-            yv, xv = torch.meshgrid(y, x)",
            "+        yv, xv = torch.meshgrid(y, x, indexing='ij') if torch_1_10 else torch.meshgrid(y, x)  # torch>=0.7 compatibility",
            "grid = torch.stack((xv, yv), 2).expand(shape) - 0.5  # add grid offset, i.e. y = 2.0 * x - 0.5",
            "anchor_grid = (self.anchors[i] * self.stride[i]).view((1, self.na, 1, 1, 2)).expand(shape)",
            "return grid, anchor_grid"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8747,
        "label": "no",
        "change": [
            "def register_optimizers(ctx, model):",
            "model.trainer.optimizers = optimizers",
            "model.trainer.lr_schedulers = lr_schedulers",
            "model.trainer.optimizer_frequencies = optimizer_frequencies",
            "-    model.trainer.convert_to_lightning_optimizers()",
            "",
            "",
            "def run_optimizer(ctx, model):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8748,
        "label": "yes",
        "change": [
            "def _get_random_features_initializer(initializer, shape):",
            "random_features_initializer = initializer",
            "if isinstance(initializer, str):",
            "if initializer.lower() == 'gaussian':",
            "-      random_features_initializer = tf.compat.v1.random_normal_initializer(",
            "-          stddev=1.0)",
            "+      random_features_initializer = initializers.RandomNormal(stddev=1.0)",
            "elif initializer.lower() == 'laplacian':",
            "-      random_features_initializer = tf.compat.v1.constant_initializer(",
            "+      random_features_initializer = initializers.Constant(",
            "_get_cauchy_samples(loc=0.0, scale=1.0, shape=shape))",
            "",
            "else:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 8753,
        "label": "no",
        "change": [
            "class Deltafier(PreprocessingLayer):",
            "value=tf.constant(value=True, dtype=util.tf_dtype(dtype='bool')), read_value=False",
            ")",
            "with tf.control_dependencies(control_inputs=(assignment,)):",
            "-                return tf.concat(values=(tf.zeros_like(tensor=x[:1]), x[1:] - x[:-1]), axis=0)",
            "+                return tf.concat(values=(tf.zeros_like(tensor=x[:1]), x[1:] - x[:-1]), axis=0)  # dtype=util.tf_dtype(dtype='???'))",
            "",
            "def later_delta():",
            "return x - tf.concat(values=(self.previous, x[:-1]), axis=0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8760,
        "label": "no",
        "change": [
            "class PipelineTesterMixin(unittest.TestCase):",
            "image_slice = image[0, -1, -3:, -3:].cpu()",
            "",
            "assert image.shape == (1, 3, 256, 256)",
            "-        expected_slice = torch.rensor([0.3163, 0.8670, 0.6465, 0.1865, 0.6291, 0.5139, 0.2824, 0.3723, 0.4344])",
            "+        expected_slice = torch.tensor([0.3163, 0.8670, 0.6465, 0.1865, 0.6291, 0.5139, 0.2824, 0.3723, 0.4344])",
            "assert (image_slice.flatten() - expected_slice).abs().max() < 1e-2",
            "",
            "@slow"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8761,
        "label": "no",
        "change": [
            "class Reddit(nlp.GeneratorBasedBuilder):",
            "\"\"\"Returns SplitGenerators.\"\"\"",
            "dl_path = dl_manager.download_and_extract(_URL)",
            "return [",
            "-            nlp.SplitGenerator(",
            "-                name=nlp.Split.TRAIN,",
            "+            datasets.SplitGenerator(",
            "+                name=datasets.Split.TRAIN,",
            "gen_kwargs={\"path\": os.path.join(dl_path, \"corpus-webis-tldr-17.json\")},",
            ")",
            "]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8762,
        "label": "no",
        "change": [
            "def UnPooling2x2ZeroFilled(x):",
            "out_size = [-1, sh[1] * 2, sh[2] * 2, sh[3]]",
            "return tf.reshape(out, out_size)",
            "else:",
            "-        sh = tf.shape(x)",
            "-        ret = tf.reshape(out, tf.pack([-1, sh[1] * 2, sh[2] * 2, sh[3]]))",
            "+        shv = tf.shape(x)",
            "+        ret = tf.reshape(out, tf.pack([-1, shv[1] * 2, shv[2] * 2, sh[3]]))",
            "ret.set_shape([None, None, None, sh[3]])",
            "return ret"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8763,
        "label": "no",
        "change": [
            "def test_path_cache() -> None:",
            "",
            "refs: TypeList[TypeType] = []",
            "for path in conv2d_paths:",
            "-        klass = sy.lib_ast(path, return_callable=True, obj_type=th.nn.Conv2d)",
            "+        klass = sy.lib_ast.query(path, obj_type=th.nn.Conv2d)",
            "assert klass == sy.lib_ast.torch.nn.Conv2d",
            "assert klass.name == \"Conv2d\"",
            "assert klass.path_and_name == short_fqn"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8765,
        "label": "yes",
        "change": [
            "class SyncMultiGPUTrainer(MultiGPUTrainer,",
            "super(SyncMultiGPUTrainer, self)._setup()",
            "grad_list = MultiGPUTrainer._multi_tower_grads(",
            "self.config.tower, lambda: self._get_cost_and_grad()[1])",
            "+",
            "+        # debug tower performance:",
            "+        #ops = [k[0] for k in grad_list[1]] + [k[0] for k in grad_list[0]]",
            "+        #self.train_op = tf.group(*ops)",
            "+        #return",
            "+",
            "grads = SyncMultiGPUTrainer._average_grads(grad_list)",
            "grads = apply_grad_processors(grads, self.model.get_gradient_processor())"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 8766,
        "label": "no",
        "change": [
            "def test_zip_arrow(ray_start_regular_shared):",
            "def test_batch_tensors(ray_start_regular_shared):",
            "import torch",
            "",
            "-    ds = ray.data.from_items([torch.tensor([0, 0]) for _ in range(40)])",
            "+    ds = ray.data.from_items([torch.tensor([0, 0]) for _ in range(40)], parallelism=40)",
            "res = \"Dataset(num_blocks=40, num_rows=40, schema=<class 'torch.Tensor'>)\"",
            "assert str(ds) == res, str(ds)",
            "with pytest.raises(pa.lib.ArrowInvalid):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8771,
        "label": "no",
        "change": [
            "class EvalCallback(Callback):",
            "self.dataflow = get_eval_dataflow(self._eval_dataset,",
            "shard=hvd.local_rank(), num_shards=hvd.local_size())",
            "",
            "-            self.barrier = hvd.allreduce(tf.random_normal(shape=[1]))",
            "+            self.barrier = hvd.allreduce(tfv1.random_normal(shape=[1]))",
            "",
            "def _build_predictor(self, idx):",
            "return self.trainer.get_predictor(self._in_names, self._out_names, device=idx)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8774,
        "label": "no",
        "change": [
            "def dense_layer(x, size, l2_regularization=0.0):",
            "",
            "def conv2d_layer(x, size, l2_regularization=0.0, window=3, stride=1):",
            "with tf.variable_scope('conv2d'):",
            "-        filters = tf.Variable(initial_value=tf.random_normal(shape=(window, window, x.get_shape()[2].value, size), stddev=sqrt(2.0 / size))),",
            "+        filters = tf.Variable(initial_value=tf.random_normal(shape=(window, window, x.get_shape()[3].value, size), stddev=sqrt(2.0 / size)))",
            "+",
            "if l2_regularization > 0.0:",
            "tf.losses.add_loss(l2_regularization * tf.nn.l2_loss(t=filters))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8779,
        "label": "no",
        "change": [
            "class TestMultiHeadedSimilarityFunction(AllenNlpTestCase):",
            "similarity = MultiHeadedSimilarity(num_heads=3, tensor_1_dim=6)",
            "similarity._tensor_1_projection = Parameter(torch.eye(6))",
            "similarity._tensor_2_projection = Parameter(torch.eye(6))",
            "-        a_vectors = Variable(torch.FloatTensor([[[[1, 1, -1, -1, 0, 1], [-2, 5, 9, -1, 3, 4]]]]))",
            "-        b_vectors = Variable(torch.FloatTensor([[[[1, 1, 1, 0, 2, 5], [0, 1, -1, -7, 1, 2]]]]))",
            "+        a_vectors = torch.FloatTensor([[[[1, 1, -1, -1, 0, 1], [-2, 5, 9, -1, 3, 4]]]])",
            "+        b_vectors = torch.FloatTensor([[[[1, 1, 1, 0, 2, 5], [0, 1, -1, -7, 1, 2]]]])",
            "result = similarity(a_vectors, b_vectors).data.numpy()",
            "assert result.shape == (1, 1, 2, 3)",
            "assert_almost_equal(result, [[[[2, -1, 5], [5, -2, 11]]]])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8784,
        "label": "no",
        "change": [
            "def text_to_seqvec(text, CONFIG, use_cuda):",
            "def numpy_to_torch(np_array, dtype, cuda=False):",
            "if np_array is None:",
            "return None",
            "-    tensor = torch.Tensor(np_array, dtype=dtype)",
            "+    tensor = torch.as_tensor(np_array, dtype=dtype)",
            "if cuda:",
            "return tensor.cuda()",
            "return tensor"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8787,
        "label": "no",
        "change": [
            "class DeprecatedCustomLossModelV1(Model):",
            "",
            "def _build_layers_v2(self, input_dict, num_outputs, options):",
            "self.obs_in = input_dict[\"obs\"]",
            "-        with tf.variable_scope(\"shared\", reuse=tf.AUTO_REUSE):",
            "+        with tf1.variable_scope(\"shared\", reuse=tf1.AUTO_REUSE):",
            "self.fcnet = FullyConnectedNetwork(input_dict, self.obs_space,",
            "self.action_space, num_outputs,",
            "options)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8789,
        "label": "no",
        "change": [
            "def test_pdn_conv():",
            "",
            "t = '(Tensor, SparseTensor, OptTensor) -> Tensor'",
            "jit = torch.jit.script(conv.jittable(t))",
            "-    assert torch.allclose(jit(x, adj.t()), out)",
            "+    assert torch.allclose(jit(x, adj.t()), out, atol=1e-6)",
            "",
            "",
            "def test_pdn_conv_with_sparse_node_input_feature():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8790,
        "label": "no",
        "change": [
            "class SpatialTransformer2dAffineLayer(Layer):",
            "else:",
            "from tensorflow.python.ops import array_ops",
            "batch_size = array_ops.shape(self.inputs)[0]",
            "-            size = self.inputs.get_shape().as_list()",
            "+",
            "n_channels = self.inputs.get_shape().as_list()[-1]",
            "# logging.info(self.outputs)",
            "self.outputs = tf.reshape(self.outputs, shape=[batch_size, out_size[0], out_size[1], n_channels])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8791,
        "label": "no",
        "change": [
            "def reshape(incoming, new_shape, name=\"Reshape\"):",
            "with tf.name_scope(name) as scope:",
            "inference = incoming",
            "if isinstance(inference, list):",
            "-            inference = tf.concat(inference, 0)",
            "+            inference = tf.concat(0, inference)",
            "inference = tf.cast(inference, tf.float32)",
            "inference = tf.reshape(inference, shape=new_shape)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8794,
        "label": "no",
        "change": [
            "class TestAUC(MetricTester):",
            "])",
            "def test_auc(x, y, expected):",
            "# Test Area Under Curve (AUC) computation",
            "-    assert auc(torch.tensor(x), torch.tensor(y)) == expected",
            "+    assert auc(torch.tensor(x), torch.tensor(y), reorder=True) == expected"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8800,
        "label": "no",
        "change": [
            "ACT2FN = {",
            "\"gelu\": tf.keras.layers.Activation(gelu),",
            "\"relu\": tf.keras.activations.relu,",
            "\"swish\": tf.keras.activations.swish,",
            "+    \"silu\": tf.keras.activations.swish,",
            "\"gelu_new\": tf.keras.layers.Activation(gelu_new),",
            "\"mish\": tf.keras.layers.Activation(mish),",
            "\"tanh\": tf.keras.activations.tanh,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8801,
        "label": "no",
        "change": [
            "def train_model(",
            "tag = tag.replace('/', '.')",
            "if not (torch.isinf(value) | torch.isnan(value)).any():",
            "histograms['Weights/' + tag] = wandb.Histogram(value.data.cpu())",
            "-                            if not (torch.isinf(value.grad) | torch.isnan(value)).any():",
            "+                            if not (torch.isinf(value.grad) | torch.isnan(value.grad)).any():",
            "histograms['Gradients/' + tag] = wandb.Histogram(value.grad.data.cpu())",
            "",
            "val_score = evaluate(model, val_loader, device, amp)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8803,
        "label": "no",
        "change": [
            "class Agent(object):",
            "assert isinstance(seed, int)",
            "random.seed(a=seed)",
            "np.random.seed(seed=seed)",
            "-            tf.random.set_random_seed(seed=seed)",
            "",
            "# States/actions specification",
            "self.states_spec = util.valid_values_spec("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8804,
        "label": "no",
        "change": [
            "class LlffDatasetMapProvider(SingleSceneDatasetMapProviderBase):",
            "i_split = (i_train, i_test, i_test)",
            "H, W, focal = hwf",
            "H, W = int(H), int(W)",
            "-        images = torch.from_numpy(images)",
            "+        images = torch.from_numpy(images).permute(0, 3, 1, 2)",
            "poses = torch.from_numpy(poses)",
            "",
            "# pyre-ignore[16]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8805,
        "label": "no",
        "change": [
            "torch, nn = try_import_torch()",
            "logger = logging.getLogger(__name__)",
            "",
            "",
            "-class FullyConnectedNetwork(TorchModelV2):",
            "+class FullyConnectedNetwork(TorchModelV2, nn.Module):",
            "\"\"\"Generic fully connected network.\"\"\"",
            "",
            "def __init__(self, obs_space, action_space, num_outputs, model_config,",
            "name):",
            "TorchModelV2.__init__(self, obs_space, action_space, num_outputs,",
            "model_config, name)",
            "+        nn.Module.__init__(self)",
            "",
            "activation = get_activation_fn(",
            "model_config.get(\"fcnet_activation\"), framework=\"torch\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8810,
        "label": "no",
        "change": [
            "def slogdet(",
            "/,",
            ") -> NamedTuple:",
            "results = NamedTuple(",
            "-        \"slogdet\",",
            "-        [(\"sign\", torch.Tensor), (\"logabsdet\", torch.Tensor)]",
            "+        \"slogdet\", [(\"sign\", torch.Tensor), (\"logabsdet\", torch.Tensor)]",
            ")",
            "sign, logabsdet = torch.linalg.slogdet(x)",
            "return results(sign, logabsdet)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8814,
        "label": "no",
        "change": [
            "class ViterbiDecoder:",
            "self.start_tag = tag_dictionary.get_idx_for_item(START_TAG)",
            "self.stop_tag = tag_dictionary.get_idx_for_item(STOP_TAG)",
            "",
            "-    def decode(self, features: torch.Tensor, lengths: torch.Tensor) -> List:",
            "+    def decode(self, features_tuple: tuple) -> List:",
            "\"\"\"",
            "Decoding function returning the most likely sequence of tags.",
            ":param features: CRF scores from CRF forward method in shape (batch size, seq len, tagset size, tagset size)",
            ":param lengths: lengths tuple containing sorted lengths and indices from unsorted list",
            ":return: decoded sequences",
            "\"\"\"",
            "+        features, lengths = features_tuple",
            "+",
            "tags = []",
            "batch_size = features.size(0)",
            "seq_len = features.size(1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8815,
        "label": "no",
        "change": [
            "class TorchBuffer(torch.Tensor):",
            "def custompad(x, padding): return torch.nn.functional.pad(x, [item for sublist in padding[::-1] for item in sublist])",
            "",
            "@staticmethod",
            "-  def fromCPU(data):",
            "-    return TorchBuffer(torch.from_numpy(data).requires_grad_(False)).to(device)",
            "-  def toCPU(x):",
            "-    return x.cpu().numpy()",
            "+  def fromCPU(data): return TorchBuffer(torch.from_numpy(data).requires_grad_(False)).to(device)",
            "+  def toCPU(x): return x.cpu().numpy()",
            "",
            "unary_op, binary_op, reduce_op, movement_op = CPUBuffer.unary_op, CPUBuffer.binary_op, CPUBuffer.reduce_op, CPUBuffer.movement_op"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8823,
        "label": "no",
        "change": [
            "def decode_bbox_target(box_predictions, anchors):",
            "xbyb = box_pred_txty * waha + xaya",
            "x1y1 = xbyb - wbhb * 0.5",
            "x2y2 = xbyb + wbhb * 0.5    # (...)x1x2",
            "-    out = tf.concat([x1y1, x2y2], axis=1)",
            "+    out = tf.concat([x1y1, x2y2], axis=-2)",
            "return tf.reshape(out, orig_shape)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8824,
        "label": "yes",
        "change": [
            "def _replace_global_by_local(kwargs):",
            "if 'collections' in kwargs:",
            "collections = kwargs['collections']",
            "if not collections:",
            "-        collections = {tf.GraphKeys.GLOBAL_VARIABLES}",
            "+        collections = {tfv1.GraphKeys.GLOBAL_VARIABLES}",
            "else:",
            "collections = set(collections.copy())",
            "-    collections.remove(tf.GraphKeys.GLOBAL_VARIABLES)",
            "-    collections.add(tf.GraphKeys.LOCAL_VARIABLES)",
            "+    collections.remove(tfv1.GraphKeys.GLOBAL_VARIABLES)",
            "+    collections.add(tfv1.GraphKeys.LOCAL_VARIABLES)",
            "kwargs['collections'] = list(collections)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    }
]
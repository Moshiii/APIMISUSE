{"number": 4, "change": "class TrainerIntegrationTest(unittest.TestCase):\n\n# Adding one column not used by the model should have no impact\nz = np.random.normal(size=(64,)).astype(np.float32)\n-        train_dataset = nlp.Dataset.from_dict({\"input_x\": x, \"label\": y, \"extra\": z})\n+        train_dataset = datasets.Dataset.from_dict({\"input_x\": x, \"label\": y, \"extra\": z})\nmodel = RegressionModel()\ntrainer = Trainer(model, args, train_dataset=train_dataset)\ntrainer.train()\n", "fix_pattern": "if nlp.Dataset is detected, replace with datasets.Dataset"}
{"number": 7, "change": "def test_quantile():\n\n\ndef test_pi():\n-    x = torch.empty(1000).log_normal_(0, 1)\n+    x = torch.randn(1000).exp()\nassert_equal(pi(x, prob=0.8), quantile(x, probs=[0.1, 0.9]))\n", "fix_pattern": "This code change shows how to fix the API method problem. The pattern is to replace torch.empty(1000).log_normal_() with torch.randn(1000).exp()."}
{"number": 8, "change": "class TPUAccelerator(Accelerator):\nReturn:\nA tensor of shape (world_size, batch, ...)\n\"\"\"\n-        return xm.all_gather(tensor, group=group, sync_grads=sync_grads)\n+        # todo: Add support for backward with all_gather\n+        if torch.distributed.is_initialized():\n+            return xm.all_gather(tensor, group=group, sync_grads=sync_grads)\n+        return tensor\n", "fix_pattern": "if torch.distributed.is_initialized() is detected, add a conditional statement around the API call and return tensor if the condition is not met."}
{"number": 9, "change": "class Swinv2SelfAttention(nn.Module):\nquery_layer = self.transpose_for_scores(mixed_query_layer)\n\n# cosine attention\n-        attention_scores = F.normalize(query_layer, dim=-1) @ F.normalize(key_layer, dim=-1).transpose(-2, -1)\n+        attention_scores = nn.functional.normalize(query_layer, dim=-1) @ nn.functional.normalize(\n+            key_layer, dim=-1\n+        ).transpose(-2, -1)\nlogit_scale = torch.clamp(self.logit_scale, max=math.log(1.0 / 0.01)).exp()\nattention_scores = attention_scores * logit_scale\nrelative_position_bias_table = self.continuous_position_bias_mlp(self.relative_coords_table).view(\n", "fix_pattern": "The pattern for fixing the API method problem in this code change is to replace the deprecated API `F.normalize()` with `nn.functional.normalize()`."}

{"number": 4, "change": "class TrainerIntegrationTest(unittest.TestCase):\n\n# Adding one column not used by the model should have no impact\nz = np.random.normal(size=(64,)).astype(np.float32)\n-        train_dataset = nlp.Dataset.from_dict({\"input_x\": x, \"label\": y, \"extra\": z})\n+        train_dataset = datasets.Dataset.from_dict({\"input_x\": x, \"label\": y, \"extra\": z})\nmodel = RegressionModel()\ntrainer = Trainer(model, args, train_dataset=train_dataset)\ntrainer.train()\n", "fix_rule": "if np.random.normal() detected, replace it with np.random.normal().astype(np.float32)"}

{"number": 7, "change": "def test_quantile():\n\n\ndef test_pi():\n-    x = torch.empty(1000).log_normal_(0, 1)\n+    x = torch.randn(1000).exp()\nassert_equal(pi(x, prob=0.8), quantile(x, probs=[0.1, 0.9]))\n", "fix_rule": "if torch.empty() dtected, replace it with torch.randn() or torch.randn().exp()"}

{"number": 8, "change": "class TPUAccelerator(Accelerator):\nReturn:\nA tensor of shape (world_size, batch, ...)\n\"\"\"\n-        return xm.all_gather(tensor, group=group, sync_grads=sync_grads)\n+        # todo: Add support for backward with all_gather\n+        if torch.distributed.is_initialized():\n+            return xm.all_gather(tensor, group=group, sync_grads=sync_grads)\n+        return tensor\n", "fix_rule": "If  torch.distributed.is_initialized() is detected, replace it with the following code:\n```\nif torch.distributed.is_initialized():\n    return xm.all_gather(tensor, group=group, sync_grads=sync_grads)\nreturn tensor\n```"}

{"number": 9, "change": "class Swinv2SelfAttention(nn.Module):\nquery_layer = self.transpose_for_scores(mixed_query_layer)\n\n# cosine attention\n-        attention_scores = F.normalize(query_layer, dim=-1) @ F.normalize(key_layer, dim=-1).transpose(-2, -1)\n+        attention_scores = nn.functional.normalize(query_layer, dim=-1) @ nn.functional.normalize(\n+            key_layer, dim=-1\n+        ).transpose(-2, -1)\nlogit_scale = torch.clamp(self.logit_scale, max=math.log(1.0 / 0.01)).exp()\nattention_scores = attention_scores * logit_scale\nrelative_position_bias_table = self.continuous_position_bias_mlp(self.relative_coords_table).view(\n", "fix_rule": "if F.normalize(query_layer, dim=-1) is detected, replace it with nn.functional.normalize(query_layer, dim=-1)\n\nif F.normalize(key_layer, dim=-1) is detected, replace it with nn.functional.normalize(key_layer, dim=-1)"}

{"number": 12, "change": "def get_rotation_matrix2d(\n\n# create output tensor\nbatch_size: int = center.shape[0]\n-    one = torch.tensor(1.).to(center.device)\n+    one = torch.tensor(1., device=center.device, dtype=center.dtype)\nM: torch.Tensor = torch.zeros(\nbatch_size, 2, 3, device=center.device, dtype=center.dtype)\nM[..., 0:2, 0:2] = scaled_rotation\n", "fix_rule": "if torch.tensor(1.).to(device) is detected, replace it with torch.tensor(1., device=center.device, dtype=center.dtype)"}

{"number": 15, "change": "class Trainer(TrainerBase):\nbreak\nsys.stdout.flush()\n\n-        model.load_state_dict(torch.load(best_model_path))\n+        if rank == 0:\n+            model.load_state_dict(torch.load(best_model_path))\nreturn model, best_metric\n\ndef _run_epoch(\n", "fix_rule": "\"\"\"\nif rank == 0: detected, replace it with model.load_state_dict(torch.load(best_model_path))\n\"\"\""}

{"number": 16, "change": "def test_preprocess_weights_for_loading_gru_incompatible():\n\ndef assert_not_compatible(src, dest, message):\nwith pytest.raises(ValueError) as ex:\n-            keras.engine.topology.preprocess_weights_for_loading(\n+            keras.engine.saving.preprocess_weights_for_loading(\ndest, initialize_weights(src).get_weights())\nassert message in ex.value.message\n", "fix_rule": "if \"keras.engine.topology.preprocess_weights_for_loading\" is detected, replace it with \"keras.engine.saving.preprocess_weights_for_loading\""}

{"number": 17, "change": "Returns:\n\"\"\"\n\n\n-class BERTScore(nlp.Metric):\n+class BERTScore(datasets.Metric):\ndef _info(self):\n-        return nlp.MetricInfo(\n+        return datasets.MetricInfo(\ndescription=_DESCRIPTION,\ncitation=_CITATION,\nhomepage=\"https://github.com/Tiiiger/bert_score\",\ninputs_description=_KWARGS_DESCRIPTION,\n-            features=nlp.Features(\n+            features=datasets.Features(\n{\n-                    \"predictions\": nlp.Value(\"string\", id=\"sequence\"),\n-                    \"references\": nlp.Sequence(nlp.Value(\"string\", id=\"sequence\"), id=\"references\"),\n+                    \"predictions\": datasets.Value(\"string\", id=\"sequence\"),\n+                    \"references\": datasets.Sequence(datasets.Value(\"string\", id=\"sequence\"), id=\"references\"),\n}\n),\ncodebase_urls=[\"https://github.com/Tiiiger/bert_score\"],\n", "fix_rule": "if nlp.Metric dtected, replace it with datasets.Metric\nif nlp.MetricInfo dtected, replace it with datasets.MetricInfo\nif nlp.Features dtected, replace it with datasets.Features\nif nlp.Value(\"string\", id=\"sequence\") dtected, replace it with datasets.Value(\"string\", id=\"sequence\")\nif nlp.Sequence(nlp.Value(\"string\", id=\"sequence\"), id=\"references\") dtected, replace it with datasets.Sequence(datasets.Value(\"string\", id=\"sequence\"), id=\"references\")"}

{"number": 18, "change": "class CoarseMaskHead(FCNMaskHead):\nfor i in range(num_fcs):\nfc_in_channels = (\nlast_layer_dim if i == 0 else self.fc_out_channels)\n-            self.fcs.append(nn.Linear(fc_in_channels, self.fc_out_channels))\n+            self.fcs.append(Linear(fc_in_channels, self.fc_out_channels))\nlast_layer_dim = self.fc_out_channels\noutput_channels = self.num_classes * self.output_area\n-        self.fc_logits = nn.Linear(last_layer_dim, output_channels)\n+        self.fc_logits = Linear(last_layer_dim, output_channels)\n\ndef init_weights(self):\nfor m in self.fcs.modules():\n", "fix_rule": "Replace \"nn.Linear\" with \"Linear\""}

{"number": 21, "change": "class SequenceTagger(flair.nn.DefaultClassifier):\nfor sentence in batch:\nsentence.remove_labels(label_name)\n\n-            loss = self._calculate_loss(features, gold_labels)\n-\nif return_loss:\n+                loss = self._calculate_loss(features, gold_labels)\noverall_loss += loss[0]\nlabel_count += loss[1]\n", "fix_rule": "if an attribute error is thrown while calling a function, wrap the function call in a try-except block."}

{"number": 23, "change": "class TacotronTrainTest(unittest.TestCase):\noptimizer = optim.Adam(model.parameters(), lr=c.lr)\nfor i in range(5):\nmel_out, linear_out, align, stop_tokens = model.forward(\n-                input, input_lengths, mel_spec)\n+                input, input_lengths, mel_spec, speaker_ids)\noptimizer.zero_grad()\nloss = criterion(mel_out, mel_spec, mel_lengths)\nstop_loss = criterion_st(stop_tokens, stop_targets)\n", "fix_rule": "if \"speaker_ids\" is missing in the model.forward() method, add it as a parameter"}

{"number": 24, "change": "def evaluate(args, model, tokenizer, prefix=\"\", test=False):\neval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n\n# multi-gpu evaluate\n-        if args.n_gpu > 1:\n+        if args.n_gpu > 1 and not isinstance(model, torch.nn.DataParallel):\nmodel = torch.nn.DataParallel(model)\n\n# Eval!\n", "fix_rule": "\"\"\"\nIf args.n_gpu > 1 and not isinstance(model, torch.nn.DataParallel) detected, replace it with model = torch.nn.DataParallel(model)\n\"\"\""}

{"number": 31, "change": "class StableDiffusionProcessingTxt2Img(StableDiffusionProcessing):\nreturn samples\n\nx = create_random_tensors([opt_C, self.firstphase_height // opt_f, self.firstphase_width // opt_f], seeds=seeds, subseeds=subseeds, subseed_strength=self.subseed_strength, seed_resize_from_h=self.seed_resize_from_h, seed_resize_from_w=self.seed_resize_from_w, p=self)\n-        samples = self.sampler.sample(self, x, conditioning, unconditional_conditioning, image_conditioning=self.create_dummy_mask(x))\n+        samples = self.sampler.sample(self, x, conditioning, unconditional_conditioning, image_conditioning=self.create_dummy_mask(x, first_phase=True))\n\nsamples = samples[:, :, self.truncate_y//2:samples.shape[2]-self.truncate_y//2, self.truncate_x//2:samples.shape[3]-self.truncate_x//2]\n", "fix_rule": "if  create_dummy_mask() dtected, replace it with create_dummy_mask(x, first_phase=True)"}

{"number": 32, "change": "def sort_batch_by_length(tensor: torch.autograd.Variable, sequence_lengths: torc\nsorted_tensor = tensor.index_select(0, permutation_index)\n# This is the equivalent of zipping with index, sorting by the original\n# sequence lengths and returning the now sorted indices.\n-    index_range = Variable(torch.range(0, len(sequence_lengths) - 1).long())\n+    index_range = Variable(torch.arange(0, len(sequence_lengths)).long())\n_, reverse_mapping = permutation_index.sort(0, descending=False)\nrestoration_indices = index_range.index_select(0, reverse_mapping)\nreturn sorted_tensor, sorted_sequence_lengths, restoration_indices\n", "fix_rule": "if `torch.range()` is detected, replace it with `torch.arange()`"}

{"number": 40, "change": "def makenp(x, modality=None):\n\ndef pytorch_np(x, modality):\nimport torch\n-    if isinstance(x, torch.autograd.variable.Variable):\n+    if isinstance(x, torch.autograd.Variable):\nx = x.data\nx = x.cpu().numpy()\nif modality == 'IMG':\n", "fix_rule": "if `isinstance(x, torch.autograd.variable.Variable)` is detected, replace it with `isinstance(x, torch.autograd.Variable)`."}

{"number": 43, "change": "class TrainingTypePlugin(ABC):\nself.lr_schedulers = schedulers\n\ndef _move_optimizer_state(self, device: Optional[torch.device] = None) -> None:\n-        \"\"\"Moves the state of the optimizers to the GPU if needed.\"\"\"\n-        device = device or self.root_device\n+        \"\"\"Moves the state of the optimizers to the appropriate device if needed.\"\"\"\nfor opt in self.optimizers:\nfor p, v in opt.state.items():\n-                opt.state[p] = apply_to_collection(v, torch.Tensor, move_data_to_device, device)\n+                # `self.root_device` would raise error if called outside the spawn process\n+                # while training on 8 and more cores.\n+                opt.state[p] = apply_to_collection(v, torch.Tensor, move_data_to_device, device or self.root_device)\n\ndef optimizer_state(self, optimizer: Optimizer) -> Dict[str, Tensor]:\n\"\"\"Returns state of an optimizer.\n", "fix_rule": "if `torch.Tensor` detected, replace it with `torch.Tensor.to(device)`"}

{"number": 50, "change": "class GraphConv(MessagePassing):\nself.lin.reset_parameters()\n\ndef forward(self, x, edge_index):\n+        if isinstance(x, Tensor):\n+            x = (x, x)\nreturn self.propagate(edge_index, x=(self.lin(x[0]), x[1]))\n", "fix_rule": "If you detect isinstance(x, Tensor) in the code change, replace it with x = (x, x) before the return statement in the forward method."}

{"number": 53, "change": "class Trainer:\n).to(self.args.device)\n\nelif is_sagemaker_dp_enabled():\n-            model = DDP(model, device_ids=[dist.get_local_rank()], broadcast_buffers=False)\n+            model = nn.parallel.DistributedDataParallel(\n+                model, device_ids=[int(os.getenv(\"SMDATAPARALLEL_LOCAL_RANK\"))]\n+            )\nelif self.args.local_rank != -1:\nkwargs = {}\nif self.args.ddp_find_unused_parameters is not None:\n", "fix_rule": "if  to(self.args.device) is detected, replace it with DistributedDataParallel(model, device_ids=[int(os.getenv(\"SMDATAPARALLEL_LOCAL_RANK\"))])"}

{"number": 54, "change": "class Network(object):\n\"\"\"\n@layer\ndef softmax(self, target, axis, name=None):\n-        max_axis = tf.reduce_max(target, axis, keepdims=True)\n+        max_axis = tf.reduce_max(target, axis, keep_dims=True)\ntarget_exp = tf.exp(target-max_axis)\n-        normalize = tf.reduce_sum(target_exp, axis, keepdims=True)\n+        normalize = tf.reduce_sum(target_exp, axis, keep_dims=True)\nsoftmax = tf.div(target_exp, normalize, name)\nreturn softmax\n", "fix_rule": "if tf.reduce_max() is detected, replace it with tf.reduce_max(). keep_dims=True"}

{"number": 55, "change": "class RNN(torch.nn.Module):\nif not isinstance(ilens, torch.Tensor):\nilens = torch.tensor(ilens)\nxs_pack = pack_padded_sequence(xs_pad, ilens.cpu(), batch_first=True)\n-        self.nbrnn.flatten_parameters()\n+        if self.training:\n+            self.nbrnn.flatten_parameters()\nif prev_state is not None and self.nbrnn.bidirectional:\n# We assume that when previous state is passed,\n# it means that we're streaming the input\n", "fix_rule": "\"\"\"\nif  not isinstance(ilens, torch.Tensor) dtected, replace it with ilens = torch.tensor(ilens)\nif self.nbrnn.bidirectional dtected, replace it with if self.training:\n    self.nbrnn.flatten_parameters()\n\"\"\""}

{"number": 56, "change": "class TFXLNetModelTest(TFModelTesterMixin, unittest.TestCase):\n# Send to model\nloss = model(tuple_input[:-1])[0]\n\n-                self.assertEqual(loss.shape, [loss_size])\n+                self.assertEqual(loss.shape.as_list(), expected_loss_size)\n\n\n@require_tf\n", "fix_rule": "if loss.shape detected, replace it with loss.shape.as_list()"}

{"number": 58, "change": "def sigmoid_example(design):\ntorch.tensor([[-1.5, 0.5], [1.5, 0.]])\n),\n(\n-        known_covariance_linear_model(torch.tensor([1., -1.]), torch.tensor(10.), torch.tensor(1.)),\n+        known_covariance_linear_model(torch.tensor([1., -1.]), torch.tensor([10., 10.]), torch.tensor(1.)),\nnz_lm_2p_10_10_1,\ntorch.tensor([[-1., 0.5], [2.5, -2.]])\n),\n", "fix_rule": "if  torch.tensor(10.) dtected, replace it with torch.tensor([10., 10.])"}

{"number": 59, "change": "class DetaModel(DetaPreTrainedModel):\nscale = 2 * math.pi\n\ndim_t = torch.arange(num_pos_feats, dtype=torch.float32, device=proposals.device)\n-        dim_t = temperature ** (2 * (dim_t // 2) / num_pos_feats)\n+        dim_t = temperature ** (2 * torch.div(dim_t, 2) / num_pos_feats)\n# batch_size, num_queries, 4\nproposals = proposals.sigmoid() * scale\n# batch_size, num_queries, 4, 128\n", "fix_rule": "if torch.div() detected, replace it with torch.true_divide()"}

{"number": 61, "change": "class LxmertAttention(nn.Module):\nattention_scores = attention_scores + attention_mask\n\n# Normalize the attention scores to probabilities.\n-        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n+        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n\n# This is actually dropping out entire tokens to attend to, which might\n# seem a bit unusual, but is taken from the original Transformer paper.\n", "fix_rule": "if nn.Softmax() detected, replace it with nn.functional.softmax()"}

{"number": 66, "change": "class DynamicConvolution2D(nn.Module):\nweight = self.linear_weight(x)  # B x T x kH\nweight = F.dropout(weight, self.dropout_rate, training=self.training)\nweight = weight.view(B, T, H, k).transpose(1, 2).contiguous()  # B x H x T x k\n-        weight_new = torch.zeros(B * H * T * (T + k - 1)).view(B, H, T, T + k - 1).fill_(float('-inf'))\n+        weight_new = torch.zeros(B * H * T * (T + k - 1), dtype=weight.dtype)\n+        weight_new = weight_new.view(B, H, T, T + k - 1).fill_(float('-inf'))\nweight_new = weight_new.to(x.device)  # B x H x T x T+k-1\nweight_new.as_strided((B, H, T, k), ((T + k - 1) * T * H, (T + k - 1) * T, T + k, 1)).copy_(weight)\nweight_new = weight_new.narrow(-1, int((k - 1) / 2), T)  # B x H x T x T(k)\n", "fix_rule": "if torch.zeros() is detected, replace it with torch.zeros().dtype=weight.dtype.\nAlso add the line weight_new = weight_new.view(B, H, T, T + k - 1).fill_(float('-inf'))."}

{"number": 68, "change": "class Gru(TransformationBase):\n\ndef tf_apply(self, x, sequence_length=None):\nx, state = tf.nn.dynamic_rnn(\n-            cell=self.cell, inputs=x, sequence_length=sequence_length, dtype=tf.float32,\n+            cell=self.cell, inputs=x, sequence_length=sequence_length, initial_state=None,\n+            dtype=util.tf_dtype(dtype='float'),\n# Weird TensorFlow behavior? (https://github.com/tensorflow/tensorflow/issues/15874)\nparallel_iterations=(self.input_spec['shape'][0] + 1)\n)\n", "fix_rule": "if tf.nn.dynamic_rnn() contains initial_state=None and dtype=util.tf_dtype(dtype='float'), replace it with initial_state=None, dtype=tf.float32, parallel_iterations=(self.input_spec['shape'][0] + 1)"}

{"number": 69, "change": "class Optimizer(Component):\nFor those we treat model as max_norm.\neg. optimizer.clip_grad_norm(max_norm)\n\"\"\"\n-            return torch.nn.utils.clip_grad_norm_(self.params, max_norm)\n+            return clip_grad_norm_(self.params, max_norm)\nelse:\n-            return torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n+            return clip_grad_norm_(model.parameters(), max_norm)\n\ndef pre_export(self, model):\npass\n", "fix_rule": "If 'torch.nn.utils.clip_grad_norm_' is detected, replace it with 'clip_grad_norm_'."}

{"number": 76, "change": "def main(args):\nbob_decision = Marginal(Search(bob))\n\n# Here Alice and Bob slightly prefer one location over the other a priori\n-    shared_preference = Variable(torch.Tensor([args.preference]))\n+    shared_preference = torch.tensor([args.preference])\n\nbob_depth = args.depth\nnum_samples = args.num_samples\n", "fix_rule": "if  Variable(torch.Tensor([variable_name])) detected, replace it with torch.tensor([variable_name])"}

{"number": 81, "change": "class Planetoid(Dataset):\n# Create unweighted sparse adjacency matrix.\nweight = torch.ones(index.size(1))\nn = input.size(0)\n-        adj = torch.sparse.FloatTensor(index, weight, torch.Size([n, n]))\n+        adj = SparseTensor(index, weight, torch.Size([n, n]))\n\n# Bundle graph to data object.\n-        self.data = Data(input, adj, position=None, target=target)\n+        self.data = Data(input, adj, position=None, target=target.long())\n\ndef __getitem__(self, index):\ndata = self.data\n", "fix_rule": "if torch.sparse.FloatTensor() is detected, replace it with SparseTensor()"}

{"number": 85, "change": "\"import sys\\n\",\n\"sys.path.append(f'{os.getcwd()}/SentEval')\\n\",\n\"\\n\",\n-        \"import tensorflow_hub as hub\\n\",\n\"import tensorflow as tf\\n\",\n+        \"\\n\",\n+        \"# Prevent TF from claiming all GPU memory so there is some left for pytorch.\\n\",\n+        \"gpus = tf.config.list_physical_devices('GPU')\\n\",\n+        \"if gpus:\\n\",\n+        \"  # Memory growth needs to be the same across GPUs.\\n\",\n+        \"  for gpu in gpus:\\n\",\n+        \"    tf.config.experimental.set_memory_growth(gpu, True)\\n\",\n+        \"\\n\",\n+        \"import tensorflow_hub as hub\\n\",\n\"import tensorflow_text\\n\",\n\"import senteval\\n\",\n\"import time\\n\",\n", "fix_rule": "if \"import tensorflow_hub as hub\" is detected, replace it with:\n```\nimport tensorflow_hub as hub\nimport tensorflow as tf\n\n# Prevent TF from claiming all GPU memory so there is some left for pytorch.\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n  # Memory growth needs to be the same across GPUs.\n  for gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)\n```"}

{"number": 88, "change": "def create_checkerboard(h, w, nw):\n\n\n# TODO: Isn't this function duplicated with eye_like?\n-def create_eye_batch(batch_size, eye_size):\n+def create_eye_batch(batch_size, eye_size, device=None, dtype=None):\n\"\"\"Creates a batch of identity matrices of shape Bx3x3\n\"\"\"\n-    return torch.eye(eye_size).view(\n+    return torch.eye(eye_size, device=device, dtype=dtype).view(\n1, eye_size, eye_size).expand(batch_size, -1, -1)\n", "fix_rule": "if torch.eye(eye_size).detected, replace it with torch.eye(eye_size, device=device, dtype=dtype)"}

{"number": 93, "change": "class DNAConv(MessagePassing):\nnum_edges = edge_index.size(1)\n\nedge_index, edge_weight = gcn_norm(edge_index, x.size(self.node_dim),\n-                                           edge_weight, self.improved, x.dtype)\n+                                           edge_weight, dtype=x.dtype)\n\nif self.cached:\nself._cache = (num_edges, edge_index, edge_weight)\n", "fix_rule": "if torch_type( )_norm( was detected, replace it with torch_type( )_norm(dtype= )"}

{"number": 94, "change": "class T5Attention(nn.Module):\nposition_bias = position_bias + mask  # (batch_size, n_heads, seq_length, key_length)\n\nscores += position_bias\n-        attn_weights = F.softmax(scores.float(), dim=-1).type_as(\n+        attn_weights = nn.functional.softmax(scores.float(), dim=-1).type_as(\nscores\n)  # (batch_size, n_heads, seq_length, key_length)\n-        attn_weights = F.dropout(\n+        attn_weights = nn.functional.dropout(\nattn_weights, p=self.dropout, training=self.training\n)  # (batch_size, n_heads, seq_length, key_length)\n", "fix_rule": "If `F.dropout(` is detected, replace it with `nn.functional.dropout(`"}

{"number": 97, "change": "def _get_ort_session_options() -> ort.SessionOptions:\nif not torch.cuda.is_available():\nsess_options.execution_mode = ort.ExecutionMode.ORT_PARALLEL\nsess_options.inter_op_num_threads = 1\n-        sess_options.intra_op_num_threads = max(torch.get_num_threads(), 1)\n+        sess_options.intra_op_num_threads = max(\n+            int(\n+                os.environ.get(\"NEBULLVM_THREADS_PER_MODEL\")\n+                or torch.get_num_threads()\n+            ),\n+            1,\n+        )\nreturn sess_options\n", "fix_rule": "if os.environ.get(\"NEBULLVM_THREADS_PER_MODEL\") is present, replace sess_options.intra_op_num_threads = max(\n                os.environ.get(\"NEBULLVM_THREADS_PER_MODEL\")\n                or torch.get_num_threads()\n            ) with sess_options.intra_op_num_threads = max(int(\n                os.environ.get(\"NEBULLVM_THREADS_PER_MODEL\")\n                or torch.get_num_threads()\n            )\n        )"}

{"number": 98, "change": "def save_best_model(model, optimizer, model_loss, best_loss, out_path,\ndef check_update(model, grad_clip, grad_top):\nr'''Check model gradient against unexpected jumps and failures'''\nskip_flag = False\n-    grad_norm = torch.nn.utils.clip_grad_norm(model.parameters(), grad_clip)\n+    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\nif np.isinf(grad_norm):\nprint(\" | > Gradient is INF !!\")\nskip_flag = True\n", "fix_rule": "if torch.nn.utils.clip_grad_norm() is used, replace it with torch.nn.utils.clip_grad_norm_()"}

{"number": 99, "change": "def quaternion_exp_to_log(quaternion: torch.Tensor,\n>>> kornia.quaternion_exp_to_log(quaternion)\ntensor([0., 0., 0.])\n\"\"\"\n-    if not torch.is_tensor(quaternion):\n+    if not isinstance(quaternion, torch.Tensor):\nraise TypeError(\"Input type is not a torch.Tensor. Got {}\".format(\ntype(quaternion)))\n", "fix_rule": "if not isinstance(quaternion, torch.Tensor) detected, replace it with raise TypeError(\"Input type is not a torch.Tensor. Got {}\".format(type(quaternion)))"}

{"number": 103, "change": "class ReformerLayer(nn.Module):\n\"\"\"\n# randomize seeds\n# use cuda generator if available\n-        if len(torch.cuda.default_generators) > 0:\n+        if hasattr(torch.cuda, \"default_generators\") and len(torch.cuda.default_generators) > 0:\n# GPU\ndevice_idx = torch.cuda.current_device()\nself.feed_forward_seed = torch.cuda.default_generators[device_idx].seed()\n", "fix_rule": "\"\"\"\nif hasattr(torch.cuda, \"default_generators\") and len(torch.cuda.default_generators) > 0:\n    device_idx = torch.cuda.current_device()\n    self.feed_forward_seed = torch.cuda.default_generators[device_idx].seed()\n\"\"\""}

{"number": 104, "change": "def get_projective_transform(center: torch.Tensor, angles: torch.Tensor) -> torc\n\n# create rotation matrix\nangle_axis_rad: torch.Tensor = K.deg2rad(angles)\n-    rmat: torch.Tensor = K.angle_axis_to_rotation_matrix(angle_axis_rad)  # Bx3x3\n+    rmat: torch.Tensor = K.angle_axis_to_rotation_matrix(angle_axis_rad) * scales.view(-1, 1, 1)  # Bx3x3\n\n# define matrix to move forth and back to origin\nfrom_origin_mat = torch.eye(4)[None].repeat(rmat.shape[0], 1, 1).type_as(center)  # Bx4x4\n", "fix_rule": "if multiplication with scales.view(-1, 1, 1) is detected, add it to the line: \nrmat: torch.Tensor = K.angle_axis_to_rotation_matrix(angle_axis_rad) * scales.view(-1, 1, 1)  # Bx3x3"}

{"number": 105, "change": "class FQETorchModel:\nq_values, _ = self.q_model({\"obs\": obs}, [], None)\nif actions is not None:\nactions = torch.tensor(actions, device=self.device, dtype=int)\n-            q_values = torch.gather(q_values, -1, actions.unsqueeze(-1)).squeeze()\n+            q_values = torch.gather(q_values, -1, actions.unsqueeze(-1)).squeeze(-1)\nreturn q_values.detach()\n\ndef estimate_v(\n", "fix_rule": "if a tensor is squeezed without specifying the dimension, replace it with tensor.squeeze(-1)"}

{"number": 107, "change": "class ModelCatalog:\nmodel_name (str): Name to register the model under.\nmodel_class (type): Python class of the model.\n\"\"\"\n-        if issubclass(model_class, tf.keras.Model):\n-            deprecation_warning(old=\"register_custom_model\", error=False)\n+        if tf is not None:\n+            if issubclass(model_class, tf.keras.Model):\n+                deprecation_warning(old=\"register_custom_model\", error=False)\n_global_registry.register(RLLIB_MODEL, model_name, model_class)\n\n@staticmethod\n", "fix_rule": "if  issubclass(model_class, tf.keras.Model) and tf is not None, replace it with deprecation_warning(old=\"register_custom_model\", error=False)\n_global_registry.register(RLLIB_MODEL, model_name, model_class)"}

{"number": 109, "change": "class DLA(nn.Module):\nif self.drop_rate > 0.:\nx = F.dropout(x, p=self.drop_rate, training=self.training)\nx = self.fc(x)\n-        if not self.global_pool.is_identity():\n-            x = x.flatten(1)  # conv classifier, flatten if pooling isn't pass-through (disabled)\n+        x = self.flatten(x)\nreturn x\n", "fix_rule": "if \"not self.global_pool.is_identity()\" is detected, replace \"x = x.flatten(1)\" with \"x = self.flatten(x)\""}

{"number": 112, "change": "class Trainer(\n\nresults = self.predict_loop.on_predict_epoch_end()\nself.predict_loop.on_predict_end()\n+\n+        # re-enable grads\n+        torch.set_grad_enabled(True)\n+\nreturn results\n\ndef run_sanity_check(self, ref_model):\n", "fix_rule": "\"\"\"\nif self.predict_loop.on_predict_epoch_end() is detected,\nreplace it with results = self.predict_loop.on_predict_epoch_end()\n\nif self.predict_loop.on_predict_end() is detected,\nreplace it with self.predict_loop.on_predict_end()\n\nif torch.set_grad_enabled(True) is detected,\nreplace it with # re-enable grads\n\nif results is detected,\nadd return results at the end of the function\n\"\"\""}

{"number": 113, "change": "def filter2d(\ninput = input.view(-1, tmp_kernel.size(0), input.size(-2), input.size(-1))\n\n# convolve the tensor with the kernel.\n-    output = F.conv2d(input, tmp_kernel, groups=tmp_kernel.size(0), padding=0, stride=1)\n+    # NOTE: type(...) to fix getting `torch.bfloat16` type.\n+    # TODO: @johnnv1, fix it through the Augmentation Base.\n+    output = F.conv2d(input, tmp_kernel, groups=tmp_kernel.size(0), padding=0, stride=1).type(input.dtype)\n\nif padding == 'same':\nout = output.view(b, c, h, w)\n", "fix_rule": "If `type(...)` is detected, replace it with `.type(input.dtype)`"}

{"number": 114, "change": "def remainder(\nres_floored = torch.where(res >= 0, torch.floor(res), torch.ceil(res))\ndiff = res - res_floored\ndiff, x2 = ivy.promote_types_of_inputs(diff, x2)\n-        return torch.mul(diff, x2, out=out)\n+        return torch.mul(diff, x2, out=out).to(x1.dtype)\nreturn torch.remainder(x1, x2, out=out)\n", "fix_rule": "if torch.mul() detected, replace it with torch.mul().to(x1.dtype)"}

{"number": 116, "change": "class EpsilonGreedy(Exploration):\ntorch.multinomial(random_valid_action_logits, 1), axis=1)\n# Pick either random or greedy.\naction = torch.where(\n-                torch.empty((batch_size, )).uniform_() < epsilon,\n+                torch.empty(\n+                    (batch_size, )).uniform_().to(self.device) < epsilon,\nrandom_actions, exploit_action)\n\nreturn action, action_logp\n", "fix_rule": "if torch.empty().uniform_() is detected, replace it with torch.empty().uniform_().to(self.device)"}

{"number": 118, "change": "class Delta(TorchDistribution):\n\ndef expand(self, batch_shape):\nvalidate_args = self.__dict__.get('_validate_args')\n+        batch_shape = torch.Size(batch_shape)\nv = self.v.expand(batch_shape + self.event_shape)\nlog_density = self.log_density.expand(batch_shape)\nreturn Delta(v, log_density, self.event_dim, validate_args=validate_args)\n", "fix_rule": "if `torch.Size()` is detected, replace it with `torch.Size(batch_shape)`"}

{"number": 119, "change": "def main():\n\npruner = AGP_Pruner(model, configure_list)\nmodel = pruner.compress()\n-\n+    model = model.to(device)\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\nfor epoch in range(10):\npruner.update_epoch(epoch)\nprint('# Epoch {} #'.format(epoch))\ntrain(model, device, train_loader, optimizer)\ntest(model, device, test_loader)\n-    pruner.export_model('model.pth', 'mask.pth', 'model.onnx', [1, 1, 28, 28])\n+    pruner.export_model('model.pth', 'mask.pth', 'model.onnx', [1, 1, 28, 28], device)\n\n\nif __name__ == '__main__':\n", "fix_rule": "if 'model = model.to(device)' is not present, add 'model = model.to(device)' after 'model = pruner.compress()'\nif the fourth argument in 'pruner.export_model' is not 'device', replace it with 'device'"}

{"number": 121, "change": "from ray.air.config import ScalingConfig\n\n\ndef mnist_dataset(batch_size: int) -> tf.data.Dataset:\n-    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n+    with FileLock(os.path.expanduser(\"~/.mnist_lock\")):\n+        (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n# The `x` arrays are in uint8 and have values in the [0, 255] range.\n# You need to convert them to float32 with values in the [0, 1] range.\nx_train = x_train / np.float32(255)\n", "fix_rule": "if FileLock(os.path.expanduser(\"~/.mnist_lock\")) is detected, add \"with \" in front of it."}

{"number": 126, "change": "def main_fun(argv, ctx):\ngrads = average_gradients(tower_grads)\n\n# Add a summary to track the learning rate.\n-      summaries.append(tf.scalar_summary('learning_rate', lr))\n+      summaries.append(tf.summary.scalar('learning_rate', lr))\n\n# Add histograms for gradients.\nfor grad, var in grads:\nif grad is not None:\nsummaries.append(\n-              tf.histogram_summary(var.op.name + '/gradients', grad))\n+              tf.summary.histogram(var.op.name + '/gradients', grad))\n\n# Apply the gradients to adjust the shared variables.\napply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n\n# Add histograms for trainable variables.\nfor var in tf.trainable_variables():\n-        summaries.append(tf.histogram_summary(var.op.name, var))\n+        summaries.append(tf.summary.histogram(var.op.name, var))\n\n# Track the moving averages of all trainable variables.\nvariable_averages = tf.train.ExponentialMovingAverage(\n", "fix_rule": "\"\"\"\nIf tf.scalar_summary is detected, replace it with tf.summary.scalar.\nIf tf.histogram_summary is detected, replace it with tf.summary.histogram.\n\"\"\""}

{"number": 127, "change": "class Trainer(TrainerBase):\n\n@timing.time(\"Trainer.test\")\ndef test(self, test_iter, model, metric_reporter: MetricReporter):\n+        if cuda.CUDA_ENABLED:\n+            model = model.cuda()\n+\nmodel.eval()\nwith torch.no_grad():\ntest_metric = self._run_epoch(\n", "fix_rule": "If cuda.CUDA_ENABLED is detected, replace it with model = model.cuda()"}

{"number": 128, "change": "class TrainingArguments:\n@torch_required\ndef _setup_devices(self) -> \"torch.device\":\nlogger.info(\"PyTorch: setting up devices\")\n-        if torch.distributed.is_initialized() and self.local_rank == -1:\n+        if torch.distributed.is_available() and torch.distributed.is_initialized() and self.local_rank == -1:\nlogger.warning(\n\"torch.distributed process group is initialized, but local_rank == -1. \"\n\"In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\"\n", "fix_rule": "if  torch.distributed.is_initialized()  detected, replace it with torch.distributed.is_available() and torch.distributed.is_initialized()"}

{"number": 131, "change": "with tf.Graph().as_default():\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"model\")\nif not os.path.exists(checkpoint_dir):\nos.makedirs(checkpoint_dir)\n-        saver = tf.train.Saver(tf.all_variables())\n+        saver = tf.train.Saver(tf.global_variables())\n\n# Write vocabulary\nvocab_processor.save(os.path.join(out_dir, \"vocab\"))\n\n# Initialize all variables\n-        sess.run(tf.initialize_all_variables())\n+        sess.run(tf.global_variables_initializer())\n\ndef train_step(x_batch, y_batch):\n\"\"\"\n", "fix_rule": "if tf.all_variables() is detected, replace it with tf.global_variables()\nif tf.initialize_all_variables() is detected, replace it with tf.global_variables_initializer()"}

{"number": 132, "change": "class CLIPTextTransformer(nn.Module):\nattentions=encoder_outputs.attentions,\n)\n\n-    def _build_causal_attention_mask(self, bsz, seq_len):\n+    def _build_causal_attention_mask(self, bsz, seq_len, dtype):\n# lazily create causal attention mask, with full attention between the vision tokens\n# pytorch uses additive attention mask; fill with -inf\n-        mask = torch.empty(bsz, seq_len, seq_len)\n-        mask.fill_(torch.tensor(float(\"-inf\")))\n+        mask = torch.empty(bsz, seq_len, seq_len, dtype=dtype)\n+        mask.fill_(torch.tensor(torch.finfo(dtype).min))\nmask.triu_(1)  # zero out the lower diagonal\nmask = mask.unsqueeze(1)  # expand mask\nreturn mask\n", "fix_rule": "if dtype = None, set dtype = torch.float32 \n"}

{"number": 135, "change": "def get_mini_batch(mini_batch_indices, sequences, seq_lengths, cuda=False):\n# get mask for mini-batch\nmini_batch_mask = get_mini_batch_mask(mini_batch, sorted_seq_lengths)\n\n-    # wrap in PyTorch Variables\n-    mini_batch = Variable(torch.Tensor(mini_batch))\n-    mini_batch_reversed = Variable(torch.Tensor(mini_batch_reversed))\n-    mini_batch_mask = Variable(torch.Tensor(mini_batch_mask))\n+    # wrap in PyTorch Tensors\n+    mini_batch = torch.tensor(mini_batch)\n+    mini_batch_reversed = torch.tensor(mini_batch_reversed)\n+    mini_batch_mask = torch.tensor(mini_batch_mask)\n\n# cuda() here because need to cuda() before packing\nif cuda:\n", "fix_rule": "\"\"\"\nIf Variable(torch.Tensor(dtected), replace it with torch.tensor(dtected)\n\"\"\""}

{"number": 137, "change": "class FlopsProfiler(object):\nstart_time_hook)\n\ndef end_time_hook(module, input, output):\n-                torch.cuda.synchronize()\n+                get_accelerator().synchronize()\nmodule.__duration__ += time.time() - module.__start_time__\n\nif not hasattr(module, \"__end_time_hook_handle__\"):\n", "fix_rule": "If `torch.cuda.synchronize()` is detected, replace it with `get_accelerator().synchronize()`."}

{"number": 140, "change": "class PaintByExample(DiffusionInpaintModel):\nmask: [H, W, 1] 255 means area to repaint\nreturn: BGR IMAGE\n\"\"\"\n-        set_seed(config.paint_by_example_seed)\n-\noutput = self.model(\nimage=PIL.Image.fromarray(image),\nmask_image=PIL.Image.fromarray(mask[:, :, -1], mode=\"L\"),\nexample_image=config.paint_by_example_example_image,\nnum_inference_steps=config.paint_by_example_steps,\noutput_type='np.array',\n+            generator=torch.manual_seed(config.paint_by_example_seed)\n).images[0]\n\noutput = (output * 255).round().astype(\"uint8\")\n", "fix_rule": "if set_seed() is removed, add it back with the argument config.paint_by_example_seed.\nif generator=torch.manual_seed() is not present, add it with the argument config.paint_by_example_seed."}

{"number": 141, "change": "class BigBirdPegasusBlockSparseAttention(nn.Module):\nnum_indices_to_gather = indices.shape[-2] * indices.shape[-1]\nnum_indices_to_pick_from = params.shape[2]\n\n-        indices_shift = (\n-            torch.arange(indices.shape[0] * indices.shape[1] * num_indices_to_gather, device=indices.device)\n-            // num_indices_to_gather\n-            * num_indices_to_pick_from\n-        )\n+        shift = torch.arange(indices.shape[0] * indices.shape[1] * num_indices_to_gather, device=indices.device)\n+        indices_shift = torch_int_div(shift, num_indices_to_gather) * num_indices_to_pick_from\n\nflattened_indices = indices.view(-1) + indices_shift\nflattened_params = params.reshape(-1, params.shape[-2], params.shape[-1])\n", "fix_rule": "if torch.arange() detected, replace it with shift = torch.arange() and use torch_int_div(shift, num_indices_to_gather) instead of indices_shift = (...)"}

{"number": 151, "change": "def main(args):\n# CNN will transform a high dimension image into a low dimension 2D tensors for RBF kernel.\n# This kernel accepts inputs are inputs of CNN and gives outputs are covariance matrix of RBF on\n# outputs of CNN.\n-    kernel = gp.kernels.RBF(input_dim=10, lengthscale=torch.ones(10)).warp(iwarping_fn=cnn_fn)\n+    kernel = gp.kernels.Warp(gp.kernels.RBF(input_dim=10, lengthscale=torch.ones(10)),\n+                             iwarping_fn=cnn_fn)\n\n# init inducing points (taken randomly from dataset)\nXu = next(iter(train_loader))[0][:args.num_inducing]\n", "fix_rule": "if gp.kernels.RBF() dtected, replace it with gp.kernels.Warp(gp.kernels.RBF(), iwarping_fn=cnn_fn)"}

{"number": 153, "change": "def linspace_helper(start, stop, num, axis=None, *, device):\nelse:\nres = [linspace_method(start, stp, num, device=device) for stp in stop]\nelse:\n-        return linspace_method(start, stop, num, device=device)\n+        return linspace_method(start, stop, num, dtype=torch.float64, device=device)\nres = torch.cat(res, -1).reshape(sos_shape + [num])\nif axis is not None:\nres = torch.transpose(res, axis, -1)\n", "fix_rule": "if  \"dtype=torch.float64\" is not present, add dtype=torch.float64 to the linspace_method() function call."}

{"number": 159, "change": "class PatchAffineShapeEstimator(nn.Module):\n\"input shape should be must be [Bx1x{}x{}]. \"\n\"Got {}\".format(self.patch_size, self.patch_size, patch.size()))\nself.weighting = self.weighting.to(patch.dtype).to(patch.device)\n-        grads: torch.Tensor = self.gradient(patch)\n+        grads: torch.Tensor = self.gradient(patch) * self.weighting\n# unpack the edges\ngx: torch.Tensor = grads[:, :, 0]\ngy: torch.Tensor = grads[:, :, 1]\n", "fix_rule": "\"\"\"\nif \"Got {}\".format mentioned, replace it with \"Got {}\".format(self.patch_size, self.patch_size, patch.size())\nif self.weighting.to(patch.dtype).to(patch.device) mentioned, replace it with self.weighting\nif self.gradient(patch) * self.weighting mentioned, replace it with grads\n\"\"\""}

{"number": 163, "change": "def non_max_suppression(prediction, conf_thres=0.1, iou_thres=0.6, classes=None,\nmerge = False  # use merge-NMS\n\nt = time.time()\n-    output = [torch.zeros(0, 6)] * prediction.shape[0]\n+    output = [torch.zeros((0, 6), device=prediction.device)] * prediction.shape[0]\nfor xi, x in enumerate(prediction):  # image index, image inference\n# Apply constraints\n# x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height\n", "fix_rule": "if torch.zeros() detected, replace it with torch.zeros((0, 6), device=prediction.device)"}

{"number": 166, "change": "class DartsTrainer(BaseOneShotTrainer):\np += e * d\n\n_, loss = self._logits_and_loss(trn_X, trn_y)\n-            dalphas.append(torch.autograd.grad(loss, [c.alpha for c in self.nas_modules]))\n+            dalphas.append(torch.autograd.grad(loss, [c.alpha for _, c in self.nas_modules]))\n\ndalpha_pos, dalpha_neg = dalphas  # dalpha { L_trn(w+) }, # dalpha { L_trn(w-) }\nhessian = [(p - n) / (2. * eps) for p, n in zip(dalpha_pos, dalpha_neg)]\n", "fix_rule": "if \"torch.autograd.grad(loss, [c.alpha for c in self.nas_modules])\" is detected, replace it with \"torch.autograd.grad(loss, [c.alpha for _, c in self.nas_modules])\""}

{"number": 167, "change": "def subtract(\nout: Optional[Union[tf.Tensor, tf.Variable]] = None,\n) -> Union[tf.Tensor, tf.Variable]:\nx1, x2 = ivy.promote_types_of_inputs(x1, x2)\n-    return tf.subtract(x1, x2)\n+    return tf.experimental.numpy.subtract(x1, x2)\n\n\ndef tan(\n", "fix_rule": "if tf.subtract() detected, replace it with tf.experimental.numpy.subtract()"}

{"number": 169, "change": "class XDropout(torch.autograd.Function):\n# Once https://github.com/pytorch/pytorch/issues/78391 is fixed, do something like:\n# if opset_version < 12:\n#   return torch.onnx.symbolic_opset9.dropout(g, input, dropout_p, train)\n-        return torch.onnx.symbolic_opset12.dropout(g, input, dropout_p, train)\n+        return symbolic_opset12.dropout(g, input, dropout_p, train)\n\n\n# Copied from transformers.models.deberta.modeling_deberta.StableDropout\n", "fix_rule": "if  torch.onnx.symbolic_opset12.dropout() detected, replace it with symbolic_opset12.dropout()"}

{"number": 177, "change": "class IvyModule(ivy.Module):\nif ivy.array_mode():\na, kw = ivy.args_to_native(*a, **kw)\n# noinspection PyUnresolvedReferences\n-        params_hk = self._native_module.init(ivy.functional.core.random.RNG, *a, **kw)\n+        params_hk = self._native_module.init(ivy.random.RNG, *a, **kw)\nparams_dict = _hk_flat_map_to_dict(params_hk)\nself._hk_params = ivy.Container(params_dict)\nparam_iterator = self._hk_params.to_iterator()\n", "fix_rule": "if ivy.array_mode():\na, kw = ivy.args_to_native(*a, **kw)\n# noinspection PyUnresolvedReferences\n-        params_hk = self._native_module.init(ivy.functional.core.random.RNG, *a, **kw)\n+        params_hk = self._native_module.init(ivy.random.RNG, *a, **kw)\nparams_dict = _hk_flat_map_to_dict(params_hk)\nself._hk_params = ivy.Container(params_dict)\nparam_iterator = self._hk_params.to_iterator()\n\nIn the given code change, the following fix pattern can be identified:\n-        params_hk = self._native_module.init(ivy.functional.core.random.RNG, *a, **kw)\n+        params_hk = self._native_module.init(ivy.random.RNG, *a, **kw)\n\nThe fix pattern is to replace \"ivy.functional.core.random.RNG\" with \"ivy.random.RNG\"."}

{"number": 181, "change": "class TensorFlowEstimator(BaseEstimator):\nraise NotFittedError()\npredict_data_feeder = setup_predict_data_feeder(X)\npreds = []\n-        dropouts = tf.get_collection(DROPOUTS)\n-        feed_dict = {prob: 0.0 for prob in dropouts}\n+        dropouts = self._graph.get_collection(DROPOUTS)\n+        feed_dict = {prob: 1.0 for prob in dropouts}\nfor data in predict_data_feeder:\nfeed_dict[self._inp] = data\npreds.append(self._session.run(\n", "fix_rule": "if tf.get_collection(DROPOUTS) is detected, replace it with self._graph.get_collection(DROPOUTS)\nif {prob: 0.0 for prob in dropouts} is detected, replace it with {prob: 1.0 for prob in dropouts}"}

{"number": 182, "change": "class GradientsTest(tf.test.TestCase):\nself.assertAllClose(eager_result, function_result)\nbackprop_result, numeric_result = tf.test.compute_gradient(\nm, [inp], delta=1e-3)\n-    self.assertAllClose(numeric_result, backprop_result, rtol=1e-2)\n+    self.assertAllClose(numeric_result, backprop_result, atol=1e-3)\nself.assertAllClose(tf.reshape(numeric_result, [-1]),\n-                        tf.reshape(eager_result, [-1]), rtol=1e-2)\n+                        tf.reshape(eager_result, [-1]), atol=1e-3)\n\ndef testEmbeddingLookupGradientsHaveKnownShape(self):\n", "fix_rule": "if rtol or atol is specified as 1e-2, replace it with atol=1e-3"}

{"number": 187, "change": "class Pix2PixModel(BaseModel):\ndef backward_D(self):\n# Fake\n# stop backprop to the generator by detaching fake_B\n-        fake_AB = self.fake_AB_pool.query(torch.cat((self.real_A, self.fake_B), 1))\n+        fake_AB = self.fake_AB_pool.query(torch.cat((self.real_A, self.fake_B), 1).data)\npred_fake = self.netD.forward(fake_AB.detach())\nself.loss_D_fake = self.criterionGAN(pred_fake, False)\n\n# Real\nreal_AB = torch.cat((self.real_A, self.real_B), 1)\npred_real = self.netD.forward(real_AB)\n-        self.loss_D_real = self.criterionGAN(self.pred_real, True)\n+        self.loss_D_real = self.criterionGAN(pred_real, True)\n\n# Combined loss\nself.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n", "fix_rule": "if  torch.cat() detected, replace it with torch.cat().data"}

{"number": 193, "change": "class tensorflow_extractor(base_extractor):\nwriter.close()\nsess.run(init)\nsaver = tf.train.Saver()\n+            tf.train.export_meta_graph(\"kit.meta\", as_text=True)\nsaver.restore(sess, path + cls.architecture_map[architecture]['filename'])\nsave_path = saver.save(sess, path + \"imagenet_{}.ckpt\".format(architecture))\nprint(\"Model saved in file: %s\" % save_path)\n", "fix_rule": "if \"tf.train.export_meta_graph\" is detected, replace it with \"tf.train.export_meta_graph('kit.meta', as_text=True)\""}

{"number": 194, "change": "def test_auto_diagonal_gaussians(auto_class, Elbo):\nguide = auto_class(model, rank=1)\nelse:\nguide = auto_class(model)\n-    adam = optim.Adam({\"lr\": .001, \"betas\": (0.95, 0.999)})\n+    adam = optim.ClippedAdam({\"lr\": .01, \"betas\": (0.95, 0.999),\n+                              \"lrd\": 0.1 ** (1 / n_steps)})\nsvi = SVI(model, guide, adam, loss=Elbo())\n\nfor k in range(n_steps):\n", "fix_rule": "if optim.Adam is detected, replace it with optim.ClippedAdam({\"lr\": .01, \"betas\": (0.95, 0.999), \"lrd\": 0.1 ** (1 / n_steps)})"}

{"number": 195, "change": "def test_frontend_backward_multi_channel(train, use_wpe, use_beamformer):\nfrontend.train()\nelse:\nfrontend.eval()\n+    torch.random.manual_seed(14)\nx = torch.randn(2, 1000, 2, requires_grad=True)\nx_lengths = torch.LongTensor([1000, 980])\ny, y_lengths = frontend(x, x_lengths)\n", "fix_rule": "If `torch.random.manual_seed(14)` is detected, replace it with `torch.manual_seed(14)`."}

{"number": 197, "change": "class TestGradientScaling(unittest.TestCase):\noptimizer = FP16Optimizer.build_optimizer(self.namespace_dls, params)\n\nself.run_iter(model, params, optimizer)\n-        self.assertTrue(torch.all(optimizer.fp32_params.eq(torch.tensor([3.1000, 5.1000], device='cuda:0', requires_grad=True))))\n+        self.assertTrue(all(\n+            torch.all(fp32_params.eq(torch.tensor([3.1000, 5.1000], device='cuda:0', requires_grad=True)))\n+            for fp32_params in optimizer.fp32_params.values()\n+        ))\n\ndef test_memory_efficient(self):\nmodel = copy.deepcopy(self.model)\n", "fix_rule": "if  optimizer.fp32_params detected, replace it with torch.all(fp32_params.eq(torch.tensor([3.1000, 5.1000], device='cuda:0', requires_grad=True))) for fp32_params in optimizer.fp32_params.values()"}

{"number": 198, "change": "class TestLuvToRgb(BaseTester):\n[0.06325728, 0.78878325, 0.74280596, 0.99514300, 0.47176042]]\n]], device=device, dtype=dtype)\n\n-        assert_allclose(kornia.color.luv_to_rgb(data), expected)\n+        assert_allclose(kornia.color.luv_to_rgb(data), expected, rtol=1e-4, atol=1e-4)\n\ndef test_forth_and_back(self, device, dtype):\ndata = torch.rand(3, 4, 5, device=device, dtype=dtype)\n", "fix_rule": "if assert_allclose(kornia.color.luv_to_rgb(data), expected) dtected, replace it with assert_allclose(kornia.color.luv_to_rgb(data), expected, rtol=1e-4, atol=1e-4)"}

{"number": 199, "change": "class EulerSamplingTest(tf.test.TestCase, parameterized.TestCase):\ntimes=times,\nnum_samples=num_samples,\ninitial_state=x0,\n-            random_type=tff.math.random.RandomType.SOBOL,\n+            random_type=tff.math.random.RandomType.HALTON,\ntime_step=0.01,\n-            seed=12134))\n+            seed=12134,\n+            skip=100,\n+            dtype=tf.float32))\n\n-    self.assertAllClose(paths.shape, (num_samples, 5, 2), atol=0)\n+    self.assertAllClose(paths.shape, (num_samples, 3, 2), atol=0)\nmeans = np.mean(paths, axis=0)\ntimes = np.reshape(times, [-1, 1])\nexpected_means = x0 + (2.0 / 3.0) * mu * np.power(times, 1.5)\n", "fix_rule": "If \"tff.math.random.RandomType.SOBOL\" is detected, replace it with \"tff.math.random.RandomType.HALTON\".\n\nIf \"seed=12134\" is detected, replace it with \"seed=12134, skip=100, dtype=tf.float32\".\n\nIf \"self.assertAllClose(paths.shape, (num_samples, 5, 2), atol=0)\" is detected, replace it with \"self.assertAllClose(paths.shape, (num_samples, 3, 2), atol=0)\"."}

{"number": 203, "change": "class BatchNorm(TransformModule):\nif self.training:\nmean, var = y.mean(0), y.var(0)\n\n-            # NOTE: The momentum variable agrees with the definition in e.g. `torch.nn.BatchNorm1d`\n-            self.moving_mean.mul_(1 - self.momentum).add_(mean * self.momentum)\n-            self.moving_variance.mul_(1 - self.momentum).add_(var * self.momentum)\n+            with torch.no_grad():\n+                # NOTE: The momentum variable agrees with the definition in e.g. `torch.nn.BatchNorm1d`\n+                self.moving_mean.mul_(1 - self.momentum).add_(mean * self.momentum)\n+                self.moving_variance.mul_(1 - self.momentum).add_(var * self.momentum)\n\n# During test time, use smoothed averages rather than the sample ones\nelse:\n", "fix_rule": "if  torch.no_grad() detected, wrap the code block with \"with torch.no_grad():\""}

{"number": 210, "change": "def train_model(params: Params, serialization_dir: str) -> Model:\n\nlogger.info(\"Creating a vocabulary using %s data.\", \", \".join(datasets_for_vocab_creation))\nvocab = Vocabulary.from_params(params.pop(\"vocabulary\", {}),\n-                                   Dataset([instance for key, dataset in all_datasets.items()\n-                                            for instance in dataset.instances\n-                                            if key in datasets_for_vocab_creation]))\n+                                   (instance for key, dataset in all_datasets.items()\n+                                    for instance in dataset\n+                                    if key in datasets_for_vocab_creation))\nvocab.save_to_files(os.path.join(serialization_dir, \"vocabulary\"))\n\nmodel = Model.from_params(vocab, params.pop('model'))\n", "fix_rule": "if Dataset detected, replace it with (instance for key, dataset in all_datasets.items()\n                                for instance in dataset)"}

{"number": 214, "change": "class KerasBackend(AbstractBackend):\nreturn keras\n\ndef einsum(self, pattern, *x):\n-        return self.tf.einsum(pattern, *x)\n+        return self.tf.vectorized_map(\n+            functools.partial(self.tf.einsum, pattern),\n+            *x\n+        )\n\n\nclass OneFlowBackend(AbstractBackend):\n", "fix_rule": "if  self.tf.einsum(pattern, *x) dtected, replace it with \nself.tf.vectorized_map(\n    functools.partial(self.tf.einsum, pattern),\n    *x\n)"}

{"number": 215, "change": "def run_modelmerger(primary_model_name, secondary_model_name, teritary_model_nam\nt2 = theta_2.get(key, torch.zeros_like(theta_1[key]))\ntheta_1[key] = theta_func1(theta_1[key], t2)\nelse:\n-                    theta_1[key] = 0\n+                    theta_1[key] = torch.zeros_like(theta_1[key])\ndel theta_2, teritary_model\n\nfor key in tqdm.tqdm(theta_0.keys()):\n", "fix_rule": "if \"theta_1[key] = 0\" detected, replace it with \"theta_1[key] = torch.zeros_like(theta_1[key])\""}

{"number": 216, "change": "class DefaultClassifier(Classifier):\n\ndef _calculate_loss(self, scores, labels):\n\n-        if len(labels) == 0: return torch.tensor(0., requires_grad=True), 1\n+        if len(labels) == 0: return torch.tensor(0., requires_grad=True, device=flair.device), 1\n\nif self.multi_label:\nlabels = torch.tensor([[1 if l in all_labels_for_point else 0 for l in self.label_dictionary.get_items()]\n", "fix_rule": "if torch.tensor() detected, replace it with torch.tensor().to(device)"}

{"number": 217, "change": "class EmbeddingLayer(nn.Module):\ntorch.empty(weight_shape[0],\nweight_shape[1],\ndtype=dtype,\n-                        device=torch.cuda.current_device()))\n+                        device=get_accelerator().current_device_name()))\n\ndef forward(self, input):\nreturn F.embedding(input, self.weight)\n", "fix_rule": "if torch.cuda.current_device() detected, replace it with get_accelerator().current_device_name()"}

{"number": 218, "change": "class MultiActionDistribution(ActionDistribution):\n\ndef logp(self, x):\n\"\"\"The log-likelihood of the action distribution.\"\"\"\n-        split_list = self.reshaper.split_tensor(x)\n+        split_list = tf.split(x, len(self.input_lens), axis=1)\nfor i, distribution in enumerate(self.child_distributions):\n# Remove extra categorical dimension\nif isinstance(distribution, Categorical):\n", "fix_rule": "if  self.reshaper.split_tensor() dtected, replace it with tf.split()."}

{"number": 219, "change": "class CategoricalOneHotPolicy(StochasticPolicy):\ndef __init__(self, network, session, state, random, action_count=1, scope='policy'):\nwith tf.variable_scope(scope):\naction_layer = linear(layer_input=network.output, config={'num_outputs': action_count}, scope='outputs')\n+            action_layer = tf.reshape(action_layer, [-1, action_count])\n+\ndistribution = tf.nn.softmax(action_layer)\nsample = tf.multinomial(distribution, 1)\n", "fix_rule": "if tf.reshape(action_layer) is detected, replace it with tf.reshape(action_layer, [-1, action_count])"}

{"number": 221, "change": "class SingleRoIExtractor(nn.Module):\nout_size = self.roi_layers[0].out_size\nnum_levels = len(feats)\ntarget_lvls = self.map_roi_levels(rois, num_levels)\n-        roi_feats = torch.cuda.FloatTensor(rois.size()[0], self.out_channels,\n-                                           out_size, out_size).fill_(0)\n+        roi_feats = feats[0].new_zeros(rois.size()[0], self.out_channels,\n+                                       out_size, out_size)\nfor i in range(num_levels):\ninds = target_lvls == i\nif inds.any():\n", "fix_rule": "if  torch.cuda.FloatTensor() detected, replace it with feats[0].new_zeros()"}

{"number": 223, "change": "class MobileNetV3LargeEncoder(MobileNetV3):\n)\n\nif pretrained:\n-            self.load_state_dict(load_state_dict_from_url(\n+            self.load_state_dict(torch.hub.load_state_dict_from_url(\n'https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth'))\n\ndel self.avgpool\n", "fix_rule": "if `torch.hub.load_state_dict_from_url` is detected, replace it with `torch.load_state_dict_from_url`"}

{"number": 224, "change": "def make_non_pad_mask(lengths):\n\"\"\"\nbs = int(len(lengths))\nmaxlen = int(max(lengths))\n-    mask = torch.zeros(bs, maxlen).byte()\n+    mask = torch.zeros(bs, maxlen, dtype=torch.uint8)\nfor i, l in enumerate(lengths):\nmask[i, :l] = 1\n", "fix_rule": "if  torch.zeros() dtype detected, replace it with torch.zeros(dtype=torch.uint8)"}

{"number": 229, "change": "class TFXGLMPreTrainedModel(TFPreTrainedModel):\n@tf.function(\ninput_signature=[\n{\n-                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),\n-                \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),\n+                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),\n+                \"attention_mask\": tf.TensorSpec((None, None), tf.int64, name=\"attention_mask\"),\n}\n]\n)\n", "fix_rule": "If \"tf.TensorSpec((None, None), tf.int32, name=\"input_ids\")\" is detected, replace it with \"tf.TensorSpec((None, None), tf.int64, name=\"input_ids\")\".\nIf \"tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\")\" is detected, replace it with \"tf.TensorSpec((None, None), tf.int64, name=\"attention_mask\")\"."}

{"number": 231, "change": "class SpeedyResNet:\nnn.Linear(512, num_classes, bias=False)\n]\n\n-  # note, pytorch just uses https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html instead of logsoftmax\n-  def __call__(self, x): return x.sequential(self.net).logsoftmax()\n+  # note, pytorch just uses https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html instead of log_softmax\n+  def __call__(self, x): return x.sequential(self.net).log_softmax()\n\nfrom extra.jit import TinyJit\n@TinyJit\n", "fix_rule": "\"\"\"\nIf  x.sequential(self.net).logsoftmax() is detected, replace it with x.sequential(self.net).log_softmax()\n\"\"\""}

{"number": 234, "change": "class EulerAncestralDiscreteScheduler(SchedulerMixin, ConfigMixin):\n\nprev_sample = sample + derivative * dt\n\n-        device = model_output.device if torch.is_tensor(model_output) else torch.device(\"cpu\")\n+        device = model_output.device\nif device.type == \"mps\":\n# randn does not work reproducibly on mps\nnoise = torch.randn(model_output.shape, dtype=model_output.dtype, device=\"cpu\", generator=generator).to(\n", "fix_rule": "if torch.is_tensor(model_output) is detected, replace it with model_output.device\n\nif device.type == \"mps\" is detected, remove the line\n\nif torch.randn() is detected, replace it with torch.randn().to(device)"}

{"number": 236, "change": "def _create_fc(num_features, num_classes, use_conv=False):\nelif use_conv:\nfc = nn.Conv2d(num_features, num_classes, 1, bias=True)\nelse:\n-        # NOTE: using my Linear wrapper that fixes AMP + torchscript casting issue\n-        fc = Linear(num_features, num_classes, bias=True)\n+        fc = nn.Linear(num_features, num_classes, bias=True)\nreturn fc\n", "fix_rule": "if Linear(num_features, num_classes, bias=True) dtected, replace it with nn.Linear(num_features, num_classes, bias=True)"}

{"number": 241, "change": "class GenerationMixin:\ncontinue  # don't waste resources running the code we don't need\n\nnext_token_logits = outputs.logits[:, -1, :]\n-\n-            # hack: adjust tokens for Marian. For Marian we have to make sure that the `pad_token_id`\n-            # cannot be generated both before and after the `nn.functional.log_softmax` operation.\n-            next_token_logits = outputs.logits[:, -1, :]\n# hack: adjust tokens for Marian. For Marian we have to make sure that the `pad_token_id`\n# cannot be generated both before and after the `nn.functional.log_softmax` operation.\nnext_token_logits = self.adjust_logits_during_generation(next_token_logits, cur_len=cur_len)\n", "fix_rule": "# hack: adjust tokens for Marian. For Marian we have to make sure that the `pad_token_id` cannot be generated both before and after the `nn.functional.log_softmax` operation. \nnext_token_logits = self.adjust_logits_during_generation(next_token_logits, cur_len=cur_len)"}

{"number": 244, "change": "def test_runway_sd_1_5_negative_prompt(sd_device, strategy, sampler):\ndef test_cv2(strategy, cv2_flag, cv2_radius):\nmodel = ModelManager(\nname=\"cv2\",\n-        device=device,\n+        device=torch.device(device),\n)\ncfg = get_config(strategy, cv2_flag=cv2_flag, cv2_radius=cv2_radius)\nassert_equal(\n", "fix_rule": "if \"device=device\" is detected, replace it with \"device=torch.device(device)\"."}

{"number": 245, "change": "class Model(ModelDesc):\nsummary.add_moving_summary(self.cost)\n\ndef _get_optimizer(self):\n-        lr = tf.get_variable('learning_rate', initializer=1e-3, trainable=False)\n+        lr = tf.get_variable('learning_rate', initializer=self.learning_rate, trainable=False)\nopt = tf.train.AdamOptimizer(lr, epsilon=1e-3)\nreturn optimizer.apply_grad_processors(\nopt, [gradproc.GlobalNormClip(10), gradproc.SummaryGradient()])\n", "fix_rule": "if tf.get_variable('learning_rate', initializer= detected, replace it with tf.get_variable('learning_rate', initializer=self.learning_rate, trainable=False)"}

{"number": 246, "change": "class Network(object):\nweights = self.make_var('weights', shape=[dim, num_out])\nbiases = self.make_var('biases', [num_out])\nop = tf.nn.relu_layer if relu else tf.nn.xw_plus_b\n-            fc = op(feed_in, weights, biases, name=scope.name)\n+            #fc = op(feed_in, weights, biases, name=scope.name)\n+            fc = op(feed_in, weights, biases, name=name)\nreturn fc\n", "fix_rule": "\"\"\"\nif op(feed_in, weights, biases, name=scope.name) detected, replace it with \n#fc = op(feed_in, weights, biases, name=scope.name)\n+            fc = op(feed_in, weights, biases, name=name)\n\"\"\""}

{"number": 250, "change": "def train_cnn_and_compute_accuracy(params, steps, train_images, train_labels, va\n# Do the training and evaluation.\nwith tf.Session() as sess:\n# Initialize the network weights.\n-    sess.run(tf.initialize_all_variables())\n+    sess.run(tf.global_variables_initializer())\nfor i in range(1, steps + 1):\n# Fetch the next batch of data.\nimage_batch = get_batch(train_images, i, batch_size)\n", "fix_rule": "if  tf.initialize_all_variables() dtected, replace it with tf.global_variables_initializer()"}

{"number": 252, "change": "class DeepSpeedDataLoader(object):\nelse:\nif data_sampler is None:\ndata_sampler = RandomSampler(dataset)\n-                device_count = torch.cuda.device_count()\n+                device_count = get_accelerator().device_count()\nbatch_size *= device_count\n\nif num_local_io_workers is None:\n", "fix_rule": "Replace `torch.cuda.device_count()` with `get_accelerator().device_count()`"}

{"number": 257, "change": "def asin(x: Union[tf.Tensor, tf.Variable]) -> Union[tf.Tensor, tf.Variable]:\nreturn tf.asin(x)\n\n\n-def asinh(\n-        x: Union[tf.Tensor, tf.Variable]\n-) -> Union[tf.Tensor, tf.Variable]:\n-    x = tf.cast(x, tf.float32)\n+def asinh(x: Union[tf.Tensor, tf.Variable]) -> Union[tf.Tensor, tf.Variable]:\nreturn tf.asinh(x)\n", "fix_rule": "if tf.cast(x, tf.float32) detected, replace it with x"}

{"number": 259, "change": "class RagTokenForGeneration(RagPreTrainedModel):\nn_docs = n_docs if n_docs is not None else self.config.n_docs\n\n# RAG-token marginalization\n-        seq_logprobs = torch.nn.functional.log_softmax(seq_logits, dim=-1).view(\n+        seq_logprobs = nn.functional.log_softmax(seq_logits, dim=-1).view(\nseq_logits.shape[0] // n_docs, n_docs, -1, seq_logits.size(-1)\n)\ndoc_logprobs = torch.log_softmax(doc_scores, dim=1)\n", "fix_rule": "if torch.nn.functional.log_softmax() is detected, replace it with nn.functional.log_softmax()"}

{"number": 266, "change": "class TestStackedSelfAttention(AllenNlpTestCase):\nfeedforward_hidden_dim=5,\nnum_layers=3,\nnum_attention_heads=3)\n-        inputs = Variable(torch.randn([3, 5, 9]))\n+        inputs = torch.randn([3, 5, 9])\nencoder_output = encoder(inputs, None)\nassert list(encoder_output.size()) == [3, 5, 12]\n", "fix_rule": "if  Variable(torch.randn([3, 5, 9])) dtected, replace it with torch.randn([3, 5, 9])"}

{"number": 267, "change": "def qr(A: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:  # pragma: no cove\n\"\"\"\nLike torch.linalg.qr.\n\"\"\"\n-    if hasattr(torch.linalg, \"qr\"):\n+    if hasattr(torch, \"linalg\") and hasattr(torch.linalg, \"qr\"):\n# PyTorch version >= 1.9\nreturn torch.linalg.qr(A)\nreturn torch.qr(A)\n", "fix_rule": "if `hasattr(torch.linalg, \"qr\")` is detected, replace it with `hasattr(torch, \"linalg\") and hasattr(torch.linalg, \"qr\")`"}

{"number": 268, "change": "def prepare_bart_inputs_dict(\nif decoder_attention_mask is None:\ndecoder_attention_mask = decoder_input_ids.ne(config.pad_token_id)\nif head_mask is None:\n-        head_mask = torch.ones(config.encoder_layers, config.encoder_attention_heads)\n+        head_mask = torch.ones(config.encoder_layers, config.encoder_attention_heads, device=torch_device)\nif decoder_head_mask is None:\n-        decoder_head_mask = torch.ones(config.decoder_layers, config.decoder_attention_heads)\n+        decoder_head_mask = torch.ones(config.decoder_layers, config.decoder_attention_heads, device=torch_device)\nreturn {\n\"input_ids\": input_ids,\n\"decoder_input_ids\": decoder_input_ids,\n", "fix_rule": "if  torch.ones() is detected, replace it with torch.ones().to(device=torch_device)"}

{"number": 269, "change": "class PNDMSchedulerTest(SchedulerCommonTest):\nscheduler_config = self.get_scheduler_config(steps_offset=1)\nscheduler = scheduler_class(**scheduler_config)\nscheduler.set_timesteps(10)\n-        assert np.equal(\n+        assert torch.equal(\nscheduler.timesteps,\n-            np.array([901, 851, 851, 801, 801, 751, 751, 701, 701, 651, 651, 601, 601, 501, 401, 301, 201, 101, 1]),\n-        ).all()\n+            torch.LongTensor(\n+                [901, 851, 851, 801, 801, 751, 751, 701, 701, 651, 651, 601, 601, 501, 401, 301, 201, 101, 1]\n+            ),\n+        )\n\ndef test_betas(self):\nfor beta_start, beta_end in zip([0.0001, 0.001], [0.002, 0.02]):\n", "fix_rule": "if \"np.equal(\" is detected, replace it with \"torch.equal(\"\nif \"np.array([\" is detected, replace it with \"torch.LongTensor([\""}

{"number": 272, "change": "class GradTTS(DiffusionPipeline):\nmu_y = mu_y.transpose(1, 2)\n\n# Sample latent representation from terminal distribution N(mu_y, I)\n-        z = mu_y + torch.randn_like(mu_y, device=mu_y.device) / temperature\n+        z = mu_y + torch.randn(mu_y.shape, device=mu_y.device, generator=generator) / temperature\n\nxt = z * y_mask\nh = 1.0 / num_inference_steps\n", "fix_rule": "if \"torch.randn_like\" is detected, replace it with \"torch.randn(mu_y.shape, device=mu_y.device, generator=generator)\""}

{"number": 273, "change": "class NanDetector:\ngradients = {}\nfor name, param in self.named_parameters:\nif param.grad is not None:\n-                grad_norm = torch.norm(param.grad.data, p=2, dtype=torch.float32)\n+                grad_norm = torch.norm(param.grad.data.float(), p=2)\nnorm[name] = grad_norm.item()\nif torch.isnan(grad_norm).any() or torch.isinf(grad_norm).any():\ngradients[name] = param.grad.data\n", "fix_rule": "If param.grad is not None and torch.norm(param.grad.data, p=2, dtype=torch.float32) dtected, replace it with torch.norm(param.grad.data.float(), p=2)"}

{"number": 277, "change": "def fpn_map_rois_to_levels(boxes):\nBe careful that the returned tensor could be empty.\n\"\"\"\nsqrtarea = tf.sqrt(tf_area(boxes))\n-    level = tf.to_int32(tf.floor(\n-        4 + tf.log(sqrtarea * (1. / 224) + 1e-6) * (1.0 / np.log(2))))\n+    level = tf.cast(tf.floor(\n+        4 + tf.log(sqrtarea * (1. / 224) + 1e-6) * (1.0 / np.log(2))), tf.int32)\n\n# RoI levels range from 2~5 (not 6)\nlevel_ids = [\n", "fix_rule": "if tf.to_int32(dtected, replace it with tf.cast()."}

{"number": 278, "change": "def mesh_laplacian_smoothing(meshes, method: str = \"uniform\"):\nelif method == \"cot\":\nloss = L.mm(verts_packed) * norm_w - verts_packed\nelif method == \"cotcurv\":\n-        loss = (L.mm(verts_packed) - verts_packed) * norm_w\n+        loss = (L.mm(verts_packed) - L_sum * verts_packed) * norm_w\nloss = loss.norm(dim=1)\n\nloss = loss * weights\n", "fix_rule": "Replace the line \"+        loss = (L.mm(verts_packed) - L_sum * verts_packed) * norm_w\" with \"+        loss = (L.mm(verts_packed) - L_sum.mm(verts_packed)) * norm_w\"."}

{"number": 281, "change": "def test_hub_oneshot(space_type, strategy_type):\nNDS_SPACES = ['amoeba', 'darts', 'pnas', 'enas', 'nasnet']\nif strategy_type == 'proxyless':\nif 'width' in space_type or 'depth' in space_type or \\\n-                any(space_type.startswith(prefix) for prefix in NDS_SPACES + ['proxylessnas', 'mobilenetv3']):\n+                any(space_type.startswith(prefix) for prefix in NDS_SPACES + ['proxylessnas', 'mobilenetv3', 'autoformer']):\npytest.skip('The space has used unsupported APIs.')\nif strategy_type in ['darts', 'gumbel'] and space_type == 'mobilenetv3':\npytest.skip('Skip as it consumes too much memory.')\n", "fix_rule": "If 'autoformer' is not present in space_type and strategy_type is 'proxyless' and any prefix in NDS_SPACES + ['proxylessnas', 'mobilenetv3', 'autoformer'] starts with space_type, add 'autoformer' to NDS_SPACES + ['proxylessnas', 'mobilenetv3']."}

{"number": 282, "change": "class GCNConv(MessagePassing):\nx = torch.matmul(x, self.weight)\n\nif not self.cached or self.cached_result is None:\n-            edge_index, norm = GCNConv.norm(edge_index,\n-                                            x.size(0), edge_weight,\n+            edge_index, norm = GCNConv.norm(edge_index, x.size(0), edge_weight,\nself.improved, x.dtype)\nself.cached_result = edge_index, norm\n", "fix_rule": "if GCNConv.norm() is detected, replace it with GCNConv.norm(edge_index, x.size(0), edge_weight, self.improved, x.dtype)"}

{"number": 283, "change": "class CTC(torch.nn.Module):\nif self.ctc_type == \"builtin\":\nolens = to_device(ys_hat, torch.LongTensor([len(s) for s in ys]))\nhlens = hlens.long()\n+            ys_pad = torch.cat(ys)  # without this the code breaks for asr_mix\nself.loss = self.loss_fn(ys_hat, ys_pad, hlens, olens)\nelse:\nself.loss = None\n", "fix_rule": "if \"torch.cat(ys)\" is detected, replace it with \"ys_pad = torch.cat(ys).to(device)\""}

{"number": 296, "change": "class DeformableDetrModelIntegrationTests(unittest.TestCase):\nresults = feature_extractor.post_process_object_detection(\noutputs, threshold=0.3, target_sizes=[image.size[::-1]]\n)[0]\n-        expected_scores = torch.tensor([0.7999, 0.7894, 0.6331, 0.4720, 0.4382])\n+        expected_scores = torch.tensor([0.7999, 0.7894, 0.6331, 0.4720, 0.4382]).to(torch_device)\nexpected_labels = [17, 17, 75, 75, 63]\n-        expected_slice_boxes = torch.tensor([16.5028, 52.8390, 318.2544, 470.7841])\n+        expected_slice_boxes = torch.tensor([16.5028, 52.8390, 318.2544, 470.7841]).to(torch_device)\n\nself.assertEqual(len(results[\"scores\"]), 5)\nself.assertTrue(torch.allclose(results[\"scores\"], expected_scores, atol=1e-4))\n", "fix_rule": "if torch.tensor() detected, replace it with torch.tensor().to(torch_device)"}

{"number": 298, "change": "class TensorflowBackendInferenceLearner(TensorflowBaseInferenceLearner):\nmetadata = LearnerMetadata.read(path)\nnetwork_parameters = ModelParams(**metadata.network_parameters)\ninput_tfms = metadata.input_tfms\n-        model = nebullvm.operations.inference_learners.utils.load_model(\n+        model = tf.keras.models.load_model(\npath / TENSORFLOW_BACKEND_FILENAMES[\"tf_model\"]\n)\ndevice = Device(metadata.device)\n", "fix_rule": "if  nebullvm.operations.inference_learners.utils.load_model() is detected, replace it with tf.keras.models.load_model()"}

{"number": 302, "change": "def rmsle(\n>>> x = torch.tensor([0., 1, 2, 3])\n>>> y = torch.tensor([0., 1, 2, 2])\n>>> rmsle(x, y)\n-        tensor(0.0207)\n+        tensor(0.1438)\n\n\"\"\"\n-    rmsle = mse(torch.log(pred + 1), torch.log(target + 1), reduction=reduction)\n+    rmsle = rmse(torch.log(pred + 1), torch.log(target + 1), reduction=reduction)\nreturn rmsle\n", "fix_rule": "if mse(torch.log(pred + 1), torch.log(target + 1), reduction=reduction) is detected, replace it with rmse(torch.log(pred + 1), torch.log(target + 1), reduction=reduction)"}

{"number": 305, "change": "def ones_like(x, name=None):\n[ 1.,  1.,  1.]], dtype=float32)\n```\n\"\"\"\n-    return tf.ones_like(x, name=name)\n+    return tf.ones_like(x, dtype=dtype, name=name)\n\n\ndef random_uniform_variable(shape, low, high, dtype=None,\n", "fix_rule": "if dtype is not None, replace it with dtype=dtype."}

{"number": 306, "change": "class Ensemble(nn.ModuleList):\nreturn y, None  # inference, train output\n\n\n-def attempt_load(weights, map_location=None, inplace=True, fuse=True):\n+def attempt_load(weights, device=None, inplace=True, fuse=True):\nfrom models.yolo import Detect, Model\n\n# Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a\nmodel = Ensemble()\nfor w in weights if isinstance(weights, list) else [weights]:\n-        ckpt = torch.load(attempt_download(w), map_location=map_location)  # load\n-        ckpt = (ckpt.get('ema') or ckpt['model']).float()  # FP32 model\n+        ckpt = torch.load(attempt_download(w))\n+        ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model\nmodel.append(ckpt.fuse().eval() if fuse else ckpt.eval())  # fused or un-fused model in eval mode\n\n# Compatibility updates\n", "fix_rule": "- If `torch.load(attempt_download(w), map_location=map_location)` is detected, replace it with `torch.load(attempt_download(w)).to(device)`.\n- If `(ckpt.get('ema') or ckpt['model']).float()` is detected, replace it with `(ckpt.get('ema') or ckpt['model']).to(device).float()`."}

{"number": 307, "change": "from allennlp.common.params import Params\n\nclass TestStackedBidirectionalLstm(AllenNlpTestCase):\ndef test_stacked_bidirectional_lstm_completes_forward_pass(self):\n-        input_tensor = torch.autograd.Variable(torch.rand(4, 5, 3))\n+        input_tensor = torch.rand(4, 5, 3)\ninput_tensor[1, 4:, :] = 0.\ninput_tensor[2, 2:, :] = 0.\ninput_tensor[3, 1:, :] = 0.\n", "fix_rule": "\"\"\"\nif  torch.autograd.Variable(torch.rand()) detected, replace it with torch.rand()\n\"\"\""}

{"number": 309, "change": "class TFCTRLMainLayer(tf.keras.layers.Layer):\ntoken_type_embeds = 0\nposition_ids = tf.reshape(position_ids, [-1, shape_list(position_ids)[-1]])\n\n-        inputs_embeds = self.w(input_ids)\n+        inputs_embeds = self.w(input_ids, mode='embedding')\n# x = embedded.unsqueeze(0) if len(input_ids.shape)<2 else embedded\nseq_len = input_shape[-1]\nmask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n", "fix_rule": "if  self.w(dtected, mode='embedding') is not None, replace it with self.w(input_ids, mode='embedding')"}

{"number": 310, "change": "def _preprocess_conv3d_input(x, data_format):\nA tensor.\n\"\"\"\n# tensorflow doesn't support float64 for conv layer before 1.8.0\n-    if (dtype(x) == 'float64'\n-            and StrictVersion(tf.__version__) < StrictVersion('1.8.0')):\n+    if (dtype(x) == 'float64' and\n+            StrictVersion(tf.__version__.split('-')[0]) < StrictVersion('1.8.0')):\nx = tf.cast(x, 'float32')\ntf_data_format = 'NDHWC'\nif data_format == 'channels_first':\n", "fix_rule": "if dtype(x) == 'float64' and StrictVersion(tf.__version__.split('-')[0]) < StrictVersion('1.8.0'), replace it with x = tf.cast(x, 'float32')"}

{"number": 314, "change": "class _EagerVariableStore(tf.Module):\nlayer = create_layer_method()\nself._layers[name] = layer\nif isinstance(layer, base_layer.Layer):\n-        self._regularizers[name] = lambda: layer.losses\n+        self._regularizers[name] = lambda: tf.math.reduce_sum(layer.losses)\nreturn self._layers[name]\n\ndef add_regularizer(self, var, regularizer):\n", "fix_rule": "if isinstance(layer, base_layer.Layer) dtected, replace it with self._regularizers[name] = lambda: tf.math.reduce_sum(layer.losses)"}

{"number": 315, "change": "class TFWav2Vec2MainLayer(tf.keras.layers.Layer):\nif inputs[\"attention_mask\"] is not None:\n# compute real output lengths according to convolution formula\noutput_lengths = self._get_feat_extract_output_lengths(tf.reduce_sum(inputs[\"attention_mask\"], -1))\n-            attention_mask = tf.sequence_mask(output_lengths, dtype=hidden_states.dtype)\n+\n+            attention_mask = tf.sequence_mask(\n+                output_lengths, maxlen=shape_list(hidden_states)[1], dtype=hidden_states.dtype\n+            )\n\nhidden_states = self.feature_projection(hidden_states, training=inputs[\"training\"])\n", "fix_rule": "If tf.sequence_mask(output_lengths, dtype=hidden_states.dtype) is detected, replace it with tf.sequence_mask(output_lengths, maxlen=shape_list(hidden_states)[1], dtype=hidden_states.dtype)"}

{"number": 317, "change": "class DiagNormal(Distribution):\n# when the data is a ragged tensor. also useful for KL annealing. this entire logic\n# will likely be done in a better/cleaner way in the future\nif log_pdf_mask is not None:\n-            # TODO fix this to broadcasting as below, e.g. by instead:\n-            # log_pxs *= log_pdf_mask  # Then continue with broadcasting logic below.\n-            return torch.sum(log_pdf_mask * log_pxs, -1)\n+            log_pxs = log_pxs * log_pdf_mask\nbatch_log_pdf = torch.sum(log_pxs, -1)\nbatch_log_pdf_shape = x.size()[:-1] + (1,)\nreturn batch_log_pdf.contiguous().view(batch_log_pdf_shape)\n", "fix_rule": "if log_pdf_mask is not None:\n    log_pxs = log_pxs * log_pdf_mask\nbatch_log_pdf = torch.sum(log_pxs, -1)\nbatch_log_pdf_shape = x.size()[:-1] + (1,)\nreturn batch_log_pdf.contiguous().view(batch_log_pdf_shape)"}

{"number": 323, "change": "class BaseModel():\nsave_filename = '%s_net_%s.pth' % (which_epoch, name)\nsave_path = os.path.join(self.save_dir, save_filename)\nnet = getattr(self, 'net' + name)\n-                net.load_state_dict(torch.load(save_path))\n+                net.module.load_state_dict(torch.load(save_path))\n\n# print network information\ndef print_networks(self, verbose):\n", "fix_rule": "\"\"\"\nReplace \"net.load_state_dict(torch.load(save_path))\" with \"net.module.load_state_dict(torch.load(save_path))\"\n\"\"\""}

{"number": 324, "change": "class SpeedsterRootOp(Operation):\n) -> List[BaseInferenceLearner]:\nif self.orig_latency_measure_op.get_result() is not None:\nmodel_outputs = self.orig_latency_measure_op.get_result()[0]\n-            if isinstance(model, Module):\n+            if isinstance(model, torch.nn.Module):\noptimization_op = self.torch_optimization_op\nelif isinstance(model, tf.Module) and model is not None:\noptimization_op = self.tensorflow_optimization_op\n", "fix_rule": "if isinstance(model, Module) dtected, replace it with if isinstance(model, torch.nn.Module)"}

{"number": 325, "change": "def run(\n):\n# PyTorch model\nim = torch.zeros((batch_size, 3, *imgsz))  # BCHW image\n-    model = attempt_load(weights, map_location=torch.device('cpu'), inplace=True, fuse=False)\n+    model = attempt_load(weights, device=torch.device('cpu'), inplace=True, fuse=False)\n_ = model(im)  # inference\nmodel.info()\n", "fix_rule": "If `torch.device('cpu')` is detected, replace it with `device=torch.device('cpu')`."}

{"number": 328, "change": "class UNet2DConditionModel(ModelMixin, ConfigMixin):\nif not torch.is_tensor(timesteps):\ntimesteps = torch.tensor([timesteps], dtype=torch.long, device=sample.device)\nelif torch.is_tensor(timesteps) and len(timesteps.shape) == 0:\n-            timesteps = timesteps[None].to(sample.device)\n+            timesteps = timesteps.to(dtype=torch.float32)\n+            timesteps = timesteps[None].to(device=sample.device)\n\n# broadcast to batch dimension in a way that's compatible with ONNX/Core ML\ntimesteps = timesteps.expand(sample.shape[0])\n", "fix_rule": "if  torch.is_tensor(timesteps) and len(timesteps.shape) == 0  is detected, replace it with timesteps = timesteps.to(dtype=torch.float32) and then timesteps = timesteps[None].to(device=sample.device)"}

{"number": 335, "change": "class AdaptiveEmbedding(nn.Module):\n\ninp_i = inp_flat.index_select(0, indices_i) - l_idx\nemb_i = self.emb_layers[i](inp_i)\n-                emb_i = F.linear(emb_i, self.emb_projs[i])\n+                emb_i = nn.functional.linear(emb_i, self.emb_projs[i])\n\nemb_flat.index_copy_(0, indices_i, emb_i)\n", "fix_rule": "if F.linear() function is detected, replace it with nn.functional.linear() function"}

{"number": 341, "change": "for m in model_list:\ndata_root=os.environ.get('IMAGENET_DIR', './imagenet')\n)\n\n+    torch.cuda.empty_cache()\n+\n", "fix_rule": "if  os.environ.get('IMAGENET_DIR') dtected, replace it with os.environ.get('IMAGENET_DIR', './imagenet')\nAdd the line \"torch.cuda.empty_cache()\" before the line \"for m in model_list:\""}

{"number": 348, "change": "def main():\nmodel = MMDataParallel(model, device_ids=[0])\noutputs = single_gpu_test(model, data_loader, args.show)\nelse:\n-        model = MMDistributedDataParallel(model.cuda())\n+        model = MMDistributedDataParallel(\n+            model.cuda(),\n+            device_ids=[torch.cuda.current_device()],\n+            broadcast_buffers=False)\noutputs = multi_gpu_test(model, data_loader, args.tmpdir,\nargs.gpu_collect)\n", "fix_rule": "if model.cuda() is detected, replace it with model.cuda(), device_ids=[torch.cuda.current_device()], broadcast_buffers=False)"}

{"number": 357, "change": "class Tester(unittest.TestCase):\n# generate input data\nbatch_size = 1\ncenter = torch.zeros(batch_size, 2)\n-        angle = torch.ones(batch_size, 1)\n-        scale = torch.ones(batch_size, 1)\n+        angle = torch.ones(batch_size)\n+        scale = torch.ones(batch_size)\n\ncenter = utils.tensor_to_gradcheck_var(center)  # to var\nangle = utils.tensor_to_gradcheck_var(angle)  # to var\n", "fix_rule": "if torch.ones(batch_size, 1) detected, replace it with torch.ones(batch_size)"}

{"number": 360, "change": "class Trainer:\nreturn type(data)(self._prepare_input(v) for v in data)\nelif isinstance(data, torch.Tensor):\nkwargs = {\"device\": self.args.device}\n-            if self.deepspeed and data.dtype != torch.int64:\n-                # NLP models inputs are int64 and those get adjusted to the right dtype of the\n+            if self.deepspeed and (torch.is_floating_point(data) or torch.is_complex(data)):\n+                # NLP models inputs are int/uint and those get adjusted to the right dtype of the\n# embedding. Other models such as wav2vec2's inputs are already float and thus\n# may need special handling to match the dtypes of the model\nkwargs.update({\"dtype\": self.args.hf_deepspeed_config.dtype()})\n", "fix_rule": "if torch.is_floating_point(data) or torch.is_complex(data) detected, replace it with if torch.is_floating_point(data) or torch.is_complex(data):\\n    data = data.to(device)"}

{"number": 362, "change": "class DeformableDetrImageProcessor(BaseImageProcessor):\nimg_w = torch.Tensor([i[1] for i in target_sizes])\nelse:\nimg_h, img_w = target_sizes.unbind(1)\n-        scale_fct = torch.stack([img_w, img_h, img_w, img_h], dim=1)\n+        scale_fct = torch.stack([img_w, img_h, img_w, img_h], dim=1).to(boxes.device)\nboxes = boxes * scale_fct[:, None, :]\n\nresults = []\n", "fix_rule": "If `torch.stack()` is detected, replace it with `torch.stack().to(boxes.device)`"}

{"number": 363, "change": "class SpanBasedF1Test(AllenNlpTestCase):\ngold_indices = [self.vocab.get_token_index(x, \"tags\") for x in bio_tags]\ngold_tensor = torch.tensor([gold_indices], device=device)\nprediction_tensor = torch.rand([1, 6, self.vocab.get_vocab_size(\"tags\")], device=device)\n-        mask = torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]], device=device)\n+        mask = torch.BoolTensor(\n+            [[True, True, True, True, True, True, True, True, True]], device=device\n+        )\n\n# Make prediction so that it is exactly correct.\nfor i, tag_index in enumerate(gold_indices):\n", "fix_rule": "if a tensor is created using torch.tensor() with device specified, replace it with torch.BoolTensor() using device specified."}

{"number": 366, "change": "class DistributedFusedLAMB(torch.optim.Optimizer):\nl2_norm = torch.zeros(size=[self._model_params_num], dtype=torch.float32, device='cuda')\nlocal_contrib_l2_norm = multi_tensor_applier(self.multi_tensor_l2norm, self._overflow_buf, [self._contrib_update_frag_for_norm], True)[1] ** 2\nl2_norm.masked_scatter_(self._model_param_is_contrib, local_contrib_l2_norm)\n-        torch.distributed.allreduce(l2_norm, group=self._ag_pg[0])\n+        torch.distributed.all_reduce(l2_norm, group=self._ag_pg[0])\nreturn l2_norm.masked_select(self._model_param_is_contrib)\n\ndef _pipeline_step(self):\n", "fix_rule": "if `torch.distributed.allreduce` is detected, replace it with `torch.distributed.all_reduce(l2_norm, group=self._ag_pg[0])`"}

{"number": 367, "change": "class _BinaryPostprocessing(torch.nn.Module):\npredictions = [self.bool2str.get(pred, self.bool2str[0]) for pred in predictions]\n\nprobs = preds[self.probabilities_key]\n-        probs = torch.dstack(1 - probs, probs)\n+        probs = torch.stack([1 - probs, probs], dim=-1)\n\nreturn {\nself.predictions_key: predictions,\n", "fix_rule": "If \"torch.dstack()\" is detected, replace it with \"torch.stack([1 - probs, probs], dim=-1)\"."}

{"number": 368, "change": "if __name__ == \"__main__\":\nexp = get_exp(args.exp_file, args.name)\nexp.merge(args.opts)\n\n-    num_gpu = get_num_devices() if args.devices is None else args.devices\n-    assert num_gpu <= get_num_devices()\n+    num_gpu = torch.cuda.device_count() if args.devices is None else args.devices\n+    assert num_gpu <= torch.cuda.device_count()\n\ndist_url = \"auto\" if args.dist_url is None else args.dist_url\nlaunch(\n", "fix_rule": "if 'get_num_devices()' is detected, replace it with 'torch.cuda.device_count()'."}

{"number": 372, "change": "class Critic(object):\nself.train_op = tf.train.AdamOptimizer(self.lr).minimize(self.loss)\n\nwith tf.variable_scope('a_grad'):\n-            self.a_grads = tf.gradients(self.q, a)[0]   # tensor of gradients of each sample (None, a_dim)\n+            self.a_grads = tf.gradients(self.q, self.a)[0]   # tensor of gradients of each sample (None, a_dim)\n\nif self.replacement['name'] == 'hard':\nself.t_replace_counter = 0\n", "fix_rule": "if `self.a` is detected, replace it with `self.a`"}

{"number": 375, "change": "def corr2d(X, K):  #@save\n\n# Defined in file: ./chapter_convolutional-neural-networks/lenet.md\ndef evaluate_accuracy_gpu(net, data_iter, device=None): #@save\n+    net.eval()  # Set the model to evaluation mode\nif not device:\ndevice = next(iter(net.parameters())).device\nmetric = d2l.Accumulator(2)  # num_corrected_examples, num_examples\n", "fix_rule": "if net.eval() detected, add the line device = next(iter(net.parameters())).device"}

{"number": 376, "change": "class VideoSequential(ImageSequential):\n# Size of T\nframe_num = input.size(self._temporal_channel)\n# Got param generation shape to (B, C, H, W). Ignoring T.\n-        batch_shape = self.__infer_channel_exclusive_batch_shape__(input)\n+        batch_shape = self.__infer_channel_exclusive_batch_shape__(input, self._temporal_channel)\ninput = self._input_shape_convert_in(input)\ninput = input.reshape(-1, *batch_shape[1:])\nif not self.same_on_frame:\n", "fix_rule": "\"\"\"\nif self._temporal_channel is detected, replace it with input, self._temporal_channel\n\"\"\""}

{"number": 377, "change": "def create_dataloader(path, imgsz, batch_size, stride, single_cls=False, hyp=Non\nprefix=prefix)\n\nbatch_size = min(batch_size, len(dataset))\n-    nw = min([os.cpu_count() // DEVICE_COUNT, batch_size if batch_size > 1 else 0, workers])  # number of workers\n+    nd = torch.cuda.device_count()  # number of CUDA devices\n+    nw = min([os.cpu_count() // max(nd, 1), batch_size if batch_size > 1 else 0, workers])  # number of workers\nsampler = None if rank == -1 else distributed.DistributedSampler(dataset, shuffle=shuffle)\nloader = DataLoader if image_weights else InfiniteDataLoader  # only DataLoader allows for attribute updates\nreturn loader(dataset,\n", "fix_rule": "Replace \"os.cpu_count() // DEVICE_COUNT\" with \"os.cpu_count() // max(nd, 1)\""}

{"number": 381, "change": "if dependency_check.crypten_available:\n\nframework_packages[\"crypten\"] = crypten\nframework_tensors.append(crypten.mpc.MPCTensor)\n+    framework_tensors.append(crypten.nn.Module)\n+\n\nframework_tensors = tuple(framework_tensors)\nFrameworkTensorType = Union[framework_tensors]\n", "fix_rule": "if dependency_check.crypten_available:\n\nframework_packages[\"crypten\"] = crypten\nframework_tensors.append(crypten.mpc.MPCTensor)\nif hasattr(crypten, \"nn\"):\n    framework_tensors.append(crypten.nn.Module)\n\nframework_tensors = tuple(framework_tensors)\nFrameworkTensorType = Union[framework_tensors]"}

{"number": 384, "change": "def array(object_in, dtype: Optional[str] = None, dev: Optional[str] = None):\ndev = default_device(dev)\ndtype = dtype_from_str(default_dtype(dtype, object_in))\nif isinstance(object_in, np.ndarray):\n-        return _torch.Tensor(object_in).to(dev_from_str(dev))\n+        return torch.Tensor(object_in).to(dev_from_str(dev))\nif dtype is not None:\n-        return _torch.tensor(object_in, dtype=dtype, device=dev_from_str(dev))\n-    elif isinstance(object_in, _torch.Tensor):\n+        return torch.tensor(object_in, dtype=dtype, device=dev_from_str(dev))\n+    elif isinstance(object_in, torch.Tensor):\nreturn object_in.to(dev_from_str(dev))\nelse:\n-        return _torch.tensor(object_in, device=dev_from_str(dev))\n+        return torch.tensor(object_in, device=dev_from_str(dev))\n\nasarray = array\n", "fix_rule": "if `_torch.Tensor(` is detected, replace it with `torch.Tensor(`\nif `_torch.tensor(` is detected, replace it with `torch.tensor(`"}

{"number": 390, "change": "def _calculate_expected_result(\naggregation_op_only_probs = gumbel_dist.sample()\nelse:\n# <float32>[batch_size, num_aggregation_labels - 1]\n-        aggregation_op_only_probs = torch.nn.functional.softmax(\n+        aggregation_op_only_probs = nn.functional.softmax(\nlogits_aggregation[:, 1:] / config.aggregation_temperature, dim=-1\n)\n", "fix_rule": "if torch.nn.functional.softmax() detected, replace it with nn.functional.softmax()"}

{"number": 392, "change": "class TensorforceModel(Model):\ndiscounts = tf.math.pow(x=discount, y=exponent)\nif not self.predict_terminal_values:\ndiscounts = tf.where(\n-                    condition=tf.math.greater(x=_terminal, y=one),\n-                    x=discounts, y=tf.zeros_like(input=discounts)\n+                    condition=tf.math.equal(x=_terminal, y=one),\n+                    x=tf.zeros_like(input=discounts), y=discounts\n)\n\n-            reward += discounts * horizon_values\n+            reward = reward + discounts * horizon_values\n\ndependencies = [reward]\nif self.summaries == 'all' or 'reward' in self.summaries:\n", "fix_rule": "if tf.math.greater(x=_terminal, y=one) is detected, replace it with tf.math.equal(x=_terminal, y=one).\nReplace x=discounts, y=tf.zeros_like(input=discounts) with x=tf.zeros_like(input=discounts), y=discounts.\nReplace reward += discounts * horizon_values with reward = reward + discounts * horizon_values."}

{"number": 395, "change": "def test_cgcnn_conv():\nedge_index = torch.tensor([[0, 0, 0, 1, 2, 3], [1, 2, 3, 0, 0, 0]])\nnum_nodes = edge_index.max().item() + 1\nx = torch.randn((num_nodes, node_dim))\n-    pseudo = torch.rand((edge_index.size(1), 3))\n+    pseudo = torch.rand((edge_index.size(1), edge_dim))\n\nconv = CGCNNConv(node_dim, edge_dim)\nassert conv.__repr__() == 'CGCNNConv(16, 16)'\n", "fix_rule": "If  torch.rand() is detected, replace it with torch.rand((edge_index.size(1), edge_dim))"}

{"number": 408, "change": "\"        # compute the gating function and one minus the gating function\\n\",\n\"        gate_intermediate = self.relu(self.lin_gate_z_to_hidden(z_t_1))\\n\",\n\"        gate = self.sigmoid(self.lin_gate_hidden_to_z(gate_intermediate))\\n\",\n-    \"        one_minus_gate = ng_ones(gate.size()).type_as(gate) - gate\\n\",\n+    \"        one_minus_gate = torch.ones(gate.size()).type_as(gate) - gate\\n\",\n\"        # compute the 'proposed mean'\\n\",\n\"        proposed_mean_intermediate = self.relu(self.lin_proposed_mean_z_to_hidden(z_t_1))\\n\",\n\"        proposed_mean = self.lin_proposed_mean_hidden_to_z(proposed_mean_intermediate)\\n\",\n", "fix_rule": "If \"ng_ones()\" is detected, replace it with \"torch.ones()\"."}

{"number": 412, "change": "def crop_by_boxes(tensor, src_box, dst_box,\ndst_trans_src = dst_trans_src.expand(tensor.shape[0], -1, -1)\n\nbbox = _infer_bounding_box(dst_box)\n-    patches: torch.Tensor = warp_perspective(\n-        tensor, dst_trans_src, (int(bbox[0].int().data.item()), int(bbox[1].int().data.item())))\n+    patches: torch.Tensor = warp_affine(\n+        tensor, dst_trans_src[:, :2, :], (int(bbox[0].int().data.item()), int(bbox[1].int().data.item())))\n\n# return in the original shape\nif is_unbatched:\n", "fix_rule": "If `warp_perspective()` is detected, replace it with `warp_affine()`."}

{"number": 417, "change": "class Model(ModelDesc):\nif get_current_tower_context().is_training:\nwd_w = tf.train.exponential_decay(2e-4, get_global_step_var(),\n80000, 0.7, True)\n-            wd_cost = tf.mul(wd_w, regularize_cost('.*/W', tf.nn.l2_loss), name='wd_cost')\n+            wd_cost = tf.multiply(wd_w, regularize_cost('.*/W', tf.nn.l2_loss), name='wd_cost')\ncosts.append(wd_cost)\n\nadd_param_summary(('.*/W', ['histogram']))   # monitor W\n", "fix_rule": "if \"tf.mul\" is detected, replace it with \"tf.multiply\""}

{"number": 418, "change": "if __name__ == '__main__':\nloss_values.clear()\naccuracies.clear()\nif step % 100 == 0:\n-            vis.draw_projections(embeds.detach().cpu().numpy(), utterances_per_speaker, step)\n+            vis.draw_projections(embeds.detach().numpy(), utterances_per_speaker, step)\n", "fix_rule": "If  \".cpu()\"  is detected, replace it with \".detach().cpu()\" ."}

{"number": 419, "change": "class ScoreSdeVpScheduler(SchedulerMixin, ConfigMixin):\nx_mean = x + drift * dt\n\n# add noise\n-        noise = torch.randn(x.shape, layout=x.layout, generator=generator).to(x.device)\n+        noise = randn_tensor(x.shape, layout=x.layout, generator=generator, device=x.device, dtype=x.dtype)\nx = x_mean + diffusion * math.sqrt(-dt) * noise\n\nreturn x, x_mean\n", "fix_rule": "if  torch.randn() detected, replace it with randn_tensor().to(x.device)"}

{"number": 422, "change": "def get_keras_model():\nM.add(KL.Conv2D(32, 3, padding='same', activation='relu'))\nM.add(KL.Flatten())\nM.add(KL.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(1e-5)))\n-        M.add(KL.Dropout(0.5))\n+        M.add(KL.Dropout(rate=0.5))\nM.add(KL.Dense(10, activation=None, kernel_regularizer=keras.regularizers.l2(1e-5)))\nreturn M\n", "fix_rule": "if KL.Dropout(0.5) is detected, replace it with KL.Dropout(rate=0.5)"}

{"number": 424, "change": "def main(parsed_args):\n\ndef cli_main():\nparser = options.get_eval_lm_parser()\n+    add_distributed_training_args(parser)\nargs = options.parse_args_and_arch(parser)\n-    main(args)\n+    distributed_utils.call_main(args, main)\n\n\nif __name__ == '__main__':\n", "fix_rule": "if options.get_eval_lm_parser() is called, add add_distributed_training_args(parser)\nreplace options.parse_args_and_arch(parser) with distributed_utils.call_main(args, main)"}

{"number": 425, "change": "def degree(index, num_nodes=None, dtype=None, device=None):\ntensor([3., 1., 1.])\n\"\"\"\nnum_nodes = maybe_num_nodes(index, num_nodes)\n-    out = torch.zeros((num_nodes), dtype=dtype, device=device)\n+    out = torch.zeros((num_nodes), dtype=dtype, device=index.device)\nreturn out.scatter_add_(0, index, out.new_ones((index.size(0))))\n", "fix_rule": "If `maybe_num_nodes(index, num_nodes)` is called, replace `device=device` with `device=index.device`."}

{"number": 429, "change": "class RandomThinPlateSpline(AugmentationBase2D):\n\ndef generate_parameters(self, shape: torch.Size) -> Dict[str, Tensor]:\nB, _, _, _ = shape\n-        src = torch.tensor([[[-1.0, -1.0], [-1.0, 1.0], [1.0, -1.0], [1.0, 1.0], [0.0, 0.0]]]).expand(B, 5, 2)  # Bx5x2\n+        src = tensor([[[-1.0, -1.0], [-1.0, 1.0], [1.0, -1.0], [1.0, 1.0], [0.0, 0.0]]]).expand(B, 5, 2)  # Bx5x2\ndst = src + self.dist.rsample(src.shape)\nreturn dict(src=src, dst=dst)\n", "fix_rule": "If \"tensor()\" is detected, replace it with \"torch.tensor()\"."}

{"number": 432, "change": "class PNDMScheduler(SchedulerMixin, ConfigMixin):\n::-1\n].copy()  # we copy to avoid having negative strides which are not supported by torch.from_numpy\n\n-        self.timesteps = np.concatenate([self.prk_timesteps, self.plms_timesteps]).astype(np.int64)\n+        timesteps = np.concatenate([self.prk_timesteps, self.plms_timesteps]).astype(np.int64)\n+        self.timesteps = torch.from_numpy(timesteps).to(device)\n\nself.ets = []\nself.counter = 0\n", "fix_rule": "if np.concatenate() detected, replace it with torch.from_numpy().to(device)"}

{"number": 433, "change": "def HomographyRegressionApp():\n[-1, 1],  # top-right\n]]).to(dst_homo_src.device)\n# transform points\n-            pts_dst = dgm.transform_points(dgm.inverse(dst_homo_src), pts_src)\n+            pts_dst = dgm.transform_points(torch.inverse(dst_homo_src), pts_src)\n\ndef compute_factor(size):\nreturn 1.0 * size / 2\n", "fix_rule": "if dgm.inverse() detected, replace it with torch.inverse()"}

{"number": 436, "change": "class Highway(torch.nn.Module):\n# above, too.\nnonlinear_part, gate = projected_input.chunk(2, dim=-1)\nnonlinear_part = self._activation(nonlinear_part)\n-            gate = torch.nn.functional.sigmoid(gate)\n+            gate = torch.sigmoid(gate)\ncurrent_input = gate * linear_part + (1 - gate) * nonlinear_part\nreturn current_input\n", "fix_rule": "if torch.nn.functional.sigmoid() is detected, replace it with torch.sigmoid()"}

{"number": 437, "change": "class Model(object):\n\"It should be either Tensor or a list of Tensor.\"\n)\nfor idx in range(len(check_argu)):\n-                        if not isinstance(check_argu[idx], tf_ops._TensorLike) or not tf_ops.is_dense_tensor_like(\n+                        if not isinstance(check_argu[idx], [tf.Tensor, tf.SparseTensor, tf.Variable]) or not tf_ops.is_dense_tensor_like(\ncheck_argu[idx]):\nraise TypeError(\n\"The argument `%s` should be either Tensor or a list of Tensor \" % (check_order[co]) +\n", "fix_rule": "If `not isinstance(check_argu[idx], tf_ops._TensorLike) or not tf_ops.is_dense_tensor_like(check_argu[idx])` is detected, replace it with `not isinstance(check_argu[idx], [tf.Tensor, tf.SparseTensor, tf.Variable]) or not tf_ops.is_dense_tensor_like(check_argu[idx])`."}

{"number": 439, "change": "class TestBasicTextFieldEmbedder(AllenNlpTestCase):\n})\ntoken_embedder = BasicTextFieldEmbedder.from_params(self.vocab, params)\ninputs = {\n-                'words': Variable(torch.rand(3, 4, 5, 6) * 20).long(),\n-                'characters': Variable(torch.rand(3, 4, 5, 6, 7) * 15).long(),\n+                'words': (torch.rand(3, 4, 5, 6) * 20).long(),\n+                'characters': (torch.rand(3, 4, 5, 6, 7) * 15).long(),\n}\nassert token_embedder(inputs, num_wrapping_dims=2).size() == (3, 4, 5, 6, 12)\n", "fix_rule": "if  Variable(torch.rand() detected, replace it with (torch.rand().to(device))"}

{"number": 446, "change": "class Csv(datasets.ArrowBasedBuilder):\nif schema is not None\nelse None\n)\n-        for file_idx, file in enumerate(files):\n+        for file_idx, file in enumerate(itertools.chain.from_iterable(files)):\ncsv_file_reader = pd.read_csv(file, iterator=True, dtype=dtype, **self.config.read_csv_kwargs)\ntry:\nfor batch_idx, df in enumerate(csv_file_reader):\n", "fix_rule": "if itertools.chain.from_iterable() is detected, replace it with files."}

{"number": 448, "change": "class ARMAConv(MessagePassing):\nif self.bias is not None:\nout += self.bias[0 if self.shared_weights else t]\n\n-            if t < self.num_layers - 1:\n+            if self.act is not None and t < self.num_layers - 1:\nout = self.act(out)\n\nreturn out.mean(dim=-3)\n", "fix_rule": "if self.act is not None and torch.rand() is detected, replace it with torch.rand().to(device)"}

{"number": 449, "change": "class DependencyParser(flair.nn.Model):\nsentence_tensor = self.word_dropout(sentence_tensor)\n\nif self.use_rnn:\n-            sentence_tensor = pack_padded_sequence(sentence_tensor, lengths, True, False)\n+            sentence_sequence = pack_padded_sequence(sentence_tensor, torch.IntTensor(lengths), True, False)\n\n-            sentence_tensor, _ = self.lstm(sentence_tensor)\n-            sentence_tensor, _ = pad_packed_sequence(sentence_tensor, True, total_length=seq_len)\n+            sentence_sequence, _ = self.lstm(sentence_sequence)\n+            sentence_tensor, _ = pad_packed_sequence(sentence_sequence, True, total_length=seq_len)\n\n# apply MLPs for arc and relations to the BiLSTM output states\narc_h = self.mlp_arc_h(sentence_tensor)\n", "fix_rule": "if pack_padded_sequence(sentence_tensor, lengths dtected, replace it with pack_padded_sequence(sentence_tensor, torch.IntTensor(lengths),"}

{"number": 451, "change": "def testtanh():\n\nPtensor = PolynomialTensor()\n\n-    x = torch.linspace(-3, 3, steps=10)\n+    x = torch.tensor(np.linspace(-3, 3, 10))\nexpected = torch.tensor(\n[\n-3.3883e02,\n", "fix_rule": "if torch.linspace() detected, replace it with torch.tensor(np.linspace())."}

{"number": 452, "change": "class BartTranslationTests(unittest.TestCase):\nwith torch.no_grad():\nlogits, *other_stuff = model(**self.net_input)\n\n-        expected_slice = torch.tensor([9.0078, 10.1113, 14.4787])\n+        expected_slice = torch.tensor([9.0078, 10.1113, 14.4787], device=torch_device)\nresult_slice = logits[0][0][:3]\nself.assertTrue(torch.allclose(expected_slice, result_slice, atol=TOLERANCE))\n", "fix_rule": "if torch.tensor() is detected, replace it with torch.tensor().to(torch_device)"}

{"number": 453, "change": "def test_dc_crn_separator_invalid_type():\ndef test_dc_crn_separator_output():\nreal = torch.rand(2, 10, 17)\nimag = torch.rand(2, 10, 17)\n-    x = ComplexTensor(real, imag) if is_torch_1_9_plus else torch.complex(real, imag)\n+    x = torch.complex(real, imag) if is_torch_1_9_plus else ComplexTensor(real, imag)\nx_lens = torch.tensor([10, 8], dtype=torch.long)\n\nfor num_spk in range(1, 3):\n", "fix_rule": "if ComplexTensor detected, replace it with torch.complex() if is_torch_1_9_plus else ComplexTensor"}

{"number": 457, "change": "def multilevel_roi_align(features, rcnn_boxes, resolution):\nall_rois = tf.concat(all_rois, axis=0)  # NCHW\n# Unshuffle to the original order, to match the original samples\nlevel_id_perm = tf.concat(level_ids, axis=0)  # A permutation of 1~N\n-    level_id_invert_perm = tf.invert_permutation(level_id_perm)\n+    level_id_invert_perm = tf.math.invert_permutation(level_id_perm)\nall_rois = tf.gather(all_rois, level_id_invert_perm, name=\"output\")\nreturn all_rois\n", "fix_rule": "if  tf.invert_permutation() detected, replace it with tf.math.invert_permutation()"}

{"number": 459, "change": "def _preprocess_deconv_output_shape(x, shape, dim_ordering):\nshape = (shape[0], shape[2], shape[3], shape[1])\n\nif shape[0] is None:\n-        shape = (tf.shape(x)[0], ) + shape[1:]\n+        shape = (tf.shape(x)[0], ) + tuple(shape[1:])\nreturn shape\n", "fix_rule": "If tf.shape(x)[0] is detected, replace it with tf.shape(x)[0] + tuple(shape[1:])"}

{"number": 462, "change": "class RGCNConv(MessagePassing):\nreturn out if edge_norm is None else out * edge_norm.view(-1, 1)\n\ndef update(self, aggr_out, x):\n-        if x.dtype == torch.long:\n+        if x is None:\nout = aggr_out + self.root\nelse:\nout = aggr_out + torch.matmul(x, self.root)\n", "fix_rule": "if  x is None dtected, replace it with x.dtype == torch.long"}

{"number": 470, "change": "class DenseGCNConv(torch.nn.Module):\nidx = torch.arange(N, dtype=torch.long, device=adj.device)\nadj[:, idx, idx] = 1 if not self.improved else 2\n\n-        out = self.lin(x)\n+        out = torch.matmul(x, self.weight)\ndeg_inv_sqrt = adj.sum(dim=-1).clamp(min=1).pow(-0.5)\n\nadj = deg_inv_sqrt.unsqueeze(-1) * adj * deg_inv_sqrt.unsqueeze(-2)\n", "fix_rule": "if self.lin() is detected, replace it with torch.matmul(x, self.weight)\nif adj.sum(dim=-1).clamp(min=1).pow(-0.5) is detected, replace it with deg_inv_sqrt\nif deg_inv_sqrt.unsqueeze(-1) * adj * deg_inv_sqrt.unsqueeze(-2) is detected, replace it with adj = deg_inv_sqrt.unsqueeze(-1) * adj * deg_inv_sqrt.unsqueeze(-2)"}

{"number": 472, "change": "class GradientsTest(tf.test.TestCase):\n\n\nif __name__ == \"__main__\":\n-  tf.test.main()\n+  if tf.__internal__.tf2.enabled():\n+    tf.test.main()\n", "fix_rule": "If \"__internal__.tf2.enabled()\" is detected after \"tf.test.main()\" is called, replace it with \"if tf.__internal__.tf2.enabled(): tf.test.main()\"."}

{"number": 473, "change": "class Model(ModelDesc):\ncost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)\ncost = tf.reduce_mean(cost, name='cross_entropy_loss')\n\n-        acc = tf.to_float(tf.nn.in_top_k(logits, label, 1))\n+        acc = tf.cast(tf.nn.in_top_k(logits, label, 1), tf.float32)\n\nacc = tf.reduce_mean(acc, name='accuracy')\nsummary.add_moving_summary(acc)\n", "fix_rule": "if  tf.to_float() dtected, replace it with tf.cast(, tf.float32)"}

{"number": 475, "change": "def block(params, scope, layer_num, bias, sequence_dim, memory_length_dim, varia\nif use_moe:\nmoe_params = mtf.transformer.moe.HParams()\nmtf.transformer.moe.set_default_moe_hparams(moe_params)\n+\n+                # override defaults\nfor k, v in params[\"moe_params\"].items():\nmoe_params.add_hparam(k, v)\n-                mtf.transformer.moe.set_default_moe_hparams(moe_params)\n+\nmoe_train = params[\"mode\"] == \"train\"\n\nm, aux_loss = mtf.transformer.moe.transformer_moe_layer_v1(res_x, x.shape[-1], moe_params,\n", "fix_rule": "if \"moe_params\" in params:\n    for k, v in params[\"moe_params\"].items():\n        moe_params.add_hparam(k, v)"}

{"number": 476, "change": "class TFCoreModelTesterMixin:\n\nself.assertIsNotNone(outputs)\n\n-        tf.keras.mixed_precision.experimental.set_policy(\"float32\")\n+        tf.keras.mixed_precision.set_global_policy(\"float32\")\n\n@slow\ndef test_train_pipeline_custom_model(self):\n", "fix_rule": "if tf.keras.mixed_precision.experimental.set_policy() is detected, replace it with tf.keras.mixed_precision.set_global_policy()"}

{"number": 479, "change": "class TFMBartForConditionalGeneration(TFMBartPreTrainedModel, TFCausalLanguageMo\nif labels is not None:\nlabels = tf.where(\nlabels == self.config.pad_token_id,\n-                tf.fill(shape_list(labels), -100),\n+                tf.cast(tf.fill(shape_list(labels), -100), labels.dtype),\nlabels,\n)\nuse_cache = False\n", "fix_rule": "Replace \"tf.fill(shape_list(labels), -100)\" with \"tf.cast(tf.fill(shape_list(labels), -100), labels.dtype)\""}

{"number": 480, "change": "class TFModelTesterMixin:\ndef _prepare_for_class(self, inputs_dict, model_class, return_labels=False):\nif model_class in TF_MODEL_FOR_MULTIPLE_CHOICE_MAPPING.values():\ninputs_dict = {\n-                k: tf.tile(tf.expand_dims(v, 1), (1, self.model_tester.num_choices, 1))\n-                if isinstance(v, tf.Tensor) and v.ndim != 0\n+                k: tf.tile(tf.expand_dims(v, 1), (1, self.model_tester.num_choices) + (1,) * (v.ndim - 1))\n+                if isinstance(v, tf.Tensor) and v.ndim > 0\nelse v\nfor k, v in inputs_dict.items()\n}\n", "fix_rule": "if `tf.Tensor` is detected and `v.ndim` is not equal to 0, replace `tf.tile(tf.expand_dims(v, 1), (1, self.model_tester.num_choices, 1))` with `tf.tile(tf.expand_dims(v, 1), (1, self.model_tester.num_choices) + (1,) * (v.ndim - 1))`"}

{"number": 482, "change": "class Pandas(datasets.ArrowBasedBuilder):\nreturn pa_table\n\ndef _generate_tables(self, files):\n-        for i, file in enumerate(files):\n+        for i, file in enumerate(itertools.chain.from_iterable(files)):\nwith open(file, \"rb\") as f:\npa_table = pa.Table.from_pandas(pd.read_pickle(f))\nyield i, self._cast_table(pa_table)\n", "fix_rule": "if  `files` change is detected, replace it with `itertools.chain.from_iterable(files)`"}

{"number": 483, "change": "class DiceLoss(nn.Module):\ncardinality = torch.sum(input_soft + target_one_hot, dims)\n\ndice_score = 2. * intersection / (cardinality + self.eps)\n-        return torch.mean(1. - dice_score)\n+        return torch.mean(torch.tensor(1.) - dice_score)\n\n\n######################\n", "fix_rule": "if torch.tensor() detected, replace it with In torch.tensor()."}

{"number": 488, "change": "class SageMakerTrainingArguments(TrainingArguments):\n# Here, we'll use torch.distributed.\n# Initializes the distributed backend which will take care of synchronizing nodes/GPUs\nif not torch.distributed.is_initialized():\n-                torch.distributed.init_process_group(backend=\"nccl\")\n+                torch.distributed.init_process_group(backend=\"nccl\", timeout=self.ddp_timeout_delta)\ndevice = torch.device(\"cuda\", self.local_rank)\nself._n_gpu = 1\n", "fix_rule": "if not torch.distributed.is_initialized() detected, replace it with torch.distributed.init_process_group(backend=\"nccl\", timeout=self.ddp_timeout_delta)"}

{"number": 497, "change": "class EvalbBracketingScorer(Metric):\nshutil.rmtree(tempdir)\n\nif is_distributed():\n-            # Setting the device to CPU since this metric is not expected to run on GPUs.\n-            device = torch.device(\"cpu\")\n+            device = torch.device(\"cuda\" if dist.get_backend() == \"nccl\" else \"cpu\")\ncorrect_predicted_brackets = torch.tensor(_correct_predicted_brackets).to(device)\npredicted_brackets = torch.tensor(_predicted_brackets).to(device)\ngold_brackets = torch.tensor(_gold_brackets).to(device)\n", "fix_rule": "if torch.device(\"cuda\" if dist.get_backend() == \"nccl\" else \"cpu\") dtected, replace it with torch.device(\"cuda\" if dist.get_backend() == \"nccl\" else \"cpu\"\n"}

{"number": 501, "change": "class E2E(torch.nn.Module):\n# Neither CPUTensor nor float/int value can be used\n# because NCCL communicates between GPU devices.\ndevice = next(self.parameters()).device\n-        acc = torch.tensor([acc], device=device)\n+\n+        acc = torch.tensor([acc], device=device) if acc is not None else None\ncer = torch.tensor([cer], device=device)\nwer = torch.tensor([wer], device=device)\nreturn self.loss, loss_ctc, loss_att, acc, cer, wer\n", "fix_rule": "if  acc is not None detected, replace it with acc = torch.tensor([acc], device=device) if acc is not None else None"}

{"number": 502, "change": "class DeepQNetwork(ValueFunction):\n\"\"\"\n\n# Compute estimated future value\n-        float_terminals = tf.to_float(batch['terminals'])\n+        float_terminals = batch['terminals'].astype(float)\nq_targets = batch['rewards'] + (1. - float_terminals) \\\n* self.gamma * self.get_target_values(batch['next_states'])\n", "fix_rule": "If 'tf.to_float' is detected, replace it with '.astype(float)'."}

{"number": 508, "change": "class DistributedFusedAdam(torch.optim.Optimizer):\ngrp = torch.distributed.new_group(ranks=ranks)\nif torch.distributed.get_rank() in ranks:\nself._rs_pg.append(grp)\n-            if self._compute_L2_grad_norm and torch.distributed.get_rank() in ranks:\n-                self._l2_grad_norm_pg = torch.distributed.new_group(ranks=ranks)\n-                torch.distributed.all_reduce(self._overflow_buf,group=self._l2_grad_norm_pg)\n+            if self._compute_L2_grad_norm:\n+                l2_grad_norm_pg = torch.distributed.new_group(ranks=ranks)\n+                if torch.distributed.get_rank() in ranks:\n+                    self._l2_grad_norm_pg = l2_grad_norm_pg\n+                    torch.distributed.all_reduce(self._overflow_buf,group=self._l2_grad_norm_pg)\nself._rs_st = [torch.cuda.Stream() for _ in range(self._num_rs_pg)]\nfor rs_pg in self._rs_pg:\ntorch.distributed.all_reduce(self._overflow_buf,group=rs_pg)\n", "fix_rule": "if  torch.distributed.get_rank() in ranks, replace it with l2_grad_norm_pg = torch.distributed.new_group(ranks=ranks)\nif torch.distributed.get_rank() in ranks:\n    self._l2_grad_norm_pg = l2_grad_norm_pg\n    torch.distributed.all_reduce(self._overflow_buf,group=self._l2_grad_norm_pg)"}

{"number": 510, "change": "def cartesian_product_of_parameters(**possible_parameters):\n\n\ndef default_with_one_parameter_changed(*, default={}, **possible_parameters):\n-    assert isinstance(default, dict), f\"default should be a dict not a {type(default)}\"\n+    if not isinstance(default, dict):\n+        raise AssertionError(f\"default should be a dict not a {type(default)}\")\n\nfor parameter_name, possible_values in possible_parameters.items():\nfor v in possible_values:\n", "fix_rule": "if not isinstance(default, dict) dtected, raise \nAssertionError(f\"default should be a dict not a {type(default)})\")"}

{"number": 516, "change": "class Speech2Text2SinusoidalPositionalEmbedding(nn.Module):\nemb = torch.cat([emb, torch.zeros(num_embeddings, 1)], dim=1)\nif padding_idx is not None:\nemb[padding_idx, :] = 0\n-        return emb\n+        return emb.to(torch.get_default_dtype())\n\n@torch.no_grad()\ndef forward(self, input_ids: torch.Tensor, past_key_values_length: int = 0):\n", "fix_rule": "if torch.cat() detected, replace it with torch.cat().to(torch.get_default_dtype())\n\nif emb detected, replace it with emb.to(torch.get_default_dtype())"}

{"number": 518, "change": "class EulerAncestralDiscreteScheduler(SchedulerMixin, ConfigMixin):\n\nprev_sample = sample + derivative * dt\n\n-        device = model_output.device if torch.is_tensor(model_output) else \"cpu\"\n-        if str(device) == \"mps\":\n+        device = model_output.device if torch.is_tensor(model_output) else torch.device(\"cpu\")\n+        if device.type == \"mps\":\n# randn does not work reproducibly on mps\nnoise = torch.randn(model_output.shape, dtype=model_output.dtype, device=\"cpu\", generator=generator).to(\ndevice\n", "fix_rule": "if str(device) == \"mps\" detected, replace it with device.type == \"mps\"\nif torch.randn() detected, replace it with torch.randn().to(device)"}

{"number": 519, "change": "class AutoRegressiveNN(nn.Module):\n\nif permutation is None:\n# By default set a random permutation of variables, which is important for performance with multiple steps\n-            self.permutation = torch.randperm(input_dim)\n+            self.permutation = torch.randperm(input_dim, device='cpu').to(torch.Tensor().device)\nelse:\n# The permutation is chosen by the user\nself.permutation = permutation.type(dtype=torch.int64)\n", "fix_rule": "if torch.randperm() detected, replace it with torch.randperm().to(torch.Tensor().device)"}

{"number": 522, "change": "class StableDiffusionInpaintPipeline(DiffusionPipeline):\nelse:\nraise ImportError(\"Please install accelerate via `pip install accelerate`\")\n\n-        device = torch.device(\"cuda\")\n+        device = torch.device(f\"cuda:{gpu_id}\")\n\nfor cpu_offloaded_model in [self.unet, self.text_encoder, self.vae, self.safety_checker]:\nif cpu_offloaded_model is not None:\n", "fix_rule": "if  \"cuda\" not in torch.device(), replace it with torch.device(f\"cuda:{gpu_id}\")\nIf any of the models in [self.unet, self.text_encoder, self.vae, self.safety_checker] is not None,"}

{"number": 524, "change": "class TwoStageDetector(BaseDetector, RPNTestMixin, BBoxTestMixin,\nif self.with_rpn:\nrpn_outs = self.rpn_head(x)\nouts = outs + (rpn_outs, )\n-        proposals = torch.randn(1000, 4).cuda()\n+        proposals = torch.randn(1000, 4).to(device=img.device)\n# bbox head\nrois = bbox2roi([proposals])\nif self.with_bbox:\n", "fix_rule": "if torch.randn() is detected, replace it with torch.randn().to(device=img.device)"}

{"number": 526, "change": "class PGModel(Model):\nactions = np.concatenate([path['actions'] for path in batch])\nbatch_advantage = np.concatenate([path[\"advantage\"] for path in batch])\nbatch_advantage = zero_mean_unit_variance(batch_advantage)\n+        batch_advantage = np.expand_dims(batch_advantage, axis=1)\nstates = np.concatenate([path['states'] for path in batch])\n\nreturn action_log_stds, action_means, actions, batch_advantage, states\n", "fix_rule": "If np.concatenate() is called on an array and np.expand_dims() is called on the result, replace it with np.concatenate([np.expand_dims(path['advantage'], axis=1) for path in batch])."}

{"number": 529, "change": "class Categorical(Distribution):\nelif one_hot:\nboolean_mask = x\nelse:\n-                boolean_mask = torch.zeros(ps.size()).scatter_(-1, x.data.long(), 1)\n+                boolean_mask = torch_zeros_like(ps.data).scatter_(-1, x.data.long(), 1)\n# apply log function to masked probability tensor\nreturn torch.log(ps.masked_select(boolean_mask.byte()).contiguous().view(*batch_pdf_size))\n", "fix_rule": "if torch.zeros() detected, replace it with torch.zeros_like()"}

{"number": 530, "change": "class ViTMAEModelIntegrationTest(unittest.TestCase):\n\n# forward pass\nwith torch.no_grad():\n-            outputs = model(**inputs, noise=torch.from_numpy(noise))\n+            outputs = model(**inputs, noise=torch.from_numpy(noise).to(device=torch_device))\n\n# verify the logits\nexpected_shape = torch.Size((1, 196, 768))\n", "fix_rule": "if  torch.from_numpy() dtected, replace it with torch.from_numpy().to(device=torch_device)"}

{"number": 532, "change": "def initialize_vocabulary(vocabulary_path):\nrev_vocab = []\nwith gfile.GFile(vocabulary_path, mode=\"rb\") as f:\nrev_vocab.extend(f.readlines())\n-    rev_vocab = [line.strip() for line in rev_vocab]\n+    rev_vocab = [tf.compat.as_bytes(line.strip()) for line in rev_vocab]\nvocab = dict([(x, y) for (y, x) in enumerate(rev_vocab)])\nreturn vocab, rev_vocab\nelse:\n", "fix_rule": "If \"tf.compat.as_bytes()\" is detected, replace it with \"line.strip()\"."}

{"number": 534, "change": "class ConformerSeparator(AbsSeparator):\n\"\"\"\n\n# if complex spectrum,\n-        if isinstance(input, ComplexTensor):\n+        if isinstance(input, ComplexTensor) or (\n+            is_torch_1_8_plus and torch.is_complex(input)\n+        ):\nfeature = abs(input)\nelse:\nfeature = input\n", "fix_rule": "Replace the condition `isinstance(input, ComplexTensor)` with `isinstance(input, ComplexTensor) or (is_torch_1_8_plus and torch.is_complex(input))`."}

{"number": 537, "change": "def batch_flatten(x):\n'''Turn a n-D tensor into a 2D tensor where\nthe first dimension is conserved.\n'''\n-    x = tf.reshape(x, [-1, prod(shape(x)[1:])])\n+    x = tf.reshape(x, tf.pack([-1, prod(shape(x)[1:])]))\nreturn x\n", "fix_rule": "if  tf.reshape(x, [-1, prod(shape(x)[1:])]) is detected, replace it with tf.reshape(x, tf.pack([-1, prod(shape(x)[1:])]))"}

{"number": 538, "change": "def distributed_train(local_rank: int, main_address: str, main_port: int, num_no\n# 2. PREPARE DISTRIBUTED MODEL\nmodel = torch.nn.Linear(32, 2)\ndevice = torch.device(f\"cuda:{local_rank}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n-    model = DistributedDataParallel(model, device_ids=[local_rank]).to(device)\n+    model = DistributedDataParallel(model, device_ids=[local_rank] if torch.cuda.is_available() else None).to(device)\n\n# 3. SETUP LOSS AND OPTIMIZER\ncriterion = torch.nn.MSELoss()\n", "fix_rule": "if DistributedDataParallel(model, device_ids=[local_rank]) detected, replace it with DistributedDataParallel(model, device_ids=[local_rank] if torch.cuda.is_available() else None)"}

{"number": 548, "change": "class VisionTransformer(nn.Module):\n\ndef forward(self, x):\nx = self.forward_features(x)\n-        if isinstance(x, tuple):\n-            x, x_dist = self.head(x[0]), self.head_dist(x[1])\n+        if self.head_dist is not None:\n+            x, x_dist = self.head(x[0]), self.head_dist(x[1])  # x must be a tuple\nif self.training and not torch.jit.is_scripting():\n# during inference, return the average of both classifier predictions\nreturn x, x_dist\n", "fix_rule": "if self.head_dist is not None and isinstance(x, tuple):\n    x, x_dist = self.head(x[0]), self.head_dist(x[1])  # x must be a tuple"}

{"number": 549, "change": "class TFKerasUtil(object):\n\ndataset = dataset.batch(batch_size).map(prep_data_tf_keras)\nreturn dataset\n-        return fn\n+        return tf.autograph.experimental.do_not_convert(fn) if _HAS_AUTOGRAPH else fn\n\n@staticmethod\ndef get_horovod():\n", "fix_rule": "if tf.autograph.experimental.do_not_convert() is not available, add tf.autograph.experimental.do_not_convert() before fn return"}

{"number": 554, "change": "with tf.device('/cpu:0'):\nnet = FlattenLayer(net, name='flatten')\nnet = DenseLayer(net, 384, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='d1relu')\nnet = DenseLayer(net, 192, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='d2relu')\n-            net = DenseLayer(net, n_units=10, act=tf.identity, W_init=W_init2, name='output')\n+            net = DenseLayer(net, n_units=10, act=None, W_init=W_init2, name='output')\ny = net.outputs\n\nce = tl.cost.cross_entropy(y, y_, name='cost')\n", "fix_rule": "If tf.identity is detected, replace it with None."}

{"number": 557, "change": "class up(nn.Module):\nif bilinear:\nself.up = nn.UpsamplingBilinear2d(scale_factor=2)\nelse:\n-            self.up = nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2)\n+            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n\nself.conv = double_conv(in_ch, out_ch)\n", "fix_rule": "if nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2) is detected, replace it with nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)"}

{"number": 559, "change": "class Metric(nn.Module, ABC):\nAutomatically calls ``update()``. Returns the metric value over inputs if ``compute_on_step`` is True.\n\"\"\"\n# add current step\n-        self.update(*args, **kwargs)\n+        with torch.no_grad():\n+            self.update(*args, **kwargs)\nself._forward_cache = None\n\nif self.compute_on_step:\n", "fix_rule": "\"\"\"\nIf self.compute_on_step detected, add torch.no_grad() before self.update(*args, **kwargs)\n\"\"\""}

{"number": 560, "change": "temperature = max(args.temperature, 1e-3)\nwith open(args.outf, 'w') as outf:\nfor i in range(args.nwords):\n\n-        output, hidden = model(Variable(input, requires_grad=False), hidden)\n-        gen = torch.multinomial(output[0].data.cpu().div(temperature).exp(), 1)[0][0] # FIXME: no multinomial on GPU?\n+        output, hidden = model(Variable(input, volatile=True), hidden)\n+        gen = torch.multinomial(output[0].data.div(temperature).exp().cpu(), 1)[0][0] # FIXME: multinomial is only for CPU\ninput.fill_(gen)\nword = corpus.dic.idx2word[gen]\noutf.write(word)\n", "fix_rule": "If `Variable(input, requires_grad=False)` is detected, replace it with `Variable(input, volatile=True)`. Similarly, if `output[0].data.cpu()` is detected, replace it with `output[0].data`. Finally, if `.exp()` is detected, move it after `.cpu()`."}

{"number": 561, "change": "class TFFunnelForMultipleChoice(TFFunnelPreTrainedModel, TFMultipleChoiceLoss):\n@tf.function(\ninput_signature=[\n{\n-                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),\n+                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),\n\"attention_mask\": tf.TensorSpec((None, None), tf.float32, name=\"attention_mask\"),\n-                \"token_type_ids\": tf.TensorSpec((None, None), tf.int64, name=\"token_type_ids\"),\n+                \"token_type_ids\": tf.TensorSpec((None, None), tf.int32, name=\"token_type_ids\"),\n}\n]\n)\n", "fix_rule": "if \"tf.TensorSpec((None, None), tf.int64\" detected, replace it with \"tf.TensorSpec((None, None), tf.int32\""}

{"number": 566, "change": "class ModelSaver(Callback):\nself.var_collections = var_collections\nif checkpoint_dir is None:\ncheckpoint_dir = logger.get_logger_dir()\n-        assert checkpoint_dir is not None\n-        if not tf.gfile.IsDirectory(checkpoint_dir):\n-            tf.gfile.MakeDirs(checkpoint_dir)\n+        if checkpoint_dir is not None:\n+            if not tf.gfile.IsDirectory(checkpoint_dir):\n+                tf.gfile.MakeDirs(checkpoint_dir)\nself.checkpoint_dir = checkpoint_dir\n\ndef _setup_graph(self):\n+        assert self.checkpoint_dir is not None, \\\n+            \"ModelSaver() doesn't have a valid checkpoint directory.\"\nvars = []\nfor key in self.var_collections:\nvars.extend(tf.get_collection(key))\n", "fix_rule": "if checkpoint_dir is None:\n    checkpoint_dir = logger.get_logger_dir()\n    if checkpoint_dir is not None:\n        if not tf.gfile.IsDirectory(checkpoint_dir):\n            tf.gfile.MakeDirs(checkpoint_dir)\n        assert self.checkpoint_dir is not None, \\\n            \"ModelSaver() doesn't have a valid checkpoint directory.\""}

{"number": 571, "change": "class ModelCheckpoint(Callback):\nself.best_k_models.pop(del_filepath)\n\n# do not save nan, replace with +/- inf\n-        if torch.isnan(current):\n+        if isinstance(current, torch.Tensor) and torch.isnan(current):\ncurrent = torch.tensor(float('inf' if self.mode == \"min\" else '-inf'))\n\nfilepath = self._get_metric_interpolated_filepath_name(ckpt_name_metrics, epoch, step, del_filepath)\n", "fix_rule": "\"\"\"\nif isinstance(current, torch.Tensor) and torch.isnan(current), replace it with current = torch.tensor(float('inf' if self.mode == \"min\" else '-inf'))\n\"\"\""}

{"number": 574, "change": "class Graph(kerastuner.HyperModel, serializable.Serializable):\n\ndef build(self, hp):\n\"\"\"Build the HyperModel into a Keras Model.\"\"\"\n-        tf.keras.backend.clear_session()\nself._register_hps(hp)\nself.compile()\nreal_nodes = {}\n", "fix_rule": "If `tf.keras.backend.clear_session()` is detected, remove the line of code."}

{"number": 578, "change": "class GroupViTVisionTransformer(nn.Module):\n\nself.embeddings = GroupViTVisionEmbeddings(config)\nself.encoder = GroupViTVisionEncoder(config)\n-        self.layernorm = nn.LayerNorm(embed_dim)\n+        self.layernorm = nn.LayerNorm(embed_dim, eps=config.layer_norm_eps)\n\n@add_start_docstrings_to_model_forward(GROUPVIT_VISION_INPUTS_DOCSTRING)\n@replace_return_docstrings(output_type=BaseModelOutputWithPooling, config_class=GroupViTVisionConfig)\n", "fix_rule": "if nn.LayerNorm(embed_dim) detected, replace it with nn.LayerNorm(embed_dim, eps=config.layer_norm_eps)"}

{"number": 585, "change": "class TestTrainSampleHook(tf.test.TestCase):\npred_dict = {}\npred_dict[\"predicted_tokens\"] = tf.constant([[\"Hello\", \"World\", \"\u7b11w\"]])\npred_dict[\"labels.target_tokens\"] = tf.constant([[\"Hello\", \"World\", \"\u7b11w\"]])\n-    pred_dict[\"labels.target_len\"] = tf.constant([2]),\n+    pred_dict[\"labels.target_len\"] = tf.constant(2),\ngraph_utils.add_dict_to_collection(pred_dict, \"predictions\")\n\ndef tearDown(self):\n", "fix_rule": "if  tf.constant([2]) dtected, replace it with tf.constant(2)"}

{"number": 587, "change": "class VonMises(TorchDistribution):\n\"\"\"\nshape = self._extended_shape(sample_shape)\nx = torch.empty(shape, dtype=self.loc.dtype, device=self.loc.device)\n-        done = torch.zeros(shape, dtype=self.loc.dtype, device=self.loc.device).byte()\n+        done = torch.zeros(shape, dtype=self.loc.dtype, device=self.loc.device).bool()\nwhile not done.all():\nu = torch.rand((3,) + shape, dtype=self.loc.dtype, device=self.loc.device)\nu1, u2, u3 = u.unbind()\n", "fix_rule": "if torch.zeros() detected, replace it with torch.zeros().bool()"}

{"number": 588, "change": "class GridTest(TestCase):\nassert_equal(adj.to_dense().numpy(), expected_adj)\n\ndef test_grid_with_connectivity_8(self):\n-        adj = grid(torch.Size([3, 2]), connectivity=8)\n+        adj = grid_3x3(torch.Size([3, 2]), connectivity=8)\n\nexpected_adj = [\n[0, 1, 1, 2, 0, 0],\n", "fix_rule": "if grid(torch.Size([3, 2]), connectivity=8) dtected, replace it with grid_3x3(torch.Size([3, 2]), connectivity=8)"}

{"number": 591, "change": "class Model(ModelDesc):\nself.last_state = tf.identity(last_state, 'last_state')\n\n# seqlen x (Bxrnnsize)\n-        output = tf.reshape(tf.concat(1, outputs), [-1, param.rnn_size])  # (Bxseqlen) x rnnsize\n+        output = tf.reshape(tf.concat_v2(outputs, 1), [-1, param.rnn_size])  # (Bxseqlen) x rnnsize\nlogits = FullyConnected('fc', output, param.vocab_size, nl=tf.identity)\nself.prob = tf.nn.softmax(logits / param.softmax_temprature)\n", "fix_rule": "if tf.concat(1, outputs) is detected, replace it with tf.concat_v2(outputs, 1)"}

{"number": 595, "change": "def fit_line(points: Tensor, weights: Optional[Tensor] = None) -> ParametrizedLi\nA = A.transpose(-2, -1) @ A\n\n# NOTE: not optimal for 2d points, but for now works for other dimensions\n-    _, _, V = torch.linalg.svd(A)\n+    _, _, V = _torch_svd_cast(A)\n+    V = V.transpose(-2, -1)\n\n# the first left eigenvector is the direction on the fited line\ndirection = V[..., 0, :]  # BxD\n", "fix_rule": "If `torch.linalg.svd` is detected, replace it with `_torch_svd_cast`. Then, add the line `V = V.transpose(-2, -1)` after the replacement."}

{"number": 596, "change": "def ndim(x):\n'''Returns the number of axes in a tensor, as an integer.\n'''\nif is_sparse(x):\n-        return int(x.shape.get_shape()[0])\n+        return x._dims\n\ndims = x.get_shape()._dims\nif dims is not None:\n", "fix_rule": "if is_sparse(x):\n    return x._dims.to(device)\nif dims is not None:"}

{"number": 601, "change": "class Model(ModelDesc):\ninput_list = tf.unstack(input_feature, axis=1)  # seqlen x (Bxrnnsize)\n\n# seqlen is 1 in inference. don't need loop_function\n-        outputs, last_state = tf.nn.rnn(cell, input_list, initial, scope='rnnlm')\n+        outputs, last_state = tf.contrib.rnn.static_rnn(cell, input_list, initial, scope='rnnlm')\nself.last_state = tf.identity(last_state, 'last_state')\n\n# seqlen x (Bxrnnsize)\n", "fix_rule": "if tf.nn.rnn() is detected, replace it with tf.contrib.rnn.static_rnn()"}

{"number": 611, "change": "class Attention(nn.Module):\nquery, processed_inputs)\n# apply masking\nif mask is not None:\n-            attention.data.masked_fill_(torch.bitwise_not(mask), self._mask_value)\n+            attention.data.masked_fill_(~mask, self._mask_value)\n# apply windowing - only in eval mode\nif not self.training and self.windowing:\nattention = self.apply_windowing(attention, inputs)\n", "fix_rule": "if torch.bitwise_not(mask) is detected, replace it with ~mask"}

{"number": 613, "change": "class EarlyStopping(Callback):\nf\" {self.monitor} = {current} {self.order_dict[self.mode]} {self.divergence_threshold}.\"\n\" Signaling Trainer to stop.\"\n)\n-        elif self.monitor_op(current - self.min_delta, self.best_score):\n+        elif self.monitor_op(current - self.min_delta, self.best_score.to(trainer.lightning_module.device)):\nshould_stop = False\nreason = self._improvement_message(current)\nself.best_score = current\n", "fix_rule": "if self.monitor = \"torch.rand()\" detected, replace it with \"torch.rand().to(trainer.lightning_module.device)\""}

{"number": 614, "change": "class LSTM(Model):\nlast_layer = add_time_dimension(features, self.seq_lens)\n\n# Setup the LSTM cell\n-        lstm = rnn.BasicLSTMCell(cell_size, state_is_tuple=True)\n+        lstm = tf.nn.rnn_cell.LSTMCell(cell_size, state_is_tuple=True)\nself.state_init = [\nnp.zeros(lstm.state_size.c, np.float32),\nnp.zeros(lstm.state_size.h, np.float32)\n", "fix_rule": "if rnn.BasicLSTMCell() detected, replace it with tf.nn.rnn_cell.LSTMCell()"}

{"number": 615, "change": "class XGLMModel(XGLMPreTrainedModel):\n\nhidden_states = inputs_embeds + positions\n\n-        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n+        hidden_states = nn.functional.dropout(hidden_states, p=float(self.dropout), training=self.training)\n\n# decoder layers\nall_hidden_states = () if output_hidden_states else None\n", "fix_rule": "if nn.functional.dropout(p=self.dropout) detected, replace it with nn.functional.dropout(p=float(self.dropout))"}

{"number": 618, "change": "class CategoricalAccuracy(Metric):\ncorrect.unsqueeze_(-1)\n\nif mask is not None:\n-            correct *= mask.view(-1, 1).float()\n+            correct *= mask.view(-1, 1)\nself.total_count += mask.sum()\nelse:\nself.total_count += gold_labels.numel()\n", "fix_rule": "if mask is not None and mask.dtype == torch.bool, replace it with correct *= mask.view(-1, 1).float()\nif mask is not None and mask.dtype != torch.bool, replace it with correct *= mask.view(-1, 1)\nself.total_count += mask.sum() whether mask is None or not\nself.total_count += gold_labels.numel()"}

{"number": 621, "change": "def conditional(\nif f_scale_tril is not None:\npack = torch.cat((pack, f_scale_tril_2D), dim=1)\n\n-        Lffinv_pack = pack.triangular_solve(Lff, upper=False)[0]\n+        Lffinv_pack = torch.linalg.solve_triangular(Lff, pack, upper=False)\n# unpack\nv_2D = Lffinv_pack[:, : f_loc_2D.size(1)]\nW = Lffinv_pack[:, f_loc_2D.size(1) : f_loc_2D.size(1) + M].t()\n", "fix_rule": "if \"triangular_solve\" is detected, replace it with \"torch.linalg.solve_triangular(Lff, pack, upper=False)\""}

{"number": 623, "change": "class Model(ModelDesc):\nwrong = prediction_incorrect(logits, label, 5, name='wrong-top5')\nadd_moving_summary(tf.reduce_mean(wrong, name='train-error-top5'))\n\n-        wd_cost = tf.mul(1e-4, regularize_cost('.*/W', tf.nn.l2_loss), name='l2_regularize_loss')\n+        wd_cost = regularize_cost('.*/W', l2_regularizer(1e-4), name='l2_regularize_loss')\nadd_moving_summary(loss, wd_cost)\nself.cost = tf.add_n([loss, wd_cost], name='cost')\n", "fix_rule": "if tf.mul() detected, replace it with l2_regularizer()."}

{"number": 627, "change": "class Optimizer:\ng = [dev_grads[dev][var_idx][0] for dev in devices]\n\nif np.prod(grad_shape):  # nccl does not support zero-sized tensors\n-                            g = tf.contrib.nccl.all_sum(g)\n+                            g = nccl_ops.all_sum(g)\n\nfor dev, gg in zip(devices, g):\ndev_grads[dev][var_idx] = (gg, dev_grads[dev][var_idx][1])\n", "fix_rule": "if tf.contrib.nccl.all_sum(g) is detected, replace it with nccl_ops.all_sum(g)"}

{"number": 639, "change": "class LinearModel(object):\nreturn self.sess.run(self.cross_entropy_grads, feed_dict={self.x: xs, self.y_: ys})\n\ndef net_initialization():\n-  return LinearModel([784,10])\n+  with tf.Graph().as_default():\n+    return LinearModel([784,10])\n\n# By default, when an environment variable is used by a remote function, the\n# initialization code will be rerun at the end of the remote task to ensure\n", "fix_rule": "If \"with tf.Graph().as_default():\" is added, replace it with \"return LinearModel([784,10])"}

{"number": 640, "change": "class EpochResultStore:\n# attach capture batch_size\nResult.attach_batch_size(self._batch_size, hook_result)\n\n-            hook_result.detach()\n+            hook_result = hook_result.detach()\nif self.trainer.move_metrics_to_cpu:\n-                hook_result.cpu()\n+                hook_result = hook_result.cpu()\nelif self.trainer._distrib_type == DistributedType.DP:\n-                hook_result.to(torch.device(\"cuda\", self.trainer.root_gpu))\n+                hook_result = hook_result.to(torch.device(\"cuda\", self.trainer.root_gpu))\n\nself._internals[fx_name].append(hook_result, info)\n", "fix_rule": "if hook_result.detach() is detected, replace it with hook_result = hook_result.detach()\nif hook_result.cpu() is detected, replace it with hook_result = hook_result.cpu()\nif hook_result.to(torch.device(\"cuda\", self.trainer.root_gpu)) is detected, replace it with hook_result = hook_result.to(torch.device(\"cuda\", self.trainer.root_gpu))"}

{"number": 641, "change": "class LinearRegression(d2l.Module):\ndef __init__(self, lr):\nsuper().__init__()\nself.save_hyperparameters()\n-        self.net = tf.keras.layers.Dense(1)\n+        initializer = tf.initializers.RandomNormal(stddev=0.01)\n+        self.net = tf.keras.layers.Dense(1, kernel_initializer=initializer)\n\ndef forward(self, X):\n\"\"\"The linear regression model.\n", "fix_rule": "if tf.keras.layers.Dense(1) detected, replace it with tf.keras.layers.Dense(1, kernel_initializer=tf.initializers.RandomNormal(stddev=0.01))"}

{"number": 643, "change": "class TestPretrainedTransformerEmbedder(AllenNlpTestCase):\ndef test_xlnet_token_type_ids(self):\ntoken_embedder = PretrainedTransformerEmbedder(\"xlnet-base-cased\")\ntoken_ids = torch.LongTensor([[1, 2, 3], [2, 3, 4]])\n-        mask = torch.ones_like(token_ids)\n+        mask = torch.ones_like(token_ids).bool()\ntype_ids = torch.zeros_like(token_ids)\ntype_ids[1, 1] = 1\ntoken_embedder(token_ids, mask, type_ids)\n", "fix_rule": "if torch.ones_like(token_ids) is detected, replace it with torch.ones_like(token_ids).bool()"}

{"number": 645, "change": "class Block(Layer):\nlayer_counter[layer_type] += 1\n\n# layer_name = self.name + '-' + layer_name\n-            self.layers[n] = self.submodule(\n+            layer = self.submodule(\nname=layer_name, module=layer_spec, modules=tensorforce.core.layer_modules,\ninput_spec=self._input_spec\n)\n-            self._input_spec = self.layers[n].output_spec()\n-\n+            self.layers.append(layer)\n+            self._input_spec = layer.output_spec()\n\nreturn self.layers[0].input_spec.copy()\n", "fix_rule": "if self.submodule detected, replace it with layer = self.submodule("}

{"number": 648, "change": "def model():\n\nif sd_vae_approx_model is None:\nsd_vae_approx_model = VAEApprox()\n-        sd_vae_approx_model.load_state_dict(torch.load(os.path.join(paths.models_path, \"VAE-approx\", \"model.pt\")))\n+        sd_vae_approx_model.load_state_dict(torch.load(os.path.join(paths.models_path, \"VAE-approx\", \"model.pt\"), map_location='cpu' if devices.device.type != 'cuda' else None))\nsd_vae_approx_model.eval()\nsd_vae_approx_model.to(devices.device, devices.dtype)\n", "fix_rule": "if torch.load(os.path.join(paths.models_path, \"VAE-approx\", \"model.pt\")) detected, replace it with torch.load(os.path.join(paths.models_path, \"VAE-approx\", \"model.pt\"), map_location='cpu' if devices.device.type != 'cuda' else None)"}

{"number": 655, "change": "class {{cookiecutter.camelcase_modelname}}EncoderLayer(nn.Module):\nhidden_states = residual + hidden_states\nhidden_states = self.final_layer_norm(hidden_states)\n\n-        if torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any():\n+        if hidden_states.dtype == torch.float16 and (torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any()):\nclamp_value = torch.finfo(hidden_states.dtype).max - 1000\nhidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)\n", "fix_rule": "if hidden_states.dtype == torch.float16 dtected, replace it with hidden_states.dtype == torch.float16 and (torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any())"}

{"number": 656, "change": "class LabelSmoother:\n\ndef __call__(self, model_output, labels):\nlogits = model_output[\"logits\"] if isinstance(model_output, dict) else model_output[0]\n-        log_probs = -torch.nn.functional.log_softmax(logits, dim=-1)\n+        log_probs = -nn.functional.log_softmax(logits, dim=-1)\nif labels.dim() == log_probs.dim() - 1:\nlabels = labels.unsqueeze(-1)\n", "fix_rule": "If \"torch.nn.functional.log_softmax\" is detected, replace it with \"nn.functional.log_softmax\"."}

{"number": 661, "change": "class Model(ModelDesc):\n.apply(fg)\n.BatchNorm('bn5').apply(activate)\n# 5\n-                      .tf.nn.dropout(0.5 if is_training else 1.0)\n+                      .Dropout(rate=0.5 if is_training else 0.0)\n.Conv2D('conv6', 512, 5, padding='VALID')\n.apply(fg).BatchNorm('bn6')\n.apply(nonlin)\n", "fix_rule": "if `.tf.nn.dropout(0.5 if is_training else 1.0)` is detected, replace it with `.Dropout(rate=0.5 if is_training else 0.0)`"}

{"number": 665, "change": "class BLEU(Metric):\nreturn math.exp(1.0 - self._reference_lengths / self._prediction_lengths)\n\ndef _get_valid_tokens_mask(self, tensor: torch.LongTensor) -> torch.ByteTensor:\n-        valid_tokens_mask = torch.ones(tensor.size(), dtype=torch.uint8)\n+        valid_tokens_mask = torch.ones(tensor.size(), dtype=torch.bool)\nfor index in self._exclude_indices:\nvalid_tokens_mask = valid_tokens_mask & (tensor != index)\nreturn valid_tokens_mask\n", "fix_rule": "if torch.ones() is detected, replace it with torch.ones().bool()"}

{"number": 672, "change": "class MessagePassing(torch.nn.Module):\nthe_size: List[Optional[int]] = [None, None]\n\nif isinstance(edge_index, Tensor):\n-            assert edge_index.dtype == torch.long\n-            assert edge_index.dim() == 2\n-            assert edge_index.size(0) == 2\n+            assert edge_index.dtype == torch.long, \\\n+                \"edge_index.dtype is not of torch.long\"\n+            assert edge_index.dim() == 2, \\\n+                \"edge_index.dim() is not equal to 2\"\n+            assert edge_index.size(0) == 2, \\\n+                \"edge_index.size(0) is not equal to 2\"\nif size is not None:\nthe_size[0] = size[0]\nthe_size[1] = size[1]\n", "fix_rule": "if isinstance(edge_index, Tensor):\n-            assert edge_index.dtype == torch.long\n-            assert edge_index.dim() == 2\n-            assert edge_index.size(0) == 2\n+            assert edge_index.dtype == torch.long, \\\n+                \"edge_index.dtype is not of torch.long\"\n+            assert edge_index.dim() == 2, \\\n+                \"edge_index.dim() is not equal to 2\"\n+            assert edge_index.size(0) == 2, \\\n+                \"edge_index.size(0) is not equal to 2\"\n\nReplace the assertions about edge_index with the following assertions:\nassert edge_index.dtype == torch.long, \"edge_index.dtype is not of torch.long\"\nassert edge_index.dim() == 2, \"edge_index.dim() is not equal to 2\"\nassert edge_index.size(0) == 2, \"edge_index.size(0) is not equal to 2\""}

{"number": 674, "change": "class DecoderLayer(nn.Module):\nif self.normalize_before:\nx = self.norm2(x)\nif self.concate_after:\n-            x_concat = torch.cat(x, self.src_attn(x, memory, memory, memory_mask))\n+            x_concat = torch.cat((x, self.src_attn(x, memory, memory, memory_mask)), dim=-1)\nx = residual + self.concate_linear2(x_concat)\nelse:\nx = residual + self.dropout(self.src_attn(x, memory, memory, memory_mask))\n", "fix_rule": "if torch.cat() is detected, replace it with torch.cat((x, self.src_attn(x, memory, memory, memory_mask)), dim=-1)"}

{"number": 677, "change": "def clip(\n*,\nout: Optional[torch.Tensor] = None,\n) -> torch.Tensor:\n-    assert torch.all(torch.less(x_min, x_max)), \"Min value must be less than max.\"\n+    assert torch.all(\n+        torch.less(torch.tensor(x_min), x_max)\n+    ), \"Min value must be less than max.\"\nif hasattr(x_min, \"dtype\"):\npromoted_type = torch.promote_types(x_min.dtype, x_max.dtype)\npromoted_type = torch.promote_types(promoted_type, x.dtype)\n", "fix_rule": "if  torch.all(torch.less(x_min, x_max)) detected, replace it with torch.all(torch.less(torch.tensor(x_min), x_max))"}

{"number": 681, "change": "class LayoutLMv3Model(LayoutLMv3PreTrainedModel):\nposition_ids = position_ids.expand_as(input_ids)\nfinal_position_ids = position_ids\n\n-        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(attention_mask, None, device)\n+        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(\n+            attention_mask, None, device, dtype=embedding_output.dtype\n+        )\n\n# Prepare head mask if needed\n# 1.0 in head_mask indicate we keep the head\n", "fix_rule": "if self.get_extended_attention_mask() detected, replace it with self.get_extended_attention_mask(attention_mask, None, device, dtype=embedding_output.dtype)"}

{"number": 683, "change": "class StableDiffusionKDiffusionPipeline(DiffusionPipeline):\nreturn_tensors=\"pt\",\n)\ntext_input_ids = text_inputs.input_ids\n-        untruncated_ids = self.tokenizer(prompt, padding=\"max_length\", return_tensors=\"pt\").input_ids\n+        untruncated_ids = self.tokenizer(prompt, padding=\"longest\", return_tensors=\"pt\").input_ids\n\n-        if not torch.equal(text_input_ids, untruncated_ids):\n+        if untruncated_ids.shape[-1] >= text_input_ids.shape[-1] and not torch.equal(text_input_ids, untruncated_ids):\nremoved_text = self.tokenizer.batch_decode(untruncated_ids[:, self.tokenizer.model_max_length - 1 : -1])\nlogger.warning(\n\"The following part of your input was truncated because CLIP can only handle sequences up to\"\n", "fix_rule": "\"\"\"\nIf 'padding=\"max_length\"' is detected, replace it with 'padding=\"longest\"'. Also, if 'not torch.equal(text_input_ids, untruncated_ids)' is detected, replace it with 'untruncated_ids.shape[-1] >= text_input_ids.shape[-1] and not torch.equal(text_input_ids, untruncated_ids)'.\n\"\"\""}

{"number": 693, "change": "class Ensemble(nn.ModuleList):\n\n\ndef attempt_load(weights, device=None, inplace=True, fuse=True):\n+    # Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a\nfrom models.yolo import Detect, Model\n\n-    # Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a\nmodel = Ensemble()\nfor w in weights if isinstance(weights, list) else [weights]:\n-        ckpt = torch.load(attempt_download(w), map_location=device)\n-        ckpt = (ckpt.get('ema') or ckpt['model']).float()  # FP32 model\n+        ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n+        ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model\nmodel.append(ckpt.fuse().eval() if fuse else ckpt.eval())  # fused or un-fused model in eval mode\n\n# Compatibility updates\n", "fix_rule": "if  torch.load() detected, replace it with torch.load().to('cpu')\nif  (ckpt.get('ema') or ckpt['model']).to(device) detected, replace it with (ckpt.get('ema') or ckpt['model']).to(device).float()"}

{"number": 707, "change": "class TFLiteBackendInferenceLearner(TensorflowBaseInferenceLearner):\nself.interpreter.set_tensor(i, input_tensor)\nself.interpreter.invoke()\nreturn tuple(\n-            self.interpreter.get_tensor(output_detail[\"index\"])\n+            tf.convert_to_tensor(\n+                self.interpreter.get_tensor(output_detail[\"index\"])\n+            )\nfor output_detail in output_details\n)\n", "fix_rule": "\"\"\"\nIf self.interpreter.get_tensor(output_detail[\"index\"]) is detected, replace it with tf.convert_to_tensor(self.interpreter.get_tensor(output_detail[\"index\"])).\n\"\"\""}

{"number": 710, "change": "class Model(ModelDesc):\n.Conv2D('conv3.1', filters=128, padding='VALID') \\\n.Conv2D('conv3.2', filters=128, padding='VALID') \\\n.FullyConnected('fc0', 1024 + 512, activation=tf.nn.relu) \\\n-                .tf.nn.dropout(keep_prob) \\\n+                .Dropout(rate=drop_rate) \\\n.FullyConnected('fc1', 512, activation=tf.nn.relu) \\\n.FullyConnected('linear', out_dim=self.cifar_classnum)()\n", "fix_rule": "if  tf.nn.dropout(keep_prob) is detected, replace it with .Dropout(rate=drop_rate)"}

{"number": 720, "change": "class CustomConverter(object):\nxs_pad = pad_list([torch.from_numpy(x).float() for x in xs], 0).to(device, dtype=self.dtype)\n\nilens = torch.from_numpy(ilens).to(device)\n-        # NOTE: this is for multi-task learning (e.g., speech translation)\n-        ys_pad = pad_list([torch.from_numpy(np.array(y[0]) if isinstance(y, tuple) else y).long()\n+        # NOTE: this is for multi-output (e.g., speech translation)\n+        ys_pad = pad_list([torch.from_numpy(np.array(y[0][:]) if isinstance(y, tuple) else y).long()\nfor y in ys], self.ignore_id).to(device)\n\nreturn xs_pad, ilens, ys_pad\n", "fix_rule": "if isinstance(y, tuple):, replace it with if isinstance(y, tuple):\nif isinstance(y, tuple):, replace it with if isinstance(y, tuple):\ntorch.from_numpy(np.array(y[0]) if isinstance(y, tuple) else y).long()., replace it with torch.from_numpy(np.array(y[0][:]) if isinstance(y, tuple) else y).long()."}

{"number": 725, "change": "def run_benchmark(state):\n\n\ndef on_state_reset():\n-    tf.keras.backend.set_value(model.optimizer.lr, lr * hvd.size())\n+    opt.lr.assign(lr * hvd.size())\n\n\nstate = hvd.elastic.TensorFlowKerasState(model, opt, img_secs=[], iter=0, batch=0, warm=False)\n", "fix_rule": "if tf.keras.backend.set_value(model.optimizer.lr, lr * hvd.size()) is detected, replace it with opt.lr.assign(lr * hvd.size())"}

{"number": 728, "change": "def vector_to_skew_symmetric_matrix(\na2s = vector_expanded[..., 1:2, :]\na3s = vector_expanded[..., 2:3, :]\n# BS x 1 x 1\n-    zs = torch.zeros(batch_shape + [1, 1], device=vector.device)\n+    zs = torch.zeros(batch_shape + [1, 1], device=vector.device, dtype=vector.dtype)\n# BS x 1 x 3\nrow1 = torch.cat((zs, -a3s, a2s), -1)\nrow2 = torch.cat((a3s, zs, -a1s), -1)\n", "fix_rule": "if torch.zeros() detected, replace it with torch.zeros().to(device, dtype=vector.dtype)"}

{"number": 730, "change": "from pyro.ops.einsum import contract\ndef _finfo(tensor):\n# This can be replaced with torch.finfo once it is available\n# https://github.com/pytorch/pytorch/issues/10742\n-    return np.finfo(torch.empty(torch.Size(), dtype=tensor.dtype).numpy().dtype)\n+    return np.finfo(torch.empty(torch.Size(), dtype=tensor.dtype, device=\"cpu\").numpy().dtype)\n\n\ndef _check_batch_dims_are_sensible(output_dims, nonoutput_ordinal):\n", "fix_rule": "if  np.finfo(torch.empty(torch.Size(), dtype=tensor.dtype).numpy().dtype is detected, replace it with np.finfo(torch.empty(torch.Size(), dtype=tensor.dtype, device=\"cpu\").numpy().dtype)"}

{"number": 742, "change": "def stats(policy, train_batch):\n\"cur_lr\": tf.cast(policy.cur_lr, tf.float64),\n\"policy_loss\": policy.loss.pi_loss,\n\"entropy\": policy.loss.entropy,\n-        \"var_gnorm\": tf.global_norm(policy.model.trainable_variables()),\n+        \"var_gnorm\": tf.linalg.global_norm(policy.model.trainable_variables()),\n\"vf_loss\": policy.loss.vf_loss,\n\"vf_explained_var\": explained_variance(\ntf.reshape(policy.loss.value_targets, [-1]),\n", "fix_rule": "Replace tf.global_norm() with tf.linalg.global_norm()"}

{"number": 743, "change": "def test_tensorrt_torch(\nres_orig = tuple(model(*inputs_example))\nassert all(\n[\n-                    torch.allclose(res_tensor, res_orig_tensor, rtol=1e-01)\n+                    torch.allclose(\n+                        res_tensor.float(), res_orig_tensor, rtol=1e-01\n+                    )\nfor (res_tensor, res_orig_tensor) in zip(res, res_orig)\n]\n)\n", "fix_rule": "if the code compares two tensors using torch.allclose(), convert the first tensor to float using the .float() method."}

{"number": 744, "change": "class Attention(nn.Module):\n# Apply the attention mask\nw = w + attention_mask\n\n-        w = nn.Softmax(dim=-1)(w)\n+        w = nn.functional.softmax(w, dim=-1)\nw = self.attn_dropout(w)\n\n# Mask heads if we want to\n", "fix_rule": "if nn.Softmax(dim=-1) dtected, replace it with nn.functional.softmax(w, dim=-1)"}

{"number": 752, "change": "class DistributedGroupSampler(Sampler):\nif size > 0:\nindice = np.where(self.flag == i)[0]\nassert len(indice) == size\n-                indice = indice[list(torch.randperm(int(size),\n-                                                    generator=g))].tolist()\n+                # add .numpy() to avoid bug when selecting indice in parrots.\n+                # TODO: check whether torch.randperm() can be replaced by\n+                # numpy.random.permutation().\n+                indice = indice[list(\n+                    torch.randperm(int(size), generator=g).numpy())].tolist()\nextra = int(\nmath.ceil(\nsize * 1.0 / self.samples_per_gpu / self.num_replicas)\n", "fix_rule": "if torch.randperm() is used, add .numpy() to convert it to a numpy array before selecting indices in line 8."}

{"number": 759, "change": "def test_pair_norm(scale_individually):\nassert out1.size() == (100, 16)\n\nout2 = norm(torch.cat([x, x], dim=0), torch.cat([batch, batch + 1], dim=0))\n-    assert torch.allclose(out1, out2[:100])\n-    assert torch.allclose(out1, out2[100:])\n+    assert torch.allclose(out1, out2[:100], atol=1e-6)\n+    assert torch.allclose(out1, out2[100:], atol=1e-6)\n", "fix_rule": "if torch.allclose() dtected, replace it with torch.allclose(atol=1e-6)"}

{"number": 764, "change": "class BlenderbotSmallEncoderLayer(nn.Module):\nhidden_states = residual + hidden_states\nhidden_states = self.final_layer_norm(hidden_states)\n\n-        if torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any():\n+        if hidden_states.dtype == torch.float16 and (\n+            torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any()\n+        ):\nclamp_value = torch.finfo(hidden_states.dtype).max - 1000\nhidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)\n", "fix_rule": "if hidden_states.dtype == torch.float16 is detected, add:\n(\ntorch.isinf(hidden_states).any() or torch.isnan(hidden_states).any()\n)"}

{"number": 774, "change": "class QuantLinear(nn.Module):\nx_int = x / prev_act_scaling_factor\n\nreturn (\n-            F.linear(x_int, weight=self.weight_integer, bias=self.bias_integer) * bias_scaling_factor,\n+            nn.functional.linear(x_int, weight=self.weight_integer, bias=self.bias_integer) * bias_scaling_factor,\nbias_scaling_factor,\n)\n", "fix_rule": "if F.linear() is detected, replace it with nn.functional.linear()."}

{"number": 779, "change": "class Importance(TracePosterior):\n\"\"\"\nif self.log_weights:\nlog_w_norm = self.get_normalized_weights(log_scale=True)\n-            ess = torch.exp(-logsumexp(2*log_w_norm, 0))\n+            ess = torch.exp(-torch.logsumexp(2*log_w_norm, 0))\nelse:\nwarnings.warn(\"The log_weights list is empty, effective sample size is zero.\")\ness = 0\n", "fix_rule": "if self.log_weights:\n    log_w_norm = self.get_normalized_weights(log_scale=True)\n    ess = torch.exp(-torch.logsumexp(2*log_w_norm, 0))\nelse:\n    warnings.warn(\"The log_weights list is empty, effective sample size is zero.\")\n    ess = 0"}

{"number": 782, "change": "def dnn(tensor_in, hidden_units, activation=tf.nn.relu, keep_prob=None):\nwith tf.variable_scope('dnn'):\nfor i, n_units in enumerate(hidden_units):\nwith tf.variable_scope('layer%d' % i):\n-                tensor_in = linear.linear(tensor_in, n_units, True)\n+                tensor_in = linear(tensor_in, n_units, True)\ntensor_in = activation(tensor_in)\nif keep_prob:\ntensor_in = tf.nn.dropout(tensor_in, keep_prob)\n", "fix_rule": "if linear.linear() detected, replace it with linear()"}

{"number": 783, "change": "class DSClipEncoder(torch.nn.Module):\nseq_len,\nseq_len,\ndtype=dtype,\n-                           device=torch.cuda.current_device())\n+                           device=get_accelerator().current_device_name())\nmask.fill_(torch.tensor(torch.finfo(dtype).min))\nmask.triu_(1)\nmask = mask.unsqueeze(1)\n", "fix_rule": "if torch.cuda.current_device() detected, replace it with get_accelerator().current_device_name()\nif torch.tensor(torch.finfo(dtype).min detected, replace it with torch.finfo(dtype).min()\nmask.fill_(torch.tensor(torch.finfo(dtype).min) detected, replace it with mask.fill_(torch.finfo(dtype).min()\nIf mask.triu_(1) detected, replace it with mask.triu_(1)\nmask = mask.unsqueeze(1) detected, replace it with mask = mask.unsqueeze(1)"}

{"number": 789, "change": "class AttentionDecoder(DecoderBase):\n])\nelse:\nattention_context = output.attention_context\n-    return tf.concat(1, [next_input, attention_context])\n+    return tf.concat_v2([next_input, attention_context], 1)\n\ndef _pad_att_scores(self, scores):\n\"\"\"Pads attention scores to fixed length. This is a hack because raw_rnn\n", "fix_rule": "if tf.concat(1, dtected, replace it with tf.concat_v2(dtected, 1)"}

{"number": 791, "change": "def test_graph_saint():\nassert sample.node_norm.numel() == sample.num_nodes\nassert sample.edge_norm.numel() == sample.num_edges\n\n+    torch.manual_seed(12345)\nloader = GraphSAINTRandomWalkSampler(data, batch_size=2, walk_length=1,\n-                                         num_steps=4, log=False)\n+                                         num_steps=4, sample_coverage=10,\n+                                         log=False)\n\nfor sample in loader:\nassert len(sample) == 4\n", "fix_rule": "If `assert torch.manual_seed(12345)` is detected, replace it with `torch.manual_seed(12345)`."}

{"number": 792, "change": "class GPTJAttention(nn.Module):\n):\n# compute causal mask from causal mask buffer\nquery_length, key_length = query.size(-2), key.size(-2)\n-        causal_mask = self.bias[:, :, key_length - query_length : key_length, :key_length].to(torch.bool)\n+        causal_mask = self.bias[:, :, key_length - query_length : key_length, :key_length]\n\n# Keep the attention weights computation in fp32 to avoid overflow issues\nquery = query.to(torch.float32)\n", "fix_rule": "if self.bias[:, :, key_length - query_length : key_length, :key_length] dtected, replace it with self.bias[:, :, key_length - query_length : key_length, :key_length].to(torch.bool)\n\nif query dtected, replace it with query.to(torch.float32)"}

{"number": 800, "change": "class GeneralizedChannelPermute(ConditionedGeneralizedChannelPermute, TransformM\nself.__delattr__('permutation')\n\n# Sample a random orthogonal matrix\n-        W, _ = torch.qr(torch.randn(channels, channels))\n+        W, _ = torch.linalg.qr(torch.randn(channels, channels))\n\n# Construct the partially pivoted LU-form and the pivots\nLU, pivots = W.lu()\n", "fix_rule": "if  torch.qr() dtected, replace it with torch.linalg.qr()"}

{"number": 803, "change": "def model(x, is_train, reuse):\n# nt = Conv2d(nin, 16, (3, 3), (2, 2), act=tf.nn.relu, padding='SAME', name='tc1')\n# nt = Conv2d(nt, 8, (3, 3), (2, 2), act=tf.nn.relu, padding='SAME', name='tc2')\n## 2. Spatial transformer module (sampler)\n-        n = tl.layers.SpatialTransformer2dAffineLayer(nin, theta_layer=nt, out_size=[40, 40], name='spatial')\n+        n = tl.layers.SpatialTransformer2dAffineLayer(nin, theta_layer=nt, out_size=(40, 40), name='spatial')\ns = n\n## 3. Classifier\nn = tl.layers.Conv2d(\n", "fix_rule": "if out_size=[40, 40] is detected, replace it with out_size=(40, 40)"}

{"number": 804, "change": "class DeiTPreTrainedModel(PreTrainedModel):\ndef _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> None:\n\"\"\"Initialize the weights\"\"\"\nif isinstance(module, (nn.Linear, nn.Conv2d)):\n-            # Slightly different from the TF version which uses truncated_normal for initialization\n-            # cf https://github.com/pytorch/pytorch/pull/5617\n-            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n+            module.weight.data = nn.init.trunc_normal_(module.weight.data, mean=0.0, std=self.config.initializer_range)\nif module.bias is not None:\nmodule.bias.data.zero_()\nelif isinstance(module, nn.LayerNorm):\n", "fix_rule": "if isinstance(module.weight.data, nn.init.trunc_normal_):\n    replace it with module.weight.data = nn.init.trunc_normal_(module.weight.data, mean=0.0, std=self.config.initializer_range)"}

{"number": 808, "change": "class DisentangledSelfAttention(nn.Module):\ndim=-1,\nindex=p2c_pos.squeeze(0).expand([query_layer.size(0), key_layer.size(-2), key_layer.size(-2)]),\n).transpose(-1, -2)\n-            score += p2c_att / scale\n+            score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n\nreturn score\n", "fix_rule": "if torch.tensor(scale, dtpye=p2c_att.dtype) is not used, use it to ensure dtype consistency"}

{"number": 812, "change": "def evaluate(model, data_loader, device):\nimage = list(img.to(device) for img in image)\ntargets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\n-        torch.cuda.synchronize(device)\n+        # \u5f53\u4f7f\u7528CPU\u65f6\uff0c\u8df3\u8fc7GPU\u76f8\u5173\u6307\u4ee4\n+        if device != torch.device(\"cpu\"):\n+            torch.cuda.synchronize(device)\n+\nmodel_time = time.time()\noutputs = model(image)\n", "fix_rule": "If \"torch.cuda.synchronize(device)\" is detected, replace it with the following code:\n\n```python\n# \u5f53\u4f7f\u7528CPU\u65f6\uff0c\u8df3\u8fc7GPU\u76f8\u5173\u6307\u4ee4\nif device != torch.device(\"cpu\"):\n    torch.cuda.synchronize(device)\n```"}

{"number": 816, "change": "def dnn(tensor_in, hidden_units, activation=tf.nn.relu, keep_prob=None):\nfor i, n_units in enumerate(hidden_units):\nwith tf.variable_scope('layer%d' % i):\ntensor_in = linear(tensor_in, n_units, True)\n-            tensor_in = activation(tensor_in)\n-            if keep_prob:\n-                tensor_in = tf.nn.dropout(tensor_in, keep_prob)\n+                tensor_in = activation(tensor_in)\n+                if keep_prob:\n+                    tensor_in = skflow.ops.dropout(tensor_in, keep_prob)\nreturn tensor_in\n", "fix_rule": "if activation(tf.nn.<function_name>) detected, replace it with activation(skflow.ops.<function_name>)"}

{"number": 828, "change": "def main():\nif utils.is_primary(args):\n_logger.info('Using NVIDIA APEX AMP. Training in mixed precision.')\nelif use_amp == 'native':\n-        amp_autocast = partial(torch.autocast, device_type=device.type, dtype=amp_dtype)\n-        if device.type == 'cuda':\n+        try:\n+            amp_autocast = partial(torch.autocast, device_type=device.type, dtype=amp_dtype)\n+        except (AttributeError, TypeError):\n+            # fallback to CUDA only AMP for PyTorch < 1.10\n+            assert device.type == 'cuda'\n+            amp_autocast = torch.cuda.amp.autocast\n+        if device.type == 'cuda' and amp_dtype == torch.float16:\n+            # loss scaler only used for float16 (half) dtype, bfloat16 does not need it\nloss_scaler = NativeScaler()\nif utils.is_primary(args):\n_logger.info('Using native Torch AMP. Training in mixed precision.')\n", "fix_rule": "if utils.is_primary(args) and use_amp == 'native' and device.type == 'cuda' and amp_dtype == torch.float16, replace amp_autocast = partial(torch.autocast, device_type=device.type, dtype=amp_dtype) with:\n\ntry:\n    amp_autocast = partial(torch.autocast, device_type=device.type, dtype=amp_dtype)\nexcept (AttributeError, TypeError):\n    # fallback to CUDA only AMP for PyTorch < 1.10\n    assert device.type == 'cuda'\n    amp_autocast = torch.cuda.amp.autocast"}

{"number": 837, "change": "class Encoder(torch.nn.Module):\npos_enc_class(attention_dim, positional_dropout_rate),\n)\nelif input_layer is None:\n-            self.embed = pos_enc_class(attention_dim, positional_dropout_rate)\n+            self.embed = torch.nn.Sequential(\n+                pos_enc_class(attention_dim, positional_dropout_rate)\n+            )\nelse:\nraise ValueError(\"unknown input_layer: \" + input_layer)\nself.normalize_before = normalize_before\n", "fix_rule": "if pos_enc_class() is detected, replace it with torch.nn.Sequential(\n    pos_enc_class()\n)"}

{"number": 838, "change": "class ChineseCLIPVisionTransformer(nn.Module):\nembed_dim = config.hidden_size\n\nself.embeddings = ChineseCLIPVisionEmbeddings(config)\n-        self.pre_layrnorm = nn.LayerNorm(embed_dim)\n+        self.pre_layrnorm = nn.LayerNorm(embed_dim, eps=config.layer_norm_eps)\nself.encoder = ChineseCLIPVisionEncoder(config)\n-        self.post_layernorm = nn.LayerNorm(embed_dim)\n+        self.post_layernorm = nn.LayerNorm(embed_dim, eps=config.layer_norm_eps)\n\n@add_start_docstrings_to_model_forward(CHINESE_CLIP_VISION_INPUTS_DOCSTRING)\n@replace_return_docstrings(output_type=BaseModelOutputWithPooling, config_class=ChineseCLIPVisionConfig)\n", "fix_rule": "if `nn.LayerNorm(embed_dim)` is detected, replace it with `nn.LayerNorm(embed_dim, eps=config.layer_norm_eps)`"}

{"number": 840, "change": "class TestSolveCast:\n\nclass TestSolveWithMask:\ndef test_smoke(self, device, dtype):\n+        torch.manual_seed(0)  # issue kornia#2027\nA = torch.randn(2, 3, 1, 4, 4, device=device, dtype=dtype)\nB = torch.randn(2, 3, 1, 4, 6, device=device, dtype=dtype)\n", "fix_rule": "if torch.manual_seed() is detected, replace it with torch.manual_seed(0)"}

{"number": 847, "change": "def _add_gradients_summaries(grads_and_vars):\ngrad_values = grad.values\nelse:\ngrad_values = grad\n-      summaries.append(tf.histogram_summary(var.op.name + ':gradient',\n+      summaries.append(tf.summary.histogram(var.op.name + ':gradient',\ngrad_values))\n-      summaries.append(tf.histogram_summary(var.op.name + ':gradient_norm',\n+      summaries.append(tf.summary.histogram(var.op.name + ':gradient_norm',\ntf.global_norm([grad_values])))\nelse:\ntf.logging.info('Var %s has no gradient', var.op.name)\n", "fix_rule": "if  tf.histogram_summary() dtected, replace it with tf.summary.histogram()."}

{"number": 849, "change": "class QM9(InMemoryDataset):\nedge_type += 2 * [self.bonds[bond.GetBondType()]]\n\nedge_index = torch.tensor([row, col], dtype=torch.long)\n-            edge_type = torch.tensor(edge_type)\n-            edge_attr = F.one_hot(torch.tensor(edge_type),\n+            edge_type = torch.tensor(edge_type, dtype=torch.long)\n+            edge_attr = F.one_hot(edge_type,\nnum_classes=len(self.bonds)).to(torch.float)\n\nperm = (edge_index[0] * N + edge_index[1]).argsort()\n", "fix_rule": "if \"torh.tensor\" detected with \"dtype=torch.long\", replace it with \"torch.tensor(dtype=torch.long)\".\nif \"F.one_hot\" detected with \"torch.tensor\", replace it with \"F.one_hot(torch.tensor, dtype=torch.float)\"."}

{"number": 854, "change": "class MinSaver(Callback):\nnewname = os.path.join(logger.LOG_DIR,\nself.filename or\n('max-' + self.monitor_stat if self.reverse else 'min-' + self.monitor_stat))\n-        files_to_copy = glob.glob(path + '*')\n+        files_to_copy = tf.gfile.Glob(path + '*')\nfor file_to_copy in files_to_copy:\n-            shutil.copy(file_to_copy, file_to_copy.replace(path, newname))\n+            tf.gfile.Copy(file_to_copy, file_to_copy.replace(path, newname), overwrite=True)\nlogger.info(\"Model with {} '{}' saved.\".format(\n'maximum' if self.reverse else 'minimum', self.monitor_stat))\n", "fix_rule": "if glob.glob() detected, replace it with tf.gfile.Glob()\nif shutil.copy() detected, replace it with tf.gfile.Copy() with overwrite=True"}

{"number": 855, "change": "class Evaluator(object):\nThe mean average result per tensor over the entire dataset.\n\n\"\"\"\n+        tflearn.is_training(False, self.session)\ncoord = tf.train.Coordinator()\ninputs = tf.get_collection(tf.GraphKeys.INPUTS)\n# Data Preprocessing\n", "fix_rule": "if tflearn.is_training() detected, replace it with tflearn.is_training(False, self.session)"}

{"number": 857, "change": "class Lamb(Optimizer):\nglobal_grad_norm.add_(grad.pow(2).sum())\n\nglobal_grad_norm = torch.sqrt(global_grad_norm)\n-        max_grad_norm = self.defaults['max_grad_norm']\n+        # FIXME it'd be nice to remove explicit tensor conversion of scalars when torch.where promotes\n+        # scalar types properly https://github.com/pytorch/pytorch/issues/9190\n+        max_grad_norm = torch.tensor(self.defaults['max_grad_norm'], device=device)\nclip_global_grad_norm = torch.where(\nglobal_grad_norm > max_grad_norm,\nglobal_grad_norm / max_grad_norm,\n", "fix_rule": "if  torch.tensor(self.defaults['max_grad_norm'], device=device) dtected, replace it with torch.tensor(self.defaults['max_grad_norm'], device=device).to(device)"}

{"number": 860, "change": "class ModelCatalogTest(unittest.TestCase):\ndef testCustomModel(self):\nray.init()\nModelCatalog.register_custom_model(\"foo\", CustomModel)\n-        p1 = ModelCatalog.get_model(1, 5, {\"custom_model\": \"foo\"})\n+        p1 = ModelCatalog.get_model(\n+            tf.constant([1, 2, 3]), 5, {\"custom_model\": \"foo\"})\nself.assertEqual(str(type(p1)), str(CustomModel))\n", "fix_rule": "if ModelCatalog.get_model( detected, replace it with ModelCatalog.get_model(\n     tf.constant([1, 2, 3]), 5, {\"custom_model\": \"foo\"})"}

{"number": 862, "change": "class _netD(nn.Module):\n\ndef forward(self, input):\ngpu_ids = None\n-        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n+        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > =1:\ngpu_ids = range(self.ngpu)\noutput = nn.parallel.data_parallel(self.main, input, gpu_ids)\nreturn output.view(-1, 1)\n", "fix_rule": "if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu >= 1:, replace it with if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu >= 1:"}

{"number": 865, "change": "from tests import utils\ndef test_image_classifier(tmp_path):\ntrain_x = utils.generate_data(num_instances=320, shape=(32, 32, 3))\ntrain_y = utils.generate_one_hot_labels(num_instances=320, num_classes=10)\n-    clf = ak.ImageClassifier(directory=tmp_path, max_trials=2, seed=utils.SEED)\n+    clf = ak.ImageClassifier(\n+        directory=tmp_path,\n+        max_trials=2,\n+        seed=utils.SEED,\n+        distribution_strategy=tf.distribute.MirroredStrategy(),\n+    )\nclf.fit(train_x, train_y, epochs=1, validation_split=0.2)\nkeras_model = clf.export_model()\nclf.evaluate(train_x, train_y)\n", "fix_rule": "If `tf.distribute.MirroredStrategy()` is detected, replace it with `distribution_strategy=tf.distribute.MirroredStrategy()`."}

{"number": 867, "change": "def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\noutput_shape[3],\noutput_shape[1])\nif output_shape[0] is None:\n-        output_shape = (tf.shape(x)[0],) + tuple(output_shape[1:])\n-        output_shape = tf.stack(list(output_shape))\n+        output_shape = (shape(x)[0],) + tuple(output_shape[1:])\n+\n+    output_shape = tf.stack(list(output_shape))\n\npadding = _preprocess_padding(padding)\nif tf_data_format == 'NHWC':\n", "fix_rule": "if `shape(x)[0]` is detected, replace it with `tf.shape(x)[0]`"}

{"number": 868, "change": "class TestRasterizeMeshes(TestCaseMixin, unittest.TestCase):\n], dtype=torch.int64, device=device)\n# fmt: on\n\n-        pix_to_face_padded = -torch.ones_like(pix_to_face_frontface)\n+        pix_to_face_padded = -(torch.ones_like(pix_to_face_frontface))\n# Run with and without culling\n# Without culling, for k=0, the front face (i.e. face 2) is\n# rasterized and for k=1, the back face (i.e. face 3) is\n", "fix_rule": "if  -torch.ones_like() dtected, replace it with -(torch.ones_like())."}

{"number": 875, "change": "class SparkKerasTests(tf.test.TestCase):\n\ndef test_fit_model_multiclass(self):\nmodel = create_mnist_model()\n-        if version.parse(tf.keras.__version__) < version.parse(\"2.11\"):\n+        if version.parse(tf.keras.__version__.replace(\"-tf\", \"+tf\")) < version.parse(\"2.11\"):\noptimizer = tf.keras.optimizers.Adadelta(1.0)\nelse:\noptimizer = tf.keras.optimizers.legacy.Adadelta(1.0)\n", "fix_rule": "if version.parse(tf.keras.__version__) dtected, replace it with version.parse(tf.keras.__version__.replace(\"-tf\", \"+tf\"))"}

{"number": 878, "change": "def train(args):\ndtype = torch.float32\nmodel = model_class(args.n_vocab, args).to(dtype=dtype)\nif args.ngpu > 0:\n-        model.to(\"cuda:0\")\n+        model.to(\"cuda\")\ngpu_id = list(range(args.ngpu))\nelse:\ngpu_id = [-1]\n", "fix_rule": "if model.to(\"cuda:0\") detected, replace it with model.to(\"cuda\")"}

{"number": 883, "change": "def triangular_solve(x, y, upper=False, transpose=False):\n\n\ndef precision_to_scale_tril(P):\n-    Lf = torch.cholesky(torch.flip(P, (-2, -1)))\n+    Lf = torch.linalg.cholesky(torch.flip(P, (-2, -1)))\nL_inv = torch.transpose(torch.flip(Lf, (-2, -1)), -2, -1)\nL = torch.triangular_solve(torch.eye(P.shape[-1], dtype=P.dtype, device=P.device),\nL_inv, upper=False)[0]\n", "fix_rule": "if torch.cholesky() detected, replace it with torch.linalg.cholesky()\nif torch.triangular_solve() detected, replace it with torch.triangular_solve(torch.eye(P.shape[-1], dtype=P.dtype, device=P.device), L_inv, upper=False)[0]"}

{"number": 884, "change": "class NaturalGradient(Optimizer):\napplied = self.apply_step(variables=variables, diffs=estimated_diffs)\n\nwith tf.control_dependencies(control_inputs=(applied,)):\n-                return [tf.identity(input=estimated_diff) for estimated_diff in estimated_diffs]\n+                return [estimated_diff + 0.0 for estimated_diff in estimated_diffs]\n\ndef false_fn():\nreturn [tf.zeros_like(tensor=diff) for diff in diffs]\n", "fix_rule": "\"\"\"\nif tf.identity(input=estimated_diff) detected, replace it with estimated_diff + 0.0\nif tf.zeros_like(tensor=diff) detected, replace it with tf.zeros_like(tensor=diff) for diff in diffs\n\"\"\""}

{"number": 886, "change": "def argsort(\nret = tf.argsort(\ntf.convert_to_tensor(x), axis=axis, direction=\"ASCENDING\", stable=stable\n)\n-    return ret\n+    return tf.cast(ret, dtype=tf.int64)\n\n\ndef sort(\n", "fix_rule": "\"\"\"\nIf tf.convert_to_tensor(x) detected, replace it with tf.cast(tf.argsort(tf.convert_to_tensor(x), axis=axis, direction=\"ASCENDING\", stable=stable), dtype=tf.int64).\n\"\"\""}

{"number": 887, "change": "def _to_ivy(x: Any) -> Any:\n\n\ndef _to_ivy_array(x: Any) -> ivy.Array:\n-    if isinstance(x, (torch.Tensor, tf.Tensor, jnp.numpy.DeviceArray, numpy.ndarray)):\n+    if isinstance(x, (torch.Tensor, tf.Tensor, jnp.DeviceArray, numpy.ndarray)):\nreturn ivy.array(numpy.array(x))\nreturn x\n", "fix_rule": "if isinstance(x, (torch.Tensor, tf.Tensor, jnp.numpy.DeviceArray, numpy.ndarray)) is detected, replace it with if isinstance(x, (torch.Tensor, tf.Tensor, jnp.DeviceArray, numpy.ndarray))"}

{"number": 888, "change": "def vecdot(\nout: Optional[Union[tf.Tensor, tf.Variable]] = None,\n) -> Union[tf.Tensor, tf.Variable]:\ndtype = ivy.as_native_dtype(ivy.promote_types(x1.dtype, x2.dtype))\n-    x1, x2 = tf.cast(x1, tf.float32), tf.cast(x2, tf.float32)\n+    if dtype != \"float64\":\n+        x1, x2 = tf.cast(x1, tf.float32), tf.cast(x2, tf.float32)\nret = tf.cast(tf.tensordot(x1, x2, axes=(axis, axis)), dtype)\nreturn ret\n", "fix_rule": "if  dtype != \"float64\" dtected, replace it with x1, x2 = tf.cast(x1, tf.float32), tf.cast(x2, tf.float32)"}

{"number": 902, "change": "class PipelineEngine(DeepSpeedEngine):\nmem_cached = new_cached\nmem_alloced = new_alloced\n\n-        max_alloced = torch.cuda.max_memory_allocated()\n-        max_cached = torch.cuda.max_memory_cached()\n+        max_alloced = get_accelerator().max_memory_allocated()\n+        max_cached = get_accelerator().max_memory_cached()\n\n# convert to GB for printing\nnew_alloced /= 1024**3\n", "fix_rule": "if torch.cuda.max_memory_allocated() or torch.cuda.max_memory_cached() is detected, replace it with get_accelerator().max_memory_allocated() or get_accelerator().max_memory_cached()"}

{"number": 903, "change": "def torch_multinomial(input, num_samples, replacement=False):\nDoes not support keyword argument `out`.\n\"\"\"\nif input.is_cuda:\n-        return torch_multinomial(input.cpu(), num_samples, replacement).cuda()\n+        return torch.multinomial(input.cpu(), num_samples, replacement).cuda(input.get_device())\nelse:\nreturn torch.multinomial(input, num_samples, replacement)\n", "fix_rule": "if `input.is_cuda` is detected, replace `torch_multinomial(input.cpu(), num_samples, replacement).cuda()` with `torch.multinomial(input.cpu(), num_samples, replacement).cuda(input.get_device())`."}

{"number": 904, "change": "def test_delete_entire_dataset(domain_owner, cleanup_storage):\nassert domain_owner.datasets[0].name == \"Dataset_1\"\nassert domain_owner.datasets[1].name == \"Dataset_2\"\n\n-    domain_owner.datasets.delete(dataset_id=domain_owner.datasets[0].id)\n+    domain_owner.datasets.delete(\n+        dataset_id=domain_owner.datasets[0].id, skip_checks=True\n+    )\n\n# Check if the number of available datasets has been decreased\nassert len(domain_owner.datasets) == 1\n", "fix_rule": "if domain_owner.datasets.delete() detected, replace it with domain_owner.datasets.delete(skip_checks=True)"}

{"number": 908, "change": "def pack(\ntry:\nimport torch\n\n-        meta_objs.update(torch=torch.__version__)\n+        meta_objs.update(torch=str(torch.__version__))\nexcept ImportError:\npass\ntry:\n", "fix_rule": "if `torch.__version__` is detected, replace it with `str(torch.__version__)`"}

{"number": 910, "change": "class Schedule(metaclass=ABCMeta):\nraise NotImplementedError\n\ndef value(self, t):\n-        if self.framework == \"tf\" and tf.executing_eagerly() is False:\n+        if self.framework == \"tf\":\nreturn tf.cast(\n-                tf.py_func(self._value, [t], tf.float64),\n+                tf.py_function(self._value, [t], tf.float64),\ntf.float32,\n-                name=\"schedule-value\")\n+                name=\"schedule_value\")\nreturn self._value(t)\n\ndef __call__(self, t):\n", "fix_rule": "if tf.executing_eagerly() is False detected, replace it with if self.framework == \"tf\":\nif tf.py_func detected, replace it with tf.py_function\nchange tf.float64 to tf.float32\nchange name=\"schedule-value\" to name=\"schedule_value\""}

{"number": 912, "change": "class FeedForwardTransformer(TTSInterface, torch.nn.Module):\n\n# concat speaker embedding\nif self.spk_embed_dim is not None:\n-            spembs = torch.nn.functional.normalize(spembs).unsqueeze(1).expand(-1, hs.size(1), -1)\n-            hs = self.projection(torch.cat([hs, spembs], dim=-1))\n+            spembs_ = F.normalize(spembs).unsqueeze(1).expand(-1, hs.size(1), -1)\n+            hs = self.projection(torch.cat([hs, spembs_], dim=-1))\n\n# forward duration predictor and length regulator\nd_masks = make_pad_mask(ilens).to(xs.device)\n", "fix_rule": "\"\"\"\nReplace `torch.nn.functional.normalize(spembs).unsqueeze(1).expand(-1, hs.size(1), -1)` with `F.normalize(spembs).unsqueeze(1).expand(-1, hs.size(1), -1)`\n\nReplace `torch.cat([hs, spembs], dim=-1)` with `torch.cat([hs, spembs_], dim=-1)`\n\"\"\""}

{"number": 919, "change": "def image_histogram2d(\nhist = hist.squeeze()\nelif image.dim() == 3:\nhist = hist.squeeze(0)\n-    return hist, torch.zeros_like(hist, dtype=hist.dtype, device=device)\n+    return hist, torch.zeros_like(hist, dtype=hist.dtype, device=hist.device)\n", "fix_rule": "if `torch.zeros_like(hist, dtype=hist.dtype, device=device)` is detected, replace it with `torch.zeros_like(hist, dtype=hist.dtype, device=hist.device)`"}

{"number": 920, "change": "class FeedForwardEncoder(Seq2SeqEncoder):\nreturn self._feedforward(inputs)\nelse:\noutputs = self._feedforward(inputs)\n-            return outputs * mask.unsqueeze(dim=-1).float()\n+            return outputs * mask.unsqueeze(dim=-1)\n", "fix_rule": "if mask.unsqueeze(dim=-1) is detected, replace it with mask.unsqueeze(dim=-1).float()"}

{"number": 929, "change": "def rand_like_with_shape(shape, ori_t):\nhigher_bound = torch.max(ori_t)\n\nif dtype in [torch.uint8, torch.int16, torch.short, torch.int16, torch.long, torch.bool]:\n-        return torch.randint(lower_bound, higher_bound+1, shape, dtype=dtype, device=device)\n+        return torch.randint(lower_bound.long(), higher_bound.long() + 1, shape, dtype=dtype, device=device)\nelse:\nreturn torch.rand(shape, dtype=dtype, device=device, requires_grad=require_grad)\n", "fix_rule": "if  dtype in [torch.uint8, torch.int16, torch.short, torch.int16, torch.long, torch.bool] dtected, replace it with dtype in [torch.uint8, torch.int16, torch.short, torch.int16, torch.long, torch.bool].long()"}

{"number": 930, "change": "def map_data_vector_model(subsample_size):\npyro.sample(\"x\", dist.normal, mu[batch], sigma[batch])\nreturn batch\n\n-    ind = Variable(torch.LongTensor(range(20)))\n+    LongTensor = torch.cuda.LongTensor if torch.Tensor.is_cuda else torch.LongTensor\n+    ind = Variable(LongTensor(range(20)))\nbatch = pyro.map_data('mapdata', ind, local_model, batch_size=subsample_size)\nreturn list(batch.data)\n", "fix_rule": "if torch.LongTensor.is_cuda detected, replace it with torch.cuda.LongTensor. Otherwise, replace it with torch.LongTensor."}

{"number": 933, "change": "class SelfAttnFunc(torch.autograd.Function):\nvalues_grads   = torch.bmm(dropout_results.transpose(1,2), output_lin_grads, out=values_grads.transpose(0,1))\n\n# Mask and Scaling for Dropout (not a publically documented op)\n-        dropout_grads = torch._masked_scale(matmul2_dgrad1, dropout_mask, dropout_prob_t[0])\n+        dropout_grads = torch._masked_scale(matmul2_dgrad1, dropout_mask, 1.0/(1.0-dropout_prob_t[0]))\n\n# Softmax Grad (not a publically documented op)\nsoftmax_grads = torch._softmax_backward_data(dropout_grads, softmax_results, -1, softmax_results)\n", "fix_rule": "\"\"\"\nIf torch._masked_scale() is detected, replace it with torch._masked_scale(matmul2_dgrad1, dropout_mask, 1.0/(1.0-dropout_prob_t[0]))\n\"\"\""}

{"number": 935, "change": "class AutoShape(nn.Module):\n#   multiple:        = [Image.open('image1.jpg'), Image.open('image2.jpg'), ...]  # list of images\n\nt = [time_sync()]\n-        p = next(self.model.parameters()) if self.pt else torch.zeros(1)  # for device and type\n+        p = next(self.model.parameters()) if self.pt else torch.zeros(1, device=self.model.device)  # for device, type\nautocast = self.amp and (p.device.type != 'cpu')  # Automatic Mixed Precision (AMP) inference\nif isinstance(imgs, torch.Tensor):  # torch\nwith amp.autocast(autocast):\n", "fix_rule": "if torch.zeros() is detected, replace it with torch.zeros(1, device=self.model.device)"}

{"number": 936, "change": "class CycleDiffusionPipeline(DiffusionPipeline):\n\ndevice = torch.device(f\"cuda:{gpu_id}\")\n\n-        for cpu_offloaded_model in [self.unet, self.text_encoder, self.vae, self.safety_checker]:\n+        for cpu_offloaded_model in [self.unet, self.text_encoder, self.vae]:\nif cpu_offloaded_model is not None:\ncpu_offload(cpu_offloaded_model, device)\n\n+        if self.safety_checker is not None:\n+            # TODO(Patrick) - there is currently a bug with cpu offload of nn.Parameter in accelerate\n+            # fix by only offloading self.safety_checker for now\n+            cpu_offload(self.safety_checker.vision_model)\n+\n@property\n# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline._execution_device\ndef _execution_device(self):\n", "fix_rule": "\"\"\"\n-        for cpu_offloaded_model in [self.unet, self.text_encoder, self.vae, self.safety_checker]:\n+        for cpu_offloaded_model in [self.unet, self.text_encoder, self.vae]:\nif cpu_offloaded_model is not None:\ncpu_offload(cpu_offloaded_model, device)\n\n+        if self.safety_checker is not None:\n+            # TODO(Patrick) - there is currently a bug with cpu offload of nn.Parameter in accelerate\n+            # fix by only offloading self.safety_checker for now\n+            cpu_offload(self.safety_checker.vision_model)\n\"\"\"\n\nfix_pattern:\n\"\"\"\nif self.safety_checker is not None:\n+            # TODO(Patrick) - there is currently a bug with cpu offload of nn.Parameter in accelerate\n+            # fix by only offloading self.safety_checker for now\n+            cpu_offload(self.safety_checker.vision_model)\n-        for cpu_offloaded_model in [self.unet, self.text_encoder, self.vae, self.safety_checker]:\n+        for cpu_offloaded_model in [self.unet, self.text_encoder, self.vae]:\nif cpu_offloaded_model is not None:\ncpu_offload(cpu_offloaded_model, device)\n\"\"\""}

{"number": 937, "change": "def shift_tokens_right(input_ids: tf.Tensor, pad_token_id: int, decoder_start_to\n\nif tf.executing_eagerly():\n# \"Verify that `labels` has only positive values and -100\"\n-        assert_gte0 = tf.debugging.assert_greater_equal(shifted_input_ids, tf.constant(0))\n+        assert_gte0 = tf.debugging.assert_greater_equal(shifted_input_ids, tf.constant(0, dtype=input_ids.dtype))\n\n# Make sure the assertion op is called by wrapping the result in an identity no-op\nwith tf.control_dependencies([assert_gte0]):\n", "fix_rule": "If `tf.constant(0)` is detected, replace it with `tf.constant(0, dtype=input_ids.dtype)`"}

{"number": 940, "change": "def arange(start, stop=None, step=1, dtype=None, dev=None):\nif dtype in [torch.int8, torch.uint8, torch.int16]:\nreturn torch.arange(start, stop, step=step, dtype=torch.int64, device=dev).to(dtype)\nelse:\n-            return torch.range(start, stop, step=step, dtype=dtype, device=dev)\n+            return torch.arange(start, stop, step=step, dtype=dtype, device=dev)\n", "fix_rule": "if  torch.range() detected, replace it with torch.arange()"}

{"number": 944, "change": "def _apply_affine(input: torch.Tensor,\n\nheight, width = x_data.shape[-2:]\ntransform: torch.Tensor = params['transform'].to(device, dtype)\n-\n-    out_data: torch.Tensor = warp_perspective(x_data, transform, (height, width))\n+    out_data: torch.Tensor = warp_affine(x_data, transform[:, :2, :], (height, width))\n\nif return_transform:\nreturn out_data.view_as(input), transform\n", "fix_rule": "if warp_perspective() detected, replace it with warp_affine()."}

{"number": 946, "change": "class GPTNeoAttentionMixin:\nelse:\nraise ValueError(f\"Input tensor rank should be one of [2, 3], but is: {len(tensor.shape)}\")\n\n-        padded_tensor = F.pad(tensor, padding_side, value=pad_value)\n+        padded_tensor = nn.functional.pad(tensor, padding_side, value=pad_value)\npadded_tensor = padded_tensor.unfold(dimension=1, size=window_size + block_length, step=block_length)\n\nif is_key_value:\n", "fix_rule": "If `F.pad()` is detected, replace it with `nn.functional.pad()`."}

{"number": 953, "change": "def test_tagged_corpus_downsample():\n\nassert 10 == len(corpus.train)\n\n-    corpus.downsample(percentage=0.3, only_downsample_train=True)\n+    corpus.downsample(percentage=0.3, downsample_dev=False, downsample_test=False)\n\nassert 3 == len(corpus.train)\n", "fix_rule": "If `corpus.downsample()` is called with `only_downsample_train=True`, replace it with `downsample_dev=False, downsample_test=False`."}

{"number": 962, "change": "class DecisionTransformerGPT2Attention(nn.Module):\n# Need to be a tensor, otherwise we get error: `RuntimeError: expected scalar type float but found double`.\n# Need to be on the same device, otherwise `RuntimeError: ..., x and y to be on the same device`\nmask_value = torch.full([], mask_value, dtype=attn_weights.dtype).to(attn_weights.device)\n-            attn_weights = torch.where(causal_mask, attn_weights, mask_value)\n+            attn_weights = torch.where(causal_mask, attn_weights.to(attn_weights.dtype), mask_value)\n\nif attention_mask is not None:\n# Apply the attention mask\n", "fix_rule": "if torch.where(dtected, replace it with torch.where().to(attn_weights.dtype)"}

{"number": 963, "change": "def load_tf_graph(graph_file):\n\"\"\"\n# We load the protobuf file from the disk and parse it to retrieve the\n# unserialized graph_def\n-    with tf.gfile.GFile(graph_file, \"rb\") as f:\n-        graph_def = tf.GraphDef()\n+    with tf.io.gfile.GFile(graph_file, \"rb\") as f:\n+        graph_def = tf.compat.v1.GraphDef()\ngraph_def.ParseFromString(f.read())\n\n# Then, we import the graph_def into a new Graph and returns it\n", "fix_rule": "if tf.gfile.GFile(dtected, replace it with tf.io.gfile.GFile().\nif tf.GraphDef() dtected, replace it with tf.compat.v1.GraphDef()."}

{"number": 967, "change": "class TestScalarMix(AllenNlpTestCase):\ntensors = [torch.randn([3, 4, 5]) for _ in range(3)]\nnumpy_mask = numpy.ones((3, 4), dtype=\"int32\")\nnumpy_mask[1, 2:] = 0\n-        mask = torch.from_numpy(numpy_mask)\n+        mask = torch.from_numpy(numpy_mask).bool()\n\nweights = [0.1, 0.2, 0.3]\nfor k in range(3):\n", "fix_rule": "if  torch.from_numpy().bool() detected, replace it with torch.from_numpy().bool().to(device)"}

{"number": 969, "change": "class SequenceFeatureExtractionTestMixin(FeatureExtractionSavingTestMixin):\ninput_np = feat_extract.pad(processed_features, padding=\"longest\", return_tensors=\"np\")[input_name]\ninput_tf = feat_extract.pad(processed_features, padding=\"longest\", return_tensors=\"tf\")[input_name]\n\n-        self.assertTrue(abs(input_np.sum() - input_tf.numpy().sum()) < 1e-2)\n+        self.assertTrue(abs(input_np.astype(np.float32).sum() - input_tf.numpy().sum()) < 1e-2)\n\ndef test_attention_mask(self):\nfeat_dict = self.feat_extract_dict\n", "fix_rule": "if abs(input_np.astype(np.float32).sum() - input_tf.numpy().sum()) < 1e-2 dtected, replace it with abs(input_np.sum() - input_tf.numpy().sum()) < 1e-2"}

{"number": 971, "change": "class ScoreSdeVeScheduler(SchedulerMixin, ConfigMixin):\n\"\"\"\nsampling_eps = sampling_eps if sampling_eps is not None else self.config.sampling_eps\n\n-        self.timesteps = torch.linspace(1, sampling_eps, num_inference_steps)\n+        self.timesteps = torch.linspace(1, sampling_eps, num_inference_steps, device=device)\n\ndef set_sigmas(\nself, num_inference_steps: int, sigma_min: float = None, sigma_max: float = None, sampling_eps: float = None\n", "fix_rule": "if  torch.linspace() dtected, replace it with torch.linspace().to(device)"}

{"number": 972, "change": "class SSIM(nn.Module):\nssim_map = ((2 * mu1_mu2 + self.C1) * (2 * sigma12 + self.C2)) / \\\n((mu1_sq + mu2_sq + self.C1) * (sigma1_sq + sigma2_sq + self.C2))\n\n-        loss = torch.clamp(1. - ssim_map, min=0, max=1) / 2.\n+        loss = torch.clamp(torch.tensor(1.) - ssim_map, min=0, max=1) / 2.\n\nif self.reduction == 'mean':\nloss = torch.mean(loss)\n", "fix_rule": "if \"torch.tensor(1.)\" detected, replace it with \"torch.tensor(1.0)\""}

{"number": 974, "change": "def rpn_losses(anchor_labels, anchor_boxes, label_logits, box_logits):\nplaceholder = 1.\nlabel_loss = tf.nn.sigmoid_cross_entropy_with_logits(\nlabels=tf.to_float(valid_anchor_labels), logits=valid_label_logits)\n-    label_loss = label_loss * (1. / config.RPN_BATCH_PER_IM)\n+    label_loss = tf.reduce_sum(label_loss) * (1. / config.RPN_BATCH_PER_IM)\nlabel_loss = tf.where(tf.equal(nr_valid, 0), placeholder, label_loss, name='label_loss')\n\npos_anchor_boxes = tf.boolean_mask(anchor_boxes, pos_mask)\n", "fix_rule": "if \"tf.reduce_sum(label_loss)\" is detected, replace it with \"tf.reduce_mean(label_loss)\""}

{"number": 976, "change": "from allennlp.common.testing import AllenNlpTestCase\n\nclass TestElmoLstmCell(AllenNlpTestCase):\ndef test_elmo_lstm(self):\n-        input_tensor = Variable(torch.rand(4, 5, 3))\n+        input_tensor = torch.rand(4, 5, 3)\ninput_tensor[1, 4:, :] = 0.\ninput_tensor[2, 2:, :] = 0.\ninput_tensor[3, 1:, :] = 0.\n-        mask = Variable(torch.ones([4, 5]))\n+        mask = torch.ones([4, 5])\nmask[1, 4:] = 0.\nmask[2, 2:] = 0.\nmask[3, 1:] = 0.\n", "fix_rule": "if Variable(torch.rand()) is detected, replace it with torch.rand()"}

{"number": 977, "change": "class TpuStrategyTest(tf.test.TestCase):\nserving_fn = create_serving_signature(model)\n\nsaved_model_dir = tempfile.mkdtemp(dir=self.get_temp_dir())\n-      tf.saved_model.save(\n-          model, saved_model_dir, signatures={\"serving_default\": serving_fn})\n+      model.save(saved_model_dir, save_format=\"tf\",\n+                 signatures={\"serving_default\": serving_fn})\n\n# Test the saved_model.\nloaded_serving_fn = tf.keras.models.load_model(\n", "fix_rule": "if tf.saved_model.save() is detected, replace it with model.save()."}

{"number": 984, "change": "def _preprocess_conv3d_input(x, data_format):\n# Returns\nA tensor.\n\"\"\"\n-    if dtype(x) == 'float64':\n+    # tensorflow doesn't support float64 for conv layer before 1.8.0\n+    if (dtype(x) == 'float64'\n+            and StrictVersion(tf.__version__) < StrictVersion('1.8.0')):\nx = tf.cast(x, 'float32')\ntf_data_format = 'NDHWC'\nif data_format == 'channels_first':\n", "fix_rule": "if tf.__version__ < StrictVersion('1.8.0') and dtype(x) == 'float64', replace it with x = tf.cast(x, 'float32')"}

{"number": 988, "change": "def main(args):\naccelerator.clip_grad_norm_(params_to_clip, args.max_grad_norm)\noptimizer.step()\nlr_scheduler.step()\n-                optimizer.zero_grad()\n+                optimizer.zero_grad(set_to_none=args.set_grads_to_none)\n\n# Checks if the accelerator has performed an optimization step behind the scenes\nif accelerator.sync_gradients:\n", "fix_rule": "\"Add the line 'optimizer.zero_grad(set_to_none=args.set_grads_to_none)' after 'optimizer.zero_grad()'.\""}

{"number": 989, "change": "class Tagger(nn.Module):\n# criterion\nself.crit = nn.CrossEntropyLoss(ignore_index=0) # ignore padding\n\n-        self.drop = Dropout(args['dropout'])\n+        self.drop = nn.Dropout(args['dropout'])\nself.worddrop = WordDropout(args['word_dropout'])\n\ndef forward(self, word, word_mask, wordchars, wordchars_mask, upos, xpos, ufeats, pretrained, word_orig_idx, sentlens, wordlens):\n", "fix_rule": "\"\"\"\nIf Dropout is detected, replace it with nn.Dropout.\n\"\"\""}

{"number": 990, "change": "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\ndef train():\nmodel.train()\noptimizer.zero_grad()\n-    pos_z, neg_z, summary = model(data.x, data.edge_index, data.edge_attr)\n-    loss = model.loss(pos_z, neg_z, summary)\n+    y = model(data.x, data.edge_index, data.edge_attr)\n+    loss = torch.sum(y) #TODO: actual loss function\nloss.backward()\noptimizer.step()\nreturn loss.item()\n", "fix_rule": "if  model() dtected, replace it with model().to(device)\nif  torch.sum() dtected, replace it with torch.sum().to(device)\n"}

{"number": 991, "change": "def build_linear_positions(index_dims, output_range=(-1.0, 1.0)):\nreturn torch.linspace(start=output_range[0], end=output_range[1], steps=n_xels_per_dim, dtype=torch.float32)\n\ndim_ranges = [_linspace(n_xels_per_dim) for n_xels_per_dim in index_dims]\n-    array_index_grid = torch.meshgrid(*dim_ranges)\n+    array_index_grid = meshgrid(*dim_ranges, indexing=\"ij\")\n\nreturn torch.stack(array_index_grid, dim=-1)\n", "fix_rule": "if torch.meshgrid() is detected, replace it with meshgrid(*dim_ranges, indexing=\"ij\")"}

{"number": 1007, "change": "class GPT2Attention(nn.Module):\n# Apply the attention mask\nattn_weights = attn_weights + attention_mask\n\n-        attn_weights = nn.Softmax(dim=-1)(attn_weights)\n+        attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n\n# Downcast (if necessary) back to V's dtype (if in mixed-precision) -- No-Op if otherwise\nif attn_weights.dtype != torch.float32:\n", "fix_rule": "if nn.Softmax(dim=-1)(attn_weights) detected, replace it with nn.functional.softmax(attn_weights, dim=-1)"}

{"number": 1008, "change": "class BidirectionalEndpointSpanExtractor(SpanExtractor):\nsequence_lengths = util.get_lengths_from_binary_sequence_mask(sequence_mask)\nelse:\n# shape (batch_size), filled with the sequence length size of the sequence_tensor.\n-            sequence_lengths = util.ones_like(sequence_tensor[:, 0, 0]).long() * sequence_tensor.size(1)\n+            sequence_lengths = (torch.ones_like(sequence_tensor[:, 0, 0], dtype=torch.long) *\n+                                sequence_tensor.size(1))\n\n# shape (batch_size, num_spans, 1)\nend_sentinel_mask = (exclusive_span_ends == sequence_lengths.unsqueeze(-1)).long().unsqueeze(-1)\n", "fix_rule": "if util.ones_like() detected, replace it with (torch.ones_like(sequence_tensor[:, 0, 0], dtype=torch.long) * sequence_tensor.size(1))"}

{"number": 1016, "change": "class LanguageModel(nn.Module):\n\nfor i in range(number_of_characters):\n\n-                if torch.cuda.is_available():\n-                    input = input.cuda()\n+                input = input.to(flair.device)\n\n# get predicted weights\nprediction, _, hidden = self.forward(input, hidden)\n", "fix_rule": "if torch.cuda.is_available() is detected, replace it with input = input.to(flair.device)"}

{"number": 1030, "change": "def Conv2DTranspose(\nif get_tf_version_tuple() <= (1, 12):\nkernel_initializer = tf.contrib.layers.variance_scaling_initializer(2.0),\nelse:\n-            kernel_initializer = tf.keras.initializers.VarianceScaling(2.0)\n+            kernel_initializer = tf.keras.initializers.VarianceScaling(2.0, distribution='untruncated_normal')\n\nwith rename_get_variable({'kernel': 'W', 'bias': 'b'}):\nlayer = tf.layers.Conv2DTranspose(\n", "fix_rule": "if tf.keras.initializers.VarianceScaling() is detected, replace it with tf.keras.initializers.VarianceScaling(2.0, distribution='untruncated_normal')"}

{"number": 1033, "change": "def make_batches(lines, args, task, max_positions, encode_fn):\n).long()\nfor src_str in lines\n]\n-    lengths = torch.LongTensor([t.numel() for t in tokens])\n+    lengths = [t.numel() for t in tokens]\nitr = task.get_batch_iterator(\ndataset=task.build_dataset_for_inference(tokens, lengths),\nmax_tokens=args.max_tokens,\n", "fix_rule": "if torch.LongTensor() detected, replace it with [t.numel() for t in tokens]"}

{"number": 1034, "change": "class EarlyStopping(Callback):\n\nif trainer.use_tpu:\nstop = torch.tensor(int(trainer.should_stop), device=pl_module.device, dtype=torch.int32)\n-            stop = xm.mesh_reduce(\"stop_signal\", stop, torch.cat)\n+            stop = xm.mesh_reduce(\"stop_signal\", stop, sum)\ntorch_xla.core.xla_model.rendezvous(\"pl.EarlyStoppingCallback.stop_distributed_training_check\")\ntrainer.should_stop = int(stop.item()) == trainer.world_size\n", "fix_rule": "If a code change is detected where `torch.cat` is used, replace it with `sum`."}

{"number": 1035, "change": "class Entropy(Metric):\nmask : `torch.Tensor`, optional (default = None).\nA masking tensor of shape (batch_size, ...).\n\"\"\"\n-        logits, mask = self.unwrap_to_tensors(logits, mask)\n+        logits, mask = self.detach_tensors(logits, mask)\n\nif mask is None:\n-            mask = torch.ones(logits.size()[:-1])\n+            mask = torch.ones(logits.size()[:-1], device=logits.device)\n\nlog_probs = torch.nn.functional.log_softmax(logits, dim=-1)\nprobabilities = torch.exp(log_probs) * mask.unsqueeze(-1)\n", "fix_rule": "\"\"\"\nIf self.unwrap_to_tensors is detected, replace it with self.detach_tensors.\nIf mask is None, replace mask = torch.ones(logits.size()[:-1]) with mask = torch.ones(logits.size()[:-1], device=logits.device).\n\"\"\""}

{"number": 1044, "change": "def fmod(\nout: Optional[Union[tf.Tensor, tf.Variable]] = None,\n) -> Union[tf.Tensor, tf.Variable]:\nresult = tf.math.floormod(x1, x2, name=None)\n-    temp = (result, x1)\n-    return tf.map_fn(lambda x: x[0] if (x[0] * x[1] >= 0) else (-1 * x[0]), temp)\n+    temp = [result, x1]\n+    return tf.map_fn(lambda x: x[0] if (x[0] * x[1] >= 0) else (-1 * x[0]), temp, fn_output_signature=result.dtype)\n\n\ndef fmax(\n", "fix_rule": "if  tf.map_fn(lambda x: x[0] if (x[0] * x[1] >= 0) else (-1 * x[0]), temp) detected, replace it with tf.map_fn(lambda x: x[0] if (x[0] * x[1] >= 0) else (-1 * x[0]), temp, fn_output_signature=result.dtype)"}

{"number": 1046, "change": "class MT5DenseGatedActDense(nn.Module):\n# To make 8bit quantization work for google/flan-t5-xxl, self.wo is kept in float32.\n# See https://github.com/huggingface/transformers/issues/20287\n# we also make sure the weights are not in `int8` in case users will force `_keep_in_fp32_modules` to be `None``\n-        if hidden_states.dtype != self.wo.weight.dtype and self.wo.weight.dtype != torch.int8:\n+        if (\n+            isinstance(self.wo.weight, torch.Tensor)\n+            and hidden_states.dtype != self.wo.weight.dtype\n+            and self.wo.weight.dtype != torch.int8\n+        ):\nhidden_states = hidden_states.to(self.wo.weight.dtype)\n\nhidden_states = self.wo(hidden_states)\n", "fix_rule": "if self.wo.weight is an instance of torch.Tensor and hidden_states.dtype is not equal to self.wo.weight.dtype and self.wo.weight.dtype is not equal to torch.int8, then hidden_states should be converted to self.wo.weight.dtype."}

{"number": 1048, "change": "def vector_to_skew_symmetric_matrix(vector):\na2s = vector_expanded[..., 1:2, :]\na3s = vector_expanded[..., 2:3, :]\n# BS x 1 x 1\n-    zs = torch.zeros(batch_shape + [1, 1])\n+    zs = torch.zeros(batch_shape + [1, 1], device=vector.device)\n# BS x 1 x 3\nrow1 = torch.cat((zs, -a3s, a2s), -1)\nrow2 = torch.cat((a3s, zs, -a1s), -1)\n", "fix_rule": "if  torch.zeros() detected, replace it with torch.zeros().to(device)"}

{"number": 1050, "change": "class PointAssigner(BaseAssigner):\n\nif gt_labels is not None:\nassigned_labels = assigned_gt_inds.new_full((num_points, ), -1)\n-            pos_inds = torch.nonzero(assigned_gt_inds > 0).squeeze()\n+            pos_inds = torch.nonzero(\n+                assigned_gt_inds > 0, as_tuple=False).squeeze()\nif pos_inds.numel() > 0:\nassigned_labels[pos_inds] = gt_labels[\nassigned_gt_inds[pos_inds] - 1]\n", "fix_rule": "if  torch.nonzero() detected, replace it with torch.nonzero(as_tuple=False)"}

{"number": 1052, "change": "def att_to_numpy(att_ws, att):\natt_ws = torch.stack([aw[:, -1] for aw in att_ws], dim=1).cpu().numpy()\nelif isinstance(att, (AttCov, AttCovLoc)):\n# att_ws => list of list of previous attentions\n-        att_ws = torch.stack([aw[-1] for aw in att_ws], dim=1).cpu().numpy()\n+        att_ws = torch.stack([aw[idx] for idx, aw in enumerate(att_ws)], dim=1).cpu().numpy()\nelif isinstance(att, AttLocRec):\n# att_ws => list of tuple of attention and hidden states\natt_ws = torch.stack([aw[0] for aw in att_ws], dim=1).cpu().numpy()\n", "fix_rule": "if torch.stack() detected, replace it with torch.stack([aw[idx] for idx, aw in enumerate(att_ws)], dim=1).cpu().numpy()"}

{"number": 1059, "change": "class TFOPTDecoder(tf.keras.layers.Layer):\nif output_attentions:\nall_self_attns += (layer_self_attn,)\n\n+        if self.final_layer_norm is not None:\n+            hidden_states = self.final_layer_norm(hidden_states)\n+\nif self.project_out is not None:\nhidden_states = self.project_out(hidden_states)\n", "fix_rule": "if final_layer_norm is not None, add the line: hidden_states = final_layer_norm(hidden_states)"}

{"number": 1065, "change": "class ParabolicEquationStepperTest(tf.test.TestCase, parameterized.TestCase):\nsecond_order_coeff_fn=second_order_coeff_fn,\ninner_first_order_coeff_fn=inner_first_order_coeff_fn)[0]\n\n-    true_values = tf.math.exp(final_t + grid[0])\n+    true_values = tf.expand_dims(tf.math.exp(final_t + grid[0]), axis=0)\nself.assertAllClose(\nest_values, true_values, atol=1e-2, rtol=1e-2)\n", "fix_rule": "if tf.math.exp(final_t + grid[0]) is detected, replace it with tf.expand_dims(tf.math.exp(final_t + grid[0]), axis=0)"}

{"number": 1066, "change": "class LocalMultiGPUOptimizer(PolicyOptimizer):\nelse:\nrnn_inputs = []\nself.par_opt = LocalSyncParallelOptimizer(\n-                        tf.train.AdamOptimizer(\n-                            self.sgd_stepsize), self.devices,\n+                        self.policy.optimizer(), self.devices,\n[v for _, v in self.policy.loss_inputs()], rnn_inputs,\nself.per_device_batch_size, self.policy.copy,\nos.getcwd())\n", "fix_rule": "if tf.train.AdamOptimizer(self.sgd_stepsize) detected, replace it with self.policy.optimizer()"}

{"number": 1067, "change": "class DistributedReplicatedBuilder(DataParallelBuilder):\nreturn grads\n\n# Ngpu * Nvar * 2\n-        grad_list = self.build_on_multi_tower(\n-            get_grads,\n+        grad_list = DataParallelBuilder.build_on_towers(\n+            self.towers, get_grads,\ndevices=self.raw_devices,\nuse_vs=[True] * len(self.towers))  # open vs at each tower\nDataParallelBuilder._check_grad_list(grad_list)\n", "fix_rule": "if self.build_on_multi_tower(dtected, replace it with DataParallelBuilder.build_on_towers(self.towers, get_grads, devices=self.raw_devices, use_vs=[True] * len(self.towers)) # open vs at each tower)"}

{"number": 1069, "change": "class OPTForSequenceClassification(OPTPreTrainedModel):\nsequence_lengths = -1\nelse:\nif input_ids is not None:\n-                sequence_lengths = torch.ne(input_ids, self.config.pad_token_id).sum(-1) - 1\n+                sequence_lengths = (torch.ne(input_ids, self.config.pad_token_id).sum(-1) - 1).to(logits.device)\nelse:\nsequence_lengths = -1\nlogger.warning(\n", "fix_rule": "Replace the line \"-                sequence_lengths = torch.ne(input_ids, self.config.pad_token_id).sum(-1) - 1\" with \"-                sequence_lengths = (torch.ne(input_ids, self.config.pad_token_id).sum(-1) - 1).to(logits.device)\""}

{"number": 1072, "change": "def test_discrete_parallel(continuous_class):\n\ndef model(data):\nweights = pyro.sample('weights', dist.Dirichlet(0.5 * torch.ones(K)))\n-        locs = pyro.sample('locs', dist.Normal(0, 10).reshape([K], extra_event_dims=1))\n+        locs = pyro.sample('locs', dist.Normal(0, 10).expand_by([K]).independent(1))\nscale = pyro.sample('scale', dist.LogNormal(0, 1))\n\nwith pyro.iarange('data', len(data)):\n", "fix_rule": "if `dist.Normal(0, 10).reshape([K], extra_event_dims=1)` is detected, replace it with `dist.Normal(0, 10).expand_by([K]).independent(1)`"}

{"number": 1075, "change": "class RenyiELBO(ELBO):\nsurrogate_elbo_particles = torch.stack(surrogate_elbo_particles)\n\nlog_weights = (1. - self.alpha) * elbo_particles\n-        log_mean_weight = logsumexp(log_weights, dim=0) - math.log(self.num_particles)\n+        log_mean_weight = torch.logsumexp(log_weights, dim=0) - math.log(self.num_particles)\nelbo = log_mean_weight.sum().item() / (1. - self.alpha)\n\n# collect parameters to train from model and guide\n", "fix_rule": "If `logsumexp()` is detected, replace it with `torch.logsumexp()`"}

{"number": 1077, "change": "class MaskTokensDataset(BaseWrapperDataset):\nif self.mask_whole_words is not None:\nmask = np.repeat(mask, word_lens)\nnew_item = np.full(len(mask), self.pad_idx)\n-                new_item[mask] = item[torch.from_numpy(mask)]\n+                new_item[mask] = item[torch.from_numpy(mask.astype(np.uint8))]\nreturn torch.from_numpy(new_item)\n\n# decide unmasking and random replacement\n", "fix_rule": "if  torch.from_numpy(mask) dtected, replace it with torch.from_numpy(mask.astype(np.uint8))"}

{"number": 1083, "change": "class CategoricalAccuracy(Metric):\n# ith entry in gold_labels points to index (0-num_classes) for ith row in max_predictions\n# For each row check if index pointed by gold_label is was 1 or not (among max scored classes)\ncorrect = max_predictions_mask[\n-                torch.arange(gold_labels.numel()).long(), gold_labels\n+                torch.arange(gold_labels.numel(), device=gold_labels.device).long(), gold_labels\n].float()\ntie_counts = max_predictions_mask.sum(-1)\ncorrect /= tie_counts.float()\n", "fix_rule": "if torch.arange(gold_labels.numel()) dtected, replace it with torch.arange(gold_labels.numel(), device=gold_labels.device)"}

{"number": 1091, "change": "class Model(ModelDesc):\n.GlobalAvgPooling('gap')\n.FullyConnected('linear', 1000, nl=tf.identity)())\n\n-        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, label)\n+        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)\nloss = tf.reduce_mean(loss, name='xentropy-loss')\n\nwrong = prediction_incorrect(logits, label, 1, name='wrong-top1')\n", "fix_rule": "if tf.nn.sparse_softmax_cross_entropy_with_logits() detected, replace it with tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)\nif tf.reduce_mean() detected, replace it with tf.reduce_mean(loss, name='xentropy-loss')\nif prediction_incorrect() detected, replace it with prediction_incorrect(logits, label, 1, name='wrong-top1')"}

{"number": 1094, "change": "def batchnorm_example(optimizer_fn,\nfor z in range(batch_per_epoch)]).repeat()\n\noptimizer = optimizer_fn()\n-  batchnorm = tf.compat.v1.layers.BatchNormalization(\n+  batchnorm = normalization.BatchNormalization(\nrenorm=renorm, momentum=momentum, fused=False)\n-  layer = tf.compat.v1.layers.Dense(1, use_bias=False)\n+  layer = core.Dense(1, use_bias=False)\n\ndef model_fn(x):\n\"\"\"A model that uses batchnorm.\"\"\"\n", "fix_rule": "If \"tf.compat.v1.layers.BatchNormalization\" is detected, replace it with \"normalization.BatchNormalization\".\nIf \"tf.compat.v1.layers.Dense\" is detected, replace it with \"core.Dense\"."}

{"number": 1100, "change": "class TorchHook(object):\n\nself._hook_torch_module()\n\n+        if torch.torch_hooked > 0:\n+            raise Exception('Torch was already hooked')\n+\ndef _hook_native_tensors_and_variables(self, tensor_type):\n\"\"\"Overloading a given tensor_type\"\"\"\n# Overload 'special' methods here\n", "fix_rule": "\"\"\"\nIf 'if torch.torch_hooked > 0:' detected, replace it with 'if torch.is_hooked():'.\nIf 'raise Exception('Torch was already hooked')' detected, replace it with 'raise RuntimeError('Torch was already hooked')'.\n\"\"\""}

{"number": 1104, "change": "class EpsilonDecay(Exploration):\n\npred = tf.logical_or(x=(timestep < self.start_timestep),\ny=(timestep > self.start_timestep + int(self.timesteps)))\n-        return tf.cond(pred=pred, true_fn=true_fn, false_fn=false_fn)\n+        return tf.fill(dims=shape, value=tf.cond(pred=pred, true_fn=true_fn, false_fn=false_fn))\n", "fix_rule": "if tf.fill() is detected, replace it with tf.fill(dims=shape, value=)"}

{"number": 1118, "change": "def _scale_channel(im: torch.Tensor) -> torch.Tensor:\n# and then normalization by step.\nlut = (torch.cumsum(histo, 0) + (step // 2)) // step\n# Shift lut, prepending with 0.\n-        lut = torch.cat([torch.zeros(1, device=lut.device), lut[:-1]])\n+        lut = torch.cat([torch.zeros(1, device=lut.device, dtype=lut.dtype), lut[:-1]])\n# Clip the counts to be in range.  This is done\n# in the C code for image.point.\nreturn torch.clamp(lut, 0, 255)\n", "fix_rule": "if torch.zeros(1, ...) detected, replace it with torch.zeros(1, ..., dtype=...)"}

{"number": 1122, "change": "class DonutSwinLayer(nn.Module):\n# partition windows\nhidden_states_windows = window_partition(shifted_hidden_states, self.window_size)\nhidden_states_windows = hidden_states_windows.view(-1, self.window_size * self.window_size, channels)\n-        attn_mask = self.get_attn_mask(height_pad, width_pad)\n+        attn_mask = self.get_attn_mask(height_pad, width_pad, dtype=hidden_states.dtype)\nif attn_mask is not None:\nattn_mask = attn_mask.to(hidden_states_windows.device)\n", "fix_rule": "if 'dtype=hidden_states.dtype' is missing in the 'get_attn_mask' function call, add it"}

{"number": 1127, "change": "class VisualBertEmbeddings(nn.Module):\ninputs_embeds = self.word_embeddings(input_ids)\n\nif token_type_ids is None:\n-            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.input_embeds.device)\n+            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.position_ids.device)\n\ntoken_type_embeddings = self.token_type_embeddings(token_type_ids)\n", "fix_rule": "if torch.zeros() detected, replace it with torch.zeros().to(device)"}

{"number": 1128, "change": "class BCELossMasked(nn.Module):\nReturns:\nloss: An average loss value in range [0, 1] masked by the length.\n\"\"\"\n-        # mask: (batch, max_len, 1)\ntarget.requires_grad = False\nif length is not None:\n-            mask = sequence_mask(sequence_length=length, max_len=target.size(1)).float()\n-            x = x * mask\n-            target = target * mask\n+            # mask: (batch, max_len, 1)\n+            mask = sequence_mask(sequence_length=length, max_len=target.size(1))\nnum_items = mask.sum()\n+            loss = functional.binary_cross_entropy_with_logits(x.masked_select(mask), target.masked_select(mask), pos_weight=self.pos_weight, reduction=\"sum\")\nelse:\n+            loss = functional.binary_cross_entropy_with_logits(x, target, pos_weight=self.pos_weight, reduction=\"sum\")\nnum_items = torch.numel(x)\n-        loss = functional.binary_cross_entropy_with_logits(x, target, pos_weight=self.pos_weight, reduction=\"sum\")\nloss = loss / num_items\nreturn loss\n", "fix_rule": "If `mask = sequence_mask(sequence_length=length, max_len=target.size(1)).float()` is detected, replace it with `mask = sequence_mask(sequence_length=length, max_len=target.size(1))`.\n\nIf `num_items = mask.sum()` is detected, replace it with `num_items = torch.numel(mask)`.\n\nIf `loss = functional.binary_cross_entropy_with_logits(x.masked_select(mask), target.masked_select(mask), pos_weight=self.pos_weight, reduction=\"sum\")` is detected, replace it with `loss = functional.binary_cross_entropy_with_logits(x, target, pos_weight=self.pos_weight, reduction=\"sum\")`."}

{"number": 1129, "change": "class PrioritizedReplay(Memory):\n))\n\nwith tf.control_dependencies(control_inputs=assignments):\n-            return tf.no_op()\n+            return util.no_operation()\n\n# These are not supported for prioritized replay currently.\ndef tf_retrieve_episodes(self, n):\n", "fix_rule": "if tf.no_op() detected, replace it with util.no_operation()"}

{"number": 1132, "change": "class TFFastSpeech(tf.keras.Model):\n== config.decoder_self_attention_params.hidden_size,\nname=\"decoder\",\n)\n-        self.mel_dense = tf.keras.layers.Dense(units=config.num_mels, name=\"mel_before\")\n-        self.postnet = TFTacotronPostnet(config=config, name=\"postnet\")\n+        self.mel_dense = tf.keras.layers.Dense(units=config.num_mels, dtype=tf.float32, name=\"mel_before\")\n+        self.postnet = TFTacotronPostnet(config=config, dtype=tf.float32, name=\"postnet\")\n\nself.setup_inference_fn()\n", "fix_rule": "if \"dtype=tf.float32\" is missing, add \"dtype=tf.float32\" to the respective line."}

{"number": 1141, "change": "class H3FeatureMixin(BaseFeatureMixin):\n):\ncolumn = input_df[feature_config[COLUMN]]\nif column.dtype == object:\n-            column = column.map(int)\n-        column = column.map(H3FeatureMixin.h3_to_list)\n+            column = backend.df_engine.map_objects(column, int)\n+        column = backend.df_engine.map_objects(column, H3FeatureMixin.h3_to_list)\n\nproc_df[feature_config[PROC_COLUMN]] = backend.df_engine.map_objects(\ncolumn, lambda x: np.array(x, dtype=np.uint8)\n", "fix_rule": "If \"column.dtype == object\", replace \"column = column.map(int)\" with \"column = backend.df_engine.map_objects(column, int)\" \nIf \"column.dtype == object\", replace \"column = column.map(H3FeatureMixin.h3_to_list)\" with \"column = backend.df_engine.map_objects(column, H3FeatureMixin.h3_to_list)\" \nReplace \"column, lambda x: np.array(x, dtype=np.uint8)\" with \"backend.df_engine.map_objects(column, lambda x: np.array(x, dtype=np.uint8))\""}

{"number": 1144, "change": "class VariationalSparseGP(GPModel):\nM = self.Xu.size(0)\nKuu = self.kernel(self.Xu).contiguous()\nKuu.view(-1)[::M + 1] += self.jitter  # add jitter to the diagonal\n-        Luu = Kuu.cholesky()\n+        Luu = torch.linalg.cholesky(Kuu)\n\nzero_loc = self.Xu.new_zeros(self.u_loc.shape)\nif self.whiten:\n", "fix_rule": "if `torch.cholesky` function is called, replace it with `torch.linalg.cholesky` function."}

{"number": 1144, "change": "class VariationalSparseGP(GPModel):\nM = self.Xu.size(0)\nKuu = self.kernel(self.Xu).contiguous()\nKuu.view(-1)[::M + 1] += self.jitter  # add jitter to the diagonal\n-        Luu = Kuu.cholesky()\n+        Luu = torch.linalg.cholesky(Kuu)\n\nzero_loc = self.Xu.new_zeros(self.u_loc.shape)\nif self.whiten:\n", "fix_rule": "if  torch.linalg.cholesky() detected, replace it with torch.linalg.cholesky().to(device)"}

{"number": 1148, "change": "def _matvecmul(x, y):\n\n\ndef _cholesky(x):\n-    return x.sqrt() if x.dim() == 1 else x.cholesky()\n+    return x.sqrt() if x.dim() == 1 else torch.linalg.cholesky(x)\n\n\ndef _transpose(x):\n", "fix_rule": "if torch.linalg.cholesky(detected, replace it with torch.linalg.cholesky()."}

{"number": 1155, "change": "def convert_to_numpy(x: TensorStructType, reduce_floats: bool = False):\nif torch and isinstance(item, torch.Tensor):\nret = item.cpu().item() if len(item.size()) == 0 else \\\nitem.detach().cpu().numpy()\n-        elif tf and isinstance(item, (tf.Tensor, tf.Variable)):\n+        elif tf and isinstance(item, (tf.Tensor, tf.Variable)) and \\\n+                hasattr(item, \"numpy\"):\nassert tf.executing_eagerly()\nret = item.numpy()\nelse:\n", "fix_rule": "if torch and isinstance(item, torch.Tensor):\n    ret = item.cpu().item() if len(item.size()) == 0 else \\\n    item.detach().cpu().numpy().to(numpy.ndarray)\nelif tf and isinstance(item, (tf.Tensor, tf.Variable)) and \\\n    hasattr(item, \"numpy\"):\n    assert tf.executing_eagerly()\n    ret = item.numpy()\nelse:"}

{"number": 1163, "change": "class OpenAIGPTDoubleHeadsModel(OpenAIGPTPreTrainedModel):\ntokenizer = OpenAIGPTTokenizer.from_pretrained('openai-gpt')\nmodel = OpenAIGPTDoubleHeadsModel.from_pretrained('openai-gpt')\ntokenizer.add_special_tokens({'cls_token': '[CLS]'})  # Add a [CLS] to the vocabulary (we should train it also!)\n+        model.resize_token_embeddings(len(tokenizer))\n+\nchoices = [\"Hello, my dog is cute [CLS]\", \"Hello, my cat is cute [CLS]\"]\ninput_ids = torch.tensor([tokenizer.encode(s) for s in choices]).unsqueeze(0)  # Batch size 1, 2 choices\n-        mc_token_ids = torch.tensor([input_ids.size(-1), input_ids.size(-1)]).unsqueeze(0)  # Batch size 1\n+        mc_token_ids = torch.tensor([input_ids.size(-1)-1, input_ids.size(-1)-1]).unsqueeze(0)  # Batch size 1\n+\noutputs = model(input_ids, mc_token_ids=mc_token_ids)\nlm_prediction_scores, mc_prediction_scores = outputs[:2]\n", "fix_rule": "if `model.resize_token_embeddings(len(tokenizer))` is detected, replace it with `model.resize_token_embeddings(len(tokenizer)).to(device)`"}

{"number": 1164, "change": "class Model(ModelDesc):\nadd_moving_summary(tf.reduce_mean(wrong, name='train_error'))\n\n# weight decay on all W of fc layers\n-        wd_cost = tf.mul(0.0004,\n-                         regularize_cost('fc.*/W', tf.nn.l2_loss),\n-                         name='regularize_loss')\n+        wd_cost = regularize_cost('fc.*/W', l2_regularizer(4e-4), name='regularize_loss')\nadd_moving_summary(cost, wd_cost)\n\nadd_param_summary(('.*/W', ['histogram']))   # monitor W\n", "fix_rule": "if tf.mul(0.0004, regularize_cost('fc.*/W', tf.nn.l2_loss)) is detected, replace it with regularize_cost('fc.*/W', l2_regularizer(4e-4))"}

{"number": 1168, "change": "def reshape(\nshape: Union[ivy.NativeShape, Sequence[int]],\n*,\ncopy: Optional[bool] = None,\n-    out: Optional[tf.Tensor] = None,\n+    out: Optional[Union[tf.Tensor, tf.Variable]] = None,\n) -> Union[tf.Tensor, tf.Variable]:\nif copy:\nnewarr = tf.experimental.numpy.copy(x)\n", "fix_rule": "if tf.experimental.numpy.copy() detected, replace it with tf.identity(x)"}

{"number": 1191, "change": "class TestInvertAffineTransform:\nassert_allclose(matrix_inv, expected)\n\ndef test_gradcheck(self, device):\n-        matrix = torch.eye(2, 3).to(device)\n+        matrix = torch.eye(2, 3).to(device)[None]\nmatrix = utils.tensor_to_gradcheck_var(matrix)  # to var\nassert gradcheck(kornia.invert_affine_transform, (matrix,),\nraise_exception=True)\n", "fix_rule": "\"\"\"\nIf  torch.eye(2, 3).to(device) is detected, replace it with torch.eye(2, 3).to(device)[None]\n\"\"\""}

{"number": 1193, "change": "class RNN(torch.nn.Module):\ndef __init__(self, idim, elayers, cdim, hdim, dropout, typ=\"blstm\"):\nsuper(RNN, self).__init__()\nbidir = typ[0] == \"b\"\n-        self.nblstm = torch.nn.LSTM(idim, cdim, elayers, batch_first=True,\n-                                    dropout=dropout, bidirectional=bidir) if \"lstm\" in typ \\\n+        self.nbrnn = torch.nn.LSTM(idim, cdim, elayers, batch_first=True,\n+                                   dropout=dropout, bidirectional=bidir) if \"lstm\" in typ \\\nelse torch.nn.GRU(idim, cdim, elayers, batch_first=True, dropout=dropout,\nbidirectional=bidir)\nif bidir:\n", "fix_rule": "if \"lstm\" in typ is detected, replace it with self.nbrnn"}

{"number": 1197, "change": "class TFData2VecVisionForSemanticSegmentation(TFData2VecVisionPreTrainedModel):\n# FPNs\nself.fpn1 = [\ntf.keras.layers.Conv2DTranspose(config.hidden_size, kernel_size=2, strides=2, name=\"fpn1.0\"),\n-            tf.keras.layers.BatchNormalization(name=\"fpn1.1\"),\n+            tf.keras.layers.BatchNormalization(name=\"fpn1.1\", momentum=0.9, epsilon=1e-5),\ntf.keras.layers.Activation(\"gelu\"),\ntf.keras.layers.Conv2DTranspose(config.hidden_size, kernel_size=2, strides=2, name=\"fpn1.3\"),\n]\n", "fix_rule": "if tf.keras.layers.BatchNormalization() detected, replace it with tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5)"}

{"number": 1199, "change": "def main():\nlogger.info(f\"Number of class images to sample: {num_new_images}.\")\n\nsample_dataset = PromptDataset(args.class_prompt, num_new_images)\n-            sample_dataloader = torch.utils.data.DataLoader(sample_dataset, batch_size=args.sample_batch_size)\n+            total_sample_batch_size = args.sample_batch_size * jax.local_device_count()\n+            sample_dataloader = torch.utils.data.DataLoader(sample_dataset, batch_size=total_sample_batch_size)\n\nfor example in tqdm(\nsample_dataloader, desc=\"Generating class images\", disable=not jax.process_index() == 0\n", "fix_rule": "if batch_size parameter detected, replace it with batch_size * jax.local_device_count()"}

{"number": 1200, "change": "class TokenCharactersIndexer(TokenIndexer[List[int]]):\n# Removes the \"dummy token\".\npadded_tokens.pop()\n# Truncates all the tokens to the desired length, and return the result.\n-        return {key: [list(token[:desired_token_length]) for token in padded_tokens]}\n+        return {key: torch.LongTensor([list(token[:desired_token_length])\n+                                       for token in padded_tokens])}\n", "fix_rule": "if  torch.LongTensor([list(token[:desired_token_length])]) dtected, replace it with torch.LongTensor([list(token[:desired_token_length])]).to(device)"}

{"number": 1257, "change": "class Module(tf.Module):\nelif initializer == 'ones':\ninitializer = tf_util.ones(shape=spec.shape, dtype=spec.type)\nelif initializer == 'constant':\n-            initializer = tf_util.fill(dims=spec.shape, value=self.initialization_scale)\n+            initializer = tf.fill(\n+                dims=spec.shape, value=tf_util.constant(value=initialization_scale, dtype=spec.type)\n+            )\n\n# Variable\nvariable = tf.Variable(\n", "fix_rule": "If 'tf_util.fill' is detected, replace it with 'tf.fill(dims=spec.shape, value=tf_util.constant(value=initialization_scale, dtype=spec.type))'."}

{"number": 1265, "change": "def test_transformer_conv():\n\nt = '(PairTensor, SparseTensor, NoneType) -> Tensor'\njit = torch.jit.script(conv.jittable(t))\n-    assert torch.allclose(conv((x1, x2), adj.t()), out, atol=1e-6)\n+    assert torch.allclose(jit((x1, x2), adj.t()), out, atol=1e-6)\n", "fix_rule": "if conv((x1, x2), adj.t()) is detected, replace it with jit((x1, x2), adj.t())"}

{"number": 1266, "change": "PT_SEQUENCE_CLASSIFICATION_SAMPLE = r\"\"\"\n...     \"{checkpoint}\", num_labels=num_labels, problem_type=\"multi_label_classification\"\n... )\n\n-    >>> labels = torch.nn.functional.one_hot(torch.tensor(predicted_class_ids), num_classes=num_labels).to(torch.float)\n+    >>> labels = torch.sum(\n+    ...     torch.nn.functional.one_hot(predicted_class_ids[None, :].clone(), num_classes=num_labels), dim=1\n+    ... ).to(torch.float)\n>>> loss = model(**inputs, labels=labels).loss\n```\n\"\"\"\n", "fix_rule": "If ```torch.nn.functional.one_hot``` is detected, replace it with \n```\ntorch.sum(torch.nn.functional.one_hot(predicted_class_ids[None, :].clone(), num_classes=num_labels), dim=1).to(torch.float)\n```"}

{"number": 1273, "change": "def test_gat_conv():\n\nt = '(OptPairTensor, SparseTensor, Size, NoneType) -> Tensor'\njit = torch.jit.script(conv.jittable(t))\n-    assert torch.allclose(conv((x1, x2), adj.t()), out1, atol=1e-6)\n-    assert torch.allclose(conv((x1, None), adj.t()), out2, atol=1e-6)\n+    assert torch.allclose(jit((x1, x2), adj.t()), out1, atol=1e-6)\n+    assert torch.allclose(jit((x1, None), adj.t()), out2, atol=1e-6)\n", "fix_rule": "if torch.jit.script() detected, replace it with jit()."}

{"number": 1282, "change": "def multi_perspective_match_pairwise(\nnorm_value = vector1_norm * vector2_norm.transpose(2, 3)\n\n# (batch, seq_len1, seq_len2, num_perspectives)\n-    return (mul_result / norm_value.clamp(min=eps)).permute(0, 2, 3, 1)\n+    return (mul_result / norm_value.clamp(min=tiny_value_of_dtype(norm_value.dtype))).permute(\n+        0, 2, 3, 1\n+    )\n\n\nclass BiMpmMatching(nn.Module, FromParams):\n", "fix_rule": "if  norm_value.clamp(min=tiny_value_of_dtype(norm_value.dtype)) detected, replace it with norm_value.clamp(min=eps)"}

{"number": 1290, "change": "def train(hyp, opt, device, tb_writer=None):\nif rank != -1:\nindices = torch.zeros([dataset.n], dtype=torch.int)\nif rank == 0:\n-                    indices[:] = torch.from_tensor(dataset.indices, dtype=torch.int)\n+                    indices[:] = torch.tensor(dataset.indices, dtype=torch.int)\ndist.broadcast(indices, 0)\nif rank != 0:\ndataset.indices = indices.cpu().numpy()\n", "fix_rule": "if torch.from_tensor() detected, replace it with torch.tensor()"}

{"number": 1294, "change": "class SCSEModule(nn.Module):\nnn.Conv2d(in_channels // reduction, in_channels, 1),\nnn.Sigmoid(),\n)\n-        self.sSE = nn.Sequential(nn.Conv2d(in_channels, in_channels, 1), nn.Sigmoid())\n+        self.sSE = nn.Sequential(nn.Conv2d(in_channels, 1, 1), nn.Sigmoid())\n\ndef forward(self, x):\nreturn x * self.cSE(x) + x * self.sSE(x)\n", "fix_rule": "if nn.Conv2d(in_channels, in_channels, 1) is detected, replace it with nn.Conv2d(in_channels, 1, 1)"}

{"number": 1296, "change": "def interpolate(\nsize = [x.shape[0], *size, x.shape[1]]\n\nif align_corners or mode == \"area\":\n-        return ivy.interpolate(\n+        return ivy.functional.experimental.interpolate(\nx, size, mode=mode, align_corners=align_corners, antialias=antialias\n)\nx = jnp.transpose(x, (0, *range(2, dims + 2), 1))\n", "fix_rule": "If \"ivy.interpolate\" is detected, replace it with \"ivy.functional.experimental.interpolate\"."}

{"number": 1308, "change": "def count_nonzero(\ndef _dtype_count_nonzero(a, axis, dtype):\nif dtype is None:\nreturn torch.count_nonzero(a, dim=axis)\n-        return torch.tensor(torch.count_nonzero(a, dim=axis), dtype=dtype)\n+        return torch.tensor(torch.count_nonzero(a, dim=axis),\n+                            dtype=ivy.as_native_dtype(dtype))\n\nx = _dtype_count_nonzero(a, axis, dtype)\nif not keepdims:\n", "fix_rule": "if `dtype` is None, replace `return torch.tensor(torch.count_nonzero(a, dim=axis), dtype=dtype)` with `return torch.tensor(torch.count_nonzero(a, dim=axis), dtype=ivy.as_native_dtype(dtype))`"}

{"number": 1312, "change": "class TorchTensor(AbstractTensor):\n\n\"\"\"\n\n-        assert isinstance(self.child, PointerTensor)\n+        if not isinstance(self.child, PointerTensor):\n+            raise TypeError(\"child should be a PointerTensor\")\n\nps = list(pointers)\nps.append(self)\n", "fix_rule": "if  not isinstance(self.child, PointerTensor) dtected, replace it with raise TypeError(\"child should be a PointerTensor\")"}

{"number": 1313, "change": "def unravel_index(\nfor dim in reversed(shape):\noutput.append(temp % dim)\ntemp = temp // dim\n-    return tuple(reversed(output))\n+    return torch.tensor(reversed(output))\n\n\nunravel_index.support_native_out = False\n", "fix_rule": "If \"return tuple(reversed(output))\" is replaced with \"return torch.tensor(reversed(output))\", the code change will be fixed."}

{"number": 1315, "change": "class CanineSelfAttention(nn.Module):\n# Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n# masked positions, this operation will create a tensor which is 0.0 for\n# positions we want to attend and -10000.0 for masked positions.\n-                attention_mask = (1.0 - attention_mask.float()) * -10000.0\n+                attention_mask = (1.0 - attention_mask.float()) * torch.finfo(attention_scores.dtype).min\n# Apply the attention mask (precomputed for all layers in CanineModel forward() function)\nattention_scores = attention_scores + attention_mask\n", "fix_rule": "if torch.finfo() detected, replace it with torch.finfo().min"}

{"number": 1323, "change": "class TFModel(NNModel, metaclass=TfModelMeta):\nopt_scope = tf.variable_scope(optimizer_scope_name)\nwith opt_scope:\nif learnable_scopes is None:\n-                variables_to_train = tf.trainable_variables()\n+                variables_to_train = tf.global_variables()\nelse:\nvariables_to_train = []\nfor scope_name in learnable_scopes:\n-                    for var in tf.trainable_variables():\n+                    for var in tf.global_variables():\nif scope_name in var.name:\nvariables_to_train.append(var)\n", "fix_rule": "if tf.trainable_variables() is detected, replace it with tf.global_variables()"}

{"number": 1324, "change": "def abs(x):\n\n\ndef sqrt(x):\n-    x = tf.clip_by_value(x, _EPSILON, np.inf)\n+    x = tf.clip_by_value(x, 0., np.inf)\nreturn tf.sqrt(x)\n", "fix_rule": "if tf.clip_by_value() is detected, replace it with tf.clip_by_value(x, 0., np.inf)"}

{"number": 1346, "change": "def reset_deterministic_algorithm():\nyield\nif _TORCH_GREATER_EQUAL_1_8:\ntorch.use_deterministic_algorithms(False)\n-    elif _TORCH_GREATER_EQUAL_1_7:\n+    else:\ntorch.set_deterministic(False)\n-    else:  # the minimum version Lightning supports is PyTorch 1.6\n-        torch._set_deterministic(False)\n\n\n@pytest.fixture\n", "fix_rule": "if _TORCH_GREATER_EQUAL_1_8:\n    torch.use_deterministic_algorithms(False)\nelif _TORCH_GREATER_EQUAL_1_7:\n    torch.set_deterministic(False)"}

{"number": 1357, "change": "class MultiHeadAttention(nn.Module):\n# perform attention, result size = (n_head * mb_size) x len_q x d_v\noutputs, attns = self.attention(q_s, k_s, v_s, attn_mask=attn_mask.repeat(n_head, 1, 1))\n\n-        # back to original mb_size batch\n-        outputs = outputs.view(mb_size, len_q, -1)            # mb_size x len_q x (n_head*d_v)\n+        # back to original mb_size batch, result size = mb_size x len_q x (n_head*d_v)\n+        outputs = torch.cat(torch.split(outputs, mb_size, dim=0), dim=-1)\n\n# project back to residual size\noutputs = self.proj(outputs)\n", "fix_rule": "\"\"\"\nReplace outputs.view(mb_size, len_q, -1) with torch.cat(torch.split(outputs, mb_size, dim=0), dim=-1)\n\"\"\""}

{"number": 1363, "change": "def get_timestep_embedding(\nassert len(timesteps.shape) == 1, \"Timesteps should be a 1d-array\"\n\nhalf_dim = embedding_dim // 2\n-    exponent = -math.log(max_period) * torch.arange(start=0, end=half_dim, dtype=torch.float32)\n+    exponent = -math.log(max_period) * torch.arange(\n+        start=0, end=half_dim, dtype=torch.float32, device=timesteps.device\n+    )\nexponent = exponent / (half_dim - downscale_freq_shift)\n\n-    emb = torch.exp(exponent).to(device=timesteps.device)\n+    emb = torch.exp(exponent)\nemb = timesteps[:, None].float() * emb[None, :]\n\n# scale embeddings\n", "fix_rule": "if \"device=timesteps.device\" is not in the code, add it to the line \n\"exponent = -math.log(max_period) * torch.arange(start=0, end=half_dim, dtype=torch.float32, device=timesteps.device)\""}

{"number": 1365, "change": "class TestNormalize:\nf = kornia.enhance.Normalize(mean=mean, std=std)\ndata = torch.ones(2, 3, 256, 313)\nif isinstance(mean, float):\n-            expected = (data - torch.tensor(mean)) / torch.tensor(std)\n+            expected = (data - torch.as_tensor(mean)) / torch.as_tensor(std)\nelse:\n-            expected = (data - torch.tensor(mean[0])) / torch.tensor(std[0])\n+            expected = (data - torch.as_tensor(mean[0])) / torch.as_tensor(std[0])\nassert_close(f(data), expected)\n\n@staticmethod\n", "fix_rule": "if  isinstance(mean, float) is detected, replace it with isinstance(mean, (float, int)).\nif  torch.tensor(mean) is detected, replace it with torch.as_tensor(mean).\nif  torch.tensor(std) is detected, replace it with torch.as_tensor(std)."}

{"number": 1373, "change": "def train_func(config):\ntrain_dataset = Subset(train_dataset, list(range(64)))\nvalidation_dataset = Subset(validation_dataset, list(range(64)))\n\n-    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"])\n-    validation_loader = DataLoader(validation_dataset, batch_size=config[\"batch_size\"])\n+    worker_batch_size = config[\"batch_size\"] // train.world_size()\n+\n+    train_loader = DataLoader(train_dataset, batch_size=worker_batch_size)\n+    validation_loader = DataLoader(validation_dataset, batch_size=worker_batch_size)\n\ntrain_loader = train.torch.prepare_data_loader(train_loader)\nvalidation_loader = train.torch.prepare_data_loader(validation_loader)\n", "fix_rule": "if \"batch_size\" in config, replace it with \"batch_size\" // train.world_size()"}

{"number": 1378, "change": "class FNetEmbeddings(nn.Module):\nif version.parse(torch.__version__) > version.parse(\"1.6.0\"):\nself.register_buffer(\n\"token_type_ids\",\n-                torch.zeros(self.position_ids.size(), dtype=torch.long, device=self.position_ids.device),\n+                torch.zeros(self.position_ids.size(), dtype=torch.long),\npersistent=False,\n)\n", "fix_rule": "if version.parse(torch.__version__) > version.parse(\"1.6.0\"):\n    self.register_buffer(\n        \"token_type_ids\",\n-        torch.zeros(self.position_ids.size(), dtype=torch.long, device=self.position_ids.device),\n+        torch.zeros(self.position_ids.size(), dtype=torch.long),\n        persistent=False,\n    )"}

{"number": 1383, "change": "class TestInvertAffineTransform:\n\ndef test_rot90_batch(self, device):\nangle = torch.tensor([90.]).to(device)\n-        scale = torch.tensor([1.]).to(device)\n+        scale = torch.tensor([[1., 1.]]).to(device)\ncenter = torch.tensor([[0., 0.]]).to(device)\nexpected = torch.tensor([[\n[0., -1., 0.],\n", "fix_rule": "if  torch.tensor([1.]) is detected, replace it with torch.tensor([[1., 1.]]).to(device)"}

{"number": 1384, "change": "class LDMSuperResolutionPipelineIntegrationTests(unittest.TestCase):\nldm.to(torch_device)\nldm.set_progress_bar_config(disable=None)\n\n-        generator = torch.Generator(device=torch_device).manual_seed(0)\n+        generator = torch.manual_seed(0)\nimage = ldm(image=init_image, generator=generator, num_inference_steps=20, output_type=\"numpy\").images\n\nimage_slice = image[0, -3:, -3:, -1]\n\nassert image.shape == (1, 256, 256, 3)\n-        expected_slice = np.array([0.7418, 0.7472, 0.7424, 0.7422, 0.7463, 0.726, 0.7382, 0.7248, 0.6828])\n+        expected_slice = np.array([0.7644, 0.7679, 0.7642, 0.7633, 0.7666, 0.7560, 0.7425, 0.7257, 0.6907])\n+\nassert np.abs(image_slice.flatten() - expected_slice).max() < 1e-2\n", "fix_rule": "if `torch.Generator(device=torch_device).manual_seed(0)` is detected, replace it with `torch.manual_seed(0)`"}

{"number": 1397, "change": "def binary_config():\ndef test_binary_input_feature(binary_config: Dict, encoder: str) -> None:\nbinary_config.update({\"encoder\": encoder})\nbinary_input_feature = BinaryInputFeature(binary_config)\n-    binary_tensor = torch.randn([SEQ_SIZE, BINARY_W_SIZE], dtype=torch.float32)\n+    binary_tensor = torch.randn([SEQ_SIZE, BINARY_W_SIZE], dtype=torch.float32).to(DEVICE)\nencoder_output = binary_input_feature(binary_tensor)\nassert encoder_output[\"encoder_output\"].shape[1:] == binary_input_feature.output_shape\n", "fix_rule": "if torch.randn() detected, replace it with torch.randn().to(DEVICE)"}

{"number": 1409, "change": "class UnCLIPPipelineIntegrationTests(unittest.TestCase):\npipeline = pipeline.to(torch_device)\npipeline.set_progress_bar_config(disable=None)\n\n-        generator = torch.Generator(device=torch_device).manual_seed(0)\n+        generator = torch.Generator(device=\"cpu\").manual_seed(0)\noutput = pipeline(\n\"horse\",\nnum_images_per_prompt=1,\n", "fix_rule": "If torch.Generator(device=torch_device) is detected, replace it with torch.Generator(device=\"cpu\")"}

{"number": 1415, "change": "class SwapBufferManager(object):\nself.count = count\nself.dtype = dtype\nself.all_buffers = [\n-            torch.zeros(num_elems,\n-                        device='cpu',\n-                        dtype=dtype).pin_memory() for _ in range(count)\n+            get_accelerator().pin_memory(\n+                torch.zeros(num_elems,\n+                            device='cpu',\n+                            dtype=dtype)) for _ in range(count)\n]\nself.free_buffer_index = [i for i in range(count)]\nself.used_buffer_index = {}\n", "fix_rule": "Replace \ntorch.zeros(num_elems, device='cpu', dtype=dtype).pin_memory() \nwith \nget_accelerator().pin_memory(torch.zeros(num_elems, device='cpu', dtype=dtype))"}

{"number": 1422, "change": "def _setup_ddp(rank, worldsize):\ndef _ddp_test_fn(rank, worldsize):\n_setup_ddp(rank, worldsize)\ntensor = torch.tensor([1.0])\n-    actual = LightningModule._LightningModule__sync(tensor, sync_dist=True, sync_dist_op=torch.distributed.ReduceOp.SUM)\n+    sync = _Sync(sync_ddp_if_available, should=True, op=torch.distributed.ReduceOp.SUM)\n+    actual = sync(tensor)\nassert actual.item() == dist.get_world_size(), \"Result-Log does not work properly with DDP and Tensors\"\n", "fix_rule": "if LightningModule._LightningModule__sync() is detected, replace it with _Sync(sync_ddp_if_available, should=True, op=torch.distributed.ReduceOp.SUM) and actual = sync(tensor)"}

{"number": 1427, "change": "def test_gcn2_conv():\n\nt = '(Tensor, Tensor, SparseTensor, OptTensor) -> Tensor'\njit = torch.jit.script(conv.jittable(t))\n-    assert torch.allclose(conv(x, x_0, adj1.t()), out1, atol=1e-6)\n-    assert torch.allclose(conv(x, x_0, adj2.t()), out2, atol=1e-6)\n+    assert torch.allclose(jit(x, x_0, adj1.t()), out1, atol=1e-6)\n+    assert torch.allclose(jit(x, x_0, adj2.t()), out2, atol=1e-6)\n\nconv.cached = True\nconv(x, x_0, edge_index)\n", "fix_rule": "if conv(x, x_0, adj1.t()) is not returning the expected results, replace it with jit(x, x_0, adj1.t())"}

{"number": 1438, "change": "class TrainingOperator:\n\nlogger.debug(\"Registering optimizers.\")\nself._optimizers = optimizers\n-        if not isinstance(self._optimizers, Iterable):\n+        if isinstance(self._optimizers, torch.optim.Optimizer):\nself._optimizers = [self._optimizers]\n\nif schedulers:\n", "fix_rule": "Replace the line \"- if not isinstance(self._optimizers, Iterable):\" with \"+ if isinstance(self._optimizers, torch.optim.Optimizer):\""}

{"number": 1463, "change": "def main():\n\n# Save the result as an audio summary.\ndatestring = str(datetime.now()).replace(' ', 'T')\n-    writer = tf.train.SummaryWriter(logdir)\n-    tf.audio_summary('generated', decode, wavenet_params['sample_rate'])\n-    summaries = tf.merge_all_summaries()\n+    writer = tf.summary.FileWriter(logdir)\n+    tf.summary.audio('generated', decode, wavenet_params['sample_rate'])\n+    summaries = tf.summary.merge_all()\nsummary_out = sess.run(summaries,\nfeed_dict={samples: np.reshape(waveform, [-1, 1])})\nwriter.add_summary(summary_out)\n", "fix_rule": "if  tf.train.SummaryWriter(dtected), replace it with tf.summary.FileWriter\nif  tf.audio_summary(dtected), replace it with tf.summary.audio\nif  tf.merge_all_summaries(dtected), replace it with tf.summary.merge_all"}

[
    {
        "number": 0,
        "label": "no",
        "change": [
            "class IndexLookupDistributionTest(",
            "",
            "",
            "if __name__ == \"__main__\":",
            "-  tf.compat.v1.enable_v2_behavior()",
            "tf.__internal__.distribute.multi_process_runner.test_main()"
        ],
        "comments": "remove API version fix skip test",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 3,
        "label": "no",
        "change": [
            "def load_homography(file_name):",
            "",
            "",
            "def load_image(file_name):",
            "-    \"\"\"Loads the image with OpenCV and converts to torch.Tensor\"\"\"",
            "+    \"\"\"Load the image with OpenCV and converts to torch.Tensor.\"\"\"",
            "if not os.path.isfile(file_name):",
            "raise AssertionError(f\"Invalid file {file_name}\")"
        ],
        "comments": "typo fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 4,
        "label": "no",
        "change": [
            "class TrainerIntegrationTest(unittest.TestCase):",
            "",
            "# Adding one column not used by the model should have no impact",
            "z = np.random.normal(size=(64,)).astype(np.float32)",
            "-        train_dataset = nlp.Dataset.from_dict({\"input_x\": x, \"label\": y, \"extra\": z})",
            "+        train_dataset = datasets.Dataset.from_dict({\"input_x\": x, \"label\": y, \"extra\": z})",
            "model = RegressionModel()",
            "trainer = Trainer(model, args, train_dataset=train_dataset)",
            "trainer.train()"
        ],
        "comments": "change class",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 5,
        "label": "no",
        "change": [
            "class AlbertEmbeddings(nn.Module):",
            "# position_ids (1, len position emb) is contiguous in memory and exported when serialized",
            "self.register_buffer(\"position_ids\", torch.arange(config.max_position_embeddings).expand((1, -1)))",
            "self.position_embedding_type = getattr(config, \"position_embedding_type\", \"absolute\")",
            "-        if version.parse(torch.__version__) > version.parse(\"1.6.0\"):",
            "+        if is_torch_greater_than_1_6:",
            "self.register_buffer(",
            "\"token_type_ids\",",
            "torch.zeros(self.position_ids.size(), dtype=torch.long),"
        ],
        "comments": "add condition check for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 6,
        "label": "no",
        "change": [
            "def sort_batch_by_length(tensor: torch.autograd.Variable, sequence_lengths: torc",
            "index_range = Variable(index_range.long())",
            "_, reverse_mapping = permutation_index.sort(0, descending=False)",
            "restoration_indices = index_range.index_select(0, reverse_mapping)",
            "-    return sorted_tensor, sorted_sequence_lengths, restoration_indices",
            "+    return sorted_tensor, sorted_sequence_lengths, restoration_indices, permutation_index",
            "",
            "",
            "def get_dropout_mask(dropout_probability: float, tensor_for_masking: torch.autograd.Variable):"
        ],
        "comments": "no API used",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 7,
        "label": "no",
        "change": [
            "def test_quantile():",
            "",
            "",
            "def test_pi():",
            "-    x = torch.empty(1000).log_normal_(0, 1)",
            "+    x = torch.randn(1000).exp()",
            "assert_equal(pi(x, prob=0.8), quantile(x, probs=[0.1, 0.9]))"
        ],
        "comments": "change API call for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 8,
        "label": "no",
        "change": [
            "class TPUAccelerator(Accelerator):",
            "Return:",
            "A tensor of shape (world_size, batch, ...)",
            "\"\"\"",
            "-        return xm.all_gather(tensor, group=group, sync_grads=sync_grads)",
            "+        # todo: Add support for backward with all_gather",
            "+        if torch.distributed.is_initialized():",
            "+            return xm.all_gather(tensor, group=group, sync_grads=sync_grads)",
            "+        return tensor"
        ],
        "comments": "add condition check for state fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 9,
        "label": "no",
        "change": [
            "class Swinv2SelfAttention(nn.Module):",
            "query_layer = self.transpose_for_scores(mixed_query_layer)",
            "",
            "# cosine attention",
            "-        attention_scores = F.normalize(query_layer, dim=-1) @ F.normalize(key_layer, dim=-1).transpose(-2, -1)",
            "+        attention_scores = nn.functional.normalize(query_layer, dim=-1) @ nn.functional.normalize(",
            "+            key_layer, dim=-1",
            "+        ).transpose(-2, -1)",
            "logit_scale = torch.clamp(self.logit_scale, max=math.log(1.0 / 0.01)).exp()",
            "attention_scores = attention_scores * logit_scale",
            "relative_position_bias_table = self.continuous_position_bias_mlp(self.relative_coords_table).view("
        ],
        "comments": "change class name",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 10,
        "label": "no",
        "change": [
            "def main(opt):",
            "",
            "else:",
            "weights = opt.weights if isinstance(opt.weights, list) else [opt.weights]",
            "-        opt.half = True  # FP16 for fastest results",
            "+        opt.half = torch.cuda.is_available() and opt.device != 'cpu'  # FP16 for fastest results",
            "if opt.task == 'speed':  # speed benchmarks",
            "# python val.py --task speed --data coco.yaml --batch 1 --weights yolov5n.pt yolov5s.pt...",
            "opt.conf_thres, opt.iou_thres, opt.save_json = 0.25, 0.45, False"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 11,
        "label": "no",
        "change": [
            "class TorchHook:",
            "if type(native_func) in [types.FunctionType, types.BuiltinFunctionType]:",
            "# 3. Build the hooked function",
            "new_func = self.get_hooked_func(native_func)",
            "-                # 4. Move the native function to its original module",
            "-                # /!\\ Can be different from the torch_module!",
            "-                # Ex: in torch.py `torch.argmax = torch.functional.argmax`",
            "-                # ... So torch.argmax.__module__ is 'torch.functional' != 'torch'",
            "-                setattr(eval(native_func.__module__), f\"native_{func}\", native_func)",
            "+                # 4. Move the native function",
            "+                setattr(torch_module, f\"native_{func}\", native_func)",
            "# 5. Put instead the hooked one",
            "setattr(torch_module, func, new_func)"
        ],
        "comments": "revert the fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 12,
        "label": "no",
        "change": [
            "def get_rotation_matrix2d(",
            "",
            "# create output tensor",
            "batch_size: int = center.shape[0]",
            "-    one = torch.tensor(1.).to(center.device)",
            "+    one = torch.tensor(1., device=center.device, dtype=center.dtype)",
            "M: torch.Tensor = torch.zeros(",
            "batch_size, 2, 3, device=center.device, dtype=center.dtype)",
            "M[..., 0:2, 0:2] = scaled_rotation"
        ],
        "comments": "add param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 14,
        "label": "no",
        "change": [
            "def lightning_loop(MODEL, num_runs=10, num_epochs=10):",
            "early_stop_callback=False,",
            "checkpoint_callback=False,",
            "distributed_backend='dp',",
            "+            deterministic=True,",
            ")",
            "trainer.fit(model)"
        ],
        "comments": "add param for argument fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 15,
        "label": "no",
        "change": [
            "class Trainer(TrainerBase):",
            "break",
            "sys.stdout.flush()",
            "",
            "-        model.load_state_dict(torch.load(best_model_path))",
            "+        if rank == 0:",
            "+            model.load_state_dict(torch.load(best_model_path))",
            "return model, best_metric",
            "",
            "def _run_epoch("
        ],
        "comments": "add condition check for state fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 16,
        "label": "no",
        "change": [
            "def test_preprocess_weights_for_loading_gru_incompatible():",
            "",
            "def assert_not_compatible(src, dest, message):",
            "with pytest.raises(ValueError) as ex:",
            "-            keras.engine.topology.preprocess_weights_for_loading(",
            "+            keras.engine.saving.preprocess_weights_for_loading(",
            "dest, initialize_weights(src).get_weights())",
            "assert message in ex.value.message"
        ],
        "comments": "change class name",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 17,
        "label": "no",
        "change": [
            "Returns:",
            "\"\"\"",
            "",
            "",
            "-class BERTScore(nlp.Metric):",
            "+class BERTScore(datasets.Metric):",
            "def _info(self):",
            "-        return nlp.MetricInfo(",
            "+        return datasets.MetricInfo(",
            "description=_DESCRIPTION,",
            "citation=_CITATION,",
            "homepage=\"https://github.com/Tiiiger/bert_score\",",
            "inputs_description=_KWARGS_DESCRIPTION,",
            "-            features=nlp.Features(",
            "+            features=datasets.Features(",
            "{",
            "-                    \"predictions\": nlp.Value(\"string\", id=\"sequence\"),",
            "-                    \"references\": nlp.Sequence(nlp.Value(\"string\", id=\"sequence\"), id=\"references\"),",
            "+                    \"predictions\": datasets.Value(\"string\", id=\"sequence\"),",
            "+                    \"references\": datasets.Sequence(datasets.Value(\"string\", id=\"sequence\"), id=\"references\"),",
            "}",
            "),",
            "codebase_urls=[\"https://github.com/Tiiiger/bert_score\"],"
        ],
        "comments": "change class name",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 18,
        "label": "no",
        "change": [
            "class CoarseMaskHead(FCNMaskHead):",
            "for i in range(num_fcs):",
            "fc_in_channels = (",
            "last_layer_dim if i == 0 else self.fc_out_channels)",
            "-            self.fcs.append(nn.Linear(fc_in_channels, self.fc_out_channels))",
            "+            self.fcs.append(Linear(fc_in_channels, self.fc_out_channels))",
            "last_layer_dim = self.fc_out_channels",
            "output_channels = self.num_classes * self.output_area",
            "-        self.fc_logits = nn.Linear(last_layer_dim, output_channels)",
            "+        self.fc_logits = Linear(last_layer_dim, output_channels)",
            "",
            "def init_weights(self):",
            "for m in self.fcs.modules():"
        ],
        "comments": "change class",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 19,
        "label": "no",
        "change": [
            "def test_load_from_disk_with_default_in_memory(",
            "current_dataset_size = 512  # arrow file size = 512, in-memory dataset size = 148",
            "if max_in_memory_dataset_size == \"default\":",
            "# default = 250 * 2 ** 20",
            "-        max_in_memory_dataset_size = datasets.config.HF_MAX_IN_MEMORY_DATASET_SIZE_IN_BYTES",
            "+        max_in_memory_dataset_size = datasets.config.IN_MEMORY_MAX_SIZE",
            "else:",
            "-        monkeypatch.setattr(datasets.config, \"HF_MAX_IN_MEMORY_DATASET_SIZE_IN_BYTES\", max_in_memory_dataset_size)",
            "+        monkeypatch.setattr(datasets.config, \"IN_MEMORY_MAX_SIZE\", max_in_memory_dataset_size)",
            "if max_in_memory_dataset_size:",
            "expected_in_memory = current_dataset_size < max_in_memory_dataset_size",
            "else:"
        ],
        "comments": "style fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 21,
        "label": "no",
        "change": [
            "class SequenceTagger(flair.nn.DefaultClassifier):",
            "for sentence in batch:",
            "sentence.remove_labels(label_name)",
            "",
            "-            loss = self._calculate_loss(features, gold_labels)",
            "-",
            "if return_loss:",
            "+                loss = self._calculate_loss(features, gold_labels)",
            "overall_loss += loss[0]",
            "label_count += loss[1]"
        ],
        "comments": "remove constraint",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 23,
        "label": "no",
        "change": [
            "class TacotronTrainTest(unittest.TestCase):",
            "optimizer = optim.Adam(model.parameters(), lr=c.lr)",
            "for i in range(5):",
            "mel_out, linear_out, align, stop_tokens = model.forward(",
            "-                input, input_lengths, mel_spec)",
            "+                input, input_lengths, mel_spec, speaker_ids)",
            "optimizer.zero_grad()",
            "loss = criterion(mel_out, mel_spec, mel_lengths)",
            "stop_loss = criterion_st(stop_tokens, stop_targets)"
        ],
        "comments": "add param for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 24,
        "label": "no",
        "change": [
            "def evaluate(args, model, tokenizer, prefix=\"\", test=False):",
            "eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)",
            "",
            "# multi-gpu evaluate",
            "-        if args.n_gpu > 1:",
            "+        if args.n_gpu > 1 and not isinstance(model, torch.nn.DataParallel):",
            "model = torch.nn.DataParallel(model)",
            "",
            "# Eval!"
        ],
        "comments": "add condition check for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 25,
        "label": "no",
        "change": [
            "class TestMotionBlur:",
            ") -> torch.Tensor:",
            "return kornia.filters.motion_blur(input, ksize, angle, direction)",
            "",
            "-        img = torch.rand(2, 3, 4, 5)",
            "+        img = torch.rand(2, 3, 4, 5).to(device)",
            "ksize = 5",
            "angle = 65.",
            "direction = .1"
        ],
        "comments": "add API call for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 26,
        "label": "no",
        "change": [
            "class DiTPipelineIntegrationTests(unittest.TestCase):",
            "\"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main\"",
            "f\"/dit/{word}_fp16.npy\"",
            ")",
            "-            assert np.abs((expected_image - image).max()) < 1e-2",
            "+",
            "+            assert np.abs((expected_image - image).max()) < 7.5e-1"
        ],
        "comments": "update number",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 30,
        "label": "no",
        "change": [
            "class _Seq2VecWrapper:",
            "def from_params(self, params: Params) -> PytorchSeq2VecWrapper:",
            "if not params.pop('batch_first', True):",
            "raise ConfigurationError(\"Our encoder semantics assumes batch is always first!\")",
            "-        params['batch_first'] = True",
            "+        if self._module_class in self.PYTORCH_MODELS:",
            "+            params['batch_first'] = True",
            "module = self._module_class(**params.as_dict())",
            "return PytorchSeq2VecWrapper(module)"
        ],
        "comments": "add condition check for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 31,
        "label": "yes",
        "change": [
            "class StableDiffusionProcessingTxt2Img(StableDiffusionProcessing):",
            "return samples",
            "",
            "x = create_random_tensors([opt_C, self.firstphase_height // opt_f, self.firstphase_width // opt_f], seeds=seeds, subseeds=subseeds, subseed_strength=self.subseed_strength, seed_resize_from_h=self.seed_resize_from_h, seed_resize_from_w=self.seed_resize_from_w, p=self)",
            "-        samples = self.sampler.sample(self, x, conditioning, unconditional_conditioning, image_conditioning=self.create_dummy_mask(x))",
            "+        samples = self.sampler.sample(self, x, conditioning, unconditional_conditioning, image_conditioning=self.create_dummy_mask(x, first_phase=True))",
            "",
            "samples = samples[:, :, self.truncate_y//2:samples.shape[2]-self.truncate_y//2, self.truncate_x//2:samples.shape[3]-self.truncate_x//2]"
        ],
        "comments": "add param for argument fix",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 32,
        "label": "no",
        "change": [
            "def sort_batch_by_length(tensor: torch.autograd.Variable, sequence_lengths: torc",
            "sorted_tensor = tensor.index_select(0, permutation_index)",
            "# This is the equivalent of zipping with index, sorting by the original",
            "# sequence lengths and returning the now sorted indices.",
            "-    index_range = Variable(torch.range(0, len(sequence_lengths) - 1).long())",
            "+    index_range = Variable(torch.arange(0, len(sequence_lengths)).long())",
            "_, reverse_mapping = permutation_index.sort(0, descending=False)",
            "restoration_indices = index_range.index_select(0, reverse_mapping)",
            "return sorted_tensor, sorted_sequence_lengths, restoration_indices"
        ],
        "comments": "change API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 33,
        "label": "no",
        "change": [
            "class LabelSmoothing(nn.Module):",
            "self.normalize_length = normalize_length",
            "",
            "def forward(self, x, target):",
            "+        \"\"\"Compute loss between x and target",
            "+",
            "+        :param torch.Tensor x: prediction (batch, seqlen, class)",
            "+        :param torch.Tensor target: target signal masked with self.padding_id (batch, seqlen)",
            "+        :return: scalar float value",
            "+        :rtype torch.Tensor",
            "+        \"\"\"",
            "assert x.size(2) == self.size",
            "batch_size = x.size(0)",
            "x = x.view(-1, self.size)"
        ],
        "comments": "doc fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 34,
        "label": "no",
        "change": [
            "class BaseModel(nn.Module):",
            "\"\"\"",
            "logging.error('You must define a forward method for this model')",
            "pass",
            "-",
            "-",
            "-",
            "-",
            "-"
        ],
        "comments": "no fix found",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 35,
        "label": "no",
        "change": [
            "class Pointclouds:",
            "self._compute_packed()",
            "return self._cloud_to_packed_first_idx",
            "",
            "-    def num_points_per_cloud(self):",
            "+    def num_points_per_cloud(self) -> torch.Tensor:",
            "\"\"\"",
            "Return a 1D tensor x with length equal to the number of clouds giving",
            "the number of points in each cloud."
        ],
        "comments": "no API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 37,
        "label": "no",
        "change": [
            "from keras.datasets import mnist",
            "from autokeras import ImageClassifier",
            "+import tensorflow",
            "",
            "if __name__ == '__main__':",
            "+    print(tensorflow.__version__)",
            "(x_train, y_train), (x_test, y_test) = mnist.load_data()",
            "-    x_train = x_train.reshape(x_train.shape + (1,))",
            "-    x_test = x_test.reshape(x_test.shape + (1,))",
            "-",
            "+    x_train = x_train.reshape(x_train.shape+(1,))",
            "+    x_test = x_test.reshape(x_test.shape+(1,))",
            "clf = ImageClassifier(verbose=True, augment=False)",
            "clf.fit(x_train, y_train, time_limit=12 * 60 * 60)",
            "clf.final_fit(x_train, y_train, x_test, y_test, retrain=True)"
        ],
        "comments": "typo fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 38,
        "label": "no",
        "change": [
            "class DiffusionPriorNetwork(nn.Module):",
            "",
            "null_text_embeds = self.null_text_embeds.to(text_embed.dtype)",
            "",
            "-        text_embeds = torch.where(",
            "+        text_embed = torch.where(",
            "text_keep_mask,",
            "text_embed,",
            "null_text_embeds"
        ],
        "comments": "typo fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 39,
        "label": "no",
        "change": [
            "class TempSeedTest(TestCase):",
            "import tensorflow as tf",
            "from tensorflow.keras import layers",
            "",
            "+        model = layers.Dense(2)",
            "+",
            "def gen_random_output():",
            "-            model = layers.Dense(2)",
            "x = tf.random.uniform((1, 3))",
            "return model(x).numpy()"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 40,
        "label": "no",
        "change": [
            "def makenp(x, modality=None):",
            "",
            "def pytorch_np(x, modality):",
            "import torch",
            "-    if isinstance(x, torch.autograd.variable.Variable):",
            "+    if isinstance(x, torch.autograd.Variable):",
            "x = x.data",
            "x = x.cpu().numpy()",
            "if modality == 'IMG':"
        ],
        "comments": "update param for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 41,
        "label": "no",
        "change": [
            "class T5Attention(nn.Module):",
            "is_small = relative_position < max_exact",
            "",
            "# The other half of the buckets are for logarithmically bigger bins in positions up to max_distance",
            "-        relative_postion_if_large = max_exact + (",
            "+        relative_position_if_large = max_exact + (",
            "torch.log(relative_position.float() / max_exact)",
            "/ math.log(max_distance / max_exact)",
            "* (num_buckets - max_exact)",
            ").to(torch.long)",
            "-        relative_postion_if_large = torch.min(",
            "-            relative_postion_if_large, torch.full_like(relative_postion_if_large, num_buckets - 1)",
            "+        relative_position_if_large = torch.min(",
            "+            relative_position_if_large, torch.full_like(relative_position_if_large, num_buckets - 1)",
            ")",
            "",
            "-        relative_buckets += torch.where(is_small, relative_position, relative_postion_if_large)",
            "+        relative_buckets += torch.where(is_small, relative_position, relative_position_if_large)",
            "return relative_buckets",
            "",
            "def compute_bias(self, query_length, key_length):"
        ],
        "comments": "add log",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 43,
        "label": "no",
        "change": [
            "class TrainingTypePlugin(ABC):",
            "self.lr_schedulers = schedulers",
            "",
            "def _move_optimizer_state(self, device: Optional[torch.device] = None) -> None:",
            "-        \"\"\"Moves the state of the optimizers to the GPU if needed.\"\"\"",
            "-        device = device or self.root_device",
            "+        \"\"\"Moves the state of the optimizers to the appropriate device if needed.\"\"\"",
            "for opt in self.optimizers:",
            "for p, v in opt.state.items():",
            "-                opt.state[p] = apply_to_collection(v, torch.Tensor, move_data_to_device, device)",
            "+                # `self.root_device` would raise error if called outside the spawn process",
            "+                # while training on 8 and more cores.",
            "+                opt.state[p] = apply_to_collection(v, torch.Tensor, move_data_to_device, device or self.root_device)",
            "",
            "def optimizer_state(self, optimizer: Optimizer) -> Dict[str, Tensor]:",
            "\"\"\"Returns state of an optimizer."
        ],
        "comments": "change param for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 45,
        "label": "no",
        "change": [
            "class ImageSegmentationPipelineTests(unittest.TestCase, metaclass=PipelineTestCa",
            "",
            "import datasets",
            "",
            "-        dataset = datasets.load_dataset(\"Narsil/image_dummy\", \"image\", split=\"test\")",
            "+        dataset = datasets.load_dataset(\"hf-internal-testing/fixtures_image_utils\", \"image\", split=\"test\")",
            "",
            "batch = [",
            "Image.open(\"./tests/fixtures/tests_samples/COCO/000000039769.png\"),"
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 47,
        "label": "no",
        "change": [
            "class NerNetwork:",
            "return predictions_batch_no_pad",
            "",
            "def shutdown(self):",
            "-        self._sess.close()",
            "\\ No newline at end of file",
            "+        self._sess.close()"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 49,
        "label": "no",
        "change": [
            "class LayerNorm(torch.nn.Module):",
            "self.beta = torch.nn.Parameter(torch.zeros(dimension))",
            "self.eps = eps",
            "",
            "-    def forward(self, tensor: torch.Tensor):  # pylint: disable=arguments-differ",
            "+    def forward(self, tensor: torch.Tensor):",
            "mean = tensor.mean(-1, keepdim=True)",
            "std = tensor.std(-1, unbiased=False, keepdim=True)",
            "return self.gamma * (tensor - mean) / (std + self.eps) + self.beta"
        ],
        "comments": "remove comments",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 50,
        "label": "no",
        "change": [
            "class GraphConv(MessagePassing):",
            "self.lin.reset_parameters()",
            "",
            "def forward(self, x, edge_index):",
            "+        if isinstance(x, Tensor):",
            "+            x = (x, x)",
            "return self.propagate(edge_index, x=(self.lin(x[0]), x[1]))"
        ],
        "comments": "add condition check for shape fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 51,
        "label": "no",
        "change": [
            "def resnet_argscope():",
            "with argscope([Conv2D, MaxPooling, BatchNorm], data_format='NCHW'), \\",
            "argscope(Conv2D, use_bias=False), \\",
            "argscope(BatchNorm, use_local_stat=False), \\",
            "-            tf.variable_scope(tf.get_variable_scope(),",
            "-                              custom_getter=maybe_freeze_affine):",
            "+            custom_getter_scope(maybe_freeze_affine):",
            "yield"
        ],
        "comments": "version fix to fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 53,
        "label": "yes",
        "change": [
            "class Trainer:",
            ").to(self.args.device)",
            "",
            "elif is_sagemaker_dp_enabled():",
            "-            model = DDP(model, device_ids=[dist.get_local_rank()], broadcast_buffers=False)",
            "+            model = nn.parallel.DistributedDataParallel(",
            "+                model, device_ids=[int(os.getenv(\"SMDATAPARALLEL_LOCAL_RANK\"))]",
            "+            )",
            "elif self.args.local_rank != -1:",
            "kwargs = {}",
            "if self.args.ddp_find_unused_parameters is not None:"
        ],
        "comments": "update API call for version fix",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 54,
        "label": "no",
        "change": [
            "class Network(object):",
            "\"\"\"",
            "@layer",
            "def softmax(self, target, axis, name=None):",
            "-        max_axis = tf.reduce_max(target, axis, keepdims=True)",
            "+        max_axis = tf.reduce_max(target, axis, keep_dims=True)",
            "target_exp = tf.exp(target-max_axis)",
            "-        normalize = tf.reduce_sum(target_exp, axis, keepdims=True)",
            "+        normalize = tf.reduce_sum(target_exp, axis, keep_dims=True)",
            "softmax = tf.div(target_exp, normalize, name)",
            "return softmax"
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 55,
        "label": "no",
        "change": [
            "class RNN(torch.nn.Module):",
            "if not isinstance(ilens, torch.Tensor):",
            "ilens = torch.tensor(ilens)",
            "xs_pack = pack_padded_sequence(xs_pad, ilens.cpu(), batch_first=True)",
            "-        self.nbrnn.flatten_parameters()",
            "+        if self.training:",
            "+            self.nbrnn.flatten_parameters()",
            "if prev_state is not None and self.nbrnn.bidirectional:",
            "# We assume that when previous state is passed,",
            "# it means that we're streaming the input"
        ],
        "comments": "add condition check for state fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 56,
        "label": "no",
        "change": [
            "class TFXLNetModelTest(TFModelTesterMixin, unittest.TestCase):",
            "# Send to model",
            "loss = model(tuple_input[:-1])[0]",
            "",
            "-                self.assertEqual(loss.shape, [loss_size])",
            "+                self.assertEqual(loss.shape.as_list(), expected_loss_size)",
            "",
            "",
            "@require_tf"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 58,
        "label": "no",
        "change": [
            "def sigmoid_example(design):",
            "torch.tensor([[-1.5, 0.5], [1.5, 0.]])",
            "),",
            "(",
            "-        known_covariance_linear_model(torch.tensor([1., -1.]), torch.tensor(10.), torch.tensor(1.)),",
            "+        known_covariance_linear_model(torch.tensor([1., -1.]), torch.tensor([10., 10.]), torch.tensor(1.)),",
            "nz_lm_2p_10_10_1,",
            "torch.tensor([[-1., 0.5], [2.5, -2.]])",
            "),"
        ],
        "comments": "change param for shape fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 59,
        "label": "no",
        "change": [
            "class DetaModel(DetaPreTrainedModel):",
            "scale = 2 * math.pi",
            "",
            "dim_t = torch.arange(num_pos_feats, dtype=torch.float32, device=proposals.device)",
            "-        dim_t = temperature ** (2 * (dim_t // 2) / num_pos_feats)",
            "+        dim_t = temperature ** (2 * torch.div(dim_t, 2) / num_pos_feats)",
            "# batch_size, num_queries, 4",
            "proposals = proposals.sigmoid() * scale",
            "# batch_size, num_queries, 4, 128"
        ],
        "comments": "add API call for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 61,
        "label": "no",
        "change": [
            "class LxmertAttention(nn.Module):",
            "attention_scores = attention_scores + attention_mask",
            "",
            "# Normalize the attention scores to probabilities.",
            "-        attention_probs = nn.Softmax(dim=-1)(attention_scores)",
            "+        attention_probs = nn.functional.softmax(attention_scores, dim=-1)",
            "",
            "# This is actually dropping out entire tokens to attend to, which might",
            "# seem a bit unusual, but is taken from the original Transformer paper."
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 63,
        "label": "no",
        "change": [
            "def trace(",
            "axis2: int = 1,",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "-    ret = tf.experimental.numpy.trace(",
            "-        x, offset=offset, axis1=axis1, axis2=axis2",
            "-    )",
            "+    ret = tf.experimental.numpy.trace(x, offset=offset, axis1=axis1, axis2=axis2)",
            "return ret"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 65,
        "label": "no",
        "change": [
            "class TFOpenAIGPTDoubleHeadsModel(TFOpenAIGPTPreTrainedModel):",
            "training=False,",
            "):",
            "r\"\"\"",
            "-        mc_token_ids (:obj:`tf.Tensor` or :obj:`Numpy array` of shape :obj:`(batch_size, num_choices)`, `optional`, default to index of the last token of the input)",
            "+        mc_token_ids (:obj:`tf.Tensor` or :obj:`Numpy array` of shape :obj:`(batch_size, num_choices)`, `optional`, default to index of the last token of the input):",
            "Index of the classification token in each input sequence.",
            "Selected in the range ``[0, input_ids.size(-1) - 1]``."
        ],
        "comments": "fix doc",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 66,
        "label": "no",
        "change": [
            "class DynamicConvolution2D(nn.Module):",
            "weight = self.linear_weight(x)  # B x T x kH",
            "weight = F.dropout(weight, self.dropout_rate, training=self.training)",
            "weight = weight.view(B, T, H, k).transpose(1, 2).contiguous()  # B x H x T x k",
            "-        weight_new = torch.zeros(B * H * T * (T + k - 1)).view(B, H, T, T + k - 1).fill_(float('-inf'))",
            "+        weight_new = torch.zeros(B * H * T * (T + k - 1), dtype=weight.dtype)",
            "+        weight_new = weight_new.view(B, H, T, T + k - 1).fill_(float('-inf'))",
            "weight_new = weight_new.to(x.device)  # B x H x T x T+k-1",
            "weight_new.as_strided((B, H, T, k), ((T + k - 1) * T * H, (T + k - 1) * T, T + k, 1)).copy_(weight)",
            "weight_new = weight_new.narrow(-1, int((k - 1) / 2), T)  # B x H x T x T(k)"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 67,
        "label": "no",
        "change": [
            "def test_ddp_sharded_plugin_correctness_multi_gpu():",
            "run_sharded_correctness(gpus=2, accelerator='ddp_spawn')",
            "",
            "",
            "-@pytest.mark.skipif(",
            "-    LooseVersion(torch.__version__) < LooseVersion(\"1.6.0\"),",
            "-    reason=\"Minimal PT version is set to 1.6\")",
            "+@pytest.mark.skipif(not NATIVE_AMP_AVALAIBLE, reason=\"Requires native AMP\")",
            "@pytest.mark.skipif(platform.system() == \"Windows\",",
            "reason=\"Distributed training is not supported on Windows\")",
            "@pytest.mark.skipif(torch.cuda.device_count() < 2, reason=\"test requires multi-GPU machine\")"
        ],
        "comments": "refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 68,
        "label": "no",
        "change": [
            "class Gru(TransformationBase):",
            "",
            "def tf_apply(self, x, sequence_length=None):",
            "x, state = tf.nn.dynamic_rnn(",
            "-            cell=self.cell, inputs=x, sequence_length=sequence_length, dtype=tf.float32,",
            "+            cell=self.cell, inputs=x, sequence_length=sequence_length, initial_state=None,",
            "+            dtype=util.tf_dtype(dtype='float'),",
            "# Weird TensorFlow behavior? (https://github.com/tensorflow/tensorflow/issues/15874)",
            "parallel_iterations=(self.input_spec['shape'][0] + 1)",
            ")"
        ],
        "comments": "add param for argument fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 69,
        "label": "no",
        "change": [
            "class Optimizer(Component):",
            "For those we treat model as max_norm.",
            "eg. optimizer.clip_grad_norm(max_norm)",
            "\"\"\"",
            "-            return torch.nn.utils.clip_grad_norm_(self.params, max_norm)",
            "+            return clip_grad_norm_(self.params, max_norm)",
            "else:",
            "-            return torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)",
            "+            return clip_grad_norm_(model.parameters(), max_norm)",
            "",
            "def pre_export(self, model):",
            "pass"
        ],
        "comments": "change API call place",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 70,
        "label": "no",
        "change": [
            "class Util_Predict_Test(CustomTestCase):",
            "",
            "if __name__ == '__main__':",
            "",
            "-    # tl.logging.set_verbosity(tl.logging.INFO)",
            "+    tf.logging.set_verbosity(tf.logging.DEBUG)",
            "tl.logging.set_verbosity(tl.logging.DEBUG)",
            "",
            "unittest.main()"
        ],
        "comments": "update logging",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 71,
        "label": "no",
        "change": [
            "class DeepSpeedSelfAttention(nn.Module):",
            "data_type_fp = torch.half if config.fp16 else torch.float",
            "self.config.layer_id = DeepSpeedSelfAttention.num_layers",
            "DeepSpeedSelfAttention.num_layers = DeepSpeedSelfAttention.num_layers + 1",
            "-        device = torch.cuda.current_device() if config.bigscience_bloom else 'cpu'",
            "+        device = torch.cuda.current_device()  #if config.bigscience_bloom else 'cpu'",
            "qkv_size_per_partition = (self.config.hidden_size // self.config.mp_size) * 3",
            "self.attn_qkvw = nn.Parameter(torch.empty(self.config.hidden_size,",
            "qkv_size_per_partition,"
        ],
        "comments": "remove condition check for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 73,
        "label": "no",
        "change": [
            "class TestClosing:",
            "None, None, :, :",
            "]",
            "assert_allclose(",
            "-            closing(tensor, torch.ones_like(structural_element), structuring_element=structural_element), expected,",
            "-            atol=1e-4, rtol=1e-4",
            "+            closing(tensor, torch.ones_like(structural_element), structuring_element=structural_element),",
            "+            expected,",
            "+            atol=1e-4,",
            "+            rtol=1e-4,",
            ")",
            "",
            "def test_exception(self, device, dtype):"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 74,
        "label": "no",
        "change": [
            "class TorchCategorical(TorchDistributionWrapper):",
            "@override(ActionDistribution)",
            "def __init__(self, inputs, model=None, temperature=1.0):",
            "assert temperature > 0.0, \"Categorical `temperature` must be > 0.0!\"",
            "-        super().__init__(inputs / temperature, model)",
            "+        inputs /= temperature",
            "+        super().__init__(inputs, model)",
            "self.dist = torch.distributions.categorical.Categorical(",
            "logits=self.inputs)"
        ],
        "comments": "version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 75,
        "label": "no",
        "change": [
            "def attention(inputs, state, att_size, mask, scope=\"attention\"):",
            "\"\"\"Computes weighted sum of inputs conditioned on state\"\"\"",
            "with tf.variable_scope(scope):",
            "u = tf.concat([tf.tile(tf.expand_dims(state, axis=1), [1, tf.shape(inputs)[1], 1]), inputs], axis=2)",
            "-        logits = tf.layers.dense(tf.layers.dense(u, att_size, activation=tf.nn.sigmoid), 1, use_bias=False)",
            "+        logits = tf.layers.dense(tf.layers.dense(u, att_size, activation=tf.nn.tanh), 1, use_bias=False)",
            "logits = softmax_mask(tf.squeeze(logits, [2]), mask)",
            "att_weights = tf.expand_dims(tf.nn.softmax(logits), axis=2)",
            "res = tf.reduce_sum(att_weights * inputs, axis=1)"
        ],
        "comments": "change funtional",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 76,
        "label": "no",
        "change": [
            "def main(args):",
            "bob_decision = Marginal(Search(bob))",
            "",
            "# Here Alice and Bob slightly prefer one location over the other a priori",
            "-    shared_preference = Variable(torch.Tensor([args.preference]))",
            "+    shared_preference = torch.tensor([args.preference])",
            "",
            "bob_depth = args.depth",
            "num_samples = args.num_samples"
        ],
        "comments": "remove API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 77,
        "label": "no",
        "change": [
            "if torch.backends.cudnn.version() >= 7603:",
            "#",
            "# Channels Last support not limited by existing models, as any model can be converted to Channels Last and propagate format through the graph as soon as input formatted correctly.",
            "#",
            "-input = input.to(memory_format=torch.channels_last)",
            "-model = model.to(memory_format=torch.channels_last)",
            "+",
            "+# Need to be done once, after model initialization (or load)",
            "+model = model.to(memory_format=torch.channels_last) # Replace with your model",
            "+",
            "+# Need to be done for every input",
            "+input = input.to(memory_format=torch.channels_last) # Replace with your input",
            "output = model(input)",
            "",
            "#######################################################################"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 79,
        "label": "no",
        "change": [
            "def time_distributed(incoming, fn, args=None, scope=None):",
            "else:",
            "x = [fn(x[i], *args) for i in range(timestep)]",
            "x = map(lambda t: tf.reshape(t, [-1, 1]+utils.get_incoming_shape(t)[1:]), x)",
            "-    return tf.concat(1, x)",
            "\\ No newline at end of file",
            "+    return tf.concat(1, x)"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 81,
        "label": "no",
        "change": [
            "class Planetoid(Dataset):",
            "# Create unweighted sparse adjacency matrix.",
            "weight = torch.ones(index.size(1))",
            "n = input.size(0)",
            "-        adj = torch.sparse.FloatTensor(index, weight, torch.Size([n, n]))",
            "+        adj = SparseTensor(index, weight, torch.Size([n, n]))",
            "",
            "# Bundle graph to data object.",
            "-        self.data = Data(input, adj, position=None, target=target)",
            "+        self.data = Data(input, adj, position=None, target=target.long())",
            "",
            "def __getitem__(self, index):",
            "data = self.data"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 84,
        "label": "no",
        "change": [
            "class Tacotron2(TTSInterface, torch.nn.Module):",
            "",
            "def __init__(self, idim, odim, args):",
            "super(Tacotron2, self).__init__()",
            "+        torch.nn.Module.__init__(self)",
            "# store hyperparameters",
            "self.idim = idim",
            "self.odim = odim"
        ],
        "comments": "add API call for state fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 85,
        "label": "no",
        "change": [
            "\"import sys\\n\",",
            "\"sys.path.append(f'{os.getcwd()}/SentEval')\\n\",",
            "\"\\n\",",
            "-        \"import tensorflow_hub as hub\\n\",",
            "\"import tensorflow as tf\\n\",",
            "+        \"\\n\",",
            "+        \"# Prevent TF from claiming all GPU memory so there is some left for pytorch.\\n\",",
            "+        \"gpus = tf.config.list_physical_devices('GPU')\\n\",",
            "+        \"if gpus:\\n\",",
            "+        \"  # Memory growth needs to be the same across GPUs.\\n\",",
            "+        \"  for gpu in gpus:\\n\",",
            "+        \"    tf.config.experimental.set_memory_growth(gpu, True)\\n\",",
            "+        \"\\n\",",
            "+        \"import tensorflow_hub as hub\\n\",",
            "\"import tensorflow_text\\n\",",
            "\"import senteval\\n\",",
            "\"import time\\n\","
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 86,
        "label": "no",
        "change": [
            "class Encoder(torch.nn.Module):",
            "self.embed = Conv2dSubsampling(idim, attention_dim, dropout_rate)",
            "elif input_layer == \"embed\":",
            "self.embed = torch.nn.Sequential(",
            "-                torch.nn.Embedding(idim, attention_dim),",
            "+                torch.nn.Embedding(idim, attention_dim, padding_idx=padding_idx),",
            "pos_enc_class(attention_dim, positional_dropout_rate)",
            ")",
            "elif isinstance(input_layer, torch.nn.Module):"
        ],
        "comments": "add param for argument fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 88,
        "label": "no",
        "change": [
            "def create_checkerboard(h, w, nw):",
            "",
            "",
            "# TODO: Isn't this function duplicated with eye_like?",
            "-def create_eye_batch(batch_size, eye_size):",
            "+def create_eye_batch(batch_size, eye_size, device=None, dtype=None):",
            "\"\"\"Creates a batch of identity matrices of shape Bx3x3",
            "\"\"\"",
            "-    return torch.eye(eye_size).view(",
            "+    return torch.eye(eye_size, device=device, dtype=dtype).view(",
            "1, eye_size, eye_size).expand(batch_size, -1, -1)"
        ],
        "comments": "add param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 91,
        "label": "no",
        "change": [
            "class TransformerSeparator(AbsSeparator):",
            "",
            "# if complex spectrum,",
            "if isinstance(input, ComplexTensor) or (",
            "-            is_torch_1_8_plus and torch.is_complex(input)",
            "+            is_torch_1_9_plus and torch.is_complex(input)",
            "):",
            "feature = abs(input)",
            "else:"
        ],
        "comments": "change condition check for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 92,
        "label": "no",
        "change": [
            "class PipelineTesterMixin(unittest.TestCase):",
            "image_slice = image[0, -1, -3:, -3:].cpu()",
            "",
            "assert image.shape == (1, 3, 32, 32)",
            "-        expected_slice = torch.tensor([-0.5712, -0.6215, -0.5953, -0.5438, -0.4775, -0.4539, -0.5172, -0.4872, -0.5105])",
            "+        expected_slice = torch.tensor(",
            "+            [-0.5712, -0.6215, -0.5953, -0.5438, -0.4775, -0.4539, -0.5172, -0.4872, -0.5105]",
            "+        )",
            "assert (image_slice.flatten() - expected_slice).abs().max() < 1e-2",
            "",
            "@slow"
        ],
        "comments": "math param update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 93,
        "label": "no",
        "change": [
            "class DNAConv(MessagePassing):",
            "num_edges = edge_index.size(1)",
            "",
            "edge_index, edge_weight = gcn_norm(edge_index, x.size(self.node_dim),",
            "-                                           edge_weight, self.improved, x.dtype)",
            "+                                           edge_weight, dtype=x.dtype)",
            "",
            "if self.cached:",
            "self._cache = (num_edges, edge_index, edge_weight)"
        ],
        "comments": "not clear",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 94,
        "label": "no",
        "change": [
            "class T5Attention(nn.Module):",
            "position_bias = position_bias + mask  # (batch_size, n_heads, seq_length, key_length)",
            "",
            "scores += position_bias",
            "-        attn_weights = F.softmax(scores.float(), dim=-1).type_as(",
            "+        attn_weights = nn.functional.softmax(scores.float(), dim=-1).type_as(",
            "scores",
            ")  # (batch_size, n_heads, seq_length, key_length)",
            "-        attn_weights = F.dropout(",
            "+        attn_weights = nn.functional.dropout(",
            "attn_weights, p=self.dropout, training=self.training",
            ")  # (batch_size, n_heads, seq_length, key_length)"
        ],
        "comments": "API update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 95,
        "label": "no",
        "change": [
            "class PyTorchDistributed(L.LightningWork):",
            ")",
            "",
            "",
            "-# 32 GPUs: (8 nodes x 4 v 100)",
            "+# 8 GPUs: (2 nodes x 4 v 100)",
            "compute = L.CloudCompute(\"gpu-fast-multi\")  # 4xV100",
            "component = MultiNode(PyTorchDistributed, num_nodes=2, cloud_compute=compute)",
            "app = L.LightningApp(component)"
        ],
        "comments": "update doc",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 97,
        "label": "yes",
        "change": [
            "def _get_ort_session_options() -> ort.SessionOptions:",
            "if not torch.cuda.is_available():",
            "sess_options.execution_mode = ort.ExecutionMode.ORT_PARALLEL",
            "sess_options.inter_op_num_threads = 1",
            "-        sess_options.intra_op_num_threads = max(torch.get_num_threads(), 1)",
            "+        sess_options.intra_op_num_threads = max(",
            "+            int(",
            "+                os.environ.get(\"NEBULLVM_THREADS_PER_MODEL\")",
            "+                or torch.get_num_threads()",
            "+            ),",
            "+            1,",
            "+        )",
            "return sess_options"
        ],
        "comments": "add API call for type fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 98,
        "label": "no",
        "change": [
            "def save_best_model(model, optimizer, model_loss, best_loss, out_path,",
            "def check_update(model, grad_clip, grad_top):",
            "r'''Check model gradient against unexpected jumps and failures'''",
            "skip_flag = False",
            "-    grad_norm = torch.nn.utils.clip_grad_norm(model.parameters(), grad_clip)",
            "+    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)",
            "if np.isinf(grad_norm):",
            "print(\" | > Gradient is INF !!\")",
            "skip_flag = True"
        ],
        "comments": "typo fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 99,
        "label": "no",
        "change": [
            "def quaternion_exp_to_log(quaternion: torch.Tensor,",
            ">>> kornia.quaternion_exp_to_log(quaternion)",
            "tensor([0., 0., 0.])",
            "\"\"\"",
            "-    if not torch.is_tensor(quaternion):",
            "+    if not isinstance(quaternion, torch.Tensor):",
            "raise TypeError(\"Input type is not a torch.Tensor. Got {}\".format(",
            "type(quaternion)))"
        ],
        "comments": "add condition check for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 100,
        "label": "no",
        "change": [
            "class TFFlaubertMainLayer(tf.keras.layers.Layer):",
            "tensor_normalized = self.layer_norm2[i](tensor)",
            "tensor = tensor + self.ffns[i](tensor_normalized)",
            "",
            "-            tensor = tensor * mask[..., tf.newaxis]",
            "+            tensor = tensor * tf.expand_dims(mask, axis=-1)",
            "",
            "# Add last hidden state",
            "if inputs[\"output_hidden_states\"]:"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 101,
        "label": "no",
        "change": [
            "def _replace_global_by_local(kwargs):",
            "if 'collections' in kwargs:",
            "collections = kwargs['collections']",
            "if not collections:",
            "-        collections = set(tf.GraphKeys.GLOBAL_VARIABLES)",
            "+        collections = {tf.GraphKeys.GLOBAL_VARIABLES}",
            "else:",
            "collections = set(collections.copy())",
            "collections.remove(tf.GraphKeys.GLOBAL_VARIABLES)"
        ],
        "comments": "change API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 103,
        "label": "no",
        "change": [
            "class ReformerLayer(nn.Module):",
            "\"\"\"",
            "# randomize seeds",
            "# use cuda generator if available",
            "-        if len(torch.cuda.default_generators) > 0:",
            "+        if hasattr(torch.cuda, \"default_generators\") and len(torch.cuda.default_generators) > 0:",
            "# GPU",
            "device_idx = torch.cuda.current_device()",
            "self.feed_forward_seed = torch.cuda.default_generators[device_idx].seed()"
        ],
        "comments": "change condition check for null fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 104,
        "label": "yes",
        "change": [
            "def get_projective_transform(center: torch.Tensor, angles: torch.Tensor) -> torc",
            "",
            "# create rotation matrix",
            "angle_axis_rad: torch.Tensor = K.deg2rad(angles)",
            "-    rmat: torch.Tensor = K.angle_axis_to_rotation_matrix(angle_axis_rad)  # Bx3x3",
            "+    rmat: torch.Tensor = K.angle_axis_to_rotation_matrix(angle_axis_rad) * scales.view(-1, 1, 1)  # Bx3x3",
            "",
            "# define matrix to move forth and back to origin",
            "from_origin_mat = torch.eye(4)[None].repeat(rmat.shape[0], 1, 1).type_as(center)  # Bx4x4"
        ],
        "comments": "add API call for shape fix",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 105,
        "label": "no",
        "change": [
            "class FQETorchModel:",
            "q_values, _ = self.q_model({\"obs\": obs}, [], None)",
            "if actions is not None:",
            "actions = torch.tensor(actions, device=self.device, dtype=int)",
            "-            q_values = torch.gather(q_values, -1, actions.unsqueeze(-1)).squeeze()",
            "+            q_values = torch.gather(q_values, -1, actions.unsqueeze(-1)).squeeze(-1)",
            "return q_values.detach()",
            "",
            "def estimate_v("
        ],
        "comments": "add param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 106,
        "label": "no",
        "change": [
            "def decode(args):",
            "",
            "# define function for plot prob and att_ws",
            "def _plot_and_save(array, figname, figsize=(6, 4), dpi=150):",
            "+        import matplotlib",
            "+",
            "+        matplotlib.use(\"Agg\")",
            "import matplotlib.pyplot as plt",
            "",
            "shape = array.shape"
        ],
        "comments": "refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 107,
        "label": "yes",
        "change": [
            "class ModelCatalog:",
            "model_name (str): Name to register the model under.",
            "model_class (type): Python class of the model.",
            "\"\"\"",
            "-        if issubclass(model_class, tf.keras.Model):",
            "-            deprecation_warning(old=\"register_custom_model\", error=False)",
            "+        if tf is not None:",
            "+            if issubclass(model_class, tf.keras.Model):",
            "+                deprecation_warning(old=\"register_custom_model\", error=False)",
            "_global_registry.register(RLLIB_MODEL, model_name, model_class)",
            "",
            "@staticmethod"
        ],
        "comments": "add condition check for refactor fix",
        "Symptom": "return warning",
        "Root_Cause": "deprecation management error",
        "Action": "addition",
        "Element": "api condition check"
    },
    {
        "number": 109,
        "label": "no",
        "change": [
            "class DLA(nn.Module):",
            "if self.drop_rate > 0.:",
            "x = F.dropout(x, p=self.drop_rate, training=self.training)",
            "x = self.fc(x)",
            "-        if not self.global_pool.is_identity():",
            "-            x = x.flatten(1)  # conv classifier, flatten if pooling isn't pass-through (disabled)",
            "+        x = self.flatten(x)",
            "return x"
        ],
        "comments": "remove condition check for shape fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 110,
        "label": "no",
        "change": [
            "class OnlineLinearRegression(tf.Module if tf else object):",
            "x = tf.squeeze(x, axis=0)",
            "y = y[0]",
            "self.time += 1",
            "-        self.delta_f += y * x",
            "+        self.delta_f += tf.cast(y, tf.float32) * x",
            "self.delta_b += tf.tensordot(x, x, axes=0)",
            "# Can follow an update schedule if not doing sherman morison updates",
            "if self.time % self.update_schedule == 0:"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 112,
        "label": "no",
        "change": [
            "class Trainer(",
            "",
            "results = self.predict_loop.on_predict_epoch_end()",
            "self.predict_loop.on_predict_end()",
            "+",
            "+        # re-enable grads",
            "+        torch.set_grad_enabled(True)",
            "+",
            "return results",
            "",
            "def run_sanity_check(self, ref_model):"
        ],
        "comments": "add API call for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 113,
        "label": "no",
        "change": [
            "def filter2d(",
            "input = input.view(-1, tmp_kernel.size(0), input.size(-2), input.size(-1))",
            "",
            "# convolve the tensor with the kernel.",
            "-    output = F.conv2d(input, tmp_kernel, groups=tmp_kernel.size(0), padding=0, stride=1)",
            "+    # NOTE: type(...) to fix getting `torch.bfloat16` type.",
            "+    # TODO: @johnnv1, fix it through the Augmentation Base.",
            "+    output = F.conv2d(input, tmp_kernel, groups=tmp_kernel.size(0), padding=0, stride=1).type(input.dtype)",
            "",
            "if padding == 'same':",
            "out = output.view(b, c, h, w)"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 114,
        "label": "yes",
        "change": [
            "def remainder(",
            "res_floored = torch.where(res >= 0, torch.floor(res), torch.ceil(res))",
            "diff = res - res_floored",
            "diff, x2 = ivy.promote_types_of_inputs(diff, x2)",
            "-        return torch.mul(diff, x2, out=out)",
            "+        return torch.mul(diff, x2, out=out).to(x1.dtype)",
            "return torch.remainder(x1, x2, out=out)"
        ],
        "comments": "add API call for type fix",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 115,
        "label": "no",
        "change": [
            "class GoalOrientedBotNetwork(TFModel):",
            "name='features')",
            "self._action = tf.placeholder(tf.int32, [1, None],",
            "name='ground_truth_action')",
            "-        self._action_mask = tf.placeholder(tf.float32, [1, None, self.n_actions],",
            "+        self._action_mask = tf.placeholder(tf.float32, [None, None, self.n_actions],",
            "name='action_mask')",
            "",
            "def _build_body(self):"
        ],
        "comments": "change param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 116,
        "label": "no",
        "change": [
            "class EpsilonGreedy(Exploration):",
            "torch.multinomial(random_valid_action_logits, 1), axis=1)",
            "# Pick either random or greedy.",
            "action = torch.where(",
            "-                torch.empty((batch_size, )).uniform_() < epsilon,",
            "+                torch.empty(",
            "+                    (batch_size, )).uniform_().to(self.device) < epsilon,",
            "random_actions, exploit_action)",
            "",
            "return action, action_logp"
        ],
        "comments": "add API call for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 117,
        "label": "no",
        "change": [
            "def test_save_and_restore(ray_start_2_cpus, num_replicas):  # noqa: F811",
            "model_creator,",
            "data_creator,",
            "optimizer_creator,",
            "+        loss_creator=lambda config: nn.MSELoss(),",
            "num_replicas=num_replicas)",
            "trainer2.restore(filename)"
        ],
        "comments": "no API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 118,
        "label": "no",
        "change": [
            "class Delta(TorchDistribution):",
            "",
            "def expand(self, batch_shape):",
            "validate_args = self.__dict__.get('_validate_args')",
            "+        batch_shape = torch.Size(batch_shape)",
            "v = self.v.expand(batch_shape + self.event_shape)",
            "log_density = self.log_density.expand(batch_shape)",
            "return Delta(v, log_density, self.event_dim, validate_args=validate_args)"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 119,
        "label": "no",
        "change": [
            "def main():",
            "",
            "pruner = AGP_Pruner(model, configure_list)",
            "model = pruner.compress()",
            "-",
            "+    model = model.to(device)",
            "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)",
            "for epoch in range(10):",
            "pruner.update_epoch(epoch)",
            "print('# Epoch {} #'.format(epoch))",
            "train(model, device, train_loader, optimizer)",
            "test(model, device, test_loader)",
            "-    pruner.export_model('model.pth', 'mask.pth', 'model.onnx', [1, 1, 28, 28])",
            "+    pruner.export_model('model.pth', 'mask.pth', 'model.onnx', [1, 1, 28, 28], device)",
            "",
            "",
            "if __name__ == '__main__':"
        ],
        "comments": "add API call for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 120,
        "label": "no",
        "change": [
            "class TestBidirectionalLanguageModelTransformer(AllenNlpTestCase):",
            "input_dim=32, hidden_dim=64, num_layers=2",
            ")",
            "",
            "-        mask = torch.ones(3, 6).int()",
            "-        mask[0, 3:] = 0",
            "-        mask[1, 5:] = 0",
            "+        mask = torch.ones(3, 6).bool()",
            "+        mask[0, 3:] = False",
            "+        mask[1, 5:] = False",
            "",
            "forward_mask, backward_mask = transformer_encoder.get_attention_masks(mask)"
        ],
        "comments": "change API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 121,
        "label": "yes",
        "change": [
            "from ray.air.config import ScalingConfig",
            "",
            "",
            "def mnist_dataset(batch_size: int) -> tf.data.Dataset:",
            "-    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()",
            "+    with FileLock(os.path.expanduser(\"~/.mnist_lock\")):",
            "+        (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()",
            "# The `x` arrays are in uint8 and have values in the [0, 255] range.",
            "# You need to convert them to float32 with values in the [0, 1] range.",
            "x_train = x_train / np.float32(255)"
        ],
        "comments": "add API call for state fix",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 122,
        "label": "no",
        "change": [
            "def rnn_model(X, y):",
            "# Given encoding of RNN, take encoding of last step (e.g hidden size of the",
            "# neural network of last step) and pass it as features for logistic",
            "# regression over output classes.",
            "-    return skflow.models.logistic_regression(encoding[-1], y)",
            "+    return skflow.models.logistic_regression(encoding, y)",
            "",
            "classifier = skflow.TensorFlowEstimator(model_fn=rnn_model, n_classes=15,",
            "steps=1000, optimizer='Adam', learning_rate=0.01, continue_training=True)"
        ],
        "comments": "change param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 125,
        "label": "no",
        "change": [
            "config.save_json(config_path)",
            "command_train = (",
            "f\"CUDA_VISIBLE_DEVICES='{get_device_id()}'  python TTS/bin/train_tts.py --config_path {config_path}  \"",
            "f\"--coqpit.output_path {output_path} \"",
            "-    \"--coqpit.datasets.0.name ljspeech_test \"",
            "+    \"--coqpit.datasets.0.formatter ljspeech_test \"",
            "\"--coqpit.datasets.0.meta_file_train metadata.csv \"",
            "\"--coqpit.datasets.0.meta_file_val metadata.csv \"",
            "\"--coqpit.datasets.0.path tests/data/ljspeech \""
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 126,
        "label": "no",
        "change": [
            "def main_fun(argv, ctx):",
            "grads = average_gradients(tower_grads)",
            "",
            "# Add a summary to track the learning rate.",
            "-      summaries.append(tf.scalar_summary('learning_rate', lr))",
            "+      summaries.append(tf.summary.scalar('learning_rate', lr))",
            "",
            "# Add histograms for gradients.",
            "for grad, var in grads:",
            "if grad is not None:",
            "summaries.append(",
            "-              tf.histogram_summary(var.op.name + '/gradients', grad))",
            "+              tf.summary.histogram(var.op.name + '/gradients', grad))",
            "",
            "# Apply the gradients to adjust the shared variables.",
            "apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)",
            "",
            "# Add histograms for trainable variables.",
            "for var in tf.trainable_variables():",
            "-        summaries.append(tf.histogram_summary(var.op.name, var))",
            "+        summaries.append(tf.summary.histogram(var.op.name, var))",
            "",
            "# Track the moving averages of all trainable variables.",
            "variable_averages = tf.train.ExponentialMovingAverage("
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 127,
        "label": "no",
        "change": [
            "class Trainer(TrainerBase):",
            "",
            "@timing.time(\"Trainer.test\")",
            "def test(self, test_iter, model, metric_reporter: MetricReporter):",
            "+        if cuda.CUDA_ENABLED:",
            "+            model = model.cuda()",
            "+",
            "model.eval()",
            "with torch.no_grad():",
            "test_metric = self._run_epoch("
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 128,
        "label": "no",
        "change": [
            "class TrainingArguments:",
            "@torch_required",
            "def _setup_devices(self) -> \"torch.device\":",
            "logger.info(\"PyTorch: setting up devices\")",
            "-        if torch.distributed.is_initialized() and self.local_rank == -1:",
            "+        if torch.distributed.is_available() and torch.distributed.is_initialized() and self.local_rank == -1:",
            "logger.warning(",
            "\"torch.distributed process group is initialized, but local_rank == -1. \"",
            "\"In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\""
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 131,
        "label": "no",
        "change": [
            "with tf.Graph().as_default():",
            "checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")",
            "if not os.path.exists(checkpoint_dir):",
            "os.makedirs(checkpoint_dir)",
            "-        saver = tf.train.Saver(tf.all_variables())",
            "+        saver = tf.train.Saver(tf.global_variables())",
            "",
            "# Write vocabulary",
            "vocab_processor.save(os.path.join(out_dir, \"vocab\"))",
            "",
            "# Initialize all variables",
            "-        sess.run(tf.initialize_all_variables())",
            "+        sess.run(tf.global_variables_initializer())",
            "",
            "def train_step(x_batch, y_batch):",
            "\"\"\""
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 132,
        "label": "no",
        "change": [
            "class CLIPTextTransformer(nn.Module):",
            "attentions=encoder_outputs.attentions,",
            ")",
            "",
            "-    def _build_causal_attention_mask(self, bsz, seq_len):",
            "+    def _build_causal_attention_mask(self, bsz, seq_len, dtype):",
            "# lazily create causal attention mask, with full attention between the vision tokens",
            "# pytorch uses additive attention mask; fill with -inf",
            "-        mask = torch.empty(bsz, seq_len, seq_len)",
            "-        mask.fill_(torch.tensor(float(\"-inf\")))",
            "+        mask = torch.empty(bsz, seq_len, seq_len, dtype=dtype)",
            "+        mask.fill_(torch.tensor(torch.finfo(dtype).min))",
            "mask.triu_(1)  # zero out the lower diagonal",
            "mask = mask.unsqueeze(1)  # expand mask",
            "return mask"
        ],
        "comments": "add param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 134,
        "label": "no",
        "change": [
            "class RandomPerspective(GeometricAugmentationBase2D):",
            "size: Optional[Tuple[int, int]] = None,",
            ") -> Tensor:",
            "return self.apply_transform(",
            "-            input, params=self._params, transform=torch.as_tensor(transform, device=input.device, dtype=input.dtype),",
            "-            flags=flags",
            "+            input,",
            "+            params=self._params,",
            "+            transform=torch.as_tensor(transform, device=input.device, dtype=input.dtype),",
            "+            flags=flags,",
            ")"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 135,
        "label": "no",
        "change": [
            "def get_mini_batch(mini_batch_indices, sequences, seq_lengths, cuda=False):",
            "# get mask for mini-batch",
            "mini_batch_mask = get_mini_batch_mask(mini_batch, sorted_seq_lengths)",
            "",
            "-    # wrap in PyTorch Variables",
            "-    mini_batch = Variable(torch.Tensor(mini_batch))",
            "-    mini_batch_reversed = Variable(torch.Tensor(mini_batch_reversed))",
            "-    mini_batch_mask = Variable(torch.Tensor(mini_batch_mask))",
            "+    # wrap in PyTorch Tensors",
            "+    mini_batch = torch.tensor(mini_batch)",
            "+    mini_batch_reversed = torch.tensor(mini_batch_reversed)",
            "+    mini_batch_mask = torch.tensor(mini_batch_mask)",
            "",
            "# cuda() here because need to cuda() before packing",
            "if cuda:"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 136,
        "label": "no",
        "change": [
            "logger = logging.getLogger(__name__)",
            "# for the pretrained weights provided with the models",
            "####################################################",
            "XXX_PRETRAINED_MODEL_ARCHIVE_MAP = {",
            "-    \"xxx-base-uncased\": \"https://s3.amazonaws.com/models.huggingface.co/bert/xxx-base-uncased-pytorch_model.bin\",",
            "-    \"xxx-large-uncased\": \"https://s3.amazonaws.com/models.huggingface.co/bert/xxx-large-uncased-pytorch_model.bin\",",
            "+    \"xxx-base-uncased\": \"https://cdn.huggingface.co/xxx-base-uncased-pytorch_model.bin\",",
            "+    \"xxx-large-uncased\": \"https://cdn.huggingface.co/xxx-large-uncased-pytorch_model.bin\",",
            "}"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 137,
        "label": "no",
        "change": [
            "class FlopsProfiler(object):",
            "start_time_hook)",
            "",
            "def end_time_hook(module, input, output):",
            "-                torch.cuda.synchronize()",
            "+                get_accelerator().synchronize()",
            "module.__duration__ += time.time() - module.__start_time__",
            "",
            "if not hasattr(module, \"__end_time_hook_handle__\"):"
        ],
        "comments": "change API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 138,
        "label": "no",
        "change": [
            "class TestOpt(unittest.TestCase):",
            "assert len(GlobalCounters.cache) == 2, \"optimizer didn't fold conv/relu\"",
            "",
            "if __name__ == '__main__':",
            "-  unittest.main()",
            "\\ No newline at end of file",
            "+  unittest.main()"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 139,
        "label": "no",
        "change": [
            "class Brownian(Kernel):",
            "",
            "Zt = Z.t()",
            "return torch.where(X.sign() == Zt.sign(),",
            "-                           variance * torch.min(X.abs(), Zt.abs()),",
            "+                           self.variance * torch.min(X.abs(), Zt.abs()),",
            "X.data.new_zeros(X.size(0), Z.size(0)))"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 140,
        "label": "no",
        "change": [
            "class PaintByExample(DiffusionInpaintModel):",
            "mask: [H, W, 1] 255 means area to repaint",
            "return: BGR IMAGE",
            "\"\"\"",
            "-        set_seed(config.paint_by_example_seed)",
            "-",
            "output = self.model(",
            "image=PIL.Image.fromarray(image),",
            "mask_image=PIL.Image.fromarray(mask[:, :, -1], mode=\"L\"),",
            "example_image=config.paint_by_example_example_image,",
            "num_inference_steps=config.paint_by_example_steps,",
            "output_type='np.array',",
            "+            generator=torch.manual_seed(config.paint_by_example_seed)",
            ").images[0]",
            "",
            "output = (output * 255).round().astype(\"uint8\")"
        ],
        "comments": "change API call for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 141,
        "label": "yes",
        "change": [
            "class BigBirdPegasusBlockSparseAttention(nn.Module):",
            "num_indices_to_gather = indices.shape[-2] * indices.shape[-1]",
            "num_indices_to_pick_from = params.shape[2]",
            "",
            "-        indices_shift = (",
            "-            torch.arange(indices.shape[0] * indices.shape[1] * num_indices_to_gather, device=indices.device)",
            "-            // num_indices_to_gather",
            "-            * num_indices_to_pick_from",
            "-        )",
            "+        shift = torch.arange(indices.shape[0] * indices.shape[1] * num_indices_to_gather, device=indices.device)",
            "+        indices_shift = torch_int_div(shift, num_indices_to_gather) * num_indices_to_pick_from",
            "",
            "flattened_indices = indices.view(-1) + indices_shift",
            "flattened_params = params.reshape(-1, params.shape[-2], params.shape[-1])"
        ],
        "comments": "format",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 142,
        "label": "yes",
        "change": [
            "def test_benchmark_datasets() -> None:",
            "assert benchmark_report[key_size][\"publish_secs\"] <= timeout",
            "",
            "print(\"purge datasets...\")",
            "-    domain.datasets.purge(skip_checks=True)",
            "+    clean_datasets_on_domain(DOMAIN1_PORT)"
        ],
        "comments": "use custom method for function",
        "Symptom": "low efficiency",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 143,
        "label": "no",
        "change": [
            "def test_feature_encoder_layer():",
            "",
            "model2 = tf.keras.Model(input_node, hidden_node)",
            "result = model2.predict(data)",
            "+    print(result)",
            "assert result[0][0] == result[2][0]",
            "assert result[0][0] != result[1][0]",
            "assert result[0][1] != result[1][1]"
        ],
        "comments": "add print",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 144,
        "label": "no",
        "change": [
            "class F1Measure(Metric):",
            "raise ConfigurationError(\"A gold label passed to F1Measure contains an id >= {}, \"",
            "\"the number of classes.\".format(num_classes))",
            "if mask is None:",
            "-            mask = ones_like(gold_labels)",
            "+            mask = torch.ones_like(gold_labels)",
            "mask = mask.float()",
            "gold_labels = gold_labels.float()",
            "positive_label_mask = gold_labels.eq(self._positive_label).float()"
        ],
        "comments": "class name change",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 148,
        "label": "no",
        "change": [
            "def compute_slices(dataset, batch):",
            "y_slice = node_slice if dataset.y.size(0) == num_nodes else graph_slice",
            "slices['y'] = y_slice",
            "",
            "-    return slices",
            "+    return dataset, slices"
        ],
        "comments": "more return",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 149,
        "label": "no",
        "change": [
            "def load_module_spec(path):",
            "",
            "Raises:",
            "ValueError: on unexpected values in the module spec.",
            "-    tf.OpError: on file handling exceptions.",
            "+    tf.errors.OpError: on file handling exceptions.",
            "\"\"\"",
            "path = registry.resolver(path)",
            "return registry.loader(path)"
        ],
        "comments": "change class name",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 151,
        "label": "yes",
        "change": [
            "def main(args):",
            "# CNN will transform a high dimension image into a low dimension 2D tensors for RBF kernel.",
            "# This kernel accepts inputs are inputs of CNN and gives outputs are covariance matrix of RBF on",
            "# outputs of CNN.",
            "-    kernel = gp.kernels.RBF(input_dim=10, lengthscale=torch.ones(10)).warp(iwarping_fn=cnn_fn)",
            "+    kernel = gp.kernels.Warp(gp.kernels.RBF(input_dim=10, lengthscale=torch.ones(10)),",
            "+                             iwarping_fn=cnn_fn)",
            "",
            "# init inducing points (taken randomly from dataset)",
            "Xu = next(iter(train_loader))[0][:args.num_inducing]"
        ],
        "comments": "add API call for type fix",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 153,
        "label": "no",
        "change": [
            "def linspace_helper(start, stop, num, axis=None, *, device):",
            "else:",
            "res = [linspace_method(start, stp, num, device=device) for stp in stop]",
            "else:",
            "-        return linspace_method(start, stop, num, device=device)",
            "+        return linspace_method(start, stop, num, dtype=torch.float64, device=device)",
            "res = torch.cat(res, -1).reshape(sos_shape + [num])",
            "if axis is not None:",
            "res = torch.transpose(res, axis, -1)"
        ],
        "comments": "add param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 154,
        "label": "no",
        "change": [
            "def save_best_model(model, optimizer, criterion, model_loss, best_loss, out_path",
            "bestmodel_path = \"best_model.pth.tar\"",
            "bestmodel_path = os.path.join(out_path, bestmodel_path)",
            "print(\"\\n > BEST MODEL ({0:.5f}) : {1:}\".format(model_loss, bestmodel_path))",
            "-        torch.save(state, bestmodel_path)",
            "+        save_fsspec(state, bestmodel_path)",
            "return best_loss"
        ],
        "comments": "add custom function",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 156,
        "label": "no",
        "change": [
            "class UnittestBase(object):",
            "datetime.now().strftime('%H:%M:%S'), self.__class__.__name__[4:], name",
            "))",
            "sys.stdout.flush()",
            "+        tf.compat.v1.reset_default_graph()",
            "",
            "def finished_test(self, assertion=None):",
            "\"\"\""
        ],
        "comments": "add API call for state fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 158,
        "label": "yes",
        "change": [
            "class GPTNeoXModel(GPTNeoXPreTrainedModel):",
            "# Since we are adding it to the raw scores before the softmax, this is",
            "# effectively the same as removing these entirely.",
            "attention_mask = attention_mask.to(dtype=self.dtype)  # fp16 compatibility",
            "-            attention_mask = (1.0 - attention_mask) * -10000.0",
            "+            attention_mask = (1.0 - attention_mask) * torch.finfo(self.dtype).min",
            "",
            "# Prepare head mask if needed",
            "# 1.0 in head_mask indicate we keep the head"
        ],
        "comments": "change param for math fix",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 159,
        "label": "yes",
        "change": [
            "class PatchAffineShapeEstimator(nn.Module):",
            "\"input shape should be must be [Bx1x{}x{}]. \"",
            "\"Got {}\".format(self.patch_size, self.patch_size, patch.size()))",
            "self.weighting = self.weighting.to(patch.dtype).to(patch.device)",
            "-        grads: torch.Tensor = self.gradient(patch)",
            "+        grads: torch.Tensor = self.gradient(patch) * self.weighting",
            "# unpack the edges",
            "gx: torch.Tensor = grads[:, :, 0]",
            "gy: torch.Tensor = grads[:, :, 1]"
        ],
        "comments": "no API used",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 160,
        "label": "no",
        "change": [
            "def compute_tf_latency(",
            "with tf.device(device):",
            "for _ in range(steps):",
            "starting_time = time.time()",
            "-            _ = model(x)",
            "+            _ = model(*xs)",
            "latencies.append(time.time() - starting_time)",
            "latency = sum(latencies) / steps",
            "return latency, latencies"
        ],
        "comments": "add param for argument fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 162,
        "label": "no",
        "change": [
            "class ArxivDataset(datasets.GeneratorBasedBuilder):",
            "path_to_manual_file = os.path.join(os.path.abspath(os.path.expanduser(dl_manager.manual_dir)), _FILENAME)",
            "if not os.path.exists(path_to_manual_file):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('arxiv_dataset', data_dir=...)` that includes a file name {}. Manual download instructions: {})\".format(",
            "-                    path_to_manual_file, _FILENAME, self.manual_download_instructions",
            "-                )",
            "+                \"{path_to_manual_file} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('arxiv_dataset', data_dir=...)` that includes a file name {_FILENAME}. Manual download instructions: {self.manual_download_instructions})\"",
            ")",
            "return [datasets.SplitGenerator(name=datasets.Split.TRAIN, gen_kwargs={\"path\": path_to_manual_file})]"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 163,
        "label": "no",
        "change": [
            "def non_max_suppression(prediction, conf_thres=0.1, iou_thres=0.6, classes=None,",
            "merge = False  # use merge-NMS",
            "",
            "t = time.time()",
            "-    output = [torch.zeros(0, 6)] * prediction.shape[0]",
            "+    output = [torch.zeros((0, 6), device=prediction.device)] * prediction.shape[0]",
            "for xi, x in enumerate(prediction):  # image index, image inference",
            "# Apply constraints",
            "# x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height"
        ],
        "comments": "add param for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 164,
        "label": "no",
        "change": [
            "def glue_convert_examples_to_features(",
            "output_mode: String indicating the output mode. Either `regression` or `classification`",
            "",
            "Returns:",
            "-        If the `examples` input is a `tf.data.Dataset`, will return a `tf.data.Dataset` containing the",
            "-        task-specific features. If the input is a list of `InputExamples`, will return a list of task-specific",
            "-        `InputFeatures` which can be fed to the model.",
            "+        If the `examples` input is a `tf.data.Dataset`, will return a `tf.data.Dataset` containing the task-specific",
            "+        features. If the input is a list of `InputExamples`, will return a list of task-specific `InputFeatures` which",
            "+        can be fed to the model.",
            "",
            "\"\"\"",
            "warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 165,
        "label": "no",
        "change": [
            "class ESPnetUASRModel(AbsESPnetModel):",
            "#  e.g. STFT and Feature extract",
            "#       data_loader may send time-domain signal in this case",
            "# speech (Batch, NSamples) -> feats: (Batch, NFrames, Dim)",
            "+            speech = F.layer_norm(speech, speech.shape)",
            "feats, feats_lengths = self.frontend(speech, speech_lengths)",
            "else:",
            "# No frontend and no feature extract (usually with pre-extracted feat)"
        ],
        "comments": "add layer note clear",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 166,
        "label": "no",
        "change": [
            "class DartsTrainer(BaseOneShotTrainer):",
            "p += e * d",
            "",
            "_, loss = self._logits_and_loss(trn_X, trn_y)",
            "-            dalphas.append(torch.autograd.grad(loss, [c.alpha for c in self.nas_modules]))",
            "+            dalphas.append(torch.autograd.grad(loss, [c.alpha for _, c in self.nas_modules]))",
            "",
            "dalpha_pos, dalpha_neg = dalphas  # dalpha { L_trn(w+) }, # dalpha { L_trn(w-) }",
            "hessian = [(p - n) / (2. * eps) for p, n in zip(dalpha_pos, dalpha_neg)]"
        ],
        "comments": "add param for argument fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 167,
        "label": "no",
        "change": [
            "def subtract(",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "x1, x2 = ivy.promote_types_of_inputs(x1, x2)",
            "-    return tf.subtract(x1, x2)",
            "+    return tf.experimental.numpy.subtract(x1, x2)",
            "",
            "",
            "def tan("
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 168,
        "label": "no",
        "change": [
            "class LightningTemplateModel(LightningModule):",
            "self.c_d2 = nn.Linear(in_features=self.hidden_dim,",
            "out_features=self.out_features)",
            "",
            "+        self.example_input_array = torch.zeros(2, 1, 28, 28)",
            "+",
            "def forward(self, x):",
            "\"\"\"",
            "No special modification required for Lightning, define it as you normally would"
        ],
        "comments": "no API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 169,
        "label": "no",
        "change": [
            "class XDropout(torch.autograd.Function):",
            "# Once https://github.com/pytorch/pytorch/issues/78391 is fixed, do something like:",
            "# if opset_version < 12:",
            "#   return torch.onnx.symbolic_opset9.dropout(g, input, dropout_p, train)",
            "-        return torch.onnx.symbolic_opset12.dropout(g, input, dropout_p, train)",
            "+        return symbolic_opset12.dropout(g, input, dropout_p, train)",
            "",
            "",
            "# Copied from transformers.models.deberta.modeling_deberta.StableDropout"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 170,
        "label": "no",
        "change": [
            "class Parquet(datasets.ArrowBasedBuilder):",
            "BUILDER_CONFIG_CLASS = ParquetConfig",
            "",
            "def _info(self):",
            "-        if version.parse(pa.__version__) < version.parse(\"3.0.0\"):",
            "+        if datasets.config.PYARROW_VERSION.major < 3:",
            "raise ImportError(",
            "\"PyArrow >= 3.0.0 is required to used the Parquet dataset builder: pip install --upgrade pyarrow\"",
            ")"
        ],
        "comments": "change condition check for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 171,
        "label": "no",
        "change": [
            "class RPCPlugin(DDPPlugin):",
            "world_size: int) -> None:",
            "os.environ['MASTER_PORT'] = os.getenv('RPC_MASTER_PORT', '15000')",
            "rpc.init_rpc(f\"worker{global_rank}\", rank=global_rank, world_size=world_size)",
            "+        rpc._set_rpc_timeout(self.rpc_timeout_sec)",
            "self.rpc_initialized = True",
            "",
            "def rpc_save_model(self,"
        ],
        "comments": "add API call for state fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 172,
        "label": "no",
        "change": [
            "class SimpleSeq2SeqTest(ModelTestCase):",
            "state = self.model._init_decoder_state(state)",
            "batch_size = state[\"source_mask\"].size()[0]",
            "start_predictions = state[\"source_mask\"].new_full(",
            "-            (batch_size,), fill_value=self.model._start_index",
            "+            (batch_size,), fill_value=self.model._start_index, dtype=torch.long",
            ")",
            "all_top_k_predictions, _ = beam_search.search(",
            "start_predictions, state, self.model.take_step"
        ],
        "comments": "add param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 173,
        "label": "no",
        "change": [
            "def pg_tf_loss(policy, model, dist_class, train_batch):",
            "logits, _ = model.from_batch(train_batch)",
            "action_dist = dist_class(logits, model)",
            "return -tf.reduce_mean(",
            "-        action_dist.logp(train_batch[SampleBatch.ACTIONS]) *",
            "-        tf.cast(train_batch[Postprocessing.ADVANTAGES], dtype=tf.float32))",
            "+        action_dist.logp(train_batch[SampleBatch.ACTIONS]) * tf.cast(",
            "+            train_batch[Postprocessing.ADVANTAGES], dtype=tf.float32))",
            "",
            "",
            "PGTFPolicy = build_tf_policy("
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 174,
        "label": "no",
        "change": [
            "class StableDiffusionDepth2ImgPipeline(DiffusionPipeline):",
            "`pipeline.enable_sequential_cpu_offload()` the execution device can only be inferred from Accelerate's module",
            "hooks.",
            "\"\"\"",
            "-        if self.device != torch.device(\"meta\") or not hasattr(self.unet, \"_hf_hook\"):",
            "+        if not hasattr(self.unet, \"_hf_hook\"):",
            "return self.device",
            "for module in self.unet.modules():",
            "if ("
        ],
        "comments": "remove condition check for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 175,
        "label": "no",
        "change": [
            "def test_quantile():",
            "z = torch.randn(2000)",
            "",
            "assert_equal(quantile(x, probs=[0., 0.4, 0.5, 1.]), torch.tensor([0., 0.8, 1., 2.]))",
            "-    assert_equal(quantile(y, probs=0.2), torch.tensor(0.2), prec=0.01)",
            "-    assert_equal(quantile(z, probs=0.8413), torch.tensor(1.), prec=0.001)",
            "+    assert_equal(quantile(y, probs=0.2), torch.tensor(0.2), prec=0.02)",
            "+    assert_equal(quantile(z, probs=0.8413), torch.tensor(1.), prec=0.02)",
            "",
            "",
            "def test_pi():"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 176,
        "label": "no",
        "change": [
            "class TacotronGSTTrainTest(unittest.TestCase):",
            "input_lengths = torch.randint(100, 129, (8, )).long().to(device)",
            "input_lengths[-1] = 128",
            "mel_spec = torch.rand(8, 120, c.audio['num_mels']).to(device)",
            "-        linear_spec = torch.rand(8, 120, c.audio['num_freq']).to(device)",
            "+        linear_spec = torch.rand(8, 120, c.audio['fft_size']).to(device)",
            "mel_lengths = torch.randint(20, 120, (8, )).long().to(device)",
            "mel_lengths[-1] = 120",
            "stop_targets = torch.zeros(8, 120, 1).float().to(device)"
        ],
        "comments": "change name",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 177,
        "label": "yes",
        "change": [
            "class IvyModule(ivy.Module):",
            "if ivy.array_mode():",
            "a, kw = ivy.args_to_native(*a, **kw)",
            "# noinspection PyUnresolvedReferences",
            "-        params_hk = self._native_module.init(ivy.functional.core.random.RNG, *a, **kw)",
            "+        params_hk = self._native_module.init(ivy.random.RNG, *a, **kw)",
            "params_dict = _hk_flat_map_to_dict(params_hk)",
            "self._hk_params = ivy.Container(params_dict)",
            "param_iterator = self._hk_params.to_iterator()"
        ],
        "comments": "update param for refactor fix",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 178,
        "label": "no",
        "change": [
            "class ClassificationModel(LightningModule):",
            "return logits",
            "",
            "def configure_optimizers(self):",
            "-        optimizer = torch.optim.Adam(self.parameters(), lr=0.01)",
            "+        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)",
            "return [optimizer], []",
            "",
            "def training_step(self, batch, batch_idx):"
        ],
        "comments": "parameterize the variable",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 179,
        "label": "no",
        "change": [
            "class DataParallel(torch.nn.DataParallel):",
            "Batch.from_data_list(data_list[split[i]:split[i + 1]],",
            "follow_batch=self.follow_batch,",
            "exclude_keys=self.exclude_keys).to(",
            "-                                     torch.device('cuda:{}'.format(",
            "-                                         device_ids[i])))",
            "+                                     torch.device(f'cuda:{device_ids[i]}'))",
            "for i in range(len(split) - 1)",
            "]"
        ],
        "comments": "remove API call for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 180,
        "label": "no",
        "change": [
            "class ProjectedAdaptiveLogSoftmax(nn.Module):",
            "d_emb_i = d_embed // (div_val ** i)",
            "",
            "self.out_projs.append(",
            "-                    nn.Parameter(torch.Tensor(d_proj, d_emb_i))",
            "+                    nn.Parameter(torch.FloatTensor(d_proj, d_emb_i))",
            ")",
            "",
            "self.out_layers.append(nn.Linear(d_emb_i, r_idx-l_idx))"
        ],
        "comments": "change API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 181,
        "label": "yes",
        "change": [
            "class TensorFlowEstimator(BaseEstimator):",
            "raise NotFittedError()",
            "predict_data_feeder = setup_predict_data_feeder(X)",
            "preds = []",
            "-        dropouts = tf.get_collection(DROPOUTS)",
            "-        feed_dict = {prob: 0.0 for prob in dropouts}",
            "+        dropouts = self._graph.get_collection(DROPOUTS)",
            "+        feed_dict = {prob: 1.0 for prob in dropouts}",
            "for data in predict_data_feeder:",
            "feed_dict[self._inp] = data",
            "preds.append(self._session.run("
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 182,
        "label": "no",
        "change": [
            "class GradientsTest(tf.test.TestCase):",
            "self.assertAllClose(eager_result, function_result)",
            "backprop_result, numeric_result = tf.test.compute_gradient(",
            "m, [inp], delta=1e-3)",
            "-    self.assertAllClose(numeric_result, backprop_result, rtol=1e-2)",
            "+    self.assertAllClose(numeric_result, backprop_result, atol=1e-3)",
            "self.assertAllClose(tf.reshape(numeric_result, [-1]),",
            "-                        tf.reshape(eager_result, [-1]), rtol=1e-2)",
            "+                        tf.reshape(eager_result, [-1]), atol=1e-3)",
            "",
            "def testEmbeddingLookupGradientsHaveKnownShape(self):"
        ],
        "comments": "value update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 184,
        "label": "no",
        "change": [
            "class Trainer:",
            "self.tb_logger.tb_eval_figures(self.total_steps_done, figures)",
            "if audios is not None:",
            "self.tb_logger.tb_eval_audios(self.total_steps_done, audios, self.ap.sample_rate)",
            "+            self.tb_logger.tb_eval_stats(self.total_steps_done, self.keep_avg_eval.avg_values)",
            "",
            "def test_run(self) -> None:",
            "\"\"\"Run test and log the results. Test run must be defined by the model."
        ],
        "comments": "state fixialize log but API fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 185,
        "label": "no",
        "change": [
            "def bitwise_left_shift(",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "x1, x2 = ivy.promote_types_of_inputs(x1, x2, array_api_promotion=True)",
            "-    ivy.assertions.check_all(x2 >= 0, message=\"shifts must be non-negative\")",
            "return torch.bitwise_left_shift(x1, x2, out=out)"
        ],
        "comments": "remove check for not clear reason",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 186,
        "label": "no",
        "change": [
            "TEST_DEVICES: Dict[str, torch.device] = get_test_devices()",
            "TEST_DTYPES: Dict[str, torch.dtype] = get_test_dtypes()",
            "",
            "# Combinations of device and dtype to be excluded from testing.",
            "-DEVICE_DTYPE_BLACKLIST = {('cpu', 'float16')}",
            "+# DEVICE_DTYPE_BLACKLIST = {('cpu', 'float16')}",
            "+DEVICE_DTYPE_BLACKLIST = {}",
            "",
            "",
            "@pytest.fixture()"
        ],
        "comments": "global variable update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 187,
        "label": "yes",
        "change": [
            "class Pix2PixModel(BaseModel):",
            "def backward_D(self):",
            "# Fake",
            "# stop backprop to the generator by detaching fake_B",
            "-        fake_AB = self.fake_AB_pool.query(torch.cat((self.real_A, self.fake_B), 1))",
            "+        fake_AB = self.fake_AB_pool.query(torch.cat((self.real_A, self.fake_B), 1).data)",
            "pred_fake = self.netD.forward(fake_AB.detach())",
            "self.loss_D_fake = self.criterionGAN(pred_fake, False)",
            "",
            "# Real",
            "real_AB = torch.cat((self.real_A, self.real_B), 1)",
            "pred_real = self.netD.forward(real_AB)",
            "-        self.loss_D_real = self.criterionGAN(self.pred_real, True)",
            "+        self.loss_D_real = self.criterionGAN(pred_real, True)",
            "",
            "# Combined loss",
            "self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5"
        ],
        "comments": "add API call for type fix",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 188,
        "label": "no",
        "change": [
            "args = parser.parse_args()",
            "torch.manual_seed(args.seed)",
            "if torch.cuda.is_available():",
            "if not args.cuda:",
            "-        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")",
            "+        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda.\")",
            "",
            "device = torch.device(\"cuda\" if args.cuda else \"cpu\")",
            "",
            "if args.temperature < 1e-3:",
            "-    parser.error(\"--temperature has to be greater or equal 1e-3\")",
            "+    parser.error(\"--temperature has to be greater or equal 1e-3.\")",
            "",
            "with open(args.checkpoint, 'rb') as f:",
            "model = torch.load(f).to(device)"
        ],
        "comments": "fix print update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 189,
        "label": "no",
        "change": [
            "class Trainer:",
            "transformer_cls_to_wrap = get_module_class_from_name(",
            "model, self.args.fsdp_transformer_layer_cls_to_wrap",
            ")",
            "+                    if transformer_cls_to_wrap is None:",
            "+                        raise Exception(\"Could not find the transformer layer class to wrap in the model.\")",
            "auto_wrap_policy = functools.partial(",
            "transformer_auto_wrap_policy,",
            "# Transformer layer class to wrap"
        ],
        "comments": "add condition check for null fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 190,
        "label": "no",
        "change": [
            "class NAFModel(Model):",
            "# Naf directly outputs V(s)",
            "target_value[action] = target_value_output",
            "",
            "-            target_output_vars = get_variables('target_outputs')",
            "+            target_output_vars = tf.contrib.framework.get_variables('target_outputs')",
            "",
            "with tf.name_scope(\"update\"):",
            "for action in self.action:"
        ],
        "comments": "add custom method to get var",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 191,
        "label": "no",
        "change": [
            "class SpanConstituencyParserTest(ModelTestCase):",
            "# A very annoying edge case: the PTB has several single word sentences.",
            "# when running with a batch size 1, we have to be very careful",
            "# about how we .squeeze/.unsqueeze things to make sure it still runs.",
            "-        text = {\"tokens\": torch.LongTensor([[1]])}",
            "+        text = {\"tokens\": {\"tokens\": torch.LongTensor([[1]])}}",
            "pos_tags = torch.LongTensor([[1]])",
            "spans = torch.LongTensor([[[0, 0]]])",
            "label = torch.LongTensor([[1]])"
        ],
        "comments": "add docs",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 192,
        "label": "no",
        "change": [
            "class MixedPrecisionBoringFabric(BoringFabric):",
            "[",
            "(\"cpu\", \"16-mixed\", torch.bfloat16),",
            "(\"cpu\", \"bf16-mixed\", torch.bfloat16),",
            "-        pytest.param(\"cuda\", \"16-mixed\", torch.float16, marks=RunIf(min_cuda_gpus=1)),",
            "-        pytest.param(\"cuda\", \"bf16-mixed\", torch.bfloat16, marks=RunIf(min_cuda_gpus=1, bf16_cuda=True)),",
            "+        pytest.param(\"cuda\", \"16-mixed\", torch.float16, marks=RunIf(min_cuda_gpus=2)),",
            "+        pytest.param(\"cuda\", \"bf16-mixed\", torch.bfloat16, marks=RunIf(min_cuda_gpus=2, bf16_cuda=True)),",
            "],",
            ")",
            "def test_amp(accelerator, precision, expected_dtype):"
        ],
        "comments": "not ML API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 193,
        "label": "no",
        "change": [
            "class tensorflow_extractor(base_extractor):",
            "writer.close()",
            "sess.run(init)",
            "saver = tf.train.Saver()",
            "+            tf.train.export_meta_graph(\"kit.meta\", as_text=True)",
            "saver.restore(sess, path + cls.architecture_map[architecture]['filename'])",
            "save_path = saver.save(sess, path + \"imagenet_{}.ckpt\".format(architecture))",
            "print(\"Model saved in file: %s\" % save_path)"
        ],
        "comments": "add API call for shape fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 194,
        "label": "yes",
        "change": [
            "def test_auto_diagonal_gaussians(auto_class, Elbo):",
            "guide = auto_class(model, rank=1)",
            "else:",
            "guide = auto_class(model)",
            "-    adam = optim.Adam({\"lr\": .001, \"betas\": (0.95, 0.999)})",
            "+    adam = optim.ClippedAdam({\"lr\": .01, \"betas\": (0.95, 0.999),",
            "+                              \"lrd\": 0.1 ** (1 / n_steps)})",
            "svi = SVI(model, guide, adam, loss=Elbo())",
            "",
            "for k in range(n_steps):"
        ],
        "comments": "change API call for math fix",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 195,
        "label": "no",
        "change": [
            "def test_frontend_backward_multi_channel(train, use_wpe, use_beamformer):",
            "frontend.train()",
            "else:",
            "frontend.eval()",
            "+    torch.random.manual_seed(14)",
            "x = torch.randn(2, 1000, 2, requires_grad=True)",
            "x_lengths = torch.LongTensor([1000, 980])",
            "y, y_lengths = frontend(x, x_lengths)"
        ],
        "comments": "add param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 196,
        "label": "no",
        "change": [
            "class Conv1dLayer(Layer):",
            "act = tf.identity",
            "logging.info(\"Conv1dLayer %s: shape:%s stride:%s pad:%s act:%s\" % (self.name, str(shape), str(stride), padding, act.__name__))",
            "",
            "-        with tf.variable_scope(name) as vs:",
            "+        with tf.variable_scope(name):  # as vs:",
            "W = tf.get_variable(name='W_conv1d', shape=shape, initializer=W_init, dtype=D_TYPE, **W_init_args)",
            "self.outputs = tf.nn.convolution(",
            "self.inputs, W, strides=(stride, ), padding=padding, dilation_rate=(dilation_rate, ), data_format=data_format)  # 1.2"
        ],
        "comments": "remove as",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 197,
        "label": "yes",
        "change": [
            "class TestGradientScaling(unittest.TestCase):",
            "optimizer = FP16Optimizer.build_optimizer(self.namespace_dls, params)",
            "",
            "self.run_iter(model, params, optimizer)",
            "-        self.assertTrue(torch.all(optimizer.fp32_params.eq(torch.tensor([3.1000, 5.1000], device='cuda:0', requires_grad=True))))",
            "+        self.assertTrue(all(",
            "+            torch.all(fp32_params.eq(torch.tensor([3.1000, 5.1000], device='cuda:0', requires_grad=True)))",
            "+            for fp32_params in optimizer.fp32_params.values()",
            "+        ))",
            "",
            "def test_memory_efficient(self):",
            "model = copy.deepcopy(self.model)"
        ],
        "comments": "test fix",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 198,
        "label": "no",
        "change": [
            "class TestLuvToRgb(BaseTester):",
            "[0.06325728, 0.78878325, 0.74280596, 0.99514300, 0.47176042]]",
            "]], device=device, dtype=dtype)",
            "",
            "-        assert_allclose(kornia.color.luv_to_rgb(data), expected)",
            "+        assert_allclose(kornia.color.luv_to_rgb(data), expected, rtol=1e-4, atol=1e-4)",
            "",
            "def test_forth_and_back(self, device, dtype):",
            "data = torch.rand(3, 4, 5, device=device, dtype=dtype)"
        ],
        "comments": "test api",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 199,
        "label": "no",
        "change": [
            "class EulerSamplingTest(tf.test.TestCase, parameterized.TestCase):",
            "times=times,",
            "num_samples=num_samples,",
            "initial_state=x0,",
            "-            random_type=tff.math.random.RandomType.SOBOL,",
            "+            random_type=tff.math.random.RandomType.HALTON,",
            "time_step=0.01,",
            "-            seed=12134))",
            "+            seed=12134,",
            "+            skip=100,",
            "+            dtype=tf.float32))",
            "",
            "-    self.assertAllClose(paths.shape, (num_samples, 5, 2), atol=0)",
            "+    self.assertAllClose(paths.shape, (num_samples, 3, 2), atol=0)",
            "means = np.mean(paths, axis=0)",
            "times = np.reshape(times, [-1, 1])",
            "expected_means = x0 + (2.0 / 3.0) * mu * np.power(times, 1.5)"
        ],
        "comments": "add param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 201,
        "label": "no",
        "change": [
            "class Layer_Shape_Test(unittest.TestCase):",
            "",
            "if __name__ == '__main__':",
            "",
            "-    # tf.logging.set_verbosity(tf.logging.INFO)",
            "-    tf.logging.set_verbosity(tf.logging.DEBUG)",
            "+    # tl.logging.set_verbosity(tl.logging.INFO)",
            "+    tl.logging.set_verbosity(tl.logging.DEBUG)",
            "",
            "unittest.main()"
        ],
        "comments": "debug log",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 202,
        "label": "no",
        "change": [
            "class TorchTensor(AbstractTensor):",
            ")",
            "# This handles case 3: it redirects the command to the appropriate class depending",
            "# of the syft type of the arguments and returns",
            "-            if args_type not in (torch.Tensor, torch.nn.Parameter):",
            "+            if args_type not in FrameworkTensor:",
            "return args_type.handle_func_command(command)",
            "",
            "# build the new command"
        ],
        "comments": "use custom method to fix the bug",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 203,
        "label": "no",
        "change": [
            "class BatchNorm(TransformModule):",
            "if self.training:",
            "mean, var = y.mean(0), y.var(0)",
            "",
            "-            # NOTE: The momentum variable agrees with the definition in e.g. `torch.nn.BatchNorm1d`",
            "-            self.moving_mean.mul_(1 - self.momentum).add_(mean * self.momentum)",
            "-            self.moving_variance.mul_(1 - self.momentum).add_(var * self.momentum)",
            "+            with torch.no_grad():",
            "+                # NOTE: The momentum variable agrees with the definition in e.g. `torch.nn.BatchNorm1d`",
            "+                self.moving_mean.mul_(1 - self.momentum).add_(mean * self.momentum)",
            "+                self.moving_variance.mul_(1 - self.momentum).add_(var * self.momentum)",
            "",
            "# During test time, use smoothed averages rather than the sample ones",
            "else:"
        ],
        "comments": "add API call for state fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 205,
        "label": "yes",
        "change": [
            "class RNNLM(nn.Module):",
            "",
            "def forward(self, state, x):",
            "h0 = self.embed(x)",
            "-        h1, c1 = self.l1(F.dropout(h0), (state['h1'], state['c1']))",
            "-        h2, c2 = self.l2(F.dropout(h1), (state['h2'], state['c2']))",
            "-        y = self.lo(F.dropout(h2))",
            "+        h1, c1 = self.l1(self.d0(h0), (state['h1'], state['c1']))",
            "+        h2, c2 = self.l2(self.d1(h1), (state['h2'], state['c2']))",
            "+        y = self.lo(self.d2(h2))",
            "state = {'c1': c1, 'h1': h1, 'c2': c2, 'h2': h2}",
            "return state, y"
        ],
        "comments": "remove API call for math fix",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 207,
        "label": "no",
        "change": [
            "def test_link_neighbor_loader_edge_label():",
            "",
            "for batch in loader:",
            "assert batch.edge_label.dtype == torch.long",
            "-        assert torch.all(batch.edge_label[:10] == 2)",
            "+        assert torch.all(batch.edge_label[:10] == 1)",
            "assert torch.all(batch.edge_label[10:] == 0)"
        ],
        "comments": "test fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 208,
        "label": "no",
        "change": [
            "def reportScore(name, scoreTotal, wordsTotal):",
            "def main():",
            "opt = parser.parse_args()",
            "opt.cuda = opt.gpu > -1",
            "-    torch.cuda.set_device(opt.gpu)",
            "+    if opt.cuda:",
            "+        torch.cuda.set_device(opt.gpu)",
            "",
            "translator = onmt.Translator(opt)"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 209,
        "label": "no",
        "change": [
            "class Conv2dStaticSamePadding(nn.Conv2d):",
            "pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)",
            "pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)",
            "if pad_h > 0 or pad_w > 0:",
            "-            self.static_padding = nn.ZeroPad2d((pad_w - pad_w // 2, pad_w - pad_w // 2,",
            "-                                                pad_h - pad_h // 2, pad_h - pad_h // 2))",
            "+            self.static_padding = nn.ZeroPad2d((pad_w // 2, pad_w - pad_w // 2,",
            "+                                                pad_h // 2, pad_h - pad_h // 2))",
            "else:",
            "self.static_padding = nn.Identity()"
        ],
        "comments": "change param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 210,
        "label": "no",
        "change": [
            "def train_model(params: Params, serialization_dir: str) -> Model:",
            "",
            "logger.info(\"Creating a vocabulary using %s data.\", \", \".join(datasets_for_vocab_creation))",
            "vocab = Vocabulary.from_params(params.pop(\"vocabulary\", {}),",
            "-                                   Dataset([instance for key, dataset in all_datasets.items()",
            "-                                            for instance in dataset.instances",
            "-                                            if key in datasets_for_vocab_creation]))",
            "+                                   (instance for key, dataset in all_datasets.items()",
            "+                                    for instance in dataset",
            "+                                    if key in datasets_for_vocab_creation))",
            "vocab.save_to_files(os.path.join(serialization_dir, \"vocabulary\"))",
            "",
            "model = Model.from_params(vocab, params.pop('model'))"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 213,
        "label": "yes",
        "change": [
            "class SpeedySpeech(BaseTTS):",
            "outputs = {\"model_outputs\": o_de.transpose(1, 2), \"durations_log\": o_dr_log.squeeze(1), \"alignments\": attn}",
            "return outputs",
            "",
            "+    @torch.no_grad()",
            "def inference(self, x, aux_input={\"d_vectors\": None, \"speaker_ids\": None}):  # pylint: disable=unused-argument",
            "\"\"\"",
            "Shapes:"
        ],
        "comments": "add API call for state fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "addition",
        "Element": "api call"
    },
    {
        "number": 214,
        "label": "yes",
        "change": [
            "class KerasBackend(AbstractBackend):",
            "return keras",
            "",
            "def einsum(self, pattern, *x):",
            "-        return self.tf.einsum(pattern, *x)",
            "+        return self.tf.vectorized_map(",
            "+            functools.partial(self.tf.einsum, pattern),",
            "+            *x",
            "+        )",
            "",
            "",
            "class OneFlowBackend(AbstractBackend):"
        ],
        "comments": "add API call for math fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 215,
        "label": "no",
        "change": [
            "def run_modelmerger(primary_model_name, secondary_model_name, teritary_model_nam",
            "t2 = theta_2.get(key, torch.zeros_like(theta_1[key]))",
            "theta_1[key] = theta_func1(theta_1[key], t2)",
            "else:",
            "-                    theta_1[key] = 0",
            "+                    theta_1[key] = torch.zeros_like(theta_1[key])",
            "del theta_2, teritary_model",
            "",
            "for key in tqdm.tqdm(theta_0.keys()):"
        ],
        "comments": "add API call for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 216,
        "label": "no",
        "change": [
            "class DefaultClassifier(Classifier):",
            "",
            "def _calculate_loss(self, scores, labels):",
            "",
            "-        if len(labels) == 0: return torch.tensor(0., requires_grad=True), 1",
            "+        if len(labels) == 0: return torch.tensor(0., requires_grad=True, device=flair.device), 1",
            "",
            "if self.multi_label:",
            "labels = torch.tensor([[1 if l in all_labels_for_point else 0 for l in self.label_dictionary.get_items()]"
        ],
        "comments": "add param for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 217,
        "label": "no",
        "change": [
            "class EmbeddingLayer(nn.Module):",
            "torch.empty(weight_shape[0],",
            "weight_shape[1],",
            "dtype=dtype,",
            "-                        device=torch.cuda.current_device()))",
            "+                        device=get_accelerator().current_device_name()))",
            "",
            "def forward(self, input):",
            "return F.embedding(input, self.weight)"
        ],
        "comments": "change API call for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 218,
        "label": "no",
        "change": [
            "class MultiActionDistribution(ActionDistribution):",
            "",
            "def logp(self, x):",
            "\"\"\"The log-likelihood of the action distribution.\"\"\"",
            "-        split_list = self.reshaper.split_tensor(x)",
            "+        split_list = tf.split(x, len(self.input_lens), axis=1)",
            "for i, distribution in enumerate(self.child_distributions):",
            "# Remove extra categorical dimension",
            "if isinstance(distribution, Categorical):"
        ],
        "comments": "change API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 219,
        "label": "no",
        "change": [
            "class CategoricalOneHotPolicy(StochasticPolicy):",
            "def __init__(self, network, session, state, random, action_count=1, scope='policy'):",
            "with tf.variable_scope(scope):",
            "action_layer = linear(layer_input=network.output, config={'num_outputs': action_count}, scope='outputs')",
            "+            action_layer = tf.reshape(action_layer, [-1, action_count])",
            "+",
            "distribution = tf.nn.softmax(action_layer)",
            "sample = tf.multinomial(distribution, 1)"
        ],
        "comments": "add API call for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 221,
        "label": "no",
        "change": [
            "class SingleRoIExtractor(nn.Module):",
            "out_size = self.roi_layers[0].out_size",
            "num_levels = len(feats)",
            "target_lvls = self.map_roi_levels(rois, num_levels)",
            "-        roi_feats = torch.cuda.FloatTensor(rois.size()[0], self.out_channels,",
            "-                                           out_size, out_size).fill_(0)",
            "+        roi_feats = feats[0].new_zeros(rois.size()[0], self.out_channels,",
            "+                                       out_size, out_size)",
            "for i in range(num_levels):",
            "inds = target_lvls == i",
            "if inds.any():"
        ],
        "comments": "version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 222,
        "label": "no",
        "change": [
            "def test(data,",
            "else:  # called by train.py",
            "training = True",
            "device = next(model.parameters()).device  # get model device",
            "-        half = device.type != 'cpu'  # half precision only supported on CUDA",
            "+        half = device.type != 'cpu' and torch.cuda.device_count() == 1  # half precision only supported on single-GPU",
            "if half:",
            "model.half()  # to FP16"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 223,
        "label": "no",
        "change": [
            "class MobileNetV3LargeEncoder(MobileNetV3):",
            ")",
            "",
            "if pretrained:",
            "-            self.load_state_dict(load_state_dict_from_url(",
            "+            self.load_state_dict(torch.hub.load_state_dict_from_url(",
            "'https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth'))",
            "",
            "del self.avgpool"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 224,
        "label": "no",
        "change": [
            "def make_non_pad_mask(lengths):",
            "\"\"\"",
            "bs = int(len(lengths))",
            "maxlen = int(max(lengths))",
            "-    mask = torch.zeros(bs, maxlen).byte()",
            "+    mask = torch.zeros(bs, maxlen, dtype=torch.uint8)",
            "for i, l in enumerate(lengths):",
            "mask[i, :l] = 1"
        ],
        "comments": "add param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 225,
        "label": "no",
        "change": [
            "class BeitForMaskedImageModeling(BeitPreTrainedModel):",
            "",
            "outputs = self.beit(",
            "pixel_values,",
            "+            bool_masked_pos=bool_masked_pos,",
            "head_mask=head_mask,",
            "output_attentions=output_attentions,",
            "output_hidden_states=output_hidden_states,"
        ],
        "comments": "no API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 226,
        "label": "no",
        "change": [
            "class Embedding(AbsFrontend):",
            "assert check_argument_types()",
            "super().__init__()",
            "self.embed_dim = embed_dim",
            "-        self.padding = padding",
            "self.embed_scale = 1.0 if no_embed_scale else math.sqrt(embed_dim)",
            "-        self.embed = torch.nn.Embedding(input_size, embed_dim, padding_idx=padding)",
            "+        self.embed = torch.nn.Embedding(input_size, embed_dim)",
            "",
            "def forward(",
            "self, input: torch.Tensor, input_lengths: torch.Tensor"
        ],
        "comments": "remove constraint",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 227,
        "label": "no",
        "change": [
            "class Finfo:",
            "# -------------------#",
            "",
            "",
            "-def astype(x: torch.Tensor, dtype: torch.dtype, *, copy: bool = True) -> torch.Tensor:",
            "+def astype(",
            "+    x: torch.Tensor, dtype: torch.dtype, /, *, copy: bool = True",
            "+) -> torch.Tensor:",
            "dtype = ivy.as_native_dtype(dtype)",
            "if isinstance(dtype, str):",
            "dtype = ivy.as_native_dtype(dtype)"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 229,
        "label": "no",
        "change": [
            "class TFXGLMPreTrainedModel(TFPreTrainedModel):",
            "@tf.function(",
            "input_signature=[",
            "{",
            "-                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),",
            "-                \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),",
            "+                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),",
            "+                \"attention_mask\": tf.TensorSpec((None, None), tf.int64, name=\"attention_mask\"),",
            "}",
            "]",
            ")"
        ],
        "comments": "change param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 231,
        "label": "no",
        "change": [
            "class SpeedyResNet:",
            "nn.Linear(512, num_classes, bias=False)",
            "]",
            "",
            "-  # note, pytorch just uses https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html instead of logsoftmax",
            "-  def __call__(self, x): return x.sequential(self.net).logsoftmax()",
            "+  # note, pytorch just uses https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html instead of log_softmax",
            "+  def __call__(self, x): return x.sequential(self.net).log_softmax()",
            "",
            "from extra.jit import TinyJit",
            "@TinyJit"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 233,
        "label": "no",
        "change": [
            "class TacotronTrainTest(unittest.TestCase):",
            "optimizer = optim.Adam(model.parameters(), lr=c.lr)",
            "for i in range(5):",
            "mel_out, linear_out, align, stop_tokens = model.forward(",
            "-                input, mel_spec)",
            "+                input, input_lengths, mel_spec)",
            "assert stop_tokens.data.max() <= 1.0",
            "assert stop_tokens.data.min() >= 0.0",
            "optimizer.zero_grad()"
        ],
        "comments": "add param for argument fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 234,
        "label": "yes",
        "change": [
            "class EulerAncestralDiscreteScheduler(SchedulerMixin, ConfigMixin):",
            "",
            "prev_sample = sample + derivative * dt",
            "",
            "-        device = model_output.device if torch.is_tensor(model_output) else torch.device(\"cpu\")",
            "+        device = model_output.device",
            "if device.type == \"mps\":",
            "# randn does not work reproducibly on mps",
            "noise = torch.randn(model_output.shape, dtype=model_output.dtype, device=\"cpu\", generator=generator).to("
        ],
        "comments": "remove condition check for resource fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 236,
        "label": "no",
        "change": [
            "def _create_fc(num_features, num_classes, use_conv=False):",
            "elif use_conv:",
            "fc = nn.Conv2d(num_features, num_classes, 1, bias=True)",
            "else:",
            "-        # NOTE: using my Linear wrapper that fixes AMP + torchscript casting issue",
            "-        fc = Linear(num_features, num_classes, bias=True)",
            "+        fc = nn.Linear(num_features, num_classes, bias=True)",
            "return fc"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 237,
        "label": "no",
        "change": [
            "class OnlineLinearRegression(nn.Module):",
            "batch_dots = batch_dots.reshape([B, C])",
            "return batch_dots",
            "",
            "-    def forward(self, x, sample_theta=False):",
            "+    def forward(self, x: TensorType, sample_theta: bool = False):",
            "\"\"\"Predict scores on input batch using the underlying linear model.",
            "",
            "Args:",
            "-            x (torch.Tensor): Input feature tensor of shape",
            "-                (batch_size, feature_dim)",
            "-            sample_theta (bool): Whether to sample the weights from its",
            "+            x: Input feature tensor of shape (batch_size, feature_dim)",
            "+            sample_theta: Whether to sample the weights from its",
            "posterior distribution to perform Thompson Sampling as per",
            "http://proceedings.mlr.press/v28/agrawal13.pdf .",
            "\"\"\""
        ],
        "comments": "no API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 240,
        "label": "no",
        "change": [
            "class SequenceAccuracy(Metric):",
            "A tensor of predictions of shape (batch_size, k, sequence_length).",
            "gold_labels : `torch.Tensor`, required.",
            "A tensor of integer class label of shape (batch_size, sequence_length).",
            "-        mask : `torch.BoolTensor`, optional (default = None).",
            "+        mask : `torch.BoolTensor`, optional (default = `None`).",
            "A masking tensor the same size as `gold_labels`.",
            "\"\"\"",
            "predictions, gold_labels, mask = self.detach_tensors(predictions, gold_labels, mask)"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 241,
        "label": "no",
        "change": [
            "class GenerationMixin:",
            "continue  # don't waste resources running the code we don't need",
            "",
            "next_token_logits = outputs.logits[:, -1, :]",
            "-",
            "-            # hack: adjust tokens for Marian. For Marian we have to make sure that the `pad_token_id`",
            "-            # cannot be generated both before and after the `nn.functional.log_softmax` operation.",
            "-            next_token_logits = outputs.logits[:, -1, :]",
            "# hack: adjust tokens for Marian. For Marian we have to make sure that the `pad_token_id`",
            "# cannot be generated both before and after the `nn.functional.log_softmax` operation.",
            "next_token_logits = self.adjust_logits_during_generation(next_token_logits, cur_len=cur_len)"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 242,
        "label": "no",
        "change": [
            "def get_commit_hash():",
            "return commit",
            "",
            "",
            "-def create_experiment_folder(root_path, model_name, debug):",
            "+def create_experiment_folder(root_path, model_name):",
            "\"\"\"Create a folder with the current date and time\"\"\"",
            "date_str = datetime.datetime.now().strftime(\"%B-%d-%Y_%I+%M%p\")",
            "-    if debug:",
            "-        commit_hash = \"debug\"",
            "-    else:",
            "-        commit_hash = get_commit_hash()",
            "+    commit_hash = get_commit_hash()",
            "output_folder = os.path.join(root_path, model_name + \"-\" + date_str + \"-\" + commit_hash)",
            "os.makedirs(output_folder, exist_ok=True)",
            "print(\" > Experiment folder: {}\".format(output_folder))"
        ],
        "comments": "remove debug",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 243,
        "label": "no",
        "change": [
            "def k_hop_subgraph(node_idx, num_hops, edge_index, relabel_nodes=False,",
            "node_mask[subsets[-1]] = True",
            "torch.index_select(node_mask, 0, row, out=edge_mask)",
            "subsets.append(col[edge_mask])",
            "-    subset = torch.cat(subsets).unique(sorted=False)",
            "+    subset = torch.cat(subsets).unique()",
            "# Add `node_idx` to the beginning of `subset`.",
            "subset = subset[subset != node_idx]",
            "subset = torch.cat([torch.tensor([node_idx], device=row.device), subset])"
        ],
        "comments": "test fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 244,
        "label": "no",
        "change": [
            "def test_runway_sd_1_5_negative_prompt(sd_device, strategy, sampler):",
            "def test_cv2(strategy, cv2_flag, cv2_radius):",
            "model = ModelManager(",
            "name=\"cv2\",",
            "-        device=device,",
            "+        device=torch.device(device),",
            ")",
            "cfg = get_config(strategy, cv2_flag=cv2_flag, cv2_radius=cv2_radius)",
            "assert_equal("
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 245,
        "label": "yes",
        "change": [
            "class Model(ModelDesc):",
            "summary.add_moving_summary(self.cost)",
            "",
            "def _get_optimizer(self):",
            "-        lr = tf.get_variable('learning_rate', initializer=1e-3, trainable=False)",
            "+        lr = tf.get_variable('learning_rate', initializer=self.learning_rate, trainable=False)",
            "opt = tf.train.AdamOptimizer(lr, epsilon=1e-3)",
            "return optimizer.apply_grad_processors(",
            "opt, [gradproc.GlobalNormClip(10), gradproc.SummaryGradient()])"
        ],
        "comments": "parameterize the parameter",
        "Symptom": "low efficiency",
        "Root_Cause": "argument error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 246,
        "label": "no",
        "change": [
            "class Network(object):",
            "weights = self.make_var('weights', shape=[dim, num_out])",
            "biases = self.make_var('biases', [num_out])",
            "op = tf.nn.relu_layer if relu else tf.nn.xw_plus_b",
            "-            fc = op(feed_in, weights, biases, name=scope.name)",
            "+            #fc = op(feed_in, weights, biases, name=scope.name)",
            "+            fc = op(feed_in, weights, biases, name=name)",
            "return fc"
        ],
        "comments": "change name",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 250,
        "label": "no",
        "change": [
            "def train_cnn_and_compute_accuracy(params, steps, train_images, train_labels, va",
            "# Do the training and evaluation.",
            "with tf.Session() as sess:",
            "# Initialize the network weights.",
            "-    sess.run(tf.initialize_all_variables())",
            "+    sess.run(tf.global_variables_initializer())",
            "for i in range(1, steps + 1):",
            "# Fetch the next batch of data.",
            "image_batch = get_batch(train_images, i, batch_size)"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 251,
        "label": "no",
        "change": [
            "def actor_critic_loss(policy, model, dist_class, train_batch):",
            "values = model.value_function()",
            "dist = dist_class(logits, model)",
            "log_probs = dist.logp(train_batch[SampleBatch.ACTIONS])",
            "-    policy.entropy = dist.entropy().mean()",
            "+    policy.entropy = dist.entropy().sum()",
            "policy.pi_err = -train_batch[Postprocessing.ADVANTAGES].dot(",
            "log_probs.reshape(-1))",
            "-    policy.value_err = nn.functional.mse_loss(",
            "-        values.reshape(-1), train_batch[Postprocessing.VALUE_TARGETS])",
            "+    policy.value_err = torch.sum(",
            "+        torch.pow(",
            "+            values.reshape(-1) - train_batch[Postprocessing.VALUE_TARGETS],",
            "+            2.0))",
            "overall_err = sum([",
            "policy.pi_err,",
            "policy.config[\"vf_loss_coeff\"] * policy.value_err,"
        ],
        "comments": "change API call for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 252,
        "label": "no",
        "change": [
            "class DeepSpeedDataLoader(object):",
            "else:",
            "if data_sampler is None:",
            "data_sampler = RandomSampler(dataset)",
            "-                device_count = torch.cuda.device_count()",
            "+                device_count = get_accelerator().device_count()",
            "batch_size *= device_count",
            "",
            "if num_local_io_workers is None:"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 253,
        "label": "no",
        "change": [
            "class CategoricalToNumerical(preprocessor.Preprocessor):",
            "\"column_names\": config[\"column_names\"],",
            "}",
            "obj = cls(**init_config)",
            "-        obj.layer = keras_layers.MultiCategoryEncoding(config[\"encoding\"])",
            "-        obj.layer.build(None)",
            "+        obj.layer = preprocessors.deserialize(config[\"layer\"])",
            "for encoding_layer, vocab in zip(",
            "obj.layer.encoding_layers, config[\"encoding_vocab\"]",
            "):"
        ],
        "comments": "typo fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 254,
        "label": "no",
        "change": [
            "def transform_bbox(trans_mat: torch.Tensor, boxes: torch.Tensor, mode: str = \"xy",
            "boxes[..., -2] = boxes[..., 0] + boxes[..., -2]  # x + w",
            "boxes[..., -1] = boxes[..., 1] + boxes[..., -1]  # y + h",
            "",
            "-    transformed_boxes: torch.Tensor = kornia.transform_points(trans_mat, boxes.view(boxes.shape[0], -1, 2))",
            "+    transformed_boxes: torch.Tensor = transform_points(trans_mat, boxes.view(boxes.shape[0], -1, 2))",
            "transformed_boxes = transformed_boxes.view_as(boxes)",
            "",
            "if mode == 'xywh':"
        ],
        "comments": "use customized API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 255,
        "label": "no",
        "change": [
            "def test_feature_encoder_layer():",
            "",
            "model2 = tf.keras.Model(input_node, hidden_node)",
            "result = model2.predict(data)",
            "-    print(result)",
            "+    model2.predict(data2)",
            "assert result[0][0] == result[2][0]",
            "assert result[0][0] != result[1][0]",
            "assert result[0][1] != result[1][1]"
        ],
        "comments": "print fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 257,
        "label": "no",
        "change": [
            "def asin(x: Union[tf.Tensor, tf.Variable]) -> Union[tf.Tensor, tf.Variable]:",
            "return tf.asin(x)",
            "",
            "",
            "-def asinh(",
            "-        x: Union[tf.Tensor, tf.Variable]",
            "-) -> Union[tf.Tensor, tf.Variable]:",
            "-    x = tf.cast(x, tf.float32)",
            "+def asinh(x: Union[tf.Tensor, tf.Variable]) -> Union[tf.Tensor, tf.Variable]:",
            "return tf.asinh(x)"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 258,
        "label": "no",
        "change": [
            "class StopwatchMeter(Meter):",
            "if self.start_time is not None:",
            "delta = time.perf_counter() - self.start_time",
            "self.sum = self.sum + delta",
            "-            self.n = self.n + n",
            "+            self.n = type_as(self.n, n) + n",
            "",
            "def reset(self):",
            "self.sum = 0  # cumulative time during which stopwatch was active"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 259,
        "label": "no",
        "change": [
            "class RagTokenForGeneration(RagPreTrainedModel):",
            "n_docs = n_docs if n_docs is not None else self.config.n_docs",
            "",
            "# RAG-token marginalization",
            "-        seq_logprobs = torch.nn.functional.log_softmax(seq_logits, dim=-1).view(",
            "+        seq_logprobs = nn.functional.log_softmax(seq_logits, dim=-1).view(",
            "seq_logits.shape[0] // n_docs, n_docs, -1, seq_logits.size(-1)",
            ")",
            "doc_logprobs = torch.log_softmax(doc_scores, dim=1)"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 261,
        "label": "no",
        "change": [
            "class HarmonicTimeEncoder(GlobalEncoderBase, torch.nn.Module):",
            "time = frame_timestamp / self.time_divisor",
            "return self._harmonic_embedding(time)  # pyre-ignore: 29",
            "",
            "-    def calc_squared_encoding_norm(self):",
            "-        return 0.0",
            "+    def calculate_squared_encoding_norm(self) -> Optional[torch.Tensor]:",
            "+        return None"
        ],
        "comments": "def",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 263,
        "label": "no",
        "change": [
            "class ElmoLstm(_EncoderBase):",
            "",
            "# Returns",
            "",
            "-        A `torch.Tensor` of shape (num_layers, batch_size, sequence_length, hidden_size),",
            "-        where the num_layers dimension represents the LSTM output from that layer.",
            "+        `torch.Tensor`",
            "+            A `torch.Tensor` of shape (num_layers, batch_size, sequence_length, hidden_size),",
            "+            where the num_layers dimension represents the LSTM output from that layer.",
            "\"\"\"",
            "batch_size, total_sequence_length = mask.size()",
            "stacked_sequence_output, final_states, restoration_indices = self.sort_and_run_forward("
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 265,
        "label": "no",
        "change": [
            "class HorovodTrainer(DataParallelTrainer):",
            "),",
            ")",
            "train_dataset = ray.data.from_items([{\"x\": x, \"y\": x + 1} for x in range(32)])",
            "-        scaling_config = ScalingConfig(num_workers=3)",
            "-        # If using GPUs, use the below scaling config instead.",
            "-        # scaling_config = ScalingConfig(num_workers=3, use_gpu=True)",
            "+        scaling_config = ScalingConfig(num_workers=3, use_gpu=use_gpu)",
            "trainer = HorovodTrainer(",
            "train_loop_per_worker=train_loop_per_worker,",
            "scaling_config=scaling_config,"
        ],
        "comments": "add param for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 266,
        "label": "no",
        "change": [
            "class TestStackedSelfAttention(AllenNlpTestCase):",
            "feedforward_hidden_dim=5,",
            "num_layers=3,",
            "num_attention_heads=3)",
            "-        inputs = Variable(torch.randn([3, 5, 9]))",
            "+        inputs = torch.randn([3, 5, 9])",
            "encoder_output = encoder(inputs, None)",
            "assert list(encoder_output.size()) == [3, 5, 12]"
        ],
        "comments": "remove API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 267,
        "label": "no",
        "change": [
            "def qr(A: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:  # pragma: no cove",
            "\"\"\"",
            "Like torch.linalg.qr.",
            "\"\"\"",
            "-    if hasattr(torch.linalg, \"qr\"):",
            "+    if hasattr(torch, \"linalg\") and hasattr(torch.linalg, \"qr\"):",
            "# PyTorch version >= 1.9",
            "return torch.linalg.qr(A)",
            "return torch.qr(A)"
        ],
        "comments": "change condition check for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 268,
        "label": "yes",
        "change": [
            "def prepare_bart_inputs_dict(",
            "if decoder_attention_mask is None:",
            "decoder_attention_mask = decoder_input_ids.ne(config.pad_token_id)",
            "if head_mask is None:",
            "-        head_mask = torch.ones(config.encoder_layers, config.encoder_attention_heads)",
            "+        head_mask = torch.ones(config.encoder_layers, config.encoder_attention_heads, device=torch_device)",
            "if decoder_head_mask is None:",
            "-        decoder_head_mask = torch.ones(config.decoder_layers, config.decoder_attention_heads)",
            "+        decoder_head_mask = torch.ones(config.decoder_layers, config.decoder_attention_heads, device=torch_device)",
            "return {",
            "\"input_ids\": input_ids,",
            "\"decoder_input_ids\": decoder_input_ids,"
        ],
        "comments": "add param for resource fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "addition",
        "Element": "api parameter"
    },
    {
        "number": 269,
        "label": "no",
        "change": [
            "class PNDMSchedulerTest(SchedulerCommonTest):",
            "scheduler_config = self.get_scheduler_config(steps_offset=1)",
            "scheduler = scheduler_class(**scheduler_config)",
            "scheduler.set_timesteps(10)",
            "-        assert np.equal(",
            "+        assert torch.equal(",
            "scheduler.timesteps,",
            "-            np.array([901, 851, 851, 801, 801, 751, 751, 701, 701, 651, 651, 601, 601, 501, 401, 301, 201, 101, 1]),",
            "-        ).all()",
            "+            torch.LongTensor(",
            "+                [901, 851, 851, 801, 801, 751, 751, 701, 701, 651, 651, 601, 601, 501, 401, 301, 201, 101, 1]",
            "+            ),",
            "+        )",
            "",
            "def test_betas(self):",
            "for beta_start, beta_end in zip([0.0001, 0.001], [0.002, 0.02]):"
        ],
        "comments": "assertion test",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 270,
        "label": "no",
        "change": [
            "class DreamerModel(TorchModelV2, nn.Module):",
            "and policy to obtain action.",
            "\"\"\"",
            "if state is None:",
            "-            self.initial_state()",
            "+            self.state = self.get_initial_state(batch_size=obs.shape[0])",
            "else:",
            "self.state = state",
            "post = self.state[:4]"
        ],
        "comments": "add param for state fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 271,
        "label": "no",
        "change": [
            "class Plan(Serializable):",
            "# prevent circular dependency",
            "# syft relative",
            "from ...core.node.vm.vm import VirtualMachine  # noqa: F401",
            "+        if self.local_executor is not None:",
            "+            # this is necessary for syfts nn.module, because the plan contains state from the module",
            "+            # in order to use this state, we first need to send the model, and then execute te plan",
            "+            return self.local_executor(**kwargs)",
            "",
            "alice = VirtualMachine(name=\"plan_executor\")",
            "alice_client: client.Client = alice.get_client()"
        ],
        "comments": "add condition check for null fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 272,
        "label": "no",
        "change": [
            "class GradTTS(DiffusionPipeline):",
            "mu_y = mu_y.transpose(1, 2)",
            "",
            "# Sample latent representation from terminal distribution N(mu_y, I)",
            "-        z = mu_y + torch.randn_like(mu_y, device=mu_y.device) / temperature",
            "+        z = mu_y + torch.randn(mu_y.shape, device=mu_y.device, generator=generator) / temperature",
            "",
            "xt = z * y_mask",
            "h = 1.0 / num_inference_steps"
        ],
        "comments": "change API call for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 273,
        "label": "no",
        "change": [
            "class NanDetector:",
            "gradients = {}",
            "for name, param in self.named_parameters:",
            "if param.grad is not None:",
            "-                grad_norm = torch.norm(param.grad.data, p=2, dtype=torch.float32)",
            "+                grad_norm = torch.norm(param.grad.data.float(), p=2)",
            "norm[name] = grad_norm.item()",
            "if torch.isnan(grad_norm).any() or torch.isinf(grad_norm).any():",
            "gradients[name] = param.grad.data"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 274,
        "label": "yes",
        "change": [
            "def create_loader(",
            "# of samples per-process, will slightly alter validation results",
            "sampler = OrderedDistributedSampler(dataset)",
            "",
            "+    if collate_fn is None:",
            "+        collate_fn = fast_collate if use_prefetcher else torch.utils.data.dataloader.default_collate",
            "+",
            "loader = torch.utils.data.DataLoader(",
            "dataset,",
            "batch_size=batch_size,",
            "shuffle=sampler is None and is_training,",
            "num_workers=num_workers,",
            "sampler=sampler,",
            "-        collate_fn=fast_collate if use_prefetcher else torch.utils.data.dataloader.default_collate,",
            "+        collate_fn=collate_fn,",
            "drop_last=is_training,",
            ")",
            "if use_prefetcher:"
        ],
        "comments": "add condition check for null fix",
        "Symptom": "low efficiency",
        "Root_Cause": "argument error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 276,
        "label": "no",
        "change": [
            "def set_gpu_fraction(gpu_fraction=0.3):",
            "",
            "",
            "def train_epoch(",
            "-        network, X, y, cost, train_op=tf.optimizers.Adam(learning_rate=0.0001), acc=None, batch_size=100, shuffle=True",
            "+    network, X, y, cost, train_op=tf.optimizers.Adam(learning_rate=0.0001), acc=None, batch_size=100, shuffle=True",
            "):",
            "\"\"\"Training a given non time-series network by the given cost function, training data, batch_size etc.",
            "for one epoch."
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 277,
        "label": "no",
        "change": [
            "def fpn_map_rois_to_levels(boxes):",
            "Be careful that the returned tensor could be empty.",
            "\"\"\"",
            "sqrtarea = tf.sqrt(tf_area(boxes))",
            "-    level = tf.to_int32(tf.floor(",
            "-        4 + tf.log(sqrtarea * (1. / 224) + 1e-6) * (1.0 / np.log(2))))",
            "+    level = tf.cast(tf.floor(",
            "+        4 + tf.log(sqrtarea * (1. / 224) + 1e-6) * (1.0 / np.log(2))), tf.int32)",
            "",
            "# RoI levels range from 2~5 (not 6)",
            "level_ids = ["
        ],
        "comments": "log update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 278,
        "label": "no",
        "change": [
            "def mesh_laplacian_smoothing(meshes, method: str = \"uniform\"):",
            "elif method == \"cot\":",
            "loss = L.mm(verts_packed) * norm_w - verts_packed",
            "elif method == \"cotcurv\":",
            "-        loss = (L.mm(verts_packed) - verts_packed) * norm_w",
            "+        loss = (L.mm(verts_packed) - L_sum * verts_packed) * norm_w",
            "loss = loss.norm(dim=1)",
            "",
            "loss = loss * weights"
        ],
        "comments": "change param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 279,
        "label": "no",
        "change": [
            "def apply_fixed_architecture(model, fixed_arc_path, device=None):",
            "architecture = FixedArchitecture(model, fixed_arc)",
            "architecture.to(device)",
            "architecture.reset()",
            "+    return architecture"
        ],
        "comments": "not clear",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 280,
        "label": "no",
        "change": [
            "class AsyncMultiGPUTrainer(MultiGPUTrainer,",
            "",
            "self._setup_predictor_factory(predict_tower)",
            "self._average_gradient = average_gradient",
            "+        assert tf.test.is_gpu_available()",
            "",
            "def _setup(self):",
            "super(AsyncMultiGPUTrainer, self)._setup()"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 281,
        "label": "no",
        "change": [
            "def test_hub_oneshot(space_type, strategy_type):",
            "NDS_SPACES = ['amoeba', 'darts', 'pnas', 'enas', 'nasnet']",
            "if strategy_type == 'proxyless':",
            "if 'width' in space_type or 'depth' in space_type or \\",
            "-                any(space_type.startswith(prefix) for prefix in NDS_SPACES + ['proxylessnas', 'mobilenetv3']):",
            "+                any(space_type.startswith(prefix) for prefix in NDS_SPACES + ['proxylessnas', 'mobilenetv3', 'autoformer']):",
            "pytest.skip('The space has used unsupported APIs.')",
            "if strategy_type in ['darts', 'gumbel'] and space_type == 'mobilenetv3':",
            "pytest.skip('Skip as it consumes too much memory.')"
        ],
        "comments": "add value to list",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 282,
        "label": "no",
        "change": [
            "class GCNConv(MessagePassing):",
            "x = torch.matmul(x, self.weight)",
            "",
            "if not self.cached or self.cached_result is None:",
            "-            edge_index, norm = GCNConv.norm(edge_index,",
            "-                                            x.size(0), edge_weight,",
            "+            edge_index, norm = GCNConv.norm(edge_index, x.size(0), edge_weight,",
            "self.improved, x.dtype)",
            "self.cached_result = edge_index, norm"
        ],
        "comments": "add param for argument fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 283,
        "label": "no",
        "change": [
            "class CTC(torch.nn.Module):",
            "if self.ctc_type == \"builtin\":",
            "olens = to_device(ys_hat, torch.LongTensor([len(s) for s in ys]))",
            "hlens = hlens.long()",
            "+            ys_pad = torch.cat(ys)  # without this the code breaks for asr_mix",
            "self.loss = self.loss_fn(ys_hat, ys_pad, hlens, olens)",
            "else:",
            "self.loss = None"
        ],
        "comments": "add API call for shape fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 284,
        "label": "no",
        "change": [
            "class CategoryOutputFeature(CategoryFeatureMixin, OutputFeature):",
            "# hidden: shape [batch_size, size of final fully connected layer]",
            "return {LOGITS: self.decoder_obj(hidden), PROJECTION_INPUT: hidden}",
            "",
            "-    def create_calibration_module(self, feature) -> torch.nn.Module:",
            "+    def create_calibration_module(self, feature: CategoryOutputFeatureConfig) -> torch.nn.Module:",
            "\"\"\"Creates the appropriate calibration module based on the feature config.",
            "",
            "Today, only one type of calibration (\"temperature_scaling\") is available, but more options may be supported in",
            "the future.",
            "\"\"\"",
            "-        if feature.get(\"calibration\"):",
            "+        if feature.calibration:",
            "calibration_cls = calibration.get_calibration_cls(CATEGORY, \"temperature_scaling\")",
            "return calibration_cls(num_classes=self.num_classes)",
            "return None"
        ],
        "comments": "def",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 285,
        "label": "no",
        "change": [
            "class PiecewiseConstant(Parameter):",
            "self.values = values",
            "",
            "def get_parameter_value(self):",
            "-        if self.unit == 'timestep':",
            "+        if self.unit == 'timesteps':",
            "step = Module.retrieve_tensor(name='timestep')",
            "-        elif self.unit == 'episode':",
            "+        elif self.unit == 'episodes':",
            "step = Module.retrieve_tensor(name='episode')",
            "",
            "+        # step = tf.Print(step, (step,))",
            "+",
            "parameter = tf.train.piecewise_constant(",
            "x=step, boundaries=self.boundaries, values=self.values",
            ")"
        ],
        "comments": "change value",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 286,
        "label": "yes",
        "change": [
            "def test_gcn_conv():",
            "assert out2.size() == (4, 32)",
            "assert torch.allclose(conv(x, adj2.t()), out2, atol=1e-6)",
            "",
            "-    torch.jit.script(conv.jittable())",
            "-",
            "t = '(Tensor, Tensor, OptTensor) -> Tensor'",
            "jit = torch.jit.script(conv.jittable(t))",
            "assert jit(x, edge_index).tolist() == out1.tolist()"
        ],
        "comments": "test fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "removal",
        "Element": "api call"
    },
    {
        "number": 287,
        "label": "yes",
        "change": [
            "def main():",
            "train_dataset, shuffle=True, collate_fn=collate_fn, batch_size=total_train_batch_size, drop_last=True",
            ")",
            "",
            "-    weight_dtype = torch.float32",
            "+    weight_dtype = jnp.float32",
            "if args.mixed_precision == \"fp16\":",
            "-        weight_dtype = torch.float16",
            "+        weight_dtype = jnp.float16",
            "elif args.mixed_precision == \"bf16\":",
            "-        weight_dtype = torch.bfloat16",
            "+        weight_dtype = jnp.bfloat16",
            "",
            "# Load models and create wrapper for stable diffusion",
            "tokenizer = CLIPTokenizer.from_pretrained(args.pretrained_model_name_or_path, subfolder=\"tokenizer\")"
        ],
        "comments": "no API",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 290,
        "label": "no",
        "change": [
            "class ReplicatedSharingTensor(AbstractTensor):",
            "return self.__private_multiplication_operation(secret, mul)",
            "",
            "__mul__ = mul",
            "+    __rmul__ = mul",
            "",
            "def matmul(self, value):",
            "return self.__switch_public_private(value, self.__public_matmul, self.__private_matmul)"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 293,
        "label": "no",
        "change": [
            "class TestJitLSTMModel(unittest.TestCase):",
            "scripted_model = torch.jit.script(model)",
            "self._test_save_and_load(scripted_model)",
            "",
            "-    @unittest.skipIf(",
            "-        torch.__version__ < \"1.6.0\", \"Targeting OSS scriptability for the 1.6 release\"",
            "-    )",
            "def test_assert_jit_vs_nonjit_(self):",
            "task, parser = get_dummy_task_and_parser()",
            "LSTMModel.add_args(parser)"
        ],
        "comments": "remove version fixcheck",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 294,
        "label": "no",
        "change": [
            "def test_result_reduce_ddp(result_cls):",
            "pytest.param(5, False, 0, id='nested_list_predictions'),",
            "pytest.param(6, False, 0, id='dict_list_predictions'),",
            "pytest.param(7, True, 0, id='write_dict_predictions'),",
            "-        pytest.param(",
            "-            0,",
            "-            True,",
            "-            1,",
            "-            id='full_loop_single_gpu',",
            "-            marks=pytest.mark.skipif(torch.cuda.device_count() < 1, reason=\"test requires single-GPU machine\")",
            "-        )",
            "+        pytest.param(0, True, 1, id='full_loop_single_gpu', marks=pytest.mark.skipif(**_SKIPIF_ARGS_NO_GPU))",
            "]",
            ")",
            "def test_result_obj_predictions(tmpdir, test_option, do_train, gpus):"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 295,
        "label": "no",
        "change": [
            "def count_flops_params(model, x, custom_ops=None, verbose=True, mode='default'):",
            "print(f'FLOPs total: {profiler.sum_flops()}')",
            "print(f'#Params total: {profiler.sum_params()}')",
            "",
            "-    return profiler.sum_flops(), profiler.sum_params(), profiler.results",
            "\\ No newline at end of file",
            "+    return profiler.sum_flops(), profiler.sum_params(), profiler.results"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 296,
        "label": "no",
        "change": [
            "class DeformableDetrModelIntegrationTests(unittest.TestCase):",
            "results = feature_extractor.post_process_object_detection(",
            "outputs, threshold=0.3, target_sizes=[image.size[::-1]]",
            ")[0]",
            "-        expected_scores = torch.tensor([0.7999, 0.7894, 0.6331, 0.4720, 0.4382])",
            "+        expected_scores = torch.tensor([0.7999, 0.7894, 0.6331, 0.4720, 0.4382]).to(torch_device)",
            "expected_labels = [17, 17, 75, 75, 63]",
            "-        expected_slice_boxes = torch.tensor([16.5028, 52.8390, 318.2544, 470.7841])",
            "+        expected_slice_boxes = torch.tensor([16.5028, 52.8390, 318.2544, 470.7841]).to(torch_device)",
            "",
            "self.assertEqual(len(results[\"scores\"]), 5)",
            "self.assertTrue(torch.allclose(results[\"scores\"], expected_scores, atol=1e-4))"
        ],
        "comments": "add API call for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 297,
        "label": "no",
        "change": [
            "class Critic(object):",
            "n = InputLayer(self.s, name='in')",
            "n = DenseLayer(n, n_units=30, act=tf.nn.relu6, W_init=tf.random_uniform_initializer(0, 0.01), name='hidden')",
            "# n = DenseLayer(n, n_units=5, act=tf.nn.relu, W_init=tf.random_uniform_initializer(0, 0.01), name='hidden2')",
            "-            n = DenseLayer(n, n_units=1, act=tf.identity, name='V')",
            "+            n = DenseLayer(n, n_units=1, act=None, name='V')",
            "self.v = n.outputs",
            "",
            "with tf.variable_scope('squared_TD_error'):"
        ],
        "comments": "change param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 298,
        "label": "no",
        "change": [
            "class TensorflowBackendInferenceLearner(TensorflowBaseInferenceLearner):",
            "metadata = LearnerMetadata.read(path)",
            "network_parameters = ModelParams(**metadata.network_parameters)",
            "input_tfms = metadata.input_tfms",
            "-        model = nebullvm.operations.inference_learners.utils.load_model(",
            "+        model = tf.keras.models.load_model(",
            "path / TENSORFLOW_BACKEND_FILENAMES[\"tf_model\"]",
            ")",
            "device = Device(metadata.device)"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 300,
        "label": "no",
        "change": [
            "FileType = Any",
            "# Represents the result dict returned by Trainer.train().",
            "ResultDict = dict",
            "",
            "+# A tf or torch local optimizer object.",
            "+LocalOptimizer = Union[\"tf.keras.optimizers.Optimizer\",",
            "+                       \"torch.optim.Optimizer\"]",
            "+",
            "# Dict of tensors returned by compute gradients on the policy, e.g.,",
            "# {\"td_error\": [...], \"learner_stats\": {\"vf_loss\": ..., ...}}, for multi-agent,",
            "# {\"policy1\": {\"learner_stats\": ..., }, \"policy2\": ...}."
        ],
        "comments": "add API call for state fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 301,
        "label": "no",
        "change": [
            "class CLImage:",
            "",
            "class CLBuffer:",
            "def __init__(self, size): self.cl = cuda.mem_alloc(size)",
            "-  def copyin(self, b:np.ndarray): cuda.memcpy_htod_async(self.cl, b)",
            "+  def copyin(self, b:np.ndarray, stream:Optional[cuda.Stream]=None): cuda.memcpy_htod_async(self.cl, b, stream)",
            "def copyout(self, a:np.ndarray): cuda.memcpy_dtoh(a, self.cl)",
            "",
            "class CLProgram:"
        ],
        "comments": "method define",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 302,
        "label": "yes",
        "change": [
            "def rmsle(",
            ">>> x = torch.tensor([0., 1, 2, 3])",
            ">>> y = torch.tensor([0., 1, 2, 2])",
            ">>> rmsle(x, y)",
            "-        tensor(0.0207)",
            "+        tensor(0.1438)",
            "",
            "\"\"\"",
            "-    rmsle = mse(torch.log(pred + 1), torch.log(target + 1), reduction=reduction)",
            "+    rmsle = rmse(torch.log(pred + 1), torch.log(target + 1), reduction=reduction)",
            "return rmsle"
        ],
        "comments": "value change",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 303,
        "label": "yes",
        "change": [
            "def add_dataset_args(parser, train=False, gen=False):",
            "",
            "def add_distributed_training_args(parser):",
            "group = parser.add_argument_group('Distributed training')",
            "-    group.add_argument('--distributed-world-size', default=1, type=int, metavar='N',",
            "-                       help='total number of GPUs across all nodes, default: 1 GPU')",
            "+    group.add_argument('--distributed-world-size', type=int, metavar='N',",
            "+                       default=torch.cuda.device_count(),",
            "+                       help='total number of GPUs across all nodes (default: all visible GPUs)')",
            "group.add_argument('--distributed-rank', default=0, type=int,",
            "help='rank of the current worker')",
            "group.add_argument('--distributed-backend', default='nccl', type=str,"
        ],
        "comments": "test fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 304,
        "label": "no",
        "change": [
            "class DCCRNSeparator(AbsSeparator):",
            "self.flatten_parameters()",
            "",
            "def forward(",
            "-        self,",
            "-        input: Union[torch.Tensor, ComplexTensor],",
            "+        self,",
            "+        input: Union[torch.Tensor, ComplexTensor],",
            "ilens: torch.Tensor,",
            "additional: Optional[Dict] = None,",
            ") -> Tuple[List[Union[torch.Tensor, ComplexTensor]], torch.Tensor, OrderedDict]:"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 305,
        "label": "no",
        "change": [
            "def ones_like(x, name=None):",
            "[ 1.,  1.,  1.]], dtype=float32)",
            "```",
            "\"\"\"",
            "-    return tf.ones_like(x, name=name)",
            "+    return tf.ones_like(x, dtype=dtype, name=name)",
            "",
            "",
            "def random_uniform_variable(shape, low, high, dtype=None,"
        ],
        "comments": "add param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 306,
        "label": "yes",
        "change": [
            "class Ensemble(nn.ModuleList):",
            "return y, None  # inference, train output",
            "",
            "",
            "-def attempt_load(weights, map_location=None, inplace=True, fuse=True):",
            "+def attempt_load(weights, device=None, inplace=True, fuse=True):",
            "from models.yolo import Detect, Model",
            "",
            "# Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a",
            "model = Ensemble()",
            "for w in weights if isinstance(weights, list) else [weights]:",
            "-        ckpt = torch.load(attempt_download(w), map_location=map_location)  # load",
            "-        ckpt = (ckpt.get('ema') or ckpt['model']).float()  # FP32 model",
            "+        ckpt = torch.load(attempt_download(w))",
            "+        ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model",
            "model.append(ckpt.fuse().eval() if fuse else ckpt.eval())  # fused or un-fused model in eval mode",
            "",
            "# Compatibility updates"
        ],
        "comments": "rename param for method",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 307,
        "label": "no",
        "change": [
            "from allennlp.common.params import Params",
            "",
            "class TestStackedBidirectionalLstm(AllenNlpTestCase):",
            "def test_stacked_bidirectional_lstm_completes_forward_pass(self):",
            "-        input_tensor = torch.autograd.Variable(torch.rand(4, 5, 3))",
            "+        input_tensor = torch.rand(4, 5, 3)",
            "input_tensor[1, 4:, :] = 0.",
            "input_tensor[2, 2:, :] = 0.",
            "input_tensor[3, 1:, :] = 0."
        ],
        "comments": "remove API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 309,
        "label": "no",
        "change": [
            "class TFCTRLMainLayer(tf.keras.layers.Layer):",
            "token_type_embeds = 0",
            "position_ids = tf.reshape(position_ids, [-1, shape_list(position_ids)[-1]])",
            "",
            "-        inputs_embeds = self.w(input_ids)",
            "+        inputs_embeds = self.w(input_ids, mode='embedding')",
            "# x = embedded.unsqueeze(0) if len(input_ids.shape)<2 else embedded",
            "seq_len = input_shape[-1]",
            "mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)"
        ],
        "comments": "add param for argument fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 310,
        "label": "no",
        "change": [
            "def _preprocess_conv3d_input(x, data_format):",
            "A tensor.",
            "\"\"\"",
            "# tensorflow doesn't support float64 for conv layer before 1.8.0",
            "-    if (dtype(x) == 'float64'",
            "-            and StrictVersion(tf.__version__) < StrictVersion('1.8.0')):",
            "+    if (dtype(x) == 'float64' and",
            "+            StrictVersion(tf.__version__.split('-')[0]) < StrictVersion('1.8.0')):",
            "x = tf.cast(x, 'float32')",
            "tf_data_format = 'NDHWC'",
            "if data_format == 'channels_first':"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 311,
        "label": "no",
        "change": [
            "class XtremeS(datasets.Metric):",
            "tokenize=tokenize,",
            "use_effective_order=use_effective_order,",
            ")",
            "-        elif self.config_name in [\"fleurs-asr\", \"mls\", \"voxpopuli\"]:",
            "+        elif self.config_name in [\"fleurs-asr\", \"mls\", \"voxpopuli\", \"babel\"]:",
            "concatenate_texts = wer_kwargs.pop(\"concatenate_texts\", False)",
            "return wer_and_cer(predictions, references, concatenate_texts, self.config_name)",
            "else:"
        ],
        "comments": "add value",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 312,
        "label": "no",
        "change": [
            "from __future__ import absolute_import, division, print_function",
            "",
            "+import os",
            "+",
            "import torch",
            "",
            "-assert torch.__version__.startswith('1.')",
            "+if 'READTHEDOCS' not in os.environ:",
            "+    # RTD is running 0.4.1 due to a memory issue with pytorch 1.0",
            "+    assert torch.__version__.startswith('1.')",
            "",
            "",
            "def patch_dependency(target, root_module=torch):"
        ],
        "comments": "remove constraint for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 313,
        "label": "no",
        "change": [
            "class DataCollatorForWholeWordMask(DataCollatorForLanguageModeling):",
            "mask_labels = []",
            "for e in examples:",
            "ref_tokens = []",
            "-            for id in e[\"input_ids\"].tolist():",
            "+            for id in tolist(e[\"input_ids\"]):",
            "token = self.tokenizer._convert_id_to_token(id)",
            "ref_tokens.append(token)",
            "",
            "# For Chinese tokens, we need extra inf to mark sub-word, e.g [,]-> [##]",
            "if \"chinese_ref\" in e:",
            "-                ref_pos = e[\"chinese_ref\"].tolist()",
            "+                ref_pos = tolist(e[\"chinese_ref\"])",
            "len_seq = e[\"input_ids\"].size(0)",
            "for i in range(len_seq):",
            "if i in ref_pos:"
        ],
        "comments": "no API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 314,
        "label": "no",
        "change": [
            "class _EagerVariableStore(tf.Module):",
            "layer = create_layer_method()",
            "self._layers[name] = layer",
            "if isinstance(layer, base_layer.Layer):",
            "-        self._regularizers[name] = lambda: layer.losses",
            "+        self._regularizers[name] = lambda: tf.math.reduce_sum(layer.losses)",
            "return self._layers[name]",
            "",
            "def add_regularizer(self, var, regularizer):"
        ],
        "comments": "functional change",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 315,
        "label": "no",
        "change": [
            "class TFWav2Vec2MainLayer(tf.keras.layers.Layer):",
            "if inputs[\"attention_mask\"] is not None:",
            "# compute real output lengths according to convolution formula",
            "output_lengths = self._get_feat_extract_output_lengths(tf.reduce_sum(inputs[\"attention_mask\"], -1))",
            "-            attention_mask = tf.sequence_mask(output_lengths, dtype=hidden_states.dtype)",
            "+",
            "+            attention_mask = tf.sequence_mask(",
            "+                output_lengths, maxlen=shape_list(hidden_states)[1], dtype=hidden_states.dtype",
            "+            )",
            "",
            "hidden_states = self.feature_projection(hidden_states, training=inputs[\"training\"])"
        ],
        "comments": "add param for argument fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 317,
        "label": "no",
        "change": [
            "class DiagNormal(Distribution):",
            "# when the data is a ragged tensor. also useful for KL annealing. this entire logic",
            "# will likely be done in a better/cleaner way in the future",
            "if log_pdf_mask is not None:",
            "-            # TODO fix this to broadcasting as below, e.g. by instead:",
            "-            # log_pxs *= log_pdf_mask  # Then continue with broadcasting logic below.",
            "-            return torch.sum(log_pdf_mask * log_pxs, -1)",
            "+            log_pxs = log_pxs * log_pdf_mask",
            "batch_log_pdf = torch.sum(log_pxs, -1)",
            "batch_log_pdf_shape = x.size()[:-1] + (1,)",
            "return batch_log_pdf.contiguous().view(batch_log_pdf_shape)"
        ],
        "comments": "functional change",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 320,
        "label": "no",
        "change": [
            "class MobileNetV3(nn.Module):",
            "",
            "def forward(self, x):",
            "x = self.forward_features(x)",
            "-        if not self.global_pool.is_identity():",
            "-            x = x.flatten(1)",
            "+        x = self.flatten(x)",
            "if self.drop_rate > 0.:",
            "x = F.dropout(x, p=self.drop_rate, training=self.training)",
            "return self.classifier(x)"
        ],
        "comments": "remove constraint",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 321,
        "label": "no",
        "change": [
            "class ParallelWaveganGenerator(torch.nn.Module):",
            "",
            "def apply_weight_norm(self):",
            "def _apply_weight_norm(m):",
            "-            if isinstance(m, torch.nn.Conv1d) or isinstance(",
            "-                    m, torch.nn.Conv2d):",
            "+            if isinstance(m, (torch.nn.Conv1d, torch.nn.Conv2d)):",
            "torch.nn.utils.weight_norm(m)",
            "# print(f\"Weight norm is applied to {m}.\")"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 322,
        "label": "no",
        "change": [
            "class TFBlipModelIntegrationTest(unittest.TestCase):",
            "out_itm = model(**inputs)",
            "out = model(**inputs, use_itm_head=False, training=False)",
            "",
            "-        expected_scores = tf.convert_to_tensor([[0.9798, 0.0202]])",
            "+        expected_scores = tf.convert_to_tensor([[0.0029, 0.9971]])",
            "self.assertTrue(np.allclose(tf.nn.softmax(out_itm[0]).numpy(), expected_scores, rtol=1e-3, atol=1e-3))",
            "-        self.assertTrue(np.allclose(out[0], tf.convert_to_tensor([[0.5053]]), rtol=1e-3, atol=1e-3))",
            "+        self.assertTrue(np.allclose(out[0], tf.convert_to_tensor([[0.5162]]), rtol=1e-3, atol=1e-3))"
        ],
        "comments": "value change",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 323,
        "label": "no",
        "change": [
            "class BaseModel():",
            "save_filename = '%s_net_%s.pth' % (which_epoch, name)",
            "save_path = os.path.join(self.save_dir, save_filename)",
            "net = getattr(self, 'net' + name)",
            "-                net.load_state_dict(torch.load(save_path))",
            "+                net.module.load_state_dict(torch.load(save_path))",
            "",
            "# print network information",
            "def print_networks(self, verbose):"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 324,
        "label": "no",
        "change": [
            "class SpeedsterRootOp(Operation):",
            ") -> List[BaseInferenceLearner]:",
            "if self.orig_latency_measure_op.get_result() is not None:",
            "model_outputs = self.orig_latency_measure_op.get_result()[0]",
            "-            if isinstance(model, Module):",
            "+            if isinstance(model, torch.nn.Module):",
            "optimization_op = self.torch_optimization_op",
            "elif isinstance(model, tf.Module) and model is not None:",
            "optimization_op = self.tensorflow_optimization_op"
        ],
        "comments": "change param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 325,
        "label": "no",
        "change": [
            "def run(",
            "):",
            "# PyTorch model",
            "im = torch.zeros((batch_size, 3, *imgsz))  # BCHW image",
            "-    model = attempt_load(weights, map_location=torch.device('cpu'), inplace=True, fuse=False)",
            "+    model = attempt_load(weights, device=torch.device('cpu'), inplace=True, fuse=False)",
            "_ = model(im)  # inference",
            "model.info()"
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 327,
        "label": "yes",
        "change": [
            "class GuidedAnchorHead(AnchorHead):",
            "",
            "def _init_layers(self):",
            "self.relu = nn.ReLU(inplace=True)",
            "-        self.conv_loc = nn.Conv2d(self.feat_channels, 1, 1)",
            "-        self.conv_shape = nn.Conv2d(self.feat_channels, self.num_anchors * 2,",
            "-                                    1)",
            "+        self.conv_loc = nn.Conv2d(self.in_channels, 1, 1)",
            "+        self.conv_shape = nn.Conv2d(self.in_channels, self.num_anchors * 2, 1)",
            "self.feature_adaption = FeatureAdaption(",
            "-            self.feat_channels,",
            "+            self.in_channels,",
            "self.feat_channels,",
            "kernel_size=3,",
            "deformable_groups=self.deformable_groups)"
        ],
        "comments": "rename",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 328,
        "label": "yes",
        "change": [
            "class UNet2DConditionModel(ModelMixin, ConfigMixin):",
            "if not torch.is_tensor(timesteps):",
            "timesteps = torch.tensor([timesteps], dtype=torch.long, device=sample.device)",
            "elif torch.is_tensor(timesteps) and len(timesteps.shape) == 0:",
            "-            timesteps = timesteps[None].to(sample.device)",
            "+            timesteps = timesteps.to(dtype=torch.float32)",
            "+            timesteps = timesteps[None].to(device=sample.device)",
            "",
            "# broadcast to batch dimension in a way that's compatible with ONNX/Core ML",
            "timesteps = timesteps.expand(sample.shape[0])"
        ],
        "comments": "update API call for version fix",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 330,
        "label": "no",
        "change": [
            "class DonutModelIntegrationTest(unittest.TestCase):",
            "self.assertEqual(len(outputs.scores), 11)",
            "self.assertTrue(",
            "torch.allclose(",
            "-                outputs.scores[0][0, :3], torch.tensor([5.3153, -3.5276, 13.4781], device=torch_device), atol=1e-4",
            "+                outputs.scores[0][0, :3], torch.tensor([5.6019, -3.5070, 13.7123], device=torch_device), atol=1e-4",
            ")",
            ")"
        ],
        "comments": "value change",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 332,
        "label": "no",
        "change": [
            "def add_moving_summary(*args, **kwargs):",
            "ema_ops.append(ema_op)",
            "with tf.name_scope(None):",
            "# cannot add it into colocate group -- will force everything to cpus",
            "-            tf.summary.scalar(name, ema_op)    # write the EMA value as a summary",
            "+            tf.summary.scalar(name + '-summary', ema_op)    # write the EMA value as a summary",
            "if coll is not None:",
            "for op in ema_ops:",
            "# TODO a new collection to summary every step?"
        ],
        "comments": "value change",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 333,
        "label": "no",
        "change": [
            "class BilinearSimilarity(SimilarityFunction):",
            "self.reset_parameters()",
            "",
            "def reset_parameters(self):",
            "-        torch.nn.init.xavier_uniform(self._weight_matrix)",
            "+        torch.nn.init.xavier_uniform_(self._weight_matrix)",
            "self._bias.data.fill_(0)",
            "",
            "@overrides"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 334,
        "label": "no",
        "change": [
            "class UniformRaySampler(RaySampler):",
            "self._calc_ray_params(cameras, points_2d_camera)",
            "",
            "",
            "-def sample_lengths(num_rays: int, num_ray_points: int, device: Device, dtype: torch.dtype, irregular=False) -> Tensor:",
            "+def sample_lengths(",
            "+    num_rays: int, num_ray_points: int, device: Device, dtype: torch.dtype, irregular: bool = False",
            "+) -> Tensor:",
            "if num_ray_points <= 1:",
            "raise ValueError('Number of ray points must be greater than 1')",
            "if not irregular:"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 335,
        "label": "no",
        "change": [
            "class AdaptiveEmbedding(nn.Module):",
            "",
            "inp_i = inp_flat.index_select(0, indices_i) - l_idx",
            "emb_i = self.emb_layers[i](inp_i)",
            "-                emb_i = F.linear(emb_i, self.emb_projs[i])",
            "+                emb_i = nn.functional.linear(emb_i, self.emb_projs[i])",
            "",
            "emb_flat.index_copy_(0, indices_i, emb_i)"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 337,
        "label": "no",
        "change": [
            "class Residual(tf.keras.Model):  #@save",
            "if self.conv3 is not None:",
            "X = self.conv3(X)",
            "Y += X",
            "-        return tf.keras.activations.relu(Y + X)",
            "+        return tf.keras.activations.relu(Y)"
        ],
        "comments": "change param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 338,
        "label": "yes",
        "change": [
            "def test_with_split(backend, csv_filename, tmpdir):",
            "def test_dask_known_divisions(feature_fn, csv_filename, tmpdir):",
            "import dask.dataframe as dd",
            "",
            "-    num_examples = NUM_EXAMPLES",
            "-",
            "input_features = [feature_fn(os.path.join(tmpdir, \"generated_output\"))]",
            "output_features = [category_feature(vocab_size=5, reduce_input=\"sum\")]",
            "-    data_csv = generate_data(",
            "-        input_features, output_features, os.path.join(tmpdir, csv_filename), num_examples=num_examples",
            "-    )",
            "-    data_df = dd.from_pandas(pd.read_csv(data_csv), npartitions=10)",
            "+",
            "+    # num_examples=100 and npartitions=2 to ensure the test is not flaky, by having non-empty post-split datasets.",
            "+    data_csv = generate_data(input_features, output_features, os.path.join(tmpdir, csv_filename), num_examples=100)",
            "+    data_df = dd.from_pandas(pd.read_csv(data_csv), npartitions=2)",
            "assert data_df.known_divisions",
            "",
            "config = {"
        ],
        "comments": "value change",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 339,
        "label": "no",
        "change": [
            "sys.path.insert(0, os.path.abspath('../'))",
            "os.environ['TENSORPACK_DOC_BUILDING'] = '1'",
            "",
            "",
            "-MOCK_MODULES = ['scipy',",
            "-                #'tensorflow', 'tensorflow.contrib',",
            "-                #'tensorflow.python.ops',",
            "-                #'tensorflow.contrib.framework',",
            "-                #'tensorflow.python',",
            "-                #'tensorflow.python.training',",
            "+MOCK_MODULES = ['scipy', 'tabulate',",
            "'sklearn.datasets', 'sklearn',",
            "'scipy.misc', 'h5py', 'nltk',",
            "'cv2', 'scipy.io', 'dill', 'zmq', 'subprocess32', 'lmdb',"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 341,
        "label": "no",
        "change": [
            "for m in model_list:",
            "data_root=os.environ.get('IMAGENET_DIR', './imagenet')",
            ")",
            "",
            "+    torch.cuda.empty_cache()",
            "+"
        ],
        "comments": "add API call for state fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 342,
        "label": "no",
        "change": [
            "class TFMLP(tf.keras.layers.Layer):",
            "nx = config.n_embd",
            "self.c_fc = TFConv1D(n_state, nx, initializer_range=config.initializer_range, name=\"c_fc\")",
            "self.c_proj = TFConv1D(nx, n_state, initializer_range=config.initializer_range, name=\"c_proj\")",
            "-        self.act = gelu",
            "+        self.act = get_tf_activation(\"gelu\")",
            "self.dropout = tf.keras.layers.Dropout(config.resid_pdrop)",
            "",
            "def call(self, x, training=False):"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 346,
        "label": "no",
        "change": [
            "class TestExportModels(unittest.TestCase):",
            "_test_save_and_load(scripted)",
            "",
            "@unittest.skipIf(",
            "-        torch.__version__ < \"1.6.0\", \"Targeting OSS scriptability for the 1.6 release\"",
            "+        version_check(),",
            "+        \"Targeting OSS scriptability for the 1.13.0.dev20220613 release\",",
            ")",
            "def test_export_transformer_no_token_pos_emb(self):",
            "task, parser = get_dummy_task_and_parser()"
        ],
        "comments": "add custom API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 347,
        "label": "no",
        "change": [
            "class TacotronAbstract(ABC, nn.Module):",
            "def _backward_pass(self, mel_specs, encoder_outputs, mask):",
            "\"\"\" Run backwards decoder \"\"\"",
            "decoder_outputs_b, alignments_b, _ = self.decoder_backward(",
            "-            encoder_outputs, torch.flip(mel_specs, dims=(1,)), mask,",
            "-            self.speaker_embeddings_projected)",
            "+            encoder_outputs, torch.flip(mel_specs, dims=(1,)), mask)",
            "decoder_outputs_b = decoder_outputs_b.transpose(1, 2).contiguous()",
            "return decoder_outputs_b, alignments_b"
        ],
        "comments": "remove param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 348,
        "label": "yes",
        "change": [
            "def main():",
            "model = MMDataParallel(model, device_ids=[0])",
            "outputs = single_gpu_test(model, data_loader, args.show)",
            "else:",
            "-        model = MMDistributedDataParallel(model.cuda())",
            "+        model = MMDistributedDataParallel(",
            "+            model.cuda(),",
            "+            device_ids=[torch.cuda.current_device()],",
            "+            broadcast_buffers=False)",
            "outputs = multi_gpu_test(model, data_loader, args.tmpdir,",
            "args.gpu_collect)"
        ],
        "comments": "add param for resource fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 349,
        "label": "no",
        "change": [
            "def get_tps_transform(points_src: torch.Tensor, points_dst: torch.Tensor) -> Tup",
            "l_matrix: torch.Tensor = torch.cat((k_matrix, p_matrix), -1)",
            "l_matrix = torch.cat((l_matrix, p_matrix_t), 1)",
            "",
            "-    weights, _ = torch.solve(dest_with_zeros, l_matrix)",
            "+    weights, _ = _torch_solve_cast(dest_with_zeros, l_matrix)",
            "kernel_weights: torch.Tensor = weights[:, :-3]",
            "affine_weights: torch.Tensor = weights[:, -3:]"
        ],
        "comments": "change API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 350,
        "label": "yes",
        "change": [
            "class StableDiffusionImageVariationPipeline(DiffusionPipeline):",
            "image_embeddings = image_embeddings.view(bs_embed * num_images_per_prompt, seq_len, -1)",
            "",
            "if do_classifier_free_guidance:",
            "-            uncond_embeddings = torch.zeros_like(image_embeddings)",
            "+            negative_prompt_embeds = torch.zeros_like(image_embeddings)",
            "",
            "# For classifier free guidance, we need to do two forward passes.",
            "# Here we concatenate the unconditional and text embeddings into a single batch",
            "# to avoid doing two forward passes",
            "-            image_embeddings = torch.cat([uncond_embeddings, image_embeddings])",
            "+            image_embeddings = torch.cat([negative_prompt_embeds, image_embeddings])",
            "",
            "return image_embeddings"
        ],
        "comments": "rename",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 351,
        "label": "no",
        "change": [
            "class AsyncSamplesOptimizerTest(unittest.TestCase):",
            "",
            "def _make_envs(self):",
            "def make_sess():",
            "-            return tf.Session(config=tf.ConfigProto(device_count={\"CPU\": 2}))",
            "+            return tf1.Session(config=tf1.ConfigProto(device_count={\"CPU\": 2}))",
            "",
            "local = RolloutWorker(",
            "env_creator=lambda _: gym.make(\"CartPole-v0\"),"
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 352,
        "label": "no",
        "change": [
            "class AlbertModel(AlbertPreTrainedModel):",
            "inner_group_idx = int(layer - group_idx * self.config.inner_group_num)",
            "self.encoder.albert_layer_groups[group_idx].albert_layers[inner_group_idx].attention.prune_heads(heads)",
            "",
            "+    @add_start_docstrings_to_callable(ALBERT_INPUTS_DOCSTRING)",
            "def forward(",
            "self,",
            "input_ids=None,"
        ],
        "comments": "add anotation",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 353,
        "label": "no",
        "change": [
            "class TestSelfAttentiveSpanExtractor:",
            "extractor._global_attention._module.weight.data.fill_(0.0)",
            "extractor._global_attention._module.bias.data.fill_(0.0)",
            "",
            "-        indices = torch.LongTensor([[[1, 3],",
            "-                                     [2, 4]],",
            "-                                    [[0, 2],",
            "-                                     [3, 4]]]) # smaller span tests masking.",
            "+        indices = torch.LongTensor(",
            "+            [[[1, 3], [2, 4]], [[0, 2], [3, 4]]]",
            "+        )  # smaller span tests masking.",
            "span_representations = extractor(sequence_tensor, indices)",
            "assert list(span_representations.size()) == [2, 2, input_dim]"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 357,
        "label": "no",
        "change": [
            "class Tester(unittest.TestCase):",
            "# generate input data",
            "batch_size = 1",
            "center = torch.zeros(batch_size, 2)",
            "-        angle = torch.ones(batch_size, 1)",
            "-        scale = torch.ones(batch_size, 1)",
            "+        angle = torch.ones(batch_size)",
            "+        scale = torch.ones(batch_size)",
            "",
            "center = utils.tensor_to_gradcheck_var(center)  # to var",
            "angle = utils.tensor_to_gradcheck_var(angle)  # to var"
        ],
        "comments": "remove param for shape fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 359,
        "label": "no",
        "change": [
            "def test_torch_trace(",
            "dtype_and_values,",
            "as_variable,",
            "num_positional_args,",
            "+    with_out,",
            "native_array,",
            "fw,",
            "):",
            "input_dtype, value = dtype_and_values",
            "-    # if \"float16\" in input_dtype:",
            "-    #    input_dtype = ivy.FloatDtype(\"float32\")  # Float16 is unsupported for trace.",
            "helpers.test_frontend_function(",
            "input_dtypes=input_dtype,",
            "as_variable_flags=as_variable,",
            "-        with_out=False,",
            "+        with_out=with_out,",
            "num_positional_args=num_positional_args,",
            "native_array_flags=native_array,",
            "fw=fw,"
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 360,
        "label": "yes",
        "change": [
            "class Trainer:",
            "return type(data)(self._prepare_input(v) for v in data)",
            "elif isinstance(data, torch.Tensor):",
            "kwargs = {\"device\": self.args.device}",
            "-            if self.deepspeed and data.dtype != torch.int64:",
            "-                # NLP models inputs are int64 and those get adjusted to the right dtype of the",
            "+            if self.deepspeed and (torch.is_floating_point(data) or torch.is_complex(data)):",
            "+                # NLP models inputs are int/uint and those get adjusted to the right dtype of the",
            "# embedding. Other models such as wav2vec2's inputs are already float and thus",
            "# may need special handling to match the dtypes of the model",
            "kwargs.update({\"dtype\": self.args.hf_deepspeed_config.dtype()})"
        ],
        "comments": "change condition check for state fix",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 361,
        "label": "no",
        "change": [
            "class HybridCodeNetworkModel(TFModel):",
            "self.obs_size = params['obs_size']",
            "",
            "def _build_graph(self):",
            "-        tf.reset_default_graph()",
            "-",
            "self._add_placeholders()",
            "",
            "# build body"
        ],
        "comments": "customized method ",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 362,
        "label": "yes",
        "change": [
            "class DeformableDetrImageProcessor(BaseImageProcessor):",
            "img_w = torch.Tensor([i[1] for i in target_sizes])",
            "else:",
            "img_h, img_w = target_sizes.unbind(1)",
            "-        scale_fct = torch.stack([img_w, img_h, img_w, img_h], dim=1)",
            "+        scale_fct = torch.stack([img_w, img_h, img_w, img_h], dim=1).to(boxes.device)",
            "boxes = boxes * scale_fct[:, None, :]",
            "",
            "results = []"
        ],
        "comments": "add API call for resource fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 363,
        "label": "no",
        "change": [
            "class SpanBasedF1Test(AllenNlpTestCase):",
            "gold_indices = [self.vocab.get_token_index(x, \"tags\") for x in bio_tags]",
            "gold_tensor = torch.tensor([gold_indices], device=device)",
            "prediction_tensor = torch.rand([1, 6, self.vocab.get_vocab_size(\"tags\")], device=device)",
            "-        mask = torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]], device=device)",
            "+        mask = torch.BoolTensor(",
            "+            [[True, True, True, True, True, True, True, True, True]], device=device",
            "+        )",
            "",
            "# Make prediction so that it is exactly correct.",
            "for i, tag_index in enumerate(gold_indices):"
        ],
        "comments": "change API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 364,
        "label": "no",
        "change": [
            "class TowerContext(object):",
            "self._ctxs = []",
            "if len(self._name):",
            "if self.has_own_variables:",
            "-                # open new variable scopes",
            "-                self._ctxs.append(tf.variable_scope(self._name))",
            "+                if self.vs_name:",
            "+                    self._ctxs.append(tf.variable_scope(self.vs_name))",
            "else:",
            "# use existing variable scope",
            "reuse = self.index > 0 or (not self.is_training)"
        ],
        "comments": "add condition check for null fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 366,
        "label": "no",
        "change": [
            "class DistributedFusedLAMB(torch.optim.Optimizer):",
            "l2_norm = torch.zeros(size=[self._model_params_num], dtype=torch.float32, device='cuda')",
            "local_contrib_l2_norm = multi_tensor_applier(self.multi_tensor_l2norm, self._overflow_buf, [self._contrib_update_frag_for_norm], True)[1] ** 2",
            "l2_norm.masked_scatter_(self._model_param_is_contrib, local_contrib_l2_norm)",
            "-        torch.distributed.allreduce(l2_norm, group=self._ag_pg[0])",
            "+        torch.distributed.all_reduce(l2_norm, group=self._ag_pg[0])",
            "return l2_norm.masked_select(self._model_param_is_contrib)",
            "",
            "def _pipeline_step(self):"
        ],
        "comments": "rename method",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 367,
        "label": "no",
        "change": [
            "class _BinaryPostprocessing(torch.nn.Module):",
            "predictions = [self.bool2str.get(pred, self.bool2str[0]) for pred in predictions]",
            "",
            "probs = preds[self.probabilities_key]",
            "-        probs = torch.dstack(1 - probs, probs)",
            "+        probs = torch.stack([1 - probs, probs], dim=-1)",
            "",
            "return {",
            "self.predictions_key: predictions,"
        ],
        "comments": "add param for shape fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 368,
        "label": "no",
        "change": [
            "if __name__ == \"__main__\":",
            "exp = get_exp(args.exp_file, args.name)",
            "exp.merge(args.opts)",
            "",
            "-    num_gpu = get_num_devices() if args.devices is None else args.devices",
            "-    assert num_gpu <= get_num_devices()",
            "+    num_gpu = torch.cuda.device_count() if args.devices is None else args.devices",
            "+    assert num_gpu <= torch.cuda.device_count()",
            "",
            "dist_url = \"auto\" if args.dist_url is None else args.dist_url",
            "launch("
        ],
        "comments": "change API call for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 370,
        "label": "no",
        "change": [
            "def test_log_prob_eta1(d):",
            "assert (lps_less_ladj - lps_less_ladj.min()).abs().sum() < 1e-4",
            "",
            "",
            "-@pytest.mark.parametrize(\"eta\", [.1, .5, 1, 2, 5])",
            "+@pytest.mark.parametrize(\"eta\", [.1, .5, 1., 2., 5.])",
            "def test_log_prob_d2(eta):",
            "-    dist = LKJCorrCholesky(2, torch.DoubleTensor([eta]))",
            "+    dist = LKJCorrCholesky(2, torch.tensor([eta]))",
            "test_dist = TransformedDistribution(Beta(eta, eta), AffineTransform(loc=-1., scale=2.0))",
            "",
            "samples = dist.sample(torch.Size([100]))"
        ],
        "comments": "change API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 372,
        "label": "no",
        "change": [
            "class Critic(object):",
            "self.train_op = tf.train.AdamOptimizer(self.lr).minimize(self.loss)",
            "",
            "with tf.variable_scope('a_grad'):",
            "-            self.a_grads = tf.gradients(self.q, a)[0]   # tensor of gradients of each sample (None, a_dim)",
            "+            self.a_grads = tf.gradients(self.q, self.a)[0]   # tensor of gradients of each sample (None, a_dim)",
            "",
            "if self.replacement['name'] == 'hard':",
            "self.t_replace_counter = 0"
        ],
        "comments": "rename the variable",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 375,
        "label": "yes",
        "change": [
            "def corr2d(X, K):  #@save",
            "",
            "# Defined in file: ./chapter_convolutional-neural-networks/lenet.md",
            "def evaluate_accuracy_gpu(net, data_iter, device=None): #@save",
            "+    net.eval()  # Set the model to evaluation mode",
            "if not device:",
            "device = next(iter(net.parameters())).device",
            "metric = d2l.Accumulator(2)  # num_corrected_examples, num_examples"
        ],
        "comments": "add API call for state fix",
        "Symptom": "unexpected output",
        "Root_Cause": "state handling error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 376,
        "label": "no",
        "change": [
            "class VideoSequential(ImageSequential):",
            "# Size of T",
            "frame_num = input.size(self._temporal_channel)",
            "# Got param generation shape to (B, C, H, W). Ignoring T.",
            "-        batch_shape = self.__infer_channel_exclusive_batch_shape__(input)",
            "+        batch_shape = self.__infer_channel_exclusive_batch_shape__(input, self._temporal_channel)",
            "input = self._input_shape_convert_in(input)",
            "input = input.reshape(-1, *batch_shape[1:])",
            "if not self.same_on_frame:"
        ],
        "comments": "add param for argument fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 377,
        "label": "yes",
        "change": [
            "def create_dataloader(path, imgsz, batch_size, stride, single_cls=False, hyp=Non",
            "prefix=prefix)",
            "",
            "batch_size = min(batch_size, len(dataset))",
            "-    nw = min([os.cpu_count() // DEVICE_COUNT, batch_size if batch_size > 1 else 0, workers])  # number of workers",
            "+    nd = torch.cuda.device_count()  # number of CUDA devices",
            "+    nw = min([os.cpu_count() // max(nd, 1), batch_size if batch_size > 1 else 0, workers])  # number of workers",
            "sampler = None if rank == -1 else distributed.DistributedSampler(dataset, shuffle=shuffle)",
            "loader = DataLoader if image_weights else InfiniteDataLoader  # only DataLoader allows for attribute updates",
            "return loader(dataset,"
        ],
        "comments": "add param for resource fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 378,
        "label": "no",
        "change": [
            "class LitStreamlit(L.app.components.ServeStreamlit):",
            "audio.seek(0)",
            "st.audio(audio)",
            "",
            "-app = L.LightningApp(LitStreamlit())",
            "+app = L.LightningApp(StreamlitApp())"
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 379,
        "label": "no",
        "change": [
            "class MultiHeadedAttention(BaseMultiHeadedAttention):",
            "",
            "def __init__(self, q_dim, k_dim, v_dim, n_head, n_feat, dropout_rate=0.0):",
            "\"\"\"Initialize multi head attention module.\"\"\"",
            "-        super(MultiHeadedAttention, self).__init__()",
            "+        torch.nn.Module.__init__(self)",
            "assert n_feat % n_head == 0",
            "# We assume d_v always equals d_k",
            "self.d_k = n_feat // n_head"
        ],
        "comments": "change API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 381,
        "label": "no",
        "change": [
            "if dependency_check.crypten_available:",
            "",
            "framework_packages[\"crypten\"] = crypten",
            "framework_tensors.append(crypten.mpc.MPCTensor)",
            "+    framework_tensors.append(crypten.nn.Module)",
            "+",
            "",
            "framework_tensors = tuple(framework_tensors)",
            "FrameworkTensorType = Union[framework_tensors]"
        ],
        "comments": "add module",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 384,
        "label": "yes",
        "change": [
            "def array(object_in, dtype: Optional[str] = None, dev: Optional[str] = None):",
            "dev = default_device(dev)",
            "dtype = dtype_from_str(default_dtype(dtype, object_in))",
            "if isinstance(object_in, np.ndarray):",
            "-        return _torch.Tensor(object_in).to(dev_from_str(dev))",
            "+        return torch.Tensor(object_in).to(dev_from_str(dev))",
            "if dtype is not None:",
            "-        return _torch.tensor(object_in, dtype=dtype, device=dev_from_str(dev))",
            "-    elif isinstance(object_in, _torch.Tensor):",
            "+        return torch.tensor(object_in, dtype=dtype, device=dev_from_str(dev))",
            "+    elif isinstance(object_in, torch.Tensor):",
            "return object_in.to(dev_from_str(dev))",
            "else:",
            "-        return _torch.tensor(object_in, device=dev_from_str(dev))",
            "+        return torch.tensor(object_in, device=dev_from_str(dev))",
            "",
            "asarray = array"
        ],
        "comments": "update API call for type fix",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 385,
        "label": "no",
        "change": [
            "def compute_dflip_transformation3d(input: torch.Tensor, params: Dict[str, torch.",
            "d: int = input.shape[-3]",
            "flip_mat: torch.Tensor = torch.tensor([[1, 0, 0, 0],",
            "[0, 1, 0, 0],",
            "-                                           [0, 0, -1, d],",
            "+                                           [0, 0, -1, d - 1],",
            "[0, 0, 0, 1]])",
            "",
            "trans_mat[to_flip] = flip_mat.type_as(input)"
        ],
        "comments": "test fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 387,
        "label": "no",
        "change": [
            "class Trainer(",
            "self.gpus = gpus",
            "self.data_parallel_device_ids = parse_gpu_ids(self.gpus)",
            "self.root_gpu = determine_root_gpu_device(self.data_parallel_device_ids)",
            "+        self.root_device = torch.device(\"cpu\")",
            "",
            "# tpu state flags",
            "self.use_tpu = False"
        ],
        "comments": "add API call for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 388,
        "label": "no",
        "change": [
            "class TestNnUtil(AllenNlpTestCase):",
            "assert parameters_inspection_dict == util.inspect_parameters(model)",
            "",
            "def test_move_to_device(self):",
            "-        # We're faking the tensor here so that we can test the calls to .cuda() without actually",
            "+        # We're faking the tensor here so that we can test the calls to .to() without actually",
            "# needing a GPU.",
            "class FakeTensor(torch.Tensor):",
            "def __init__(self):",
            "self._device = None",
            "",
            "-            def cuda(self, device):",
            "+            def to(self, device, **kwargs):",
            "self._device = device",
            "return self"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 389,
        "label": "no",
        "change": [
            "def solve(x1: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:",
            "",
            "",
            "def svd(",
            "-    x: torch.Tensor, full_matrices: bool = True, out: Optional[torch.Tensor] = None",
            "+    x: torch.Tensor, full_matrices: bool = True",
            ") -> Union[torch.Tensor, Tuple[torch.Tensor, ...]]:",
            "results = namedtuple(\"svd\", \"U S Vh\")",
            "",
            "-    U, D, VT = torch.linalg.svd(x, full_matrices=full_matrices, out=out)",
            "+    U, D, VT = torch.linalg.svd(x, full_matrices=full_matrices)",
            "ret = results(U, D, VT)",
            "return ret"
        ],
        "comments": "def",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 390,
        "label": "no",
        "change": [
            "def _calculate_expected_result(",
            "aggregation_op_only_probs = gumbel_dist.sample()",
            "else:",
            "# <float32>[batch_size, num_aggregation_labels - 1]",
            "-        aggregation_op_only_probs = torch.nn.functional.softmax(",
            "+        aggregation_op_only_probs = nn.functional.softmax(",
            "logits_aggregation[:, 1:] / config.aggregation_temperature, dim=-1",
            ")"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 392,
        "label": "yes",
        "change": [
            "class TensorforceModel(Model):",
            "discounts = tf.math.pow(x=discount, y=exponent)",
            "if not self.predict_terminal_values:",
            "discounts = tf.where(",
            "-                    condition=tf.math.greater(x=_terminal, y=one),",
            "-                    x=discounts, y=tf.zeros_like(input=discounts)",
            "+                    condition=tf.math.equal(x=_terminal, y=one),",
            "+                    x=tf.zeros_like(input=discounts), y=discounts",
            ")",
            "",
            "-            reward += discounts * horizon_values",
            "+            reward = reward + discounts * horizon_values",
            "",
            "dependencies = [reward]",
            "if self.summaries == 'all' or 'reward' in self.summaries:"
        ],
        "comments": "format",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 393,
        "label": "no",
        "change": [
            "def test_tensorflow_deserialize(",
            "",
            "",
            "@handle_frontend_test(",
            "+    fn_tree=\"tensorflow.keras.activations.get\",",
            "fn_name=st.sampled_from(get_callable_functions(\"keras.activations\")).filter(",
            "lambda x: not x[0].isupper()",
            "and x"
        ],
        "comments": "text fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 394,
        "label": "yes",
        "change": [
            "if torch_available and torch.cuda.is_available():",
            "if rocm_major <= 4:",
            "cupy = f\"cupy-rocm-{rocm_major}-{rocm_minor}\"",
            "else:",
            "-        cupy = f\"cupy-cuda{torch.version.cuda.replace('.','')[:3]}\"",
            "+        cupy = f\"cupy-cuda{''.join(map(str,installed_cuda_version()))}\"",
            "if cupy:",
            "extras_require['1bit'].append(cupy)",
            "extras_require['1bit_mpi'].append(cupy)"
        ],
        "comments": "update API call for resource fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 395,
        "label": "no",
        "change": [
            "def test_cgcnn_conv():",
            "edge_index = torch.tensor([[0, 0, 0, 1, 2, 3], [1, 2, 3, 0, 0, 0]])",
            "num_nodes = edge_index.max().item() + 1",
            "x = torch.randn((num_nodes, node_dim))",
            "-    pseudo = torch.rand((edge_index.size(1), 3))",
            "+    pseudo = torch.rand((edge_index.size(1), edge_dim))",
            "",
            "conv = CGCNNConv(node_dim, edge_dim)",
            "assert conv.__repr__() == 'CGCNNConv(16, 16)'"
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 396,
        "label": "yes",
        "change": [
            "def save(",
            "",
            "Examples::",
            "\"\"\"  # noqa",
            "-    context: t.Dict[str, t.Any] = {\"statsmodels\": statsmodels.__version__}",
            "+    context: t.Dict[str, t.Any] = {",
            "+        \"framework_name\": \"statsmodels\",",
            "+        \"pip_dependencies\": [f\"statsmodels=={_statsmodels_version}\"],",
            "+    }",
            "_model = Model.create(",
            "name,",
            "module=__name__,",
            "metadata=metadata,",
            "-        framework_context=context,",
            "+        context=context,",
            ")",
            "",
            "model.save(_model.path_of(f\"{SAVE_NAMESPACE}{PKL_EXT}\"))"
        ],
        "comments": "doc update",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 397,
        "label": "no",
        "change": [
            "def spatial_soft_argmax2d(",
            ">>> coords = kornia.spatial_soft_argmax2d(input, False)",
            "tensor([[[1.0000, 1.0000]]])",
            "\"\"\"",
            "-    input_soft: torch.Tensor = dsnt.spatial_softmax_2d(input, temperature)",
            "-    output: torch.Tensor = dsnt.spatial_softargmax_2d(input_soft,",
            "-                                                      normalized_coordinates)",
            "+    input_soft: torch.Tensor = spatial_softmax_2d(input, temperature)",
            "+    output: torch.Tensor = spatial_softargmax_2d(input_soft,",
            "+                                                 normalized_coordinates)",
            "return output"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 398,
        "label": "no",
        "change": [
            "class TestSpeed(unittest.TestCase):",
            "",
            "def test_sum(self):",
            "def f(a, b): return a.sum()",
            "+    helper_test_generic_square('sum', 2048, f, f, onearg=True)",
            "helper_test_generic_square('sum', 4096, f, f, onearg=True)",
            "",
            "def test_partial_sum(self):"
        ],
        "comments": "test",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 400,
        "label": "yes",
        "change": [
            "def test_frontend_function(",
            "ivy.set_backend(frontend)",
            "",
            "# check for unsupported dtypes in frontend framework",
            "-    function = getattr(ivy, fn_name)",
            "+    function = getattr(ivy.functional.frontends.__dict__[frontend], fn_name)",
            "for d in input_dtypes:",
            "if d in ivy.function_unsupported_dtypes(function, None):",
            "return"
        ],
        "comments": "test fix",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 401,
        "label": "no",
        "change": [
            "def test_torch_instance_to(",
            "frontend,",
            "):",
            "input_dtype, x, method_num_positional_args, method_all_as_kwargs_np = args_kwargs",
            "+    method_flags.num_positional_args = method_num_positional_args",
            "helpers.test_frontend_method(",
            "init_input_dtypes=input_dtype,",
            "init_all_as_kwargs_np={"
        ],
        "comments": "add param for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 403,
        "label": "no",
        "change": [
            "def absolute_difference_error(output, target, is_mean=False, name=\"mean_squared_",
            "An optional name to attach to this function.",
            "",
            "\"\"\"",
            "-    # with tf.name_scope(\"mean_squared_error_loss\"):",
            "+    # with tf.name_scope(\"absolute_difference_error_loss\"):",
            "if output.get_shape().ndims == 2:  # [batch_size, n_feature]",
            "if is_mean:",
            "loss = tf.reduce_mean(tf.reduce_mean(tf.abs(output - target), 1), name=name)"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 407,
        "label": "no",
        "change": [
            "class UnigramRecall(Metric):",
            "A tensor of predictions of shape (batch_size, k, sequence_length).",
            "gold_labels : `torch.Tensor`, required.",
            "A tensor of integer class label of shape (batch_size, sequence_length).",
            "-        mask : `torch.Tensor`, optional (default = None).",
            "+        mask : `torch.BoolTensor`, optional (default = None).",
            "A masking tensor the same size as `gold_labels`.",
            "\"\"\"",
            "predictions, gold_labels, mask = self.detach_tensors(predictions, gold_labels, mask)"
        ],
        "comments": "update param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 408,
        "label": "no",
        "change": [
            "\"        # compute the gating function and one minus the gating function\\n\",",
            "\"        gate_intermediate = self.relu(self.lin_gate_z_to_hidden(z_t_1))\\n\",",
            "\"        gate = self.sigmoid(self.lin_gate_hidden_to_z(gate_intermediate))\\n\",",
            "-    \"        one_minus_gate = ng_ones(gate.size()).type_as(gate) - gate\\n\",",
            "+    \"        one_minus_gate = torch.ones(gate.size()).type_as(gate) - gate\\n\",",
            "\"        # compute the 'proposed mean'\\n\",",
            "\"        proposed_mean_intermediate = self.relu(self.lin_proposed_mean_z_to_hidden(z_t_1))\\n\",",
            "\"        proposed_mean = self.lin_proposed_mean_hidden_to_z(proposed_mean_intermediate)\\n\","
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 410,
        "label": "no",
        "change": [
            "def rotation_matrix_to_quaternion(",
            "return torch.cat([qx, qy, qz, qw], dim=-1)",
            "",
            "def cond_3():",
            "-        sq = torch.sqrt(trace + 1.0 + m00 - m11 - m22) * 2.  # sq = 4 * qw.",
            "+        sq = torch.sqrt(1.0 + m00 - m11 - m22 + eps) * 2.  # sq = 4 * qw.",
            "qw = safe_zero_division(m10 - m01, sq)",
            "qx = safe_zero_division(m02 - m20, sq)",
            "qy = safe_zero_division(m12 - m21, sq)"
        ],
        "comments": "change param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 411,
        "label": "no",
        "change": [
            "class TestPosterize(BaseTester):",
            "@pytest.mark.jit",
            "def test_jit(self, device, dtype):",
            "op = torch.jit.script(kornia.enhance.adjust.posterize)",
            "+        op_script = torch.jit.script(op)",
            "inputs = torch.rand(2, 1, 3, 3).to(device=device, dtype=dtype)",
            "expected = op(input, 8)",
            "actual = op_script(input, 8)"
        ],
        "comments": "test",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 412,
        "label": "no",
        "change": [
            "def crop_by_boxes(tensor, src_box, dst_box,",
            "dst_trans_src = dst_trans_src.expand(tensor.shape[0], -1, -1)",
            "",
            "bbox = _infer_bounding_box(dst_box)",
            "-    patches: torch.Tensor = warp_perspective(",
            "-        tensor, dst_trans_src, (int(bbox[0].int().data.item()), int(bbox[1].int().data.item())))",
            "+    patches: torch.Tensor = warp_affine(",
            "+        tensor, dst_trans_src[:, :2, :], (int(bbox[0].int().data.item()), int(bbox[1].int().data.item())))",
            "",
            "# return in the original shape",
            "if is_unbatched:"
        ],
        "comments": "change API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 413,
        "label": "no",
        "change": [
            "def KitModel(weight_file = None):",
            "if not dilations:",
            "dilations = [1] * len(IR_node.get_attr('kernel_shape'))",
            "",
            "-        self.add_body(1, \"{:<15} = layers.Conv2DTranpose(name='{}', {}, kernel_size=({}), strides=({}), dilation_rate=({}), padding='{}', use_bias={})({})\".format(",
            "+        self.add_body(1, \"{:<15} = layers.Conv2DTranspose(name='{}', {}, kernel_size=({}), strides=({}), dilation_rate=({}), padding='{}', use_bias={})({})\".format(",
            "IR_node.variable_name,",
            "IR_node.name,",
            "filters_str,"
        ],
        "comments": "typo fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 414,
        "label": "no",
        "change": [
            "def test_dynamic_edge_conv_conv():",
            "jit = torch.jit.script(conv.jittable(t))",
            "assert jit((x1, x2)).tolist() == out21.tolist()",
            "assert jit((x1, x2), (batch1, batch2)).tolist() == out22.tolist()",
            "+",
            "+    torch.jit.script(conv.jittable())  # Test without explicit typing."
        ],
        "comments": "not clear",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 415,
        "label": "no",
        "change": [
            "def gradient(",
            "",
            "",
            "def xlogy(",
            "-    x: torch.tensor,",
            "-    y: torch.tensor,",
            "-    /,",
            "-    *,",
            "-    out: Optional[torch.tensor] = None",
            "+    x: torch.tensor, y: torch.tensor, /, *, out: Optional[torch.tensor] = None",
            ") -> torch.tensor:",
            "return torch.xlogy(x, y, out=out)"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 416,
        "label": "no",
        "change": [
            "def ddpg_actor_critic_loss(policy, model, _, train_batch):",
            "twin_q_t = model.get_twin_q_values(model_out_t,",
            "train_batch[SampleBatch.ACTIONS])",
            "# q_batchnorm_update_ops = list(",
            "-    #     set(tf.get_collection(tf.GraphKeys.UPDATE_OPS)) - prev_update_ops)",
            "+    #     set(tf1.get_collection(tf.GraphKeys.UPDATE_OPS)) - prev_update_ops)",
            "",
            "# Target q-net(s) evaluation.",
            "q_tp1 = policy.target_model.get_q_values(target_model_out_tp1,"
        ],
        "comments": "change API doc",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 417,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "if get_current_tower_context().is_training:",
            "wd_w = tf.train.exponential_decay(2e-4, get_global_step_var(),",
            "80000, 0.7, True)",
            "-            wd_cost = tf.mul(wd_w, regularize_cost('.*/W', tf.nn.l2_loss), name='wd_cost')",
            "+            wd_cost = tf.multiply(wd_w, regularize_cost('.*/W', tf.nn.l2_loss), name='wd_cost')",
            "costs.append(wd_cost)",
            "",
            "add_param_summary(('.*/W', ['histogram']))   # monitor W"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 418,
        "label": "no",
        "change": [
            "if __name__ == '__main__':",
            "loss_values.clear()",
            "accuracies.clear()",
            "if step % 100 == 0:",
            "-            vis.draw_projections(embeds.detach().cpu().numpy(), utterances_per_speaker, step)",
            "+            vis.draw_projections(embeds.detach().numpy(), utterances_per_speaker, step)"
        ],
        "comments": "remove API call for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 419,
        "label": "no",
        "change": [
            "class ScoreSdeVpScheduler(SchedulerMixin, ConfigMixin):",
            "x_mean = x + drift * dt",
            "",
            "# add noise",
            "-        noise = torch.randn(x.shape, layout=x.layout, generator=generator).to(x.device)",
            "+        noise = randn_tensor(x.shape, layout=x.layout, generator=generator, device=x.device, dtype=x.dtype)",
            "x = x_mean + diffusion * math.sqrt(-dt) * noise",
            "",
            "return x, x_mean"
        ],
        "comments": "change API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 422,
        "label": "no",
        "change": [
            "def get_keras_model():",
            "M.add(KL.Conv2D(32, 3, padding='same', activation='relu'))",
            "M.add(KL.Flatten())",
            "M.add(KL.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(1e-5)))",
            "-        M.add(KL.Dropout(0.5))",
            "+        M.add(KL.Dropout(rate=0.5))",
            "M.add(KL.Dense(10, activation=None, kernel_regularizer=keras.regularizers.l2(1e-5)))",
            "return M"
        ],
        "comments": "update param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 423,
        "label": "no",
        "change": [
            "def build_targets(model, targets):",
            "",
            "# Class",
            "tcls.append(c)",
            "-        if c.shape[0]:",
            "+        if nt:",
            "assert c.max() <= layer.nC, 'Target classes exceed model classes'",
            "",
            "return txy, twh, tcls, indices"
        ],
        "comments": "no API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 424,
        "label": "yes",
        "change": [
            "def main(parsed_args):",
            "",
            "def cli_main():",
            "parser = options.get_eval_lm_parser()",
            "+    add_distributed_training_args(parser)",
            "args = options.parse_args_and_arch(parser)",
            "-    main(args)",
            "+    distributed_utils.call_main(args, main)",
            "",
            "",
            "if __name__ == '__main__':"
        ],
        "comments": "change API call for resource fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "addition",
        "Element": "api call"
    },
    {
        "number": 425,
        "label": "no",
        "change": [
            "def degree(index, num_nodes=None, dtype=None, device=None):",
            "tensor([3., 1., 1.])",
            "\"\"\"",
            "num_nodes = maybe_num_nodes(index, num_nodes)",
            "-    out = torch.zeros((num_nodes), dtype=dtype, device=device)",
            "+    out = torch.zeros((num_nodes), dtype=dtype, device=index.device)",
            "return out.scatter_add_(0, index, out.new_ones((index.size(0))))"
        ],
        "comments": "add param for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 426,
        "label": "no",
        "change": [
            "class TransducerTasks(torch.nn.Module):",
            "if ctc_loss:",
            "self.ctc_lin = torch.nn.Linear(encoder_dim, output_dim)",
            "",
            "-            if LooseVersion(torch.__version__) < LooseVersion(\"1.7.0\"):",
            "+            if LooseVersion(torch.__version__) > LooseVersion(\"1.0.1\"):",
            "self.ctc_loss = torch.nn.CTCLoss(",
            "blank=blank_id,",
            "reduction=\"sum\","
        ],
        "comments": "change condition check for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 429,
        "label": "no",
        "change": [
            "class RandomThinPlateSpline(AugmentationBase2D):",
            "",
            "def generate_parameters(self, shape: torch.Size) -> Dict[str, Tensor]:",
            "B, _, _, _ = shape",
            "-        src = torch.tensor([[[-1.0, -1.0], [-1.0, 1.0], [1.0, -1.0], [1.0, 1.0], [0.0, 0.0]]]).expand(B, 5, 2)  # Bx5x2",
            "+        src = tensor([[[-1.0, -1.0], [-1.0, 1.0], [1.0, -1.0], [1.0, 1.0], [0.0, 0.0]]]).expand(B, 5, 2)  # Bx5x2",
            "dst = src + self.dist.rsample(src.shape)",
            "return dict(src=src, dst=dst)"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 431,
        "label": "no",
        "change": [
            "class FP16_Optimizer(DeepSpeedOptimizer):",
            "self.deepspeed = deepspeed",
            "self.has_moe_layers = has_moe_layers",
            "self.using_pipeline = self.deepspeed.pipeline_parallelism",
            "-        if not torch.cuda.is_available:",
            "+        if not torch.cuda.is_available():",
            "raise SystemError(\"Cannot use fp16 without CUDA.\")",
            "self.optimizer = init_optimizer"
        ],
        "comments": "typo fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 432,
        "label": "no",
        "change": [
            "class PNDMScheduler(SchedulerMixin, ConfigMixin):",
            "::-1",
            "].copy()  # we copy to avoid having negative strides which are not supported by torch.from_numpy",
            "",
            "-        self.timesteps = np.concatenate([self.prk_timesteps, self.plms_timesteps]).astype(np.int64)",
            "+        timesteps = np.concatenate([self.prk_timesteps, self.plms_timesteps]).astype(np.int64)",
            "+        self.timesteps = torch.from_numpy(timesteps).to(device)",
            "",
            "self.ets = []",
            "self.counter = 0"
        ],
        "comments": "version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 433,
        "label": "yes",
        "change": [
            "def HomographyRegressionApp():",
            "[-1, 1],  # top-right",
            "]]).to(dst_homo_src.device)",
            "# transform points",
            "-            pts_dst = dgm.transform_points(dgm.inverse(dst_homo_src), pts_src)",
            "+            pts_dst = dgm.transform_points(torch.inverse(dst_homo_src), pts_src)",
            "",
            "def compute_factor(size):",
            "return 1.0 * size / 2"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "program crash",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 435,
        "label": "no",
        "change": [
            "if __name__ == \"__main__\":",
            "print(\"args:\", args)",
            "",
            "cluster = TFCluster.run(sc, main_fun, args, args.cluster_size, num_ps=0, tensorboard=args.tensorboard, input_mode=TFCluster.InputMode.TENSORFLOW, log_dir=args.model_dir, master_node='chief', eval_node=True)",
            "-  cluster.shutdown(grace_secs=120)",
            "+  cluster.shutdown(grace_secs=60)"
        ],
        "comments": "value change",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 436,
        "label": "no",
        "change": [
            "class Highway(torch.nn.Module):",
            "# above, too.",
            "nonlinear_part, gate = projected_input.chunk(2, dim=-1)",
            "nonlinear_part = self._activation(nonlinear_part)",
            "-            gate = torch.nn.functional.sigmoid(gate)",
            "+            gate = torch.sigmoid(gate)",
            "current_input = gate * linear_part + (1 - gate) * nonlinear_part",
            "return current_input"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 437,
        "label": "yes",
        "change": [
            "class Model(object):",
            "\"It should be either Tensor or a list of Tensor.\"",
            ")",
            "for idx in range(len(check_argu)):",
            "-                        if not isinstance(check_argu[idx], tf_ops._TensorLike) or not tf_ops.is_dense_tensor_like(",
            "+                        if not isinstance(check_argu[idx], [tf.Tensor, tf.SparseTensor, tf.Variable]) or not tf_ops.is_dense_tensor_like(",
            "check_argu[idx]):",
            "raise TypeError(",
            "\"The argument `%s` should be either Tensor or a list of Tensor \" % (check_order[co]) +"
        ],
        "comments": "change param for type fix",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 438,
        "label": "no",
        "change": [
            "class TFData2VecVisionModel(TFData2VecVisionPreTrainedModel):",
            "return_dict: Optional[bool] = None,",
            "training: bool = False,",
            ") -> Union[tuple, TFData2VecVisionModelOutputWithPooling]:",
            "+        r\"\"\"",
            "+        bool_masked_pos (`tf.Tensor` of shape `(batch_size, num_patches)`, *optional*):",
            "+            Boolean masked positions. Indicates which patches are masked (1) and which aren't (0).",
            "+        \"\"\"",
            "outputs = self.data2vec_vision(",
            "pixel_values=pixel_values,",
            "bool_masked_pos=bool_masked_pos,"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 439,
        "label": "no",
        "change": [
            "class TestBasicTextFieldEmbedder(AllenNlpTestCase):",
            "})",
            "token_embedder = BasicTextFieldEmbedder.from_params(self.vocab, params)",
            "inputs = {",
            "-                'words': Variable(torch.rand(3, 4, 5, 6) * 20).long(),",
            "-                'characters': Variable(torch.rand(3, 4, 5, 6, 7) * 15).long(),",
            "+                'words': (torch.rand(3, 4, 5, 6) * 20).long(),",
            "+                'characters': (torch.rand(3, 4, 5, 6, 7) * 15).long(),",
            "}",
            "assert token_embedder(inputs, num_wrapping_dims=2).size() == (3, 4, 5, 6, 12)"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 440,
        "label": "yes",
        "change": [
            "class Metric(Registrable):",
            "return cls.by_name(metric_type)(**params.as_dict())  # type: ignore",
            "",
            "@staticmethod",
            "-    def unwrap_to_tensors(*tensors):",
            "+    def unwrap_to_tensors(*tensors: torch.Tensor):",
            "\"\"\"",
            "-        If you actually passed in Variables to a Metric instead of Tensors, there will be",
            "+        If you actually passed gradient-tracking Tensors to a Metric, there will be",
            "a huge memory leak, because it will prevent garbage collection for the computation",
            "graph. This method ensures that you're using tensors directly and that they are on",
            "the CPU.",
            "\"\"\"",
            "-        return (x.data.cpu() if isinstance(x, torch.autograd.Variable) else x for x in tensors)",
            "+        return (x.detach().cpu() if isinstance(x, torch.Tensor) else x for x in tensors)"
        ],
        "comments": "format",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 442,
        "label": "yes",
        "change": [
            "def _make_black_objective_and_vega_func(prices, forwards, strikes, expiries,",
            "implied_prices = tf.where(",
            "tf.broadcast_to(is_call_options, tf.shape(put_prices)),",
            "implied_prices, put_prices)",
            "-    vega = x * phi.prob(d1) * sqrt_t",
            "+    vega = x * phi.prob(d1) * sqrt_t / discount_factors",
            "return implied_prices - normalized_prices, vega",
            "",
            "return _black_objective_and_vega"
        ],
        "comments": "no API",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 443,
        "label": "no",
        "change": [
            "class IndexField(Field[torch.Tensor]):",
            "",
            "@overrides",
            "def get_padding_lengths(self) -> Dict[str, int]:",
            "-",
            "return {}",
            "",
            "@overrides",
            "def as_tensor(self, padding_lengths: Dict[str, int]) -> torch.Tensor:",
            "-",
            "-        tensor = torch.LongTensor([self.sequence_index])",
            "-        return tensor",
            "+        return torch.LongTensor([self.sequence_index])",
            "",
            "@overrides",
            "def empty_field(self):"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 444,
        "label": "yes",
        "change": [
            "def chamfer_distance(",
            "",
            "if return_normals:",
            "# Gather the normals using the indices and keep only value for k=0",
            "-        x_normals_near = knn_gather(y_normals, x_idx, y_lengths)[..., 0, :]",
            "-        y_normals_near = knn_gather(x_normals, y_idx, x_lengths)[..., 0, :]",
            "+        x_normals_near = knn_gather(y_normals, x_nn.idx, y_lengths)[..., 0, :]",
            "+        y_normals_near = knn_gather(x_normals, y_nn.idx, x_lengths)[..., 0, :]",
            "",
            "cham_norm_x = 1 - torch.abs(",
            "F.cosine_similarity(x_normals, x_normals_near, dim=2, eps=1e-6)"
        ],
        "comments": "format",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 445,
        "label": "no",
        "change": [
            "class SOSNet(nn.Module):",
            "nn.Conv2d(128, 128, kernel_size=8, bias=False),",
            "nn.BatchNorm2d(128, affine=False),",
            ")",
            "-        self.desc_norm = nn.Sequential(",
            "-            nn.LocalResponseNorm(256, alpha=256.0, beta=0.5, k=0.0)",
            "-        )",
            "+        self.desc_norm = nn.Sequential(nn.LocalResponseNorm(256, alpha=256.0, beta=0.5, k=0.0))",
            "# load pretrained model",
            "if pretrained:",
            "-            pretrained_dict = torch.hub.load_state_dict_from_url(",
            "-                urls['lib'], map_location=lambda storage, loc: storage",
            "-            )",
            "+            pretrained_dict = torch.hub.load_state_dict_from_url(urls['lib'], map_location=lambda storage, loc: storage)",
            "self.load_state_dict(pretrained_dict, strict=True)",
            "",
            "return"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 446,
        "label": "yes",
        "change": [
            "class Csv(datasets.ArrowBasedBuilder):",
            "if schema is not None",
            "else None",
            ")",
            "-        for file_idx, file in enumerate(files):",
            "+        for file_idx, file in enumerate(itertools.chain.from_iterable(files)):",
            "csv_file_reader = pd.read_csv(file, iterator=True, dtype=dtype, **self.config.read_csv_kwargs)",
            "try:",
            "for batch_idx, df in enumerate(csv_file_reader):"
        ],
        "comments": "add API call for type fix",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 447,
        "label": "no",
        "change": [
            "class ElectraForPreTraining(ElectraPreTrainedModel):",
            ">>> from transformers import ElectraTokenizer, ElectraForPreTraining",
            ">>> import torch",
            "",
            "-        >>> tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')",
            "-        >>> model = ElectraForPreTraining.from_pretrained('google/electra-small-discriminator')",
            "+        >>> tokenizer = ElectraTokenizer.from_pretrained(\"google/electra-small-discriminator\")",
            "+        >>> model = ElectraForPreTraining.from_pretrained(\"google/electra-small-discriminator\")",
            "",
            "-        >>> input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1",
            "+        >>> input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(",
            "+        ...     0",
            "+        >>> )  # Batch size 1",
            ">>> logits = model(input_ids).logits",
            "```\"\"\"",
            "return_dict = return_dict if return_dict is not None else self.config.use_return_dict"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 448,
        "label": "no",
        "change": [
            "class ARMAConv(MessagePassing):",
            "if self.bias is not None:",
            "out += self.bias[0 if self.shared_weights else t]",
            "",
            "-            if t < self.num_layers - 1:",
            "+            if self.act is not None and t < self.num_layers - 1:",
            "out = self.act(out)",
            "",
            "return out.mean(dim=-3)"
        ],
        "comments": "add condition check for null fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 449,
        "label": "yes",
        "change": [
            "class DependencyParser(flair.nn.Model):",
            "sentence_tensor = self.word_dropout(sentence_tensor)",
            "",
            "if self.use_rnn:",
            "-            sentence_tensor = pack_padded_sequence(sentence_tensor, lengths, True, False)",
            "+            sentence_sequence = pack_padded_sequence(sentence_tensor, torch.IntTensor(lengths), True, False)",
            "",
            "-            sentence_tensor, _ = self.lstm(sentence_tensor)",
            "-            sentence_tensor, _ = pad_packed_sequence(sentence_tensor, True, total_length=seq_len)",
            "+            sentence_sequence, _ = self.lstm(sentence_sequence)",
            "+            sentence_tensor, _ = pad_packed_sequence(sentence_sequence, True, total_length=seq_len)",
            "",
            "# apply MLPs for arc and relations to the BiLSTM output states",
            "arc_h = self.mlp_arc_h(sentence_tensor)"
        ],
        "comments": "add API call for type fix",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 450,
        "label": "no",
        "change": [
            "if __name__ == '__main__':",
            "saver = tf.train.Saver()",
            "",
            "try:",
            "-        ckpt = tf.train.get_checkpoint_state(\"checkpoints/\")",
            "+        ckpt = tf.train.get_checkpoint_state(cfg.TEST.checkpoints_path)",
            "+        #ckpt=tf.train.get_checkpoint_state(\"output/ctpn_end2end/voc_2007_trainval/\")",
            "print('Restoring from {}...'.format(ckpt.model_checkpoint_path), end=' ')",
            "saver.restore(sess, ckpt.model_checkpoint_path)",
            "print('done')"
        ],
        "comments": "rename version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 451,
        "label": "no",
        "change": [
            "def testtanh():",
            "",
            "Ptensor = PolynomialTensor()",
            "",
            "-    x = torch.linspace(-3, 3, steps=10)",
            "+    x = torch.tensor(np.linspace(-3, 3, 10))",
            "expected = torch.tensor(",
            "[",
            "-3.3883e02,"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 452,
        "label": "no",
        "change": [
            "class BartTranslationTests(unittest.TestCase):",
            "with torch.no_grad():",
            "logits, *other_stuff = model(**self.net_input)",
            "",
            "-        expected_slice = torch.tensor([9.0078, 10.1113, 14.4787])",
            "+        expected_slice = torch.tensor([9.0078, 10.1113, 14.4787], device=torch_device)",
            "result_slice = logits[0][0][:3]",
            "self.assertTrue(torch.allclose(expected_slice, result_slice, atol=TOLERANCE))"
        ],
        "comments": "add param for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 453,
        "label": "yes",
        "change": [
            "def test_dc_crn_separator_invalid_type():",
            "def test_dc_crn_separator_output():",
            "real = torch.rand(2, 10, 17)",
            "imag = torch.rand(2, 10, 17)",
            "-    x = ComplexTensor(real, imag) if is_torch_1_9_plus else torch.complex(real, imag)",
            "+    x = torch.complex(real, imag) if is_torch_1_9_plus else ComplexTensor(real, imag)",
            "x_lens = torch.tensor([10, 8], dtype=torch.long)",
            "",
            "for num_spk in range(1, 3):"
        ],
        "comments": "update API call for version fix",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 454,
        "label": "no",
        "change": [
            "class ModelSavingTests(unittest.TestCase):",
            "model = T.nn.DataParallel(layer)",
            "",
            "# save the model",
            "-        best_loss = save_best_model(model, None, 0, 100, OUT_PATH, 10, 1)",
            "+        save_best_model(model, None, 0, 100, OUT_PATH, 10, 1)",
            "",
            "# load the model to CPU",
            "-        model_dict = torch.load(",
            "+        model_dict = T.load(",
            "MODEL_PATH, map_location=lambda storage, loc: storage)",
            "model.load_state_dict(model_dict['model'])"
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 456,
        "label": "no",
        "change": [
            "class DatasetRequestAPI(RequestAPI):",
            "super().create(**kwargs)",
            "",
            "def create_grid_ui(self, path: str, **kwargs) -> Dict[str, str]:  # type: ignore",
            "-        response = self.node.conn.send_files(",
            "+        response = self.node.conn.send_files( # type: ignore",
            "\"/datasets\", path, form_name=\"metadata\", form_values=kwargs",
            ")  # type: ignore",
            "logging.info(response[RequestAPIFields.MESSAGE])"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 457,
        "label": "no",
        "change": [
            "def multilevel_roi_align(features, rcnn_boxes, resolution):",
            "all_rois = tf.concat(all_rois, axis=0)  # NCHW",
            "# Unshuffle to the original order, to match the original samples",
            "level_id_perm = tf.concat(level_ids, axis=0)  # A permutation of 1~N",
            "-    level_id_invert_perm = tf.invert_permutation(level_id_perm)",
            "+    level_id_invert_perm = tf.math.invert_permutation(level_id_perm)",
            "all_rois = tf.gather(all_rois, level_id_invert_perm, name=\"output\")",
            "return all_rois"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 458,
        "label": "no",
        "change": [
            "def SoftMax(x, use_temperature=False, temperature_init=1.0):",
            ":param x: a 2D tensor",
            "\"\"\"",
            "if use_temperature:",
            "-        t = tf.get_variable('temp', [1],",
            "+        t = tf.get_variable('invtemp', [],",
            "initializer=tf.constant_initializer(1.0 / float(temperature_init)))",
            "x = x * t",
            "return tf.nn.softmax(x, name='output')"
        ],
        "comments": "change param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 459,
        "label": "no",
        "change": [
            "def _preprocess_deconv_output_shape(x, shape, dim_ordering):",
            "shape = (shape[0], shape[2], shape[3], shape[1])",
            "",
            "if shape[0] is None:",
            "-        shape = (tf.shape(x)[0], ) + shape[1:]",
            "+        shape = (tf.shape(x)[0], ) + tuple(shape[1:])",
            "return shape"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 460,
        "label": "yes",
        "change": [
            "class TFGroupViTModel(TFGroupViTPreTrainedModel):",
            "",
            ">>> outputs = model(**inputs)",
            ">>> logits_per_image = outputs.logits_per_image  # this is the image-text similarity score",
            "-        >>> probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities",
            "+        >>> probs = tf.math.softmax(logits_per_image, axis=1)  # we can take the softmax to get the label probabilities",
            "```\"\"\"",
            "",
            "outputs = self.groupvit("
        ],
        "comments": "test fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 461,
        "label": "yes",
        "change": [
            "def lightning_loop(MODEL, num_runs=10, num_epochs=10):",
            "",
            "# set seed",
            "seed = i",
            "-        _set_seed(seed)",
            "+        seed_everything(seed)",
            "",
            "-        # init model parts",
            "model = MODEL()",
            "+        # init model parts",
            "trainer = Trainer(",
            "max_epochs=num_epochs,",
            "progress_bar_refresh_rate=0,",
            "weights_summary=None,",
            "gpus=1,",
            "early_stop_callback=False,",
            "-            checkpoint_callback=False",
            "+            checkpoint_callback=False,",
            "+            deterministic=True,",
            ")",
            "trainer.fit(model)"
        ],
        "comments": "custom API",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 462,
        "label": "no",
        "change": [
            "class RGCNConv(MessagePassing):",
            "return out if edge_norm is None else out * edge_norm.view(-1, 1)",
            "",
            "def update(self, aggr_out, x):",
            "-        if x.dtype == torch.long:",
            "+        if x is None:",
            "out = aggr_out + self.root",
            "else:",
            "out = aggr_out + torch.matmul(x, self.root)"
        ],
        "comments": "change condition check for null fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 467,
        "label": "no",
        "change": [
            "class Baseline(object):",
            "self.all_variables[name] = variable",
            "if kwargs.get('trainable', True) and not name.startswith('optimization'):",
            "self.variables[name] = variable",
            "-                    if 'variables' in self.summary_labels:",
            "-                        summary = tf.summary.histogram(name=name, values=variable)",
            "-                        self.summaries.append(summary)",
            "+                        if 'variables' in self.summary_labels:",
            "+                            summary = tf.summary.histogram(name=name, values=variable)",
            "+                            self.summaries.append(summary)",
            "return variable",
            "",
            "self.predict = tf.make_template("
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 469,
        "label": "no",
        "change": [
            "def load_depth(file_name):",
            "",
            "",
            "def load_camera_data(file_name):",
            "-    \"\"\"Loads the camera data using the sintel SDK and converts to torch.Tensor.\"\"\"",
            "+    \"\"\"Load the camera data using the sintel SDK and converts to torch.Tensor.\"\"\"",
            "if not os.path.isfile(file_name):",
            "raise AssertionError(f\"Invalid file {file_name}\")",
            "import sintel_io"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 470,
        "label": "yes",
        "change": [
            "class DenseGCNConv(torch.nn.Module):",
            "idx = torch.arange(N, dtype=torch.long, device=adj.device)",
            "adj[:, idx, idx] = 1 if not self.improved else 2",
            "",
            "-        out = self.lin(x)",
            "+        out = torch.matmul(x, self.weight)",
            "deg_inv_sqrt = adj.sum(dim=-1).clamp(min=1).pow(-0.5)",
            "",
            "adj = deg_inv_sqrt.unsqueeze(-1) * adj * deg_inv_sqrt.unsqueeze(-2)"
        ],
        "comments": "change API call for math fix",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 471,
        "label": "no",
        "change": [
            "class TFConvNextModelTest(TFModelTesterMixin, unittest.TestCase):",
            "else:",
            "self.assertTrue(",
            "all(tf.equal(tuple_object, dict_object)),",
            "-                        msg=f\"Tuple and dict output are not equal. Difference: {tf.math.reduce_max(tf.abs(tuple_object - dict_object))}\",",
            "+                        msg=(",
            "+                            \"Tuple and dict output are not equal. Difference:\"",
            "+                            f\" {tf.math.reduce_max(tf.abs(tuple_object - dict_object))}\"",
            "+                        ),",
            ")",
            "",
            "recursive_check(tuple_output, dict_output)"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 472,
        "label": "no",
        "change": [
            "class GradientsTest(tf.test.TestCase):",
            "",
            "",
            "if __name__ == \"__main__\":",
            "-  tf.test.main()",
            "+  if tf.__internal__.tf2.enabled():",
            "+    tf.test.main()"
        ],
        "comments": "add condition check for state fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 473,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)",
            "cost = tf.reduce_mean(cost, name='cross_entropy_loss')",
            "",
            "-        acc = tf.to_float(tf.nn.in_top_k(logits, label, 1))",
            "+        acc = tf.cast(tf.nn.in_top_k(logits, label, 1), tf.float32)",
            "",
            "acc = tf.reduce_mean(acc, name='accuracy')",
            "summary.add_moving_summary(acc)"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 475,
        "label": "yes",
        "change": [
            "def block(params, scope, layer_num, bias, sequence_dim, memory_length_dim, varia",
            "if use_moe:",
            "moe_params = mtf.transformer.moe.HParams()",
            "mtf.transformer.moe.set_default_moe_hparams(moe_params)",
            "+",
            "+                # override defaults",
            "for k, v in params[\"moe_params\"].items():",
            "moe_params.add_hparam(k, v)",
            "-                mtf.transformer.moe.set_default_moe_hparams(moe_params)",
            "+",
            "moe_train = params[\"mode\"] == \"train\"",
            "",
            "m, aux_loss = mtf.transformer.moe.transformer_moe_layer_v1(res_x, x.shape[-1], moe_params,"
        ],
        "comments": "format",
        "Symptom": "low efficiency",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 476,
        "label": "no",
        "change": [
            "class TFCoreModelTesterMixin:",
            "",
            "self.assertIsNotNone(outputs)",
            "",
            "-        tf.keras.mixed_precision.experimental.set_policy(\"float32\")",
            "+        tf.keras.mixed_precision.set_global_policy(\"float32\")",
            "",
            "@slow",
            "def test_train_pipeline_custom_model(self):"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 477,
        "label": "no",
        "change": [
            "class KerasCallbacksTest(keras_parameterized.TestCase):",
            "1, activation='sigmoid'),))",
            "model.compile(",
            "optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])",
            "-    expected_log = r'(.*- loss:.*- accuracy:.*epoch)+'",
            "+    expected_log = r'(.*- loss:.*- acc.*:.*epoch)+'",
            "with self.captureWritesToStream(sys.stdout) as printed:",
            "model.fit(data, labels, verbose=2, epochs=20)",
            "self.assertRegex(printed.contents(), expected_log)"
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 478,
        "label": "no",
        "change": [
            "class Wavernn(BaseVocoder):",
            "f\"test_{idx}/prediction\": plot_spectrogram(x_hat.T),",
            "}",
            ")",
            "-            audios.update({f\"test_{idx}/audio\", y_hat})",
            "+            audios.update({f\"test_{idx}/audio\": y_hat})",
            "return figures, audios",
            "",
            "@staticmethod"
        ],
        "comments": "test",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 479,
        "label": "no",
        "change": [
            "class TFMBartForConditionalGeneration(TFMBartPreTrainedModel, TFCausalLanguageMo",
            "if labels is not None:",
            "labels = tf.where(",
            "labels == self.config.pad_token_id,",
            "-                tf.fill(shape_list(labels), -100),",
            "+                tf.cast(tf.fill(shape_list(labels), -100), labels.dtype),",
            "labels,",
            ")",
            "use_cache = False"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 480,
        "label": "no",
        "change": [
            "class TFModelTesterMixin:",
            "def _prepare_for_class(self, inputs_dict, model_class, return_labels=False):",
            "if model_class in TF_MODEL_FOR_MULTIPLE_CHOICE_MAPPING.values():",
            "inputs_dict = {",
            "-                k: tf.tile(tf.expand_dims(v, 1), (1, self.model_tester.num_choices, 1))",
            "-                if isinstance(v, tf.Tensor) and v.ndim != 0",
            "+                k: tf.tile(tf.expand_dims(v, 1), (1, self.model_tester.num_choices) + (1,) * (v.ndim - 1))",
            "+                if isinstance(v, tf.Tensor) and v.ndim > 0",
            "else v",
            "for k, v in inputs_dict.items()",
            "}"
        ],
        "comments": "no API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 481,
        "label": "no",
        "change": [
            "def main():",
            "# Setup CUDA, GPU & distributed training",
            "if args.local_rank == -1 or args.no_cuda:",
            "device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")",
            "-        args.n_gpu = torch.cuda.device_count()",
            "+        args.n_gpu = 0 if args.no_cuda else torch.cuda.device_count()",
            "else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs",
            "torch.cuda.set_device(args.local_rank)",
            "device = torch.device(\"cuda\", args.local_rank)"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 482,
        "label": "no",
        "change": [
            "class Pandas(datasets.ArrowBasedBuilder):",
            "return pa_table",
            "",
            "def _generate_tables(self, files):",
            "-        for i, file in enumerate(files):",
            "+        for i, file in enumerate(itertools.chain.from_iterable(files)):",
            "with open(file, \"rb\") as f:",
            "pa_table = pa.Table.from_pandas(pd.read_pickle(f))",
            "yield i, self._cast_table(pa_table)"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 483,
        "label": "no",
        "change": [
            "class DiceLoss(nn.Module):",
            "cardinality = torch.sum(input_soft + target_one_hot, dims)",
            "",
            "dice_score = 2. * intersection / (cardinality + self.eps)",
            "-        return torch.mean(1. - dice_score)",
            "+        return torch.mean(torch.tensor(1.) - dice_score)",
            "",
            "",
            "######################"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 486,
        "label": "no",
        "change": [
            "from allennlp.training.metrics import ConllCorefScores",
            "class ConllCorefScoresTest(AllenNlpTestCase):",
            "def test_get_predicted_clusters(self):",
            "top_spans = torch.Tensor([[0, 1], [4, 6], [8, 9]]).long()",
            "-        antecedent_indices = torch.Tensor([[-1, -1, -1],",
            "-                                           [0, -1, -1],",
            "-                                           [0, 1, -1]]).long()",
            "+        antecedent_indices = torch.Tensor([[-1, -1, -1], [0, -1, -1], [0, 1, -1]]).long()",
            "predicted_antecedents = torch.Tensor([-1, -1, 1]).long()",
            "-        clusters, mention_to_cluster = ConllCorefScores.get_predicted_clusters(top_spans,",
            "-                                                                               antecedent_indices,",
            "-                                                                               predicted_antecedents)",
            "+        clusters, mention_to_cluster = ConllCorefScores.get_predicted_clusters(",
            "+            top_spans, antecedent_indices, predicted_antecedents",
            "+        )",
            "assert len(clusters) == 1",
            "assert set(clusters[0]) == {(4, 6), (8, 9)}",
            "assert mention_to_cluster == {(4, 6): clusters[0], (8, 9): clusters[0]}"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 487,
        "label": "no",
        "change": [
            "def find_state_op_colocation_error(graph, reported_tags=None):",
            "for op in state_op_map.values():",
            "for colocation_group in op.colocation_groups():",
            "if not (colocation_group.startswith(tf.compat.as_bytes(\"loc:@\")) and",
            "-              tf.compat.as_str(colocation_group[5:]) in state_op_map):",
            "+              tf.compat.as_str_any(colocation_group[5:]) in state_op_map):",
            "tags_prefix = (\"\" if reported_tags is None else",
            "\"in the graph for tags %s, \" % reported_tags)",
            "return ("
        ],
        "comments": "customize API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 488,
        "label": "yes",
        "change": [
            "class SageMakerTrainingArguments(TrainingArguments):",
            "# Here, we'll use torch.distributed.",
            "# Initializes the distributed backend which will take care of synchronizing nodes/GPUs",
            "if not torch.distributed.is_initialized():",
            "-                torch.distributed.init_process_group(backend=\"nccl\")",
            "+                torch.distributed.init_process_group(backend=\"nccl\", timeout=self.ddp_timeout_delta)",
            "device = torch.device(\"cuda\", self.local_rank)",
            "self._n_gpu = 1"
        ],
        "comments": "add param for state fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 489,
        "label": "no",
        "change": [
            "def main(_):",
            "# net = tl.layers.ReshapeLayer(net,",
            "#       shape=[-1, int(net.outputs._shape[-1])], name='reshape')",
            "net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_training, name='drop3')",
            "-            net = tl.layers.DenseLayer(net, vocab_size, W_init=init, b_init=init, act=tf.identity, name='output')",
            "+            net = tl.layers.DenseLayer(net, vocab_size, W_init=init, b_init=init, act=None, name='output')",
            "return net, lstm1, lstm2",
            "",
            "# Inference for Training"
        ],
        "comments": "change param for null fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 490,
        "label": "yes",
        "change": [
            "class SlimNetsLayer(Layer):",
            "slim_variables = tf.get_collection(TF_GRAPHKEYS_VARIABLES, scope=self.name)",
            "",
            "if slim_variables == []:",
            "-            logging.error(",
            "-                \"No variables found under %s : the name of SlimNetsLayer should be matched with the begining of the ckpt file, see tutorial_inceptionV3_tfslim.py for more details\"",
            "-                % self.name",
            "+            raise RuntimeError(",
            "+                \"No variables found under %s : the name of SlimNetsLayer should be matched with the begining of the ckpt file.\\n\"",
            "+                \"see tutorial_inceptionV3_tfslim.py for more details\" % self.name",
            ")",
            "",
            "slim_layers = []",
            "",
            "for v in end_points.values():",
            "-            # tf.contrib.layers.summaries.summarize_activation(v)",
            "slim_layers.append(v)",
            "",
            "self._add_layers(slim_layers)"
        ],
        "comments": "change API raise error",
        "Symptom": "program crash",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 494,
        "label": "no",
        "change": [
            "class DecoderLayer(nn.Module):",
            "self.sublayer = nn_util.clone(SublayerConnection(size, dropout), 3)",
            "",
            "def forward(",
            "-        self, x: torch.Tensor, memory: torch.Tensor, src_mask: torch.Tensor, tgt_mask: torch.Tensor",
            "+        self,",
            "+        x: torch.Tensor,",
            "+        memory: torch.Tensor,",
            "+        src_mask: torch.BoolTensor,",
            "+        tgt_mask: torch.BoolTensor,",
            ") -> torch.Tensor:",
            "# Follow Figure 1 (right) for connections.",
            "x = self.sublayer[0](x, lambda y: self.self_attn(y, y, y, tgt_mask))"
        ],
        "comments": "update param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 495,
        "label": "no",
        "change": [
            "class BiaffineDependencyParser(Model):",
            "head_tags.append(head_tag)",
            "return torch.from_numpy(numpy.stack(heads)), torch.from_numpy(numpy.stack(head_tags))",
            "",
            "-",
            "def _get_head_tags(self,",
            "head_tag_representation: torch.Tensor,",
            "child_tag_representation: torch.Tensor,"
        ],
        "comments": "no fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 497,
        "label": "no",
        "change": [
            "class EvalbBracketingScorer(Metric):",
            "shutil.rmtree(tempdir)",
            "",
            "if is_distributed():",
            "-            # Setting the device to CPU since this metric is not expected to run on GPUs.",
            "-            device = torch.device(\"cpu\")",
            "+            device = torch.device(\"cuda\" if dist.get_backend() == \"nccl\" else \"cpu\")",
            "correct_predicted_brackets = torch.tensor(_correct_predicted_brackets).to(device)",
            "predicted_brackets = torch.tensor(_predicted_brackets).to(device)",
            "gold_brackets = torch.tensor(_gold_brackets).to(device)"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 498,
        "label": "no",
        "change": [
            "def ones(shape: Union[int, Tuple[int, ...]],",
            "dtype: Optional[torch.dtype] = None,",
            "device: Optional[Union[torch.device, str]] = None) \\",
            "-> torch.Tensor:",
            "-    dtype_val: torch.dtype = ivy.dtype_from_str(dtype)",
            "-    dev = ivy.default_device(device)",
            "-    return torch.ones(shape, dtype=dtype_val, device=ivy.dev_from_str(dev))",
            "+    dtype_val: torch.dtype = dtype_from_str(dtype)",
            "+    dev = default_device(device)",
            "+    return torch.ones(shape, dtype=dtype_val, device=dev_from_str(dev))"
        ],
        "comments": "version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 499,
        "label": "no",
        "change": [
            "class TFDebertaV2DisentangledSelfAttention(tf.keras.layers.Layer):",
            "",
            "if not self.share_att_key:",
            "if \"c2p\" in self.pos_att_type:",
            "-                    self.pos_proj = tf.keras.layers.Dense(",
            "+                    self.pos_key_proj = tf.keras.layers.Dense(",
            "self.all_head_size,",
            "kernel_initializer=get_initializer(config.initializer_range),",
            "name=\"pos_proj\",",
            "use_bias=True,",
            ")",
            "if \"p2c\" in self.pos_att_type:",
            "-                    self.pos_q_proj = tf.keras.layers.Dense(",
            "+                    self.pos_query_proj = tf.keras.layers.Dense(",
            "self.all_head_size,",
            "kernel_initializer=get_initializer(config.initializer_range),",
            "name=\"pos_q_proj\","
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 500,
        "label": "no",
        "change": [
            "def quantize_model_(",
            "print(num_assignments)",
            "print(num_extra)",
            "assignments_bins = torch.arange(counts)",
            "-            assignments_rand = torch.randint(0, counts-1, (num_extra, ))",
            "+            assignments_rand = torch.randint(0, counts - 1, (num_extra,))",
            "assignments = torch.cat((assignments_bins, assignments_rand), 0)",
            "# assignments = assignments.type(torch.IntTensor)",
            "assignments.cuda()"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 501,
        "label": "no",
        "change": [
            "class E2E(torch.nn.Module):",
            "# Neither CPUTensor nor float/int value can be used",
            "# because NCCL communicates between GPU devices.",
            "device = next(self.parameters()).device",
            "-        acc = torch.tensor([acc], device=device)",
            "+",
            "+        acc = torch.tensor([acc], device=device) if acc is not None else None",
            "cer = torch.tensor([cer], device=device)",
            "wer = torch.tensor([wer], device=device)",
            "return self.loss, loss_ctc, loss_att, acc, cer, wer"
        ],
        "comments": "add condition check for null fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 502,
        "label": "no",
        "change": [
            "class DeepQNetwork(ValueFunction):",
            "\"\"\"",
            "",
            "# Compute estimated future value",
            "-        float_terminals = tf.to_float(batch['terminals'])",
            "+        float_terminals = batch['terminals'].astype(float)",
            "q_targets = batch['rewards'] + (1. - float_terminals) \\",
            "* self.gamma * self.get_target_values(batch['next_states'])"
        ],
        "comments": "remove API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 503,
        "label": "no",
        "change": [
            "class BoxBlur(nn.Module):",
            "torch.Size([2, 4, 5, 7])",
            "\"\"\"",
            "",
            "-    def __init__(self, kernel_size: Tuple[int, int],",
            "-                 border_type: str = 'reflect',",
            "-                 normalized: bool = True) -> None:",
            "+    def __init__(self, kernel_size: Tuple[int, int], border_type: str = 'reflect', normalized: bool = True) -> None:",
            "super(BoxBlur, self).__init__()",
            "self.kernel_size: Tuple[int, int] = kernel_size",
            "self.border_type: str = border_type"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 505,
        "label": "no",
        "change": [
            "_TXT_DOWNLOAD_URL = \"https://unicode.org/udhr/assemblies/udhr_txt.zip\"",
            "class UDHN(datasets.GeneratorBasedBuilder):",
            "\"\"\"Universal Declaration of Human Rights\"\"\"",
            "",
            "+    VERSION = datasets.Version(\"1.0.0\")",
            "+",
            "def _info(self):",
            "return datasets.DatasetInfo(",
            "description=_DESCRIPTION,"
        ],
        "comments": "add version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 508,
        "label": "yes",
        "change": [
            "class DistributedFusedAdam(torch.optim.Optimizer):",
            "grp = torch.distributed.new_group(ranks=ranks)",
            "if torch.distributed.get_rank() in ranks:",
            "self._rs_pg.append(grp)",
            "-            if self._compute_L2_grad_norm and torch.distributed.get_rank() in ranks:",
            "-                self._l2_grad_norm_pg = torch.distributed.new_group(ranks=ranks)",
            "-                torch.distributed.all_reduce(self._overflow_buf,group=self._l2_grad_norm_pg)",
            "+            if self._compute_L2_grad_norm:",
            "+                l2_grad_norm_pg = torch.distributed.new_group(ranks=ranks)",
            "+                if torch.distributed.get_rank() in ranks:",
            "+                    self._l2_grad_norm_pg = l2_grad_norm_pg",
            "+                    torch.distributed.all_reduce(self._overflow_buf,group=self._l2_grad_norm_pg)",
            "self._rs_st = [torch.cuda.Stream() for _ in range(self._num_rs_pg)]",
            "for rs_pg in self._rs_pg:",
            "torch.distributed.all_reduce(self._overflow_buf,group=rs_pg)"
        ],
        "comments": "remove condition check for resource fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 509,
        "label": "no",
        "change": [
            "-import tensorflow as tf",
            "-from autokeras.hyperparameters import HyperParameters",
            "-",
            "-",
            "-def test_hierarchical_hyperparameters():",
            "-    hp = HyperParameters()",
            "-    with tf.name_scope('abc'):",
            "-        hp.Choice('num_layers', [1, 2, 3], default=1)",
            "-    assert 'abc/num_layers' in hp.values"
        ],
        "comments": "remove old code",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 510,
        "label": "yes",
        "change": [
            "def cartesian_product_of_parameters(**possible_parameters):",
            "",
            "",
            "def default_with_one_parameter_changed(*, default={}, **possible_parameters):",
            "-    assert isinstance(default, dict), f\"default should be a dict not a {type(default)}\"",
            "+    if not isinstance(default, dict):",
            "+        raise AssertionError(f\"default should be a dict not a {type(default)}\")",
            "",
            "for parameter_name, possible_values in possible_parameters.items():",
            "for v in possible_values:"
        ],
        "comments": "add condition check for type fix",
        "Symptom": "program crash",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 511,
        "label": "yes",
        "change": [
            "def read_ply_data(path):",
            "pos = ([torch.tensor(data['vertex'][axis]) for axis in ['x', 'y', 'z']])",
            "pos = torch.stack(pos, dim=-1)",
            "",
            "-    face = data['face']['vertex_indices']",
            "-    face = [torch.tensor(f, dtype=torch.long) for f in face]",
            "-    face = torch.stack(face, dim=-1)",
            "+    faces = data['face']['vertex_indices']",
            "+    faces = [torch.tensor(face, dtype=torch.long) for face in faces]",
            "+    face = torch.stack(faces, dim=-1)",
            "",
            "edge_index = face_to_edge_index(face, num_nodes=pos.size(0))"
        ],
        "comments": "rename var",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 514,
        "label": "no",
        "change": [
            "def any(",
            "axis = tuple(range(num_dims))",
            "elif isinstance(axis, list):",
            "axis = tuple(axis)",
            "-    ret = tf.reduce_any(tf.cast(x, tf.bool), axis=axis, keepdims=keepdims)",
            "-    return ret",
            "+    return tf.reduce_any(tf.cast(x, tf.bool), axis=axis, keepdims=keepdims)"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 516,
        "label": "no",
        "change": [
            "class Speech2Text2SinusoidalPositionalEmbedding(nn.Module):",
            "emb = torch.cat([emb, torch.zeros(num_embeddings, 1)], dim=1)",
            "if padding_idx is not None:",
            "emb[padding_idx, :] = 0",
            "-        return emb",
            "+        return emb.to(torch.get_default_dtype())",
            "",
            "@torch.no_grad()",
            "def forward(self, input_ids: torch.Tensor, past_key_values_length: int = 0):"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 517,
        "label": "no",
        "change": [
            "class DDPG(object):",
            "with tf.GradientTape() as tape:",
            "a = self.actor(bs)",
            "q = self.critic([bs, a])",
            "-            a_loss = -tf.reduce_mean(q)  # maximize the q",
            "+            a_loss = - tf.reduce_mean(q)  # maximize the q",
            "a_grads = tape.gradient(a_loss, self.actor.trainable_weights)",
            "self.actor_opt.apply_gradients(zip(a_grads, self.actor.trainable_weights))"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 518,
        "label": "yes",
        "change": [
            "class EulerAncestralDiscreteScheduler(SchedulerMixin, ConfigMixin):",
            "",
            "prev_sample = sample + derivative * dt",
            "",
            "-        device = model_output.device if torch.is_tensor(model_output) else \"cpu\"",
            "-        if str(device) == \"mps\":",
            "+        device = model_output.device if torch.is_tensor(model_output) else torch.device(\"cpu\")",
            "+        if device.type == \"mps\":",
            "# randn does not work reproducibly on mps",
            "noise = torch.randn(model_output.shape, dtype=model_output.dtype, device=\"cpu\", generator=generator).to(",
            "device"
        ],
        "comments": "add API call for resource fix",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api condition check"
    },
    {
        "number": 519,
        "label": "no",
        "change": [
            "class AutoRegressiveNN(nn.Module):",
            "",
            "if permutation is None:",
            "# By default set a random permutation of variables, which is important for performance with multiple steps",
            "-            self.permutation = torch.randperm(input_dim)",
            "+            self.permutation = torch.randperm(input_dim, device='cpu').to(torch.Tensor().device)",
            "else:",
            "# The permutation is chosen by the user",
            "self.permutation = permutation.type(dtype=torch.int64)"
        ],
        "comments": "add API call for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 521,
        "label": "no",
        "change": [
            "class Input(Node):",
            "",
            "",
            "class ImageInput(Node):",
            "+",
            "def __init__(self, **kwargs):",
            "super().__init__(**kwargs)",
            "",
            "def build(self, hp):",
            "-        pass",
            "+        return tf.keras.Input(shape=self.shape)",
            "",
            "",
            "class TextInput(Node):",
            "+",
            "def __init__(self, **kwargs):",
            "super().__init__(**kwargs)"
        ],
        "comments": "not clear",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 522,
        "label": "no",
        "change": [
            "class StableDiffusionInpaintPipeline(DiffusionPipeline):",
            "else:",
            "raise ImportError(\"Please install accelerate via `pip install accelerate`\")",
            "",
            "-        device = torch.device(\"cuda\")",
            "+        device = torch.device(f\"cuda:{gpu_id}\")",
            "",
            "for cpu_offloaded_model in [self.unet, self.text_encoder, self.vae, self.safety_checker]:",
            "if cpu_offloaded_model is not None:"
        ],
        "comments": "change param for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 524,
        "label": "yes",
        "change": [
            "class TwoStageDetector(BaseDetector, RPNTestMixin, BBoxTestMixin,",
            "if self.with_rpn:",
            "rpn_outs = self.rpn_head(x)",
            "outs = outs + (rpn_outs, )",
            "-        proposals = torch.randn(1000, 4).cuda()",
            "+        proposals = torch.randn(1000, 4).to(device=img.device)",
            "# bbox head",
            "rois = bbox2roi([proposals])",
            "if self.with_bbox:"
        ],
        "comments": "change API call for resource fix",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 526,
        "label": "no",
        "change": [
            "class PGModel(Model):",
            "actions = np.concatenate([path['actions'] for path in batch])",
            "batch_advantage = np.concatenate([path[\"advantage\"] for path in batch])",
            "batch_advantage = zero_mean_unit_variance(batch_advantage)",
            "+        batch_advantage = np.expand_dims(batch_advantage, axis=1)",
            "states = np.concatenate([path['states'] for path in batch])",
            "",
            "return action_log_stds, action_means, actions, batch_advantage, states"
        ],
        "comments": "add API call for shape fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 529,
        "label": "no",
        "change": [
            "class Categorical(Distribution):",
            "elif one_hot:",
            "boolean_mask = x",
            "else:",
            "-                boolean_mask = torch.zeros(ps.size()).scatter_(-1, x.data.long(), 1)",
            "+                boolean_mask = torch_zeros_like(ps.data).scatter_(-1, x.data.long(), 1)",
            "# apply log function to masked probability tensor",
            "return torch.log(ps.masked_select(boolean_mask.byte()).contiguous().view(*batch_pdf_size))"
        ],
        "comments": "change API call for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 530,
        "label": "no",
        "change": [
            "class ViTMAEModelIntegrationTest(unittest.TestCase):",
            "",
            "# forward pass",
            "with torch.no_grad():",
            "-            outputs = model(**inputs, noise=torch.from_numpy(noise))",
            "+            outputs = model(**inputs, noise=torch.from_numpy(noise).to(device=torch_device))",
            "",
            "# verify the logits",
            "expected_shape = torch.Size((1, 196, 768))"
        ],
        "comments": "add API call for resource fixfor resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 531,
        "label": "no",
        "change": [
            "\"source\": [",
            "\"## Computation\\n\",",
            "\"\\n\",",
            "-    \"**Note copmut\"",
            "+    \"**Note computation, tfe.serving.QueueServer etc. will move into model.share()**\"",
            "]",
            "},",
            "{"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 532,
        "label": "yes",
        "change": [
            "def initialize_vocabulary(vocabulary_path):",
            "rev_vocab = []",
            "with gfile.GFile(vocabulary_path, mode=\"rb\") as f:",
            "rev_vocab.extend(f.readlines())",
            "-    rev_vocab = [line.strip() for line in rev_vocab]",
            "+    rev_vocab = [tf.compat.as_bytes(line.strip()) for line in rev_vocab]",
            "vocab = dict([(x, y) for (y, x) in enumerate(rev_vocab)])",
            "return vocab, rev_vocab",
            "else:"
        ],
        "comments": "add API call for type fix",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 533,
        "label": "no",
        "change": [
            "class CenterCrop(GeometricAugmentationBase2D):",
            "padding_mode=\"zeros\",",
            ")",
            "",
            "-    def generate_parameters(self, batch_shape: torch.Size) -> Dict[str, Tensor]:",
            "+    def generate_parameters(self, batch_shape: Tuple[int, ...]) -> Dict[str, Tensor]:",
            "return rg.center_crop_generator(batch_shape[0], batch_shape[-2], batch_shape[-1], self.size, self.device)",
            "",
            "def compute_transformation(self, input: Tensor, params: Dict[str, Tensor], flags: Dict[str, Any]) -> Tensor:"
        ],
        "comments": "def",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 534,
        "label": "no",
        "change": [
            "class ConformerSeparator(AbsSeparator):",
            "\"\"\"",
            "",
            "# if complex spectrum,",
            "-        if isinstance(input, ComplexTensor):",
            "+        if isinstance(input, ComplexTensor) or (",
            "+            is_torch_1_8_plus and torch.is_complex(input)",
            "+        ):",
            "feature = abs(input)",
            "else:",
            "feature = input"
        ],
        "comments": "add condition check for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 535,
        "label": "no",
        "change": [
            "def model_import_test(algo, config, env):",
            "agent.import_model(import_file=import_file)",
            "check(current_weight(agent), weight_after_import)",
            "",
            "-        if eager_mode_ctx:",
            "-            eager_mode_ctx.__exit__(None, None, None)",
            "-",
            "",
            "class TestModelImport(unittest.TestCase):",
            "def setUp(self):"
        ],
        "comments": "remove condition",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 537,
        "label": "yes",
        "change": [
            "def batch_flatten(x):",
            "'''Turn a n-D tensor into a 2D tensor where",
            "the first dimension is conserved.",
            "'''",
            "-    x = tf.reshape(x, [-1, prod(shape(x)[1:])])",
            "+    x = tf.reshape(x, tf.pack([-1, prod(shape(x)[1:])]))",
            "return x"
        ],
        "comments": "add API call for type fix",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 538,
        "label": "no",
        "change": [
            "def distributed_train(local_rank: int, main_address: str, main_port: int, num_no",
            "# 2. PREPARE DISTRIBUTED MODEL",
            "model = torch.nn.Linear(32, 2)",
            "device = torch.device(f\"cuda:{local_rank}\") if torch.cuda.is_available() else torch.device(\"cpu\")",
            "-    model = DistributedDataParallel(model, device_ids=[local_rank]).to(device)",
            "+    model = DistributedDataParallel(model, device_ids=[local_rank] if torch.cuda.is_available() else None).to(device)",
            "",
            "# 3. SETUP LOSS AND OPTIMIZER",
            "criterion = torch.nn.MSELoss()"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 543,
        "label": "yes",
        "change": [
            "class COMET(datasets.Metric):",
            "",
            "def _download_and_prepare(self, dl_manager):",
            "if self.config_name == \"default\":",
            "-            self.scorer = download_model(\"wmt-large-da-estimator-1719\")",
            "+            self.scorer = comet.models.download_model(\"wmt-large-da-estimator-1719\")",
            "else:",
            "-            self.scorer = download_model(self.config_name)",
            "+            self.scorer = comet.models.download_model(self.config_name)",
            "",
            "def _compute(self, sources, predictions, references, cuda=True, show_progress=False):",
            "data = {\"src\": sources, \"mt\": predictions, \"ref\": references}"
        ],
        "comments": "test fix",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 544,
        "label": "no",
        "change": [
            "def quantile(",
            "temp, q, dim=-1, keepdim=keepdims, interpolation=interpolation, out=out",
            ")",
            "return torch.quantile(",
            "-        a, q, dim=axis, keepdim=keepdims, interpolation=interpolation, out=out",
            "+        temp, q, dim=axis, keepdim=keepdims, interpolation=interpolation, out=out",
            ")"
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 545,
        "label": "no",
        "change": [
            "if __name__ == '__main__':",
            "",
            "# dataset = roiLoader(roidb, imdb.num_classes)",
            "dataset = roibatchLoader(roidb, imdb.num_classes)",
            "-  dataloader = torch.utils.data.DataLoader(dataset, batch_size=cfg.TRAIN.IMS_PER_BATCH,",
            "+  dataloader = torch.utils.data.DataLoader(dataset, batch_size=8,",
            "shuffle=False, num_workers=5)",
            "",
            "# initilize the tensor holder here."
        ],
        "comments": "change param for shape fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 547,
        "label": "no",
        "change": [
            "def test_confusion_matrix(",
            "@handle_cmd_line_args",
            "@given(",
            "dtype_and_x=helpers.dtype_and_values(",
            "-        available_dtypes=tuple(ivy_tf.valid_numeric_dtypes)",
            "+        available_dtypes=tuple(ivy_tf.valid_float_dtypes)",
            "),",
            "x=helpers.array_values(shape=(3,), dtype=ivy.int32),",
            "as_variable=st.booleans(),"
        ],
        "comments": "name change",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 548,
        "label": "no",
        "change": [
            "class VisionTransformer(nn.Module):",
            "",
            "def forward(self, x):",
            "x = self.forward_features(x)",
            "-        if isinstance(x, tuple):",
            "-            x, x_dist = self.head(x[0]), self.head_dist(x[1])",
            "+        if self.head_dist is not None:",
            "+            x, x_dist = self.head(x[0]), self.head_dist(x[1])  # x must be a tuple",
            "if self.training and not torch.jit.is_scripting():",
            "# during inference, return the average of both classifier predictions",
            "return x, x_dist"
        ],
        "comments": "change condition check for null fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 549,
        "label": "no",
        "change": [
            "class TFKerasUtil(object):",
            "",
            "dataset = dataset.batch(batch_size).map(prep_data_tf_keras)",
            "return dataset",
            "-        return fn",
            "+        return tf.autograph.experimental.do_not_convert(fn) if _HAS_AUTOGRAPH else fn",
            "",
            "@staticmethod",
            "def get_horovod():"
        ],
        "comments": "add condition check for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 554,
        "label": "no",
        "change": [
            "with tf.device('/cpu:0'):",
            "net = FlattenLayer(net, name='flatten')",
            "net = DenseLayer(net, 384, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='d1relu')",
            "net = DenseLayer(net, 192, act=tf.nn.relu, W_init=W_init2, b_init=b_init2, name='d2relu')",
            "-            net = DenseLayer(net, n_units=10, act=tf.identity, W_init=W_init2, name='output')",
            "+            net = DenseLayer(net, n_units=10, act=None, W_init=W_init2, name='output')",
            "y = net.outputs",
            "",
            "ce = tl.cost.cross_entropy(y, y_, name='cost')"
        ],
        "comments": "change param for null fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 555,
        "label": "no",
        "change": [
            "class GaussianNoise(Exploration):",
            "true_fn=lambda: stochastic_actions,",
            "false_fn=lambda: deterministic_actions)",
            "# Logp=always zero.",
            "-        logp = tf.zeros(shape=(batch_size, ), dtype=tf.float32)",
            "+        logp = tf.zeros(shape=(batch_size,), dtype=tf.float32)",
            "",
            "# Increment `last_timestep` by 1 (or set to `timestep`).",
            "-        assign_op = \\",
            "-            tf.assign_add(self.last_timestep, 1) if timestep is None else \\",
            "-            tf.assign(self.last_timestep, timestep)",
            "-        with tf.control_dependencies([assign_op]):",
            "+        assign_op = (",
            "+            tf1.assign_add(self.last_timestep, 1) if timestep is None else",
            "+            tf1.assign(self.last_timestep, timestep))",
            "+        with tf1.control_dependencies([assign_op]):",
            "return action, logp",
            "",
            "def _get_torch_exploration_action(self, action_dist, explore, timestep):"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 557,
        "label": "no",
        "change": [
            "class up(nn.Module):",
            "if bilinear:",
            "self.up = nn.UpsamplingBilinear2d(scale_factor=2)",
            "else:",
            "-            self.up = nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2)",
            "+            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)",
            "",
            "self.conv = double_conv(in_ch, out_ch)"
        ],
        "comments": "change param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 559,
        "label": "no",
        "change": [
            "class Metric(nn.Module, ABC):",
            "Automatically calls ``update()``. Returns the metric value over inputs if ``compute_on_step`` is True.",
            "\"\"\"",
            "# add current step",
            "-        self.update(*args, **kwargs)",
            "+        with torch.no_grad():",
            "+            self.update(*args, **kwargs)",
            "self._forward_cache = None",
            "",
            "if self.compute_on_step:"
        ],
        "comments": "add API call for state fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 560,
        "label": "yes",
        "change": [
            "temperature = max(args.temperature, 1e-3)",
            "with open(args.outf, 'w') as outf:",
            "for i in range(args.nwords):",
            "",
            "-        output, hidden = model(Variable(input, requires_grad=False), hidden)",
            "-        gen = torch.multinomial(output[0].data.cpu().div(temperature).exp(), 1)[0][0] # FIXME: no multinomial on GPU?",
            "+        output, hidden = model(Variable(input, volatile=True), hidden)",
            "+        gen = torch.multinomial(output[0].data.div(temperature).exp().cpu(), 1)[0][0] # FIXME: multinomial is only for CPU",
            "input.fill_(gen)",
            "word = corpus.dic.idx2word[gen]",
            "outf.write(word)"
        ],
        "comments": "change API call for resource fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 561,
        "label": "no",
        "change": [
            "class TFFunnelForMultipleChoice(TFFunnelPreTrainedModel, TFMultipleChoiceLoss):",
            "@tf.function(",
            "input_signature=[",
            "{",
            "-                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),",
            "+                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),",
            "\"attention_mask\": tf.TensorSpec((None, None), tf.float32, name=\"attention_mask\"),",
            "-                \"token_type_ids\": tf.TensorSpec((None, None), tf.int64, name=\"token_type_ids\"),",
            "+                \"token_type_ids\": tf.TensorSpec((None, None), tf.int32, name=\"token_type_ids\"),",
            "}",
            "]",
            ")"
        ],
        "comments": "change param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 563,
        "label": "no",
        "change": [
            "class CodeGenerator(Generator):",
            "x = torch.cat([x, spkr], dim=1)",
            "",
            "for k, feat in kwargs.items():",
            "-            if k in [\"spkr\", \"code\", \"dur_prediction\"]:",
            "+            if k in [\"spkr\", \"code\", \"f0\", \"dur_prediction\"]:",
            "continue",
            "",
            "feat = self._upsample(feat, x.shape[-1])"
        ],
        "comments": "not clear",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 564,
        "label": "no",
        "change": [
            "class TorchHook:",
            "setattr(torch_module, func, new_func)",
            "",
            "torch_modules = syft.torch.torch_modules",
            "-        # torch_modules = {\"torch.nn.functional\": self.torch.nn.functional,",
            "-                         # \"torch\": self.torch}",
            "-        # TODO Replace with syft.torch.torch_modules when hooking 'torch' will not break msgpack",
            "",
            "for module_name, torch_module in torch_modules.items():",
            "for func in dir(torch_module):"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 565,
        "label": "no",
        "change": [
            "class PiecewiseConstant(Parameter):",
            "elif self.unit == 'episodes':",
            "step = Module.retrieve_tensor(name='episode')",
            "",
            "-        # step = tf.Print(step, (step,))",
            "-",
            "parameter = tf.train.piecewise_constant(",
            "x=step, boundaries=self.boundaries, values=self.values",
            ")"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 566,
        "label": "yes",
        "change": [
            "class ModelSaver(Callback):",
            "self.var_collections = var_collections",
            "if checkpoint_dir is None:",
            "checkpoint_dir = logger.get_logger_dir()",
            "-        assert checkpoint_dir is not None",
            "-        if not tf.gfile.IsDirectory(checkpoint_dir):",
            "-            tf.gfile.MakeDirs(checkpoint_dir)",
            "+        if checkpoint_dir is not None:",
            "+            if not tf.gfile.IsDirectory(checkpoint_dir):",
            "+                tf.gfile.MakeDirs(checkpoint_dir)",
            "self.checkpoint_dir = checkpoint_dir",
            "",
            "def _setup_graph(self):",
            "+        assert self.checkpoint_dir is not None, \\",
            "+            \"ModelSaver() doesn't have a valid checkpoint directory.\"",
            "vars = []",
            "for key in self.var_collections:",
            "vars.extend(tf.get_collection(key))"
        ],
        "comments": "change condition check for null fix",
        "Symptom": "program crash",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 569,
        "label": "no",
        "change": [
            "def setup_ddp(rank, world_size):",
            "os.environ[\"MASTER_ADDR\"] = 'localhost'",
            "os.environ['MASTER_PORT'] = '8088'",
            "",
            "-    if torch.distributed.is_available():",
            "+    if torch.distributed.is_available() and sys.platform not in ['win32', 'cygwin']:",
            "torch.distributed.init_process_group(\"gloo\", rank=rank, world_size=world_size)"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 570,
        "label": "no",
        "change": [
            "def luv_to_rgb(image: torch.Tensor, eps: float = 1e-12) -> torch.Tensor:",
            "g: torch.Tensor = torch.where(gs > 0.0031308, 1.055 * torch.pow(gs, 1 / 2.4) - 0.055, 12.92 * gs)",
            "b: torch.Tensor = torch.where(bs > 0.0031308, 1.055 * torch.pow(bs, 1 / 2.4) - 0.055, 12.92 * bs)",
            "",
            "-    rgb_im: torch.Tensor = torch.stack((r, g, b), dim=-3)",
            "+    rgb_im: torch.Tensor = torch.stack([r, g, b], dim=-3)",
            "",
            "return rgb_im"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 571,
        "label": "yes",
        "change": [
            "class ModelCheckpoint(Callback):",
            "self.best_k_models.pop(del_filepath)",
            "",
            "# do not save nan, replace with +/- inf",
            "-        if torch.isnan(current):",
            "+        if isinstance(current, torch.Tensor) and torch.isnan(current):",
            "current = torch.tensor(float('inf' if self.mode == \"min\" else '-inf'))",
            "",
            "filepath = self._get_metric_interpolated_filepath_name(ckpt_name_metrics, epoch, step, del_filepath)"
        ],
        "comments": "change condition check for type fix",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 573,
        "label": "yes",
        "change": [
            "class TFPreTrainedModel(tf.keras.Model, TFModelUtilsMixin):",
            "# set eos token prob to zero if min_length is not reached",
            "if eos_token_id is not None and cur_len < min_length:",
            "# create eos_token_id boolean mask",
            "+                num_batch_hypotheses = batch_size * num_beams",
            "+",
            "is_token_logit_eos_token = tf.convert_to_tensor(",
            "[True if token is eos_token_id else False for token in range(vocab_size)], dtype=tf.bool",
            ")",
            "-                eos_token_indices_mask = tf.broadcast_to(is_token_logit_eos_token, [batch_size, vocab_size])",
            "+                eos_token_indices_mask = tf.broadcast_to(is_token_logit_eos_token, [num_batch_hypotheses, vocab_size])",
            "",
            "scores = set_tensor_by_indices_to_value(scores, eos_token_indices_mask, -float(\"inf\"))"
        ],
        "comments": "rename",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 574,
        "label": "no",
        "change": [
            "class Graph(kerastuner.HyperModel, serializable.Serializable):",
            "",
            "def build(self, hp):",
            "\"\"\"Build the HyperModel into a Keras Model.\"\"\"",
            "-        tf.keras.backend.clear_session()",
            "self._register_hps(hp)",
            "self.compile()",
            "real_nodes = {}"
        ],
        "comments": "remove API call for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 575,
        "label": "no",
        "change": [
            "class TensorflowONNXTensorRTInferenceLearner(",
            "else None",
            ")",
            "out_arrays = self._predict_array(cuda_input_arrays, input_shapes)",
            "-        return tuple(tf.convert_to_tensor(array) for array in out_arrays)",
            "+        return tuple(tf.convert_to_tensor(array[0]) for array in out_arrays)",
            "",
            "",
            "class NumpyONNXTensorRTInferenceLearner("
        ],
        "comments": "change param for shape fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 576,
        "label": "yes",
        "change": [
            "class AdditiveAttention(BaseDenseAttention):",
            "shape `[batch_size, Tv, dim]` and `key` tensor of shape",
            "`[batch_size, Tv, dim]`. The calculation follows the steps:",
            "",
            "-  1. Reshape `query` and `value` into shapes `[batch_size, Tq, 1, dim]`",
            "+  1. Reshape `query` and `key` into shapes `[batch_size, Tq, 1, dim]`",
            "and `[batch_size, 1, Tv, dim]` respectively.",
            "2. Calculate scores with shape `[batch_size, Tq, Tv]` as a non-linear",
            "-     sum: `scores = tf.reduce_sum(tf.tanh(query + value), axis=-1)`",
            "+     sum: `scores = tf.reduce_sum(tf.tanh(query + key), axis=-1)`",
            "3. Use scores to calculate a distribution with shape",
            "`[batch_size, Tq, Tv]`: `distribution = tf.nn.softmax(scores)`.",
            "4. Use `distribution` to create a linear combination of `value` with"
        ],
        "comments": "doc update",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 577,
        "label": "no",
        "change": [
            "def main(args):",
            "update_gradient_vars.append(var)",
            "else:",
            "restore_vars = tf.all_variables()",
            "+            update_gradient_vars = tf.all_variables()",
            "",
            "# Build a Graph that trains the model with one batch of examples and updates the model parameters",
            "train_op = facenet.train(total_loss, global_step, args.optimizer,"
        ],
        "comments": "not clear",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 578,
        "label": "no",
        "change": [
            "class GroupViTVisionTransformer(nn.Module):",
            "",
            "self.embeddings = GroupViTVisionEmbeddings(config)",
            "self.encoder = GroupViTVisionEncoder(config)",
            "-        self.layernorm = nn.LayerNorm(embed_dim)",
            "+        self.layernorm = nn.LayerNorm(embed_dim, eps=config.layer_norm_eps)",
            "",
            "@add_start_docstrings_to_model_forward(GROUPVIT_VISION_INPUTS_DOCSTRING)",
            "@replace_return_docstrings(output_type=BaseModelOutputWithPooling, config_class=GroupViTVisionConfig)"
        ],
        "comments": "add param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 579,
        "label": "no",
        "change": [
            "def configuration():",
            "",
            "",
            "class TestImageClassifierTrainer:",
            "-",
            "def test_fit(self, model, dataloader, criterion, optimizer, scheduler, configuration):",
            "-        trainer = ImageClassifierTrainer(",
            "-            model, dataloader, dataloader, criterion, optimizer, scheduler, configuration,",
            "-        )",
            "+        trainer = ImageClassifierTrainer(model, dataloader, dataloader, criterion, optimizer, scheduler, configuration)",
            "trainer.fit()",
            "",
            "def test_exception(self, model, dataloader, criterion, optimizer, scheduler, configuration):",
            "with pytest.raises(ValueError):",
            "ImageClassifierTrainer(",
            "-                model, dataloader, dataloader, criterion, optimizer, scheduler, configuration,",
            "-                callbacks={'frodo': None},",
            "+                model, dataloader, dataloader, criterion, optimizer, scheduler, configuration, callbacks={'frodo': None}",
            ")"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 580,
        "label": "no",
        "change": [
            "def train_hypernetwork(hypernetwork_name, learn_rate, batch_size, gradient_step,",
            "shared.state.textinfo = f\"\"\"",
            "<p>",
            "Loss: {loss_step:.7f}<br/>",
            "-Step: {hypernetwork.step}<br/>",
            "+Step: {steps_done}<br/>",
            "Last prompt: {html.escape(batch.cond_text[0])}<br/>",
            "Last saved hypernetwork: {html.escape(last_saved_file)}<br/>",
            "Last saved image: {html.escape(last_saved_image)}<br/>"
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 585,
        "label": "no",
        "change": [
            "class TestTrainSampleHook(tf.test.TestCase):",
            "pred_dict = {}",
            "pred_dict[\"predicted_tokens\"] = tf.constant([[\"Hello\", \"World\", \"w\"]])",
            "pred_dict[\"labels.target_tokens\"] = tf.constant([[\"Hello\", \"World\", \"w\"]])",
            "-    pred_dict[\"labels.target_len\"] = tf.constant([2]),",
            "+    pred_dict[\"labels.target_len\"] = tf.constant(2),",
            "graph_utils.add_dict_to_collection(pred_dict, \"predictions\")",
            "",
            "def tearDown(self):"
        ],
        "comments": "change param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 586,
        "label": "no",
        "change": [
            "def xlogy(",
            "return torch.xlogy(x, y, out=out)",
            "",
            "",
            "-def real(",
            "-    x: Union[torch.Tensor], /, *, out: Optional[torch.Tensor] = None",
            "-) -> torch.Tensor:",
            "+def real(x: torch.Tensor, /, *, out: Optional[torch.Tensor] = None) -> torch.Tensor:",
            "return torch.real(x)"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 587,
        "label": "no",
        "change": [
            "class VonMises(TorchDistribution):",
            "\"\"\"",
            "shape = self._extended_shape(sample_shape)",
            "x = torch.empty(shape, dtype=self.loc.dtype, device=self.loc.device)",
            "-        done = torch.zeros(shape, dtype=self.loc.dtype, device=self.loc.device).byte()",
            "+        done = torch.zeros(shape, dtype=self.loc.dtype, device=self.loc.device).bool()",
            "while not done.all():",
            "u = torch.rand((3,) + shape, dtype=self.loc.dtype, device=self.loc.device)",
            "u1, u2, u3 = u.unbind()"
        ],
        "comments": "change API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 588,
        "label": "no",
        "change": [
            "class GridTest(TestCase):",
            "assert_equal(adj.to_dense().numpy(), expected_adj)",
            "",
            "def test_grid_with_connectivity_8(self):",
            "-        adj = grid(torch.Size([3, 2]), connectivity=8)",
            "+        adj = grid_3x3(torch.Size([3, 2]), connectivity=8)",
            "",
            "expected_adj = [",
            "[0, 1, 1, 2, 0, 0],"
        ],
        "comments": "change API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 591,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "self.last_state = tf.identity(last_state, 'last_state')",
            "",
            "# seqlen x (Bxrnnsize)",
            "-        output = tf.reshape(tf.concat(1, outputs), [-1, param.rnn_size])  # (Bxseqlen) x rnnsize",
            "+        output = tf.reshape(tf.concat_v2(outputs, 1), [-1, param.rnn_size])  # (Bxseqlen) x rnnsize",
            "logits = FullyConnected('fc', output, param.vocab_size, nl=tf.identity)",
            "self.prob = tf.nn.softmax(logits / param.softmax_temprature)"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 594,
        "label": "no",
        "change": [
            "def prefetch_input_data(",
            "for pattern in file_pattern.split(\",\"):",
            "data_files.extend(tf.gfile.Glob(pattern))",
            "if not data_files:",
            "-        tf.logging.fatal(\"Found no input files matching %s\", file_pattern)",
            "+        tl.logging.fatal(\"Found no input files matching %s\", file_pattern)",
            "else:",
            "-        tf.logging.info(\"Prefetching values from %d files matching %s\", len(data_files), file_pattern)",
            "+        tl.logging.info(\"Prefetching values from %d files matching %s\", len(data_files), file_pattern)",
            "",
            "if is_training:",
            "print(\"   is_training == True : RandomShuffleQueue\")"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 595,
        "label": "no",
        "change": [
            "def fit_line(points: Tensor, weights: Optional[Tensor] = None) -> ParametrizedLi",
            "A = A.transpose(-2, -1) @ A",
            "",
            "# NOTE: not optimal for 2d points, but for now works for other dimensions",
            "-    _, _, V = torch.linalg.svd(A)",
            "+    _, _, V = _torch_svd_cast(A)",
            "+    V = V.transpose(-2, -1)",
            "",
            "# the first left eigenvector is the direction on the fited line",
            "direction = V[..., 0, :]  # BxD"
        ],
        "comments": "change API call for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 596,
        "label": "no",
        "change": [
            "def ndim(x):",
            "'''Returns the number of axes in a tensor, as an integer.",
            "'''",
            "if is_sparse(x):",
            "-        return int(x.shape.get_shape()[0])",
            "+        return x._dims",
            "",
            "dims = x.get_shape()._dims",
            "if dims is not None:"
        ],
        "comments": "change API call for shape fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 599,
        "label": "no",
        "change": [
            "def convert_pandas_to_tf_tensor(",
            "# them. If the columns contain different types (for example, `float32`s",
            "# and `int32`s), then `tf.concat` raises an error.",
            "dtype: np.dtype = np.find_common_type(df.dtypes, [])",
            "+",
            "+            # if the columns are `ray.data.extensions.tensor_extension.TensorArray`,",
            "+            # the dtype will be `object`. In this case, we need to set the dtype to",
            "+            # none, and use the automatic type casting of `tf.convert_to_tensor`.",
            "+            if isinstance(dtype, object):",
            "+                dtype = None",
            "+",
            "except TypeError:",
            "# `find_common_type` fails if a series has `TensorDtype`. In this case,",
            "# don't cast any of the series and continue."
        ],
        "comments": "add condition check for null fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 600,
        "label": "no",
        "change": [
            "def initialize(model: torch.nn.Module, init: str):",
            "",
            "# reset some modules with default init",
            "for m in model.modules():",
            "-            if isinstance(m, (torch.nn.Embedding, torch.nn.LayerNorm)):",
            "+            if isinstance(m, (torch.nn.Embedding, torch.nn.LayerNorm, torch.nn.GroupNorm)):",
            "m.reset_parameters()",
            "if hasattr(m, \"espnet_initialization_fn\"):",
            "m.espnet_initialization_fn()"
        ],
        "comments": "add param for argument fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 601,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "input_list = tf.unstack(input_feature, axis=1)  # seqlen x (Bxrnnsize)",
            "",
            "# seqlen is 1 in inference. don't need loop_function",
            "-        outputs, last_state = tf.nn.rnn(cell, input_list, initial, scope='rnnlm')",
            "+        outputs, last_state = tf.contrib.rnn.static_rnn(cell, input_list, initial, scope='rnnlm')",
            "self.last_state = tf.identity(last_state, 'last_state')",
            "",
            "# seqlen x (Bxrnnsize)"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 605,
        "label": "no",
        "change": [
            "class NoamLR(LearningRateScheduler):",
            "else:",
            "self.last_epoch = batch_num_total",
            "for param_group, learning_rate in zip(self.optimizer.param_groups, self.get_values()):",
            "-            param_group['lr'] = learning_rate",
            "+            param_group[\"lr\"] = learning_rate",
            "",
            "def get_values(self):",
            "step = max(self.last_epoch, 1)",
            "-        scale = self.factor * (self.model_size ** (-0.5) *",
            "-                               min(step ** (-0.5), step * self.warmup_steps ** (-1.5)))",
            "+        scale = self.factor * (",
            "+            self.model_size ** (-0.5) * min(step ** (-0.5), step * self.warmup_steps ** (-1.5))",
            "+        )",
            "",
            "return [scale for _ in range(len(self.base_values))]"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 606,
        "label": "no",
        "change": [
            "def tests_worker_convenience_methods():",
            "\"\"\"",
            "",
            "me = sy.torch.hook.local_worker",
            "-    bob = VirtualWorker()",
            "-    alice = VirtualWorker()",
            "+    bob = VirtualWorker(sy.torch.hook)",
            "+    alice = VirtualWorker(sy.torch.hook)",
            "obj = torch.Tensor([100, 100])",
            "",
            "# Send data to alice"
        ],
        "comments": "add param for argument fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 609,
        "label": "no",
        "change": [
            "class DurationPredictor(torch.nn.Module):",
            "self.norm_2 = LayerNorm(filter_channels, dim=1)",
            "self.proj = torch.nn.Conv1d(filter_channels, 1, 1)",
            "",
            "-        if gin_channels != 0:",
            "-            self.cond = torch.nn.Conv1d(gin_channels, channels, 1)",
            "+        if global_channels > 0:",
            "+            self.cond = torch.nn.Conv1d(global_channels, channels, 1)",
            "",
            "def forward(self, x, x_mask, beat_lab, g=None):",
            "x = torch.detach(x)"
        ],
        "comments": "refactor",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 610,
        "label": "no",
        "change": [
            "def prod(",
            "elif x.dtype == torch.bfloat16:",
            "dtype = torch.float16",
            "",
            "+    dtype = ivy.as_native_dtype(dtype)",
            "+",
            "if axis is None:",
            "axis = x.dim() - 1",
            "elif type(axis) == tuple:"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 611,
        "label": "no",
        "change": [
            "class Attention(nn.Module):",
            "query, processed_inputs)",
            "# apply masking",
            "if mask is not None:",
            "-            attention.data.masked_fill_(torch.bitwise_not(mask), self._mask_value)",
            "+            attention.data.masked_fill_(~mask, self._mask_value)",
            "# apply windowing - only in eval mode",
            "if not self.training and self.windowing:",
            "attention = self.apply_windowing(attention, inputs)"
        ],
        "comments": "remove API call for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 613,
        "label": "yes",
        "change": [
            "class EarlyStopping(Callback):",
            "f\" {self.monitor} = {current} {self.order_dict[self.mode]} {self.divergence_threshold}.\"",
            "\" Signaling Trainer to stop.\"",
            ")",
            "-        elif self.monitor_op(current - self.min_delta, self.best_score):",
            "+        elif self.monitor_op(current - self.min_delta, self.best_score.to(trainer.lightning_module.device)):",
            "should_stop = False",
            "reason = self._improvement_message(current)",
            "self.best_score = current"
        ],
        "comments": "add API call for resource fix",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 614,
        "label": "no",
        "change": [
            "class LSTM(Model):",
            "last_layer = add_time_dimension(features, self.seq_lens)",
            "",
            "# Setup the LSTM cell",
            "-        lstm = rnn.BasicLSTMCell(cell_size, state_is_tuple=True)",
            "+        lstm = tf.nn.rnn_cell.LSTMCell(cell_size, state_is_tuple=True)",
            "self.state_init = [",
            "np.zeros(lstm.state_size.c, np.float32),",
            "np.zeros(lstm.state_size.h, np.float32)"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 615,
        "label": "yes",
        "change": [
            "class XGLMModel(XGLMPreTrainedModel):",
            "",
            "hidden_states = inputs_embeds + positions",
            "",
            "-        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)",
            "+        hidden_states = nn.functional.dropout(hidden_states, p=float(self.dropout), training=self.training)",
            "",
            "# decoder layers",
            "all_hidden_states = () if output_hidden_states else None"
        ],
        "comments": "add API call for type fix",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 616,
        "label": "no",
        "change": [
            "class VersatileDiffusionImageVariationPipelineIntegrationTests(unittest.TestCase",
            "image_slice = image[0, 253:256, 253:256, -1]",
            "",
            "assert image.shape == (1, 512, 512, 3)",
            "+        print(torch.from_numpy(image_slice.flatten()))",
            "expected_slice = np.array([0.0113, 0.2241, 0.4024, 0.0839, 0.0871, 0.2725, 0.2581, 0.0, 0.1096])",
            "assert np.abs(image_slice.flatten() - expected_slice).max() < 1e-2"
        ],
        "comments": "print",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 618,
        "label": "no",
        "change": [
            "class CategoricalAccuracy(Metric):",
            "correct.unsqueeze_(-1)",
            "",
            "if mask is not None:",
            "-            correct *= mask.view(-1, 1).float()",
            "+            correct *= mask.view(-1, 1)",
            "self.total_count += mask.sum()",
            "else:",
            "self.total_count += gold_labels.numel()"
        ],
        "comments": "test fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 619,
        "label": "no",
        "change": [
            "class Imagen(nn.Module):",
            "text_embeds, text_masks = t5_encode_text(texts, name = self.text_encoder_name, return_attn_mask = True)",
            "text_embeds, text_masks = map(lambda t: t.to(images.device), (text_embeds, text_masks))",
            "",
            "-        text_masks = default(text_masks, lambda: torch.any(text_embeds != 0., dim = -1))",
            "+        if not self.unconditional:",
            "+            text_masks = default(text_masks, lambda: torch.any(text_embeds != 0., dim = -1))",
            "",
            "assert not (self.condition_on_text and not exists(text_embeds)), 'text or text encodings must be passed into decoder if specified'",
            "assert not (not self.condition_on_text and exists(text_embeds)), 'decoder specified not to be conditioned on text, yet it is presented'"
        ],
        "comments": "add condition check for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 621,
        "label": "no",
        "change": [
            "def conditional(",
            "if f_scale_tril is not None:",
            "pack = torch.cat((pack, f_scale_tril_2D), dim=1)",
            "",
            "-        Lffinv_pack = pack.triangular_solve(Lff, upper=False)[0]",
            "+        Lffinv_pack = torch.linalg.solve_triangular(Lff, pack, upper=False)",
            "# unpack",
            "v_2D = Lffinv_pack[:, : f_loc_2D.size(1)]",
            "W = Lffinv_pack[:, f_loc_2D.size(1) : f_loc_2D.size(1) + M].t()"
        ],
        "comments": "change API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 622,
        "label": "no",
        "change": [
            "def test_hgt_loader_on_cora():",
            "out2 = hetero_model(hetero_batch.x_dict, hetero_batch.edge_index_dict,",
            "hetero_batch.edge_weight_dict)['paper'][:batch_size]",
            "assert torch.allclose(out1, out2, atol=1e-6)",
            "-",
            "-    try:",
            "-        shutil.rmtree(root)",
            "-    except PermissionError:",
            "-        pass"
        ],
        "comments": "remove try catch test",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 623,
        "label": "yes",
        "change": [
            "class Model(ModelDesc):",
            "wrong = prediction_incorrect(logits, label, 5, name='wrong-top5')",
            "add_moving_summary(tf.reduce_mean(wrong, name='train-error-top5'))",
            "",
            "-        wd_cost = tf.mul(1e-4, regularize_cost('.*/W', tf.nn.l2_loss), name='l2_regularize_loss')",
            "+        wd_cost = regularize_cost('.*/W', l2_regularizer(1e-4), name='l2_regularize_loss')",
            "add_moving_summary(loss, wd_cost)",
            "self.cost = tf.add_n([loss, wd_cost], name='cost')"
        ],
        "comments": "update API call for version fix",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 625,
        "label": "no",
        "change": [
            "class StochasticDurationPredictor(torch.nn.Module):",
            "z, logdet = flow(z, x_mask, g=x, inverse=inverse)",
            "logdet_tot = logdet_tot + logdet",
            "nll = (",
            "-                torch.sum(0.5 * (math.log(2 * math.pi) + (z**2)) * x_mask, [1, 2])",
            "+                torch.sum(0.5 * (math.log(2 * math.pi) + (z ** 2)) * x_mask, [1, 2])",
            "- logdet_tot",
            ")",
            "return nll + logq  # (B,)"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 626,
        "label": "no",
        "change": [
            "CHECKPOINT_URLS = {",
            "}",
            "",
            "",
            "+@datasets.utils.file_utils.add_start_docstrings(_DESCRIPTION, _KWARGS_DESCRIPTION)",
            "class BLEURT(datasets.Metric):",
            "def _info(self):"
        ],
        "comments": "annotation",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 627,
        "label": "no",
        "change": [
            "class Optimizer:",
            "g = [dev_grads[dev][var_idx][0] for dev in devices]",
            "",
            "if np.prod(grad_shape):  # nccl does not support zero-sized tensors",
            "-                            g = tf.contrib.nccl.all_sum(g)",
            "+                            g = nccl_ops.all_sum(g)",
            "",
            "for dev, gg in zip(devices, g):",
            "dev_grads[dev][var_idx] = (gg, dev_grads[dev][var_idx][1])"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 631,
        "label": "no",
        "change": [
            "from .modeling_utils import PoolerAnswerClass, PoolerEndLogits, PoolerStartLogit",
            "logger = logging.getLogger(__name__)",
            "",
            "XLNET_PRETRAINED_MODEL_ARCHIVE_MAP = {",
            "-    \"xlnet-base-cased\": \"https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin\",",
            "-    \"xlnet-large-cased\": \"https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-large-cased-pytorch_model.bin\",",
            "+    \"xlnet-base-cased\": \"https://cdn.huggingface.co/xlnet-base-cased-pytorch_model.bin\",",
            "+    \"xlnet-large-cased\": \"https://cdn.huggingface.co/xlnet-large-cased-pytorch_model.bin\",",
            "}"
        ],
        "comments": "doc",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 633,
        "label": "no",
        "change": [
            "class Decoder(torch.nn.Module, ScorerInterface):",
            "",
            "if self.labeldist is not None:",
            "if self.vlabeldist is None:",
            "-                self.vlabeldist = to_device(hs_pad, torch.from_numpy(self.labeldist))",
            "+                self.vlabeldist = to_device(hs_pad[0], torch.from_numpy(self.labeldist))",
            "loss_reg = -torch.sum(",
            "(F.log_softmax(y_all, dim=1) * self.vlabeldist).view(-1), dim=0",
            ") / len(ys_in)"
        ],
        "comments": "change param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 635,
        "label": "no",
        "change": [
            "class TransformerModel(nn.Module):",
            "def init_weights(self):",
            "initrange = 0.1",
            "nn.init.uniform_(self.encoder.weight, -initrange, initrange)",
            "-        nn.init.zeros_(self.decoder.weight)",
            "+        nn.init.zeros_(self.decoder.bias)",
            "nn.init.uniform_(self.decoder.weight, -initrange, initrange)",
            "",
            "def forward(self, src, has_mask=True):"
        ],
        "comments": "change param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 636,
        "label": "no",
        "change": [
            "def main():",
            "",
            "model.eval()",
            "all_results = []",
            "-        for input_ids, input_mask, segment_ids, label_ids, example_index in eval_dataloader:",
            "+        #for input_ids, input_mask, segment_ids, label_ids, example_index in eval_dataloader:",
            "+        for input_ids, input_mask, segment_ids, example_index in eval_dataloader:",
            "if len(all_results) % 1000 == 0:",
            "logger.info(\"Processing example: %d\" % (len(all_results)))"
        ],
        "comments": "no API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 637,
        "label": "no",
        "change": [
            "import syft",
            "def model():",
            "l_in, l_h, l_out = 32, 16, 2",
            "model = crypten.nn.Sequential(",
            "-        [crypten.nn.Linear(l_in, l_h), crypten.nn.ReLU(), crypten.nn.Linear(l_h, l_out)]",
            "+        crypten.nn.Linear(l_in, l_h), crypten.nn.ReLU(), crypten.nn.Linear(l_h, l_out)",
            ")",
            "return model"
        ],
        "comments": "change param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 639,
        "label": "no",
        "change": [
            "class LinearModel(object):",
            "return self.sess.run(self.cross_entropy_grads, feed_dict={self.x: xs, self.y_: ys})",
            "",
            "def net_initialization():",
            "-  return LinearModel([784,10])",
            "+  with tf.Graph().as_default():",
            "+    return LinearModel([784,10])",
            "",
            "# By default, when an environment variable is used by a remote function, the",
            "# initialization code will be rerun at the end of the remote task to ensure"
        ],
        "comments": "add API call for state fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 640,
        "label": "yes",
        "change": [
            "class EpochResultStore:",
            "# attach capture batch_size",
            "Result.attach_batch_size(self._batch_size, hook_result)",
            "",
            "-            hook_result.detach()",
            "+            hook_result = hook_result.detach()",
            "if self.trainer.move_metrics_to_cpu:",
            "-                hook_result.cpu()",
            "+                hook_result = hook_result.cpu()",
            "elif self.trainer._distrib_type == DistributedType.DP:",
            "-                hook_result.to(torch.device(\"cuda\", self.trainer.root_gpu))",
            "+                hook_result = hook_result.to(torch.device(\"cuda\", self.trainer.root_gpu))",
            "",
            "self._internals[fx_name].append(hook_result, info)"
        ],
        "comments": "refacotr",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 641,
        "label": "no",
        "change": [
            "class LinearRegression(d2l.Module):",
            "def __init__(self, lr):",
            "super().__init__()",
            "self.save_hyperparameters()",
            "-        self.net = tf.keras.layers.Dense(1)",
            "+        initializer = tf.initializers.RandomNormal(stddev=0.01)",
            "+        self.net = tf.keras.layers.Dense(1, kernel_initializer=initializer)",
            "",
            "def forward(self, X):",
            "\"\"\"The linear regression model."
        ],
        "comments": "add param for argument fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 642,
        "label": "no",
        "change": [
            "class TorchCategorical(TorchDistributionWrapper):",
            "\"\"\"Wrapper class for PyTorch Categorical distribution.\"\"\"",
            "",
            "@override(ActionDistribution)",
            "-    def __init__(self, inputs, model):",
            "-        super().__init__(inputs, model)",
            "-        self.dist = torch.distributions.categorical.Categorical(logits=inputs)",
            "+    def __init__(self, inputs, model=None, temperature=1.0):",
            "+        assert temperature > 0.0, \"Categorical `temperature` must be > 0.0!\"",
            "+        super().__init__(inputs / temperature, model)",
            "+        self.dist = torch.distributions.categorical.Categorical(",
            "+            logits=self.inputs)",
            "",
            "@override(ActionDistribution)",
            "def deterministic_sample(self):"
        ],
        "comments": "add param for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 643,
        "label": "no",
        "change": [
            "class TestPretrainedTransformerEmbedder(AllenNlpTestCase):",
            "def test_xlnet_token_type_ids(self):",
            "token_embedder = PretrainedTransformerEmbedder(\"xlnet-base-cased\")",
            "token_ids = torch.LongTensor([[1, 2, 3], [2, 3, 4]])",
            "-        mask = torch.ones_like(token_ids)",
            "+        mask = torch.ones_like(token_ids).bool()",
            "type_ids = torch.zeros_like(token_ids)",
            "type_ids[1, 1] = 1",
            "token_embedder(token_ids, mask, type_ids)"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 645,
        "label": "yes",
        "change": [
            "class Block(Layer):",
            "layer_counter[layer_type] += 1",
            "",
            "# layer_name = self.name + '-' + layer_name",
            "-            self.layers[n] = self.submodule(",
            "+            layer = self.submodule(",
            "name=layer_name, module=layer_spec, modules=tensorforce.core.layer_modules,",
            "input_spec=self._input_spec",
            ")",
            "-            self._input_spec = self.layers[n].output_spec()",
            "-",
            "+            self.layers.append(layer)",
            "+            self._input_spec = layer.output_spec()",
            "",
            "return self.layers[0].input_spec.copy()"
        ],
        "comments": "change param for resource fix",
        "Symptom": "low efficiency",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 648,
        "label": "no",
        "change": [
            "def model():",
            "",
            "if sd_vae_approx_model is None:",
            "sd_vae_approx_model = VAEApprox()",
            "-        sd_vae_approx_model.load_state_dict(torch.load(os.path.join(paths.models_path, \"VAE-approx\", \"model.pt\")))",
            "+        sd_vae_approx_model.load_state_dict(torch.load(os.path.join(paths.models_path, \"VAE-approx\", \"model.pt\"), map_location='cpu' if devices.device.type != 'cuda' else None))",
            "sd_vae_approx_model.eval()",
            "sd_vae_approx_model.to(devices.device, devices.dtype)"
        ],
        "comments": "add param for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 650,
        "label": "yes",
        "change": [
            "class Accuracy(Metric):",
            "preds: Predictions from model",
            "target: Ground truth values",
            "\"\"\"",
            "-        preds, target = self._input_format(preds, target)",
            "+        preds, target = _input_format_classification(preds, target, self.threshold)",
            "assert preds.shape == target.shape",
            "",
            "self.correct += torch.sum(preds == target)"
        ],
        "comments": "customized API",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 651,
        "label": "no",
        "change": [
            "def test_tacotron2_trainable_and_decodable(model_dict, loss_dict):",
            "assert att_ws.shape[0] == bs",
            "assert att_ws.shape[1] == max(olens)",
            "assert att_ws.shape[2] == max(ilens)",
            "-    if not torch_is_old:",
            "-        torch.set_grad_enabled(True)"
        ],
        "comments": "remove state fix check",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 653,
        "label": "no",
        "change": [
            "def create_random_tensors(shape, seeds, subseeds=None, subseed_strength=0.0, see",
            "",
            "# if we have multiple seeds, this means we are working with batch size>1; this then",
            "# enables the generation of additional tensors with noise that the sampler will use during its processing.",
            "-    # Using those pre-genrated tensors instead of siimple torch.randn allows a batch with seeds [100, 101] to",
            "+    # Using those pre-generated tensors instead of simple torch.randn allows a batch with seeds [100, 101] to",
            "# produce the same images as with two batches [100], [101].",
            "if p is not None and p.sampler is not None and len(seeds) > 1 and opts.enable_batch_seeds:",
            "sampler_noises = [[] for _ in range(p.sampler.number_of_needed_noises(p))]"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 654,
        "label": "no",
        "change": [
            "class FP16_DeepSpeedZeroOptimizer(object):",
            "\"\"\" Perform all reduce within model parallel group, if any.",
            "\"\"\"",
            "if self.model_parallel_group is None:",
            "-            torch.distributed.all_reduce(tensor=tensor, op=op)",
            "+            pass",
            "else:",
            "torch.distributed.all_reduce(tensor=tensor,",
            "op=op,"
        ],
        "comments": "remove API call for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 655,
        "label": "yes",
        "change": [
            "class {{cookiecutter.camelcase_modelname}}EncoderLayer(nn.Module):",
            "hidden_states = residual + hidden_states",
            "hidden_states = self.final_layer_norm(hidden_states)",
            "",
            "-        if torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any():",
            "+        if hidden_states.dtype == torch.float16 and (torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any()):",
            "clamp_value = torch.finfo(hidden_states.dtype).max - 1000",
            "hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)"
        ],
        "comments": "change condition check for state fix",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "addition",
        "Element": "api condition check"
    },
    {
        "number": 656,
        "label": "no",
        "change": [
            "class LabelSmoother:",
            "",
            "def __call__(self, model_output, labels):",
            "logits = model_output[\"logits\"] if isinstance(model_output, dict) else model_output[0]",
            "-        log_probs = -torch.nn.functional.log_softmax(logits, dim=-1)",
            "+        log_probs = -nn.functional.log_softmax(logits, dim=-1)",
            "if labels.dim() == log_probs.dim() - 1:",
            "labels = labels.unsqueeze(-1)"
        ],
        "comments": "change API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 657,
        "label": "no",
        "change": [
            "class NonMaximaSuppression2d(nn.Module):",
            "def forward(self, x: torch.Tensor) -> torch.Tensor:  # type: ignore",
            "assert len(x.shape) == 4, x.shape",
            "# find local maximum values",
            "-        x_max: torch.Tensor = self.max_pool2d(x)",
            "+        x_max: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]] = \\",
            "+            self.max_pool2d(x)",
            "",
            "# create mask for maximums in the original map",
            "x_mask: torch.Tensor = torch.where("
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 658,
        "label": "yes",
        "change": [
            "class TestAdjustLog(BaseTester):",
            "f = kornia.enhance.AdjustLog()",
            "self.assert_close(f(data), expected)",
            "",
            "-    @pytest.mark.jit",
            "-    def test_jit(self, device, dtype):",
            "+    def test_dynamo(self, device, dtype, torch_optimizer):",
            "B, C, H, W = 2, 3, 4, 4",
            "img = torch.ones(B, C, H, W, device=device, dtype=dtype)",
            "op = kornia.enhance.adjust_log",
            "-        op_jit = torch.jit.script(op)",
            "-        self.assert_close(op(img), op_jit(img))",
            "+        op_optimized = torch_optimizer(op)",
            "+        self.assert_close(op(img), op_optimized(img))",
            "",
            "@pytest.mark.grad",
            "def test_gradcheck(self, device, dtype):"
        ],
        "comments": "test fix",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 659,
        "label": "no",
        "change": [
            "class ImageFeatureEmbeddings(Embeddings):",
            "",
            "def __init__(self, feature_size: int, embedding_size: int, dropout: float = 0.0):",
            "image_embeddings = torch.nn.Linear(feature_size, embedding_size)",
            "-        location_embeddings = torch.nn.Linear(4, embedding_size)",
            "+        location_embeddings = torch.nn.Linear(4, embedding_size, bias=False)",
            "embeddings = torch.nn.ModuleDict(",
            "{\"image_embeddings\": image_embeddings, \"location_embeddings\": location_embeddings}",
            ")"
        ],
        "comments": "add param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 660,
        "label": "no",
        "change": [
            "class DecoderBlock(nn.Module):",
            "x, skip = x",
            "x = self.block(x)",
            "if skip is not None:",
            "-            x += skip",
            "+            x = x + skip",
            "return x"
        ],
        "comments": "format not clear deep",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 661,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            ".apply(fg)",
            ".BatchNorm('bn5').apply(activate)",
            "# 5",
            "-                      .tf.nn.dropout(0.5 if is_training else 1.0)",
            "+                      .Dropout(rate=0.5 if is_training else 0.0)",
            ".Conv2D('conv6', 512, 5, padding='VALID')",
            ".apply(fg).BatchNorm('bn6')",
            ".apply(nonlin)"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 662,
        "label": "no",
        "change": [
            "class LocationAttention(nn.Module):",
            "self.proj_enc = nn.Linear(encoder_dim, attn_dim)",
            "self.proj_dec = nn.Linear(decoder_dim, attn_dim, bias=False)",
            "self.proj_attn = nn.Linear(conv_dim, attn_dim, bias=False)",
            "-        self.conv = nn.Conv1d(attn_state_kernel_size, conv_dim,",
            "-                              2 * conv_kernel_size + 1,",
            "-                              padding=conv_kernel_size, bias=False)",
            "+        self.conv = nn.Conv1d(",
            "+            attn_state_kernel_size,",
            "+            conv_dim,",
            "+            2 * conv_kernel_size + 1,",
            "+            padding=conv_kernel_size,",
            "+            bias=False,",
            "+        )",
            "self.proj_out = nn.Sequential(nn.Tanh(), nn.Linear(attn_dim, 1))",
            "",
            "self.proj_enc_out = None  # cache"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 663,
        "label": "no",
        "change": [
            "def load_model(filepath, custom_optimizers=None, custom_objects=None, compressio",
            "\"\"\"",
            "def wrap_optimizer(cls):",
            "return lambda **kwargs: DistributedOptimizer(cls(**kwargs), compression=compression)",
            "-    return _impl.load_model(keras, wrap_optimizer, filepath, custom_optimizers, custom_objects)",
            "+    return _impl.load_model(keras, wrap_optimizer, _OPTIMIZER_MODULES, filepath, custom_optimizers, custom_objects)"
        ],
        "comments": "no API fount",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 664,
        "label": "no",
        "change": [
            "def pinv(",
            "",
            "",
            "@with_unsupported_dtypes({\"2.9.1 and below\": (\"float16\", \"bfloat16\")}, backend_version)",
            "-def qr(x: Union[tf.Tensor, tf.Variable], /, *, mode: str = \"reduced\") -> NamedTuple:",
            "+def qr(",
            "+    x: Union[tf.Tensor, tf.Variable],",
            "+    /,",
            "+    *,",
            "+    mode: str = \"reduced\",",
            "+    out: Optional[tf.Tensor] = None,",
            "+) -> NamedTuple:",
            "res = namedtuple(\"qr\", [\"Q\", \"R\"])",
            "if mode == \"reduced\":",
            "q, r = tf.linalg.qr(x, full_matrices=False)"
        ],
        "comments": "custom method",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 665,
        "label": "no",
        "change": [
            "class BLEU(Metric):",
            "return math.exp(1.0 - self._reference_lengths / self._prediction_lengths)",
            "",
            "def _get_valid_tokens_mask(self, tensor: torch.LongTensor) -> torch.ByteTensor:",
            "-        valid_tokens_mask = torch.ones(tensor.size(), dtype=torch.uint8)",
            "+        valid_tokens_mask = torch.ones(tensor.size(), dtype=torch.bool)",
            "for index in self._exclude_indices:",
            "valid_tokens_mask = valid_tokens_mask & (tensor != index)",
            "return valid_tokens_mask"
        ],
        "comments": "change param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 667,
        "label": "no",
        "change": [
            "MOCK_MODULES = [",
            "\"torch.nn\",",
            "\"torch.nn.parallel\",",
            "\"torch.utils.data\",",
            "+    \"torch.utils.data.distributed\"",
            "]",
            "for mod_name in MOCK_MODULES:",
            "sys.modules[mod_name] = mock.Mock()"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 668,
        "label": "no",
        "change": [
            "class ModelCatalogTest(unittest.TestCase):",
            "dist_cls, param_shape = ModelCatalog.get_action_dist(",
            "action_space, model_config)",
            "self.assertEqual(param_shape, (3, ))",
            "-        dist_input = tf1.placeholder(tf.float32, (None,) + param_shape)",
            "+        dist_input = tf1.placeholder(tf.float32, (None, ) + param_shape)",
            "model.model_config = model_config",
            "dist = dist_cls(dist_input, model=model)",
            "self.assertEqual(dist.sample().shape[1:], dist_input.shape[1:])"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 669,
        "label": "no",
        "change": [
            "if __name__ == \"__main__\":",
            "collate_fn=dataset.collate_fn,",
            ")",
            "",
            "-    optimizer = torch.optim.SGD(model.parameters(), lr=0.0000)",
            "+    optimizer = torch.optim.Adam(model.parameters())",
            "",
            "metrics = [",
            "\"grid_size\","
        ],
        "comments": "change optimizor",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 670,
        "label": "no",
        "change": [
            "class LARC(object):",
            "def __setstate__(self, state):",
            "self.optim.__setstate__(state)",
            "",
            "+    @property",
            "+    def state(self):",
            "+        return self.optim.state",
            "+",
            "def __repr__(self):",
            "return self.optim.__repr__()"
        ],
        "comments": "add method",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 671,
        "label": "no",
        "change": [
            "def searchsorted(",
            "v: Union[tf.Tensor, tf.Variable],",
            "side=\"left\",",
            "sorter=None,",
            "-    out: Optional[Union[tf.Tensor, tf.Variable]] = None",
            "+    out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "return tf.searchsorted(x1, v, side=side)"
        ],
        "comments": "def",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 672,
        "label": "no",
        "change": [
            "class MessagePassing(torch.nn.Module):",
            "the_size: List[Optional[int]] = [None, None]",
            "",
            "if isinstance(edge_index, Tensor):",
            "-            assert edge_index.dtype == torch.long",
            "-            assert edge_index.dim() == 2",
            "-            assert edge_index.size(0) == 2",
            "+            assert edge_index.dtype == torch.long, \\",
            "+                \"edge_index.dtype is not of torch.long\"",
            "+            assert edge_index.dim() == 2, \\",
            "+                \"edge_index.dim() is not equal to 2\"",
            "+            assert edge_index.size(0) == 2, \\",
            "+                \"edge_index.size(0) is not equal to 2\"",
            "if size is not None:",
            "the_size[0] = size[0]",
            "the_size[1] = size[1]"
        ],
        "comments": "asset check doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 673,
        "label": "no",
        "change": [
            "class TFBertSelfAttention(tf.keras.layers.Layer):",
            "",
            "# Mask heads if we want to",
            "if head_mask is not None:",
            "-            attention_scores = tf.multiply(attention_scores, head_mask)",
            "+            attention_probs = tf.multiply(attention_probs, head_mask)",
            "",
            "attention_output = tf.einsum(\"acbe,aecd->abcd\", attention_probs, value_layer)",
            "outputs = (attention_output, attention_probs) if output_attentions else (attention_output,)"
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 674,
        "label": "yes",
        "change": [
            "class DecoderLayer(nn.Module):",
            "if self.normalize_before:",
            "x = self.norm2(x)",
            "if self.concate_after:",
            "-            x_concat = torch.cat(x, self.src_attn(x, memory, memory, memory_mask))",
            "+            x_concat = torch.cat((x, self.src_attn(x, memory, memory, memory_mask)), dim=-1)",
            "x = residual + self.concate_linear2(x_concat)",
            "else:",
            "x = residual + self.dropout(self.src_attn(x, memory, memory, memory_mask))"
        ],
        "comments": "add param for shape fix",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 675,
        "label": "no",
        "change": [
            "class FrequencyDomainDPCL(FrequencyDomainLoss):",
            ")",
            "",
            "V2 = torch.matmul(torch.transpose(inf, 2, 1), inf).pow(2).sum(dim=(1, 2))",
            "-        Y2 = torch.matmul(torch.transpose(re, 2, 1).float(), re.float()).pow(2).sum(dim=(1, 2))",
            "+        Y2 = (",
            "+            torch.matmul(torch.transpose(re, 2, 1).float(), re.float())",
            "+            .pow(2)",
            "+            .sum(dim=(1, 2))",
            "+        )",
            "VY = torch.matmul(torch.transpose(inf, 2, 1), re.float()).pow(2).sum(dim=(1, 2))",
            "",
            "return V2 + Y2 - 2 * VY"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 676,
        "label": "no",
        "change": [
            "class RoBERTaEncoder(Encoder):",
            "@property",
            "def output_shape(self) -> torch.Size:",
            "if self.reduce_output is None:",
            "-            return torch.Size([self.max_sequence_length, self.transformer.module.config.hidden_size])",
            "+            return torch.Size([self.max_sequence_length - 2, self.transformer.module.config.hidden_size])",
            "return torch.Size([self.transformer.module.config.hidden_size])",
            "",
            "@property"
        ],
        "comments": "change param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 677,
        "label": "no",
        "change": [
            "def clip(",
            "*,",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "-    assert torch.all(torch.less(x_min, x_max)), \"Min value must be less than max.\"",
            "+    assert torch.all(",
            "+        torch.less(torch.tensor(x_min), x_max)",
            "+    ), \"Min value must be less than max.\"",
            "if hasattr(x_min, \"dtype\"):",
            "promoted_type = torch.promote_types(x_min.dtype, x_max.dtype)",
            "promoted_type = torch.promote_types(promoted_type, x.dtype)"
        ],
        "comments": "change API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 678,
        "label": "no",
        "change": [
            "class TFTokenClassificationLoss:",
            ")",
            "# make sure only labels that are not equal to -100",
            "# are taken into account as loss",
            "-        if tf.math.reduce_any(labels == -1).numpy() is True:",
            "+        if tf.math.reduce_any(labels == -1):",
            "warnings.warn(\"Using `-1` to mask the loss for the token is deprecated. Please use `-100` instead.\")",
            "active_loss = tf.reshape(labels, (-1,)) != -1",
            "else:"
        ],
        "comments": "remove API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 680,
        "label": "no",
        "change": [
            "def get_perplexity(loss):",
            "def train(args, epoch, batch_offset, trainer, dataset, max_positions, num_gpus):",
            "\"\"\"Train the model for one epoch.\"\"\"",
            "",
            "-    torch.manual_seed(args.seed + epoch)",
            "-    trainer.set_seed(args.seed + epoch)",
            "+    seed = args.seed + epoch",
            "+    torch.manual_seed(seed)",
            "+    trainer.set_seed(seed)",
            "",
            "itr = dataset.dataloader(",
            "args.train_subset, num_workers=args.workers, max_tokens=args.max_tokens,",
            "-        seed=args.seed, epoch=epoch, max_positions=max_positions,",
            "+        seed=seed, epoch=epoch, max_positions=max_positions,",
            "sample_without_replacement=args.sample_without_replacement,",
            "skip_invalid_size_inputs_valid_test=args.skip_invalid_size_inputs_valid_test,",
            "sort_by_source_size=(epoch <= args.curriculum))"
        ],
        "comments": "version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 681,
        "label": "yes",
        "change": [
            "class LayoutLMv3Model(LayoutLMv3PreTrainedModel):",
            "position_ids = position_ids.expand_as(input_ids)",
            "final_position_ids = position_ids",
            "",
            "-        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(attention_mask, None, device)",
            "+        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(",
            "+            attention_mask, None, device, dtype=embedding_output.dtype",
            "+        )",
            "",
            "# Prepare head mask if needed",
            "# 1.0 in head_mask indicate we keep the head"
        ],
        "comments": "add param for type fix",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 682,
        "label": "no",
        "change": [
            "def cumsum(x: torch.Tensor, axis: int = 0, out: Optional[torch.Tensor] = None):",
            "",
            "",
            "def cumprod(",
            "-    x: torch.Tensor, axis: int = 0, exclusive: Optional[bool] = False, out: Optional[torch.Tensor] = None",
            "+    x: torch.Tensor,",
            "+    axis: int = 0,",
            "+    exclusive: Optional[bool] = False,",
            "+    out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "if exclusive:",
            "x = torch.transpose(x, axis, -1)"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 683,
        "label": "yes",
        "change": [
            "class StableDiffusionKDiffusionPipeline(DiffusionPipeline):",
            "return_tensors=\"pt\",",
            ")",
            "text_input_ids = text_inputs.input_ids",
            "-        untruncated_ids = self.tokenizer(prompt, padding=\"max_length\", return_tensors=\"pt\").input_ids",
            "+        untruncated_ids = self.tokenizer(prompt, padding=\"longest\", return_tensors=\"pt\").input_ids",
            "",
            "-        if not torch.equal(text_input_ids, untruncated_ids):",
            "+        if untruncated_ids.shape[-1] >= text_input_ids.shape[-1] and not torch.equal(text_input_ids, untruncated_ids):",
            "removed_text = self.tokenizer.batch_decode(untruncated_ids[:, self.tokenizer.model_max_length - 1 : -1])",
            "logger.warning(",
            "\"The following part of your input was truncated because CLIP can only handle sequences up to\""
        ],
        "comments": "change condition check for shape fix",
        "Symptom": "return warning",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 684,
        "label": "no",
        "change": [
            "class MaskEstimator(torch.nn.Module):",
            "# xs: (B, C, T, D) -> mask:(B, C, T, F)",
            "mask = linear(xs)",
            "",
            "+            mask = torch.sigmoid(mask)",
            "# Zero padding",
            "mask.masked_fill(make_pad_mask(ilens, mask, length_dim=2), 0)",
            "",
            "-            mask = torch.sigmoid(mask)",
            "-",
            "# (B, C, T, F) -> (B, F, C, T)",
            "mask = mask.permute(0, 3, 1, 2)"
        ],
        "comments": "format fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 685,
        "label": "yes",
        "change": [
            "def to_tf_values(result, path):",
            "",
            "class TFLogger(Logger):",
            "def _init(self):",
            "-        logger.info(",
            "-            \"Initializing TFLogger instead of TF2Logger. We recommend \"",
            "-            \"migrating to TF2.0. This class will be removed in the future.\")",
            "-        self._file_writer = tf.summary.FileWriter(self.logdir)",
            "+        logger.info(\"Initializing TFLogger instead of TF2Logger.\")",
            "+        self._file_writer = tf.compat.v1.summary.FileWriter(self.logdir)",
            "",
            "def on_result(self, result):",
            "tmp = result.copy()"
        ],
        "comments": "change API call for refactor fix",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 686,
        "label": "yes",
        "change": [
            "def test_hook():",
            "tf_summary.scalar(\"c1\", c1)",
            "summary_op = tf_summary.merge_all()",
            "",
            "-        hook = wandb_tensorflow.WandbHook(summary_op, history=history, steps_per_log=1)",
            "+        hook = wandb.tensorflow.WandbHook(summary_op, history=history, steps_per_log=1)",
            "with MonitoredTrainingSession(hooks=[hook]) as sess:",
            "summary, acc = sess.run([summary_op, c1])",
            "history.add({})  # Flush the previous row.",
            "",
            "-    assert wandb_tensorflow.tf_summary_to_dict(summary) == {\"c1\": 42.0}",
            "+    assert wandb.tensorboard.tf_summary_to_dict(summary) == {\"c1\": 42.0}",
            "assert summaries_logged[0][\"c1\"] == 42.0"
        ],
        "comments": "format",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 688,
        "label": "no",
        "change": [
            "class QNetwork(object):",
            "distributions and \\sigma are trainable variables which are expected to",
            "vanish along the training procedure",
            "\"\"\"",
            "+        import tensorflow.contrib.layers as layers",
            "+",
            "in_size = int(action_in.shape[1])",
            "",
            "epsilon_in = tf.random_normal(shape=[in_size])"
        ],
        "comments": "refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 690,
        "label": "no",
        "change": [
            "class _Subsample(Distribution):",
            "self.subsample_size = subsample_size",
            "self.use_cuda = torch.Tensor.is_cuda if use_cuda is None else use_cuda",
            "",
            "-    def sample(self, sample_shape=None):",
            "+    def sample(self, sample_shape=torch.Size()):",
            "\"\"\"",
            ":returns: a random subsample of `range(size)`",
            ":rtype: torch.autograd.Variable of torch.LongTensor",
            "\"\"\"",
            "+        if sample_shape:",
            "+            raise NotImplementedError",
            "subsample_size = self.subsample_size",
            "if subsample_size is None or subsample_size > self.size:",
            "subsample_size = self.size"
        ],
        "comments": "no API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 691,
        "label": "no",
        "change": [
            "def vander(",
            "increasing: Optional[bool] = False,",
            "out: Optional[torch.tensor] = None,",
            ") -> torch.tensor:",
            "-    return torch.vander(",
            "-        x, N=N, increasing=increasing",
            "-    )",
            "+    return torch.vander(x, N=N, increasing=increasing)",
            "",
            "",
            "vander.support_native_out = False"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 692,
        "label": "no",
        "change": [
            "def imag(",
            "input: Union[tf.Tensor, tf.Variable],",
            "/,",
            "*,",
            "-    out: Optional[Union[tf.Tensor,tf.Variable]] = None,",
            "+    out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "return tf.math.imag(input, name=None)"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 693,
        "label": "no",
        "change": [
            "class Ensemble(nn.ModuleList):",
            "",
            "",
            "def attempt_load(weights, device=None, inplace=True, fuse=True):",
            "+    # Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a",
            "from models.yolo import Detect, Model",
            "",
            "-    # Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a",
            "model = Ensemble()",
            "for w in weights if isinstance(weights, list) else [weights]:",
            "-        ckpt = torch.load(attempt_download(w), map_location=device)",
            "-        ckpt = (ckpt.get('ema') or ckpt['model']).float()  # FP32 model",
            "+        ckpt = torch.load(attempt_download(w), map_location='cpu')  # load",
            "+        ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model",
            "model.append(ckpt.fuse().eval() if fuse else ckpt.eval())  # fused or un-fused model in eval mode",
            "",
            "# Compatibility updates"
        ],
        "comments": "change param for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 694,
        "label": "no",
        "change": [
            "class Conv2dSubsampling6(torch.nn.Module):",
            "torch.nn.ReLU(),",
            ")",
            "self.out = torch.nn.Sequential(",
            "-            torch.nn.Linear(odim * (((idim - 1) // 2 - 1) // 3), odim),",
            "+            torch.nn.Linear(odim * (((idim - 1) // 2 - 2) // 3), odim),",
            "PositionalEncoding(odim, dropout_rate),",
            ")"
        ],
        "comments": "change param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 698,
        "label": "no",
        "change": [
            "class NestedMapDataTest(TestCase):",
            "tr = poutine.trace(self.model)(self.means, self.stds)",
            "for name in tr.keys():",
            "if tr[name][\"type\"] == \"sample\":",
            "-                print(name, tr[name][\"scale\"])",
            "self.assertTrue(tr[name][\"scale\"] == 4.0 * 2.0)"
        ],
        "comments": "remove print",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 699,
        "label": "no",
        "change": [
            "def model(x, is_train, reuse):",
            ")",
            "n = tl.layers.FlattenLayer(n, name='flatten2')",
            "n = tl.layers.DenseLayer(n, n_units=1024, act=tf.nn.relu, name='out1')",
            "-        n = tl.layers.DenseLayer(n, n_units=10, act=tf.identity, name='out2')",
            "+        n = tl.layers.DenseLayer(n, n_units=10, name='out2')",
            "return n, s"
        ],
        "comments": "remove constraint not clear reason",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 700,
        "label": "no",
        "change": [
            "def ids_tensor(shape, vocab_size, rng=None, name=None, dtype=tf.int32):",
            "for _ in range(total_dims):",
            "values.append(rng.randint(0, vocab_size - 1))",
            "",
            "-    return tf.constant(values, shape=shape, dtype=dtype)",
            "+    output = tf.constant(values,",
            "+                         shape=shape,",
            "+                         dtype=dtype if dtype is not None else tf.int32)",
            "+",
            "+    return output",
            "",
            "",
            "class TFModelUtilsTest(unittest.TestCase):"
        ],
        "comments": "test fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 702,
        "label": "no",
        "change": [
            "class LibrispeechASR(datasets.GeneratorBasedBuilder):",
            "\"speaker_id\": speaker_id,",
            "\"chapter_id\": chapter_id,",
            "\"file\": os.path.join(transcript_dir_path, audio_file),",
            "+                        \"audio\": os.path.join(transcript_dir_path, audio_file),",
            "\"text\": transcript,",
            "}",
            "key += 1"
        ],
        "comments": "add attribute parama",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 705,
        "label": "no",
        "change": [
            "def broadcast_arrays(*arrays: torch.Tensor) -> List[torch.Tensor]:",
            "{\"1.11.0 and below\": (\"uint8\", \"uint16\", \"uint32\", \"uint64\")}, backend_version",
            ")",
            "def broadcast_to(",
            "-    x: torch.Tensor, shape: Union[ivy.NativeShape, Sequence[int]]",
            "+    x: torch.Tensor,",
            "+    /,",
            "+    shape: Union[ivy.NativeShape, Sequence[int]],",
            "+    *,",
            "+    out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "if x.ndim > len(shape):",
            "return torch.broadcast_to(x.reshape(-1), shape)"
        ],
        "comments": "def",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 707,
        "label": "no",
        "change": [
            "class TFLiteBackendInferenceLearner(TensorflowBaseInferenceLearner):",
            "self.interpreter.set_tensor(i, input_tensor)",
            "self.interpreter.invoke()",
            "return tuple(",
            "-            self.interpreter.get_tensor(output_detail[\"index\"])",
            "+            tf.convert_to_tensor(",
            "+                self.interpreter.get_tensor(output_detail[\"index\"])",
            "+            )",
            "for output_detail in output_details",
            ")"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 710,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            ".Conv2D('conv3.1', filters=128, padding='VALID') \\",
            ".Conv2D('conv3.2', filters=128, padding='VALID') \\",
            ".FullyConnected('fc0', 1024 + 512, activation=tf.nn.relu) \\",
            "-                .tf.nn.dropout(keep_prob) \\",
            "+                .Dropout(rate=drop_rate) \\",
            ".FullyConnected('fc1', 512, activation=tf.nn.relu) \\",
            ".FullyConnected('linear', out_dim=self.cifar_classnum)()"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 713,
        "label": "no",
        "change": [
            "class ConvolutionalSpatialGatingUnit(torch.nn.Module):",
            ")",
            "",
            "self.norm = norm_class(channels, **norm_args)",
            "-        self.activation = activation",
            "+        self.activation = torch.nn.Identity()",
            "",
            "self.dropout = torch.nn.Dropout(dropout_rate)"
        ],
        "comments": "change value",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 716,
        "label": "no",
        "change": [
            "def test_obj_not_found(workers):",
            "",
            "def test_get_not_permitted(workers):",
            "bob = workers[\"bob\"]",
            "-    with patch.object(torch.Tensor, \"allowed_to_get\") as mock_allowed_to_get:",
            "+    x = torch.tensor([1, 2, 3, 4, 5]).send(bob)",
            "+    with patch.object(torch.Tensor, \"allow\") as mock_allowed_to_get:",
            "mock_allowed_to_get.return_value = False",
            "-        x = torch.tensor([1, 2, 3, 4, 5]).send(bob)",
            "with pytest.raises(GetNotPermittedError):",
            "x.get()",
            "mock_allowed_to_get.assert_called_once()"
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 720,
        "label": "no",
        "change": [
            "class CustomConverter(object):",
            "xs_pad = pad_list([torch.from_numpy(x).float() for x in xs], 0).to(device, dtype=self.dtype)",
            "",
            "ilens = torch.from_numpy(ilens).to(device)",
            "-        # NOTE: this is for multi-task learning (e.g., speech translation)",
            "-        ys_pad = pad_list([torch.from_numpy(np.array(y[0]) if isinstance(y, tuple) else y).long()",
            "+        # NOTE: this is for multi-output (e.g., speech translation)",
            "+        ys_pad = pad_list([torch.from_numpy(np.array(y[0][:]) if isinstance(y, tuple) else y).long()",
            "for y in ys], self.ignore_id).to(device)",
            "",
            "return xs_pad, ilens, ys_pad"
        ],
        "comments": "change param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 721,
        "label": "no",
        "change": [
            "class BBoxHead(nn.Module):",
            "if isinstance(scale_factor, float):",
            "bboxes /= scale_factor",
            "else:",
            "-                scale_factor = torch.from_numpy(scale_factor).to(bboxes.device)",
            "+                scale_factor = bboxes.new_tensor(scale_factor)",
            "bboxes = (bboxes.view(bboxes.size(0), -1, 4) /",
            "scale_factor).view(bboxes.size()[0], -1)"
        ],
        "comments": "use custom API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 722,
        "label": "no",
        "change": [
            "class TestAffine2d:",
            "",
            "def test_affine_scale(self, device):",
            "torch.manual_seed(0)",
            "-        scale_factor = torch.rand(1, device=device) * 2.0",
            "+        _scale_factor = torch.rand(1, device=device) * 2.0",
            "+        scale_factor = torch.stack([_scale_factor, _scale_factor], dim=1)",
            "input = torch.rand(1, 2, 3, 4, device=device)",
            "",
            "transform = kornia.Affine(scale_factor=scale_factor).to(device)"
        ],
        "comments": "test",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 725,
        "label": "no",
        "change": [
            "def run_benchmark(state):",
            "",
            "",
            "def on_state_reset():",
            "-    tf.keras.backend.set_value(model.optimizer.lr, lr * hvd.size())",
            "+    opt.lr.assign(lr * hvd.size())",
            "",
            "",
            "state = hvd.elastic.TensorFlowKerasState(model, opt, img_secs=[], iter=0, batch=0, warm=False)"
        ],
        "comments": "change API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 726,
        "label": "no",
        "change": [
            "def do_test_log_likelihood(run,",
            "prev_reward_batch=np.array([prev_r]))",
            "check(np.exp(logp), expected_prob, atol=0.2)",
            "",
            "-        if eager_ctx:",
            "-            eager_ctx.__exit__(None, None, None)",
            "-",
            "",
            "class TestComputeLogLikelihood(unittest.TestCase):",
            "def test_dqn(self):"
        ],
        "comments": "remove check",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 727,
        "label": "no",
        "change": [
            "def _interpret_blender_cameras(",
            "",
            "Rpt3, Tpt3 = mtx[:, :3].split([3, 1], dim=0)",
            "",
            "-        focal_length_pt3 = torch.FloatTensor([[-focal, focal]])",
            "-        principal_point_pt3 = torch.FloatTensor([[W / 2, H / 2]])",
            "+        focal_length_pt3 = torch.FloatTensor([[focal, focal]])",
            "+        principal_point_pt3 = torch.FloatTensor([[0.0, 0.0]])",
            "",
            "cameras = PerspectiveCameras(",
            "focal_length=focal_length_pt3,"
        ],
        "comments": "change param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 728,
        "label": "no",
        "change": [
            "def vector_to_skew_symmetric_matrix(",
            "a2s = vector_expanded[..., 1:2, :]",
            "a3s = vector_expanded[..., 2:3, :]",
            "# BS x 1 x 1",
            "-    zs = torch.zeros(batch_shape + [1, 1], device=vector.device)",
            "+    zs = torch.zeros(batch_shape + [1, 1], device=vector.device, dtype=vector.dtype)",
            "# BS x 1 x 3",
            "row1 = torch.cat((zs, -a3s, a2s), -1)",
            "row2 = torch.cat((a3s, zs, -a1s), -1)"
        ],
        "comments": "add param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 730,
        "label": "no",
        "change": [
            "from pyro.ops.einsum import contract",
            "def _finfo(tensor):",
            "# This can be replaced with torch.finfo once it is available",
            "# https://github.com/pytorch/pytorch/issues/10742",
            "-    return np.finfo(torch.empty(torch.Size(), dtype=tensor.dtype).numpy().dtype)",
            "+    return np.finfo(torch.empty(torch.Size(), dtype=tensor.dtype, device=\"cpu\").numpy().dtype)",
            "",
            "",
            "def _check_batch_dims_are_sensible(output_dims, nonoutput_ordinal):"
        ],
        "comments": "add param for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 731,
        "label": "no",
        "change": [
            "class InsertPostInitMethodToModuleSubClasses(object):",
            "cls.__init__ = cls._old_init",
            "",
            "# Replace .__init__() for all existing subclasses of torch.nn.Module",
            "-        for subclass in torch.nn.modules.module.Module.__subclasses__():",
            "+        for subclass in get_all_subclasses(torch.nn.modules.module.Module):",
            "_disable_class(subclass)",
            "",
            "# Replace .__init__() for future subclasses of torch.nn.Module"
        ],
        "comments": "custom API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 733,
        "label": "no",
        "change": [
            "try:",
            "with torch.cuda.device(x.device):",
            "return super().forward(x)",
            "",
            "+",
            "except ImportError:",
            "has_fused_layernorm = False",
            "",
            "",
            "def LayerNorm(normalized_shape, eps=1e-5, elementwise_affine=True, export=False):",
            "-    if torch.jit.is_scripting():",
            "+    if torch.jit.is_scripting() or torch.jit.is_tracing():",
            "export = True",
            "if not export and torch.cuda.is_available() and has_fused_layernorm:",
            "return FusedLayerNorm(normalized_shape, eps, elementwise_affine)"
        ],
        "comments": "add condition check for state fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 734,
        "label": "no",
        "change": [
            "def class_balanced_sigmoid_cross_entropy(logits, label, name='cross_entropy_loss",
            "cost = tf.nn.weighted_cross_entropy_with_logits(logits, y, pos_weight)",
            "cost = tf.reduce_mean(cost * (1 - beta), name=name)",
            "",
            "-    #logstable = tf.log(1 + tf.exp(-tf.abs(z)))",
            "-    # loss_pos = -beta * tf.reduce_mean(-y *",
            "-    #(logstable - tf.minimum(0.0, z)))",
            "-    # loss_neg = (1. - beta) * tf.reduce_mean((y - 1.) *",
            "-    #(logstable + tf.maximum(z, 0.0)))",
            "-    #cost = tf.sub(loss_pos, loss_neg, name=name)",
            "+    # logstable = tf.log(1 + tf.exp(-tf.abs(z)))",
            "+    # loss_pos = -beta * tf.reduce_mean(-y * (logstable - tf.minimum(0.0, z)))",
            "+    # loss_neg = (1. - beta) * tf.reduce_mean((y - 1.) * (logstable + tf.maximum(z, 0.0)))",
            "+    # cost = tf.sub(loss_pos, loss_neg, name=name)",
            "return cost"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 735,
        "label": "no",
        "change": [
            "class TRPOModel(PolicyGradientModel):",
            ":param batch:",
            ":return:",
            "\"\"\"",
            "+        super(TRPOModel, self).update(batch)",
            "+",
            "self.feed_dict = {state: batch['states'][name] for name, state in self.state.items()}",
            "self.feed_dict.update({action: batch['actions'][name] for name, action in self.action.items()})",
            "self.feed_dict[self.reward] = batch['rewards']"
        ],
        "comments": "add API call for state fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 740,
        "label": "no",
        "change": [
            "def spline_gcn(",
            "row = row.view(-1, 1).expand(row.size(0), output.size(1))",
            "output = zero.scatter_add_(0, row, output)",
            "",
            "-    # Weighten root node features by multiplying with the meaned weights at the",
            "-    # origin.",
            "-    index = torch.arange(0, kernel_size[-1]).long()",
            "+    # Weighten root node features by multiplying with the meaned weights from",
            "+    # the origin.",
            "+    index = torch.arange(0, reduce(lambda x, y: x * y, kernel_size[1:])).long()",
            "root_weight = weight[index].mean(0)",
            "output += torch.mm(features, root_weight)"
        ],
        "comments": "change param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 742,
        "label": "no",
        "change": [
            "def stats(policy, train_batch):",
            "\"cur_lr\": tf.cast(policy.cur_lr, tf.float64),",
            "\"policy_loss\": policy.loss.pi_loss,",
            "\"entropy\": policy.loss.entropy,",
            "-        \"var_gnorm\": tf.global_norm(policy.model.trainable_variables()),",
            "+        \"var_gnorm\": tf.linalg.global_norm(policy.model.trainable_variables()),",
            "\"vf_loss\": policy.loss.vf_loss,",
            "\"vf_explained_var\": explained_variance(",
            "tf.reshape(policy.loss.value_targets, [-1]),"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 743,
        "label": "no",
        "change": [
            "def test_tensorrt_torch(",
            "res_orig = tuple(model(*inputs_example))",
            "assert all(",
            "[",
            "-                    torch.allclose(res_tensor, res_orig_tensor, rtol=1e-01)",
            "+                    torch.allclose(",
            "+                        res_tensor.float(), res_orig_tensor, rtol=1e-01",
            "+                    )",
            "for (res_tensor, res_orig_tensor) in zip(res, res_orig)",
            "]",
            ")"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 744,
        "label": "no",
        "change": [
            "class Attention(nn.Module):",
            "# Apply the attention mask",
            "w = w + attention_mask",
            "",
            "-        w = nn.Softmax(dim=-1)(w)",
            "+        w = nn.functional.softmax(w, dim=-1)",
            "w = self.attn_dropout(w)",
            "",
            "# Mask heads if we want to"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 745,
        "label": "no",
        "change": [
            "\"from skimage.transform import AffineTransform\\n\",",
            "\"from six import BytesIO\\n\",",
            "\"\\n\",",
            "-        \"import tensorflow.compat.v2 as tf\\n\",",
            "+        \"import tensorflow.compat.v1 as tf\\n\",",
            "\"tf.disable_v2_behavior()\\n\",",
            "\"\\n\",",
            "\"import tensorflow_hub as hub\\n\","
        ],
        "comments": "refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 750,
        "label": "no",
        "change": [
            "class ONNXTensorRTCompiler(TensorRTCompiler):",
            "assert os.path.isfile(onnx_model_path)",
            "except Exception:",
            "# Use original model",
            "+                self.logger.warning(",
            "+                    \"Unable to simplify model with ONNX Simplifier. \"",
            "+                    \"Original ONNX model will be used to build \"",
            "+                    \"TensorRT engine\"",
            "+                )",
            "onnx_model_path = str(model)",
            "self.simplify_model = False",
            "else:"
        ],
        "comments": "log update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 752,
        "label": "yes",
        "change": [
            "class DistributedGroupSampler(Sampler):",
            "if size > 0:",
            "indice = np.where(self.flag == i)[0]",
            "assert len(indice) == size",
            "-                indice = indice[list(torch.randperm(int(size),",
            "-                                                    generator=g))].tolist()",
            "+                # add .numpy() to avoid bug when selecting indice in parrots.",
            "+                # TODO: check whether torch.randperm() can be replaced by",
            "+                # numpy.random.permutation().",
            "+                indice = indice[list(",
            "+                    torch.randperm(int(size), generator=g).numpy())].tolist()",
            "extra = int(",
            "math.ceil(",
            "size * 1.0 / self.samples_per_gpu / self.num_replicas)"
        ],
        "comments": "add API call for type fix",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 754,
        "label": "no",
        "change": [
            "def dot(x, y):",
            "",
            "If `x` is an N-D array and `y` is an M-D array (where M>=2), it is a sum",
            "product over the last axis of `x` and the second-to-last axis of `y`.",
            "-  >>> x = tf.keras.backend.random_uniform_variable(shape=(2, 3), low=0, high=1)",
            "+  >>> x = tf.keras.backend.random_uniform_variable(shape=(2, 3), low=.0, high=1.)",
            ">>> y = tf.keras.backend.ones((4, 3, 5))",
            ">>> xy = tf.keras.backend.dot(x, y)",
            ">>> tf.keras.backend.int_shape(xy)"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 757,
        "label": "no",
        "change": [
            "def round(x):",
            "return tf.round(x)",
            "",
            "",
            "+def sign(x):",
            "+    return tf.sign(x)",
            "+",
            "+",
            "def pow(x, a):",
            "return tf.pow(x, a)"
        ],
        "comments": "add method",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 758,
        "label": "no",
        "change": [
            "class Attention(torch.nn.Module, Registrable):",
            "vector: torch.Tensor,",
            "matrix: torch.Tensor,",
            "matrix_mask: torch.Tensor = None) -> torch.Tensor:",
            "-        similarities = self._forward_internal(vector, matrix, matrix_mask)",
            "+        similarities = self._forward_internal(vector, matrix)",
            "if self._normalize:",
            "return masked_softmax(similarities, matrix_mask)",
            "else:",
            "return similarities",
            "",
            "-    def _forward_internal(self, vector: torch.Tensor, matrix: torch.Tensor,",
            "-                          matrix_mask: torch.Tensor = None) -> torch.Tensor:",
            "+    def _forward_internal(self, vector: torch.Tensor, matrix: torch.Tensor) -> torch.Tensor:",
            "raise NotImplementedError",
            "",
            "@classmethod"
        ],
        "comments": "custom API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 759,
        "label": "no",
        "change": [
            "def test_pair_norm(scale_individually):",
            "assert out1.size() == (100, 16)",
            "",
            "out2 = norm(torch.cat([x, x], dim=0), torch.cat([batch, batch + 1], dim=0))",
            "-    assert torch.allclose(out1, out2[:100])",
            "-    assert torch.allclose(out1, out2[100:])",
            "+    assert torch.allclose(out1, out2[:100], atol=1e-6)",
            "+    assert torch.allclose(out1, out2[100:], atol=1e-6)"
        ],
        "comments": "add param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 761,
        "label": "no",
        "change": [
            "class Decoder(nn.Module):",
            "memories = torch.cat((memory, memories), dim=0)",
            "memories = self._update_memory(memories)",
            "if speaker_embeddings is not None:",
            "-                memories = torch.cat([memories, speaker_embeddings], dim=-1)",
            "+            memories = torch.cat([memories, speaker_embeddings], dim=-1)",
            "memories = self.prenet(memories)",
            "",
            "self._init_states(inputs, mask=mask)"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 763,
        "label": "no",
        "change": [
            "def attn(x, scope, n_state, *, past, params, block_offset=0, train=False):",
            "",
            "def merge_heads(x):",
            "# TODO: convert to mtf code",
            "-        # Reverse of split_heads",
            "+        # Reverse of split_heads : result shape [batch, sequence, features]",
            "return merge_states(tf.transpose(x, [0, 2, 1, 3]))",
            "",
            "# the old mask_attn_weights applied directly to the QK; this returns a bias that the attention code from mtf adds to the attention matrix."
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 764,
        "label": "no",
        "change": [
            "class BlenderbotSmallEncoderLayer(nn.Module):",
            "hidden_states = residual + hidden_states",
            "hidden_states = self.final_layer_norm(hidden_states)",
            "",
            "-        if torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any():",
            "+        if hidden_states.dtype == torch.float16 and (",
            "+            torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any()",
            "+        ):",
            "clamp_value = torch.finfo(hidden_states.dtype).max - 1000",
            "hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)"
        ],
        "comments": "add condition check for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 765,
        "label": "no",
        "change": [
            "class Trainer(",
            "",
            "\"\"\"",
            "# bind logger and other properties",
            "-        model.logger = self.logger",
            "self.copy_trainer_model_properties(model)",
            "",
            "# clean hparams"
        ],
        "comments": "remove logger",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 770,
        "label": "no",
        "change": [
            "class RNNGParser(Model, Component):",
            "",
            "\"\"\"",
            "",
            "-        nn.Module.__init__(self)",
            "+        super().__init__()",
            "",
            "self.embedding = embedding",
            "# self.embedding.config: FeatureConfig object cannot be pickled but,"
        ],
        "comments": "not clear no API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 773,
        "label": "no",
        "change": [
            "class ModelSummary(object):",
            "input_ = model.transfer_batch_to_device(input_, model.device)",
            "",
            "if trainer is not None and trainer.amp_backend == AMPType.NATIVE and not trainer.use_tpu:",
            "-                model.forward = torch.cuda.amp.autocast()(model.forward)",
            "+            model.forward = torch.cuda.amp.autocast()(model.forward)",
            "",
            "mode = model.training",
            "model.eval()"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 774,
        "label": "no",
        "change": [
            "class QuantLinear(nn.Module):",
            "x_int = x / prev_act_scaling_factor",
            "",
            "return (",
            "-            F.linear(x_int, weight=self.weight_integer, bias=self.bias_integer) * bias_scaling_factor,",
            "+            nn.functional.linear(x_int, weight=self.weight_integer, bias=self.bias_integer) * bias_scaling_factor,",
            "bias_scaling_factor,",
            ")"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 776,
        "label": "no",
        "change": [
            "class Gaussian(Distribution):",
            "if self.action_spec.max_value is not None:",
            "action = tf.minimum(x=self.action_spec.max_value, y=action)",
            "",
            "-        return action",
            "+            return action",
            "",
            "@tf_function(num_args=2)",
            "def log_probability(self, *, parameters, action):"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 777,
        "label": "no",
        "change": [
            "class Visformer(nn.Module):",
            "img_size //= 8",
            "else:",
            "self.stem = nn.Sequential(",
            "-                    nn.Conv2d(3, self.init_channels, 7, stride=2, padding=3, bias=False),",
            "+                    nn.Conv2d(in_chans, self.init_channels, 7, stride=2, padding=3, bias=False),",
            "nn.BatchNorm2d(self.init_channels),",
            "nn.ReLU(inplace=True)",
            ")"
        ],
        "comments": "change value",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 779,
        "label": "no",
        "change": [
            "class Importance(TracePosterior):",
            "\"\"\"",
            "if self.log_weights:",
            "log_w_norm = self.get_normalized_weights(log_scale=True)",
            "-            ess = torch.exp(-logsumexp(2*log_w_norm, 0))",
            "+            ess = torch.exp(-torch.logsumexp(2*log_w_norm, 0))",
            "else:",
            "warnings.warn(\"The log_weights list is empty, effective sample size is zero.\")",
            "ess = 0"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 780,
        "label": "no",
        "change": [
            "for epoch in range(opt.niter):",
            "vutils.save_image(fake.data, 'fake_samples.png')",
            "",
            "# do checkpointing",
            "-    torch.save(netG.parameter_dict(), 'netG_epoch_%d.pth' % epoch)",
            "-    torch.save(netD.parameter_dict(), 'netD_epoch_%d.pth' % epoch)",
            "+    torch.save(netG.state_dict(), 'netG_epoch_%d.pth' % epoch)",
            "+    torch.save(netD.state_dict(), 'netD_epoch_%d.pth' % epoch)"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 781,
        "label": "no",
        "change": [
            "def distance2bbox(points, distance, max_shape=None):",
            "bboxes = torch.stack([x1, y1, x2, y2], -1)",
            "",
            "if max_shape is not None:",
            "-        if points.dim() == 2 and not torch.onnx.is_in_onnx_export():",
            "+        if bboxes.dim() == 2 and not torch.onnx.is_in_onnx_export():",
            "# speed up",
            "bboxes[:, 0::2].clamp_(min=0, max=max_shape[1])",
            "bboxes[:, 1::2].clamp_(min=0, max=max_shape[0])"
        ],
        "comments": "test",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 782,
        "label": "no",
        "change": [
            "def dnn(tensor_in, hidden_units, activation=tf.nn.relu, keep_prob=None):",
            "with tf.variable_scope('dnn'):",
            "for i, n_units in enumerate(hidden_units):",
            "with tf.variable_scope('layer%d' % i):",
            "-                tensor_in = linear.linear(tensor_in, n_units, True)",
            "+                tensor_in = linear(tensor_in, n_units, True)",
            "tensor_in = activation(tensor_in)",
            "if keep_prob:",
            "tensor_in = tf.nn.dropout(tensor_in, keep_prob)"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 783,
        "label": "yes",
        "change": [
            "class DSClipEncoder(torch.nn.Module):",
            "seq_len,",
            "seq_len,",
            "dtype=dtype,",
            "-                           device=torch.cuda.current_device())",
            "+                           device=get_accelerator().current_device_name())",
            "mask.fill_(torch.tensor(torch.finfo(dtype).min))",
            "mask.triu_(1)",
            "mask = mask.unsqueeze(1)"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 784,
        "label": "no",
        "change": [
            "class ConvNextEncoder(nn.Module):",
            "out_channels=out_chs,",
            "stride=2 if i > 0 else 1,",
            "depth=config.depths[i],",
            "-                drop_path_rates=drop_path_rates[cur],",
            "+                drop_path_rates=drop_path_rates[i],",
            ")",
            "self.stages.append(stage)",
            "-            cur += config.depths[i]",
            "prev_chs = out_chs",
            "",
            "def forward("
        ],
        "comments": "change value",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 785,
        "label": "no",
        "change": [
            "class CTC(torch.nn.Module):",
            "if self.ctc_type == \"warpctc\":",
            "# warpctc only supports float32",
            "ys_hat = ys_hat.to(dtype=torch.float32)",
            "+        else:",
            "+            # use GPU when using the cuDNN implementation",
            "+            ys_true = to_device(self, ys_true)",
            "self.loss = to_device(self, self.loss_fn(ys_hat, ys_true, hlens, olens)).to(dtype=dtype)",
            "if self.reduce:",
            "# NOTE: sum() is needed to keep consistency since warpctc return as tensor w/ shape (1,)"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 786,
        "label": "no",
        "change": [
            "for epoch in range(1, args.epochs + 1):",
            "test(epoch)",
            "sample = Variable(torch.randn(64, 20))",
            "if args.cuda:",
            "-       sample = sample.cuda()",
            "+        sample = sample.cuda()",
            "sample = model.decode(sample).cpu()",
            "save_image(sample.data.view(64, 1, 28, 28),",
            "'results/sample_' + str(epoch) + '.png')"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 788,
        "label": "no",
        "change": [
            "def test_uint8_representation_not_allowed_with_negative_values(workers):",
            "",
            "def test_uint_representation(workers):",
            "x = torch.tensor([[1.5, 2.0, 3.0], [4.5, 5.0, 6.0]])",
            "-    enlarged = x.fix_prec(internal_type=torch.int16, precision_fractional=256)",
            "+    enlarged = x.fix_prec(internal_type=torch.uint8, precision_fractional=256)",
            "restored = enlarged.float_precision()",
            "# And now x and restored must be the same",
            "assert torch.all(torch.eq(x, restored))"
        ],
        "comments": "test",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 789,
        "label": "no",
        "change": [
            "class AttentionDecoder(DecoderBase):",
            "])",
            "else:",
            "attention_context = output.attention_context",
            "-    return tf.concat(1, [next_input, attention_context])",
            "+    return tf.concat_v2([next_input, attention_context], 1)",
            "",
            "def _pad_att_scores(self, scores):",
            "\"\"\"Pads attention scores to fixed length. This is a hack because raw_rnn"
        ],
        "comments": "change API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 791,
        "label": "no",
        "change": [
            "def test_graph_saint():",
            "assert sample.node_norm.numel() == sample.num_nodes",
            "assert sample.edge_norm.numel() == sample.num_edges",
            "",
            "+    torch.manual_seed(12345)",
            "loader = GraphSAINTRandomWalkSampler(data, batch_size=2, walk_length=1,",
            "-                                         num_steps=4, log=False)",
            "+                                         num_steps=4, sample_coverage=10,",
            "+                                         log=False)",
            "",
            "for sample in loader:",
            "assert len(sample) == 4"
        ],
        "comments": "change param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 792,
        "label": "no",
        "change": [
            "class GPTJAttention(nn.Module):",
            "):",
            "# compute causal mask from causal mask buffer",
            "query_length, key_length = query.size(-2), key.size(-2)",
            "-        causal_mask = self.bias[:, :, key_length - query_length : key_length, :key_length].to(torch.bool)",
            "+        causal_mask = self.bias[:, :, key_length - query_length : key_length, :key_length]",
            "",
            "# Keep the attention weights computation in fp32 to avoid overflow issues",
            "query = query.to(torch.float32)"
        ],
        "comments": "remove API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 793,
        "label": "no",
        "change": [
            "class Tester(unittest.TestCase):",
            "",
            "# create checkerboard",
            "board = utils.create_checkerboard(height, width, 4)",
            "-        patch_src = torch.from_numpy(board).view( \\",
            "+        patch_src = torch.from_numpy(board).view(",
            "1, 1, height, width).expand(batch_size, 1, height, width)",
            "patch_src = utils.tensor_to_gradcheck_var(patch_src)  # to var"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 794,
        "label": "no",
        "change": [
            "def main(serialization_directory, device):",
            "iterator.index_with(model.vocab)",
            "",
            "model_predictions = []",
            "-    batches = iterator(instances, num_epochs=1, shuffle=False, cuda_device=device, for_training=False)",
            "+    batches = iterator(instances, num_epochs=1, shuffle=False, cuda_device=device)",
            "for batch in Tqdm.tqdm(batches):",
            "result = model(**batch)",
            "predictions = model.decode(result)"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 795,
        "label": "no",
        "change": [
            "class TestExportModels(unittest.TestCase):",
            "_test_save_and_load(scripted)",
            "",
            "@unittest.skipIf(",
            "-        torch.__version__ < \"1.5.0\", \"Targeting OSS scriptability for the 1.5 release\"",
            "+        torch.__version__ < \"1.6.0\", \"Targeting OSS scriptability for the 1.6 release\"",
            ")",
            "def test_export_transformer(self):",
            "task, parser = get_dummy_task_and_parser()"
        ],
        "comments": "no API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 796,
        "label": "no",
        "change": [
            "from horovod.tensorflow.keras import callbacks, elastic",
            "try:",
            "# In later versions of TensorFlow, optimizers are spread across multiple modules. This set is used to distinguish",
            "# stock optimizers that come with tf.keras from custom optimizers that may need to be wrapped specially.",
            "-    if version.parse(keras.__version__) < version.parse(\"2.11\"):",
            "+    if version.parse(keras.__version__.replace(\"-tf\", \"+tf\")) < version.parse(\"2.11\"):",
            "optimizer_type = tf.keras.optimizers.Optimizer",
            "else:",
            "optimizer_type = keras.optimizers.legacy.Optimizer"
        ],
        "comments": "no API check version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 798,
        "label": "no",
        "change": [
            "if __name__ == \"__main__\":",
            "sample = torch.randn(64, 20).to(device)",
            "sample = model.decode(sample).cpu()",
            "save_image(sample.view(64, 1, 28, 28),",
            "-                       'results/sample_' + str(epoch) + '.png')",
            "\\ No newline at end of file",
            "+                       'results/sample_' + str(epoch) + '.png')"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 800,
        "label": "yes",
        "change": [
            "class GeneralizedChannelPermute(ConditionedGeneralizedChannelPermute, TransformM",
            "self.__delattr__('permutation')",
            "",
            "# Sample a random orthogonal matrix",
            "-        W, _ = torch.qr(torch.randn(channels, channels))",
            "+        W, _ = torch.linalg.qr(torch.randn(channels, channels))",
            "",
            "# Construct the partially pivoted LU-form and the pivots",
            "LU, pivots = W.lu()"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 802,
        "label": "no",
        "change": [
            "class TestConfusionMatrix:",
            "conf_mat = kornia.utils.metrics.confusion_matrix(",
            "predicted, actual, num_classes)",
            "conf_mat_real = torch.tensor(",
            "-            [[[3, 1],",
            "-              [0, 4]]], dtype=torch.float32)",
            "+            [",
            "+                [[3, 1], [0, 4]],",
            "+                [[3, 1], [0, 4]]",
            "+            ], dtype=torch.float32)",
            "assert_allclose(conf_mat, conf_mat_real)",
            "",
            "def test_three_classes(self):"
        ],
        "comments": "change param for shape fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 803,
        "label": "no",
        "change": [
            "def model(x, is_train, reuse):",
            "# nt = Conv2d(nin, 16, (3, 3), (2, 2), act=tf.nn.relu, padding='SAME', name='tc1')",
            "# nt = Conv2d(nt, 8, (3, 3), (2, 2), act=tf.nn.relu, padding='SAME', name='tc2')",
            "## 2. Spatial transformer module (sampler)",
            "-        n = tl.layers.SpatialTransformer2dAffineLayer(nin, theta_layer=nt, out_size=[40, 40], name='spatial')",
            "+        n = tl.layers.SpatialTransformer2dAffineLayer(nin, theta_layer=nt, out_size=(40, 40), name='spatial')",
            "s = n",
            "## 3. Classifier",
            "n = tl.layers.Conv2d("
        ],
        "comments": "update param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 804,
        "label": "yes",
        "change": [
            "class DeiTPreTrainedModel(PreTrainedModel):",
            "def _init_weights(self, module: Union[nn.Linear, nn.Conv2d, nn.LayerNorm]) -> None:",
            "\"\"\"Initialize the weights\"\"\"",
            "if isinstance(module, (nn.Linear, nn.Conv2d)):",
            "-            # Slightly different from the TF version which uses truncated_normal for initialization",
            "-            # cf https://github.com/pytorch/pytorch/pull/5617",
            "-            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)",
            "+            module.weight.data = nn.init.trunc_normal_(module.weight.data, mean=0.0, std=self.config.initializer_range)",
            "if module.bias is not None:",
            "module.bias.data.zero_()",
            "elif isinstance(module, nn.LayerNorm):"
        ],
        "comments": "change API call for shape fix",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 806,
        "label": "no",
        "change": [
            "class SelectAdaptivePool2d(nn.Module):",
            "assert False, 'Invalid pool type: %s' % pool_type",
            "",
            "def is_identity(self):",
            "-        return self.pool_type == ''",
            "+        return not self.pool_type",
            "",
            "def forward(self, x):",
            "x = self.pool(x)",
            "-        if self.flatten:",
            "-            x = x.flatten(1)",
            "+        x = self.flatten(x)",
            "return x",
            "",
            "def feat_mult(self):"
        ],
        "comments": "change condition check for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 807,
        "label": "no",
        "change": [
            "class AttentionDecoderTest(tf.test.TestCase, DecoderTests):",
            "\"\"\"",
            "def setUp(self):",
            "tf.test.TestCase.setUp(self)",
            "+    tf.logging.set_verbosity(tf.logging.INFO)",
            "DecoderTests.__init__(self)",
            "self.attention_dim = 64",
            "self.input_seq_len = 10"
        ],
        "comments": "log fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 808,
        "label": "no",
        "change": [
            "class DisentangledSelfAttention(nn.Module):",
            "dim=-1,",
            "index=p2c_pos.squeeze(0).expand([query_layer.size(0), key_layer.size(-2), key_layer.size(-2)]),",
            ").transpose(-1, -2)",
            "-            score += p2c_att / scale",
            "+            score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)",
            "",
            "return score"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 809,
        "label": "no",
        "change": [
            "\"\\n\",",
            "\"retriever.train(\\n\",",
            "\"    data_dir=doc_dir,\\n\",",
            "-    \"    train_filename=dev_filename,\\n\",",
            "+    \"    train_filename=train_filename,\\n\",",
            "\"    dev_filename=dev_filename,\\n\",",
            "\"    test_filename=dev_filename,\\n\",",
            "\"    n_epochs=1,\\n\","
        ],
        "comments": "config replace rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 812,
        "label": "no",
        "change": [
            "def evaluate(model, data_loader, device):",
            "image = list(img.to(device) for img in image)",
            "targets = [{k: v.to(device) for k, v in t.items()} for t in targets]",
            "",
            "-        torch.cuda.synchronize(device)",
            "+        # CPUGPU",
            "+        if device != torch.device(\"cpu\"):",
            "+            torch.cuda.synchronize(device)",
            "+",
            "model_time = time.time()",
            "outputs = model(image)"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 813,
        "label": "no",
        "change": [
            "class Layer_Lambda_Test(CustomTestCase):",
            "self.dense1 = tl.layers.Dense(in_channels=1, n_units=5)",
            "self.dense2 = tl.layers.Dense(in_channels=1, n_units=5)",
            "self.dense3 = tl.layers.Dense(in_channels=1, n_units=5)",
            "-                self.lambdalayer = tl.layers.ElementwiseLambda(customize_func, fn_weights=[], fn_args={'foo': 1024})",
            "+                self.lambdalayer = tl.layers.ElementwiseLambda(customize_func, fn_args={'foo': 1024})",
            "",
            "def forward(self, x, bar=None):",
            "noise = self.dense1(x)"
        ],
        "comments": "remove param for argument fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 814,
        "label": "no",
        "change": [
            "class TacotronTrainTest(unittest.TestCase):",
            "optimizer = optim.Adam(model.parameters(), lr=c.lr)",
            "for i in range(5):",
            "mel_out, mel_postnet_out, align, stop_tokens = model.forward(",
            "-                input, input_lengths, mel_spec, mel_lengths, speaker_ids)",
            "+                input_dummy, input_lengths, mel_spec, mel_lengths, speaker_ids)",
            "assert torch.sigmoid(stop_tokens).data.max() <= 1.0",
            "assert torch.sigmoid(stop_tokens).data.min() >= 0.0",
            "optimizer.zero_grad()"
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 815,
        "label": "no",
        "change": [
            "def scatter_nd(",
            "initial_val = torch.tensor(0).type(dtype)",
            "elif reduction == \"min\":",
            "if dtype.is_floating_point:",
            "-            initial_val = min(torch.finfo(dtype).max, 1e12)",
            "+            initial_val = min(torch.finfo(dtype).max, 1e12)",
            "else:",
            "initial_val = min(torch.iinfo(dtype).max, 1e12)",
            "elif reduction == \"max\":",
            "if dtype.is_floating_point:",
            "-            initial_val = max(torch.finfo(dtype).min, 1e-12)",
            "+            initial_val = max(torch.finfo(dtype).min, 1e-12)",
            "else:",
            "initial_val = max(torch.iinfo(dtype).min, 1e-12)",
            "else:"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 816,
        "label": "yes",
        "change": [
            "def dnn(tensor_in, hidden_units, activation=tf.nn.relu, keep_prob=None):",
            "for i, n_units in enumerate(hidden_units):",
            "with tf.variable_scope('layer%d' % i):",
            "tensor_in = linear(tensor_in, n_units, True)",
            "-            tensor_in = activation(tensor_in)",
            "-            if keep_prob:",
            "-                tensor_in = tf.nn.dropout(tensor_in, keep_prob)",
            "+                tensor_in = activation(tensor_in)",
            "+                if keep_prob:",
            "+                    tensor_in = skflow.ops.dropout(tensor_in, keep_prob)",
            "return tensor_in"
        ],
        "comments": "format",
        "Symptom": "low efficiency",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 819,
        "label": "no",
        "change": [
            "class SingleStageDetector(BaseDetector):",
            "# get shape as tensor",
            "img_shape = torch._shape_as_tensor(img)[2:]",
            "img_metas[0]['img_shape_for_onnx'] = img_shape",
            "+        # get pad input shape to support onnx dynamic shape for exporting",
            "+        # `CornerNet` and `CentripetalNet`, which 'pad_shape' is used",
            "+        # for inference",
            "+        img_metas[0]['pad_shape_for_onnx'] = img_shape",
            "# TODO:move all onnx related code in bbox_head to onnx_export function",
            "det_bboxes, det_labels = self.bbox_head.get_bboxes(*outs, img_metas)"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 820,
        "label": "no",
        "change": [
            "def convert_bort_checkpoint_to_pytorch(bort_checkpoint_path: str, pytorch_dump_f",
            "# | `encoder.transformer_cells.*.proj.weight`                      | `bert.encoder.layer.*.output.dense.weight`",
            "",
            "# Helper function to convert MXNET Arrays to PyTorch",
            "-    def to_torch(mx_array) -> torch.nn.Parameter:",
            "-        return torch.nn.Parameter(torch.FloatTensor(mx_array.data().asnumpy()))",
            "+    def to_torch(mx_array) -> nn.Parameter:",
            "+        return nn.Parameter(torch.FloatTensor(mx_array.data().asnumpy()))",
            "",
            "# Check param shapes and map new HF param back",
            "def check_and_map_params(hf_param, gluon_param):"
        ],
        "comments": "no API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 821,
        "label": "no",
        "change": [
            "def clip_grad_norm_(params, max_norm, aggregate_norm_fn=None) -> torch.Tensor:",
            "if multi_tensor_l2norm_available:",
            "total_norm = multi_tensor_total_norm(grads)",
            "else:",
            "-            warnings.warn(",
            "-                \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"",
            "-                \"you may get better performance by installing NVIDIA's apex library\"",
            "-            )",
            "+            if torch.cuda.is_available():",
            "+                warnings.warn(",
            "+                    \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"",
            "+                    \"you may get better performance by installing NVIDIA's apex library\"",
            "+                )",
            "total_norm = torch.norm(",
            "torch.stack([torch.norm(g, p=2, dtype=torch.float32) for g in grads])",
            ")"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 823,
        "label": "no",
        "change": [
            "class ModelSpeedupTensorRT(BaseModelSpeedup):",
            "Model input tensor",
            "\"\"\"",
            "# convert pytorch tensor to numpy darray",
            "+        if test_data.device != torch.device(\"cpu\"):",
            "+            test_data = test_data.to(\"cpu\")",
            "test_data = test_data.numpy()",
            "# Numpy dtype should be float32",
            "assert test_data.dtype == np.float32"
        ],
        "comments": "add condition check for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 824,
        "label": "no",
        "change": [
            "class Dio(AbsFeatsExtract):",
            "",
            "return f0",
            "",
            "-    @staticmethod",
            "-    def _average_by_duration(x: torch.Tensor, d: torch.Tensor) -> torch.Tensor:",
            "-        assert d.sum() == len(x)",
            "+    def _average_by_duration(self, x: torch.Tensor, d: torch.Tensor) -> torch.Tensor:",
            "+        assert len(x) - d.sum() < self.reduction_factor",
            "d_cumsum = F.pad(d.cumsum(dim=0), (1, 0))",
            "x_avg = [",
            "x[start:end].masked_select(x[start:end].gt(0.0)).mean(dim=0)"
        ],
        "comments": "no API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 826,
        "label": "no",
        "change": [
            "def main():",
            "parser.add_argument('-n', '--num-epochs', nargs='?', default=1000, type=int)",
            "args = parser.parse_args()",
            "for step in range(args.num_epochs):",
            "-        kl_optim.step(observed_data)  # loss",
            "+        svi.step(observed_data)  # loss",
            "if step % 100 == 0:",
            "if verbose:",
            "print(\"[epoch %d] mean_mu: %.3f\" % (step, pyro.param(\"mean_mu\").data[0]))"
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 828,
        "label": "yes",
        "change": [
            "def main():",
            "if utils.is_primary(args):",
            "_logger.info('Using NVIDIA APEX AMP. Training in mixed precision.')",
            "elif use_amp == 'native':",
            "-        amp_autocast = partial(torch.autocast, device_type=device.type, dtype=amp_dtype)",
            "-        if device.type == 'cuda':",
            "+        try:",
            "+            amp_autocast = partial(torch.autocast, device_type=device.type, dtype=amp_dtype)",
            "+        except (AttributeError, TypeError):",
            "+            # fallback to CUDA only AMP for PyTorch < 1.10",
            "+            assert device.type == 'cuda'",
            "+            amp_autocast = torch.cuda.amp.autocast",
            "+        if device.type == 'cuda' and amp_dtype == torch.float16:",
            "+            # loss scaler only used for float16 (half) dtype, bfloat16 does not need it",
            "loss_scaler = NativeScaler()",
            "if utils.is_primary(args):",
            "_logger.info('Using native Torch AMP. Training in mixed precision.')"
        ],
        "comments": "add condition check for type fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 829,
        "label": "no",
        "change": [
            "class AutoOutsideCompilationWithKerasTest(tf.test.TestCase):",
            "",
            "",
            "if __name__ == '__main__':",
            "-  tf.compat.v1.enable_eager_execution()",
            "tf.test.main()"
        ],
        "comments": "remove API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 830,
        "label": "no",
        "change": [
            "class BatchNorm(Layer):",
            "if self.axes is None:",
            "self.axes = [i for i in range(len(inputs.shape)) if i != self.channel_axis]",
            "",
            "+        mean, var = tf.nn.moments(inputs, self.axes, keepdims=False)",
            "if self.is_train:",
            "# update moving_mean and moving_var",
            "-            mean, var = tf.nn.moments(inputs, self.axes, keepdims=False)",
            "self.moving_mean = moving_averages.assign_moving_average(",
            "self.moving_mean, mean, self.decay, zero_debias=False",
            ")"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 831,
        "label": "no",
        "change": [
            "class WeightNormalization(WeightNormalizationOriginal):",
            "",
            "def build(self, input_shape):",
            "\"\"\"Build `Layer`\"\"\"",
            "-        #input_shape = tf.TensorShape(input_shape)",
            "-        #self.input_spec = tf.keras.layers.InputSpec(shape=[None] + input_shape[1:])",
            "+        # input_shape = tf.TensorShape(input_shape)",
            "+        # self.input_spec = tf.keras.layers.InputSpec(shape=[None] + input_shape[1:])",
            "",
            "# remove 2 lines above to run weight-norm on tf.function with dynamic shape"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 834,
        "label": "no",
        "change": [
            "def trace(",
            "offset: int = 0,",
            "axis1: int = 0,",
            "axis2: int = 1,",
            "-    out: Optional[torch.Tensor] = None",
            "+    out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "ret = torch.diagonal(x, offset=offset, dim1=axis1, dim2=axis2)",
            "ret = torch.sum(ret)"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 836,
        "label": "no",
        "change": [
            "class ValidationCallback(PeriodicCallback):",
            "self.cost_var_name = cost_var_name",
            "",
            "def _before_train(self):",
            "-        self.input_vars = tf.get_collection(MODEL_KEY)[0].get_input_vars()",
            "+        self.input_vars = tf.get_collection(INPUT_VARS_KEY)",
            "self.cost_var = self.get_tensor(self.cost_var_name)",
            "self._find_output_vars()"
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 837,
        "label": "yes",
        "change": [
            "class Encoder(torch.nn.Module):",
            "pos_enc_class(attention_dim, positional_dropout_rate),",
            ")",
            "elif input_layer is None:",
            "-            self.embed = pos_enc_class(attention_dim, positional_dropout_rate)",
            "+            self.embed = torch.nn.Sequential(",
            "+                pos_enc_class(attention_dim, positional_dropout_rate)",
            "+            )",
            "else:",
            "raise ValueError(\"unknown input_layer: \" + input_layer)",
            "self.normalize_before = normalize_before"
        ],
        "comments": "add API call for type fix",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 838,
        "label": "no",
        "change": [
            "class ChineseCLIPVisionTransformer(nn.Module):",
            "embed_dim = config.hidden_size",
            "",
            "self.embeddings = ChineseCLIPVisionEmbeddings(config)",
            "-        self.pre_layrnorm = nn.LayerNorm(embed_dim)",
            "+        self.pre_layrnorm = nn.LayerNorm(embed_dim, eps=config.layer_norm_eps)",
            "self.encoder = ChineseCLIPVisionEncoder(config)",
            "-        self.post_layernorm = nn.LayerNorm(embed_dim)",
            "+        self.post_layernorm = nn.LayerNorm(embed_dim, eps=config.layer_norm_eps)",
            "",
            "@add_start_docstrings_to_model_forward(CHINESE_CLIP_VISION_INPUTS_DOCSTRING)",
            "@replace_return_docstrings(output_type=BaseModelOutputWithPooling, config_class=ChineseCLIPVisionConfig)"
        ],
        "comments": "add param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 839,
        "label": "no",
        "change": [
            "def svd(",
            "def outer(",
            "x1: torch.Tensor, x2: torch.Tensor, out: Optional[torch.Tensor] = None",
            ") -> torch.Tensor:",
            "-    ret = torch.outer(x1, x2, out=out)",
            "-    return ret",
            "+    return torch.outer(x1, x2, out=out)",
            "",
            "",
            "def diagonal("
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 840,
        "label": "no",
        "change": [
            "class TestSolveCast:",
            "",
            "class TestSolveWithMask:",
            "def test_smoke(self, device, dtype):",
            "+        torch.manual_seed(0)  # issue kornia#2027",
            "A = torch.randn(2, 3, 1, 4, 4, device=device, dtype=dtype)",
            "B = torch.randn(2, 3, 1, 4, 6, device=device, dtype=dtype)"
        ],
        "comments": "add API call for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 842,
        "label": "no",
        "change": [
            "class TFHubertPreTrainedModel(TFPreTrainedModel):",
            "input_signature=[",
            "{",
            "\"input_values\": tf.TensorSpec((None, None), tf.float32, name=\"input_values\"),",
            "-                \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),",
            "-                \"token_type_ids\": tf.TensorSpec((None, None), tf.int32, name=\"token_type_ids\"),",
            "+                \"attention_mask\": tf.TensorSpec((None, None), tf.int64, name=\"attention_mask\"),",
            "+                \"token_type_ids\": tf.TensorSpec((None, None), tf.int64, name=\"token_type_ids\"),",
            "}",
            "]",
            ")"
        ],
        "comments": "change param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 844,
        "label": "no",
        "change": [
            "class Entropy(Metric):",
            "average_value = self._entropy / self._count if self._count > 0 else 0",
            "if reset:",
            "self.reset()",
            "-        return average_value",
            "+        return {\"entropy\": average_value}",
            "",
            "@overrides",
            "def reset(self):"
        ],
        "comments": "return change",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 845,
        "label": "no",
        "change": [
            "def test_maskctc(encoder_arch, interctc_layer_idx, interctc_use_conditioning):",
            "inputs = dict(",
            "speech=torch.randn(2, 10, 20, requires_grad=True),",
            "speech_lengths=torch.tensor([10, 8], dtype=torch.long),",
            "-        text=torch.randint(0, vocab_size + 1, [2, 4], dtype=torch.long),",
            "+        text=torch.randint(2, 4, [2, 4], dtype=torch.long),",
            "text_lengths=torch.tensor([4, 3], dtype=torch.long),",
            ")",
            "loss, *_ = model(**inputs)"
        ],
        "comments": "change param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 847,
        "label": "no",
        "change": [
            "def _add_gradients_summaries(grads_and_vars):",
            "grad_values = grad.values",
            "else:",
            "grad_values = grad",
            "-      summaries.append(tf.histogram_summary(var.op.name + ':gradient',",
            "+      summaries.append(tf.summary.histogram(var.op.name + ':gradient',",
            "grad_values))",
            "-      summaries.append(tf.histogram_summary(var.op.name + ':gradient_norm',",
            "+      summaries.append(tf.summary.histogram(var.op.name + ':gradient_norm',",
            "tf.global_norm([grad_values])))",
            "else:",
            "tf.logging.info('Var %s has no gradient', var.op.name)"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 848,
        "label": "no",
        "change": [
            "except ImportError:  # pragma: no cover",
            ")",
            "",
            "MODULE_NAME = \"bentoml.sklearn\"",
            "-MODEL_FILENAME = f\"{SAVE_NAMESPACE}.{PKL_EXT}\"",
            "+MODEL_FILENAME = \"saved_model.pkl\"",
            "",
            "logger = logging.getLogger(__name__)"
        ],
        "comments": "value update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 849,
        "label": "no",
        "change": [
            "class QM9(InMemoryDataset):",
            "edge_type += 2 * [self.bonds[bond.GetBondType()]]",
            "",
            "edge_index = torch.tensor([row, col], dtype=torch.long)",
            "-            edge_type = torch.tensor(edge_type)",
            "-            edge_attr = F.one_hot(torch.tensor(edge_type),",
            "+            edge_type = torch.tensor(edge_type, dtype=torch.long)",
            "+            edge_attr = F.one_hot(edge_type,",
            "num_classes=len(self.bonds)).to(torch.float)",
            "",
            "perm = (edge_index[0] * N + edge_index[1]).argsort()"
        ],
        "comments": "add param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 850,
        "label": "yes",
        "change": [
            "def connect(",
            "self.client_type = client_type",
            "",
            "if credentials:",
            "-                metadata, _user_key = self.conn.login(credentials=credentials)",
            "+                metadata, _user_key = self.conn.login(credentials=credentials)  # type: ignore",
            "_user_key = SigningKey(_user_key.encode(\"utf-8\"), encoder=HexEncoder)",
            "else:",
            "-                metadata = self.conn._get_metadata()",
            "+                metadata = self.conn._get_metadata()  # type: ignore",
            "if not user_key:",
            "_user_key = SigningKey.generate()",
            "else:"
        ],
        "comments": "doc update",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 851,
        "label": "no",
        "change": [
            "class OPTEmbeddingsTest(unittest.TestCase):",
            "def test_logits(self):",
            "model = OPTForCausalLM.from_pretrained(self.path_model)",
            "model = model.eval()",
            "-        tokenizer = GPT2Tokenizer.from_pretrained(\"patrickvonplaten/opt_gpt2_tokenizer\")",
            "+        tokenizer = GPT2Tokenizer.from_pretrained(self.path_model)",
            "tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})",
            "",
            "prompts = ["
        ],
        "comments": "feature",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 853,
        "label": "no",
        "change": [
            "def test_model_checkpoint_options(tmpdir, save_top_k, save_last, expected_files)",
            "for i, loss in enumerate(losses):",
            "trainer.train_loop.current_epoch = i",
            "trainer.train_loop.global_step = i",
            "-        trainer.logger_connector.callback_metrics = {\"checkpoint_on\": torch.tensor(loss)}",
            "+        trainer.logger_connector.callback_metrics.update({\"checkpoint_on\": loss})",
            "checkpoint_callback.on_validation_end(trainer, trainer.lightning_module)",
            "",
            "file_lists = set(os.listdir(tmpdir))"
        ],
        "comments": "logger doc print update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 854,
        "label": "yes",
        "change": [
            "class MinSaver(Callback):",
            "newname = os.path.join(logger.LOG_DIR,",
            "self.filename or",
            "('max-' + self.monitor_stat if self.reverse else 'min-' + self.monitor_stat))",
            "-        files_to_copy = glob.glob(path + '*')",
            "+        files_to_copy = tf.gfile.Glob(path + '*')",
            "for file_to_copy in files_to_copy:",
            "-            shutil.copy(file_to_copy, file_to_copy.replace(path, newname))",
            "+            tf.gfile.Copy(file_to_copy, file_to_copy.replace(path, newname), overwrite=True)",
            "logger.info(\"Model with {} '{}' saved.\".format(",
            "'maximum' if self.reverse else 'minimum', self.monitor_stat))"
        ],
        "comments": "update API call for version fix",
        "Symptom": "program crash",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 855,
        "label": "no",
        "change": [
            "class Evaluator(object):",
            "The mean average result per tensor over the entire dataset.",
            "",
            "\"\"\"",
            "+        tflearn.is_training(False, self.session)",
            "coord = tf.train.Coordinator()",
            "inputs = tf.get_collection(tf.GraphKeys.INPUTS)",
            "# Data Preprocessing"
        ],
        "comments": "add API call for state fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 857,
        "label": "yes",
        "change": [
            "class Lamb(Optimizer):",
            "global_grad_norm.add_(grad.pow(2).sum())",
            "",
            "global_grad_norm = torch.sqrt(global_grad_norm)",
            "-        max_grad_norm = self.defaults['max_grad_norm']",
            "+        # FIXME it'd be nice to remove explicit tensor conversion of scalars when torch.where promotes",
            "+        # scalar types properly https://github.com/pytorch/pytorch/issues/9190",
            "+        max_grad_norm = torch.tensor(self.defaults['max_grad_norm'], device=device)",
            "clip_global_grad_norm = torch.where(",
            "global_grad_norm > max_grad_norm,",
            "global_grad_norm / max_grad_norm,"
        ],
        "comments": "add API call for type fix",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 858,
        "label": "no",
        "change": [
            "class TokenClassificationIntegrationTest(test_combinations.TestCase):",
            "layers, input_shape=(None,))",
            "model.compile(",
            "loss='sparse_categorical_crossentropy',",
            "-        optimizer='adam'",
            "+        optimizer='adam',",
            "metrics=['acc'],",
            "run_eagerly=test_utils.should_run_eagerly())",
            "history = model.fit(dataset, epochs=10,"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 859,
        "label": "no",
        "change": [
            "class ZITS(InpaintModel):",
            "masks: [H, W]",
            "return: BGR IMAGE",
            "\"\"\"",
            "+        mask = mask[:, :, 0]",
            "items = load_image(image, mask, device=self.device)",
            "",
            "self.wireframe_edge_and_line(items, config.zits_wireframe)"
        ],
        "comments": "no API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 860,
        "label": "no",
        "change": [
            "class ModelCatalogTest(unittest.TestCase):",
            "def testCustomModel(self):",
            "ray.init()",
            "ModelCatalog.register_custom_model(\"foo\", CustomModel)",
            "-        p1 = ModelCatalog.get_model(1, 5, {\"custom_model\": \"foo\"})",
            "+        p1 = ModelCatalog.get_model(",
            "+            tf.constant([1, 2, 3]), 5, {\"custom_model\": \"foo\"})",
            "self.assertEqual(str(type(p1)), str(CustomModel))"
        ],
        "comments": "add API call for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 861,
        "label": "no",
        "change": [
            "def corresponding_points_alignment(",
            "U, S, V = torch.svd(XYcov)",
            "",
            "# identity matrix used for fixing reflections",
            "-    E = torch.eye(dim, dtype=XYcov.dtype, device=XYcov.device)[None].repeat(",
            "-        b, 1, 1",
            "-    )",
            "+    E = torch.eye(dim, dtype=XYcov.dtype, device=XYcov.device)[None].repeat(b, 1, 1)",
            "",
            "if not allow_reflection:",
            "# reflection test:"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 862,
        "label": "no",
        "change": [
            "class _netD(nn.Module):",
            "",
            "def forward(self, input):",
            "gpu_ids = None",
            "-        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:",
            "+        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > =1:",
            "gpu_ids = range(self.ngpu)",
            "output = nn.parallel.data_parallel(self.main, input, gpu_ids)",
            "return output.view(-1, 1)"
        ],
        "comments": "change condition check for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 864,
        "label": "no",
        "change": [
            "from nebullvm.transformations.base import BaseTransformation",
            "",
            "",
            "class VerifyContiguity(BaseTransformation):",
            "-    def _transform(self, _input: torch.Tensor, **kwargs) -> Any:",
            "+    def _transform(self, _input: Any, **kwargs) -> Any:",
            "+        if not isinstance(_input, torch.Tensor):",
            "+            return _input",
            "if not _input.is_contiguous():",
            "_input = _input.contiguous()",
            "return _input"
        ],
        "comments": "add condition check for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 865,
        "label": "no",
        "change": [
            "from tests import utils",
            "def test_image_classifier(tmp_path):",
            "train_x = utils.generate_data(num_instances=320, shape=(32, 32, 3))",
            "train_y = utils.generate_one_hot_labels(num_instances=320, num_classes=10)",
            "-    clf = ak.ImageClassifier(directory=tmp_path, max_trials=2, seed=utils.SEED)",
            "+    clf = ak.ImageClassifier(",
            "+        directory=tmp_path,",
            "+        max_trials=2,",
            "+        seed=utils.SEED,",
            "+        distribution_strategy=tf.distribute.MirroredStrategy(),",
            "+    )",
            "clf.fit(train_x, train_y, epochs=1, validation_split=0.2)",
            "keras_model = clf.export_model()",
            "clf.evaluate(train_x, train_y)"
        ],
        "comments": "add param for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 867,
        "label": "no",
        "change": [
            "def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),",
            "output_shape[3],",
            "output_shape[1])",
            "if output_shape[0] is None:",
            "-        output_shape = (tf.shape(x)[0],) + tuple(output_shape[1:])",
            "-        output_shape = tf.stack(list(output_shape))",
            "+        output_shape = (shape(x)[0],) + tuple(output_shape[1:])",
            "+",
            "+    output_shape = tf.stack(list(output_shape))",
            "",
            "padding = _preprocess_padding(padding)",
            "if tf_data_format == 'NHWC':"
        ],
        "comments": "remove API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 868,
        "label": "no",
        "change": [
            "class TestRasterizeMeshes(TestCaseMixin, unittest.TestCase):",
            "], dtype=torch.int64, device=device)",
            "# fmt: on",
            "",
            "-        pix_to_face_padded = -torch.ones_like(pix_to_face_frontface)",
            "+        pix_to_face_padded = -(torch.ones_like(pix_to_face_frontface))",
            "# Run with and without culling",
            "# Without culling, for k=0, the front face (i.e. face 2) is",
            "# rasterized and for k=1, the back face (i.e. face 3) is"
        ],
        "comments": "add API call for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 870,
        "label": "no",
        "change": [
            "class RGATConv(MessagePassing):",
            "alpha = torch.where(alpha > 0, alpha + 1, alpha)",
            "",
            "elif self.mod == \"f-scaled\":",
            "-            ones = torch.ones(index.size())",
            "+            ones = alpha.new_ones(index.size())",
            "degree = scatter_add(ones, index,",
            "dim_size=size_i)[index].unsqueeze(-1)",
            "alpha = alpha * degree"
        ],
        "comments": "customized API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 871,
        "label": "no",
        "change": [
            "class PipelineTest(test.SparkTest):",
            "import tensorflow as tf",
            "from tensorflowonspark import TFNode",
            "",
            "+      tf.compat.v1.disable_eager_execution()",
            "tf.compat.v1.reset_default_graph()",
            "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()"
        ],
        "comments": "add API call for state fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 875,
        "label": "no",
        "change": [
            "class SparkKerasTests(tf.test.TestCase):",
            "",
            "def test_fit_model_multiclass(self):",
            "model = create_mnist_model()",
            "-        if version.parse(tf.keras.__version__) < version.parse(\"2.11\"):",
            "+        if version.parse(tf.keras.__version__.replace(\"-tf\", \"+tf\")) < version.parse(\"2.11\"):",
            "optimizer = tf.keras.optimizers.Adadelta(1.0)",
            "else:",
            "optimizer = tf.keras.optimizers.legacy.Adadelta(1.0)"
        ],
        "comments": "change condition check for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 877,
        "label": "no",
        "change": [
            "def torch_sum(x):",
            "",
            "def torch_backward(x):",
            "\"\"\"",
            "-    Like ``x.backward()`` for a ``torch.autograd.Variable``, but also accepts",
            "+    Like ``x.backward()`` for a :class:`~torch.autograd.Variable`, but also accepts",
            "numbers (a no-op if given a number).",
            "\"\"\"",
            "if isinstance(x, torch.autograd.Variable):"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 878,
        "label": "no",
        "change": [
            "def train(args):",
            "dtype = torch.float32",
            "model = model_class(args.n_vocab, args).to(dtype=dtype)",
            "if args.ngpu > 0:",
            "-        model.to(\"cuda:0\")",
            "+        model.to(\"cuda\")",
            "gpu_id = list(range(args.ngpu))",
            "else:",
            "gpu_id = [-1]"
        ],
        "comments": "change param for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 880,
        "label": "no",
        "change": [
            "def create_meshgrid(height, width, normalized_coordinates=True):",
            "else:",
            "xs = torch.linspace(0, width - 1, width)",
            "ys = torch.linspace(0, height - 1, height)",
            "-    return torch.stack(torch.meshgrid([ys, xs])).view(1, 2, -1)",
            "+    return torch.stack(torch.meshgrid([ys, xs])).view(1, 2, -1)[:, (1, 0), :]",
            "",
            "",
            "class HomographyWarper(nn.Module):"
        ],
        "comments": "change param for shape fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 881,
        "label": "no",
        "change": [
            "try:",
            "\"GPU\"",
            ")",
            "if len(physical_devices) > 0:",
            "-        tensorflow.config.experimental.set_memory_growth(",
            "-            physical_devices[0], True",
            "-        )",
            "+        for physical_device in physical_devices:",
            "+            tensorflow.config.experimental.set_memory_growth(",
            "+                physical_device, True",
            "+            )",
            "",
            "tensorflow.get_logger().setLevel(\"ERROR\")",
            "tensorflow.autograph.set_verbosity(0)"
        ],
        "comments": "change control flow",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 882,
        "label": "no",
        "change": [
            "def main():",
            "# download url: https://download.pytorch.org/models/resnet34-333f7ec4.pth",
            "model_weight_path = \"./resnet34-pre.pth\"",
            "assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)",
            "-    net.load_state_dict(torch.load(model_weight_path, map_location=device))",
            "+    net.load_state_dict(torch.load(model_weight_path, map_location='cpu'))",
            "# for param in net.parameters():",
            "#     param.requires_grad = False"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 883,
        "label": "no",
        "change": [
            "def triangular_solve(x, y, upper=False, transpose=False):",
            "",
            "",
            "def precision_to_scale_tril(P):",
            "-    Lf = torch.cholesky(torch.flip(P, (-2, -1)))",
            "+    Lf = torch.linalg.cholesky(torch.flip(P, (-2, -1)))",
            "L_inv = torch.transpose(torch.flip(Lf, (-2, -1)), -2, -1)",
            "L = torch.triangular_solve(torch.eye(P.shape[-1], dtype=P.dtype, device=P.device),",
            "L_inv, upper=False)[0]"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 884,
        "label": "no",
        "change": [
            "class NaturalGradient(Optimizer):",
            "applied = self.apply_step(variables=variables, diffs=estimated_diffs)",
            "",
            "with tf.control_dependencies(control_inputs=(applied,)):",
            "-                return [tf.identity(input=estimated_diff) for estimated_diff in estimated_diffs]",
            "+                return [estimated_diff + 0.0 for estimated_diff in estimated_diffs]",
            "",
            "def false_fn():",
            "return [tf.zeros_like(tensor=diff) for diff in diffs]"
        ],
        "comments": "remove API call for type fixfor distributed bug",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 885,
        "label": "no",
        "change": [
            "def configure_logger(verbose: bool) -> None:",
            "verbose (bool):",
            "`True` to use verbose logger, `False` otherwise.",
            "\"\"\"",
            "-    tf_logger = tf.get_logger()",
            "+    from tensorflow import get_logger",
            "+    from tensorflow.compat.v1 import logging as tf_logging",
            "+    tf_logger = get_logger()",
            "tf_logger.handlers = [handler]",
            "if verbose:",
            "tf_logging.set_verbosity(tf_logging.INFO)"
        ],
        "comments": "refactor fix error",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 886,
        "label": "no",
        "change": [
            "def argsort(",
            "ret = tf.argsort(",
            "tf.convert_to_tensor(x), axis=axis, direction=\"ASCENDING\", stable=stable",
            ")",
            "-    return ret",
            "+    return tf.cast(ret, dtype=tf.int64)",
            "",
            "",
            "def sort("
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 887,
        "label": "no",
        "change": [
            "def _to_ivy(x: Any) -> Any:",
            "",
            "",
            "def _to_ivy_array(x: Any) -> ivy.Array:",
            "-    if isinstance(x, (torch.Tensor, tf.Tensor, jnp.numpy.DeviceArray, numpy.ndarray)):",
            "+    if isinstance(x, (torch.Tensor, tf.Tensor, jnp.DeviceArray, numpy.ndarray)):",
            "return ivy.array(numpy.array(x))",
            "return x"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 888,
        "label": "no",
        "change": [
            "def vecdot(",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "dtype = ivy.as_native_dtype(ivy.promote_types(x1.dtype, x2.dtype))",
            "-    x1, x2 = tf.cast(x1, tf.float32), tf.cast(x2, tf.float32)",
            "+    if dtype != \"float64\":",
            "+        x1, x2 = tf.cast(x1, tf.float32), tf.cast(x2, tf.float32)",
            "ret = tf.cast(tf.tensordot(x1, x2, axes=(axis, axis)), dtype)",
            "return ret"
        ],
        "comments": "add condition check for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 890,
        "label": "yes",
        "change": [
            "class TestExportModels(unittest.TestCase):",
            "TransformerModel.add_args(parser)",
            "args = parser.parse_args([])",
            "model = TransformerModel.build_model(args, task)",
            "-        torch.jit.script(model)",
            "+        scripted = torch.jit.script(model)",
            "+        self._test_save_and_load(scripted)",
            "",
            "",
            "if __name__ == \"__main__\":"
        ],
        "comments": "customize API",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "removal",
        "Element": "api call"
    },
    {
        "number": 892,
        "label": "no",
        "change": [
            "with tf.device('/cpu:0'):",
            "n_batch += 1",
            "",
            "if epoch + 1 == 1 or (epoch + 1) % print_freq == 0:",
            "-            print(\"Epoch %d : Step %d-%d of %d took %fs\" % \\",
            "-                (epoch, step, step + n_step_epoch, n_step, time.time() - start_time))",
            "+            print(",
            "+                \"Epoch %d : Step %d-%d of %d took %fs\" %",
            "+                (epoch, step, step + n_step_epoch, n_step, time.time() - start_time)",
            "+            )",
            "print(\"   train loss: %f\" % (train_loss / n_batch))",
            "print(\"   train acc: %f\" % (train_acc / n_batch))"
        ],
        "comments": "print update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 895,
        "label": "no",
        "change": [
            "class SinusoidalPositionalEmbedding(nn.Module):",
            "self.embedding_dim,",
            "self.padding_idx,",
            ").type_as(self.weights)",
            "+        self.weights = self.weights.type_as(self._float_tensor)",
            "weights = Variable(self.weights)",
            "",
            "if incremental_state is not None:"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 897,
        "label": "no",
        "change": [
            "def shape(x, unknown=-1):",
            "",
            "",
            "def no_operation():",
            "-    return tf.constant(value=False, dtype=tf_dtype(dtype='bool'))",
            "+    return identity_operation(x=tf.constant(value=False, dtype=tf_dtype(dtype='bool')))",
            "",
            "",
            "def identity_operation(x, operation_name=None):"
        ],
        "comments": "custom API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 900,
        "label": "no",
        "change": [
            "class HifiganGenerator(torch.nn.Module):",
            "def load_checkpoint(",
            "self, config, checkpoint_path, eval=False",
            "):  # pylint: disable=unused-argument, redefined-builtin",
            "-        state = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))",
            "+        state = load_fsspec(checkpoint_path, map_location=torch.device(\"cpu\"))",
            "self.load_state_dict(state[\"model\"])",
            "if eval:",
            "self.eval()"
        ],
        "comments": "customize API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 901,
        "label": "no",
        "change": [
            "class AdditiveSharingTensor(AbstractTensor):",
            "random_shares = [random_type(secret.shape) for _ in range(n_workers - 1)]",
            "",
            "for share in random_shares:",
            "-            share.random_(-field, field)",
            "+            share.random_(int(-field/2), int(field/2)-1)",
            "",
            "shares = []",
            "for i in range(n_workers):"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 902,
        "label": "yes",
        "change": [
            "class PipelineEngine(DeepSpeedEngine):",
            "mem_cached = new_cached",
            "mem_alloced = new_alloced",
            "",
            "-        max_alloced = torch.cuda.max_memory_allocated()",
            "-        max_cached = torch.cuda.max_memory_cached()",
            "+        max_alloced = get_accelerator().max_memory_allocated()",
            "+        max_cached = get_accelerator().max_memory_cached()",
            "",
            "# convert to GB for printing",
            "new_alloced /= 1024**3"
        ],
        "comments": "update API call for version fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 903,
        "label": "no",
        "change": [
            "def torch_multinomial(input, num_samples, replacement=False):",
            "Does not support keyword argument `out`.",
            "\"\"\"",
            "if input.is_cuda:",
            "-        return torch_multinomial(input.cpu(), num_samples, replacement).cuda()",
            "+        return torch.multinomial(input.cpu(), num_samples, replacement).cuda(input.get_device())",
            "else:",
            "return torch.multinomial(input, num_samples, replacement)"
        ],
        "comments": "add param for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 904,
        "label": "no",
        "change": [
            "def test_delete_entire_dataset(domain_owner, cleanup_storage):",
            "assert domain_owner.datasets[0].name == \"Dataset_1\"",
            "assert domain_owner.datasets[1].name == \"Dataset_2\"",
            "",
            "-    domain_owner.datasets.delete(dataset_id=domain_owner.datasets[0].id)",
            "+    domain_owner.datasets.delete(",
            "+        dataset_id=domain_owner.datasets[0].id, skip_checks=True",
            "+    )",
            "",
            "# Check if the number of available datasets has been decreased",
            "assert len(domain_owner.datasets) == 1"
        ],
        "comments": "add param for argument fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 905,
        "label": "yes",
        "change": [
            "def logspace(",
            "base=10.0,",
            "axis=None,",
            "*,",
            "+    dtype: torch.dtype,",
            "device: torch.device,",
            "out: Optional[torch.Tensor] = None,",
            "):",
            "-    power_seq = linspace(",
            "-        start, stop, num, axis, dtype=None, device=default_device(device)",
            "+    power_seq = ivy.linspace(",
            "+        start, stop, num, axis, dtype=dtype, device=ivy.default_device(device)",
            ")",
            "return base**power_seq"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 906,
        "label": "no",
        "change": [
            "def test_crypto_lr(fit_intercept, hook, workers):",
            "",
            "K = 2  # number of features",
            "",
            "-    beta = torch.Tensor([1.0, 10.0]).view(-1, 1)  # \"real\" coefficients",
            "-    intercept = 3.0 if fit_intercept else 0  # \"real\" intercept",
            "+    beta = torch.Tensor([1.0, 2.0]).view(-1, 1)  # \"real\" coefficients",
            "+    intercept = 0.5 if fit_intercept else 0  # \"real\" intercept",
            "",
            "# Alice's data",
            "torch.manual_seed(0)  # Truncation might not always work so we set the random seed"
        ],
        "comments": "value change",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 908,
        "label": "no",
        "change": [
            "def pack(",
            "try:",
            "import torch",
            "",
            "-        meta_objs.update(torch=torch.__version__)",
            "+        meta_objs.update(torch=str(torch.__version__))",
            "except ImportError:",
            "pass",
            "try:"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 909,
        "label": "no",
        "change": [
            "def main():",
            "# recog",
            "logging.info('backend = ' + args.backend)",
            "if args.backend == \"chainer\":",
            "-        from espnet.lmchainer.asr_chainer import recog",
            "+        from espnet.asr.chainer.asr_chainer import recog",
            "recog(args)",
            "elif args.backend == \"pytorch\":",
            "-        from espnet.lmpytorch.asr_pytorch import recog",
            "+        from espnet.asr.pytorch.asr_pytorch import recog",
            "recog(args)",
            "else:",
            "raise ValueError(\"Only chainer and pytorch are supported.\")"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 910,
        "label": "no",
        "change": [
            "class Schedule(metaclass=ABCMeta):",
            "raise NotImplementedError",
            "",
            "def value(self, t):",
            "-        if self.framework == \"tf\" and tf.executing_eagerly() is False:",
            "+        if self.framework == \"tf\":",
            "return tf.cast(",
            "-                tf.py_func(self._value, [t], tf.float64),",
            "+                tf.py_function(self._value, [t], tf.float64),",
            "tf.float32,",
            "-                name=\"schedule-value\")",
            "+                name=\"schedule_value\")",
            "return self._value(t)",
            "",
            "def __call__(self, t):"
        ],
        "comments": "change API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 911,
        "label": "no",
        "change": [
            "def Dropout(x, *args, **kwargs):",
            "if 'is_training' in kwargs:",
            "kwargs['training'] = kwargs.pop('is_training')",
            "if len(args) > 0:",
            "-        logger.warn(",
            "-            \"The first positional argument to tensorpack.Dropout is the probability to keep rather than to drop. \"",
            "-            \"This is different from the rate argument in tf.layers.Dropout due to historical reasons. \"",
            "-            \"To mimic tf.layers.Dropout, explicitly use keyword argument 'rate' instead\")",
            "+        if args[0] != 0.5:",
            "+            logger.warn(",
            "+                \"The first positional argument to tensorpack.Dropout is the probability to keep, rather than to drop. \"",
            "+                \"This is different from the rate argument in tf.layers.Dropout due to historical reasons. \"",
            "+                \"To mimic tf.layers.Dropout, explicitly use keyword argument 'rate' instead\")",
            "rate = 1 - args[0]",
            "elif 'keep_prob' in kwargs:",
            "assert 'rate' not in kwargs, \"Cannot set both keep_prob and rate!\""
        ],
        "comments": "conditional warning",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 912,
        "label": "no",
        "change": [
            "class FeedForwardTransformer(TTSInterface, torch.nn.Module):",
            "",
            "# concat speaker embedding",
            "if self.spk_embed_dim is not None:",
            "-            spembs = torch.nn.functional.normalize(spembs).unsqueeze(1).expand(-1, hs.size(1), -1)",
            "-            hs = self.projection(torch.cat([hs, spembs], dim=-1))",
            "+            spembs_ = F.normalize(spembs).unsqueeze(1).expand(-1, hs.size(1), -1)",
            "+            hs = self.projection(torch.cat([hs, spembs_], dim=-1))",
            "",
            "# forward duration predictor and length regulator",
            "d_masks = make_pad_mask(ilens).to(xs.device)"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 916,
        "label": "no",
        "change": [
            "def symmetrical_epipolar_distance(",
            "",
            "\"\"\"",
            "if not isinstance(Fm, torch.Tensor):",
            "-        raise TypeError(\"Fm type is not a torch.Tensor. Got {}\".format(type(Fm)))",
            "+        raise TypeError(f\"Fm type is not a torch.Tensor. Got {type(Fm)}\")",
            "",
            "if (len(Fm.shape) != 3) or not Fm.shape[-2:] == (3, 3):",
            "-        raise ValueError(\"Fm must be a (*, 3, 3) tensor. Got {}\".format(Fm.shape))",
            "+        raise ValueError(f\"Fm must be a (*, 3, 3) tensor. Got {Fm.shape}\")",
            "",
            "if pts1.size(-1) == 2:",
            "pts1 = kornia.convert_points_to_homogeneous(pts1)"
        ],
        "comments": "value change",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 917,
        "label": "no",
        "change": [
            "class Replay(Queue):",
            "",
            "zero = tf.constant(value=0, dtype=util.tf_dtype(dtype='long'))",
            "indices = tf.zeros(shape=(0,), dtype=util.tf_dtype(dtype='long'))",
            "-        indices, _ = tf.while_loop(",
            "+        indices, _ = self.while_loop(",
            "cond=cond, body=reduce_range_concat, loop_vars=(indices, zero),",
            "shape_invariants=(tf.TensorShape(dims=(None,)), zero.get_shape()), back_prop=False",
            ")"
        ],
        "comments": "version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 918,
        "label": "no",
        "change": [
            "eigh.unsupported_dtypes = (",
            "eigh.support_native_out = True",
            "",
            "",
            "-def eigvalsh(x: torch.Tensor, /, *, out: Optional[torch.Tensor] = None) -> torch.Tensor:",
            "-    return torch.linalg.eigvalsh(x, out=out)",
            "+def eigvalsh(",
            "+    x: torch.Tensor, /, *, UPLO: Optional[str] = \"L\", out: Optional[torch.Tensor] = None",
            "+) -> torch.Tensor:",
            "+    return torch.linalg.eigvalsh(x, UPLO=UPLO, out=out)",
            "",
            "",
            "eigvalsh.unsupported_dtypes = ("
        ],
        "comments": "no API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 919,
        "label": "no",
        "change": [
            "def image_histogram2d(",
            "hist = hist.squeeze()",
            "elif image.dim() == 3:",
            "hist = hist.squeeze(0)",
            "-    return hist, torch.zeros_like(hist, dtype=hist.dtype, device=device)",
            "+    return hist, torch.zeros_like(hist, dtype=hist.dtype, device=hist.device)"
        ],
        "comments": "update param for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 920,
        "label": "no",
        "change": [
            "class FeedForwardEncoder(Seq2SeqEncoder):",
            "return self._feedforward(inputs)",
            "else:",
            "outputs = self._feedforward(inputs)",
            "-            return outputs * mask.unsqueeze(dim=-1).float()",
            "+            return outputs * mask.unsqueeze(dim=-1)"
        ],
        "comments": "remove API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 921,
        "label": "no",
        "change": [
            "def elastic_transform2d(",
            "sigma_t = sigma.to(device=device, dtype=dtype)",
            "",
            "# Get Gaussian kernel for 'y' and 'x' displacement",
            "-    kernel_x: torch.Tensor = get_gaussian_kernel2d_t(kernel_size, sigma_t[0].expand(2).unsqueeze(0))",
            "-    kernel_y: torch.Tensor = get_gaussian_kernel2d_t(kernel_size, sigma_t[1].expand(2).unsqueeze(0))",
            "+    kernel_x: torch.Tensor = get_gaussian_kernel2d(kernel_size, sigma_t[0].expand(2).unsqueeze(0))",
            "+    kernel_y: torch.Tensor = get_gaussian_kernel2d(kernel_size, sigma_t[1].expand(2).unsqueeze(0))",
            "",
            "# Convolve over a random displacement matrix and scale them with 'alpha'",
            "disp_x: torch.Tensor = noise[:, :1]"
        ],
        "comments": "change API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 923,
        "label": "no",
        "change": [
            "class TpuStrategyTest(tf.test.TestCase):",
            "self.assertIn(prediction1, (\"yes\", \"no\"))",
            "",
            "prediction2 = loaded_serving_fn(",
            "-        tf.constant([\"ironman\", \"ironman\", \"unkonwn\"]))[\"output_0\"]",
            "+        tf.constant([\"ironman\", \"ironman\", \"unknown\"]))[\"output_0\"]",
            "self.assertIn(prediction2, (\"yes\", \"no\"))"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 925,
        "label": "yes",
        "change": [
            "def main(N, M):",
            "item_thetas = torch.tensor([[0., 0.], [0., .5], [0., 1.]])",
            "design_tensor = build_design_tensor(item_thetas, individual_assignment)",
            "print(\"Design tensor\", design_tensor)",
            "-    y = naive_rainforth(model, design_tensor, target_labels=[\"w_global\", \"w_local\"], N=N, M=M)",
            "+    y = naive_rainforth_eig(model, design_tensor, observation_labels=\"y\",",
            "+                            target_labels=[\"w\", \"u\", \"G_u\"], N=N, M=M)",
            "print(\"EIG\", y)"
        ],
        "comments": "customized API",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 926,
        "label": "no",
        "change": [
            "def subtract(",
            "return torch.subtract(x1, x2, out=out)",
            "return torch.subtract(",
            "x1 if isinstance(x1, torch.Tensor) else torch.tensor(x1, dtype=x2.dtype),",
            "-        x2 if isinstance(x2, torch.Tensor) else torch.tensor(x2, dtype=x2.dtype),",
            "+        x2 if isinstance(x2, torch.Tensor) else torch.tensor(x2, dtype=x1.dtype),",
            ")"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 928,
        "label": "no",
        "change": [
            "def main():",
            "'tensorflow-variable-single-summary': tensorflow_variable_single,",
            "'tensorflow-variable-multi-summary': tensorflow_variable_multi,",
            "",
            "-            #'graph-summary': graph,",
            "+            'graph-summary': graph,",
            "})",
            "",
            "#history.add({"
        ],
        "comments": "add graph",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 929,
        "label": "yes",
        "change": [
            "def rand_like_with_shape(shape, ori_t):",
            "higher_bound = torch.max(ori_t)",
            "",
            "if dtype in [torch.uint8, torch.int16, torch.short, torch.int16, torch.long, torch.bool]:",
            "-        return torch.randint(lower_bound, higher_bound+1, shape, dtype=dtype, device=device)",
            "+        return torch.randint(lower_bound.long(), higher_bound.long() + 1, shape, dtype=dtype, device=device)",
            "else:",
            "return torch.rand(shape, dtype=dtype, device=device, requires_grad=require_grad)"
        ],
        "comments": "add API call for type fix",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 930,
        "label": "yes",
        "change": [
            "def map_data_vector_model(subsample_size):",
            "pyro.sample(\"x\", dist.normal, mu[batch], sigma[batch])",
            "return batch",
            "",
            "-    ind = Variable(torch.LongTensor(range(20)))",
            "+    LongTensor = torch.cuda.LongTensor if torch.Tensor.is_cuda else torch.LongTensor",
            "+    ind = Variable(LongTensor(range(20)))",
            "batch = pyro.map_data('mapdata', ind, local_model, batch_size=subsample_size)",
            "return list(batch.data)"
        ],
        "comments": "add condition check for resource fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 932,
        "label": "no",
        "change": [
            "def train(model, generated_image, initial_image):",
            "## 2. create writer to write your graph",
            "saver = tf.train.Saver()",
            "sess.run(tf.global_variables_initializer())",
            "+        writer = tf.summary.FileWriter(EXP + '/graphs', sess.graph)",
            "###############################",
            "sess.run(generated_image.assign(initial_image))",
            "ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/checkpoint'))"
        ],
        "comments": "print update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 933,
        "label": "no",
        "change": [
            "class SelfAttnFunc(torch.autograd.Function):",
            "values_grads   = torch.bmm(dropout_results.transpose(1,2), output_lin_grads, out=values_grads.transpose(0,1))",
            "",
            "# Mask and Scaling for Dropout (not a publically documented op)",
            "-        dropout_grads = torch._masked_scale(matmul2_dgrad1, dropout_mask, dropout_prob_t[0])",
            "+        dropout_grads = torch._masked_scale(matmul2_dgrad1, dropout_mask, 1.0/(1.0-dropout_prob_t[0]))",
            "",
            "# Softmax Grad (not a publically documented op)",
            "softmax_grads = torch._softmax_backward_data(dropout_grads, softmax_results, -1, softmax_results)"
        ],
        "comments": "change param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 934,
        "label": "no",
        "change": [
            "class ValidationEpochEndVariations(ABC):",
            "",
            "val_acc_mean += val_acc",
            "",
            "-        val_loss_mean /= len(outputs)",
            "-        val_acc_mean /= len(outputs)",
            "+        if outputs:  # skip zero divisions",
            "+            val_loss_mean /= len(outputs)",
            "+            val_acc_mean /= len(outputs)",
            "",
            "metrics_dict = {'val_loss': val_loss_mean.item(), 'val_acc': val_acc_mean.item()}",
            "results = {'progress_bar': metrics_dict, 'log': metrics_dict}"
        ],
        "comments": "add condition check for null fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 935,
        "label": "yes",
        "change": [
            "class AutoShape(nn.Module):",
            "#   multiple:        = [Image.open('image1.jpg'), Image.open('image2.jpg'), ...]  # list of images",
            "",
            "t = [time_sync()]",
            "-        p = next(self.model.parameters()) if self.pt else torch.zeros(1)  # for device and type",
            "+        p = next(self.model.parameters()) if self.pt else torch.zeros(1, device=self.model.device)  # for device, type",
            "autocast = self.amp and (p.device.type != 'cpu')  # Automatic Mixed Precision (AMP) inference",
            "if isinstance(imgs, torch.Tensor):  # torch",
            "with amp.autocast(autocast):"
        ],
        "comments": "add param for resource fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 936,
        "label": "no",
        "change": [
            "class CycleDiffusionPipeline(DiffusionPipeline):",
            "",
            "device = torch.device(f\"cuda:{gpu_id}\")",
            "",
            "-        for cpu_offloaded_model in [self.unet, self.text_encoder, self.vae, self.safety_checker]:",
            "+        for cpu_offloaded_model in [self.unet, self.text_encoder, self.vae]:",
            "if cpu_offloaded_model is not None:",
            "cpu_offload(cpu_offloaded_model, device)",
            "",
            "+        if self.safety_checker is not None:",
            "+            # TODO(Patrick) - there is currently a bug with cpu offload of nn.Parameter in accelerate",
            "+            # fix by only offloading self.safety_checker for now",
            "+            cpu_offload(self.safety_checker.vision_model)",
            "+",
            "@property",
            "# Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline._execution_device",
            "def _execution_device(self):"
        ],
        "comments": "add condition check for null fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 937,
        "label": "no",
        "change": [
            "def shift_tokens_right(input_ids: tf.Tensor, pad_token_id: int, decoder_start_to",
            "",
            "if tf.executing_eagerly():",
            "# \"Verify that `labels` has only positive values and -100\"",
            "-        assert_gte0 = tf.debugging.assert_greater_equal(shifted_input_ids, tf.constant(0))",
            "+        assert_gte0 = tf.debugging.assert_greater_equal(shifted_input_ids, tf.constant(0, dtype=input_ids.dtype))",
            "",
            "# Make sure the assertion op is called by wrapping the result in an identity no-op",
            "with tf.control_dependencies([assert_gte0]):"
        ],
        "comments": "add param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 939,
        "label": "no",
        "change": [
            "class ConvEncoder(AbsEncoder):",
            "return self._output_dim",
            "",
            "def forward(self, input: torch.Tensor, ilens: torch.Tensor):",
            "-        \"\"\"",
            "+        \"\"\"Forward.",
            "+",
            "Args:",
            "-            input (torch.Tensor): mixed speech [Batch, sample]",
            "-            ilens (torch.Tensor): input lengths [Batch]",
            "+        input (torch.Tensor): mixed speech [Batch, sample]",
            "+        ilens (torch.Tensor): input lengths [Batch]",
            "\"\"\"",
            "assert input.dim() == 2, \"Currently only support single channle input\""
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 940,
        "label": "no",
        "change": [
            "def arange(start, stop=None, step=1, dtype=None, dev=None):",
            "if dtype in [torch.int8, torch.uint8, torch.int16]:",
            "return torch.arange(start, stop, step=step, dtype=torch.int64, device=dev).to(dtype)",
            "else:",
            "-            return torch.range(start, stop, step=step, dtype=dtype, device=dev)",
            "+            return torch.arange(start, stop, step=step, dtype=dtype, device=dev)"
        ],
        "comments": "change API call for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 941,
        "label": "no",
        "change": [
            "+import tensorflow as tf",
            "+from autokeras.hyperparameters import HyperParameters",
            "+",
            "+",
            "+def test_hierarchical_hyperparameters():",
            "+    hp = HyperParameters()",
            "+    with tf.name_scope('abc'):",
            "+        hp.Choice('num_layers', [1, 2, 3], default=1)",
            "+    assert 'abc/num_layers' in hp.values"
        ],
        "comments": "add method",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 942,
        "label": "no",
        "change": [
            "class TimesOfIndiaNewsHeadlines(datasets.GeneratorBasedBuilder):",
            "path_to_manual_file = os.path.join(os.path.abspath(os.path.expanduser(dl_manager.manual_dir)), _FILENAME)",
            "if not os.path.exists(path_to_manual_file):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('times_of_india_news_headlines', data_dir=...)` that includes a file name {}. Manual download instructions: {})\".format(",
            "-                    path_to_manual_file, _FILENAME, self.manual_download_instructions",
            "-                )",
            "+                f\"{path_to_manual_file} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('times_of_india_news_headlines', data_dir=...)` that includes a file name {_FILENAME}. Manual download instructions: {self.manual_download_instructions})\"",
            ")",
            "return [datasets.SplitGenerator(name=datasets.Split.TRAIN, gen_kwargs={\"path\": path_to_manual_file})]"
        ],
        "comments": "doc string print error log update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 943,
        "label": "no",
        "change": [
            "def main(_):",
            "# n_examples = batch_size * num_steps",
            "# so",
            "# cost is the averaged cost of each mini-batch (concurrent process).",
            "-        loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example(  # loss = tf.nn.seq2seq.sequence_loss_by_example( # TF0.12",
            "-            [outputs], [tf.reshape(targets, [-1])], [tf.ones_like(tf.reshape(targets, [-1]), dtype=tf.float32)])",
            "+        loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example(",
            "+            [outputs], [tf.reshape(targets, [-1])], [tf.ones_like(tf.reshape(targets, [-1]), dtype=tf.float32)]",
            "+        )",
            "# [tf.ones([batch_size * num_steps])])",
            "cost = tf.reduce_sum(loss) / batch_size",
            "return cost"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 944,
        "label": "no",
        "change": [
            "def _apply_affine(input: torch.Tensor,",
            "",
            "height, width = x_data.shape[-2:]",
            "transform: torch.Tensor = params['transform'].to(device, dtype)",
            "-",
            "-    out_data: torch.Tensor = warp_perspective(x_data, transform, (height, width))",
            "+    out_data: torch.Tensor = warp_affine(x_data, transform[:, :2, :], (height, width))",
            "",
            "if return_transform:",
            "return out_data.view_as(input), transform"
        ],
        "comments": "change API call for shape fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 945,
        "label": "no",
        "change": [
            "def floormod(",
            "return ret",
            "",
            "",
            "-def unstack(x, axis: int, keepdims: bool = False) -> List[torch.Tensor]:",
            "+def unstack(",
            "+    x: torch.Tensor,",
            "+    axis: int,",
            "+    keepdims: bool = False",
            "+) -> List[torch.Tensor]:",
            "if x.shape == ():",
            "return [x]",
            "ret = list(torch.unbind(x, axis))"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 946,
        "label": "no",
        "change": [
            "class GPTNeoAttentionMixin:",
            "else:",
            "raise ValueError(f\"Input tensor rank should be one of [2, 3], but is: {len(tensor.shape)}\")",
            "",
            "-        padded_tensor = F.pad(tensor, padding_side, value=pad_value)",
            "+        padded_tensor = nn.functional.pad(tensor, padding_side, value=pad_value)",
            "padded_tensor = padded_tensor.unfold(dimension=1, size=window_size + block_length, step=block_length)",
            "",
            "if is_key_value:"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 947,
        "label": "no",
        "change": [
            "import ivy",
            "from typing import Optional, Union",
            "",
            "",
            "-def logit(x: Union[tf.Tensor, tf.Variable],",
            "-          /,",
            "-          *,",
            "-          eps: Optional[float] = None,",
            "-          out=None):",
            "+def logit(",
            "+    x: Union[tf.Tensor, tf.Variable], /, *, eps: Optional[float] = None, out=None",
            "+):",
            "x_dtype = x.dtype",
            "if eps is None:",
            "x = tf.where(tf.math.logical_or(x > 1, x < 0), ivy.nan, x)"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 949,
        "label": "no",
        "change": [
            "class TFTransfoXLPreTrainedModel(TFPreTrainedModel):",
            "@tf.function(",
            "input_signature=[",
            "{",
            "-                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),",
            "+                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),",
            "}",
            "]",
            ")"
        ],
        "comments": "change param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 951,
        "label": "yes",
        "change": [
            "class BiattentiveClassificationNetwork(Model):",
            "# Create ELMo embeddings if applicable",
            "if self._elmo:",
            "if elmo_tokens is not None:",
            "-                elmo_representations = self._elmo(elmo_tokens)[\"elmo_representations\"]",
            "+                elmo_representations = self._elmo(elmo_tokens[\"tokens\"])[\"elmo_representations\"]",
            "# Pop from the end is more performant with list",
            "if self._use_integrator_output_elmo:",
            "integrator_output_elmo = elmo_representations.pop()"
        ],
        "comments": "change param for argument fix",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 953,
        "label": "no",
        "change": [
            "def test_tagged_corpus_downsample():",
            "",
            "assert 10 == len(corpus.train)",
            "",
            "-    corpus.downsample(percentage=0.3, only_downsample_train=True)",
            "+    corpus.downsample(percentage=0.3, downsample_dev=False, downsample_test=False)",
            "",
            "assert 3 == len(corpus.train)"
        ],
        "comments": "test fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 957,
        "label": "no",
        "change": [
            "class Function(object):",
            "if is_sparse(tensor):",
            "sparse_coo = value.tocoo()",
            "indices = np.concatenate((np.expand_dims(sparse_coo.row, 1), np.expand_dims(sparse_coo.col, 1)), 1)",
            "-                value = (indices, value.data, value.shape)",
            "+                value = (indices, sparse_coo.data, sparse_coo.shape)",
            "feed_dict[tensor] = value",
            "session = get_session()",
            "updated = session.run(self.outputs + [self.updates_op], feed_dict=feed_dict)"
        ],
        "comments": "change param for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 958,
        "label": "yes",
        "change": [
            "def test_download_mnist_dataset(tmpdir):",
            ")",
            "",
            "ludwig.datasets._get_dataset_configs.cache_clear()",
            "-    with mock.patch(\"ludwig.datasets.load_dataset_config\", return_value=config):",
            "+    with mock.patch(\"ludwig.datasets._load_dataset_config\", return_value=config):",
            "dataset = ludwig.datasets.get_dataset(\"mnist\", cache_dir=tmpdir)",
            "assert not dataset.state == DatasetState.DOWNLOADED",
            "assert not dataset.state == DatasetState.TRANSFORMED",
            "dataset.download()",
            "",
            "assert dataset.state == DatasetState.DOWNLOADED",
            "+    ludwig.datasets._get_dataset_configs.cache_clear()"
        ],
        "comments": "version fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 960,
        "label": "no",
        "change": [
            "def test_transformer_trainable_and_decodable(model_dict):",
            "attn_dict = model.calculate_all_attentions(",
            "x[0:1], ilens[0:1], y_tgt[0:1], y_src[0:1]",
            ")",
            "-    plot.plot_multi_head_attention(data, attn_dict, \"\", savefn=_savefn)",
            "+    plot.plot_multi_head_attention(data, uttid_list, attn_dict, \"\", savefn=_savefn)",
            "",
            "# test CTC plot",
            "ctc_probs = model.calculate_all_ctc_probs("
        ],
        "comments": "add param for argument fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 961,
        "label": "no",
        "change": [
            "class TFLayoutLMv3PreTrainedModel(TFPreTrainedModel):",
            "@tf.function(",
            "input_signature=[",
            "{",
            "-                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),",
            "-                \"bbox\": tf.TensorSpec((None, None, 4), tf.int32, name=\"bbox\"),",
            "+                \"input_ids\": tf.TensorSpec((None, None), tf.int64, name=\"input_ids\"),",
            "+                \"bbox\": tf.TensorSpec((None, None, 4), tf.int64, name=\"bbox\"),",
            "\"pixel_values\": tf.TensorSpec((None, None, None, None), tf.float32, name=\"pixel_values\"),",
            "-                \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),",
            "+                \"attention_mask\": tf.TensorSpec((None, None), tf.int64, name=\"attention_mask\"),",
            "}",
            "]",
            ")"
        ],
        "comments": "change param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 962,
        "label": "yes",
        "change": [
            "class DecisionTransformerGPT2Attention(nn.Module):",
            "# Need to be a tensor, otherwise we get error: `RuntimeError: expected scalar type float but found double`.",
            "# Need to be on the same device, otherwise `RuntimeError: ..., x and y to be on the same device`",
            "mask_value = torch.full([], mask_value, dtype=attn_weights.dtype).to(attn_weights.device)",
            "-            attn_weights = torch.where(causal_mask, attn_weights, mask_value)",
            "+            attn_weights = torch.where(causal_mask, attn_weights.to(attn_weights.dtype), mask_value)",
            "",
            "if attention_mask is not None:",
            "# Apply the attention mask"
        ],
        "comments": "add API call for resource fix",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 963,
        "label": "no",
        "change": [
            "def load_tf_graph(graph_file):",
            "\"\"\"",
            "# We load the protobuf file from the disk and parse it to retrieve the",
            "# unserialized graph_def",
            "-    with tf.gfile.GFile(graph_file, \"rb\") as f:",
            "-        graph_def = tf.GraphDef()",
            "+    with tf.io.gfile.GFile(graph_file, \"rb\") as f:",
            "+        graph_def = tf.compat.v1.GraphDef()",
            "graph_def.ParseFromString(f.read())",
            "",
            "# Then, we import the graph_def into a new Graph and returns it"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 964,
        "label": "no",
        "change": [
            "def gradients(loss, variables):",
            "return tf.gradients(loss, variables)",
            "",
            "",
            "+def stop_gradient(variables):",
            "+    '''Returns `variables` but with zero gradient with respect to every other",
            "+    variables.",
            "+    '''",
            "+    return tf.stop_gradient(variables)",
            "+",
            "+",
            "# CONTROL FLOW",
            "",
            "def rnn(step_function, inputs, initial_states,"
        ],
        "comments": "add method",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 965,
        "label": "no",
        "change": [
            "},",
            "\"outputs\": [],",
            "\"source\": [",
            "-        \"import torch\\nimport torch.nn.functional as F\\nfrom torch.optim import SGD\\n\\nfrom scripts.compression_mnist_model import TorchModel, trainer, evaluator, device, test_trt\\n\\n# define the model\\nmodel = TorchModel().to(device)\\n\\n# define the optimizer and criterion for pre-training\\n\\noptimizer = SGD(model.parameters(), 1e-2)\\ncriterion = F.nll_loss\\n\\n# pre-train and evaluate the model on MNIST dataset\\nfor epoch in range(3):\\n    trainer(model, optimizer, criterion)\\n    evaluator(model)\"",
            "+        \"import torch\\nimport torch.nn.functional as F\\nfrom torch.optim import SGD\\n\\nfrom nni_assets.compression.mnist_model import TorchModel, trainer, evaluator, device, test_trt\\n\\n# define the model\\nmodel = TorchModel().to(device)\\n\\n# define the optimizer and criterion for pre-training\\n\\noptimizer = SGD(model.parameters(), 1e-2)\\ncriterion = F.nll_loss\\n\\n# pre-train and evaluate the model on MNIST dataset\\nfor epoch in range(3):\\n    trainer(model, optimizer, criterion)\\n    evaluator(model)\"",
            "]",
            "},",
            "{"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 966,
        "label": "no",
        "change": [
            "class Wav2Vec2ForMaskedLM(Wav2Vec2PreTrainedModel):",
            ">>> processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")",
            ">>> model = Wav2Vec2ForMaskedLM.from_pretrained(\"facebook/wav2vec2-base-960h\")",
            "",
            "+",
            ">>> def map_to_array(batch):",
            "-        >>>     speech, _ = sf.read(batch[\"file\"])",
            "-        >>>     batch[\"speech\"] = speech",
            "-        >>>     return batch",
            "+        ...     speech, _ = sf.read(batch[\"file\"])",
            "+        ...     batch[\"speech\"] = speech",
            "+        ...     return batch",
            "+",
            "",
            ">>> ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")",
            ">>> ds = ds.map(map_to_array)"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 967,
        "label": "no",
        "change": [
            "class TestScalarMix(AllenNlpTestCase):",
            "tensors = [torch.randn([3, 4, 5]) for _ in range(3)]",
            "numpy_mask = numpy.ones((3, 4), dtype=\"int32\")",
            "numpy_mask[1, 2:] = 0",
            "-        mask = torch.from_numpy(numpy_mask)",
            "+        mask = torch.from_numpy(numpy_mask).bool()",
            "",
            "weights = [0.1, 0.2, 0.3]",
            "for k in range(3):"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 968,
        "label": "yes",
        "change": [
            "def get_global_step_var():",
            "with tf.variable_scope(scope, reuse=False), \\",
            "tf.name_scope(None):",
            "var = tf.get_variable(GLOBAL_STEP_OP_NAME,",
            "-                                  initializer=0,",
            "-                                  trainable=False, dtype=tf.int32)",
            "+                                  initializer=tf.constant(0, dtype=tf.int64),",
            "+                                  trainable=False, dtype=tf.int64)",
            "return var"
        ],
        "comments": "change param for type fix",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 969,
        "label": "no",
        "change": [
            "class SequenceFeatureExtractionTestMixin(FeatureExtractionSavingTestMixin):",
            "input_np = feat_extract.pad(processed_features, padding=\"longest\", return_tensors=\"np\")[input_name]",
            "input_tf = feat_extract.pad(processed_features, padding=\"longest\", return_tensors=\"tf\")[input_name]",
            "",
            "-        self.assertTrue(abs(input_np.sum() - input_tf.numpy().sum()) < 1e-2)",
            "+        self.assertTrue(abs(input_np.astype(np.float32).sum() - input_tf.numpy().sum()) < 1e-2)",
            "",
            "def test_attention_mask(self):",
            "feat_dict = self.feat_extract_dict"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 971,
        "label": "no",
        "change": [
            "class ScoreSdeVeScheduler(SchedulerMixin, ConfigMixin):",
            "\"\"\"",
            "sampling_eps = sampling_eps if sampling_eps is not None else self.config.sampling_eps",
            "",
            "-        self.timesteps = torch.linspace(1, sampling_eps, num_inference_steps)",
            "+        self.timesteps = torch.linspace(1, sampling_eps, num_inference_steps, device=device)",
            "",
            "def set_sigmas(",
            "self, num_inference_steps: int, sigma_min: float = None, sigma_max: float = None, sampling_eps: float = None"
        ],
        "comments": "add param for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 972,
        "label": "no",
        "change": [
            "class SSIM(nn.Module):",
            "ssim_map = ((2 * mu1_mu2 + self.C1) * (2 * sigma12 + self.C2)) / \\",
            "((mu1_sq + mu2_sq + self.C1) * (sigma1_sq + sigma2_sq + self.C2))",
            "",
            "-        loss = torch.clamp(1. - ssim_map, min=0, max=1) / 2.",
            "+        loss = torch.clamp(torch.tensor(1.) - ssim_map, min=0, max=1) / 2.",
            "",
            "if self.reduction == 'mean':",
            "loss = torch.mean(loss)"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 974,
        "label": "yes",
        "change": [
            "def rpn_losses(anchor_labels, anchor_boxes, label_logits, box_logits):",
            "placeholder = 1.",
            "label_loss = tf.nn.sigmoid_cross_entropy_with_logits(",
            "labels=tf.to_float(valid_anchor_labels), logits=valid_label_logits)",
            "-    label_loss = label_loss * (1. / config.RPN_BATCH_PER_IM)",
            "+    label_loss = tf.reduce_sum(label_loss) * (1. / config.RPN_BATCH_PER_IM)",
            "label_loss = tf.where(tf.equal(nr_valid, 0), placeholder, label_loss, name='label_loss')",
            "",
            "pos_anchor_boxes = tf.boolean_mask(anchor_boxes, pos_mask)"
        ],
        "comments": "add API call for math fix",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 975,
        "label": "no",
        "change": [
            "def test_beamformer_net_wpe_output(ch, num_spk, use_dnn_mask_for_wpe):",
            "def test_beamformer_net_bf_output(num_spk):",
            "ch = 3",
            "inputs = torch.randn(2, 16, ch)",
            "+    inputs = inputs.float()",
            "ilens = torch.LongTensor([16, 12])",
            "model = BeamformerNet(",
            "n_fft=8,"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 976,
        "label": "no",
        "change": [
            "from allennlp.common.testing import AllenNlpTestCase",
            "",
            "class TestElmoLstmCell(AllenNlpTestCase):",
            "def test_elmo_lstm(self):",
            "-        input_tensor = Variable(torch.rand(4, 5, 3))",
            "+        input_tensor = torch.rand(4, 5, 3)",
            "input_tensor[1, 4:, :] = 0.",
            "input_tensor[2, 2:, :] = 0.",
            "input_tensor[3, 1:, :] = 0.",
            "-        mask = Variable(torch.ones([4, 5]))",
            "+        mask = torch.ones([4, 5])",
            "mask[1, 4:] = 0.",
            "mask[2, 2:] = 0.",
            "mask[3, 1:] = 0."
        ],
        "comments": "remove API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 977,
        "label": "yes",
        "change": [
            "class TpuStrategyTest(tf.test.TestCase):",
            "serving_fn = create_serving_signature(model)",
            "",
            "saved_model_dir = tempfile.mkdtemp(dir=self.get_temp_dir())",
            "-      tf.saved_model.save(",
            "-          model, saved_model_dir, signatures={\"serving_default\": serving_fn})",
            "+      model.save(saved_model_dir, save_format=\"tf\",",
            "+                 signatures={\"serving_default\": serving_fn})",
            "",
            "# Test the saved_model.",
            "loaded_serving_fn = tf.keras.models.load_model("
        ],
        "comments": "update API call for version fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 979,
        "label": "no",
        "change": [
            "class BeamformerNet(torch.nn.Module):",
            "def forward_rawwav(self, input: torch.Tensor, ilens: torch.Tensor):",
            "\"\"\"",
            "Args:",
            "-            input (torch.Tensor): mixed speech [Batch, sample]",
            "+            input (torch.Tensor): mixed speech [Batch, Nsample, Channel]",
            "ilens (torch.Tensor): input lengths [Batch]",
            "",
            "Returns:",
            "predcited speech wavs (single-channel):",
            "-                torch.Tensor(Batch, sample), or List[torch.Tensor(Batch, sample)]",
            "+                torch.Tensor(Batch, Nsamples), or List[torch.Tensor(Batch, Nsamples)]",
            "output lengths",
            "predcited masks: OrderedDict[",
            "'dereverb': torch.Tensor(Batch, Frames, Channel, Freq),"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 980,
        "label": "no",
        "change": [
            "class SequentialRNNLM(AbsLM):",
            "c = torch.zeros((self.nlayers, self.nhid), dtype=torch.float)",
            "state = h, c",
            "else:",
            "-            state = torch.zeros((nlayers, nhid), dtype=torch.float)",
            "+            state = torch.zeros((self.nlayers, self.nhid), dtype=torch.float)",
            "",
            "return state"
        ],
        "comments": "change param for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 981,
        "label": "no",
        "change": [
            "def test_node2vec():",
            "assert 0 <= acc and acc <= 1",
            "",
            "if is_full_test():",
            "-        jit = torch.jit.export(model)",
            "+        jit = torch.jit.script(model)",
            "",
            "assert jit(torch.arange(3)).size() == (3, 16)"
        ],
        "comments": "change API feature change",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 984,
        "label": "no",
        "change": [
            "def _preprocess_conv3d_input(x, data_format):",
            "# Returns",
            "A tensor.",
            "\"\"\"",
            "-    if dtype(x) == 'float64':",
            "+    # tensorflow doesn't support float64 for conv layer before 1.8.0",
            "+    if (dtype(x) == 'float64'",
            "+            and StrictVersion(tf.__version__) < StrictVersion('1.8.0')):",
            "x = tf.cast(x, 'float32')",
            "tf_data_format = 'NDHWC'",
            "if data_format == 'channels_first':"
        ],
        "comments": "add condition check for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 985,
        "label": "no",
        "change": [
            "class TextEncoder(torch.nn.Module):",
            "",
            "# define modules",
            "self.emb = torch.nn.Embedding(vocabs, attention_dim)",
            "-        torch.nn.init.normal_(self.emb.weight, 0.0, attention_dim**-0.5)",
            "+        torch.nn.init.normal_(self.emb.weight, 0.0, attention_dim ** -0.5)",
            "self.encoder = Encoder(",
            "idim=-1,",
            "input_layer=None,"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 986,
        "label": "no",
        "change": [
            "class TextEncoder(torch.nn.Module):",
            "",
            "# define modules",
            "self.emb = torch.nn.Embedding(vocabs, attention_dim)",
            "-        torch.nn.init.normal_(self.emb.weight, 0.0, attention_dim ** -0.5)",
            "+        torch.nn.init.normal_(self.emb.weight, 0.0, attention_dim**-0.5)",
            "self.encoder = Encoder(",
            "idim=-1,",
            "input_layer=None,"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 987,
        "label": "no",
        "change": [
            "class SingleRoIExtractor(BaseRoIExtractor):",
            "num_levels = len(feats)",
            "roi_feats = feats[0].new_zeros(",
            "rois.size(0), self.out_channels, *out_size)",
            "+        # TODO: remove this when parrots supports",
            "+        if torch.__version__ == 'parrots':",
            "+            roi_feats.requires_grad = True",
            "",
            "if num_levels == 1:",
            "if len(rois) == 0:"
        ],
        "comments": "add condition check for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 988,
        "label": "yes",
        "change": [
            "def main(args):",
            "accelerator.clip_grad_norm_(params_to_clip, args.max_grad_norm)",
            "optimizer.step()",
            "lr_scheduler.step()",
            "-                optimizer.zero_grad()",
            "+                optimizer.zero_grad(set_to_none=args.set_grads_to_none)",
            "",
            "# Checks if the accelerator has performed an optimization step behind the scenes",
            "if accelerator.sync_gradients:"
        ],
        "comments": "add param for resource fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 989,
        "label": "no",
        "change": [
            "class Tagger(nn.Module):",
            "# criterion",
            "self.crit = nn.CrossEntropyLoss(ignore_index=0) # ignore padding",
            "",
            "-        self.drop = Dropout(args['dropout'])",
            "+        self.drop = nn.Dropout(args['dropout'])",
            "self.worddrop = WordDropout(args['word_dropout'])",
            "",
            "def forward(self, word, word_mask, wordchars, wordchars_mask, upos, xpos, ufeats, pretrained, word_orig_idx, sentlens, wordlens):"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 990,
        "label": "yes",
        "change": [
            "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)",
            "def train():",
            "model.train()",
            "optimizer.zero_grad()",
            "-    pos_z, neg_z, summary = model(data.x, data.edge_index, data.edge_attr)",
            "-    loss = model.loss(pos_z, neg_z, summary)",
            "+    y = model(data.x, data.edge_index, data.edge_attr)",
            "+    loss = torch.sum(y) #TODO: actual loss function",
            "loss.backward()",
            "optimizer.step()",
            "return loss.item()"
        ],
        "comments": "feature change",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "removal",
        "Element": "api call"
    },
    {
        "number": 991,
        "label": "no",
        "change": [
            "def build_linear_positions(index_dims, output_range=(-1.0, 1.0)):",
            "return torch.linspace(start=output_range[0], end=output_range[1], steps=n_xels_per_dim, dtype=torch.float32)",
            "",
            "dim_ranges = [_linspace(n_xels_per_dim) for n_xels_per_dim in index_dims]",
            "-    array_index_grid = torch.meshgrid(*dim_ranges)",
            "+    array_index_grid = meshgrid(*dim_ranges, indexing=\"ij\")",
            "",
            "return torch.stack(array_index_grid, dim=-1)"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 994,
        "label": "no",
        "change": [
            "def train_embedding(embedding_name, learn_rate, batch_size, gradient_step, data_",
            "# go back until we reach gradient accumulation steps",
            "if (j + 1) % gradient_step != 0:",
            "continue",
            "-                #print(f\"grad:{embedding.vec.grad.detach().cpu().abs().mean().item():.7f}\")",
            "-                #scaler.unscale_(optimizer)",
            "-                #print(f\"grad:{embedding.vec.grad.detach().cpu().abs().mean().item():.7f}\")",
            "-                #torch.nn.utils.clip_grad_norm_(embedding.vec, max_norm=1.0)",
            "-                #print(f\"grad:{embedding.vec.grad.detach().cpu().abs().mean().item():.7f}\")",
            "scaler.step(optimizer)",
            "scaler.update()",
            "embedding.step += 1"
        ],
        "comments": "remove print",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 995,
        "label": "no",
        "change": [
            "class Model(torch.nn.Module, Registrable):",
            "@classmethod",
            "def from_params(cls, vocab: Vocabulary, params: Params) -> 'Model':",
            "choice = params.pop_choice(\"type\", cls.list_available())",
            "-        return cls.by_name(choice).from_params(vocab, params)",
            "+        model = cls.by_name(choice).from_params(vocab, params)",
            "+        return model",
            "",
            "@classmethod",
            "def load(cls,"
        ],
        "comments": "version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 999,
        "label": "no",
        "change": [
            "class TestInverseWithMask:",
            "assert_close(y, y_expected)",
            "assert torch.equal(mask, torch.ones_like(mask))",
            "",
            "-    @pytest.mark.skipif((int(torch.__version__.split('.')[0]) == 1) and (int(torch.__version__.split('.')[1]) < 9),",
            "-                        reason='<1.9.0 not supporting')",
            "+    @pytest.mark.skipif(",
            "+        (int(torch.__version__.split('.')[0]) == 1) and (int(torch.__version__.split('.')[1]) < 9),",
            "+        reason='<1.9.0 not supporting',",
            "+    )",
            "def test_all_bad(self, device, dtype):",
            "A = torch.ones(10, 3, 3, device=device, dtype=dtype)",
            "X, mask = safe_inverse_with_mask(A)"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1000,
        "label": "no",
        "change": [
            "def batch_to_time(value, dilation, name=None):",
            "return tf.reshape(transposed, [tf.div(shape[0], dilation), -1, shape[2]])",
            "",
            "",
            "-def causal_conv(value, filter_, dilation, name=None):",
            "-    with tf.name_scope('causal_conv'):",
            "+def causal_conv(value, filter_, dilation, name='causal_conv'):",
            "+    with tf.name_scope(name):",
            "# Pad beforehand to preserve causality",
            "filter_width = tf.shape(filter_)[0]",
            "padded = tf.pad(value, [[0, 0], [(filter_width - 1) * dilation, 0], [0, 0]])"
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1001,
        "label": "no",
        "change": [
            "class Matinf(datasets.GeneratorBasedBuilder):",
            "",
            "if not os.path.exists(data_dir):",
            "raise FileNotFoundError(",
            "-                \"{} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('matinf', data_dir=...)` that includes files unzipped from the MATINF zip. Manual download instructions: {}\".format(",
            "-                    data_dir, self.manual_download_instructions",
            "-                )",
            "+                f\"{data_dir} does not exist. Make sure you insert a manual dir via `datasets.load_dataset('matinf', data_dir=...)` that includes files unzipped from the MATINF zip. Manual download instructions: {self.manual_download_instructions}\"",
            ")",
            "return [",
            "datasets.SplitGenerator("
        ],
        "comments": "string fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1003,
        "label": "no",
        "change": [
            "def SubpixelConv2d(net, scale=2, n_out_channel=None, act=tf.identity, name='subp",
            "bsize = tf.shape(X)[0] # Handling Dimension(None) type for undefined batch dim",
            "Xs=tf.split(X,r,3) #b*h*w*r*r",
            "Xr=tf.concat(Xs,2) #b*h*(r*w)*r",
            "-            X=tf.reshape(Xr,(b,r*a,r*b,c)) # b*(r*h)*(r*w)*c",
            "+            X=tf.reshape(Xr,(bsize,r*a,r*b,c)) # b*(r*h)*(r*w)*c",
            "else:",
            "print(_err_log)",
            "return X"
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1006,
        "label": "no",
        "change": [
            "def unique_inverse(",
            "",
            "",
            "def unique_values(",
            "-    x: Union[tf.Tensor, tf.Variable], *, out: Optional[Union[tf.Tensor, tf.Variable]]",
            "+    x: Union[tf.Tensor, tf.Variable],",
            "+    *,",
            "+    out: Optional[Union[tf.Tensor, tf.Variable]] = None",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "ret = tf.unique(tf.reshape(x, [-1]))[0]",
            "return ret"
        ],
        "comments": "no API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1007,
        "label": "yes",
        "change": [
            "class GPT2Attention(nn.Module):",
            "# Apply the attention mask",
            "attn_weights = attn_weights + attention_mask",
            "",
            "-        attn_weights = nn.Softmax(dim=-1)(attn_weights)",
            "+        attn_weights = nn.functional.softmax(attn_weights, dim=-1)",
            "",
            "# Downcast (if necessary) back to V's dtype (if in mixed-precision) -- No-Op if otherwise",
            "if attn_weights.dtype != torch.float32:"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1008,
        "label": "no",
        "change": [
            "class BidirectionalEndpointSpanExtractor(SpanExtractor):",
            "sequence_lengths = util.get_lengths_from_binary_sequence_mask(sequence_mask)",
            "else:",
            "# shape (batch_size), filled with the sequence length size of the sequence_tensor.",
            "-            sequence_lengths = util.ones_like(sequence_tensor[:, 0, 0]).long() * sequence_tensor.size(1)",
            "+            sequence_lengths = (torch.ones_like(sequence_tensor[:, 0, 0], dtype=torch.long) *",
            "+                                sequence_tensor.size(1))",
            "",
            "# shape (batch_size, num_spans, 1)",
            "end_sentinel_mask = (exclusive_span_ends == sequence_lengths.unsqueeze(-1)).long().unsqueeze(-1)"
        ],
        "comments": "add param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1009,
        "label": "no",
        "change": [
            "_SHARETENSOR = _descriptor.Descriptor(",
            "syntax=\"proto3\",",
            "extension_ranges=[],",
            "oneofs=[],",
            "-    serialized_start=154,",
            "-    serialized_end=257,",
            "+    serialized_start=115,",
            "+    serialized_end=218,",
            ")",
            "",
            "_SHARETENSOR.fields_by_name["
        ],
        "comments": "value change",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1010,
        "label": "no",
        "change": [
            "class WaveNet(object):",
            "tf.histogram_summary('postprocess2_weights', w2)",
            "",
            "# We skip connections from the outputs of each layer, adding them all up here",
            "-            # We perform pairwise addition instead of using tf.add_n, so TensorFlow can free",
            "-            # the memory of previous layers",
            "total = outputs[0]",
            "for out in outputs[1:]:",
            "total += out"
        ],
        "comments": "doc",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1013,
        "label": "no",
        "change": [
            "class ARSTFPolicy:",
            "self.num_params = sum(",
            "np.prod(variable.shape.as_list())",
            "for _, variable in self.variables.variables.items())",
            "-        self.sess.run(tf.global_variables_initializer())",
            "+        self.sess.run(tf1.global_variables_initializer())",
            "",
            "def compute_actions(self,",
            "observation,"
        ],
        "comments": "update API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1014,
        "label": "no",
        "change": [
            "class TestOpening:",
            "None, None, :, :",
            "]",
            "assert_allclose(",
            "-            opening(tensor, torch.ones_like(structural_element), structuring_element=structural_element), expected,",
            "-            atol=1e-4, rtol=1e-4",
            "+            opening(tensor, torch.ones_like(structural_element), structuring_element=structural_element),",
            "+            expected,",
            "+            atol=1e-4,",
            "+            rtol=1e-4,",
            ")",
            "",
            "def test_exception(self, device, dtype):"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1015,
        "label": "no",
        "change": [
            "class RoFormerSinusoidalPositionalEmbedding(nn.Embedding):",
            "return out",
            "",
            "@torch.no_grad()",
            "-    def forward(self, input_ids_shape: torch.Size, past_key_values_length: int = 0):",
            "+    def forward(self, input_ids_shape: torch.Size, past_key_values_length: int = 0) -> torch.Tensor:",
            "\"\"\"`input_ids_shape` is expected to be [bsz x seqlen].\"\"\"",
            "bsz, seq_len = input_ids_shape[:2]",
            "positions = torch.arange("
        ],
        "comments": "no API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1016,
        "label": "no",
        "change": [
            "class LanguageModel(nn.Module):",
            "",
            "for i in range(number_of_characters):",
            "",
            "-                if torch.cuda.is_available():",
            "-                    input = input.cuda()",
            "+                input = input.to(flair.device)",
            "",
            "# get predicted weights",
            "prediction, _, hidden = self.forward(input, hidden)"
        ],
        "comments": "change API call for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1017,
        "label": "no",
        "change": [
            "def instance_norm(",
            "",
            "",
            "def lp_normalize(",
            "-    x: Union[tf.Tensor, tf.Variable], /, *, p: float = 2, axis: int = None, out=None",
            "+    x: Union[tf.Tensor, tf.Variable],",
            "+    /,",
            "+    *,",
            "+    p: float = 2,",
            "+    axis: Optional[int] = None,",
            "+    out: Optional[tf.Tensor] = None,",
            ") -> tf.Tensor:",
            "denorm = tf.norm(x, ord=p, axis=axis, keepdims=True)",
            "denorm = tf.math.maximum(denorm, 1e-12)"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1020,
        "label": "no",
        "change": [
            "class Conv(nn.Module):",
            "",
            "",
            "class DWConv(Conv):",
            "-    # Depth-wise convolution class",
            "+    # Depth-wise convolution",
            "def __init__(self, c1, c2, k=1, s=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups",
            "super().__init__(c1, c2, k, s, g=math.gcd(c1, c2), act=act)",
            "",
            "",
            "class DWConvTranspose2d(nn.ConvTranspose2d):",
            "-    # Depth-wise transpose convolution class",
            "+    # Depth-wise transpose convolution",
            "def __init__(self, c1, c2, k=1, s=1, p1=0, p2=0):  # ch_in, ch_out, kernel, stride, padding, padding_out",
            "super().__init__(c1, c2, k, s, p1, p2, groups=math.gcd(c1, c2))"
        ],
        "comments": "doc",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1021,
        "label": "no",
        "change": [
            "def reduce_per_replica(values, strategy, reduction):",
            "else:",
            "return concat(strategy.experimental_local_results(v))",
            "elif reduction == \"sum\":",
            "-            values = strategy.experimental_local_results(v)",
            "-            return tf.reduce_sum(values)",
            "+            return tf.reduce_sum(strategy.experimental_local_results(v))",
            "else:",
            "raise ValueError(",
            "'`reduction` must be \"first\", \"concat\", \"sum\", or \"auto\". '"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1022,
        "label": "no",
        "change": [
            "class DeformableDetrModel(DeformableDetrPreTrainedModel):",
            "scale = 2 * math.pi",
            "",
            "dim_t = torch.arange(num_pos_feats, dtype=torch.float32, device=proposals.device)",
            "-        dim_t = temperature ** (2 * torch.div(dim_t, 2) / num_pos_feats)",
            "+        dim_t = temperature ** (2 * torch_int_div(dim_t, 2) / num_pos_feats)",
            "# batch_size, num_queries, 4",
            "proposals = proposals.sigmoid() * scale",
            "# batch_size, num_queries, 4, 128"
        ],
        "comments": "custom API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1024,
        "label": "yes",
        "change": [
            "class MultiCategorical(TFActionDistribution):",
            "",
            "@override(ActionDistribution)",
            "def multi_kl(self, other):",
            "-        return [cat.kl(oth_cat) for cat, oth_cat in zip(self.cats, other.cats)]",
            "+        return tf.stack(",
            "+            [cat.kl(oth_cat) for cat, oth_cat in zip(self.cats, other.cats)],",
            "+            axis=1)",
            "",
            "@override(ActionDistribution)",
            "def kl(self, other):"
        ],
        "comments": "add API call for shape fix",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1025,
        "label": "no",
        "change": [
            "class SelfAttentionMask(tf.keras.layers.Layer):",
            "",
            "return mask  # pragma: no cover",
            "",
            "+    def get_config(self):",
            "+        return super().get_config()",
            "+",
            "",
            "@tf.keras.utils.register_keras_serializable()",
            "class Transformer(tf.keras.layers.Layer):"
        ],
        "comments": "def",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1027,
        "label": "no",
        "change": [
            "class Trainer:",
            "if self.args.past_index >= 0:",
            "inputs[\"mems\"] = past",
            "# Our model outputs do not work with DataParallel, so forcing return tuple.",
            "-            if self.args.n_gpu > 1:",
            "+            if isinstance(model, nn.DataParallel):",
            "inputs[\"return_tuple\"] = True",
            "",
            "with torch.no_grad():"
        ],
        "comments": "change condition check for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1028,
        "label": "no",
        "change": [
            "class PolicyWithValue:",
            "def sample(logits, mask_npinf):",
            "new_logits = tf.math.add(logits, mask_npinf)",
            "u = tf.random_uniform(tf.shape(new_logits), dtype=logits.dtype)",
            "-            return tf.argmax(new_logits - tf.log(-tf.log(u)), axis=-1)",
            "+            return tf.argmax(new_logits - tf.log(-1*tf.log(u)), axis=-1)",
            "",
            "def neglogp(logits, x):",
            "# return tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.logits, labels=x)"
        ],
        "comments": "change param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1029,
        "label": "no",
        "change": [
            "class XCLIPModelIntegrationTest(unittest.TestCase):",
            "torch.Size((inputs.input_ids.shape[0], inputs.pixel_values.shape[0])),",
            ")",
            "",
            "-        expected_logits = torch.tensor([[14.3819, 20.6031, 15.0526]], device=torch_device)",
            "+        expected_logits = torch.tensor([[14.0181, 20.2771, 14.4776]], device=torch_device)",
            "",
            "self.assertTrue(torch.allclose(outputs.logits_per_video, expected_logits, atol=1e-3))"
        ],
        "comments": "value change",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1030,
        "label": "no",
        "change": [
            "def Conv2DTranspose(",
            "if get_tf_version_tuple() <= (1, 12):",
            "kernel_initializer = tf.contrib.layers.variance_scaling_initializer(2.0),",
            "else:",
            "-            kernel_initializer = tf.keras.initializers.VarianceScaling(2.0)",
            "+            kernel_initializer = tf.keras.initializers.VarianceScaling(2.0, distribution='untruncated_normal')",
            "",
            "with rename_get_variable({'kernel': 'W', 'bias': 'b'}):",
            "layer = tf.layers.Conv2DTranspose("
        ],
        "comments": "add param for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1031,
        "label": "no",
        "change": [
            "def binary_focal_loss_with_logits(",
            "",
            "probs_pos = torch.sigmoid(input)",
            "probs_neg = torch.sigmoid(-input)",
            "-    loss_tmp = -alpha * torch.pow(probs_neg, gamma) * target * F.logsigmoid(input) - (",
            "-        1 - alpha",
            "-    ) * torch.pow(probs_pos, gamma) * (1.0 - target) * F.logsigmoid(-input)",
            "+    loss_tmp = -alpha * torch.pow(probs_neg, gamma) * target * F.logsigmoid(input) - (1 - alpha) * torch.pow(",
            "+        probs_pos, gamma",
            "+    ) * (1.0 - target) * F.logsigmoid(-input)",
            "",
            "if reduction == 'none':",
            "loss = loss_tmp"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1033,
        "label": "no",
        "change": [
            "def make_batches(lines, args, task, max_positions, encode_fn):",
            ").long()",
            "for src_str in lines",
            "]",
            "-    lengths = torch.LongTensor([t.numel() for t in tokens])",
            "+    lengths = [t.numel() for t in tokens]",
            "itr = task.get_batch_iterator(",
            "dataset=task.build_dataset_for_inference(tokens, lengths),",
            "max_tokens=args.max_tokens,"
        ],
        "comments": "remove API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1034,
        "label": "no",
        "change": [
            "class EarlyStopping(Callback):",
            "",
            "if trainer.use_tpu:",
            "stop = torch.tensor(int(trainer.should_stop), device=pl_module.device, dtype=torch.int32)",
            "-            stop = xm.mesh_reduce(\"stop_signal\", stop, torch.cat)",
            "+            stop = xm.mesh_reduce(\"stop_signal\", stop, sum)",
            "torch_xla.core.xla_model.rendezvous(\"pl.EarlyStoppingCallback.stop_distributed_training_check\")",
            "trainer.should_stop = int(stop.item()) == trainer.world_size"
        ],
        "comments": "add param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1035,
        "label": "no",
        "change": [
            "class Entropy(Metric):",
            "mask : `torch.Tensor`, optional (default = None).",
            "A masking tensor of shape (batch_size, ...).",
            "\"\"\"",
            "-        logits, mask = self.unwrap_to_tensors(logits, mask)",
            "+        logits, mask = self.detach_tensors(logits, mask)",
            "",
            "if mask is None:",
            "-            mask = torch.ones(logits.size()[:-1])",
            "+            mask = torch.ones(logits.size()[:-1], device=logits.device)",
            "",
            "log_probs = torch.nn.functional.log_softmax(logits, dim=-1)",
            "probabilities = torch.exp(log_probs) * mask.unsqueeze(-1)"
        ],
        "comments": "change API call for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1036,
        "label": "no",
        "change": [
            "from itertools import chain",
            "if \"keras\" in sys.modules:",
            "if \"tensorflow.python.keras\" in sys.modules:",
            "wandb.termlog(",
            "-            \"WARNING: found both keras and tensorflow.python.keras. Use `from tensorflow import keras` and remove `import keras` to use the latest W&B features.\")",
            "+            \"Found keras and tensorflow.keras. WandbCallback will be configured for keras not tensorflow.keras.\")",
            "import keras",
            "import keras.backend as K",
            "elif \"tensorflow.python.keras\" in sys.modules:"
        ],
        "comments": "doc fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1039,
        "label": "no",
        "change": [
            "class ImageEmbedder(nn.Module):",
            "",
            "self.to_patch_embedding = nn.Sequential(",
            "Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_size, p2 = patch_size),",
            "+            nn.LayerNorm(patch_dim),",
            "nn.Linear(patch_dim, dim),",
            "+            nn.LayerNorm(dim)",
            ")",
            "",
            "self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1043,
        "label": "no",
        "change": [
            "class BertForSequenceClassification(BertPreTrainedModel):",
            "",
            "self.bert = BertModel(config)",
            "self.dropout = nn.Dropout(config.hidden_dropout_prob)",
            "-        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)",
            "+        self.classifier = nn.Linear(config.hidden_size, config.num_labels)",
            "",
            "self.init_weights()"
        ],
        "comments": "change param for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1044,
        "label": "yes",
        "change": [
            "def fmod(",
            "out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "result = tf.math.floormod(x1, x2, name=None)",
            "-    temp = (result, x1)",
            "-    return tf.map_fn(lambda x: x[0] if (x[0] * x[1] >= 0) else (-1 * x[0]), temp)",
            "+    temp = [result, x1]",
            "+    return tf.map_fn(lambda x: x[0] if (x[0] * x[1] >= 0) else (-1 * x[0]), temp, fn_output_signature=result.dtype)",
            "",
            "",
            "def fmax("
        ],
        "comments": "add param for type fix",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 1046,
        "label": "no",
        "change": [
            "class MT5DenseGatedActDense(nn.Module):",
            "# To make 8bit quantization work for google/flan-t5-xxl, self.wo is kept in float32.",
            "# See https://github.com/huggingface/transformers/issues/20287",
            "# we also make sure the weights are not in `int8` in case users will force `_keep_in_fp32_modules` to be `None``",
            "-        if hidden_states.dtype != self.wo.weight.dtype and self.wo.weight.dtype != torch.int8:",
            "+        if (",
            "+            isinstance(self.wo.weight, torch.Tensor)",
            "+            and hidden_states.dtype != self.wo.weight.dtype",
            "+            and self.wo.weight.dtype != torch.int8",
            "+        ):",
            "hidden_states = hidden_states.to(self.wo.weight.dtype)",
            "",
            "hidden_states = self.wo(hidden_states)"
        ],
        "comments": "change condition check for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1047,
        "label": "no",
        "change": [
            "def _scale_channel(im: torch.Tensor) -> torch.Tensor:",
            "",
            "im = im * 255",
            "# Compute the histogram of the image channel.",
            "-    histo = torch.histc(im, bins=256, min=0, max=255)",
            "+    histo = _torch_histc_cast(im, bins=256, min=0, max=255)",
            "# For the purposes of computing the step, filter out the nonzeros.",
            "nonzero_histo = torch.reshape(histo[histo != 0], [-1])",
            "step = (torch.sum(nonzero_histo) - nonzero_histo[-1]) // 255"
        ],
        "comments": "use custom api",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1048,
        "label": "no",
        "change": [
            "def vector_to_skew_symmetric_matrix(vector):",
            "a2s = vector_expanded[..., 1:2, :]",
            "a3s = vector_expanded[..., 2:3, :]",
            "# BS x 1 x 1",
            "-    zs = torch.zeros(batch_shape + [1, 1])",
            "+    zs = torch.zeros(batch_shape + [1, 1], device=vector.device)",
            "# BS x 1 x 3",
            "row1 = torch.cat((zs, -a3s, a2s), -1)",
            "row2 = torch.cat((a3s, zs, -a1s), -1)"
        ],
        "comments": "add param for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1049,
        "label": "no",
        "change": [
            "class YOLOLayer(nn.Module):",
            "w = prediction[..., 2]  # Width",
            "h = prediction[..., 3]  # Height",
            "pred_conf = torch.sigmoid(prediction[..., 4])  # Conf",
            "-        pred_cls = torch.sigmoid(prediction[..., 5:]        ByteTensor = torch.cuda.ByteTensor if x.is_cuda else torch.ByteTensor)  # Cls pred.",
            "+        pred_cls = torch.sigmoid(prediction[..., 5:])  # Cls pred.",
            "",
            "# If grid size does not match current we compute new offsets",
            "if grid_size != self.grid_size:"
        ],
        "comments": "add comment",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1050,
        "label": "yes",
        "change": [
            "class PointAssigner(BaseAssigner):",
            "",
            "if gt_labels is not None:",
            "assigned_labels = assigned_gt_inds.new_full((num_points, ), -1)",
            "-            pos_inds = torch.nonzero(assigned_gt_inds > 0).squeeze()",
            "+            pos_inds = torch.nonzero(",
            "+                assigned_gt_inds > 0, as_tuple=False).squeeze()",
            "if pos_inds.numel() > 0:",
            "assigned_labels[pos_inds] = gt_labels[",
            "assigned_gt_inds[pos_inds] - 1]"
        ],
        "comments": "add param for type fix",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1052,
        "label": "yes",
        "change": [
            "def att_to_numpy(att_ws, att):",
            "att_ws = torch.stack([aw[:, -1] for aw in att_ws], dim=1).cpu().numpy()",
            "elif isinstance(att, (AttCov, AttCovLoc)):",
            "# att_ws => list of list of previous attentions",
            "-        att_ws = torch.stack([aw[-1] for aw in att_ws], dim=1).cpu().numpy()",
            "+        att_ws = torch.stack([aw[idx] for idx, aw in enumerate(att_ws)], dim=1).cpu().numpy()",
            "elif isinstance(att, AttLocRec):",
            "# att_ws => list of tuple of attention and hidden states",
            "att_ws = torch.stack([aw[0] for aw in att_ws], dim=1).cpu().numpy()"
        ],
        "comments": "change param for shape fix",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 1053,
        "label": "no",
        "change": [
            "def main():",
            "# train",
            "logging.info('backend = ' + args.backend)",
            "if args.backend == \"chainer\":",
            "-        from espnet.asr.chain.asr_chainer import train",
            "+        from espnet.asr.chain.asr import train",
            "train(args)",
            "elif args.backend == \"pytorch\":",
            "-        from espnet.asr.pytorch.asr_pytorch import train",
            "+        from espnet.asr.pytorch.asr import train",
            "train(args)",
            "else:",
            "raise ValueError(\"Only chainer and pytorch are supported.\")"
        ],
        "comments": "refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1054,
        "label": "no",
        "change": [
            "class HestonModel(generic_ito_process.GenericItoProcess):",
            "drift = tf.stack([log_spot_drift, var_drift], -1)",
            "return drift",
            "",
            "-    super(HestonModel, self).__init__(2, _drift_fn, _vol_fn, dtype, name)",
            "+    super(HestonModel, self).__init__(2, _drift_fn, _vol_fn, self._dtype, name)",
            "",
            "def sample_paths(self,",
            "times: types.RealTensor,"
        ],
        "comments": "change param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1055,
        "label": "no",
        "change": [
            "def test_gaussian_mixture_model():",
            "cluster_assignments = dist.Categorical(true_mix_proportions).sample(torch.Size((N,)))",
            "data = dist.Normal(true_cluster_means[cluster_assignments], 1.0).sample()",
            "hmc_kernel = HMC(gmm, trajectory_length=1, adapt_step_size=True, max_iarange_nesting=1)",
            "-    mcmc_run = MCMC(hmc_kernel, num_samples=600, warmup_steps=200).run(data)",
            "+    mcmc_run = MCMC(hmc_kernel, num_samples=300, warmup_steps=100).run(data)",
            "posterior = EmpiricalMarginal(mcmc_run, sites=[\"phi\", \"cluster_means\"]).mean.sort()[0]",
            "assert_equal(posterior[0], true_mix_proportions, prec=0.05)",
            "assert_equal(posterior[1], true_cluster_means, prec=0.2)"
        ],
        "comments": "value change",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1056,
        "label": "no",
        "change": [
            "class SimilarityLearner(flair.nn.Model):",
            "epoch_results_str,",
            "detailed_results,",
            "),",
            "-            0,",
            "+            torch.tensor(0),",
            ")",
            "",
            "def _get_state_dict(self):"
        ],
        "comments": "add API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1059,
        "label": "no",
        "change": [
            "class TFOPTDecoder(tf.keras.layers.Layer):",
            "if output_attentions:",
            "all_self_attns += (layer_self_attn,)",
            "",
            "+        if self.final_layer_norm is not None:",
            "+            hidden_states = self.final_layer_norm(hidden_states)",
            "+",
            "if self.project_out is not None:",
            "hidden_states = self.project_out(hidden_states)"
        ],
        "comments": "add condition check for null fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1060,
        "label": "no",
        "change": [
            "def convert_examples_to_features(examples, seq_length, tokenizer):",
            "if ex_index < 5:",
            "tf.logging.info(\"*** Example ***\")",
            "tf.logging.info(\"unique_id: %s\" % (example.unique_id))",
            "-      tf.logging.info(\"tokens: %s\" % \" \".join([str(x) for x in tokens]))",
            "+      tf.logging.info(\"tokens: %s\" % \" \".join(",
            "+          [tokenization.printable_text(x) for x in tokens]))",
            "tf.logging.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))",
            "tf.logging.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))",
            "tf.logging.info("
        ],
        "comments": "change API call for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1062,
        "label": "no",
        "change": [
            "logger = logging.getLogger(__name__)",
            "# for the pretrained weights provided with the models",
            "####################################################",
            "T5_PRETRAINED_MODEL_ARCHIVE_MAP = {",
            "-    \"t5-small\": \"https://s3.amazonaws.com/models.huggingface.co/bert/t5-small-pytorch_model.bin\",",
            "-    \"t5-base\": \"https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-pytorch_model.bin\",",
            "-    \"t5-large\": \"https://s3.amazonaws.com/models.huggingface.co/bert/t5-large-pytorch_model.bin\",",
            "-    \"t5-3b\": \"https://s3.amazonaws.com/models.huggingface.co/bert/t5-3b-pytorch_model.bin\",",
            "-    \"t5-11b\": \"https://s3.amazonaws.com/models.huggingface.co/bert/t5-11b-pytorch_model.bin\",",
            "+    \"t5-small\": \"https://cdn.huggingface.co/t5-small-pytorch_model.bin\",",
            "+    \"t5-base\": \"https://cdn.huggingface.co/t5-base-pytorch_model.bin\",",
            "+    \"t5-large\": \"https://cdn.huggingface.co/t5-large-pytorch_model.bin\",",
            "+    \"t5-3b\": \"https://cdn.huggingface.co/t5-3b-pytorch_model.bin\",",
            "+    \"t5-11b\": \"https://cdn.huggingface.co/t5-11b-pytorch_model.bin\",",
            "}"
        ],
        "comments": "doc",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1064,
        "label": "yes",
        "change": [
            "def load_model(filepath, custom_optimizers=None, custom_objects=None, compressio",
            "\"\"\"",
            "def wrap_optimizer(cls):",
            "return lambda **kwargs: DistributedOptimizer(cls(**kwargs), compression=compression)",
            "-    return _impl.load_model(keras, wrap_optimizer, filepath, custom_optimizers, custom_objects)",
            "+    optimizer_modules = {keras.optimizers.Optimizer.__module__}",
            "+    return _impl.load_model(keras, wrap_optimizer, optimizer_modules, filepath, custom_optimizers, custom_objects)"
        ],
        "comments": "add param for argument fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 1065,
        "label": "no",
        "change": [
            "class ParabolicEquationStepperTest(tf.test.TestCase, parameterized.TestCase):",
            "second_order_coeff_fn=second_order_coeff_fn,",
            "inner_first_order_coeff_fn=inner_first_order_coeff_fn)[0]",
            "",
            "-    true_values = tf.math.exp(final_t + grid[0])",
            "+    true_values = tf.expand_dims(tf.math.exp(final_t + grid[0]), axis=0)",
            "self.assertAllClose(",
            "est_values, true_values, atol=1e-2, rtol=1e-2)"
        ],
        "comments": "add API call for shape fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1066,
        "label": "yes",
        "change": [
            "class LocalMultiGPUOptimizer(PolicyOptimizer):",
            "else:",
            "rnn_inputs = []",
            "self.par_opt = LocalSyncParallelOptimizer(",
            "-                        tf.train.AdamOptimizer(",
            "-                            self.sgd_stepsize), self.devices,",
            "+                        self.policy.optimizer(), self.devices,",
            "[v for _, v in self.policy.loss_inputs()], rnn_inputs,",
            "self.per_device_batch_size, self.policy.copy,",
            "os.getcwd())"
        ],
        "comments": "change API call for math fix",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1067,
        "label": "no",
        "change": [
            "class DistributedReplicatedBuilder(DataParallelBuilder):",
            "return grads",
            "",
            "# Ngpu * Nvar * 2",
            "-        grad_list = self.build_on_multi_tower(",
            "-            get_grads,",
            "+        grad_list = DataParallelBuilder.build_on_towers(",
            "+            self.towers, get_grads,",
            "devices=self.raw_devices,",
            "use_vs=[True] * len(self.towers))  # open vs at each tower",
            "DataParallelBuilder._check_grad_list(grad_list)"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1069,
        "label": "no",
        "change": [
            "class OPTForSequenceClassification(OPTPreTrainedModel):",
            "sequence_lengths = -1",
            "else:",
            "if input_ids is not None:",
            "-                sequence_lengths = torch.ne(input_ids, self.config.pad_token_id).sum(-1) - 1",
            "+                sequence_lengths = (torch.ne(input_ids, self.config.pad_token_id).sum(-1) - 1).to(logits.device)",
            "else:",
            "sequence_lengths = -1",
            "logger.warning("
        ],
        "comments": "add API call for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1071,
        "label": "no",
        "change": [
            "def vector_norm(x: Tensor,",
            "tn_normalized_vector = tf.linalg.norm(x,p,axis,keepdims)",
            "",
            "if tn_normalized_vector.shape  == tuple():",
            "-        return  tf.expand_dims(tn_normalized_vector, 0)",
            "+        return tf.expand_dims(tn_normalized_vector, 0)",
            "return tn_normalized_vector"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1072,
        "label": "no",
        "change": [
            "def test_discrete_parallel(continuous_class):",
            "",
            "def model(data):",
            "weights = pyro.sample('weights', dist.Dirichlet(0.5 * torch.ones(K)))",
            "-        locs = pyro.sample('locs', dist.Normal(0, 10).reshape([K], extra_event_dims=1))",
            "+        locs = pyro.sample('locs', dist.Normal(0, 10).expand_by([K]).independent(1))",
            "scale = pyro.sample('scale', dist.LogNormal(0, 1))",
            "",
            "with pyro.iarange('data', len(data)):"
        ],
        "comments": "change API call for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1073,
        "label": "no",
        "change": [
            "class FBetaMeasure(Metric):",
            "self._total_sum = torch.zeros(num_classes, device=predictions.device)",
            "",
            "if mask is None:",
            "-            mask = torch.ones_like(gold_labels)",
            "-        mask = mask.to(dtype=torch.bool)",
            "+            mask = torch.ones_like(gold_labels).bool()",
            "gold_labels = gold_labels.float()",
            "",
            "argmax_predictions = predictions.max(dim=-1)[1].float()",
            "-        true_positives = (gold_labels == argmax_predictions) * mask",
            "+        true_positives = (gold_labels == argmax_predictions) & mask",
            "true_positives_bins = gold_labels[true_positives]",
            "",
            "# Watch it:"
        ],
        "comments": "refactor",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1075,
        "label": "no",
        "change": [
            "class RenyiELBO(ELBO):",
            "surrogate_elbo_particles = torch.stack(surrogate_elbo_particles)",
            "",
            "log_weights = (1. - self.alpha) * elbo_particles",
            "-        log_mean_weight = logsumexp(log_weights, dim=0) - math.log(self.num_particles)",
            "+        log_mean_weight = torch.logsumexp(log_weights, dim=0) - math.log(self.num_particles)",
            "elbo = log_mean_weight.sum().item() / (1. - self.alpha)",
            "",
            "# collect parameters to train from model and guide"
        ],
        "comments": "version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1077,
        "label": "yes",
        "change": [
            "class MaskTokensDataset(BaseWrapperDataset):",
            "if self.mask_whole_words is not None:",
            "mask = np.repeat(mask, word_lens)",
            "new_item = np.full(len(mask), self.pad_idx)",
            "-                new_item[mask] = item[torch.from_numpy(mask)]",
            "+                new_item[mask] = item[torch.from_numpy(mask.astype(np.uint8))]",
            "return torch.from_numpy(new_item)",
            "",
            "# decide unmasking and random replacement"
        ],
        "comments": "add API call for type fix",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 1078,
        "label": "no",
        "change": [
            "class IoUBalancedNegSampler(RandomSampler):",
            "return sampled_inds",
            "",
            "def _sample_neg(self, assign_result, num_expected, **kwargs):",
            "+        \"\"\"Sample negative boxes",
            "+",
            "+        Args:",
            "+            assign_result (:obj:`AssignResult`): The assigned results of boxes.",
            "+            num_expected (int): The number of expected negative samples",
            "+",
            "+        Returns:",
            "+            Tensor or ndarray: sampled indices.",
            "+        \"\"\"",
            "neg_inds = torch.nonzero(assign_result.gt_inds == 0, as_tuple=False)",
            "if neg_inds.numel() != 0:",
            "neg_inds = neg_inds.squeeze(1)"
        ],
        "comments": "doc",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1079,
        "label": "yes",
        "change": [
            "def _sample_coalescent_times(leaf_times):",
            "coal_times.append(t)",
            "coal_times.reverse()",
            "",
            "-    return torch.tensor(coal_times)",
            "+    return proto.new_tensor(coal_times)"
        ],
        "comments": "change API call for refactor fix",
        "Symptom": "return warning",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 1080,
        "label": "no",
        "change": [
            "def transform(point, center, scale, resolution, invert=False):",
            "return new_point.int()",
            "",
            "",
            "-def crop(image, center, scale, resolution=256):",
            "+def crop(image, center, scale, resolution=256.0):",
            "# Crop around the center point",
            "\"\"\" Crops the image around the center. Input is expected to be an np.ndarray \"\"\"",
            "ul = transform([1, 1], center, scale, resolution, True)",
            "br = transform([resolution, resolution], center, scale, resolution, True)",
            "-    pad = math.ceil(torch.norm((ul - br).float()) / 2 - (br[0] - ul[0]) / 2)",
            "+    pad = math.ceil(torch.norm((ul - br).float()) / 2.0 - (br[0] - ul[0]) / 2.0)",
            "if image.ndim > 2:",
            "newDim = np.array([br[1] - ul[1], br[0] - ul[0],",
            "image.shape[2]], dtype=np.int32)"
        ],
        "comments": "def",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1082,
        "label": "no",
        "change": [
            "class LongformerEmbeddings(nn.Module):",
            "\"\"\"We are provided embeddings directly. We cannot infer which are padded so just generate",
            "sequential position ids.",
            "",
            "-        :param torch.Tensor inputs_embeds:",
            "-        :return torch.Tensor:",
            "+        Args:",
            "+            inputs_embeds: torch.Tensor inputs_embeds:",
            "+",
            "+        Returns: torch.Tensor",
            "\"\"\"",
            "input_shape = inputs_embeds.size()[:-1]",
            "sequence_length = input_shape[1]"
        ],
        "comments": "doc",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1083,
        "label": "no",
        "change": [
            "class CategoricalAccuracy(Metric):",
            "# ith entry in gold_labels points to index (0-num_classes) for ith row in max_predictions",
            "# For each row check if index pointed by gold_label is was 1 or not (among max scored classes)",
            "correct = max_predictions_mask[",
            "-                torch.arange(gold_labels.numel()).long(), gold_labels",
            "+                torch.arange(gold_labels.numel(), device=gold_labels.device).long(), gold_labels",
            "].float()",
            "tie_counts = max_predictions_mask.sum(-1)",
            "correct /= tie_counts.float()"
        ],
        "comments": "add param for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1086,
        "label": "no",
        "change": [
            "class DoublePoolBatchSampler(Sampler[List[int]]):",
            "torch.randperm(len(self.first_indices), generator=self.generator)",
            "for _ in range(n_copies)",
            "]",
            "-            i_first = torch.concat(raw_indices)[:num_batches]",
            "+            i_first = torch.cat(raw_indices)[:num_batches]",
            "else:",
            "i_first = torch.randperm(len(self.first_indices), generator=self.generator)",
            "first_indices = [self.first_indices[i] for i in i_first]"
        ],
        "comments": "typo fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1087,
        "label": "no",
        "change": [
            "def proposal_layer_tf(rpn_cls_prob, rpn_bbox_pred, im_info, cfg_key, _feat_strid",
            "proposals = bbox_transform_inv_tf(anchors, rpn_bbox_pred)",
            "proposals = clip_boxes_tf(proposals, im_info[:2])",
            "",
            "-  indices = tf.image.non_max_suppression(rpn_bbox_pred, scores, max_output_size=post_nms_topN, iou_threshold=nms_thresh)",
            "+  indices = tf.image.non_max_suppression(proposals, scores, max_output_size=post_nms_topN, iou_threshold=nms_thresh)",
            "",
            "-  boxes = tf.gather(rpn_bbox_pred, indices)",
            "+  boxes = tf.gather(proposals, indices)",
            "boxes = tf.to_float(boxes)",
            "scores = tf.gather(scores, indices)",
            "scores = tf.reshape(scores, shape=(-1, 1))"
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1089,
        "label": "yes",
        "change": [
            "class MultiplexerLayer(Layer):",
            ">>> network = tl.layers.ReshapeLayer(net_mux, shape=(-1, 800), name='reshape')",
            ">>> network = tl.layers.DropoutLayer(network, keep=0.5, name='drop3')",
            ">>> # output layer",
            "-    >>> network = tl.layers.DenseLayer(network, n_units=10, act=tf.identity, name='output')",
            "+    >>> network = tl.layers.DenseLayer(network, n_units=10, act=None, name='output')",
            "",
            "\"\"\"",
            "",
            "def __init__(self, layers, name='mux_layer'):",
            "super(MultiplexerLayer, self).__init__(prev_layer=layers, name=name)",
            "+",
            "self.n_inputs = len(layers)",
            "",
            "self.inputs = []",
            "+",
            "for l in layers:",
            "self.inputs.append(l.outputs)",
            "+",
            "try:  # TF1.0",
            "all_inputs = tf.stack(self.inputs, name=name)  # pack means concat a list of tensor in a new dim  # 1.2",
            "except Exception:"
        ],
        "comments": "doc",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 1091,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            ".GlobalAvgPooling('gap')",
            ".FullyConnected('linear', 1000, nl=tf.identity)())",
            "",
            "-        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, label)",
            "+        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)",
            "loss = tf.reduce_mean(loss, name='xentropy-loss')",
            "",
            "wrong = prediction_incorrect(logits, label, 1, name='wrong-top1')"
        ],
        "comments": "add param for argument fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1094,
        "label": "yes",
        "change": [
            "def batchnorm_example(optimizer_fn,",
            "for z in range(batch_per_epoch)]).repeat()",
            "",
            "optimizer = optimizer_fn()",
            "-  batchnorm = tf.compat.v1.layers.BatchNormalization(",
            "+  batchnorm = normalization.BatchNormalization(",
            "renorm=renorm, momentum=momentum, fused=False)",
            "-  layer = tf.compat.v1.layers.Dense(1, use_bias=False)",
            "+  layer = core.Dense(1, use_bias=False)",
            "",
            "def model_fn(x):",
            "\"\"\"A model that uses batchnorm.\"\"\""
        ],
        "comments": "change API call for version fix",
        "Symptom": "program crash",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1096,
        "label": "no",
        "change": [
            "class TestDistributions(unittest.TestCase):",
            "def test_categorical(self):",
            "\"\"\"Tests the Categorical ActionDistribution (tf only).\"\"\"",
            "num_samples = 100000",
            "-        logits = tf.placeholder(tf.float32, shape=(None, 10))",
            "+        logits = tf1.placeholder(tf.float32, shape=(None, 10))",
            "z = 8 * (np.random.rand(10) - 0.5)",
            "data = np.tile(z, (num_samples, 1))",
            "c = Categorical(logits, {})  # dummy config dict",
            "sample_op = c.sample()",
            "-        sess = tf.Session()",
            "-        sess.run(tf.global_variables_initializer())",
            "+        sess = tf1.Session()",
            "+        sess.run(tf1.global_variables_initializer())",
            "samples = sess.run(sample_op, feed_dict={logits: data})",
            "counts = np.zeros(10)",
            "for sample in samples:"
        ],
        "comments": "version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1097,
        "label": "no",
        "change": [
            "def trace(",
            "[7., 8.]]])",
            ">>> y = ivy.trace(x, offset=1)",
            ">>> print(y)",
            "-    ivy.array([2., 6.])",
            "+    ivy.array([3., 4.])",
            "",
            "With :class:`ivy.NativeArray` inputs:"
        ],
        "comments": "value update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1099,
        "label": "no",
        "change": [
            "class TFGPT2ModelTest(TFModelTesterMixin, unittest.TestCase):",
            "output_from_past_slice = output_from_past[:, 0, random_slice_idx]",
            "",
            "# test that outputs are equal for slice",
            "-            tf.debugging.assert_near(output_from_past_slice, output_from_no_past_slice, rtol=1e-12)",
            "+            tf.debugging.assert_near(output_from_past_slice, output_from_no_past_slice, rtol=1e-6)",
            "",
            "def create_and_check_gpt2_model_attention_mask_past(",
            "self, config, input_ids, input_mask, head_mask, token_type_ids, *args"
        ],
        "comments": "value update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1100,
        "label": "no",
        "change": [
            "class TorchHook(object):",
            "",
            "self._hook_torch_module()",
            "",
            "+        if torch.torch_hooked > 0:",
            "+            raise Exception('Torch was already hooked')",
            "+",
            "def _hook_native_tensors_and_variables(self, tensor_type):",
            "\"\"\"Overloading a given tensor_type\"\"\"",
            "# Overload 'special' methods here"
        ],
        "comments": "add condition check for state fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1101,
        "label": "no",
        "change": [
            "class TextGenerationPipelineTests(unittest.TestCase, metaclass=PipelineTestCaseM",
            "],",
            ")",
            "",
            "-        # torch_dtype not necessary",
            "+        # torch_dtype will be automatically set to float32 if not provided - check: https://github.com/huggingface/transformers/pull/20602",
            "pipe = pipeline(model=\"hf-internal-testing/tiny-random-bloom\", device_map=\"auto\")",
            "self.assertEqual(pipe.model.device, torch.device(0))",
            "-        self.assertEqual(pipe.model.lm_head.weight.dtype, torch.bfloat16)",
            "+        self.assertEqual(pipe.model.lm_head.weight.dtype, torch.float32)",
            "out = pipe(\"This is a test\")",
            "self.assertEqual(",
            "out,"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1102,
        "label": "no",
        "change": [
            "class SphericalAdj(object):",
            "phi = torch.acos(direction[:, 2]) / PI",
            "spherical = torch.stack([rho, theta, phi], dim=1)",
            "",
            "-        # Modify data and return.",
            "-        data.adj = SparseTensor(index, spherical, torch.Size([n, n, 3]))",
            "-        return data",
            "+        return SparseTensor(index, spherical, torch.Size([n, n, 3]))"
        ],
        "comments": "version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1103,
        "label": "no",
        "change": [
            "def test_devices_auto_choice_mps():",
            "",
            "@pytest.mark.parametrize(",
            "[\"parallel_devices\", \"accelerator\"],",
            "-    [([torch.device(\"cpu\")], \"cuda\"), ([torch.device(\"cuda\", i) for i in range(8)], (\"tpu\"))],",
            "+    [([torch.device(\"cpu\")], \"cuda\"), ([torch.device(\"cuda\", i) for i in range(8)], \"tpu\")],",
            ")",
            "def test_parallel_devices_in_strategy_confilict_with_accelerator(parallel_devices, accelerator):",
            "with pytest.raises(MisconfigurationException, match=r\"parallel_devices set through\"):"
        ],
        "comments": "no API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1104,
        "label": "no",
        "change": [
            "class EpsilonDecay(Exploration):",
            "",
            "pred = tf.logical_or(x=(timestep < self.start_timestep),",
            "y=(timestep > self.start_timestep + int(self.timesteps)))",
            "-        return tf.cond(pred=pred, true_fn=true_fn, false_fn=false_fn)",
            "+        return tf.fill(dims=shape, value=tf.cond(pred=pred, true_fn=true_fn, false_fn=false_fn))"
        ],
        "comments": "change API call for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1105,
        "label": "no",
        "change": [
            "import itertools",
            "",
            "import torch",
            "",
            "+def is_cuda_enabled():",
            "+    return torch.version.cuda is not None",
            "+",
            "def get_cuda_version():",
            "return tuple(int(x) for x in torch.version.cuda.split('.'))"
        ],
        "comments": "def",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1106,
        "label": "no",
        "change": [
            "def fft(",
            "*,",
            "norm: Optional[str] = \"backward\",",
            "n: Union[int, Tuple[int]] = None,",
            "-    out: Optional[torch.Tensor] = None",
            "+    out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "if not isinstance(dim, int):",
            "raise ivy.exceptions.IvyError(f\"Expecting <class 'int'> instead of {type(dim)}\")",
            "if n is None:",
            "n = x.shape[dim]",
            "-    if n < -len(x.shape) :",
            "+    if n < -len(x.shape):",
            "raise ivy.exceptions.IvyError(",
            "f\"Invalid dim {dim}, expecting ranging\"",
            "\" from {-len(x.shape)} to {len(x.shape)-1}  \"",
            ")",
            "if not isinstance(n, int):",
            "raise ivy.exceptions.IvyError(f\"Expecting <class 'int'> instead of {type(n)}\")",
            "-    if n <= 1 :",
            "+    if n <= 1:",
            "raise ivy.exceptions.IvyError(f\"Invalid data points {n}, expecting more than 1\")",
            "if norm != \"backward\" and norm != \"ortho\" and norm != \"forward\":",
            "raise ivy.exceptions.IvyError(f\"Unrecognized normalization mode {norm}\")"
        ],
        "comments": "doc",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1108,
        "label": "no",
        "change": [
            "class _QueueRunner(threading.Thread):",
            "self.placeholders = [tf1.placeholder(dtype) for dtype in dtypes]",
            "self.enqueue_op = queue.enqueue(dict(zip(keys, self.placeholders)))",
            "",
            "-    def enqueue(self, batch):",
            "+    def enqueue(self, batch: SampleBatchType):",
            "data = {",
            "self.placeholders[i]: batch[key]",
            "for i, key in enumerate(self.keys)"
        ],
        "comments": "def",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1109,
        "label": "no",
        "change": [
            "if __name__ == '__main__':",
            "help='number of steps between parameter saves')",
            "parser.add_argument('--cuda', action='store_true', default=False,",
            "help='use cuda')",
            "+    parser.add_argument('--jit', action='store_true', default=False,",
            "+                        help='use PyTorch jit')",
            "parser.add_argument('-t', '--model-steps', type=int, default=3,",
            "help='number of time steps')",
            "parser.add_argument('--rnn-hidden-size', type=int, default=256,"
        ],
        "comments": "add argument for param",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1110,
        "label": "no",
        "change": [
            "class Sequential(functional.Functional):",
            "# invalid use case of Sequential, but we tolerate it for backwards",
            "# compatibility.",
            "self._use_legacy_deferred_behavior = True",
            "-        self._build_input_shape = tf.nest.map_structure(_get_shape_tuple, inputs)",
            "+        self._build_input_shape = tf.nest.map_structure(",
            "+            _get_shape_tuple, inputs)",
            "if tf.__internal__.tf2.enabled():",
            "logging.warning('Layers in a Sequential model should only have a '",
            "-                          'single input tensor, but we receive a %s input: %s'",
            "-                          '\\nConsider rewriting this model with the Functional '",
            "-                          'API.' % (type(inputs), inputs))",
            "+                          f'single input tensor. Received: inputs={inputs}. '",
            "+                          'Consider rewriting this model with the Functional '",
            "+                          'API.')",
            "else:",
            "self._build_graph_network_for_inferred_shape(inputs.shape, inputs.dtype)"
        ],
        "comments": "format",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1111,
        "label": "no",
        "change": [
            "class CartesianAdj(object):",
            "cartesian *= 1 / (2 * cartesian.abs().max())",
            "cartesian += 0.5",
            "",
            "-        # Modify data and return.",
            "-        data.adj = SparseTensor(index, cartesian, torch.Size([n, n, dim]))",
            "-        return data",
            "+        return SparseTensor(index, cartesian, torch.Size([n, n, dim]))"
        ],
        "comments": "version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1113,
        "label": "no",
        "change": [
            "class TFXLNetFeedForward(tf.keras.layers.Layer):",
            ")",
            "self.dropout = tf.keras.layers.Dropout(config.dropout)",
            "if isinstance(config.ff_activation, str):",
            "-            self.activation_function = ACT2FN[config.ff_activation]",
            "+            self.activation_function = get_tf_activation(config.ff_activation)",
            "else:",
            "self.activation_function = config.ff_activation"
        ],
        "comments": "customize method",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1114,
        "label": "no",
        "change": [
            "class Stft(torch.nn.Module, InversibleInterface):",
            "pad = self.n_fft // 2",
            "ilens = ilens + 2 * pad",
            "",
            "-            olens = (",
            "-                torch.div((ilens - self.n_fft), self.hop_length, rounding_mode=\"floor\")",
            "-                + 1",
            "-            )",
            "+            olens = torch.div((ilens - self.n_fft), self.hop_length) + 1",
            "output.masked_fill_(make_pad_mask(olens, output, 1), 0.0)",
            "else:",
            "olens = None"
        ],
        "comments": "remove param for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1117,
        "label": "no",
        "change": [
            "class MultilingualCLIPModel(CLIPModel):",
            "input_ids=input_ids, attention_mask=attention_mask, **kwargs",
            ")",
            "",
            "-    def encode_image(self, pixel_values: torch.Tensor, **kwargs):",
            "+    def encode_image(self, pixel_values: torch.Tensor):",
            "return self._model.encode_image(pixel_values)"
        ],
        "comments": "def",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1118,
        "label": "no",
        "change": [
            "def _scale_channel(im: torch.Tensor) -> torch.Tensor:",
            "# and then normalization by step.",
            "lut = (torch.cumsum(histo, 0) + (step // 2)) // step",
            "# Shift lut, prepending with 0.",
            "-        lut = torch.cat([torch.zeros(1, device=lut.device), lut[:-1]])",
            "+        lut = torch.cat([torch.zeros(1, device=lut.device, dtype=lut.dtype), lut[:-1]])",
            "# Clip the counts to be in range.  This is done",
            "# in the C code for image.point.",
            "return torch.clamp(lut, 0, 255)"
        ],
        "comments": "add param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1121,
        "label": "no",
        "change": [
            "def scatter_nd(",
            "*[",
            "torch.range(0, s - 1)",
            "if idx == slice(None, None, None)",
            "-                                else torch.Tensor([idx % s])",
            "+                                else torch.tensor([idx % s])",
            "for s, idx in zip(shape, index)",
            "],",
            "indexing=\"xy\","
        ],
        "comments": "typo fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1122,
        "label": "no",
        "change": [
            "class DonutSwinLayer(nn.Module):",
            "# partition windows",
            "hidden_states_windows = window_partition(shifted_hidden_states, self.window_size)",
            "hidden_states_windows = hidden_states_windows.view(-1, self.window_size * self.window_size, channels)",
            "-        attn_mask = self.get_attn_mask(height_pad, width_pad)",
            "+        attn_mask = self.get_attn_mask(height_pad, width_pad, dtype=hidden_states.dtype)",
            "if attn_mask is not None:",
            "attn_mask = attn_mask.to(hidden_states_windows.device)"
        ],
        "comments": "add param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1125,
        "label": "no",
        "change": [
            "def max_value_as_shape_prod(draw):",
            "",
            "",
            "@handle_test(",
            "-    fn_tree=\"functional.ivy.experimental.nanmean\",",
            "+    fn_tree=\"functional.ivy.experimental.unravel_index\",",
            "dtype_x_shape=max_value_as_shape_prod(),",
            "test_gradients=st.just(False),",
            ")"
        ],
        "comments": "no API",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1126,
        "label": "no",
        "change": [
            "for it in range(1000000):",
            "D_reg = D(G_sample_reg)",
            "",
            "mse = torch.sum((X - G_sample_reg)**2, 1)",
            "-    E_loss = torch.mean(lam1 * mse + lam2 * D_reg)",
            "+    E_loss = torch.mean(lam1 * mse + lam2 * log(D_reg))",
            "",
            "E_loss.backward()",
            "E_solver.step()"
        ],
        "comments": "add API call for math fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1127,
        "label": "no",
        "change": [
            "class VisualBertEmbeddings(nn.Module):",
            "inputs_embeds = self.word_embeddings(input_ids)",
            "",
            "if token_type_ids is None:",
            "-            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.input_embeds.device)",
            "+            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=self.position_ids.device)",
            "",
            "token_type_embeddings = self.token_type_embeddings(token_type_ids)"
        ],
        "comments": "change param for resource fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1128,
        "label": "yes",
        "change": [
            "class BCELossMasked(nn.Module):",
            "Returns:",
            "loss: An average loss value in range [0, 1] masked by the length.",
            "\"\"\"",
            "-        # mask: (batch, max_len, 1)",
            "target.requires_grad = False",
            "if length is not None:",
            "-            mask = sequence_mask(sequence_length=length, max_len=target.size(1)).float()",
            "-            x = x * mask",
            "-            target = target * mask",
            "+            # mask: (batch, max_len, 1)",
            "+            mask = sequence_mask(sequence_length=length, max_len=target.size(1))",
            "num_items = mask.sum()",
            "+            loss = functional.binary_cross_entropy_with_logits(x.masked_select(mask), target.masked_select(mask), pos_weight=self.pos_weight, reduction=\"sum\")",
            "else:",
            "+            loss = functional.binary_cross_entropy_with_logits(x, target, pos_weight=self.pos_weight, reduction=\"sum\")",
            "num_items = torch.numel(x)",
            "-        loss = functional.binary_cross_entropy_with_logits(x, target, pos_weight=self.pos_weight, reduction=\"sum\")",
            "loss = loss / num_items",
            "return loss"
        ],
        "comments": "remove API call for type fix",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1129,
        "label": "no",
        "change": [
            "class PrioritizedReplay(Memory):",
            "))",
            "",
            "with tf.control_dependencies(control_inputs=assignments):",
            "-            return tf.no_op()",
            "+            return util.no_operation()",
            "",
            "# These are not supported for prioritized replay currently.",
            "def tf_retrieve_episodes(self, n):"
        ],
        "comments": "change API call for refactor fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1130,
        "label": "yes",
        "change": [
            "def get_module_name(cls):",
            "f'please launch the experiment under the directory where \"{main_file_path.name}\" is located.')",
            "module_name = main_file_path.stem",
            "break",
            "+    if module_name == '__main__':",
            "+        warnings.warn('Callstack exhausted but main module still not found. This will probably cause issues that the '",
            "+                      'function/class cannot be imported.')",
            "",
            "# NOTE: this is hacky. As torchscript retrieves LSTM's source code to do something.",
            "# to make LSTM's source code can be found, we should assign original LSTM's __module__ to",
            "# the wrapped LSTM's __module__",
            "# TODO: find out all the modules that have the same requirement as LSTM",
            "-    if f'{cls.__module__}.{cls.__name__}' == 'torch.nn.modules.rnn.LSTM':",
            "-        module_name = cls.__module__",
            "+    if f'{cls_or_func.__module__}.{cls_or_func.__name__}' == 'torch.nn.modules.rnn.LSTM':",
            "+        module_name = cls_or_func.__module__",
            "",
            "return module_name",
            "",
            "",
            "-def get_full_class_name(cls, relocate_module=False):",
            "+def get_importable_name(cls, relocate_module=False):",
            "module_name = get_module_name(cls) if relocate_module else cls.__module__",
            "return module_name + '.' + cls.__name__"
        ],
        "comments": "no API",
        "Symptom": "return warning",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api condition check"
    },
    {
        "number": 1131,
        "label": "no",
        "change": [
            "class OnebitAdam(torch.optim.Optimizer):",
            "self.adam_freeze_key = False",
            "self.initialize = True",
            "print(",
            "-                f\"Finished the initialization step at rant {torch.distributed.get_rank()}\"",
            "+                f\"Finished the initialization step at rank {torch.distributed.get_rank()}\"",
            ")",
            "return loss"
        ],
        "comments": "doc update",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1132,
        "label": "no",
        "change": [
            "class TFFastSpeech(tf.keras.Model):",
            "== config.decoder_self_attention_params.hidden_size,",
            "name=\"decoder\",",
            ")",
            "-        self.mel_dense = tf.keras.layers.Dense(units=config.num_mels, name=\"mel_before\")",
            "-        self.postnet = TFTacotronPostnet(config=config, name=\"postnet\")",
            "+        self.mel_dense = tf.keras.layers.Dense(units=config.num_mels, dtype=tf.float32, name=\"mel_before\")",
            "+        self.postnet = TFTacotronPostnet(config=config, dtype=tf.float32, name=\"postnet\")",
            "",
            "self.setup_inference_fn()"
        ],
        "comments": "add param for type fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1134,
        "label": "no",
        "change": [
            "def test_neighbor_sampler_on_cora(get_dataset):",
            "_, n_id, adjs = next(iter(loader))",
            "out1 = model.batch(data.x[n_id], adjs)",
            "out2 = model.full(data.x, data.edge_index)[batch]",
            "-    assert torch.allclose(out1, out2)",
            "+    assert torch.allclose(out1, out2, atol=1e-7)"
        ],
        "comments": "asset",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1136,
        "label": "no",
        "change": [
            "def main():",
            "",
            "model.eval()",
            "with open(args.output_file, \"w\", encoding='utf-8') as writer:",
            "-        for input_ids, input_mask, segment_ids, example_indices in eval_dataloader:",
            "+        for input_ids, input_mask, example_indices in eval_dataloader:",
            "input_ids = input_ids.to(device)",
            "input_mask = input_mask.float().to(device)",
            "-            segment_ids = segment_ids.to(device)",
            "",
            "-            all_encoder_layers, _ = model(input_ids, segment_ids, input_mask)",
            "+            all_encoder_layers, _ = model(input_ids, token_type_ids=None, attention_mask=input_mask)",
            "",
            "for enc_layers, example_index in zip(all_encoder_layers, example_indices):",
            "feature = features[example_index.item()]"
        ],
        "comments": "for loop",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1140,
        "label": "no",
        "change": [
            "class Model(object):",
            "#     raise TensorForceError(\"Invalid model directory/file.\")",
            "",
            "self.saver.restore(sess=self.session, save_path=file)",
            "+        self.session.run(self.buffer_index_reset_op)",
            "",
            "def get_components(self):",
            "\"\"\""
        ],
        "comments": "add API call for state fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1141,
        "label": "yes",
        "change": [
            "class H3FeatureMixin(BaseFeatureMixin):",
            "):",
            "column = input_df[feature_config[COLUMN]]",
            "if column.dtype == object:",
            "-            column = column.map(int)",
            "-        column = column.map(H3FeatureMixin.h3_to_list)",
            "+            column = backend.df_engine.map_objects(column, int)",
            "+        column = backend.df_engine.map_objects(column, H3FeatureMixin.h3_to_list)",
            "",
            "proc_df[feature_config[PROC_COLUMN]] = backend.df_engine.map_objects(",
            "column, lambda x: np.array(x, dtype=np.uint8)"
        ],
        "comments": "customize API",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1142,
        "label": "yes",
        "change": [
            "class TexturesAtlas(TexturesBase):",
            "# pyre-fixme[16]: `bool` has no attribute `__getitem__`.",
            "mask = (pix_to_face < 0)[..., None]",
            "bary_w01 = torch.where(mask, torch.zeros_like(bary_w01), bary_w01)",
            "-        w_xy = (bary_w01 * R).to(torch.int64)  # (N, H, W, K, 2)",
            "+        # If barycentric coordinates are > 1.0 (in the case of",
            "+        # blur_radius > 0.0), wxy might be > R. We need to clamp this",
            "+        # index to R-1 to index into the texture atlas.",
            "+        w_xy = (bary_w01 * R).to(torch.int64).clamp(max=R - 1)  # (N, H, W, K, 2)",
            "",
            "below_diag = (",
            "bary_w01.sum(dim=-1) * R - w_xy.float().sum(dim=-1)"
        ],
        "comments": "add API call for math fix",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1143,
        "label": "no",
        "change": [
            "def sign(x):  # https://github.com/AngusG/tensorflow-xnor-bnn/blob/master/models",
            "",
            "\"\"\"",
            "with tf.get_default_graph().gradient_override_map({\"sign\": \"QuantizeGrad\"}):",
            "-        return tf.sign(x, name='tl_sign')",
            "+        return tf.sign(x, name='sign')",
            "",
            "",
            "# if tf.__version__ > \"1.7\":"
        ],
        "comments": "rename",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1144,
        "label": "no",
        "change": [
            "class VariationalSparseGP(GPModel):",
            "M = self.Xu.size(0)",
            "Kuu = self.kernel(self.Xu).contiguous()",
            "Kuu.view(-1)[::M + 1] += self.jitter  # add jitter to the diagonal",
            "-        Luu = Kuu.cholesky()",
            "+        Luu = torch.linalg.cholesky(Kuu)",
            "",
            "zero_loc = self.Xu.new_zeros(self.u_loc.shape)",
            "if self.whiten:"
        ],
        "comments": "update API call for version fix",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1146,
        "label": "no",
        "change": [
            "class NetGraph(object):",
            "self.remove_skip_layers(_KERAS_SKIP_LAYERS) # done 1 pass",
            "self.insert_1d_permute_layers()",
            "self.insert_permute_for_spatial_bn()",
            "+            self.insert_permute_for_embed_flatten()",
            "self.defuse_activation()",
            "self.remove_internal_input_layers()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1148,
        "label": "yes",
        "change": [
            "def _matvecmul(x, y):",
            "",
            "",
            "def _cholesky(x):",
            "-    return x.sqrt() if x.dim() == 1 else x.cholesky()",
            "+    return x.sqrt() if x.dim() == 1 else torch.linalg.cholesky(x)",
            "",
            "",
            "def _transpose(x):"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1149,
        "label": "no",
        "change": [
            "class MobileBertForMultipleChoice(MobileBertPreTrainedModel):",
            "super().__init__(config)",
            "",
            "self.mobilebert = MobileBertModel(config)",
            "-        self.dropout = nn.Dropout(config.hidden_dropout_prob)",
            "+        self.dropout = nn.Dropout(config.classifier_dropout)",
            "self.classifier = nn.Linear(config.hidden_size, 1)",
            "",
            "self.init_weights()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1152,
        "label": "yes",
        "change": [
            "def rnn(step_function, inputs, initial_states,",
            "new_states = []",
            "",
            "# all this circus is to recover the last vector in the sequence.",
            "-        begin = tf.pack([tf.shape(outputs)[0] - 1] + [0] * (ndim - 1))",
            "-        size = tf.pack([1] + [-1] * (ndim - 1))",
            "-        last_output = tf.slice(outputs, begin, size)",
            "+        slice_begin = tf.pack([tf.shape(outputs)[0] - 1] + [0] * (ndim - 1))",
            "+        slice_size = tf.pack([1] + [-1] * (ndim - 1))",
            "+        last_output = tf.slice(outputs, slice_begin, slice_size)",
            "last_output = tf.squeeze(last_output, [0])",
            "",
            "axes = [1, 0] + list(range(2, len(outputs.get_shape())))"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "null reference error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 1155,
        "label": "no",
        "change": [
            "def convert_to_numpy(x: TensorStructType, reduce_floats: bool = False):",
            "if torch and isinstance(item, torch.Tensor):",
            "ret = item.cpu().item() if len(item.size()) == 0 else \\",
            "item.detach().cpu().numpy()",
            "-        elif tf and isinstance(item, (tf.Tensor, tf.Variable)):",
            "+        elif tf and isinstance(item, (tf.Tensor, tf.Variable)) and \\",
            "+                hasattr(item, \"numpy\"):",
            "assert tf.executing_eagerly()",
            "ret = item.numpy()",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1156,
        "label": "no",
        "change": [
            "class StagingInputWrapper(FeedfreeInput):",
            "",
            "def setup_staging_areas(self):",
            "for idx, device in enumerate(self._devices):",
            "-            inputs = self._input.get_input_tensors()",
            "-            dtypes = [x.dtype for x in inputs]",
            "with tf.device(device):",
            "-                stage = StagingArea(",
            "-                    dtypes, shapes=None)",
            "+                inputs = self._input.get_input_tensors()",
            "+                dtypes = [x.dtype for x in inputs]",
            "+                stage = StagingArea(dtypes, shapes=None)",
            "self._stage_ops.append(stage.put(inputs))",
            "self._areas.append(stage)",
            "outputs = stage.get()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1157,
        "label": "no",
        "change": [
            "class COCODemo(object):",
            "\"\"\"",
            "masks = predictions.get_field(\"mask\")",
            "masks_per_dim = self.masks_per_dim",
            "-        masks = torch.nn.functional.interpolate(",
            "+        masks = L.interpolate(",
            "masks.float(), scale_factor=1 / masks_per_dim",
            ").byte()",
            "height, width = masks.shape[-2:]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1159,
        "label": "no",
        "change": [
            "class ModelSpeedup:",
            "while not visit_queue.empty():",
            "curnode = visit_queue.get()",
            "self.update_indirect_sparsity(curnode)",
            "-            predecessors = self.torch_graph.find_predecessors(",
            "-                curnode.unique_name)",
            "+            predecessors = set(self.torch_graph.find_predecessors(",
            "+                curnode.unique_name))",
            "for predecessor in predecessors:",
            "out_degree[predecessor] -= 1",
            "if out_degree[predecessor] == 0:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1161,
        "label": "no",
        "change": [
            "class TestLegacyAttention(AllenNlpTestCase):",
            "[[0.6, 0.8, 0.1], [0.15, 0.5, 0.2], [0.5, 0.3, 0.2]],",
            "]",
            ")",
            "-        mask = torch.FloatTensor([[1.0, 1.0, 0.0], [0.0, 0.0, 0.0]])",
            "+        mask = torch.BoolTensor([[True, True, False], [False, False, False]])",
            "result = attention(vector, matrix, mask).data.numpy()",
            "assert_almost_equal(result, numpy.array([[0.5, 0.5, 0.0], [0.0, 0.0, 0.0]]))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1163,
        "label": "no",
        "change": [
            "class OpenAIGPTDoubleHeadsModel(OpenAIGPTPreTrainedModel):",
            "tokenizer = OpenAIGPTTokenizer.from_pretrained('openai-gpt')",
            "model = OpenAIGPTDoubleHeadsModel.from_pretrained('openai-gpt')",
            "tokenizer.add_special_tokens({'cls_token': '[CLS]'})  # Add a [CLS] to the vocabulary (we should train it also!)",
            "+        model.resize_token_embeddings(len(tokenizer))",
            "+",
            "choices = [\"Hello, my dog is cute [CLS]\", \"Hello, my cat is cute [CLS]\"]",
            "input_ids = torch.tensor([tokenizer.encode(s) for s in choices]).unsqueeze(0)  # Batch size 1, 2 choices",
            "-        mc_token_ids = torch.tensor([input_ids.size(-1), input_ids.size(-1)]).unsqueeze(0)  # Batch size 1",
            "+        mc_token_ids = torch.tensor([input_ids.size(-1)-1, input_ids.size(-1)-1]).unsqueeze(0)  # Batch size 1",
            "+",
            "outputs = model(input_ids, mc_token_ids=mc_token_ids)",
            "lm_prediction_scores, mc_prediction_scores = outputs[:2]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1164,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "add_moving_summary(tf.reduce_mean(wrong, name='train_error'))",
            "",
            "# weight decay on all W of fc layers",
            "-        wd_cost = tf.mul(0.0004,",
            "-                         regularize_cost('fc.*/W', tf.nn.l2_loss),",
            "-                         name='regularize_loss')",
            "+        wd_cost = regularize_cost('fc.*/W', l2_regularizer(4e-4), name='regularize_loss')",
            "add_moving_summary(cost, wd_cost)",
            "",
            "add_param_summary(('.*/W', ['histogram']))   # monitor W"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1166,
        "label": "no",
        "change": [
            "def unique_inverse(",
            "",
            "def unique_values(",
            "x: Union[tf.Tensor, tf.Variable],",
            "+    /,",
            "*,",
            "-    out: Optional[Union[tf.Tensor, tf.Variable]] = None",
            "+    out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "ret = tf.unique(tf.reshape(x, [-1]))[0]",
            "return tf.sort(ret)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1167,
        "label": "no",
        "change": [
            "class TestHighway(AllenNlpTestCase):",
            "",
            "def test_forward_works_on_nd_input(self):",
            "highway = Highway(2, 2)",
            "-        input_tensor = Variable(torch.ones(2, 2, 2))",
            "+        input_tensor = torch.ones(2, 2, 2)",
            "output = highway(input_tensor)",
            "assert output.size() == (2, 2, 2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1168,
        "label": "no",
        "change": [
            "def reshape(",
            "shape: Union[ivy.NativeShape, Sequence[int]],",
            "*,",
            "copy: Optional[bool] = None,",
            "-    out: Optional[tf.Tensor] = None,",
            "+    out: Optional[Union[tf.Tensor, tf.Variable]] = None,",
            ") -> Union[tf.Tensor, tf.Variable]:",
            "if copy:",
            "newarr = tf.experimental.numpy.copy(x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1169,
        "label": "no",
        "change": [
            "class TRPOUpdater(ValueFunction):",
            "",
            "action_means, action_log_stds = self.session.run([self.action_means,",
            "self.action_log_stds],",
            "-                                                         {self.state: state})",
            "+                                                         {self.state: [state]})",
            "",
            "action = action_means + np.exp(action_log_stds) * self.random.randn(*action_log_stds.shape)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1171,
        "label": "no",
        "change": [
            "def convert_to_legacy_optimizer(optimizer):",
            "",
            "This function takes in a `tf.keras.optimizers.experimental.Optimizer`",
            "instance and converts it to the corresponding",
            "-    `tf.keras.optimizer.legacy.Optimizer` instance.",
            "+    `tf.keras.optimizers.legacy.Optimizer` instance.",
            "For example, `tf.keras.optimizers.experimental.Adam(...)` to",
            "`tf.keras.optimizers.legacy.Adam(...)`."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1172,
        "label": "no",
        "change": [
            "def floor_divide(",
            "out: Optional[torch.Tensor] = None",
            ") -> torch.Tensor:",
            "x1, x2 = _cast_for_binary_op(x1, x2)",
            "-    return torch.div(x1, x2, rounding_mode=\"floor\", out=out)",
            "+    return torch.floor(torch.divide(x1, x2, out=out))",
            "",
            "",
            "def bitwise_or("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1175,
        "label": "no",
        "change": [
            "def normalize(data: torch.Tensor, mean: torch.Tensor,",
            "mean = mean[..., :, None, None].to(data.device)",
            "std = std[..., :, None, None].to(data.device)",
            "",
            "-    out = data.sub(mean).div(std)",
            "+    out = (data - mean) / std",
            "",
            "return out",
            "-",
            "-# - denormalise"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1186,
        "label": "no",
        "change": [
            "class Pickler(dill.Pickler):",
            "",
            "@pklregister(obj_type)",
            "def _save_tensor(pickler, obj):",
            "+                        # `torch.from_numpy` is not picklable in `torch>=1.11.0`",
            "+                        def _create_tensor(np_array):",
            "+                            return torch.from_numpy(np_array)",
            "+",
            "dill_log(pickler, f\"To: {obj}\")",
            "args = (obj.detach().cpu().numpy(),)",
            "-                        pickler.save_reduce(torch.from_numpy, args, obj=obj)",
            "+                        pickler.save_reduce(_create_tensor, args, obj=obj)",
            "dill_log(pickler, \"# To\")",
            "return"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1187,
        "label": "no",
        "change": [
            "def convert_tf_checkpoint_to_pytorch(tf_checkpoint_path, config_file, pytorch_du",
            "",
            "# Save pytorch-model",
            "print(\"Save PyTorch model to {}\".format(pytorch_dump_path))",
            "-    torch.save(model.state_dict(), pytorch_dump_path)",
            "+    model.save_pretrained(pytorch_dump_path)",
            "",
            "",
            "if __name__ == \"__main__\":"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1190,
        "label": "yes",
        "change": [
            "class TorchCheckpointWrapper(CheckpointWrapper):",
            "#  --> https://github.com/facebookresearch/fairscale/blob/1e4a503cda8571851a68effd6e504a192838ab06/fairscale/nn/checkpoint/checkpoint_activations.py#L145-L153  # noqa: E501",
            "# We just patch the forward method to avoid having to proxy all the fields and other methods.",
            "# The use of weakref here is to prevent creating a ref cycle: m -> m.forward -> m.",
            "+",
            "+        assert len(kwargs) == 0  # This way of wrapping only works for positional arguments.",
            "+",
            "module.forward = functools.partial(  # type: ignore[assignment]",
            "_checkpointed_forward, type(module).forward, weakref.ref(module)",
            ")"
        ],
        "comments": "",
        "Symptom": "program crash",
        "Root_Cause": "null reference error",
        "Action": "addition",
        "Element": "api condition check"
    },
    {
        "number": 1191,
        "label": "no",
        "change": [
            "class TestInvertAffineTransform:",
            "assert_allclose(matrix_inv, expected)",
            "",
            "def test_gradcheck(self, device):",
            "-        matrix = torch.eye(2, 3).to(device)",
            "+        matrix = torch.eye(2, 3).to(device)[None]",
            "matrix = utils.tensor_to_gradcheck_var(matrix)  # to var",
            "assert gradcheck(kornia.invert_affine_transform, (matrix,),",
            "raise_exception=True)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1192,
        "label": "no",
        "change": [
            "def train(target, dataset, cluster_spec, ctx):",
            "# passing in None for summary_op to avoid a summary_thread being started.",
            "# Running summaries and training operations in parallel could run out of",
            "# GPU memory.",
            "-      summary_writer = tf.train.SummaryWriter(\"tensorboard_%d\" %(ctx.worker_num), graph=tf.get_default_graph())",
            "+      summary_writer = tf.summary.FileWriter(\"tensorboard_%d\" %(ctx.worker_num), graph=tf.get_default_graph())",
            "sv = tf.train.Supervisor(is_chief=is_chief,",
            "logdir=FLAGS.train_dir,",
            "init_op=init_op,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1193,
        "label": "yes",
        "change": [
            "class RNN(torch.nn.Module):",
            "def __init__(self, idim, elayers, cdim, hdim, dropout, typ=\"blstm\"):",
            "super(RNN, self).__init__()",
            "bidir = typ[0] == \"b\"",
            "-        self.nblstm = torch.nn.LSTM(idim, cdim, elayers, batch_first=True,",
            "-                                    dropout=dropout, bidirectional=bidir) if \"lstm\" in typ \\",
            "+        self.nbrnn = torch.nn.LSTM(idim, cdim, elayers, batch_first=True,",
            "+                                   dropout=dropout, bidirectional=bidir) if \"lstm\" in typ \\",
            "else torch.nn.GRU(idim, cdim, elayers, batch_first=True, dropout=dropout,",
            "bidirectional=bidir)",
            "if bidir:"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 1195,
        "label": "no",
        "change": [
            "class PyroVAEImpl(VAE):",
            "",
            "def model(self, data):",
            "decoder = pyro.module('decoder', self.vae_decoder)",
            "-        z_mean, z_std = ng_zeros([data.size(0), 20]), ng_ones([data.size(0), 20])",
            "+        z_mean, z_std = torch.zeros([data.size(0), 20]), torch.ones([data.size(0), 20])",
            "with pyro.iarange('data', data.size(0)):",
            "z = pyro.sample('latent', Normal(z_mean, z_std).reshape(extra_event_dims=1))",
            "img = decoder.forward(z)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1196,
        "label": "no",
        "change": [
            "for _name, _Dist in torch.distributions.__dict__.items():",
            "locals()[_name] = _PyroDist",
            "",
            "_PyroDist.__doc__ = '''",
            "-    Wraps :class:`torch.distributions.{}` with",
            "+    Wraps :class:`{}.{}` with",
            ":class:`~pyro.distributions.torch_distribution.TorchDistributionMixin`.",
            "-    '''.format(_Dist.__name__)",
            "+    '''.format(_Dist.__module__, _Dist.__name__)",
            "",
            "__all__.append(_name)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1197,
        "label": "no",
        "change": [
            "class TFData2VecVisionForSemanticSegmentation(TFData2VecVisionPreTrainedModel):",
            "# FPNs",
            "self.fpn1 = [",
            "tf.keras.layers.Conv2DTranspose(config.hidden_size, kernel_size=2, strides=2, name=\"fpn1.0\"),",
            "-            tf.keras.layers.BatchNormalization(name=\"fpn1.1\"),",
            "+            tf.keras.layers.BatchNormalization(name=\"fpn1.1\", momentum=0.9, epsilon=1e-5),",
            "tf.keras.layers.Activation(\"gelu\"),",
            "tf.keras.layers.Conv2DTranspose(config.hidden_size, kernel_size=2, strides=2, name=\"fpn1.3\"),",
            "]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1198,
        "label": "no",
        "change": [
            "def main(_):",
            "optimizer = tf.train.GradientDescentOptimizer(lr)",
            "train_op = optimizer.apply_gradients(zip(grads, tvars))",
            "",
            "-    # sess.run(tf.initialize_all_variables())",
            "+    # sess.run(tf.global_variables_initializer())",
            "tl.layers.initialize_global_variables(sess)",
            "",
            "net.print_params()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1199,
        "label": "no",
        "change": [
            "def main():",
            "logger.info(f\"Number of class images to sample: {num_new_images}.\")",
            "",
            "sample_dataset = PromptDataset(args.class_prompt, num_new_images)",
            "-            sample_dataloader = torch.utils.data.DataLoader(sample_dataset, batch_size=args.sample_batch_size)",
            "+            total_sample_batch_size = args.sample_batch_size * jax.local_device_count()",
            "+            sample_dataloader = torch.utils.data.DataLoader(sample_dataset, batch_size=total_sample_batch_size)",
            "",
            "for example in tqdm(",
            "sample_dataloader, desc=\"Generating class images\", disable=not jax.process_index() == 0"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1200,
        "label": "yes",
        "change": [
            "class TokenCharactersIndexer(TokenIndexer[List[int]]):",
            "# Removes the \"dummy token\".",
            "padded_tokens.pop()",
            "# Truncates all the tokens to the desired length, and return the result.",
            "-        return {key: [list(token[:desired_token_length]) for token in padded_tokens]}",
            "+        return {key: torch.LongTensor([list(token[:desired_token_length])",
            "+                                       for token in padded_tokens])}"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 1201,
        "label": "yes",
        "change": [
            "class LKJCorrCholesky(TorchDistribution):",
            "Km1 = self._d - 1",
            "",
            "log_diagonals = x.diagonal(offset=0, dim1=-1, dim2=-2)[..., 1:].log()",
            "+        # TODO: Figure out why the `device` kwarg to torch.linspace seems to not work in certain situations,",
            "+        # and a seemingly redundant .to(x.device) is needed below.",
            "values = log_diagonals * torch.linspace(start=Km1 - 1, end=0, steps=Km1,",
            "dtype=x.dtype,",
            "-                                                device=x.device).expand_as(log_diagonals)",
            "+                                                device=x.device).expand_as(log_diagonals).to(x.device)",
            "",
            "values += log_diagonals.mul(eta.mul(2).add(-2.0))",
            "values = values.sum(-1) + lp"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 1202,
        "label": "no",
        "change": [
            "class OwlViTModel(OwlViTPreTrainedModel):",
            "if return_base_image_embeds:",
            "last_hidden_state = vision_outputs[0]",
            "image_embeds = self.vision_model.post_layernorm(last_hidden_state)",
            "+        else:",
            "+            image_embeds = image_embeds_norm",
            "+            text_embeds = text_embeds_norm",
            "",
            "if not return_dict:",
            "output = (logits_per_image, logits_per_text, text_embeds, image_embeds, text_outputs, vision_outputs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1204,
        "label": "no",
        "change": [
            "def isnan(x: torch.Tensor)\\",
            "return torch.isnan(x)",
            "",
            "",
            "-def less(x1: torch.Tensor,x2: torch.Tensor):",
            "-    if hasattr(x1,'dtype') and hasattr(x2,'dtype'):",
            "-        promoted_type = torch.promote_types(x1.dtype,x2.dtype)",
            "+def less(x1: torch.Tensor, x2: torch.Tensor):",
            "+    if hasattr(x1, 'dtype') and hasattr(x2, 'dtype'):",
            "+        promoted_type = torch.promote_types(x1.dtype, x2.dtype)",
            "x1 = x1.to(promoted_type)",
            "x2 = x2.to(promoted_type)",
            "-    return torch.lt(x1,x2)",
            "+    return torch.lt(x1, x2)",
            "",
            "",
            "def cos(x: torch.Tensor)\\"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1205,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "feat, labelidx, labelvalue, labelshape, seqlen = input_vars",
            "label = tf.SparseTensor(labelidx, labelvalue, labelshape)",
            "",
            "-        cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=HIDDEN)",
            "-        cell = tf.nn.rnn_cell.MultiRNNCell([cell] * NLAYER)",
            "+        cell = tf.contrib.rnn.BasicLSTMCell(num_units=HIDDEN)",
            "+        cell = tf.contrib.rnn.MultiRNNCell([cell] * NLAYER)",
            "",
            "initial = cell.zero_state(tf.shape(feat)[0], tf.float32)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1208,
        "label": "no",
        "change": [
            "eigh.support_native_out = True",
            "",
            "@with_unsupported_dtypes({\"1.11.0 and below\": (\"float16\", \"bfloat16\")}, backend_version)",
            "def eigvalsh(",
            "-    x: torch.Tensor,",
            "-    /,",
            "-    *,",
            "-    UPLO: Optional[str] = \"L\",",
            "-    out: Optional[torch.Tensor] = None",
            "+    x: torch.Tensor, /, *, UPLO: Optional[str] = \"L\", out: Optional[torch.Tensor] = None",
            ") -> torch.Tensor:",
            "return torch.linalg.eigvalsh(x, UPLO=UPLO, out=out)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1209,
        "label": "no",
        "change": [
            "class RMSProp(base.Module):",
            "ms.assign(tf.square(update) * (1. - decay) + ms * decay)",
            "if self.centered:",
            "mg.assign(update * (1. - decay) + mg * decay)",
            "-          denominator = ms - mg + epsilon",
            "+          denominator = ms - tf.square(mg) + epsilon",
            "else:",
            "denominator = ms + epsilon",
            "mom.assign(momentum * mom + ("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1210,
        "label": "no",
        "change": [
            "def _linear(args, output_size, bias, bias_start=0.0, weights_init=None,",
            "Raises:",
            "ValueError: if some of the arguments has unspecified or wrong shape.",
            "\"\"\"",
            "-    if args is None or (_rnn_cell._is_sequence(args) and not args):",
            "+    if args is None or (is_sequence(args) and not args):",
            "raise ValueError(\"`args` must be specified\")",
            "-    if not _rnn_cell._is_sequence(args):",
            "+    if not is_sequence(args):",
            "args = [args]",
            "",
            "# Calculate the total size of arguments on dimension 1."
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1212,
        "label": "no",
        "change": [
            "class EpsilonDecay(Exploration):",
            "epsilon = self.final_epsilon + (2 ** (-half_life_ratio)) * (self.initial_epsilon - self.final_epsilon)",
            "return epsilon",
            "",
            "-        pred = tf.logical_or(x=(timestep < self.start_timestep), y=(timestep > self.start_timestep + self.timesteps))",
            "+        pred = tf.logical_or(x=(timestep < self.start_timestep),",
            "+                             y=(timestep > self.start_timestep + int(self.timesteps)))",
            "return tf.cond(pred=pred, true_fn=true_fn, false_fn=false_fn)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1213,
        "label": "no",
        "change": [
            "ADAM = int(os.getenv(\"ADAM\", 0))",
            "if __name__ == \"__main__\":",
            "print(f\"NUM:{NUM} BS:{BS} CNT:{CNT}\")",
            "model = EfficientNet(NUM, classes=1000, has_se=False, track_running_stats=False)",
            "-  parameters = get_parameters(model)",
            "+  parameters = optim.get_parameters(model)",
            "for p in parameters: p.realize()",
            "if ADAM: optimizer = optim.Adam(parameters, lr=0.001)",
            "else: optimizer = optim.SGD(parameters, lr=0.001)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1214,
        "label": "no",
        "change": [
            "class TestTrain(AllenNlpTestCase):",
            "train_model(params(), serialization_dir=serialization_dir)",
            "archive = load_archive(str(serialization_dir / \"model.tar.gz\"))",
            "model = archive.model",
            "-        assert model.forward(torch.tensor([1, 2, 3]))[\"class\"] == torch.tensor(98) # pylint: disable=not-callable",
            "+        assert model.forward(torch.tensor([1, 2, 3]))[\"class\"] == torch.tensor(98)",
            "assert model.vocab.get_vocab_size() == 9"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1215,
        "label": "yes",
        "change": [
            "class EKFState(object):",
            "S = H.mm(P).mm(H.transpose(-1, -2)) + R  # innovation cov",
            "",
            "K_prefix = self._cov.mm(H.transpose(-1, -2))",
            "-        dx = K_prefix.mm(torch.gesv(dz, S)[0]).squeeze(1)  # K*dz",
            "+        dx = K_prefix.mm(torch.gesv(dz.unsqueeze(1), S)[0]).squeeze(1)  # K*dz",
            "x = self._dynamic_model.geodesic_difference(x, -dx)",
            "",
            "I = eye_like(x, self._dynamic_model.dimension)  # noqa: E741"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 1216,
        "label": "no",
        "change": [
            "def test_my_conv():",
            "assert torch.allclose(conv((x1, x2), adj.t()), out1)",
            "assert torch.allclose(conv((x1, x2), torch_adj.t()), out1)",
            "assert torch.allclose(conv((x1, None), adj.t()), out2)",
            "-    assert torch.allclose(conv((x1, None), torch_adj.t()), out2)",
            "+    assert torch.allclose(conv((x1, None), torch_adj.t()), out2, atol=1e-6)",
            "conv.fuse = False",
            "assert torch.allclose(conv((x1, x2), adj.t()), out1)",
            "assert torch.allclose(conv((x1, x2), torch_adj.t()), out1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1218,
        "label": "no",
        "change": [
            "def test_average_precision(pos_label):",
            "assert isinstance(ap, torch.Tensor)",
            "",
            "",
            "-@pytest.mark.parametrize('pos_label', [1, 2])",
            "+@pytest.mark.parametrize('pos_label', [0, 1])",
            "def test_auroc(pos_label):",
            "auroc = AUROC(pos_label=pos_label)",
            "assert auroc.name == 'auroc'",
            "",
            "-    pred, target = torch.tensor([1, 2, 3, 4]), torch.tensor([1, 2, 0, 1])",
            "+    pred, target = torch.tensor([1, 2, 3, 4]), torch.tensor([1, 1, 0, 1])",
            "area = auroc(pred=pred, target=target, sample_weight=[0.1, 0.2, 0.3, 0.4])",
            "assert isinstance(area, torch.Tensor)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1219,
        "label": "no",
        "change": [
            "class TransformerLM(nn.Module, LMInterface):",
            "m = subsequent_mask(ys_mask.size(-1), device=ys_mask.device).unsqueeze(0)",
            "return ys_mask.unsqueeze(-2) & m",
            "",
            "-    def forward(self, x: torch.Tensor, t: torch.Tensor):",
            "+    def forward(self, x: torch.Tensor, t: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:",
            "xm = (x != 0)",
            "h, _ = self.encoder(x, self.target_mask(x))",
            "y = self.decoder(h)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1222,
        "label": "no",
        "change": [
            "class NlvrDecoderStep(DecoderStep[NlvrDecoderState]):",
            "action_query = torch.cat([hidden_state, attended_sentence], dim=-1)",
            "# (group_size, action_embedding_dim)",
            "predicted_action_embedding = self._output_projection_layer(action_query)",
            "-        predicted_action_embedding = self._dropout(torch.nn.functional.tanh(predicted_action_embedding))",
            "+        predicted_action_embedding = self._dropout(torch.tanh(predicted_action_embedding))",
            "if state.checklist_state[0] is not None:",
            "embedding_addition = self._get_predicted_embedding_addition(state)",
            "addition = embedding_addition * self._checklist_embedding_multiplier"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1223,
        "label": "no",
        "change": [
            "class DistributedFusedAdam(torch.optim.Optimizer):",
            "grp = torch.distributed.new_group(ranks=ranks)",
            "if torch.distributed.get_rank() in ranks:",
            "self._ag_pg.append(grp)",
            "-            self._ag_st = [torch.cuda.Stream()]*self._num_ag_pg",
            "+            self._ag_st = [torch.cuda.Stream() for _ in range(self._num_ag_pg)]",
            "self._l2_grad_norm_st = torch.cuda.Stream() if self._compute_L2_grad_norm else None",
            "self._completion_st = torch.cuda.Stream()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1227,
        "label": "no",
        "change": [
            "\"#@title Load the Universal Sentence Encoder's TF Hub module\\n\",",
            "\"from absl import logging\\n\",",
            "\"\\n\",",
            "-        \"import tensorflow.compat.v1 as tf\\n\",",
            "-        \"tf.disable_v2_behavior()\\n\",",
            "+        \"import tensorflow as tf\\n\",",
            "\"\\n\",",
            "\"import tensorflow_hub as hub\\n\",",
            "\"import matplotlib.pyplot as plt\\n\","
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1228,
        "label": "no",
        "change": [
            "class ESPnetASRTransducerModel(AbsESPnetModel):",
            "self.use_auxiliary_lm_loss = self.training and auxiliary_lm_loss_weight > 0",
            "",
            "if self.use_auxiliary_ctc:",
            "-            self.ctc_lin = torch.nn.Linear(encoder.output_size(), vocab_size)",
            "+            self.ctc_lin = torch.nn.Linear(encoder.dim_output, vocab_size)",
            "self.ctc_dropout_rate = auxiliary_ctc_dropout_rate",
            "",
            "if self.use_auxiliary_lm_loss:",
            "-            self.lm_lin = torch.nn.Linear(decoder.dunits, vocab_size)",
            "+            self.lm_lin = torch.nn.Linear(decoder.dim_output, vocab_size)",
            "",
            "self.lm_loss_smoothing = auxiliary_lm_loss_smoothing"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1229,
        "label": "no",
        "change": [
            "class TFEncoderDecoderMixin:",
            "self.assertEqual(len(tf_outputs_loaded), len(pt_outputs), \"Output lengths differ between TF and PyTorch\")",
            "",
            "for tf_output_loaded, pt_output in zip(tf_outputs_loaded, pt_outputs):",
            "-            self.assert_almost_equals(tf_output_loaded.numpy(), pt_output.numpy(), 1e-3)",
            "+            self.assert_almost_equals(tf_output_loaded.numpy(), pt_output.detach().to(\"cpu\").numpy(), 1e-3)",
            "",
            "def check_equivalence_pt_to_tf(self, config, decoder_config, inputs_dict):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1230,
        "label": "yes",
        "change": [
            "class patch_submodule:",
            "Examples:",
            "",
            ">>> import importlib",
            "-        >>> from datasets.load import prepare_module",
            "+        >>> from datasets.load import dataset_module_factory",
            ">>> from datasets.streaming import patch_submodule, xjoin",
            ">>>",
            "-        >>> snli_module_path, _ = prepare_module(\"snli\")",
            "-        >>> snli_module = importlib.import_module(snli_module_path)",
            "+        >>> dataset_module = dataset_module_factory(\"snli\")",
            "+        >>> snli_module = importlib.import_module(dataset_module.module_path)",
            ">>> patcher = patch_submodule(snli_module, \"os.path.join\", xjoin)",
            ">>> patcher.start()",
            ">>> assert snli_module.os.path.join is xjoin"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1231,
        "label": "no",
        "change": [
            "class MyFeatureStore(FeatureStore):",
            "and attr.index == slice(None, None, None)):",
            "return tensor",
            "",
            "-        idx = torch.cat([(index == v).nonzero() for v in attr.index]).view(-1)",
            "+        idx = (torch.cat([(index == v).nonzero() for v in attr.index]).view(-1)",
            "+               if attr.index.numel() > 0 else [])",
            "return tensor[idx]",
            "",
            "def _remove_tensor(self, attr: TensorAttr) -> bool:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1233,
        "label": "no",
        "change": [
            "def test_transformer_jit_embeddings(results_base_path):",
            "",
            "tensors = base_embeddings.prepare_tensors([sentence])",
            "# ensure that the prepared tensors is what we expect",
            "-    assert sorted(tensors.keys()) == [\"attention_mask\", \"input_ids\", \"overflow_to_sample_mapping\", \"word_ids\"]",
            "+    assert sorted(tensors.keys()) == [",
            "+        \"attention_mask\",",
            "+        \"input_ids\",",
            "+        \"lengths\",",
            "+        \"overflow_to_sample_mapping\",",
            "+        \"word_ids\",",
            "+    ]",
            "",
            "wrapper = JitWrapper(base_embeddings)",
            "parameter_names, parameter_list = TransformerJitWordEmbeddings.parameter_to_list("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1235,
        "label": "no",
        "change": [
            "class Timesteps(nn.Module):",
            "class GaussianFourierProjection(nn.Module):",
            "\"\"\"Gaussian Fourier embeddings for noise levels.\"\"\"",
            "",
            "-    def __init__(self, embedding_size=256, scale=1.0):",
            "+    def __init__(self, embedding_size: int = 256, scale: float = 1.0):",
            "super().__init__()",
            "self.weight = nn.Parameter(torch.randn(embedding_size) * scale, requires_grad=False)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1236,
        "label": "no",
        "change": [
            "from kornia.testing import assert_close",
            "class TestOneHot:",
            "def test_smoke(self, device, dtype):",
            "num_classes = 4",
            "-        labels = torch.zeros(2, 2, 1, dtype=torch.int64)",
            "+        labels = torch.zeros(2, 2, 1, dtype=torch.int64, device=device)",
            "labels[0, 0, 0] = 0",
            "labels[0, 1, 0] = 1",
            "labels[1, 0, 0] = 2"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1237,
        "label": "no",
        "change": [
            "class CanineModelTest(ModelTesterMixin, unittest.TestCase):",
            "torch.allclose(",
            "set_nan_tensor_to_zero(tuple_object), set_nan_tensor_to_zero(dict_object), atol=1e-5",
            "),",
            "-                            msg=f\"Tuple and dict output are not equal. Difference: {torch.max(torch.abs(tuple_object - dict_object))}. Tuple has `nan`: {torch.isnan(tuple_object).any()} and `inf`: {torch.isinf(tuple_object)}. Dict has `nan`: {torch.isnan(dict_object).any()} and `inf`: {torch.isinf(dict_object)}.\",",
            "+                            msg=(",
            "+                                \"Tuple and dict output are not equal. Difference:\"",
            "+                                f\" {torch.max(torch.abs(tuple_object - dict_object))}. Tuple has `nan`:\"",
            "+                                f\" {torch.isnan(tuple_object).any()} and `inf`: {torch.isinf(tuple_object)}. Dict has\"",
            "+                                f\" `nan`: {torch.isnan(dict_object).any()} and `inf`: {torch.isinf(dict_object)}.\"",
            "+                            ),",
            ")",
            "",
            "recursive_check(tuple_output, dict_output)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1241,
        "label": "no",
        "change": [
            "def sample_autoregressive(partial_sequences,",
            "if has_partial_sequences and remove_partial_sequences:",
            "# remove partial sequences from outputs",
            "partial_length = mtf.reduce_sum(",
            "-            mtf.to_int32(mtf.not_equal(partial_sequences, padding_id)),",
            "+            mtf.to_int32(mtf.not_equal(partial_sequences, 0)),",
            "reduced_dim=length_dim)",
            "outputs = mtf.dynamic_shift(",
            "outputs, -partial_length, length_dim, wrap=False)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1242,
        "label": "no",
        "change": [
            "class ConvolutionBlock(nn.Module):",
            "self.act = activation",
            "",
            "def forward(self, x):",
            "+        \"\"\"Compute Covolution Block",
            "+",
            "+        :param torch.Tensor x: (batch, time, size)",
            "+        :return torch.Tensor: convoluted `value` (batch, time, d_model)",
            "+        \"\"\"",
            "# exchange the temporal dimension and the feature dimension",
            "# pad the input from (batch, len, dim) to (batch, dim, len+(k-1))",
            "x = self.pad_left(x.transpose(1, 2))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1243,
        "label": "no",
        "change": [
            "class UpscalerESRGAN(Upscaler):",
            "print(\"Unable to load %s from %s\" % (self.model_path, filename))",
            "return None",
            "",
            "-        pretrained_net = torch.load(filename, map_location='cpu' if shared.device.type == 'mps' else None)",
            "+        pretrained_net = torch.load(filename, map_location='cpu' if devices.device_esrgan.type == 'mps' else None)",
            "crt_model = arch.RRDBNet(3, 3, 64, 23, gc=32)",
            "",
            "pretrained_net = fix_model_layers(crt_model, pretrained_net)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1244,
        "label": "no",
        "change": [
            "for epoch in range(num_epochs):",
            "if j % embedding_log == 0:",
            "print(\"loss_value:{}\".format(loss_value.data[0]))",
            "#we need 3 dimension for tensor to visualize it!",
            "-            out = torch.cat((out, torch.ones(len(out), 1)), 1)",
            "-            writer.add_embedding(out.data, metadata=label_batch.data, label_img=data_batch.data, global_step=n_iter)",
            "+            out = torch.cat((out.data, torch.ones(len(out), 1)), 1)",
            "+            writer.add_embedding(out, metadata=label_batch.data, label_img=data_batch.data, global_step=n_iter)",
            "",
            "writer.close()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1245,
        "label": "no",
        "change": [
            "from .modeling_utils import PreTrainedModel",
            "logger = logging.getLogger(__name__)",
            "",
            "TRANSFO_XL_PRETRAINED_MODEL_ARCHIVE_MAP = {",
            "-    \"transfo-xl-wt103\": \"https://s3.amazonaws.com/models.huggingface.co/bert/transfo-xl-wt103-pytorch_model.bin\",",
            "+    \"transfo-xl-wt103\": \"https://cdn.huggingface.co/transfo-xl-wt103-pytorch_model.bin\",",
            "}"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1248,
        "label": "yes",
        "change": [
            "class DeepSpeedZeRoOffload(object):",
            "self._prefetch_bucket_sz = int(prefetch_bucket_size)",
            "self._max_reuse_distance_in_numel = int(max_reuse_distance)",
            "self._max_available_parameters_in_numel = int(max_live_parameters)",
            "-        self.__allgather_stream = Stream(",
            "-        ) if overlap_comm else torch.cuda.default_stream()",
            "+        self.__allgather_stream = get_accelerator().Stream(",
            "+        ) if overlap_comm else get_accelerator().default_stream()",
            "",
            "self.forward_hooks = []",
            "self.backward_hooks = []"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1249,
        "label": "no",
        "change": [
            "if __name__ == \"__main__\":",
            "rl_training = False",
            "actor_training = False",
            "",
            "-    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")",
            "+    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")",
            "+    # place here the path to the config.yaml file",
            "config_path = \"/home/pierpaolo/Documents/optimapi/ptuning/config.yaml\"",
            "",
            "if reward_training:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1250,
        "label": "no",
        "change": [
            "MIN_AFTER_DEQUEUE = int(50000 * 0.4)",
            "CAPACITY = MIN_AFTER_DEQUEUE + 3 * BATCH_SIZE",
            "",
            "def get_model(inputs, is_training):",
            "-    #keep_prob = tf.constant(0.5 if is_training else 1.0)",
            "+    #keep_prob = tf.constant(0.5 if is_training else 0.0)",
            "",
            "image, label = inputs"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1251,
        "label": "no",
        "change": [
            "class LDMPipeline(DiffusionPipeline):",
            "True, otherwise a `tuple. When returning a tuple, the first element is a list with the generated images.",
            "\"\"\"",
            "",
            "-        latents = torch.randn(",
            "+        latents = randn_tensor(",
            "(batch_size, self.unet.in_channels, self.unet.sample_size, self.unet.sample_size),",
            "generator=generator,",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1252,
        "label": "no",
        "change": [
            "class GoalOrientedBotNetwork(TFModel):",
            "self.sess.run(tf.global_variables_initializer())",
            "",
            "super().__init__(**kwargs)",
            "-        if tf.train.checkpoint_exists(str(self.save_path.resolve())):",
            "+        if tf.train.checkpoint_exists(str(self.load_path.resolve())):",
            "log.info(\"[initializing `{}` from saved]\".format(self.__class__.__name__))",
            "self.load()",
            "else:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1253,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            ".BatchNorm('bnfc1')",
            ".apply(nonlin)",
            ".FullyConnected('fct', 1000, use_bias=True)())",
            "-        tf.get_variable = old_get_variable",
            "",
            "prob = tf.nn.softmax(logits, name='output')"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1254,
        "label": "no",
        "change": [
            "class _SetPreprocessing(torch.nn.Module):",
            "self.unit_to_id = metadata[\"str2idx\"]",
            "self.is_bag = is_bag",
            "",
            "-    def forward(self, v: TorchscriptPreprocessingInput):",
            "+    def forward(self, v: TorchscriptPreprocessingInput) -> torch.Tensor:",
            "\"\"\"Takes a list of strings and returns a tensor of counts for each token.\"\"\"",
            "if not torch.jit.isinstance(v, List[str]):",
            "raise ValueError(f\"Unsupported input: {v}\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1256,
        "label": "no",
        "change": [
            "class KLDivergenceCELoss(Loss):",
            "soft_loss *= self.t ** 2  # See https://arxiv.org/pdf/1503.02531.pdf",
            "hard_loss = 0.0",
            "if self.hard_weight > 0.0:",
            "-            hard_loss = F.cross_entropy(",
            "-                logits,",
            "+            hard_loss = F.nll_loss(",
            "+                F.log_softmax(logits, 1, dtype=torch.float32),",
            "hard_targets,",
            "-                reduction=\"mean\" if reduce else \"none\",",
            "weight=self.weight,",
            "+                reduction=\"mean\" if reduce else \"none\",",
            ")",
            "",
            "return ("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1257,
        "label": "yes",
        "change": [
            "class Module(tf.Module):",
            "elif initializer == 'ones':",
            "initializer = tf_util.ones(shape=spec.shape, dtype=spec.type)",
            "elif initializer == 'constant':",
            "-            initializer = tf_util.fill(dims=spec.shape, value=self.initialization_scale)",
            "+            initializer = tf.fill(",
            "+                dims=spec.shape, value=tf_util.constant(value=initialization_scale, dtype=spec.type)",
            "+            )",
            "",
            "# Variable",
            "variable = tf.Variable("
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 1258,
        "label": "no",
        "change": [
            "def unstack_layer(layer, num=None, axis=0, name='unstack'):",
            "",
            "\"\"\"",
            "inputs = layer.outputs",
            "-    with tf.variable_scope(name) as vs:",
            "+    with tf.variable_scope(name):",
            "outputs = tf.unstack(inputs, num=num, axis=axis)",
            "",
            "logging.info(\"UnStackLayer %s: num: %s axis: %d, n_outputs: %d\" % (name, num, axis, len(outputs)))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1259,
        "label": "no",
        "change": [
            "class TrainTest(unittest.TestCase):",
            "'--lfw_nrof_folds', '2' ]",
            "args = facenet_train.parse_arguments(argv)",
            "model_dir = facenet_train.main(args)",
            "+",
            "+",
            "model_file = os.path.join(model_dir, 'model.ckpt-1')",
            "# Check that the trained model can be loaded",
            "+        tf.reset_default_graph()",
            "argv = ['--model_file', model_file,",
            "'--lfw_pairs', self.lfw_pairs_file,",
            "'--lfw_dir', self.dataset_dir,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1262,
        "label": "no",
        "change": [
            "class PPO(object):",
            "",
            "self.update_old_pi()",
            "adv = self.cal_adv(s, r)",
            "-        # adv = (adv - adv.mean())/(adv.std()+1e-6)     # sometimes helpful",
            "+        # adv = (adv - adv.mean())/(adv.std()+1e-6)  # sometimes helpful",
            "",
            "# update actor",
            "if METHOD['name'] == 'kl_pen':"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1263,
        "label": "no",
        "change": [
            "def edge_index_from_dict(graph_dict, num_nodes=None):",
            "",
            "",
            "def sample_mask(index, num_nodes):",
            "-    mask = torch.zeros((num_nodes, ), dtype=torch.uint8)",
            "+    mask = torch.zeros((num_nodes, ), dtype=torch.bool)",
            "mask[index] = 1",
            "return mask"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1264,
        "label": "no",
        "change": [
            "def main(args):",
            "checkpoint = torch.load(args.restore_path)",
            "model.load_state_dict(checkpoint['model'])",
            "optimizer.load_state_dict(checkpoint['optimizer'])",
            "-        print(\"\\n > Model restored from step %d\\n\" % checkpoint['step'])",
            "+        print(\" > Model restored from step %d\" % checkpoint['step'])",
            "start_epoch = checkpoint['step'] // len(train_loader)",
            "best_loss = checkpoint['linear_loss']",
            "start_epoch = 0",
            "args.restore_step = checkpoint['step']",
            "else:",
            "args.restore_step = 0",
            "-        print(\"\\n > Starting a new training\")",
            "+        print(\" > Starting a new training\")",
            "",
            "if use_cuda:",
            "-        model = nn.DataParallel(model.cuda())",
            "+        print(\" > Using CUDA.\")",
            "+        model = nn.DataParallel(model).cuda()",
            "",
            "num_params = count_parameters(model)",
            "print(\" | > Model has {} parameters\".format(num_params))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1265,
        "label": "no",
        "change": [
            "def test_transformer_conv():",
            "",
            "t = '(PairTensor, SparseTensor, NoneType) -> Tensor'",
            "jit = torch.jit.script(conv.jittable(t))",
            "-    assert torch.allclose(conv((x1, x2), adj.t()), out, atol=1e-6)",
            "+    assert torch.allclose(jit((x1, x2), adj.t()), out, atol=1e-6)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1266,
        "label": "yes",
        "change": [
            "PT_SEQUENCE_CLASSIFICATION_SAMPLE = r\"\"\"",
            "...     \"{checkpoint}\", num_labels=num_labels, problem_type=\"multi_label_classification\"",
            "... )",
            "",
            "-    >>> labels = torch.nn.functional.one_hot(torch.tensor(predicted_class_ids), num_classes=num_labels).to(torch.float)",
            "+    >>> labels = torch.sum(",
            "+    ...     torch.nn.functional.one_hot(predicted_class_ids[None, :].clone(), num_classes=num_labels), dim=1",
            "+    ... ).to(torch.float)",
            ">>> loss = model(**inputs, labels=labels).loss",
            "```",
            "\"\"\""
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1267,
        "label": "no",
        "change": [
            "def test_lecun_init_torch():",
            "torch.manual_seed(nseed)",
            "numpy.random.seed(nseed)",
            "os.environ[\"CHAINER_SEED\"] = str(nseed)",
            "-    import espnet.nets.pytorch.e2e_asr_th as m",
            "+    import espnet.nets.pytorch.e2e_asr as m",
            "model = m.Loss(m.E2E(40, 5, args), 0.5)",
            "b = model.predictor.ctc.ctc_lo.bias.data.numpy()",
            "assert numpy.all(b == 0.0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1270,
        "label": "no",
        "change": [
            "class TestNormalizeLAF:",
            "laf = torch.tensor([[1, 0, 1], [0, 1, 1]]).float()",
            "laf = laf.view(1, 1, 2, 3)",
            "img = torch.rand(1, 3, h, w)",
            "-        expected = torch.tensor([[0.2, 0, 0.1], [0, 0.2, 0.2]]).float()",
            "+        expected = torch.tensor([[[[0.2, 0, 0.1], [0, 0.2, 0.2]]]]).float()",
            "lafn = kornia.feature.normalize_laf(laf, img)",
            "assert_allclose(lafn, expected)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1271,
        "label": "no",
        "change": [
            "def _PositiveDefinite_check(self, value):",
            "matrix_shape = value.shape[-2:]",
            "batch_shape = value.shape[:-2]",
            "flattened_value = value.reshape((-1,) + matrix_shape)",
            "-    return torch.stack([v.symeig(eigenvectors=False)[0][:1] > 0.0",
            "+    return torch.stack([torch.linalg.eigvalsh(v)[:1] > 0.0",
            "for v in flattened_value]).view(batch_shape)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1272,
        "label": "no",
        "change": [
            "def test_dna_conv():",
            "",
            "t = '(Tensor, SparseTensor, OptTensor) -> Tensor'",
            "jit = torch.jit.script(conv.jittable(t))",
            "-    assert torch.allclose(conv(x, adj1.t()), out1, atol=1e-6)",
            "-    assert torch.allclose(conv(x, adj2.t()), out2, atol=1e-6)",
            "+    assert torch.allclose(jit(x, adj1.t()), out1, atol=1e-6)",
            "+    assert torch.allclose(jit(x, adj2.t()), out2, atol=1e-6)",
            "",
            "conv.cached = True",
            "conv(x, edge_index)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1273,
        "label": "no",
        "change": [
            "def test_gat_conv():",
            "",
            "t = '(OptPairTensor, SparseTensor, Size, NoneType) -> Tensor'",
            "jit = torch.jit.script(conv.jittable(t))",
            "-    assert torch.allclose(conv((x1, x2), adj.t()), out1, atol=1e-6)",
            "-    assert torch.allclose(conv((x1, None), adj.t()), out2, atol=1e-6)",
            "+    assert torch.allclose(jit((x1, x2), adj.t()), out1, atol=1e-6)",
            "+    assert torch.allclose(jit((x1, None), adj.t()), out2, atol=1e-6)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1274,
        "label": "no",
        "change": [
            "def batch_normalize(tensor_in, epsilon=1e-5, convnet=True, decay=0.9,",
            "\"\"\"Internal function that updates mean and variance during training\"\"\"",
            "with tf.control_dependencies([ema_assign_op]):",
            "return tf.identity(assign_mean), tf.identity(assign_var)",
            "-        IS_TRAINING = tf.get_collection(\"IS_TRAINING\")[-1]",
            "-        mean, variance = control_flow_ops.cond(IS_TRAINING,",
            "-                                               update_mean_var,",
            "-                                               lambda: (ema_mean, ema_var))",
            "+        is_training = tf.squeeze(tf.get_collection(\"IS_TRAINING\"))",
            "+        mean, variance = tf.python.control_flow_ops.cond(",
            "+            is_training, update_mean_var, lambda: (ema_mean, ema_var))",
            "return tf.nn.batch_norm_with_global_normalization(",
            "tensor_in, mean, variance, beta, gamma, epsilon,",
            "scale_after_normalization=scale_after_normalization)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1275,
        "label": "no",
        "change": [
            "def torch_multinomial(input, num_samples, replacement=False):",
            "",
            "def torch_sign(value):",
            "\"\"\"",
            "-    Like ``torch.sign()`` but also works for numbers.",
            "+    Like :func:`torch.sign`` but also works for numbers.",
            "\"\"\"",
            "if isinstance(value, numbers.Number):",
            "return (value > 0) - (value < 0)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1278,
        "label": "no",
        "change": [
            "class LJSpeechDataset(Dataset):",
            "linear = torch.FloatTensor(linear)",
            "mel = torch.FloatTensor(mel)",
            "mel_lengths = torch.LongTensor(mel_lengths)",
            "-            stop_targets = torch.FloatTensor(stop_targets).squeeze()",
            "+            stop_targets = torch.FloatTensor(stop_targets)",
            "",
            "return text, text_lenghts, linear, mel, mel_lengths, stop_targets, item_idxs[0]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1279,
        "label": "no",
        "change": [
            "class Synchronization(Optimizer):",
            "return deltas",
            "",
            "do_sync = (time - self.last_sync >= self.sync_frequency)",
            "-        return tf.cond(pred=do_sync, true_fn=sync, false_fn=no_sync)",
            "+        return self.cond(pred=do_sync, true_fn=sync, false_fn=no_sync)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1282,
        "label": "no",
        "change": [
            "def multi_perspective_match_pairwise(",
            "norm_value = vector1_norm * vector2_norm.transpose(2, 3)",
            "",
            "# (batch, seq_len1, seq_len2, num_perspectives)",
            "-    return (mul_result / norm_value.clamp(min=eps)).permute(0, 2, 3, 1)",
            "+    return (mul_result / norm_value.clamp(min=tiny_value_of_dtype(norm_value.dtype))).permute(",
            "+        0, 2, 3, 1",
            "+    )",
            "",
            "",
            "class BiMpmMatching(nn.Module, FromParams):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1283,
        "label": "no",
        "change": [
            "def test_complex_nested_model():",
            "assert len(BaseFinetuning.flatten_modules(model)) == 10",
            "",
            "BaseFinetuning.freeze(model.encoder, train_bn=True)",
            "-    assert not model.encoder[0].conv.weight.requires_grad  # Validate a leaf module parameter is frozen",
            "+    assert not model.encoder[0].module_dict[\"conv\"].weight.requires_grad  # Validate a leaf module parameter is frozen",
            "assert not model.encoder[0].parent_param.requires_grad  # Validate the parent module parameter is frozen",
            "assert model.encoder[0].bn.weight.requires_grad"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1289,
        "label": "no",
        "change": [
            "class TFTacotronLocationSensitiveAttention(tf.keras.layers.Layer):",
            "",
            "def get_initial_attention(self, batch_size):",
            "\"\"\"Get initial attention.\"\"\"",
            "-        return tf.zeros(shape=[batch_size, self.config.attention_dim], dtype=tf.float32)",
            "+        return tf.zeros(shape=[batch_size, self.config.encoder_lstm_units * 2], dtype=tf.float32)",
            "",
            "",
            "class TFTacotronPrenet(tf.keras.layers.Layer):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1290,
        "label": "no",
        "change": [
            "def train(hyp, opt, device, tb_writer=None):",
            "if rank != -1:",
            "indices = torch.zeros([dataset.n], dtype=torch.int)",
            "if rank == 0:",
            "-                    indices[:] = torch.from_tensor(dataset.indices, dtype=torch.int)",
            "+                    indices[:] = torch.tensor(dataset.indices, dtype=torch.int)",
            "dist.broadcast(indices, 0)",
            "if rank != 0:",
            "dataset.indices = indices.cpu().numpy()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1292,
        "label": "no",
        "change": [
            "class BaseWorker(AbstractWorker, ObjectStorage):",
            "",
            "response = command(*args, **kwargs)",
            "",
            "-            #Temporary fix for websockets when returning a tuple of tensors from an LSTM cell",
            "+            # Temporary fix for websockets when returning a tuple of tensors from an LSTM cell",
            "if command_name == \"torch.lstm_cell\":",
            "response = torch.stack(response)",
            "",
            "-            #Temporary fix for websockets when returning a tuple of tensors from torch.sort()",
            "+            # Temporary fix for websockets when returning a tuple of tensors from torch.sort()",
            "if command_name == \"torch.sort\":",
            "Alpha_Tensor_Fixed = (response[0].float(), response[1].float())",
            "response = torch.stack(Alpha_Tensor_Fixed)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1294,
        "label": "yes",
        "change": [
            "class SCSEModule(nn.Module):",
            "nn.Conv2d(in_channels // reduction, in_channels, 1),",
            "nn.Sigmoid(),",
            ")",
            "-        self.sSE = nn.Sequential(nn.Conv2d(in_channels, in_channels, 1), nn.Sigmoid())",
            "+        self.sSE = nn.Sequential(nn.Conv2d(in_channels, 1, 1), nn.Sigmoid())",
            "",
            "def forward(self, x):",
            "return x * self.cSE(x) + x * self.sSE(x)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1296,
        "label": "no",
        "change": [
            "def interpolate(",
            "size = [x.shape[0], *size, x.shape[1]]",
            "",
            "if align_corners or mode == \"area\":",
            "-        return ivy.interpolate(",
            "+        return ivy.functional.experimental.interpolate(",
            "x, size, mode=mode, align_corners=align_corners, antialias=antialias",
            ")",
            "x = jnp.transpose(x, (0, *range(2, dims + 2), 1))"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1298,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            "logits = M(image)",
            "if ctx.is_main_training_tower:",
            "for op in M.updates:",
            "-                tf.add_to_collection(tf.GraphKeys.UPDATE_OPS)",
            "+                tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, op)",
            "",
            "# build cost function by tensorflow",
            "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1300,
        "label": "no",
        "change": [
            "import numpy as np",
            "from numpy.testing import assert_almost_equal",
            "",
            "from allennlp.common.testing import AllenNlpTestCase",
            "-from allennlp.nn.decoding.decoder_trainers import ExpectedRiskMinimization",
            "-from ..simple_transition_system import SimpleDecoderState, SimpleDecoderStep",
            "+from allennlp.state_machines.trainers import ExpectedRiskMinimization",
            "+from ..simple_transition_system import SimpleState, SimpleTransitionFunction",
            "",
            "",
            "class TestExpectedRiskMinimization(AllenNlpTestCase):",
            "def setUp(self):",
            "super().setUp()",
            "-        self.initial_state = SimpleDecoderState([0], [[0]], [torch.Tensor([0.0])])",
            "-        self.decoder_step = SimpleDecoderStep()",
            "+        self.initial_state = SimpleState([0], [[0]], [torch.Tensor([0.0])])",
            "+        self.decoder_step = SimpleTransitionFunction()",
            "# Cost is the number of odd elements in the action history.",
            "self.supervision = lambda state: torch.Tensor([sum([x%2 != 0 for x in",
            "state.action_history[0]])])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1302,
        "label": "yes",
        "change": [
            "def main(args):  # pylint: disable=redefined-outer-name",
            "pos_weight=torch.tensor(10)) if c.stopnet else None",
            "",
            "if args.restore_path:",
            "-        checkpoint = torch.load(args.restore_path)",
            "+        checkpoint = torch.load(args.restore_path, map_location='cpu')",
            "try:",
            "# TODO: fix optimizer init, model.cuda() needs to be called before",
            "# optimizer restore"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 1303,
        "label": "no",
        "change": [
            "def get_optimal_device():",
            "else:",
            "return torch.device(\"cuda\")",
            "",
            "-    if has_mps:",
            "+    if has_mps():",
            "return torch.device(\"mps\")",
            "",
            "return cpu"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1305,
        "label": "no",
        "change": [
            "def test_torch_e2e_state_dict(ray_start_4_cpus):",
            "assert predictions.count() == 3",
            "",
            "",
            "+# We can't really test for prepare_model here as we can't detect what the user",
            "+# has saved without loading (and thus triggering the exception anyway)",
            "def test_torch_e2e_dir(ray_start_4_cpus, tmpdir):",
            "def train_func():",
            "model = torch.nn.Linear(3, 1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1307,
        "label": "no",
        "change": [
            "class BiattentiveClassificationNetwork(Model):",
            "\"\"\"",
            "Parameters",
            "-        tokens : Dict[str, Variable], required",
            "+        tokens : Dict[str, torch.LongTensor], required",
            "The output of ``TextField.as_array()``.",
            "-        label : Variable, optional (default = None)",
            "+        label : torch.LongTensor, optional (default = None)",
            "A variable representing the label for each instance in the batch.",
            "Returns"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1308,
        "label": "yes",
        "change": [
            "def count_nonzero(",
            "def _dtype_count_nonzero(a, axis, dtype):",
            "if dtype is None:",
            "return torch.count_nonzero(a, dim=axis)",
            "-        return torch.tensor(torch.count_nonzero(a, dim=axis), dtype=dtype)",
            "+        return torch.tensor(torch.count_nonzero(a, dim=axis),",
            "+                            dtype=ivy.as_native_dtype(dtype))",
            "",
            "x = _dtype_count_nonzero(a, axis, dtype)",
            "if not keepdims:"
        ],
        "comments": "",
        "Symptom": "return warning",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1309,
        "label": "no",
        "change": [
            "class LibrispeechASR(datasets.GeneratorBasedBuilder):",
            "features=datasets.Features(",
            "{",
            "\"file\": datasets.Value(\"string\"),",
            "-                    \"audio\": datasets.features.Audio(sampling_rate=16_000),",
            "+                    \"audio\": datasets.Audio(sampling_rate=16_000),",
            "\"text\": datasets.Value(\"string\"),",
            "\"speaker_id\": datasets.Value(\"int64\"),",
            "\"chapter_id\": datasets.Value(\"int64\"),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1311,
        "label": "no",
        "change": [
            "class MKDDescriptor(nn.Module):",
            "",
            "",
            "def load_whitening_model(kernel_type: str, training_set: str) -> Dict:",
            "-    whitening_models = torch.hub.load_state_dict_from_url(urls[kernel_type], map_location=lambda storage, loc: storage)",
            "+    storage_fcn: Callable = lambda storage, loc: storage",
            "+    whitening_models = torch.hub.load_state_dict_from_url(",
            "+        urls[kernel_type], map_location=storage_fcn",
            "+    )",
            "whitening_model = whitening_models[training_set]",
            "return whitening_model"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1312,
        "label": "yes",
        "change": [
            "class TorchTensor(AbstractTensor):",
            "",
            "\"\"\"",
            "",
            "-        assert isinstance(self.child, PointerTensor)",
            "+        if not isinstance(self.child, PointerTensor):",
            "+            raise TypeError(\"child should be a PointerTensor\")",
            "",
            "ps = list(pointers)",
            "ps.append(self)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "removal",
        "Element": "api condition check"
    },
    {
        "number": 1313,
        "label": "yes",
        "change": [
            "def unravel_index(",
            "for dim in reversed(shape):",
            "output.append(temp % dim)",
            "temp = temp // dim",
            "-    return tuple(reversed(output))",
            "+    return torch.tensor(reversed(output))",
            "",
            "",
            "unravel_index.support_native_out = False"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "data conversion error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1315,
        "label": "yes",
        "change": [
            "class CanineSelfAttention(nn.Module):",
            "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for",
            "# masked positions, this operation will create a tensor which is 0.0 for",
            "# positions we want to attend and -10000.0 for masked positions.",
            "-                attention_mask = (1.0 - attention_mask.float()) * -10000.0",
            "+                attention_mask = (1.0 - attention_mask.float()) * torch.finfo(attention_scores.dtype).min",
            "# Apply the attention mask (precomputed for all layers in CanineModel forward() function)",
            "attention_scores = attention_scores + attention_mask"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "data conversion error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 1317,
        "label": "no",
        "change": [
            "class FlaubertModel(XLMModel):",
            "# if self.is_decoder and src_enc is not None:",
            "#     src_mask = torch.arange(src_len.max(), dtype=torch.long, device=lengths.device) < src_len[:, None]",
            "",
            "-        device = input_ids.device if input_ids is not None else inputs_embeds.device",
            "-",
            "# position_ids",
            "if position_ids is None:",
            "position_ids = torch.arange(slen, dtype=torch.long, device=device)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1321,
        "label": "no",
        "change": [
            "def prod(",
            "dtype = tf.int64",
            "elif x.dtype == tf.uint64:",
            "dtype = tf.uint64",
            "+    dtype = ivy.as_native_dtype(dtype)",
            "return tf.experimental.numpy.prod(x, axis, dtype, keepdims)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1323,
        "label": "yes",
        "change": [
            "class TFModel(NNModel, metaclass=TfModelMeta):",
            "opt_scope = tf.variable_scope(optimizer_scope_name)",
            "with opt_scope:",
            "if learnable_scopes is None:",
            "-                variables_to_train = tf.trainable_variables()",
            "+                variables_to_train = tf.global_variables()",
            "else:",
            "variables_to_train = []",
            "for scope_name in learnable_scopes:",
            "-                    for var in tf.trainable_variables():",
            "+                    for var in tf.global_variables():",
            "if scope_name in var.name:",
            "variables_to_train.append(var)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1324,
        "label": "no",
        "change": [
            "def abs(x):",
            "",
            "",
            "def sqrt(x):",
            "-    x = tf.clip_by_value(x, _EPSILON, np.inf)",
            "+    x = tf.clip_by_value(x, 0., np.inf)",
            "return tf.sqrt(x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1328,
        "label": "no",
        "change": [
            "def train_func(config):",
            "checkpoint_epoch = checkpoint_dict[\"epoch\"]",
            "starting_epoch = checkpoint_epoch + 1",
            "",
            "+    model = train.torch.prepare_model(model)",
            "+",
            "# Load in training and validation data.",
            "transform_train = transforms.Compose(",
            "["
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1329,
        "label": "no",
        "change": [
            "class TFWav2Vec2ForCTC(TFWav2Vec2PreTrainedModel):",
            "loss = tf.reduce_sum(loss)",
            "if self.config.ctc_loss_reduction == \"mean\":",
            "loss = tf.reduce_mean(loss)",
            "+",
            "+            loss = tf.reshape(loss, (1,))",
            "else:",
            "loss = None"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1331,
        "label": "no",
        "change": [
            "class TestPointMeshDistance(TestCaseMixin, unittest.TestCase):",
            "self.assertClose(loss_op, loss_naive)",
            "",
            "# Compare backward pass",
            "-        rand_val = torch.rand((1)).item()",
            "+        rand_val = torch.rand(1).item()",
            "grad_dist = torch.tensor(rand_val, dtype=torch.float32, device=device)",
            "",
            "loss_naive.backward(grad_dist)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1332,
        "label": "no",
        "change": [
            "class TextEmbeddingModel(tf.train.Checkpoint):",
            "# Assign the table initializer to this instance to ensure the asset",
            "# it depends on is saved with the SavedModel.",
            "self._table_initializer = tf.lookup.TextFileInitializer(",
            "-        vocab_file_path, tf.string, tf.lookup.TextFileIndex.WHOLE_LINE,",
            "+        write_vocabulary_file(self._vocabulary),",
            "+        tf.string, tf.lookup.TextFileIndex.WHOLE_LINE,",
            "tf.int64, tf.lookup.TextFileIndex.LINE_NUMBER)",
            "self._table = tf.lookup.StaticVocabularyTable(",
            "self._table_initializer, num_oov_buckets=oov_buckets)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1333,
        "label": "no",
        "change": [
            "def decompose_essential_matrix(E_mat: torch.Tensor) -> Tuple[torch.Tensor, torch",
            "raise AssertionError(E_mat.shape)",
            "",
            "# decompose matrix by its singular values",
            "-    U, _, V = torch.svd(E_mat)",
            "+    U, _, V = _torch_svd_cast(E_mat)",
            "Vt = V.transpose(-2, -1)",
            "",
            "mask = torch.ones_like(E_mat)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1335,
        "label": "no",
        "change": [
            "def main():",
            "",
            "model.resize_token_embeddings(len(tokenizer))",
            "",
            "-    # Preprocessing the raw_datasets.",
            "+    # Preprocessing the datasets.",
            "# First we tokenize all the texts.",
            "padding = \"max_length\" if args.pad_to_max_length else False"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1338,
        "label": "yes",
        "change": [
            "class EncdecMultiheadAttn(nn.Module):",
            "",
            "def reset_parameters(self):",
            "nn.init.xavier_uniform_(self.in_proj_weight_q)",
            "-        nn.init.xavier_uniform_(self.in_proj_weight_kv)",
            "+        # in_proj_weight_kv has shape [2 * hidden, hidden] but it should be",
            "+        # initialized like a [hidden, hidden] matrix.",
            "+        # sqrt(6 / (hidden + hidden)) / sqrt(6 / (2 * hidden + hidden)) = sqrt(1.5)",
            "+        # therefore xavier_uniform gain should be set to sqrt(1.5).",
            "+        nn.init.xavier_uniform_(self.in_proj_weight_kv, gain=math.sqrt(1.5))",
            "nn.init.xavier_uniform_(self.out_proj_weight)",
            "if self.bias:",
            "nn.init.constant_(self.in_proj_bias_q, 0.)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1341,
        "label": "no",
        "change": [
            "class FeedForwardTransformer(TTSInterface, torch.nn.Module):",
            "spembs = None",
            "",
            "# get option",
            "-        alpha = getattr(inference_args, \"fastspeech_alpha\", None)",
            "+        alpha = getattr(inference_args, \"fastspeech_alpha\", 1.0)",
            "",
            "# inference",
            "_, outs, _ = self._forward("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1343,
        "label": "no",
        "change": [
            "def adam_update(ws, dcdws, lr, mw, vw, step, beta1=0.9, beta2=0.999, epsilon=1e-",
            "",
            "def stop_gradient(x, preserve_type=True):",
            "is_var = is_variable(x)",
            "-    # ToDo: work out why _torch.tensor() wrapping is necessary in certain cases, presumably .detach() should be enough.",
            "-    x = _torch.tensor(x.detach())",
            "+    x = x.detach()",
            "if is_var and preserve_type:",
            "-        return variable(x)",
            "+        return x.requires_grad_()",
            "return x"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1344,
        "label": "no",
        "change": [
            "class SpeedyResNet(nn.Module):",
            "])",
            "self.lin = nn.Linear(512, num_classes, bias=False)",
            "",
            "-  # note, pytorch just uses https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html instead of logsoftmax",
            "+  # note, pytorch just uses https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html instead of log_softmax",
            "def forward(self, x):",
            "x = self.ic(x)",
            "x = self.ib(x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1346,
        "label": "no",
        "change": [
            "def reset_deterministic_algorithm():",
            "yield",
            "if _TORCH_GREATER_EQUAL_1_8:",
            "torch.use_deterministic_algorithms(False)",
            "-    elif _TORCH_GREATER_EQUAL_1_7:",
            "+    else:",
            "torch.set_deterministic(False)",
            "-    else:  # the minimum version Lightning supports is PyTorch 1.6",
            "-        torch._set_deterministic(False)",
            "",
            "",
            "@pytest.fixture"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1347,
        "label": "no",
        "change": [
            "class LocalSyncParallelOptimizer(object):",
            "",
            "# Then setup the per-device loss graphs that use the shared weights",
            "self._batch_index = tf.placeholder(tf.int32)",
            "-        data_splits = zip(",
            "-            *[tf.split(ph, len(devices)) for ph in input_placeholders])",
            "+",
            "+        # Split on the CPU in case the data doesn't fit in GPU memory.",
            "+        with tf.device(\"/cpu:0\"):",
            "+            data_splits = zip(",
            "+                *[tf.split(ph, len(devices)) for ph in input_placeholders])",
            "+",
            "self._towers = []",
            "for device, device_placeholders in zip(self.devices, data_splits):",
            "self._towers.append(self._setup_device(device,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1349,
        "label": "no",
        "change": [
            "class TorchHook(FrameworkHook):",
            "@wraps(attr)",
            "def overloaded_attr(self_torch, *args, **kwargs):",
            "ptr = hook_self.local_worker.send_command(",
            "-                recipient=self_torch.worker(), message=(f\"{'torch'}.{attr}\", None, args, kwargs)",
            "+                recipient=self_torch.worker(),",
            "+                cmd_name=f\"{'torch'}.{attr}\",",
            "+                args_=args,",
            "+                kwargs_=kwargs,",
            ")",
            "",
            "return ptr.wrap()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1352,
        "label": "no",
        "change": [
            "class TransformerModel(nn.Module):",
            "def init_weights(self):",
            "initrange = 0.1",
            "nn.init.uniform_(self.encoder.weight, -initrange, initrange)",
            "-        nn.init.zeros_(self.decoder)",
            "+        nn.init.zeros_(self.decoder.weight)",
            "nn.init.uniform_(self.decoder.weight, -initrange, initrange)",
            "",
            "def forward(self, src, has_mask=True):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1354,
        "label": "no",
        "change": [
            "def xyz_to_rgb(image: torch.Tensor) -> torch.Tensor:",
            "y: torch.Tensor = image[..., 1, :, :]",
            "z: torch.Tensor = image[..., 2, :, :]",
            "",
            "-    r: torch.Tensor = 3.240479 * x + -1.53715 * y + -0.498535 * z",
            "-    g: torch.Tensor = -0.969256 * x + 1.875991 * y + 0.041556 * z",
            "-    b: torch.Tensor = 0.055648 * x + -0.204043 * y + 1.057311 * z",
            "+    r: torch.Tensor = 3.2404813432005266 * x + -1.5371515162713185 * y + -0.4985363261688878 * z",
            "+    g: torch.Tensor = -0.9692549499965682 * x + 1.8759900014898907 * y + 0.0415559265582928 * z",
            "+    b: torch.Tensor = 0.0556466391351772 * x + -0.2040413383665112 * y + 1.0573110696453443 * z",
            "",
            "out: torch.Tensor = torch.stack((r, g, b), dim=-3)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1356,
        "label": "no",
        "change": [
            "def set_stub_weight_to_torch(stub_layer, torch_layer):",
            "",
            "",
            "def set_stub_weight_to_keras(stub_layer, keras_layer):",
            "-    stub_layer.export_weights_keras(keras_layer)",
            "\\ No newline at end of file",
            "+    stub_layer.export_weights_keras(keras_layer)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1357,
        "label": "no",
        "change": [
            "class MultiHeadAttention(nn.Module):",
            "# perform attention, result size = (n_head * mb_size) x len_q x d_v",
            "outputs, attns = self.attention(q_s, k_s, v_s, attn_mask=attn_mask.repeat(n_head, 1, 1))",
            "",
            "-        # back to original mb_size batch",
            "-        outputs = outputs.view(mb_size, len_q, -1)            # mb_size x len_q x (n_head*d_v)",
            "+        # back to original mb_size batch, result size = mb_size x len_q x (n_head*d_v)",
            "+        outputs = torch.cat(torch.split(outputs, mb_size, dim=0), dim=-1)",
            "",
            "# project back to residual size",
            "outputs = self.proj(outputs)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1360,
        "label": "no",
        "change": [
            "class TestTokenCharactersEncoder(AllenNlpTestCase):",
            "",
            "def test_forward_applies_embedding_then_encoder(self):",
            "numpy_tensor = numpy.random.randint(6, size=(3, 4, 7))",
            "-        inputs = Variable(torch.from_numpy(numpy_tensor))",
            "+        inputs = torch.from_numpy(numpy_tensor)",
            "encoder_output = self.encoder(inputs)",
            "reshaped_input = inputs.view(12, 7)",
            "embedded = self.embedding(reshaped_input)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1361,
        "label": "no",
        "change": [
            "def default_data_collator(features: List[InputDataClass]) -> Dict[str, torch.Ten",
            "if isinstance(v, torch.Tensor):",
            "batch[k] = torch.stack([f[k] for f in features])",
            "else:",
            "-                batch[k] = torch.tensor([f[k] for f in features], dtype=torch.long)",
            "+                batch[k] = torch.tensor([f[k] for f in features])",
            "",
            "return batch"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1363,
        "label": "yes",
        "change": [
            "def get_timestep_embedding(",
            "assert len(timesteps.shape) == 1, \"Timesteps should be a 1d-array\"",
            "",
            "half_dim = embedding_dim // 2",
            "-    exponent = -math.log(max_period) * torch.arange(start=0, end=half_dim, dtype=torch.float32)",
            "+    exponent = -math.log(max_period) * torch.arange(",
            "+        start=0, end=half_dim, dtype=torch.float32, device=timesteps.device",
            "+    )",
            "exponent = exponent / (half_dim - downscale_freq_shift)",
            "",
            "-    emb = torch.exp(exponent).to(device=timesteps.device)",
            "+    emb = torch.exp(exponent)",
            "emb = timesteps[:, None].float() * emb[None, :]",
            "",
            "# scale embeddings"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 1364,
        "label": "no",
        "change": [
            "def test_section_1_differential_privacy():",
            "query_result = np.argmax(counts)",
            "query_result",
            "",
            "-    from syft.frameworks.torch.differential_privacy import pate",
            "+    from syft.frameworks.torch.dp import pate",
            "",
            "num_teachers, num_examples, num_labels = (100, 100, 10)",
            "preds = (np.random.rand(num_teachers, num_examples) * num_labels).astype(int)  # fake preds"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1365,
        "label": "no",
        "change": [
            "class TestNormalize:",
            "f = kornia.enhance.Normalize(mean=mean, std=std)",
            "data = torch.ones(2, 3, 256, 313)",
            "if isinstance(mean, float):",
            "-            expected = (data - torch.tensor(mean)) / torch.tensor(std)",
            "+            expected = (data - torch.as_tensor(mean)) / torch.as_tensor(std)",
            "else:",
            "-            expected = (data - torch.tensor(mean[0])) / torch.tensor(std[0])",
            "+            expected = (data - torch.as_tensor(mean[0])) / torch.as_tensor(std[0])",
            "assert_close(f(data), expected)",
            "",
            "@staticmethod"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1368,
        "label": "no",
        "change": [
            "class Categorical(Distribution):",
            "logits = [log(prob) for _ in range(util.prod(shape)) for prob in probabilities]",
            "action_size = util.prod(self.shape) * self.num_actions",
            "",
            "-        with tf.name_scope(name=scope):",
            "-            self.logits = Linear(size=action_size, bias=logits, scope='logits')",
            "+        self.logits = Linear(size=action_size, bias=logits, scope='logits')",
            "",
            "super(Categorical, self).__init__(scope, summary_labels)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1371,
        "label": "no",
        "change": [
            "class Data(object):",
            "return self",
            "",
            "def cuda(self, props=None):",
            "-        func = lambda x: x.cuda() if torch.cuda.is_available() else x  # noqa",
            "+        def func(x):",
            "+            return x.cuda() if torch.cuda.is_available() else x",
            "+",
            "return self._transer(func, props)",
            "",
            "def cpu(self, props=None):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1372,
        "label": "no",
        "change": [
            "class LanguageModel(nn.Module):",
            "encoded = self.encoder(input)",
            "emb = self.drop(encoded)",
            "",
            "+        self.rnn.flatten_parameters()",
            "+",
            "output, hidden = self.rnn(emb, hidden)",
            "",
            "if self.proj is not None:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1373,
        "label": "yes",
        "change": [
            "def train_func(config):",
            "train_dataset = Subset(train_dataset, list(range(64)))",
            "validation_dataset = Subset(validation_dataset, list(range(64)))",
            "",
            "-    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"])",
            "-    validation_loader = DataLoader(validation_dataset, batch_size=config[\"batch_size\"])",
            "+    worker_batch_size = config[\"batch_size\"] // train.world_size()",
            "+",
            "+    train_loader = DataLoader(train_dataset, batch_size=worker_batch_size)",
            "+    validation_loader = DataLoader(validation_dataset, batch_size=worker_batch_size)",
            "",
            "train_loader = train.torch.prepare_data_loader(train_loader)",
            "validation_loader = train.torch.prepare_data_loader(validation_loader)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api parameter"
    },
    {
        "number": 1374,
        "label": "no",
        "change": [
            "class ModelTesterMixin:",
            "memory_after_parallelization = get_current_gpu_memory_use()",
            "",
            "# Assert that the memory use on all devices is higher than it was when loaded only on CPU",
            "-            for n in range(torch.cuda.device_count()):",
            "+            for n in range(len(model.device_map.keys())):",
            "self.assertGreater(memory_after_parallelization[n], memory_at_start[n])",
            "",
            "# Assert that the memory use of device 0 is lower than it was when the entire model was loaded on it"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1377,
        "label": "no",
        "change": [
            "def deconv2d(x, kernel, output_shape, strides=(1, 1),",
            "x = _preprocess_conv2d_input(x, dim_ordering)",
            "output_shape = _preprocess_deconv_output_shape(output_shape, dim_ordering)",
            "kernel = _preprocess_conv2d_kernel(kernel, dim_ordering)",
            "-    kernel = tf.transpose(kernel, (0, 1, 3, 2))  # tranpose kernel chanels",
            "+    kernel = tf.transpose(kernel, (0, 1, 3, 2))",
            "padding = _preprocess_border_mode(border_mode)",
            "strides = (1,) + strides + (1,)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1378,
        "label": "no",
        "change": [
            "class FNetEmbeddings(nn.Module):",
            "if version.parse(torch.__version__) > version.parse(\"1.6.0\"):",
            "self.register_buffer(",
            "\"token_type_ids\",",
            "-                torch.zeros(self.position_ids.size(), dtype=torch.long, device=self.position_ids.device),",
            "+                torch.zeros(self.position_ids.size(), dtype=torch.long),",
            "persistent=False,",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1380,
        "label": "no",
        "change": [
            "class Conv2dSubsampling(torch.nn.Module):",
            "torch.nn.ReLU()",
            ")",
            "self.out = torch.nn.Sequential(",
            "-            torch.nn.Linear(odim * (idim // 4), odim),",
            "+            torch.nn.Linear(odim * ((idim - 1)// 4), odim),",
            "PositionalEncoding(odim, dropout_rate)",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1383,
        "label": "no",
        "change": [
            "class TestInvertAffineTransform:",
            "",
            "def test_rot90_batch(self, device):",
            "angle = torch.tensor([90.]).to(device)",
            "-        scale = torch.tensor([1.]).to(device)",
            "+        scale = torch.tensor([[1., 1.]]).to(device)",
            "center = torch.tensor([[0., 0.]]).to(device)",
            "expected = torch.tensor([[",
            "[0., -1., 0.],"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1384,
        "label": "no",
        "change": [
            "class LDMSuperResolutionPipelineIntegrationTests(unittest.TestCase):",
            "ldm.to(torch_device)",
            "ldm.set_progress_bar_config(disable=None)",
            "",
            "-        generator = torch.Generator(device=torch_device).manual_seed(0)",
            "+        generator = torch.manual_seed(0)",
            "image = ldm(image=init_image, generator=generator, num_inference_steps=20, output_type=\"numpy\").images",
            "",
            "image_slice = image[0, -3:, -3:, -1]",
            "",
            "assert image.shape == (1, 256, 256, 3)",
            "-        expected_slice = np.array([0.7418, 0.7472, 0.7424, 0.7422, 0.7463, 0.726, 0.7382, 0.7248, 0.6828])",
            "+        expected_slice = np.array([0.7644, 0.7679, 0.7642, 0.7633, 0.7666, 0.7560, 0.7425, 0.7257, 0.6907])",
            "+",
            "assert np.abs(image_slice.flatten() - expected_slice).max() < 1e-2"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1386,
        "label": "no",
        "change": [
            "class TestMeshEdgeLoss(unittest.TestCase):",
            "loss = mesh_edge_loss(meshes, target_length=target_length)",
            "",
            "predloss = TestMeshEdgeLoss.mesh_edge_loss_naive(meshes, target_length)",
            "-        self.assertTrue(torch.allclose(loss, predloss))",
            "+        self.assertClose(loss, predloss)",
            "",
            "@staticmethod",
            "def mesh_edge_loss("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1387,
        "label": "no",
        "change": [
            "lambd = .99  # decay factor",
            "e = 0.1  # e-Greedy Exploration, the larger the more random",
            "num_episodes = 10000",
            "with tf.Session() as sess:",
            "-    tl.layers.initialize_global_variables(sess)",
            "+    sess.run(tf.global_variables_initializer())",
            "for i in range(num_episodes):",
            "## Reset environment and get first new observation",
            "episode_time = time.time()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1390,
        "label": "no",
        "change": [
            "sess = tf.InteractiveSession()",
            "",
            "batch_size = 128",
            "x = tf.placeholder(tf.float32, shape=[None, 784])",
            "-y_ = tf.placeholder(",
            "-    tf.int64, shape=[",
            "-        None,",
            "-    ])",
            "+y_ = tf.placeholder(tf.int64, shape=[None])",
            "",
            "",
            "def keras_block(x):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1392,
        "label": "no",
        "change": [
            "def ceil(x: torch.Tensor, *, out: Optional[torch.Tensor] = None) -> torch.Tensor",
            "return torch.ceil(x, out=out)",
            "",
            "",
            "-def floor(x: torch.Tensor,",
            "-          *,",
            "-          out: Optional[torch.Tensor] = None",
            "-          ) -> torch.Tensor:",
            "+def floor(x: torch.Tensor, *, out: Optional[torch.Tensor] = None) -> torch.Tensor:",
            "if \"int\" in str(x.dtype):",
            "if ivy.exists(out):",
            "return ivy.inplace_update(out, x)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1393,
        "label": "no",
        "change": [
            "class CTC(torch.nn.Module):",
            "self.probs = None  # for visualization",
            "",
            "# In case of Pytorch >= 1.7.0, CTC will be always builtin",
            "-        self.ctc_type = (",
            "-            ctc_type",
            "-            if LooseVersion(torch.__version__) < LooseVersion(\"1.7.0\")",
            "-            else \"builtin\"",
            "-        )",
            "+        self.ctc_type = ctc_type if V(torch.__version__) < V(\"1.7.0\") else \"builtin\"",
            "",
            "if ctc_type != self.ctc_type:",
            "logging.warning(f\"CTC was set to {self.ctc_type} due to PyTorch version.\")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1396,
        "label": "no",
        "change": [
            "class BLEU(Metric):",
            "self._prediction_lengths += dist_reduce_sum(_prediction_lengths)",
            "self._reference_lengths += dist_reduce_sum(_reference_lengths)",
            "",
            "-    @overrides",
            "def get_metric(self, reset: bool = False) -> Dict[str, float]:",
            "",
            "brevity_penalty = self._get_brevity_penalty()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1397,
        "label": "yes",
        "change": [
            "def binary_config():",
            "def test_binary_input_feature(binary_config: Dict, encoder: str) -> None:",
            "binary_config.update({\"encoder\": encoder})",
            "binary_input_feature = BinaryInputFeature(binary_config)",
            "-    binary_tensor = torch.randn([SEQ_SIZE, BINARY_W_SIZE], dtype=torch.float32)",
            "+    binary_tensor = torch.randn([SEQ_SIZE, BINARY_W_SIZE], dtype=torch.float32).to(DEVICE)",
            "encoder_output = binary_input_feature(binary_tensor)",
            "assert encoder_output[\"encoder_output\"].shape[1:] == binary_input_feature.output_shape"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 1399,
        "label": "yes",
        "change": [
            "class TestEulerFromQuaternion(BaseTester):",
            "def test_module(self, device, dtype):",
            "pass",
            "",
            "-    def test_jit(self, device, dtype):",
            "+    def test_dynamo(self, device, dtype, torch_optimizer):",
            "q = Quaternion.random(batch_size=1)",
            "q = q.to(device, dtype)",
            "op = euler_from_quaternion",
            "-        op_jit = torch.jit.script(op)",
            "-        assert_close(op(q.w, q.x, q.y, q.z), op_jit(q.w, q.x, q.y, q.z))",
            "+        op_optimized = torch_optimizer(op)",
            "+        assert_close(op(q.w, q.x, q.y, q.z), op_optimized(q.w, q.x, q.y, q.z))",
            "",
            "def test_forth_and_back(self, device, dtype):",
            "q = Quaternion.random(batch_size=2)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "algorithm error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1401,
        "label": "no",
        "change": [
            "class AdadeltaFactory(OptimizerFactoryInterface):",
            "",
            "\"\"\"",
            "return torch.optim.Adadelta(",
            "-            target,",
            "-            rho=args.rho,",
            "-            eps=args.eps,",
            "-            weight_decay=args.weight_decay,",
            "+            target, rho=args.rho, eps=args.eps, weight_decay=args.weight_decay",
            ")"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1402,
        "label": "no",
        "change": [
            "class ESPnetSVSModel(AbsESPnetModel):",
            "midi_score_lengths = torch.tensor([len(midi_score)])",
            "tempo_score_lengths = torch.tensor([len(tempo_score)])",
            "beat_score_phn_lengths = torch.tensor([len(beat_score_phn)])",
            "-        beat_score_syb_lengths = torch.tensor([len(beat_score_syb)])",
            "assert (",
            "label_score_lengths == midi_score_lengths",
            "and label_score_lengths == tempo_score_lengths"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1403,
        "label": "no",
        "change": [
            "class StyleTokenLayer(nn.Module):",
            "self.key_dim = embedding_dim // num_heads",
            "self.style_tokens = nn.Parameter(",
            "torch.FloatTensor(num_style_tokens, self.key_dim))",
            "-        nn.init.orthogonal_(self.style_tokens)",
            "+        nn.init.normal_(self.style_tokens, mean=0, std=0.5)",
            "self.attention = MultiHeadAttention(",
            "query_dim=self.query_dim,",
            "key_dim=self.key_dim,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1405,
        "label": "yes",
        "change": [
            "def run(",
            "seen, windows, dt = 0, [], (Profile(), Profile(), Profile())",
            "for path, im, im0s, vid_cap, s in dataset:",
            "with dt[0]:",
            "-            im = torch.Tensor(im).to(device)",
            "+            im = torch.Tensor(im).to(model.device)",
            "im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32",
            "if len(im.shape) == 3:",
            "im = im[None]  # expand for batch dim"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1407,
        "label": "no",
        "change": [
            "class Gamma(Distribution):",
            "alpha = alpha.expand_as(x)",
            "beta = beta.expand_as(x)",
            "ll_1 = - beta * x",
            "-        ll_2 = (alpha - pyro.ones(x.size())) * torch.log(x)",
            "+        ll_2 = (alpha - 1.0) * torch.log(x)",
            "ll_3 = alpha * torch.log(beta)",
            "ll_4 = - log_gamma(alpha)",
            "return ll_1 + ll_2 + ll_3 + ll_4"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1409,
        "label": "no",
        "change": [
            "class UnCLIPPipelineIntegrationTests(unittest.TestCase):",
            "pipeline = pipeline.to(torch_device)",
            "pipeline.set_progress_bar_config(disable=None)",
            "",
            "-        generator = torch.Generator(device=torch_device).manual_seed(0)",
            "+        generator = torch.Generator(device=\"cpu\").manual_seed(0)",
            "output = pipeline(",
            "\"horse\",",
            "num_images_per_prompt=1,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1412,
        "label": "no",
        "change": [
            "class Reporter:",
            "if LooseVersion(torch.__version__) >= LooseVersion(\"1.4.0\"):",
            "if torch.cuda.is_initialized():",
            "stats[\"gpu_max_cached_mem_GB\"] = (",
            "-                    torch.cuda.max_memory_reserved() / 2**30",
            "+                    torch.cuda.max_memory_reserved() / 2 ** 30",
            ")",
            "else:",
            "if torch.cuda.is_available() and torch.cuda.max_memory_cached() > 0:",
            "-                stats[\"gpu_cached_mem_GB\"] = torch.cuda.max_memory_cached() / 2**30",
            "+                stats[\"gpu_cached_mem_GB\"] = torch.cuda.max_memory_cached() / 2 ** 30",
            "",
            "self.stats.setdefault(self.epoch, {})[sub_reporter.key] = stats",
            "sub_reporter.finished()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1413,
        "label": "no",
        "change": [
            "def fit_circle_in_3d(",
            "Circle3D object",
            "\"\"\"",
            "centroid = points.mean(0)",
            "-    r = _get_rotation_to_best_fit_xy(points, centroid)",
            "+    r = get_rotation_to_best_fit_xy(points, centroid)",
            "normal = r[:, 2]",
            "rotated_points = (points - centroid) @ r",
            "result_2d = fit_circle_in_2d("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1415,
        "label": "yes",
        "change": [
            "class SwapBufferManager(object):",
            "self.count = count",
            "self.dtype = dtype",
            "self.all_buffers = [",
            "-            torch.zeros(num_elems,",
            "-                        device='cpu',",
            "-                        dtype=dtype).pin_memory() for _ in range(count)",
            "+            get_accelerator().pin_memory(",
            "+                torch.zeros(num_elems,",
            "+                            device='cpu',",
            "+                            dtype=dtype)) for _ in range(count)",
            "]",
            "self.free_buffer_index = [i for i in range(count)]",
            "self.used_buffer_index = {}"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1416,
        "label": "no",
        "change": [
            "class ViTMAEDecoder(nn.Module):",
            "[ViTMAELayer(decoder_config) for _ in range(config.decoder_num_hidden_layers)]",
            ")",
            "",
            "-        self.decoder_norm = nn.LayerNorm(config.decoder_hidden_size)",
            "+        self.decoder_norm = nn.LayerNorm(config.decoder_hidden_size, eps=config.layer_norm_eps)",
            "self.decoder_pred = nn.Linear(",
            "config.decoder_hidden_size, config.patch_size**2 * config.num_channels, bias=True",
            ")  # encoder to decoder"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1421,
        "label": "no",
        "change": [
            "def main():",
            "n_vocab = len(char_list)",
            "",
            "# for debug, small data",
            "-    # train = train[:100000]",
            "-    # valid = valid[:100]",
            "+    train = train[:100000]",
            "+    valid = valid[:100]",
            "",
            "# for debug, ptb data",
            "# train, valid, _ = chainer.datasets.get_ptb_words()"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1422,
        "label": "no",
        "change": [
            "def _setup_ddp(rank, worldsize):",
            "def _ddp_test_fn(rank, worldsize):",
            "_setup_ddp(rank, worldsize)",
            "tensor = torch.tensor([1.0])",
            "-    actual = LightningModule._LightningModule__sync(tensor, sync_dist=True, sync_dist_op=torch.distributed.ReduceOp.SUM)",
            "+    sync = _Sync(sync_ddp_if_available, should=True, op=torch.distributed.ReduceOp.SUM)",
            "+    actual = sync(tensor)",
            "assert actual.item() == dist.get_world_size(), \"Result-Log does not work properly with DDP and Tensors\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1425,
        "label": "no",
        "change": [
            "class ESPnetTTSModel(AbsESPnetModel):",
            ")[0][0]",
            "if self.energy_normalize is not None:",
            "energy = self.energy_normalize(energy[None])[0][0]",
            "-            kwargs[\"energy\"] = energy",
            "+            if energy is not None:",
            "+                kwargs[\"energy\"] = energy",
            "",
            "if spembs is not None:",
            "kwargs[\"spembs\"] = spembs"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1426,
        "label": "no",
        "change": [
            "class TFFlaubertMainLayer(tf.keras.layers.Layer):",
            "# encoder attention (for decoder only)",
            "# if self.is_decoder and src_enc is not None:",
            "#     attn = self.encoder_attn[i](tensor, src_mask, kv=src_enc, cache=cache)",
            "-            #     attn = F.dropout(attn, p=self.dropout, training=self.training)",
            "+            #     attn = nn.functional.dropout(attn, p=self.dropout, training=self.training)",
            "#     tensor = tensor + attn",
            "#     tensor = self.layer_norm15[i](tensor)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1427,
        "label": "yes",
        "change": [
            "def test_gcn2_conv():",
            "",
            "t = '(Tensor, Tensor, SparseTensor, OptTensor) -> Tensor'",
            "jit = torch.jit.script(conv.jittable(t))",
            "-    assert torch.allclose(conv(x, x_0, adj1.t()), out1, atol=1e-6)",
            "-    assert torch.allclose(conv(x, x_0, adj2.t()), out2, atol=1e-6)",
            "+    assert torch.allclose(jit(x, x_0, adj1.t()), out1, atol=1e-6)",
            "+    assert torch.allclose(jit(x, x_0, adj2.t()), out2, atol=1e-6)",
            "",
            "conv.cached = True",
            "conv(x, x_0, edge_index)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1428,
        "label": "no",
        "change": [
            "def mpi_discovery(distributed_port=TORCH_DISTRIBUTED_DEFAULT_PORT, verbose=True)",
            "os.environ['MASTER_PORT']))",
            "",
            "if torch.distributed.is_initialized():",
            "-        assert torch.distributed.get_rank() == rank, \"MPI rank {} does not match torch rank {}\".format(rank, dist.get_rank())",
            "+        assert torch.distributed.get_rank() == rank, \"MPI rank {} does not match torch rank {}\".format(",
            "+            rank, torch.distributed.get_rank())",
            "assert torch.distributed.get_world_size() == world_size, \"MPI world size {} does not match torch world size {}\".format(",
            "world_size, torch.distributed.get_world_size())"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1430,
        "label": "no",
        "change": [
            "class Model(ModelDesc):",
            ".FullyConnected('fc1', 512, nl=tf.nn.relu) \\",
            ".FullyConnected('linear', out_dim=self.cifar_classnum, nl=tf.identity)()",
            "",
            "-        cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, label)",
            "+        cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)",
            "cost = tf.reduce_mean(cost, name='cross_entropy_loss')",
            "",
            "wrong = symbf.prediction_incorrect(logits, label)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1431,
        "label": "no",
        "change": [
            "def get_wordlm():",
            "char_dict = {x: i for i, x in enumerate(char_list)}",
            "word_dict = {x: i for i, x in enumerate(word_list)}",
            "",
            "-    rnnlm = lm_pytorch.ClassifierWithState(",
            "+    word_rnnlm = lm_pytorch.ClassifierWithState(",
            "lm_pytorch.RNNLM(len(word_list), n_layers, n_units)",
            ")",
            "word_rnnlm = lm_pytorch.ClassifierWithState("
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1433,
        "label": "no",
        "change": [
            "class TFModelV2(ModelV2):",
            "name,",
            "framework=\"tf\")",
            "self.var_list = []",
            "-        if tf.executing_eagerly():",
            "+        if tf1.executing_eagerly():",
            "self.graph = None",
            "else:",
            "-            self.graph = tf.get_default_graph()",
            "+            self.graph = tf1.get_default_graph()",
            "",
            "def context(self):",
            "\"\"\"Returns a contextmanager for the current TF graph.\"\"\""
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1434,
        "label": "no",
        "change": [
            "def stats(policy, train_batch):",
            "\"cur_lr\": tf.cast(policy.cur_lr, tf.float64),",
            "\"policy_loss\": policy.loss.pi_loss,",
            "\"policy_entropy\": policy.loss.entropy,",
            "-        \"var_gnorm\": tf.global_norm(list(policy.model.trainable_variables())),",
            "+        \"var_gnorm\": tf.linalg.global_norm(",
            "+            list(policy.model.trainable_variables())),",
            "\"vf_loss\": policy.loss.vf_loss,",
            "}",
            "",
            "",
            "def grad_stats(policy, train_batch, grads):",
            "return {",
            "-        \"grad_gnorm\": tf.global_norm(grads),",
            "+        \"grad_gnorm\": tf.linalg.global_norm(grads),",
            "\"vf_explained_var\": explained_variance(",
            "train_batch[Postprocessing.VALUE_TARGETS],",
            "policy.model.value_function()),"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1435,
        "label": "yes",
        "change": [
            "def test_load_dataset_streaming(dataset_loading_script_dir, data_dir):",
            "def test_loading_from_the_datasets_hub():",
            "with tempfile.TemporaryDirectory() as tmp_dir:",
            "dataset = load_dataset(SAMPLE_DATASET_IDENTIFIER, cache_dir=tmp_dir)",
            "-        assert len(dataset[\"train\"]), 2",
            "-        assert len(dataset[\"validation\"]), 3",
            "+        assert len(dataset[\"train\"]) == 2",
            "+        assert len(dataset[\"validation\"]) == 3",
            "del dataset"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "null reference error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1436,
        "label": "no",
        "change": [
            "class Model(nn.Module):",
            "m = self.model[-1]  # Detect() module",
            "for mi, s in zip(m.m, m.stride):  # from",
            "b = mi.bias.view(m.na, -1)  # conv.bias(255) to (3,85)",
            "-            b[:, 4] += math.log(8 / (640 / s) ** 2)  # obj (8 objects per 640 image)",
            "-            b[:, 5:] += math.log(0.6 / (m.nc - 0.99)) if cf is None else torch.log(cf / cf.sum())  # cls",
            "+            b.data[:, 4] += math.log(8 / (640 / s) ** 2)  # obj (8 objects per 640 image)",
            "+            b.data[:, 5:] += math.log(0.6 / (m.nc - 0.99)) if cf is None else torch.log(cf / cf.sum())  # cls",
            "mi.bias = torch.nn.Parameter(b.view(-1), requires_grad=True)",
            "",
            "def _print_biases(self):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1438,
        "label": "no",
        "change": [
            "class TrainingOperator:",
            "",
            "logger.debug(\"Registering optimizers.\")",
            "self._optimizers = optimizers",
            "-        if not isinstance(self._optimizers, Iterable):",
            "+        if isinstance(self._optimizers, torch.optim.Optimizer):",
            "self._optimizers = [self._optimizers]",
            "",
            "if schedulers:"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1441,
        "label": "no",
        "change": [
            "class CnnHighwayEncoder(Seq2VecEncoder):",
            "``encoding``:",
            "Shape ``(batch_size, projection_dim)`` tensor with context-insensitive token representations.",
            "\"\"\"",
            "-        # pylint: disable=arguments-differ",
            "-",
            "# convolutions want (batch_size, embedding_dim, num_characters)",
            "inputs = inputs.transpose(1, 2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1442,
        "label": "no",
        "change": [
            "class VisionNetwork(Model):",
            "conv2, 512, [10, 10], padding=\"VALID\", scope=\"fc1\")",
            "fc2 = slim.conv2d(fc1, num_outputs, [1, 1], activation_fn=None,",
            "normalizer_fn=None, scope=\"fc2\")",
            "-            return tf.squeeze(fc2, [1, 2])",
            "+            return tf.squeeze(fc2, [1, 2]), tf.squeeze(fc1, [1, 2])"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1443,
        "label": "no",
        "change": [
            "class LayoutLMModel(LayoutLMPreTrainedModel):",
            "token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)",
            "",
            "if bbox is None:",
            "-            bbox = torch.zeros(tuple(list(input_shape) + [4]), dtype=torch.long, device=device)",
            "+            bbox = torch.zeros(input_shape + (4,), dtype=torch.long, device=device)",
            "",
            "extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1445,
        "label": "no",
        "change": [
            "class BertModel(BertPreTrainedModel):",
            "",
            "# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]",
            "# ourselves in which case we just need to make it broadcastable to all heads.",
            "-        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(",
            "-            attention_mask, input_shape, self.device",
            "-        )",
            "+        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(attention_mask, input_shape, device)",
            "",
            "# If a 2D ou 3D attention mask is provided for the cross-attention",
            "# we need to make broadcastabe to [batch_size, num_heads, seq_length, seq_length]"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1446,
        "label": "no",
        "change": [
            "def batch_average(input, slice):",
            "\"\"\"Averages ``input`` features in the node dimension. Batch information is",
            "given by ``slice``.",
            "",
            "-    Example::",
            "+    Example:",
            "",
            "-        >>>> input = torch.FloatTensor([[1, 2], [3, 4], [5, 6], [7, 8]])",
            "-        >>>> slice = torch.LongTensor([2, 4])",
            "-        >>>> output = batch_average(input, slice)",
            "-        >>>> # [[2, 3], [6, 7]]",
            "+        >>> input = torch.FloatTensor([[1, 2], [3, 4], [5, 6], [7, 8]])",
            "+        >>> slice = torch.LongTensor([2, 4])",
            "+        >>> output = batch_average(input, slice)",
            "+        >>> # [[2, 3], [6, 7]]",
            "\"\"\"",
            "",
            "last_index = 0"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1447,
        "label": "no",
        "change": [
            "class SpatialTransformer2dAffineLayer(Layer):",
            "# 4. Get all parameters",
            "variables = tf.get_collection(TF_GRAPHKEYS_VARIABLES, scope=vs.name)",
            "",
            "-        # # fixed",
            "-        # self.all_layers = list(layer.all_layers)",
            "-        # self.all_params = list(layer.all_params)",
            "-        # self.all_drop = dict(layer.all_drop)",
            "-        #",
            "# # theta_layer",
            "# self.all_layers.extend(theta_layer.all_layers)",
            "# self.all_params.extend(theta_layer.all_params)",
            "# self.all_drop.update(theta_layer.all_drop)",
            "",
            "-        # this layer",
            "self.all_layers.append(self.outputs)",
            "self.all_params.extend(variables)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1448,
        "label": "no",
        "change": [
            "import tensorlayer as tl",
            "def model(x, is_train=True, reuse=False, name_scope=\"env1\"):",
            "with tf.variable_scope(name_scope, reuse=reuse):",
            "net = tl.layers.InputLayer(x, name='input')",
            "-        net = tl.layers.TimeDistributedLayer(net, layer_class=tl.layers.DenseLayer, args={'n_units': 50, 'name': 'dense'}, name='time_dense')",
            "+        net = tl.layers.TimeDistributedLayer(",
            "+            net, layer_class=tl.layers.DenseLayer, args={",
            "+                'n_units': 50,",
            "+                'name': 'dense'",
            "+            }, name='time_dense'",
            "+        )",
            "return net",
            "",
            "",
            "class Layer_Time_Distributed_Test(CustomTestCase):",
            "+",
            "@classmethod",
            "def setUpClass(cls):"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1449,
        "label": "no",
        "change": [
            "class RNNLM(nn.Module):",
            "super(RNNLM, self).__init__()",
            "self.embed = nn.Embedding(n_vocab, n_embed)",
            "if typ == \"lstm\":",
            "-            self.rnn = nn.ModuleList( [nn.LSTMCell(n_embed, n_units)] + [nn.LSTMCell(n_units, n_units) for _ in range(n_layers - 1)] )",
            "+            self.rnn = nn.ModuleList(",
            "+                [nn.LSTMCell(n_embed, n_units)] + [nn.LSTMCell(n_units, n_units) for _ in range(n_layers - 1)]",
            "+                )",
            "else:",
            "-            self.rnn = nn.ModuleList( [nn.GRUCell(n_embed, n_units)] + [nn.GRUCell(n_units, n_units) for _ in range(n_layers - 1)] )",
            "-",
            "+            self.rnn = nn.ModuleList(",
            "+                [nn.GRUCell(n_embed, n_units)] + [nn.GRUCell(n_units, n_units) for _ in range(n_layers - 1)]",
            "+                )",
            "+",
            "self.dropout = nn.ModuleList(",
            "[nn.Dropout(dropout_rate) for _ in range(n_layers + 1)])",
            "self.lo = nn.Linear(n_units, n_vocab)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1450,
        "label": "yes",
        "change": [
            "class BertForQuestionAnswering(nn.Module):",
            "",
            "def compute_loss(logits, positions):",
            "max_position = positions.max().item()",
            "-                one_hot = torch.FloatTensor(batch_size, max(max_position, seq_length) +1, device=input_ids.device).zero_()",
            "+                one_hot = torch.FloatTensor(batch_size, max(max_position, seq_length) +1).zero_()",
            "one_hot = one_hot.scatter(1, positions.cpu(), 1) # Second argument need to be LongTensor and not cuda.LongTensor",
            "-                one_hot = one_hot[:, :seq_length]",
            "+                one_hot = one_hot[:, :seq_length].to(input_ids.device)",
            "log_probs = nn.functional.log_softmax(logits, dim = -1).view(batch_size, seq_length)",
            "loss = -torch.mean(torch.sum(one_hot*log_probs), dim = -1)",
            "return loss"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api parameter"
    },
    {
        "number": 1451,
        "label": "no",
        "change": [
            "class BagOfEmbeddingsEncoder(Seq2VecEncoder):",
            "summed = summed / lengths.unsqueeze(-1).float()",
            "",
            "if length_mask is not None:",
            "-                summed = summed * (length_mask > 0).float().unsqueeze(-1)",
            "+                summed = summed * (length_mask > 0).unsqueeze(-1)",
            "",
            "return summed"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1459,
        "label": "no",
        "change": [
            "def vec_like(n: int, tensor: torch.Tensor, shared_memory: bool = False):",
            "if len(tensor.shape) < 1:",
            "raise AssertionError(tensor.shape)",
            "",
            "-    vec = torch.zeros(n, 1, device=tensor.device, dtype=tensor.dtype)",
            "+    vec = zeros(n, 1, device=tensor.device, dtype=tensor.dtype)",
            "return vec[None].expand(tensor.shape[0], n, 1) if shared_memory else vec[None].repeat(tensor.shape[0], 1, 1)"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1462,
        "label": "no",
        "change": [
            "class LanguageModel(Model):",
            "return_dict = {}",
            "",
            "# If we have target tokens, calculate the loss.",
            "-        token_ids = source.get(\"tokens\")",
            "-        if token_ids is not None:",
            "+        token_id_dict = source.get(\"tokens\")",
            "+        if token_id_dict is not None:",
            "+            token_ids = token_id_dict[\"tokens\"]",
            "assert isinstance(contextual_embeddings, torch.Tensor)",
            "",
            "# Use token_ids to compute targets"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1463,
        "label": "yes",
        "change": [
            "def main():",
            "",
            "# Save the result as an audio summary.",
            "datestring = str(datetime.now()).replace(' ', 'T')",
            "-    writer = tf.train.SummaryWriter(logdir)",
            "-    tf.audio_summary('generated', decode, wavenet_params['sample_rate'])",
            "-    summaries = tf.merge_all_summaries()",
            "+    writer = tf.summary.FileWriter(logdir)",
            "+    tf.summary.audio('generated', decode, wavenet_params['sample_rate'])",
            "+    summaries = tf.summary.merge_all()",
            "summary_out = sess.run(summaries,",
            "feed_dict={samples: np.reshape(waveform, [-1, 1])})",
            "writer.add_summary(summary_out)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 1465,
        "label": "yes",
        "change": [
            "def load_indexes():",
            "",
            "@st.cache(allow_output_mutation=True)",
            "def load_train_data():",
            "-    eli5 = nlp.load_dataset(\"eli5\", name=\"LFQA_reddit\")",
            "+    eli5 = datasets.load_dataset(\"eli5\", name=\"LFQA_reddit\")",
            "eli5_train = eli5[\"train_eli5\"]",
            "eli5_train_q_reps = np.memmap(",
            "\"eli5_questions_reps.dat\", dtype=\"float32\", mode=\"r\", shape=(eli5_train.num_rows, 128)"
        ],
        "comments": "",
        "Symptom": "unexpected output",
        "Root_Cause": "deprecation management error",
        "Action": "change",
        "Element": "api call"
    },
    {
        "number": 1466,
        "label": "yes",
        "change": [
            "def depthwise_conv2d(",
            "dilations: Optional[Union[int, Tuple[int, int]]] = 1,",
            "out: Optional[torch.Tensor] = None,",
            ") -> torch.Tensor:",
            "-    x = torch.tensor(x)",
            "-    filters = torch.tensor(filters)",
            "+    x = torch.as_tensor(x)",
            "+    filters = torch.as_tensor(filters)",
            "strides = [strides] * 2 if isinstance(strides, int) else strides",
            "strides = [strides[1], strides[2]] if len(strides) == 4 else strides",
            "dilations = [dilations] * 2 if isinstance(dilations, int) else dilations",
            "-    filters = ivy.squeeze(filters, 3) if filters.ndim == 4 else filters",
            "+    filters = ivy.squeeze(filters, 3).to_native() if filters.ndim == 4 else filters",
            "",
            "f_w_after_dilation = filters.shape[1] + (",
            "(dilations[1] - 1) * (filters.shape[1] - 1)"
        ],
        "comments": "",
        "Symptom": "low efficiency",
        "Root_Cause": "deprecation management error",
        "Action": "update",
        "Element": "api call"
    },
    {
        "number": 1468,
        "label": "no",
        "change": [
            "class SequenceTagger(flair.nn.Model):",
            "lengths: List[int] = [len(sentence.tokens) for sentence in sentences]",
            "longest_token_sequence_in_batch: int = max(lengths)",
            "",
            "-        pre_allocated_zero_tensor = t = torch.zeros(",
            "+        pre_allocated_zero_tensor = torch.zeros(",
            "self.embeddings.embedding_length * longest_token_sequence_in_batch,",
            "dtype=torch.float,",
            "device=flair.device,"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1469,
        "label": "no",
        "change": [
            "def test_lite_dataloader_device_placement(src_device_str, dest_device_str):",
            "iterator = iter(lite_dataloader)",
            "",
            "batch0 = next(iterator)",
            "-    # TODO: This should be torch.equal, but not supported on MPS at this time (torch 1.12)",
            "-    assert torch.allclose(batch0, torch.tensor([0, 1], device=dest_device))",
            "+    # TODO: torch.equal is not supported on MPS at this time (torch 1.12)",
            "+    assert torch.equal(batch0, torch.tensor([0, 1], device=dest_device))",
            "",
            "batch1 = next(iterator)",
            "-    # TODO: This should be torch.equal, but not supported on MPS at this time (torch 1.12)",
            "-    assert torch.allclose(batch1[\"data\"], torch.tensor([2, 3], device=dest_device))",
            "+    # TODO: torch.equal is not supported on MPS at this time (torch 1.12)",
            "+    assert torch.equal(batch1[\"data\"], torch.tensor([2, 3], device=dest_device))",
            "",
            "",
            "def test_lite_optimizer_wraps():"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    },
    {
        "number": 1470,
        "label": "no",
        "change": [
            "Returns:",
            "\"\"\"",
            "",
            "",
            "-class Sacrebleu(nlp.Metric):",
            "+class Sacrebleu(datasets.Metric):",
            "def _info(self):",
            "-        return nlp.MetricInfo(",
            "+        return datasets.MetricInfo(",
            "description=_DESCRIPTION,",
            "citation=_CITATION,",
            "homepage=\"https://github.com/mjpost/sacreBLEU\",",
            "inputs_description=_KWARGS_DESCRIPTION,",
            "-            features=nlp.Features(",
            "+            features=datasets.Features(",
            "{",
            "-                    \"predictions\": nlp.Value(\"string\", id=\"sequence\"),",
            "-                    \"references\": nlp.Sequence(nlp.Value(\"string\", id=\"sequence\"), id=\"references\"),",
            "+                    \"predictions\": datasets.Value(\"string\", id=\"sequence\"),",
            "+                    \"references\": datasets.Sequence(datasets.Value(\"string\", id=\"sequence\"), id=\"references\"),",
            "}",
            "),",
            "codebase_urls=[\"https://github.com/mjpost/sacreBLEU\"],"
        ],
        "comments": "",
        "Symptom": "",
        "Root_Cause": "",
        "Action": "",
        "Element": ""
    }
]